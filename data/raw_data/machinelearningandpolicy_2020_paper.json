[
    {
        "paper_title": "The impact of e-learning and social parameters on students' academic performance",
        "publication": "Science for Education Today",
        "citied_by": "5",
        "cover_date": "2020-12-31",
        "Abstract": "Introduction. The article examines the problem of assessing students' academic performance in the current situation. The purpose of the paper is to evaluate the influence of e-learning and some social and behavioral parameters on students' academic performance. Materials and Methods. The author employed the machine learning procedures in order to identify and assess the current problems of the educational system, students' behavior, and universities' policy. Methods of mathematical analysis and statistics as well as ensemble methods (gradient boosting and the random forest algorithms) were used in order to achieve high accuracy of the research. Results. The author conducted the analysis of the following datasets devoted to academic performance at higher and secondary educational institutions in a number of countries: Students' Performance in Portugal, E-learning Student Reactions and Students' Academic Performance. The purposes of the current study were to identify statistical correlations between social parameters of students and the level of their academic performance and to understand how academic performance is determined by the implementation of online learning and blended learning. The research findings suggest that mathematical statistics and data analysis methods allow to identify correlations between students' performance data and reveal hidden relationships which can be important for university staff. Conclusions. In conclusion, the author summarizes the results of evaluating the impact of the introduction of e-learning elements and some social parameters on students' academic performance.",
        "DOI": "10.15293/2658-6762.2006.08",
        "paper_author": "Petrusevich D.A.",
        "affiliation_name": "MIREA - Russian Technological University (RTU MIREA)",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60096204",
        "affiliation_state": "Moscow Oblast"
    },
    {
        "paper_title": "Learning method for autonomous air combat based on experience transfer",
        "publication": "Hangkong Xuebao/Acta Aeronautica et Astronautica Sinica",
        "citied_by": "2",
        "cover_date": "2020-12-25",
        "Abstract": "Most of the existing machine learning methods are in interactive learning mode, whose training process relies heavily on the interactive data with the environment. Air combat is a training mission with sparse rewards, with the system usually exploring for a long period of time to find actions that can obtain rewards during the beginning stage of learning. Retraining for every new mission wastes the computing resources. Therefore, a learning method based on experience transfer is designed in this paper, enabling the trained agent to share knowledge with the new agent and thereby improving its learning efficiency in the new task. First of all, a learning model based on experience transfer is constructed by referring to the phenomenon that mankind can learn rapidly through experiences. Secondly, considering both the knowledge sharing and characteristics of the new task, the connotation of experience is defined, and a cognitive mode of \"knowledge + task → experience\" is established. Thirdly, a reference learning method is designed, combining external experience with the task to further transform it into knowledge of the new agent. Finally, using experience applicability as the screening index, we analyze the influence of experience applicability on the reference learning efficiency, determining the screening boundary of implementing the reference learning. The new agent can therefore obtain preliminary knowledge about the new mission by reference learning and find action policies that can obtain reward so as to improve the learning speed in the new learning mission.",
        "DOI": "10.7527/S1000-6893.2020.24285",
        "paper_author": "Zhou K.",
        "affiliation_name": "Air Force Engineering University China",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60069720",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Proceedings of 2020 7th International Conference on Networking, Systems and Security, NSysS 2020",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-12-22",
        "Abstract": "The proceedings contain 15 papers. The topics discussed include: can COVID-19 change the Big5 personality traits of healthcare workers?; attacks on health workers during COVID-19 pandemic - data exploration and news article detection using NLP and GRU model; application of machine learning based hospital up-gradation policy for Bangladesh; a benchmark study on machine learning methods using several feature extraction techniques for news genre detection from Bangla news articles & titles; machine learning based malware detection on encrypted traffic: a comprehensive performance study; efficient feature selection for detecting botnets based on network traffic and behavior analysis; and solving the maze of diagnosing Parkinson’s disease based on portable EEG sensing to be adaptable to go in-the-wild.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of Machine Learning Based Hospital Up-gradation Policy for Bangladesh",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "4",
        "cover_date": "2020-12-22",
        "Abstract": "Hospital beds are an essential part of delivering medical services to the patients. Due to the hospital bed demand's stochastic nature, it is hard to predict future needs and devise an appropriate augmentation scheme. In this work, we consider Bangladesh as a test case where hospital beds are inadequate, and a sudden surge in demand can cause a massive loss of lives and wealth. We propose a deep reinforcement learning (RL) based policy for hospital capacity up-gradation schedule. The deep RL agent monitors population growth and current bed capacity and recommends the optimal number of beds for future inclusion. We utilize the state-of-the-art machine learning (ML) algorithm, Advantage Actor-Critic (A2C), to minimize the cumulative cost. This policy outperforms the straight forward strategies: Fixed upgrade and complain based upgrade.",
        "DOI": "10.1145/3428363.3428364",
        "paper_author": "Shuvo S.S.",
        "affiliation_name": "University of South Florida, Tampa",
        "affiliation_city": "Tampa",
        "affiliation_country": "United States",
        "affiliation_id": "60007740",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Social media security threats investigation and mitigation methods: A preliminary review",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "4",
        "cover_date": "2020-12-22",
        "Abstract": "Recent advancement of data collection and coupled statistics, big data became a significant issue in various research areas like: Machine learning, data mining, social networks, artificial intelligence, etc. Social networking is used as a platform for various applications like: government, business, educational, political, dating and matrimonial, etc. Like each and every platform, social networking too has its own set of pros and cons. We examine the types of posting on social media websites and influence of posting data and privacy concerns of Facebook and twitter users. This study indicates the different concerns of users regarding posting information and its influences of user voiced privacy concerns. It is beneficial in fields like: education, advertisements, online shopping but people get addicted to social networking, its time consuming in various issues and can be misused for cybercrimes. We've discussed the e-government objectives of using social media. Social networking is also vulnerable at different stages and attacked in several ways that includes evil twin attack, virus attack, phishing attack, account hijacking, data breach attack, fraud and scams. Site monitoring, developing security policies, educating users and training programs, updating software, archiving, media contents are several mitigation techniques are used to reduce the effects of cyber-attacks.",
        "DOI": "10.1088/1742-6596/1706/1/012142",
        "paper_author": "Singh M.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India",
        "affiliation_id": "60111704",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Gender and ethnic differences in publication of BMJ letters to the editor: An observational study using machine learning",
        "publication": "BMJ Open",
        "citied_by": "10",
        "cover_date": "2020-12-21",
        "Abstract": "Objectives To analyse the relationship between first author's gender and ethnicity (estimated from first name and surname), and chance of publication of rapid responses in the British Medical Journal (BMJ). To analyse whether other features of the rapid response account for any gender or ethnic differences, including the presence of multiple authors, declaration of conflicts of interests, the presence of Twitter handle, word count, reading ease, spelling and grammatical mistakes, and the presence of references. Design A retrospective observational study. Setting Website of the BMJ (BMJ.com). Participants Publicly available rapid responses submitted to BMJ.com between 1998 and 2018. Main outcome measures Publication of a rapid response as a letter to the editor in the BMJ. Results We analysed 113 265 rapid responses, of which 8415 were published as letters to the editor (7.4%). Statistically significant univariate correlations were found between odds of publication and first author estimated gender and ethnicity, multiple authors, declaration of conflicts of interest, the presence of Twitter handle, word count, reading ease, spelling and grammatical mistakes, and the presence of references. Multivariate analysis showed that first author estimated gender and ethnicity predicted publication after taking into account the other factors. Compared to white authors, black authors were 26% less likely to be published (OR: 0.74, CI: 0.57-0.96), Asian and Pacific Islander authors were 46% less likely to be published (OR: 0.54, CI: 0.49-0.59) and Hispanic authors were 49% less likely to be published (OR: 0.51, CI: 0.41-0.64). Female authors were 10% less likely to be published (OR: 0.90, CI: 0.85-0.96) than male authors. Conclusion Ethnic and gender differences in rapid response publication remained after accounting for a broad range of features, themselves all predictive of publication. This suggests that the reasons for the differences of these groups lies elsewhere.",
        "DOI": "10.1136/bmjopen-2020-037269",
        "paper_author": "Zeina M.",
        "affiliation_name": "Barts Health NHS Trust",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60159931",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Log-based malicious activity detection using machine and deep learning",
        "publication": "Malware Analysis Using Artificial Intelligence and Deep Learning",
        "citied_by": "0",
        "cover_date": "2020-12-20",
        "Abstract": "This chapter describes the application of intelligent computational techniques to the problem of malicious activity detection. It is proposed to embed machine and deep learning models for malicious activity detection into the framework of a log-based decision support system (DSS) for information security administrators. It is expected that such a solution will enable organizational-wide protection of informational assets, by providing accurate and comprehensive real-time insights into violations of information security policies. In this work, we present experiments and results on database systems' log analysis using traditional machine learning (ML) methods and deep learning (DL) on the synthetic log dataset simulating user activity in a hypothetical company.",
        "DOI": "10.1007/978-3-030-62582-5_23",
        "paper_author": "Tarnowska K.A.",
        "affiliation_name": "San Jose State University",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States",
        "affiliation_id": "60015609",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Multi-Agent Reinforcement Learning using the Deep Distributed Distributional Deterministic Policy Gradients Algorithm",
        "publication": "2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies, 3ICT 2020",
        "citied_by": "9",
        "cover_date": "2020-12-20",
        "Abstract": "In this paper, the Deep Distributed Distributional Deterministic Policy Gradients (D4PG) reinforcement learning algorithm is adopted to train a multi-agent action in a cooperative game environment. The algorithm is experimented on training the agents to play a game of tennis against each other. The architectures of the actor and cretic networks are meticulously designed and the D4PG hyperparameters are carefully tuned. The trained agents are successfully tested in the Unity Machine Learning Agents environment. The testing shows the powerful performance of the D4PG algorithm in training multi-agents in complex environments.",
        "DOI": "10.1109/3ICT51146.2020.9311945",
        "paper_author": "Farag W.",
        "affiliation_name": "American University of the Middle East",
        "affiliation_city": "Al Ahmadi",
        "affiliation_country": "Kuwait",
        "affiliation_id": "60105846",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessment of machine learning, time series, response surface methodology and empirical models in prediction of global solar radiation",
        "publication": "Journal of Cleaner Production",
        "citied_by": "118",
        "cover_date": "2020-12-20",
        "Abstract": "Solar radiation (SR) knowledge plays a vital role in the design, modelling, and operation of solar energy conversion systems and future energy investment policies of the governments. However, these data are not measured for all regions due to the non-availability of SR measurement equipment at the weather stations. Therefore, SR has to be accurately predicted using various prediction models. In this research, four models from different classes are being used to predict monthly average daily global SR data. The models used in this study are based on a machine-learning algorithm (feed-forward neural network), empirical models (3 Angstrom-type models), time series (Holt-Winters), and mathematical model (RSM). As the prediction locations, four provinces (Ankara, Karaman, Kilis, and Şırnak) in Turkey are selected. The dataset including pressure, relative humidity, wind speed, ambient temperature, and sunshine duration is supplied from the Turkish State Meteorological Service and it covers the years 2008–2018. In the study, monthly average daily global SR data for the year 2018 is being predicted, and the performance success of the models is discussed in terms of the following benchmarks R2, MBE, RMSE, MAPE, and t-stat. In the results, R2 value for all models is varying between 0.952 and 0.993 and MAPE and RMSE value for all models is smaller than 10% and 2 MJ/m2-day, respectively. Evaluation in terms of t-stat value, no models exceed the t-critic limit. Considering all the models together, ANN has presented the best results with an average R2, MBE, RMSE, MAPE, and t-stat of 0.9911, 0.1323 MJ/m2-day, 0.78 MJ/m2-day, 4.9263%, and 0.582, respectively. Then Holt-Winters, RSM, and empirical models closely followed it, respectively.",
        "DOI": "10.1016/j.jclepro.2020.122353",
        "paper_author": "Gürel A.E.",
        "affiliation_name": "Düzce Üniversitesi",
        "affiliation_city": "Duzce",
        "affiliation_country": "Türkiye",
        "affiliation_id": "60024371",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Vision-Based Deep Learning Inference Approach of Biker Safety Hat Detection System",
        "publication": "7th IEEE International Conference on Engineering Technologies and Applied Sciences, ICETAS 2020",
        "citied_by": "0",
        "cover_date": "2020-12-18",
        "Abstract": "In the Philippines road accidents were prevalent among motorcycle riders. The motorcyclist was required to wear their helmet when on the road. Some motorcyclists didn't follow the rules on wearing a helmet as safety precautions on the road. To address this, policymakers are focusing on enforcing safe and law-abiding behavior in traffic. There is, however, a lack of comprehensive data on the safety-critical behavioral metric of the use of motorcycle helmets, especially in developing countries where the main mode of transport is the motorcycle. Targeted enforcement and safety campaigns that are critical for accident reduction are prohibited by this shortage of knowledge. Hence, The researchers developed an algorithm for detecting the helmet that was worn by the motorcyclist, by using a deep learning approach the object detection was done successfully. Based on the annotated images, frames of video, and live feed data that was collected, To detect active bikes, the researchers taught the algorithm to use their helmets. An overview of the algorithm's success on an annotated research data set and a study of available data on the use of human-registered helmets indicate that our approach is extremely reliable.",
        "DOI": "10.1109/ICETAS51660.2020.9484194",
        "paper_author": "MacAlisang J.",
        "affiliation_name": "Technological University of the Philippines",
        "affiliation_city": "Manila",
        "affiliation_country": "Philippines",
        "affiliation_id": "60105065",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An evaluation of neural machine translation and pre-trained word embeddings in multilingual neural sentiment analysis",
        "publication": "Proceedings of 2020 IEEE International Conference on Progress in Informatics and Computing, PIC 2020",
        "citied_by": "8",
        "cover_date": "2020-12-18",
        "Abstract": "One of the main elements in several application domains, such as policy making, addresses the scope of public opinion analysis. The latter is recently realized through sentiment analysis and Natural Language Processing, for identifying and extracting subjective information from raw texts. An additional challenge refers to the exploitation and correlation of data from different languages, in order to analyse sentiments by considering all available information in a holistic way. This paper investigates the impact of Neural Machine Translation in sentiment analysis, based on the translation of text for which neural sentiment analysis in English has been already applied and is applied again on the translated German and Greek texts. The latter is performed through the same Neural Network models that were used in the original language, in order to analyse the differences between the performed neural sentiment analysis on the source and the target languages. The outcomes of the proposed approach have a twofold interpretation. While, it is concluded that modern Neural Machine Translation tools are mature enough to provide high accuracy translations and have minor impact on multilingual sentiment analysis, on the other hand it is shown that additional research should be performed on the multilingualism that pre-trained Word Embeddings can provide.",
        "DOI": "10.1109/PIC50277.2020.9350849",
        "paper_author": "Manias G.",
        "affiliation_name": "University of Piraeus",
        "affiliation_city": "Piraeus",
        "affiliation_country": "Greece",
        "affiliation_id": "60010667",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "Verhealth Vetting medical voice applications through policy enforcement",
        "publication": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies",
        "citied_by": "18",
        "cover_date": "2020-12-17",
        "Abstract": "Healthcare applications on Voice Personal Assistant System (e.g., Amazon Alexa), have shown a great promise to deliver personalized health services via a conversational interface. However, concerns are also raised about privacy, safety, and service quality. In this paper, we propose VerHealth, to systematically assess health-related applications on Alexa for how well they comply with existing privacy and safety policies. VerHealth contains a static module and a dynamic module based on machine learning that can trigger and detect violation behaviors hidden deep in the interaction threads. We use VerHealth to analyze 813 health-related applications on Alexa by sending over 855,000 probing questions and analyzing 863,000 responses. We also consult with three medical school students (domain experts) to confirm and assess the potential violations. We show that violations are quite common, e.g., 86.36% of them miss disclaimers when providing medical information; 30.23% of them store user physical or mental health data without approval. Domain experts believe that the applications' medical suggestions are often factually-correct but are of poor relevance, and applications should have asked more questions before providing suggestions for over half of the cases. Finally, we use our results to discuss possible directions for improvements.",
        "DOI": "10.1145/3432233",
        "paper_author": "Shezan F.H.",
        "affiliation_name": "University of Virginia",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States",
        "affiliation_id": "60021918",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Machine-learned models for the performance of six different solar PV technologies under the tropical environment",
        "publication": "2020 IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2020",
        "citied_by": "4",
        "cover_date": "2020-12-16",
        "Abstract": "Due to the recent environmental concerns and long-term challenges in energy security, the Global energy scenarios are shifting more towards sustainable and renewable energy resources. Brunei has planned to increase the use of cleaner energy technologies by contributing 10 percent or 954 GWh of renewable energy in its power generation mix by 2035. Out of the available renewable options, solar is the most promising one for Brunei, for example, the daily average solar installation is around 5kWh per day [1]. Though solar energy is an abundant resource, for optimally designing and successfully managing solar power projects, its availability in different time scales are to be analyzed and understood in a local context. In this paper, we present models for estimating the output of six different solar PV technologies using machine learning methods Performance data from the solar PV systems installed at the Tenaga Suria PV plant in Brunei are used to develop the models. Influence of relevant environmental parameters, such as irradiance, relative humidity, ambient temperature and wind speed on the power output has been analyzed for optimal feature selection. Performance models based on Support Vector Machine (SVM) and K-Nearest Neighbour (KNN) were developed and tested for predicting the PV system performance. Both the models could estimate the system performance with reasonably high level of accuracy.",
        "DOI": "10.1109/CSDE50874.2020.9411543",
        "paper_author": "Yassin H.",
        "affiliation_name": "Faculty of Integrated Technologies",
        "affiliation_city": "Bandar Seri Begawan",
        "affiliation_country": "Brunei Darussalam",
        "affiliation_id": "124236096",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Portfolio Optimization with 2D Relative-Attentional Gated Transformer",
        "publication": "2020 IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2020",
        "citied_by": "7",
        "cover_date": "2020-12-16",
        "Abstract": "Portfolio optimization is one of the most attentive fields that have been researched with machine learning approaches. Many researchers attempted to solve this problem using deep reinforcement learning due to its efficient inherence that can handle the property of financial markets. However, most of them can hardly be applicable to real-world trading since they ignore or extremely simplify the realistic constraints such as transaction costs or slippage. These constraints have a significantly negative impact on portfolio profitability. In this paper a conservative level of transaction fees and slippage are considered for the realistic experiment. To enhance the performance under those constraints, we propose a novel Deterministic Policy Gradient with 2D Relative-attentional Gated Transformer (DPGRGT) model. Applying learnable relative positional embeddings for the time and assets axes, the model better understands the peculiar structure of the financial data in the portfolio optimization domain. Also, gating layers and layer reordering are employed for stable convergence of Transformers in reinforcement learning. In our experiment using U.S. stock market data of 20 years, our model outperformed baseline models and demonstrated its effectiveness.",
        "DOI": "10.1109/CSDE50874.2020.9411635",
        "paper_author": "Kim T.W.",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60099659",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "The value–complexity trade-off for reinforcement learning based brain–computer interfaces",
        "publication": "Journal of Neural Engineering",
        "citied_by": "1",
        "cover_date": "2020-12-16",
        "Abstract": "Objective. One of the recent developments in the field of brain–computer interfaces (BCI) is the reinforcement learning (RL) based BCI paradigm, which uses neural error responses as the reward feedback on the agent’s action. While having several advantages over motor imagery based BCI, the reliability of RL-BCI is critically dependent on the decoding accuracy of noisy neural error signals. A principled method is needed to optimally handle this inherent noise under general conditions. Approach. By determining a trade-off between the expected value and the informational cost of policies, the info-RL (IRL) algorithm provides optimal low-complexity policies, which are robust under noisy reward conditions and achieve the maximal obtainable value. In this work we utilize the IRL algorithm to characterize the maximal obtainable value under different noise levels, which in turn is used to extract the optimal robust policy for each noise level. Main results. Our simulation results of a setting with Gaussian noise show that the complexity level of the optimal policy is dependent on the reward magnitude but not on the reward variance, whereas the variance determines whether a lower complexity solution is favorable or not. We show how this analysis can be utilized to select optimal robust policies for an RL-BCI and demonstrate its use on EEG data. Significance. We propose here a principled method to determine the optimal policy complexity of an RL problem with a noisy reward, which we argue is particularly useful for RL-based BCI paradigms. This framework may be used to minimize initial training time and allow for a more dynamic and robust shared control between the agent and the operator under different conditions.",
        "DOI": "10.1088/1741-2552/abc8d8",
        "paper_author": "Levi-Aharoni H.",
        "affiliation_name": "Hebrew University of Jerusalem",
        "affiliation_city": "Jerusalem",
        "affiliation_country": "Israel",
        "affiliation_id": "60007903",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Research on COVID-19 Global Forecast based on SIR Model-ML regression",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2020-12-16",
        "Abstract": "Under the background of the global COVID-19 pandemic, the global COVID-19 epidemic spread was modeled and analyzed, and its future trend was predicted. The dataset covers 163 countries and almost 2 full months from 2020, which is enough data to get some clues about the pandemic. The epidemic situation was predicted by the fusion of SIR model and ML regression, and the results showed that the model analysis was basically consistent with the real performance of the epidemic development. Finally, the development stage and trend of the epidemic situation are evaluated to provide a basis for the government to formulate relevant epidemic prevention policies.",
        "DOI": "10.1088/1742-6596/1693/1/012065",
        "paper_author": "Wei H.",
        "affiliation_name": "Beijing Institute of Graphic Communication",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60073441",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Spatially explicit calculation and simulation of estimating housing land consolidation potential in rural areas",
        "publication": "Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",
        "citied_by": "8",
        "cover_date": "2020-12-15",
        "Abstract": "Modeling of farmers' willingness to consolidation of abandoned homesteads plays an essential role in the prediction of regional land consolidation potential. Previous prediction models on land consolidation potential still have some limitations in the simulation of farmers' consolidation willingness and the spatial explicit prediction. The complex system modeling and machine learning provide effective tools for the behaviors simulation of land-use stakeholders. Land consolidation potential depends mainly on the farmers' willingness to consolidation, as well as the policies and land use planning. It is difficult to obtain enough negative training samples from the non-reclaimed area where farmers are opposed to the consolidation. There is a balance on the training samples, meaning that most training samples are positive. One-class classification approach has provided a good solution for the classification of imbalanced samples, due to only positive samples is selected to complete the training of classifiers. Hence, one-class classification can be used to solve the negative samples in the modeling of farmers' willingness to land consolidation. Therefore, an one class support vector machine (OCSVM) was selected to simulate the decision-making behaviors of the farmers. The OCSVM has been widely used as a type of one-class classification in image recognition and abnormal detection. A geographic information system (GIS) was used to build the model, in order to predict the land consolidation potential in a spatially explicit way. Furthermore, high-resolution remote sensing images were used to identify the abandoned homesteads in the study region. Pingtang was selected as the study area to evaluate the accuracy of model, where a mountainous and poverty town located in western Guangdong province, China. 4 449 positive samples were obtained, where the farmers would like to confer from the historical land consolidation project data in the study area. Another 141 negative samples were randomly selected from the non-reclaimed areas to evaluate the accuracy of model. Thus, a total of 4 590 unlabeled samples were obtained to train the model. The experimental results showed that the overall accuracy of model reached 96.36%, the prediction accuracy of positive sample was 96.88%, and the accuracy of negative samples was 80.14%, indicating that the performance of model was reliable for the potential prediction of land consolidation. The model was used to predict the land consolidation potential in the whole study area. The total area of abandoned homesteads identified by high-resolution remote sensing images was about 103.96 hm2, whereas, the predicted potential obtained by the model was about 94.74 hm2. However, there were many small spots in the study area that were too fragmented to be reclaimed. According to the land consolidation of Pingtang, the abandoned homesteads that can be reclaimed was only 36.02 hm2, accounting for 34.65% of the total areas. Consequently, terrain factors were also essential to affect the consolidation potential in mountainous and hilly areas. The model can be expected to better support the decision-making of land use planning, regional land remediation planning, and site selection in land remediation project.",
        "DOI": "10.11975/j.issn.1002-6819.2020.24.029",
        "paper_author": "Zou L.",
        "affiliation_name": "Guangdong Geology Surveying and Mapping Institute",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "101335147",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Impact of Urban Expansion and in Situ Greenery on Community-Wide Carbon Emissions: Method Development and Insights from 11 US Cities",
        "publication": "Environmental Science and Technology",
        "citied_by": "23",
        "cover_date": "2020-12-15",
        "Abstract": "Biogenic CO2 emissions in cities are shaped by urban land cover change which can release carbon stocks, and, carbon sequestration by in situ vegetation. To date, these two processes have not been studied together and compared with transboundary fossil fuel-based CO2 emissions of urban energy use. We leverage remote sensing and machine learning to quantify biogenic CO2 emissions between 2006 and 2012, across 11 U.S cities, including central and suburban cities, in different climate zones. Results indicate that in situ carbon sequestration by greenery varied moderately across cities (-2.1 to -0.87 Mg CO2 ha-1 yr-1), while emissions from the carbon stock change due to land conversion varied much more (-3.4 to 9.8 Mg CO2 ha-1 yr-1), indicating that the latter dominates biogenic CO2 emissions. Net biogenic CO2 emissions were negative (carbon sink) in four cities, while large net positive emissions were present in rapidly growing suburbs. As a ratio of community-wide energy use for travel and buildings, biogenic CO2 emissions were a small proportion in the core cities Denver (0.17%) and Minneapolis (0.33%) and as high as 38.2% in growing exurban communities. These results show that land cover change and greenery will be important policy levers in zero-carbon city planning.",
        "DOI": "10.1021/acs.est.0c02723",
        "paper_author": "Milnar M.",
        "affiliation_name": "University of Minnesota Twin Cities",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States",
        "affiliation_id": "60029445",
        "affiliation_state": "MN"
    },
    {
        "paper_title": "Satellite-based assessment of the long-term efficacy of PM<inf>2.5</inf> pollution control policies across the Taiwan Strait",
        "publication": "Remote Sensing of Environment",
        "citied_by": "24",
        "cover_date": "2020-12-15",
        "Abstract": "Evaluating the efficacy of air pollution control policies is an essential part of the decision-making process to develop new policies and improve existing measures. Since 2005, Fujian Province of Mainland China and Taiwan across the Taiwan Strait have both implemented aggressive air pollution control policies designed based on different principles, but a comprehensive evaluation of these control policies on PM2.5pollution levels is still lacking. In the current study, we assessed the effects of these policies in the Taiwan Strait Region from 2005 to 2018 using full-coverage, high-resolution PM2.5generated by a satellite-driven machine learning model. A ten-fold cross-validation for our prediction model showed an R2value of 0.89, demonstrating that these predictions can be used for policy evaluation. During the 14-year period, PM2.5levels in all areas of Fujian and Taiwan underwent a significant decrease. Separate regression models for policy evaluation in Taiwan and Fujian showed that all considered policies have mitigated PM2.5pollution to various degrees. The Clean Air Action Plans (CAAP) is the most effective control policy in Taiwan, while the Action Plan of Air Pollution Prevention and Control (APPC-AP) and Three-year Action Plan for Blue Skies (3YAP-BS) as well as their provincial implementation plans are the most successful in Fujian. The effectiveness of control policies, however, varies by land-use types especially for Taiwan.",
        "DOI": "10.1016/j.rse.2020.112067",
        "paper_author": "Wang L.",
        "affiliation_name": "Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60019499",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Regional Electricity Sales Forecasting Research Based on Big Data Application Service Platform",
        "publication": "2020 IEEE 3rd International Conference on Electronics and Communication Engineering, ICECE 2020",
        "citied_by": "4",
        "cover_date": "2020-12-14",
        "Abstract": "Regional monthly electricity sales forecast is an important basis for regional power grid planning and construction, evaluation of regional economic development and operation, and protection of residents' lives. It is also an important work of regional power regulation and management, decision-making of power generation and purchase, improvement of power supply equipment utilization rate and deepening of power system reform. Based on the current situation of power supply enterprise information development, distribution network business status and characteristics, this paper analyzes the factors affecting electricity sales. According to the characteristics of annual changes in electricity sales and data quality factors, the recurrent neural network model is selected based on the big data application service platform. The long short term memory neural network model performs multi-step multivariate prediction on time series, and uses the attention mechanism to combine two independent models for prediction. Experiments conducted on the historical electricity sales data set of a power supply company show that compared with traditional machine learning methods, this method has advantages in accuracy and efficiency.",
        "DOI": "10.1109/ICECE51594.2020.9352886",
        "paper_author": "Qi C.",
        "affiliation_name": "State Grid Corporation of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60004246",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting of Electricity Generation for Hydro Power Plants",
        "publication": "HONET 2020 - IEEE 17th International Conference on Smart Communities: Improving Quality of Life using ICT, IoT and AI",
        "citied_by": "3",
        "cover_date": "2020-12-14",
        "Abstract": "In today's world of modern technology and rapid increasing demand of electronics, electricity has become an essential and a vital part of our daily life. The under-developed or developing countries face several different challenges in order to manage demand and supply of electricity. The gap between demand and supply of electricity has a very strong effect on the economic growth. The forecasting of energy will play an important role for the policy makers to timely identify the sudden change in demand of electricity under given conditions. To this end, we developed a model for forecasting of electricity generation from hydro-power plants. Besides the parameters from hydropower plant, the forecasting model incorporates the temperature and rainfall in the catchment area of the dam. In this research work we analyzed the data for the energy generation trends on live data of Tarbela Dam, which consist of daily electricity generation for the last five years augmented with the temperature and rainfall data of the dam catchment area. Moreover, we have applied different supervised machine learning and time-series based models to forecast the energy production. The proposed solution is based on future forecasting of energy generation for hydro power plant, which can assist the policy makers in better decision making. The proposed research work will help in minimizing the increasing gap between energy demand and production considering weather conditions of the area. It can also help the power plant management to detect any anomaly or a failure in the electricity production of electricity by studying the deviation from the predicted trend. Our proposed method can forecast the production of electricity generation with Mean Absolute Error of 2.47 only.",
        "DOI": "10.1109/HONET50430.2020.9322841",
        "paper_author": "Javed U.",
        "affiliation_name": "National University of Sciences and Technology",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60059937",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "2020 7th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2020",
        "publication": "2020 7th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2020",
        "citied_by": "0",
        "cover_date": "2020-12-14",
        "Abstract": "The proceedings contain 42 papers. The topics discussed include: adopting machine learning to support the detection of malicious domain names; securing industrial control systems using physical device fingerprinting; a novel gateway selection protocol for three-layers integrated wireless networks; reliable abnormal event detection from IoT surveillance systems; a data generator for cloud-edge vehicle communication in multi domain cellular networks; a novel approach based on blockchain to enhance security with dynamic policy updating; scalable IoT architecture for balancing performance and security in mobile crowdsensing systems; investigating the potential of MFCC features in classifying respiratory diseases; and WSNB: wearable sensors with neural networks located in a base station for IoT environment.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "2020 59th IEEE Conference on Decision and Control, CDC 2020",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "0",
        "cover_date": "2020-12-14",
        "Abstract": "The proceedings contain 768 papers. The topics discussed include: a minimum energy filter for localization of an unmanned aerial vehicle; chance constrained covariance control for linear stochastic systems with output feedback; distributed composite adaptive synchronization of multiple uncertain Euler-Lagrange systems using cooperative initial excitation; online learning for job scheduling on heterogeneous machines; policy optimization for linear-quadratic zero-sum mean-field type games; on integral input-to-output stability properties; flexible regularization approaches for fairness in deep learning; information disclosure and network formation in news subscription services; performance analysis of stochastic model predictive control with direct and indirect feedback; distributed kalman filter for 3-D moving object tracking over sensor networks; and event-triggered control in presence of measurement noise: a space-regularization approach.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning Feedforward Control of a Hydraulic Clutch Actuation Path Based on Policy Gradients",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "0",
        "cover_date": "2020-12-14",
        "Abstract": "The hydraulic clutch actuation path used in heavy duty transmissions often shows a lot of variability due to manufacturing tolerances and ageing effects. Reason for this are in particular varying friction coefficients in the spools and external factors such as compliance with the specified service intervals or the choice of hydraulic fluid. As a direct consequence, the shift quality typically varies from one transmission to the next. To resolve this problem, this paper presents a machine learning algorithm for the feedforward control of the hydraulic clutch actuation path, a model-based and a data-based feedforward approach. The two approaches are evaluated and compared with each other in simulations with a high-fidelity model. As it turns out, the model-based version is to be preferred and therefore used in a real world evaluation on an embedded controller and a 16 tons wheel loader.",
        "DOI": "10.1109/CDC42340.2020.9303981",
        "paper_author": "Mesmer F.",
        "affiliation_name": "ZF Friedrichshafen AG",
        "affiliation_city": "Friedrichshafen",
        "affiliation_country": "Germany",
        "affiliation_id": "60072206",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Adaptive Control for Linearizable Systems Using On-Policy Reinforcement Learning",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "6",
        "cover_date": "2020-12-14",
        "Abstract": "This paper proposes a framework for adaptively learning a feedback linearization-based tracking controller for an unknown system using discrete-time model-free policy-gradient parameter update rules. The primary advantage of the scheme over standard model-reference adaptive control techniques is that it does not require the learned inverse model to be invertible at all instances of time. This enables the use of general function approximators to approximate the linearizing controller for the system without having to worry about singularities. The overall learning system is stochastic, due to the random nature of the policy gradient updates, thus we combine analysis techniques commonly employed in the machine learning literature alongside stability arguments from adaptive control to demonstrate that with high probability the tracking and parameter errors concentrate near zero, under a standard persistency of excitation condition. A simulated example of a double pendulum demonstrates the utility of the proposed theory.",
        "DOI": "10.1109/CDC42340.2020.9304242",
        "paper_author": "Westenbroek T.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "An Attention Based Deep Reinforcement Learning Method for Virtual Network Function Placement",
        "publication": "2020 IEEE 6th International Conference on Computer and Communications, ICCC 2020",
        "citied_by": "4",
        "cover_date": "2020-12-11",
        "Abstract": "Network Function Virtualization (NFV) decouples network functions from the dedicated hardware and produces Virtual Network Functions (VNFs) in software. The VNFs are placed on hardware and are linked together to build a service chain. The design of an efficient VNF placement algorithm is crucial. The rapid development of machine learning, especially Deep Reinforcement Learning (Deep RL), allows us to address this problem. In this paper, we present an attention based sequence to sequence Deep RL method for VNF placement. Our approach is a policy based method optimized by REINFORCE with baseline. Our model receives physical hosts and service chain as input and produces the output sequence step by step with attention encoder and decoder. We demonstrate that our method outperforms the existing learning method and greedy heuristic.",
        "DOI": "10.1109/ICCC51575.2020.9345041",
        "paper_author": "Li S.",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022281",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Improved Q-Learning for System Power Optimization with Temperature, Performance and Energy Constraint Modeling",
        "publication": "2020 IEEE Conference on Telecommunications, Optics and Computer Science, TOCS 2020",
        "citied_by": "0",
        "cover_date": "2020-12-11",
        "Abstract": "Power management of embedded systems based on machine learning have drawn more and more attention. High-level software power management and optimization have gradually become important technologies for controlling the computer system power dissipation. In paper, we have employed an improved power optimization management technique which employ Q-learning algorithm based on temperature, performance and energy. The improved Q-learning has been employed to control the uncertain states of the running system and can effectively make decisions to select a rational policy with multiple parameter constraints. As running hardware and application data can be effectively collected and modeled, the power management framework can easily explore an ideal policy by value function of Q-learning algorithm.",
        "DOI": "10.1109/TOCS50858.2020.9339699",
        "paper_author": "Li L.",
        "affiliation_name": "National Computer Network Emergency Response Technical Team",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "112126690",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread",
        "publication": "Patterns",
        "citied_by": "35",
        "cover_date": "2020-12-11",
        "Abstract": "We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform. As we enter the fifth month in the fight against COVID-19, it is evident that the government response to the COVID-19 pandemic has been spatially and temporally diverse. As such, the role played by the varying quarantine measures in different countries in shaping the infection growth curve is still not clear. To address this need, we have developed a novel model which lies at the intersection of the fields of epidemiology and machine learning and allows us to analyze and compare the role of quarantine control policies globally, across the continents of Europe, North America, South America and Asia (results hosted at https://covid19ml.org/). Such a robust, publicly available tool can be of significant value for studies looking at the correlation between the quarantine strength evolution in a particular region with a wide range of metrics spanning from mortality rate to socio-economic landscape impact of COVID-19 in that region. There is an urgent need to quantify the role played by quarantine policies implemented in various regions globally to curtail the spread of COVID-19. A model lying at the intersection of machine learning and epidemiology is shown to be powerful in diagnosing the quarantine policy evolution, which mimics well the real-time, on-ground situation seen in that region. The model, applied to 70 countries globally, is hosted publicly, making it a robust, useful tool in the fight against COVID-19.",
        "DOI": "10.1016/j.patter.2020.100145",
        "paper_author": "Dandekar R.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Predicting Skill Shortages in Labor Markets: A Machine Learning Approach",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "5",
        "cover_date": "2020-12-10",
        "Abstract": "Skill shortages are a drain on society. They hamper economic opportunities for individuals, slow growth for firms, and impede labor productivity in aggregate. Therefore, the ability to understand and predict skill shortages in advance is critical for policy-makers and educators to help alleviate their adverse effects. This research implements a high-performing Machine Learning approach to predict occupational skill shortages. In addition, we demonstrate methods to analyze the underlying skill demands of occupations in shortage and the most important features for predicting skill shortages. For this work, we compile a unique dataset of both Labor Demand and Labor Supply occupational data in Australia from 2012 to 2018. This includes data from 7.7 million job advertisements (ads) and 20 official labor force measures. We use these data as explanatory variables and leverage the XGBoost classifier to predict yearly skills shortage classifications for 132 standardized occupations. The models we construct achieve macro-F1 average performance scores of up to 83 per cent. Our results show that job ads data and employment statistics were the highest performing feature sets for predicting year-to-year skills shortage changes for occupations. We also find that features such as 'Hours Worked', years of 'Education', years of 'Experience', and median 'Salary' are highly important features for predicting occupational skill shortages. This research provides a robust data-driven approach for predicting and analyzing skill shortages, which can assist policy-makers, educators, and businesses to prepare for the future of work.",
        "DOI": "10.1109/BigData50022.2020.9377773",
        "paper_author": "Dawson N.",
        "affiliation_name": "University of Technology Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60023932",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Sketch and Scale Geo-distributed tSNE and UMAP",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "4",
        "cover_date": "2020-12-10",
        "Abstract": "Running machine learning analytics over geographically distributed datasets is a rapidly arising problem in the world of data management policies ensuring privacy and data security. Visualizing high dimensional data using tools such as t-distributed Stochastic Neighbor Embedding (tSNE) and Uniform Manifold Approximation and Projection (UMAP) became a common practice for data scientists. Both tools scale poorly in time and memory. While recent optimizations showed successful handling of 10,000 data points, scaling beyond million points is still challenging. We introduce a novel framework: Sketch and Scale (SnS). It leverages a Count Sketch data structure to compress the data on the edge nodes, aggregates the reduced size sketches on the master node, and runs vanilla tSNE or UMAP on the summary, representing the densest areas, extracted from the aggregated sketch.We show this technique to be fully parallel, scale linearly in time, logarithmically in memory and communication, making it possible to analyze datasets with many millions, potentially billions of data points, spread across several data centers around the globe. We demonstrate the power of our method on two mid-size datasets: cancer data with 52 million 35-band pixels from multiplex images of tumor biopsies; and astrophysics data of 100 million stars with multi-color photometry from the Sloan Digital Sky Survey (SDSS).",
        "DOI": "10.1109/BigData50022.2020.9377843",
        "paper_author": "Wei V.",
        "affiliation_name": "Johns Hopkins University",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60005248",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Privacy Preserving Proxy for Machine Learning as a Service",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "3",
        "cover_date": "2020-12-10",
        "Abstract": "In this paper, we propose a new framework called Privacy Preserving Proxy (PPP) to protect the online models. PPP is designed like a gateway to work on behalf of the users when requesting service, potentially masking the true origin of the online model from client. Instead of connecting directly to the machine learning-as-a-service(MLaaS) the clients submit the request to the PPP, which evaluates the request and executes some functions to maximize the safety of the models. PPP can potentially host a wide range of functions or triggers to control the complexity of the request or provide additional benefits such as privacy and security. We propose two different methods including Random Model Assignment and Intelligent Rounding Policy which can function inside PPP to protect the privacy of online models. To test the PPP we test TL-GAN based face reconstruction attack as a sophisticated approach which can reveal inefficiency of rounding policy as countermeasure. Our experiments show that, PPP can potentially nullify such complicated attacks in the future.",
        "DOI": "10.1109/BigData50022.2020.9378377",
        "paper_author": "Kasichainula K.",
        "affiliation_name": "University of Houston",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "60005837",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "A Deep Recurrent Neural Network to Support Guidelines and Decision Making of Social Distancing",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "2",
        "cover_date": "2020-12-10",
        "Abstract": "The recent Covid-19 pandemic instigated many changes in our way of life within the United States, and slowly but surely we are working towards mitigating the virus. Due to Covid-19, there are higher demands for models to accurately forecast the number of Covid-19 cases that factor mandated guidelines such as social-distancing. Many scholarly and corporate research entities are investigating ways to achieve this goal preemptively; Unfortunately, current models are not yet able to accurately model future Covid-19 cases that factor in various guidelines; What is lacking with these models is an understanding of crucial factors affecting spread, accuracy, availability of reported cases on a small scale, and quantifiable metrics for how social distancing and quarantine efforts mitigate the spread. Therefore, the goal of this study is to produce a mathematical model to directly aid policy decisions by comparing predicted models of various decisions and social distancing protocols. This model can be applied on top of existing models to factor in more imminent data and produce predictive curves, indicating troughs and peaks of new daily Covid-19 cases with comparatively high accuracy, which can aid in analysis. These predictive curves can, therefore, be generated using data corresponding to projected responses to proposed guidelines and compared to each other to choose the optimal solution for 'flattening the curve' of the Covid19 infection rate. We use an LSTM-RNN model with ANN Regression in an attempt to predict future Covid-19 cases. Our model achieved comparable results, but further improvements could be implemented for more optimal results.",
        "DOI": "10.1109/BigData50022.2020.9377800",
        "paper_author": "Aledhari M.",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States",
        "affiliation_id": "60019740",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "A Novel Lasso Regression Model for Sector Rotation Trading Strategies with Economy-Policy Cycles",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "1",
        "cover_date": "2020-12-10",
        "Abstract": "A variety of machine learning methods such as decision trees, support vector machines, neural networks, and natural language processing are demonstrating their utilities in the Financial Investing field. In this article, we use a novel and innovative Lasso Regression model called Post-Lasso to construct a profitable sector rotation trading strategy for the Chinese stock market. On the basis of the machine learning model, we further identify and analyze the Economy-Policy cycles, which represent a broader environment of the economy. Through combining two megatrends - macroeconomy and artificial intelligence, we develop an interpretable, reliable, and trustworthy trading system which applies well to more practical situations.",
        "DOI": "10.1109/BigData50022.2020.9377759",
        "paper_author": "Wang X.",
        "affiliation_name": "China Asset Management Co. Ltd.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "114022347",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Towards Green Query Processing - Auditing Power before Deploying",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "11",
        "cover_date": "2020-12-10",
        "Abstract": "Nowadays, energy reduction has become a critical and urgent issue for the database community. A lot of initiatives have been launched on energy-efficiency for intensive-workload computation covering individual hardware components, system software, to applications. This computation is mainly ensured by query optimizers. Their current versions minimize inputs-outputs operations and try to exploit RAM as much as possible, by ignoring energy. A couple of studies proposed the integration of energy into query optimizers that can be classified into hardware and software solutions. Several researchers have the idea that the operating systems and firmware manage energy and put software solutions in the second plan. This does not distinguish between tasks of operating systems and DBMSs. In this paper, we claim that building from scratch a green query processors and revisiting existing ones pass through 4-steps procedure: (1) establishment of a deep audit that allows understanding the query processor functioning, (2) identification of relevant energy-sensitive parameters belonging to hardware and software components, (3) elaboration of mathematical cost models estimating consumed energy when executing a query on a target DBMS and (4) setting of values of the energy-sensitive parameters using a nonlinear regression technique. To show the effectiveness of this procedure, we apply it on two open-source DBMSs with different functioning policies: PostgreSQL and MonetDB and compared them using the dataset and the workload of the TPC-H benchmark.",
        "DOI": "10.1109/BigData50022.2020.9377819",
        "paper_author": "Dembele S.P.",
        "affiliation_name": "ISAE-ENSMA",
        "affiliation_city": "Chasseneuil du Poitou",
        "affiliation_country": "France",
        "affiliation_id": "60009701",
        "affiliation_state": "Nouvelle-Aquitaine"
    },
    {
        "paper_title": "Machine Learning and OLAP on Big COVID-19 Data",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "62",
        "cover_date": "2020-12-10",
        "Abstract": "In the current technological era, huge amounts of big data are generated and collected from a wide variety of rich data sources. These big data can be of different levels of veracity in the sense that some of them are precise while some others are imprecise and uncertain. Embedded in these big data are useful information and valuable knowledge to be discovered. An example of these big data is healthcare and epidemiological data such as data related to patients who suffered from epidemic diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data - via data science techniques such as machine learning, data mining, and online analytical processing (OLAP) - helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. In this paper, we present a machine learning and big data analytic tool for processing and analyzing COVID-19 epidemiological data. Specifically, the tool makes good use of taxonomy and OLAP to generalize some specific attributes into some generalized attributes for effective big data analytics. Instead of ignoring unknown or unstated values of some attributes, the tool provides users with flexibility of including or excluding these values, depending on their preference and applications. Moreover, the tool discovers frequent patterns and their related patterns, which help reveal some useful knowledge such as absolute and relative frequency of the patterns. Furthermore, the tool learns from the patterns discovered from historical data and predicts useful information such as clinical outcomes for future data. As such, the tool helps users to get a better understanding of information about the confirmed cases of COVID-19. Although this tool is designed for machine learning and analytics of big epidemiological data, it would be applicable to machine learning and analytics of big data in many other real-life applications and services.",
        "DOI": "10.1109/BigData50022.2020.9378407",
        "paper_author": "Leung C.K.",
        "affiliation_name": "University of Manitoba",
        "affiliation_city": "Winnipeg",
        "affiliation_country": "Canada",
        "affiliation_id": "60009697",
        "affiliation_state": "MB"
    },
    {
        "paper_title": "A network science-based approach for an optimal microservice governance",
        "publication": "ICAC 2020 - 2nd International Conference on Advancements in Computing, Proceedings",
        "citied_by": "2",
        "cover_date": "2020-12-10",
        "Abstract": "In today's world of software application development, Kubernetes has emerged as one of the most effective microservice deployment technologies presently available due to its exceptional ability to deploy and orchestrate containerized microservices. However, a common issue faced in such orchestration technologies is the employment of vast arrays of disjoint monitoring solutions that fail to portray a holistic perspective on the state of microservice deployments, which consequently inhibit the creation of more optimized deployment policies. In response to this issue, this publication proposes the use of a network science-based approach to facilitate the creation of a microservice governance model that incorporates the use of dependency analysis, load prediction, centrality analysis, and resilience evaluation to effectively construct a more holistic perspective on a given microservice deployment. Furthermore, through analysis of the factors mentioned above, the research conducted, then proceeds to create an optimized deployment strategy for the deployment with the aid of a developed optimization algorithm. Analysis of results revealed the developed governance model aided through the utilization of the developed optimization algorithm proposed in this publication, proved to be quite effective in the generation of optimized microservice deployment policies.",
        "DOI": "10.1109/ICAC51239.2020.9357232",
        "paper_author": "Siriwardhana G.S.",
        "affiliation_name": "Sri Lanka Institute of Information Technology",
        "affiliation_city": "Colombo",
        "affiliation_country": "Sri Lanka",
        "affiliation_id": "60104431",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "COVID-19 Chest X-Ray Classification Using Convolutional Neural Network Architectures",
        "publication": "2020 3rd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2020",
        "citied_by": "8",
        "cover_date": "2020-12-10",
        "Abstract": "World Health Organizations declared that Coronavirus Disease 2019 (COVID-19) outbreak pandemic in March 2020. Countries around the world are stepping up effort to halt the spread of this pandemic. Some countries are scrambling to tackle this virus by applying lockdown policy. As of 10 August 2020, there have been confirmed 19.718.030 total cases and 728.013 total deaths of COVID-19 [2]. COVID-19 detection is vital to decide the subsequent step in handling the patients. One strategy that may be applied for COVID-19 detection is classification approach primarily based totally on chest x-ray of the patients. Convolutional neural network has been successfully applied in practical applications. It is a type of machine learning which the model is designed to learn classification tasks directly from an image. It recognizes patterns directly from image pixel. These patterns are used to classify images and to eliminate the need of manual feature extraction. The classification provides outcomes with recall, precision, and accuracy had been respectively 94.99%, 95%, and 95.47% for model 1 and 97.73%, 95%, and 96.59% for model 2.",
        "DOI": "10.1109/ISRITI51436.2020.9315499",
        "paper_author": "Nurtiyasari D.",
        "affiliation_name": "Universitas Gadjah Mada",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069380",
        "affiliation_state": "Yogyakarta"
    },
    {
        "paper_title": "An Advanced Policy Gradient Based Vector Control of PMSM for EV Application",
        "publication": "2020 10th International Electric Drives Production Conference, EDPC 2020 - Proceedings",
        "citied_by": "15",
        "cover_date": "2020-12-08",
        "Abstract": "Traditional proportional-integral (PI) based control has proven to be an influential control technique due to its advantage of easy implementation and robust performance for EV application. However, these controls are sensitive to plant parameters since the motor parameters change over time resulting in reduced performance and efficiency. This paper proposes a new vector control in permanent magnet synchronous motor (PMSM) with deep reinforcement learning (DRL) based controller in EV application. An advanced policy gradient algorithm is used to develop the DRL-based vector controller to overcome non-linearity in machine parameters and mitigate the decoupling inaccuracy issues in conventional control schemes. This contribution further evaluates the adaptive and dynamic performance against the conventional PI-based control and the research outlook is presented in the subsequent sections of this paper.",
        "DOI": "10.1109/EDPC51184.2020.9388187",
        "paper_author": "Bhattacharjee S.",
        "affiliation_name": "University of Windsor",
        "affiliation_city": "Windsor",
        "affiliation_country": "Canada",
        "affiliation_id": "60012468",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Expanding dimensions: A new source in the bibliometrician's toolbox",
        "publication": "Handbook Bibliometrics",
        "citied_by": "2",
        "cover_date": "2020-12-07",
        "Abstract": "Developed by Digital Science in collaboration with over 100 leading research organisations around the world, Dimensions is a unique platform combining data about publications, data sets, grants, patents, clinical trials, and policy documents. This database spans the broader global scientific landscape to enable individual researchers as well as research funders, research organizations, and publishers to discover, analyse, and understand multiple aspects of the research life cycle. This chapter introduces the development and deployment of the Dimensions platform and describes the breadth of available functionality with focus on bibliometric applications and question sets that can be applied to the academic and broader outcomes of research, and gather insights to inform future strategy.",
        "DOI": "10.1515/9783110646610-039",
        "paper_author": "Wastl J.",
        "affiliation_name": "Digital Science",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "117499655",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Functional Analysis of the 2020 U.S. Elections on Twitter and Facebook using Machine Learning",
        "publication": "Proceedings of the 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020",
        "citied_by": "1",
        "cover_date": "2020-12-07",
        "Abstract": "Social Networking Sites (SNS), such as Facebook and Twitter, are important tools for political campaigns. A line of related work analyzed political campaigns online. The initial efforts in analyzing campaign discourse functions relied on human analysis, which is time consuming and does not scale well with big data. To address these gaps, we propose a model to detect the type of campaign topics: Policy vs. Character, and how the public (commentators) responded to these messages. The proposed model yielded an accuracy of 78% (F-measure) in detecting post type. Moreover, experimental results show the analysis of commentators linguistic and psychological characteristics.",
        "DOI": "10.1109/ASONAM49781.2020.9381302",
        "paper_author": "Alashri S.",
        "affiliation_name": "King Abdulaziz City for Science and Technology",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60033126",
        "affiliation_state": "Ar Riyad"
    },
    {
        "paper_title": "Anticipating future learning affects current control decisions: A comparison between passive and active adaptive management in an epidemiological setting",
        "publication": "Journal of Theoretical Biology",
        "citied_by": "7",
        "cover_date": "2020-12-07",
        "Abstract": "Infectious disease epidemics present a difficult task for policymakers, requiring the implementation of control strategies under significant time constraints and uncertainty. Mathematical models can be used to predict the outcome of control interventions, providing useful information to policymakers in the event of such an epidemic. However, these models suffer in the early stages of an outbreak from a lack of accurate, relevant information regarding the dynamics and spread of the disease and the efficacy of control. As such, recommendations provided by these models are often incorporated in an ad hoc fashion, as and when more reliable information becomes available. In this work, we show that such trial-and-error-type approaches to management, which do not formally take into account the resolution of uncertainty and how control actions affect this, can lead to sub-optimal management outcomes. We compare three approaches to managing a theoretical epidemic: a non-adaptive management (AM) approach that does not use real-time outbreak information to adapt control, a passive AM approach that incorporates real-time information if and when it becomes available, and an active AM approach that explicitly incorporates the future resolution of uncertainty through gathering real-time information into its initial recommendations. The structured framework of active AM encourages the specification of quantifiable objectives, models of system behaviour and possible control and monitoring actions, followed by an iterative learning and control phase that is able to employ complex control optimisations and resolve system uncertainty. The result is a management framework that is able to provide dynamic, long-term projections to help policymakers meet the objectives of management. We investigate in detail the effect of different methods of incorporating up-to-date outbreak information. We find that, even in a highly simplified system, the method of incorporating new data can lead to different results that may influence initial policy decisions, with an active AM approach to management providing better information that can lead to more desirable outcomes from an epidemic.",
        "DOI": "10.1016/j.jtbi.2020.110380",
        "paper_author": "Atkins B.D.",
        "affiliation_name": "University of Warwick",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022020",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "Screening of Murabaha business process through Quran and hadith: a text mining analysis",
        "publication": "Journal of Islamic Accounting and Business Research",
        "citied_by": "13",
        "cover_date": "2020-12-06",
        "Abstract": "Purpose: This paper revolves around the usage of data analytics in the Qur’an and Hadith through a new text mining technique to answer the main research question of whether the activities and the data flows of the Murabaha financing contract is compatible with Sharia law. The purpose of this paper is to provide a thorough and comprehensive database that will be used to examine existing practices in Islamic banks’ and improve compliancy with Islamic financial law (Sharia). Design/methodology/approach: To design a Sharia-compliant Murabaha business process originated on text mining, the authors start by identifying the factors deemed necessary in their text mining techniques of both texts; using a four-step strategy to analyze those text mining analytics; then, they list the three basic approaches in text mining used for new knowledge discovery in databases: the co-occurrence approach based on the recursive co-occurrence algorithm; the machine learning or statistical-based; and the knowledge-based. They identify any variation and association between the Murabaha business processes produced using text mining against the one developed through data collection. Findings: The main finding attained in this paper is to confirm the compatibility of all activities and the data flows in the Murabaha financing contract produced using data analytics of the Quran and Hadith texts against the Murabaha business process that was developed based on data collection. Another key finding is revealing some shortcomings regarding Islamic banks business process compliance with Sharia law. Practical implications: Given Murabaha as the most popular mode of Islamic financing with more than 75% in total transactions, this research has managed to touch-base on an area that is interesting to the vast majority of those dealing with Islamic finance instruments. By reaching findings that could improve the existing Islamic Murabaha business process and concluding on Sharia compliance of the existing Murabaha business process, this research is quite relevant and could be used in practice as well as in influencing public policy. In fact, Islamic Sharia law experts, Islamic finance professionals and Islamic banks may find the results of this study very useful in improving at least one aspect of the Islamic finance transactions. Originality/value: By using a novel, fresh text mining methods built on recursive occurrence of synonym words from the Qur’an and Hadith to enrich Islamic finance, this research study can claim to have been the first of its kind in using machine learning to mine the Quran, Hadith and in extracting valuable knowledge to support and consolidate the Islamic financial business processes and make them more compliant with the i.",
        "DOI": "10.1108/JIABR-05-2020-0159",
        "paper_author": "Tlemsani I.",
        "affiliation_name": "IE Business School",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain",
        "affiliation_id": "60108973",
        "affiliation_state": "Madrid"
    },
    {
        "paper_title": "Bank loan prediction system using machine learning",
        "publication": "Proceedings of the 2020 9th International Conference on System Modeling and Advancement in Research Trends, SMART 2020",
        "citied_by": "35",
        "cover_date": "2020-12-04",
        "Abstract": "With the advancement in technology, there are so many enhancements in the banking sector also. The number of applications is increasing every day for loan approval. There are some bank policies that they have to consider while selecting an applicant for loan approval. Based on some parameters, the bank has to decide which one is best for approval. It is tough and risky to check out manually every person and then recommended for loan approval. In this work, we use a machine learning technique that will predict the person who is reliable for a loan, based on the previous record of the person whom the loan amount is accredited before. This work's primary objective is to predict whether the loan approval to a specific individual is safe or not.",
        "DOI": "10.1109/SMART50582.2020.9336801",
        "paper_author": "Gupta A.",
        "affiliation_name": "Teerthanker Mahaveer University, Moradabad",
        "affiliation_city": "Moradabad",
        "affiliation_country": "India",
        "affiliation_id": "60113718",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Making Cyberspace towards Sustainability A Scientometric Review for a Cyberspace that Enables Green and Digital Transformation",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "6",
        "cover_date": "2020-12-04",
        "Abstract": "Green and Digital Transformation, using digital technologies for green and inclusive development, has become the main agenda for both policy-makers and researchers. European Union (EU), for instance, has targeted the twin transition towards a green and digital economy by proposing a European Green Deal, guiding its investment and planning on the industrial applications using digital technologies such as artificial intelligence, big data, cloud and Internet of Things. While some work has been conducted to examine the digital transformation of different industries, no systematic review has been conducted to analyze the research fronts on the topic of green and digital transformation. With the purpose to layout an overall roadmap for industries and research, a scientometric study was conducted to map out the evolution, main journals, authors and keywords, thereby providing policy and research suggestions for science and technology innovations. This scientometric report on green and digital transformation, with its core value in summarizing scientific literature data using data science and machine learning techniques, provides timely accessible visualization for policy-makers, innovators and researchers evidence-based insights to make better decisions. Future research can build upon the preliminary findings here for the methodological, information and research need for tracking the development of green and digital transformation, so as to produce better strategic foresight.",
        "DOI": "10.1145/3444370.3444603",
        "paper_author": "Wang Z.",
        "affiliation_name": "Nanfang College of Sun Yet-sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117185",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Healthcare Management System with Sales Analytics using Autoregressive Integrated Moving Average and Google Vision",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "4",
        "cover_date": "2020-12-03",
        "Abstract": "Digitalization of different industries led to new systems that provide accurate information that results in efficient and effective services. This information is vital for decision-making and on the larger scale, policymaking especially in the health sector. In the Philippines, some healthcare establishments have not adjusted to this digital change. This study aims to develop an enhanced model of healthcare management system that can perform digitization of data, predictive health analytics and sales trend analysis. The researchers identified these three features as the focus of the system because it improves data quality, accessibility, reliability, and autonomy. The system is based on prescriptive analytics - a type of analytics that uses machine learning to process historical and predictive data. The artificially intelligent management system caters to the needs of the healthcare sector in this digital age to improve its services to the people.",
        "DOI": "10.1109/HNICEM51456.2020.9400035",
        "paper_author": "Madrid M.C.R.",
        "affiliation_name": "FEU Institute of Technology",
        "affiliation_city": "Manila",
        "affiliation_country": "Philippines",
        "affiliation_id": "60110905",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Development of Waste Management System using the Concept of 'Basura Advantage Points' through Artificial Neural Network",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "9",
        "cover_date": "2020-12-03",
        "Abstract": "One of the most pressing problems of the world is the growing solid waste pollution. With current demands for sustainable development, the researchers developed a waste segregator machine that satisfies efficient segregation and introduces the concept of reward system to motivate people to throw their waste into the machine. In this paper, the researchers created an automatic segregating machine that uses Artificial Neural Network (ANN) as an algorithm for machine learning and embedded with the concept of 'Basura Advantage Points'. The ANN acts as the brain of the machine for sorting out the plastic bottles as one category and other waste materials for the other category. The 'Basura Advantage Points' is a novel concept wherein whenever people throw a garbage into the segregating machine, they can earn points which can then be used to redeem awards set by policy makers. Survey results show that the machine is appealing to the public. Based on the sample wastes, the accuracy of the machine is around 80 percent. From positive feedbacks to successful evaluation, the study highlighted a good model to decrease improper waste disposal and encourage people to participate in proper waste segregation.",
        "DOI": "10.1109/HNICEM51456.2020.9400123",
        "paper_author": "Castro R.C.C.",
        "affiliation_name": "Bulacan State University",
        "affiliation_city": "Malolos",
        "affiliation_country": "Philippines",
        "affiliation_id": "60108105",
        "affiliation_state": "Bulacan"
    },
    {
        "paper_title": "Motorcycle Rider Helmet Detection for Riding Safety and Compliance Using Convolutional Neural Networks",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "8",
        "cover_date": "2020-12-03",
        "Abstract": "Traffic violation apprehension is one of the traffic problems here in the Philippines. One example is the No Helmet No Ride Law that is implemented but many motorists still choose to ignore. To alleviate the problem the government has offered many solutions, one of which is the No Contact Traffic Apprehension Policy that uses CCTV Monitoring. To further enhance this solution the government has partnered with the De La Salle University to use artificial intelligence in the system. Computer Vision tasks like image classification and object detection can help automate the traffic apprehension system. Image classification and object detection are technologies which are used in computer vision in defining an image or coordinates of an object in an image. In this work, a novel approach to classifying motorcycle riders between wearing a helmet or not will be developed. It will be demonstrated using deep machine learning, specifically convolutional neural network and by utilizing different pre-trained models to a gathered dataset.",
        "DOI": "10.1109/HNICEM51456.2020.9400149",
        "paper_author": "Giron N.N.F.",
        "affiliation_name": "Bulacan State University",
        "affiliation_city": "Malolos",
        "affiliation_country": "Philippines",
        "affiliation_id": "60108105",
        "affiliation_state": "Bulacan"
    },
    {
        "paper_title": "Classification between Pedestrians and Motorcycles using FasterRCNN Inception and SSD MobileNetv2",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "8",
        "cover_date": "2020-12-03",
        "Abstract": "Philippines is on the list of the top ten fastest growing economy in the world. One of its developments is in its traffic law enforcement. Today, the government is continuously finding ways on how to alleviate the problem on its roads with the use of technology. The Metro Manila Development Authority (MMDA) has offered a solution which is the No Contact Traffic Apprehension Policy, that utilizes Closed-Circuit Television (CCTV) Monitoring to apprehend vehicles violating traffic laws, rules and regulations by capturing videos and images. To further enhance this, the government has partnered with the De La Salle University to use artificial intelligence in the system with the project 'CATCH-ALL'. With the use of CCTVs and artificial intelligence system, it can help the system detect traffic violations using an automated process. But some tasks are not that easy to execute by the computer like differentiating a pedestrian and a motorcycle. In this study, a novel approach to classifying a pedestrian and a motorcycle with the use of object detection will be developed. It will be demonstrated using deep machine learning, specifically convolutional neural network and by utilizing different pre-trained models to a gathered dataset.",
        "DOI": "10.1109/HNICEM51456.2020.9400113",
        "paper_author": "Giron N.N.F.",
        "affiliation_name": "Bulacan State University",
        "affiliation_city": "Malolos",
        "affiliation_country": "Philippines",
        "affiliation_id": "60108105",
        "affiliation_state": "Bulacan"
    },
    {
        "paper_title": "A Machine-Learning Based Approach for Zoning Urban Area in Consolidation Schemes Context",
        "publication": "2020 13th International Colloquium of Logistics and Supply Chain Management, LOGISTIQUA 2020",
        "citied_by": "11",
        "cover_date": "2020-12-02",
        "Abstract": "Private freight transportation has many advantages, including speed, comfort and affordability. However, it is not often efficient to shorten longer commute times, as it is unable to keep-up with logistics demand during peak hours. Integrative policies, in flow terms, could fill this gap when supported through freight consolidation. Yet, a key issue that emerges in the implementation of consolidation-based transportation systems is that of logistics demand for reducing uncertainties about whether it will be met. The main target of this article is to include demand volatility to carry out a longterm urban land splitting that serve in building consolidation network. To that end, we propose a hybrid machine-learning framework combining several algorithms that are thought robust according to the literature and the achieved accuracy benchmarks. Based upon simulated system, some analytical outlooks are provided below.",
        "DOI": "10.1109/LOGISTIQUA49782.2020.9353901",
        "paper_author": "Ouadi J.E.",
        "affiliation_name": "Hassan II University of Casablanca",
        "affiliation_city": "Casablanca",
        "affiliation_country": "Morocco",
        "affiliation_id": "60025457",
        "affiliation_state": "Casablanca-Settat"
    },
    {
        "paper_title": "Prediction of Absenteeism at Work using Data Mining Techniques",
        "publication": "Proceedings of ICITR 2020 - 5th International Conference on Information Technology Research: Towards the New Digital Enlightenment",
        "citied_by": "7",
        "cover_date": "2020-12-02",
        "Abstract": "High absenteeism among employees can be detrimental to an organization as it can result in productivity and economic loss. This paper looks into a case of absenteeism in a courier company in Brazil. Machine learning techniques have been employed to understand and predict absenteeism. Understanding this would provide human resource managers an excellent decision aid to create policies that can aim to reduce absenteeism. Data has been preprocessed, and several machine learning classification algorithms (such as zeroR, tree-based J48, naive Bayes, and KNN) have been applied. The paper reports models that can predict absenteeism with an accuracy of over 92%. Furthermore, from an initial of 20 attributes, disciplinary failure turns out to be a very prominent feature in predicting absenteeism.",
        "DOI": "10.1109/ICITR51448.2020.9310913",
        "paper_author": "Skorikov M.",
        "affiliation_name": "North South University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60028220",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mapping coastal wetlands of the Bohai Rim at a spatial resolution of 10 M using multiple open-access satellite data and terrain indices",
        "publication": "Remote Sensing",
        "citied_by": "23",
        "cover_date": "2020-12-02",
        "Abstract": "Coastal wetlands provide essential ecosystem services and are closely related to human welfare. However, they can experience substantial degradation, especially in regions in which there is intense human activity. To control these increasingly severe problems and to develop corresponding management policies in coastal wetlands, it is critical to accurately map coastal wetlands. Although remote sensing is the most efficient way to monitor coastal wetlands at a regional scale, it traditionally involves a large amount of work, high cost, and low spatial resolution when mapping coastal wetlands at a large scale. In this study, we developed a workflow for rapidly mapping coastal wetlands at a 10 m spatial resolution, based on the recently emergent Google Earth Engine platform, using a machine learning algorithm, open-access Synthetic Aperture Radar (SAR) and optical images from the Sentinel satellites, and two terrain indices. We then generated a coastal wetland map of the Bohai Rim (BRCW10) based on the workflow. It has a producer accuracy of 82.7%, according to validation using 150 wetland samples. The BRCW10 data reflected finer information when compared to wetland maps derived from two sets of global high-spatial-resolution land cover data, due to the fusion of multiple data sources. The study highlights the benefits of simultaneously merging SAR and optical remote sensing images when mapping coastal wetlands.",
        "DOI": "10.3390/rs12244114",
        "paper_author": "Sun S.",
        "affiliation_name": "Tianjin University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60019533",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Development of a self-harm monitoring system for victoria",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "13",
        "cover_date": "2020-12-02",
        "Abstract": "The prevention of suicide and suicide-related behaviour are key policy priorities in Australia and internationally. The World Health Organization has recommended that member states develop self-harm surveillance systems as part of their suicide prevention efforts. This is also a priority under Australia’s Fifth National Mental Health and Suicide Prevention Plan. The aim of this paper is to describe the development of a state-based self-harm monitoring system in Victoria, Australia. In this system, data on all self-harm presentations are collected from eight hospital emergency departments in Victoria. A natural language processing classifier that uses machine learning to identify episodes of self-harm is currently being developed. This uses the free-text triage case notes, together with certain structured data fields, contained within the metadata of the incoming records. Post-processing is undertaken to identify primary mechanism of injury, substances consumed (including alcohol, illicit drugs and pharmaceutical preparations) and presence of psychiatric disorders. This system will ultimately leverage routinely collected data in combination with advanced artificial intelligence methods to support robust community-wide monitoring of self-harm. Once fully operational, this system will provide accurate and timely information on all presentations to participating emergency departments for self-harm, thereby providing a useful indicator for Australia’s suicide prevention efforts.",
        "DOI": "10.3390/ijerph17249385",
        "paper_author": "Robinson J.",
        "affiliation_name": "ORYGEN Youth Health",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60003438",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Roadside air quality forecasting in shanghai with a novel sequence-to-sequence model",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "13",
        "cover_date": "2020-12-02",
        "Abstract": "The establishment of an effective roadside air quality forecasting model provides important information for proper traffic management to mitigate severe pollution, and for alerting resident’s outdoor plans to minimize exposure. Current deterministic models rely on numerical simulation and the tuning of parameters, and empirical models present powerful learning ability but have not fully considered the temporal periodicity of air pollutants. In order to take the periodicity of pollutants into empirical air quality forecasting models, this study evaluates the temporal variations of air pollutants and develops a novel sequence to sequence model with weekly periodicity to forecast air quality. Two-year observation data from Shanghai roadside air quality monitoring stations are employed to support analyzing and modeling. The results conclude that the fine particulate matter (PM2.5) and carbon monoxide (CO) concentrations show obvious daily and weekly variations, and the temporal patterns are nearly consistent with the periodicity of traffic flow in Shanghai. Compared with PM2.5, the CO concentrations are more affected by traffic variation. The proposed model outperforms the baseline model in terms of accuracy, and presents a higher linear consistency in PM2.5 prediction and lower errors in CO prediction. This study could assist environmental researchers to further improve the technologies for urban air quality forecasting, and serve as tools for supporting policymakers to implement related traffic management and emission control policies.",
        "DOI": "10.3390/ijerph17249471",
        "paper_author": "Wang D.",
        "affiliation_name": "State Key Laboratory of Ocean Engineering",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60123520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A parametric study of a deep reinforcement learning control system applied to the swing-up problem of the cart-pole",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "48",
        "cover_date": "2020-12-02",
        "Abstract": "In this investigation, the nonlinear swing-up problem associated with the cart-pole system modeled as a multibody dynamical system is solved by developing a deep Reinforcement Learning (RL) controller. Furthermore, the sensitivity analysis of the deep RL controller applied to the cart-pole swing-up problem is carried out. To this end, the influence of modifying the physical properties of the system and the presence of dry friction forces are analyzed employing the cumulative reward during the task. Extreme limits for the modifications of the parameters are determined to prove that the neural network architecture employed in this work features enough learning capability to handle the task under modifications as high as 90% on the pendulum mass, as well as a 100% increment on the cart mass. As expected, the presence of dry friction greatly affects the performance of the controller. However, a post-training of the agent in the modified environment takes only thirty-nine episodes to find the optimal control policy, resulting in a promising path for further developments of robust controllers.",
        "DOI": "10.3390/app10249013",
        "paper_author": "Escobar C.A.M.",
        "affiliation_name": "Università degli Studi di Salerno",
        "affiliation_city": "Salerno",
        "affiliation_country": "Italy",
        "affiliation_id": "60007061",
        "affiliation_state": "SA"
    },
    {
        "paper_title": "Effects of low-dose hydrocortisone and hydrocortisone plus fludrocortisone in adults with septic shock: A protocol for a systematic review and meta-analysis of individual participant data",
        "publication": "BMJ Open",
        "citied_by": "2",
        "cover_date": "2020-12-02",
        "Abstract": "Introduction The benefits and risks of low-dose hydrocortisone in patients with septic shock have been investigated in numerous randomised controlled trials and trial-level meta-analyses. Yet, the routine use of this treatment remains controversial. To overcome the limitations of previous meta-analyses inherent to the use of aggregate data, we will perform an individual patient data meta-analysis (IPDMA) on the effect of hydrocortisone with or without fludrocortisone compared with placebo or usual care on 90-day mortality and other outcomes in patients with septic shock. Methods and analysis To assess the benefits and risks of hydrocortisone, with or without fludrocortisone for adults with septic shock, we will search major electronic databases from inception to September 2020 (Cochrane Central Register of Controlled Trials, MEDLINE, EMBASE and Latin American Caribbean Health Sciences Literature), complimented by a search for unpublished trials. The primary analysis will compare hydrocortisone with or without fludrocortisone to placebo or no treatment in adult patients with septic shock. Secondary analyses will compare hydrocortisone to placebo (or usual care), hydrocortisone plus fludrocortisone to placebo (or usual care), and hydrocortisone versus hydrocortisone plus fludrocortisone. The primary outcome will be all cause mortality at 90 days. We will conduct both one-stage IPDMA using mixed-effect models and machine learning with targeted maximum likelihood analyses. We will assess the risk of bias related to unshared data and related to the quality of individual trial. Ethics and dissemination This IPDMA will use existing data from completed randomised clinical trials and will comply with the ethical and regulatory requirements regarding data sharing for each of the component trials. The findings of this study will be submitted for publication in a peer-review journal with straightforward policy for open access.",
        "DOI": "10.1136/bmjopen-2020-040931",
        "paper_author": "Annane D.",
        "affiliation_name": "Université de Versailles Saint-Quentin-en-Yvelines",
        "affiliation_city": "Versailles",
        "affiliation_country": "France",
        "affiliation_id": "60029937",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Who Wants Peace? Predicting Civilian Preferences in Conflict Negotiations",
        "publication": "Journal of Politics in Latin America",
        "citied_by": "3",
        "cover_date": "2020-12-01",
        "Abstract": "Efforts to end civil wars via negotiations often generate sharp divisions in public opinion. A large, quantitative literature has found evidence for numerous variables serving as potential drivers of public support of and opposition to conflict negotiations. Yet the formation of policy preferences is a complex process, and while many factors might make small contributions to an individual’s conflict termination preferences, we lack a sense of which factors matter most or how to adjudicate among competing explanations. In this article, we leverage a large amount of nationally representative survey data from Colombia (2004–2015) and use machine learning tools to systematically explore which variables are the strongest predictors of public support for negotiations with Fuerzas Armadas Revolucionarias de Colombia (FARC). We find that certain aspects of conflict exposure, individual values bearing on justice and punishment, and belief in the efficacy of the state are among the strongest predictors of negotiation preferences, while many conventionally important variables in the literature have little predictive power. The results have implications for scholars seeking to understand broad drivers of (dis)satisfaction with negotiations and shed light on the polarising Colombian peace process.",
        "DOI": "10.1177/1866802X20960281",
        "paper_author": "Montoya A.M.",
        "affiliation_name": "Duke University",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60008724",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Socio monitoring framework (SMF): Efficient sentiment analysis through informal and native terms",
        "publication": "International Journal of Advanced and Applied Sciences",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Prediction and analysis of public expression is the trending topic of the current research arena. Opinion mining (a.k.a. Sentiment Analysis) is the automated orientation of public sentiments, views, suggestions, and opinions. It assists in estimating the popularity of products, events, services, and even political policies via user-generated content. Machine learning based supervised, semi-supervised, and unsupervised lexicon oriented techniques are applicable in the semantic orientation of public opinions about numerous real world entities. It is observed that socio channels contain real-time contents, which sometimes face the intricacy of informality, Slangs, Vernacular (Native terms), and sarcasm; however, these indicators provide high visibility of sentiments and opinions in terms of orientation. Unfortunately, the unclear perceptiveness of such contents lack in optimized orientation, and supervised machine learning systems are inappropriate where the Lexicon based opinion mining methods are preferred over learning based ones when training data is not adequate. In this paper, we seek to improve the performance of lexicon-based sentiment analysis by incorporating novel linguistic features such as vernaculars, slangs, and sarcasm for monitoring the social media contents up to a more realistic level. The core contributions are sarcasm detection and identification of vernacular terms. The performance of the proposed unsupervised lexicon-based framework over native, informal, and sarcastic opinion bearing terms is assessed via numerous experiments. For this, we utilized tweets relevant to two key domains, including Product and Politics. Experimental outcomes revealed that the proposed system outperformed the existing supervised and semi-supervised systems as 84.24%, and 82.35% of accuracies are achieved over informal and sarcastic contents for product and politics domains, respectively. The average accuracy for both domains is 83.29%.",
        "DOI": "10.21833/ijaas.2020.12.013",
        "paper_author": "Javed M.",
        "affiliation_name": "Gomal University",
        "affiliation_city": "Dera Ismail Khan",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60045003",
        "affiliation_state": "North-West Frontier Province"
    },
    {
        "paper_title": "Evaluating machine learning models for the fast identification of contingency cases",
        "publication": "Applied AI Letters",
        "citied_by": "3",
        "cover_date": "2020-12-01",
        "Abstract": "Fast approximations of power flow results are beneficial in power system planning and live operation. In planning, millions of power flow calculations are necessary if multiple years, different control strategies, or contingency policies are to be considered. In live operation, grid operators must assess if grid states comply with contingency requirements in a short time. In this paper, we compare regression and classification methods to either predict multivariable results, for example, bus voltage magnitudes and line loadings, or binary classifications of time steps to identify critical loading situations. We test the methods on three realistic power systems based on time series in 15 and 5 minutes resolution of 1 year. We compare different machine learning models, such as multilayer perceptrons (MLPs), decision trees, k-nearest neighbors, gradient boosting, and evaluate the required training time and prediction times as well as the prediction errors. We additionally determine the amount of training data needed for each method and show results, including the approximation of untrained curtailment of generation. Regarding the compared methods, we identified the MLPs as most suitable for the task. The MLP-based models can predict critical situations with an accuracy of 97% to 98% and a very low number of false negative predictions of 0.0% to 0.64%.",
        "DOI": "10.1002/ail2.19",
        "paper_author": "Schäfer F.",
        "affiliation_name": "Universität Kassel",
        "affiliation_city": "Kassel",
        "affiliation_country": "Germany",
        "affiliation_id": "60018123",
        "affiliation_state": "Hessen"
    },
    {
        "paper_title": "Who Is the Agent of Change?",
        "publication": "South Asian Journal of Business and Management Cases",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "The benefits of working in a large company are better infrastructure, well-defined policies, training and learning opportunities, job security and gradual growth. Slow decision-making due to the bureaucratic structure is a major drawback. The unique character of small firms offers agile structure, quick response, family-like atmosphere, opportunity to wear many hats as advantages, and lower compensation and restricted growth as disincentives to joining. However, if employees get their human relationships to energize, the size of the firm will be inconsequential for their success. That is, small firms can only offer a congenial atmosphere as a big firm never. Therefore, understanding what gives us energy and how we utilize it is critical for the leaders in small firms. This case study focuses on the CEO of a small family-owned firm (Nishio Glass and Mirror) whose decision to usher in positive organizational scholarship with the help of consultants set the firm on a successful journey. Even though statistics show that most change efforts fail irrespective of the size of the firm, in this case, it succeeded. This case study informs us that workplaces can be a community for people to amplify positive energy unleashing virtuous circles of growth. Research Questions: What is positive organizational scholarship? How can it be implemented in a small firm? Theory: Positive organizational scholarship and agents of change. Type of the Case: Study of a phenomenon. Basis of the Case: Phenomenon. Protagonist: Present, the CEO of the firm. Findings for Phenomenon-based Research Case: An organization is not a machine to transform resources into material properties. It is a community where people share the agentic roles with one another to let them transform. In a trustful community, people can examine the experience of ‘pregnant void’ to open a virtuous mindset; moreover, people can give suffering for others as an agent to embody the meaning of virtues. Discussions for Phenomenon-based Research Case: To manage a chaotic situation, which approach should be applied: crisis management or a proper management system? In this case, even a management system failed and dumped the CEO in psychological chaos. Which is that process that an external OD consultant can adopt to transform an organization by setting its employees on the path of self-transformation? If we apply hedonic happiness to the case, it seems to be fit for the past situation where people in the case wanted to have materialistic and short-term success. Discuss the alternative that can be applied.",
        "DOI": "10.1177/2277977920957959",
        "paper_author": "Nishikawa K.",
        "affiliation_name": "Konan University",
        "affiliation_city": "Kobe",
        "affiliation_country": "Japan",
        "affiliation_id": "60029341",
        "affiliation_state": "Hyogo"
    },
    {
        "paper_title": "Deep reinforcement learning based worker selection for distributed machine learning enhanced edge intelligence in internet of vehicles",
        "publication": "Intelligent and Converged Networks",
        "citied_by": "31",
        "cover_date": "2020-12-01",
        "Abstract": "Nowadays, Edge Information System (EIS) has received a lot of attentions. In EIS, Distributed Machine Learning (DML), which requires fewer computing resources, can implement many artificial intelligent applications efficiently. However, due to the dynamical network topology and the fluctuating transmission quality at the edge, work node selection affects the performance of DML a lot. In this paper, we focus on the Internet of Vehicles (IoV), one of the typical scenarios of EIS, and consider the DML-based High Definition (HD) mapping and intelligent driving decision model as the example. The worker selection problem is modeled as a Markov Decision Process (MDP), maximizing the DML model aggregate performance related to the timeliness of the local model, the transmission quality of model parameters uploading, and the effective sensing area of the worker. A Deep Reinforcement Learning (DRL) based solution is proposed, called the Worker Selection based on Policy Gradient (PG-WS) algorithm. The policy mapping from the system state to the worker selection action is represented by a deep neural network. The episodic simulations are built and the REINFORCE algorithm with baseline is used to train the policy network. Results show that the proposed PG-WS algorithm outperforms other comparation methods.",
        "DOI": "10.23919/ICN.2020.0015",
        "paper_author": "Dong J.",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022281",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Efficiency of Buffer Caching in Computing-Intensive Workloads",
        "publication": "Proceedings - 2020 7th International Conference on Information Science and Control Engineering, ICISCE 2020",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "With the recent advent of the fourth industrial revolution, computing-intensive workloads such as big data and machine learning emerge every day. Even though the workloads are computation-intensive, there are file I/Os to access storage, and we need to improve the I/O performance by using buffer caching. This paper analyzes the efficiency of the buffer caching in the emerging computing-intensive workloads, and observes some peculiar I/O patterns, which degrades the performance of the buffer caching significantly. To relieve this problem, we present a new buffer caching scheme for improving the I/O performance of computing-intensive workloads. Simulation experiments with real-world traces show that the proposed buffer caching scheme improves the cache miss rate against the well-known LRU buffer caching policy by 35.2% on average and up to 81.6%.",
        "DOI": "10.1109/ICISCE50968.2020.00120",
        "paper_author": "Bahn H.",
        "affiliation_name": "Ewha Womans University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60001018",
        "affiliation_state": "Seoul"
    },
    {
        "paper_title": "PrivacyCheck's machine learning to digest privacy policies: Competitor analysis and usage patterns",
        "publication": "Proceedings - 2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, WI-IAT 2020",
        "citied_by": "4",
        "cover_date": "2020-12-01",
        "Abstract": "Online privacy policies are lengthy and hard to comprehend. To address this problem, researchers have utilized machine learning (ML) to devise tools that automatically summarize online privacy policies for web users. One such tool is our free and publicly available browser extension, PrivacyCheck. In this paper, we enhance PrivacyCheck by adding a competitor analysis component-a part of PrivacyCheck that recommends other organizations in the same market sector with better privacy policies. We also monitored the usage patterns of about a thousand actual PrivacyCheck users, the first work to track the usage and traffic of an ML-based privacy analysis tool. Results show: (1) there is a good number of privacy policy URLs checked repeatedly by the user base; (2) the users are particularly interested in privacy policies of software services; and (3) PrivacyCheck increased the number of times a user consults privacy policies by 80%. Our work demonstrates the potential of ML-based privacy analysis tools and also sheds light on how these tools are used in practice to give users actionable knowledge they can use to pro-actively protect their privacy.",
        "DOI": "10.1109/WIIAT50758.2020.00042",
        "paper_author": "Zaeem R.N.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "The study for utilizing data of cut-slope management system by using logistic regression",
        "publication": "Journal of Engineering Geology",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Cut-slope management system (CSMS) has been investigated all slopes on the road of the whole country to evaluate risk rating of each slope. Based on this evaluation, the decision-making for maintenance can be conducted, and this procedure will be helpful to establish a consistent and efficient policy of safe road. CSMS has updated the database of all slopes annually, and this database is constructed based on a basic and detailed investigation. In the database, there are two type of data: first one is an objective data such as slopes’ location, height, width, length, and information about underground and bedrock, etc; second one is subjective data, which is decided by experts based on those objective data, e.g., degree of emergency and risk, maintenance solution, etc. The purpose of this study is identifying an data application plan to utilize those CSMS data. For this purpose, logistic regression, which is a basic machine-learning method to construct a prediction model, is performed to predict a judging-type variable (i.e., subjective data) based on objective data. The constructed logistic model shows the accurate prediction, and this model can be used to judge a priority of slopes for detailed investigation. Also, it is anticipated that the prediction model can filter unusual data by comparing with a prediction value.",
        "DOI": "10.9720/kseg.2020.4.649",
        "paper_author": "Woo Y.",
        "affiliation_name": "Korea Institute of Civil Engineering and Building Technology (KICT)",
        "affiliation_city": "Goyang",
        "affiliation_country": "South Korea",
        "affiliation_id": "60121523",
        "affiliation_state": "Gyeonggi-do"
    },
    {
        "paper_title": "Exploring the attractiveness of residential areas for human activities based on shared e-bike trajectory data",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "Human activities generate diverse and sophisticated functional areas and may impact the existing planning of functional areas. Understanding the relationship between human activities and functional areas is key to identifying the real-time urban functional areas based on trajectories. Few previous studies have analyzed the interactive information on humans and regions for functional area identification. The relationship between human activities and residential areas is the most representative for urban functional areas because residential areas cover a wide range and are closely connected with human life. The aim of this paper is to propose the CARA (Commuting Activity and Residential Area) model to quantify the correlation between human activities and urban residential areas. In this model, human activities are represented by hot spots extracted by the Gaussian Mixture Model algorithm while residential areas are represented by POI (point of interest) data. The model shows that human activities and residential areas present a logarithmic relationship. The CARA model is further assessed by retrieving urban residential areas in Tengzhou City from shared e-bike trajectories. Compared with the actual map, the accuracy reaches 83.3%, thus demonstrating the model’s reliability and feasibility. This study provides a new method for functional areas identification based on trajectory data, which is helpful for formulating the urban people-oriented policies.",
        "DOI": "10.3390/ijgi9120742",
        "paper_author": "Cheng X.",
        "affiliation_name": "Henan Polytechnic University",
        "affiliation_city": "Jiaozuo",
        "affiliation_country": "China",
        "affiliation_id": "60025881",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "Identifying unfamiliar callers' professions from privacy-preserving mobile phone data",
        "publication": "Proceedings - 2020 16th International Conference on Mobility, Sensing and Networking, MSN 2020",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "Identifying an unfamiliar caller's profession is important to protect citizens' personal safety and property. Due to limited data protection of many popular online services in some countries such as taxi hailing or takeouts ordering, many users encounter an increasing number of phone calls from strangers. This may aggravate the situation that criminals pretend to be delivery staff or taxi drivers, bringing threats to the society. Additionally, many people nowadays suffer from excessive digital marketing and fraud phone calls because of personal information leakage. However, previous works on malicious call detection only focused on binary classification, and do not work for identification of multiple professions. We observed that web service requests issued from users' mobile phones which may show their Apps preferences, spatial and temporal patterns, and other profession related information. This offers us a hint to identify unfamiliar callers. In fact, some previous works already leveraged raw data from mobile phones (which includes sensitive information) for personality studies. However, accessing users' mobile phone raw data may violate the more and more strict private data protection policies or regulations (e.g. GDPR 71). Using appropriate statistical methods to eliminate private information and preserve personal characteristics, provides a way to identify mobile phone callers without privacy concern. In this paper, we exploit privacy-preserving mobile data to develop a model which can automatically identify the callers who are divided into four categories of users: normal users (other professions), taxi drivers, delivery and takeouts staffs, telemarketers and fraudsters. The validation results over an anonymized dataset of 1, 282 users with a period of 3 months in Shanghai City prove that the proposed model could achieve an accuracy of 75+%.",
        "DOI": "10.1109/MSN50589.2020.00088",
        "paper_author": "Zhang J.",
        "affiliation_name": "Georg-August-Universität Göttingen",
        "affiliation_city": "Gottingen",
        "affiliation_country": "Germany",
        "affiliation_id": "60031514",
        "affiliation_state": "Niedersachsen"
    },
    {
        "paper_title": "Vehicular multi-slice optimization in 5G: Dynamic preference policy using reinforcement learning",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "5",
        "cover_date": "2020-12-01",
        "Abstract": "Network slicing, as an effective way of using heterogeneous network resources, is widely used in today's radio access network (RAN). However, because of the greater randomness of equipment capacity and mobility, the existing allocation schemes of network slicing do not make use of existing resources effectively. In this regard, this paper studies how to improve the efficiency of network slicing utilization in one base station (BS) area through deep Q-learning's allocation strategy. First, we propose an allocation strategy that uses the preference matrix to prioritize all network slices. Then, with low coupling, a realtime updating Q-learning model is developed to calculate the preference matrix. Finally, we demonstrate through simulation that our proposal can improve the efficiency of service delivery in a heterogeneous wireless network region.",
        "DOI": "10.1109/GLOBECOM42002.2020.9348132",
        "paper_author": "Zhang C.",
        "affiliation_name": "Advanced Institute of Industrial Technology",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60103937",
        "affiliation_state": "Tokyo"
    },
    {
        "paper_title": "The Digital and Assistive Technologies for Ageing initiative: learning from the GATE initiative",
        "publication": "The Lancet Healthy Longevity",
        "citied_by": "15",
        "cover_date": "2020-12-01",
        "Abstract": "NA",
        "DOI": "10.1016/S2666-7568(20)30049-0",
        "paper_author": "Khasnabis C.",
        "affiliation_name": "Organisation Mondiale de la Santé",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60027142",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Bayesian Sampler: Fairness in Sampling",
        "publication": "Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "We reinterpret the concept of Bayesian balance from Yang Liu [26] to find connection between fairness of algorithms and class imbalance in latent clusters of training data. We argue that the degree of class imbalance in the latent clusters of some training data is manifested in the lack of fairness of an algorithm trained on that data. A novel algorithm is proposed in this paper which decides an optimal policy to draw a balanced data sample from clustered raw data with class imbalance. The proposed Bayesian network model trades off accuracy with redefined Bayesian balance to find the optimal policy. We claim that a novel application of this sampling technique would be sampling a fair training set for recommender systems. To illustrate, we present experimental results on two real world recommender systems raw data sets and one synthetic data-set.",
        "DOI": "10.1109/ICMLA51294.2020.00048",
        "paper_author": "Chakraborty I.",
        "affiliation_name": "Baskin School of Engineering",
        "affiliation_city": "Santa Cruz",
        "affiliation_country": "United States",
        "affiliation_id": "60137794",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Bearicade: Secure access gateway to high performance computing systems",
        "publication": "Proceedings - 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2020",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Cyber security is becoming a vital part of many information technologies and computing systems. Increasingly, High-Performance Computing systems are used in scientific research, academia and industry. High-Performance Computing applications are specifically designed to take advantage of the parallel nature of High-Performance Computing systems. Current research into High-Performance Computing systems focuses on the improvements in software development, parallel algorithms and computer systems architecture. However, there are no significant efforts in developing common High-Performance Computing security standards. Security of the High-Performance Computing resources is often an add-on to existing varied institutional policies that do not take into account additional requirements for High-Performance Computing security. Also, the users' terminals or portals used to access the High-Performance Computing resources are frequently insecure or they are being used in unprotected networks. In this paper we present Bearicade - a Data-driven Security Orchestration Automation and Response system. Bearicade collects data from the HPC systems and its users, enabling the use of Machine Learning based solutions to address current security issues in the High-Performance Computing systems. The system security is achieved through monitoring, analysis and interpretation of data such as users' activity, server requests, devices used and geographic locations. Any anomaly in users' behaviour is detected using machine learning algorithms, and would be visible to system administrators to help mediate the threats. The system was tested on a university campus grid system by administrators and users. Two case studies, Anomaly detection of user behaviour and Classification of Malicious Linux Terminal Command, have demonstrated machine learning approaches in identifying potential security threats. Bearicade's data was used in the experiments. The results demonstrated that detailed information is provided to the HPC administrators to detect possible security attacks and to act promptly.",
        "DOI": "10.1109/TrustCom50675.2020.00191",
        "paper_author": "Al-Jody T.",
        "affiliation_name": "University of Huddersfield",
        "affiliation_city": "Huddersfield",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60032343",
        "affiliation_state": "West Yorkshire"
    },
    {
        "paper_title": "Resource Allocation in IRSs Aided MISO-NOMA Networks: A Machine Learning Approach",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "13",
        "cover_date": "2020-12-01",
        "Abstract": "A novel framework of intelligent reflecting surface (IRS)-aided multiple-input single-output (MISO) non-orthogonal multiple access (NOMA) network is proposed, where a base station (BS) serves multiple clusters with unfixed number of users in each cluster. The goal is to maximize the sum rate of all users by jointly optimizing the passive beamforming vector at the IRS, decoding order and power allocation coefficient vector, subject to the rate requirements of users. In order to tackle the formulated problem, a three-step approach is proposed. More particularly, a long short-term memory (LSTM) based algorithm is first adopted for predicting the mobility of users. Secondly, a K-means based Gaussian mixture model (K-GMM) algorithm is proposed for user clustering. Thirdly, a deep Q-network (DQN) based algorithm is invoked for jointly determining the phase shift matrix and power allocation policy. Simulation results are provided for demonstrating that the proposed algorithm outperforms the benchmarks, while the performance of IRS-NOMA system is better than IRS-OMA system.",
        "DOI": "10.1109/GLOBECOM42002.2020.9348009",
        "paper_author": "Gao X.",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022109",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence and hybrid imaging: the best match for personalized medicine in oncology",
        "publication": "European Journal of Hybrid Imaging",
        "citied_by": "37",
        "cover_date": "2020-12-01",
        "Abstract": "Artificial intelligence (AI) refers to a field of computer science aimed to perform tasks typically requiring human intelligence. Currently, AI is recognized in the broader technology radar within the five key technologies which emerge for their wide-ranging applications and impact in communities, companies, business, and value chain framework alike. However, AI in medical imaging is at an early phase of development, and there are still hurdles to take related to reliability, user confidence, and adoption. The present narrative review aimed to provide an overview on AI-based approaches (distributed learning, statistical learning, computer-aided diagnosis and detection systems, fully automated image analysis tool, natural language processing) in oncological hybrid medical imaging with respect to clinical tasks (detection, contouring and segmentation, prediction of histology and tumor stage, prediction of mutational status and molecular therapies targets, prediction of treatment response, and outcome). Particularly, AI-based approaches have been briefly described according to their purpose and, finally lung cancer—being one of the most extensively malignancy studied by hybrid medical imaging—has been used as illustrative scenario. Finally, we discussed clinical challenges and open issues including ethics, validation strategies, effective data-sharing methods, regulatory hurdles, educational resources, and strategy to facilitate the interaction among different stakeholders. Some of the major changes in medical imaging will come from the application of AI to workflow and protocols, eventually resulting in improved patient management and quality of life. Overall, several time-consuming tasks could be automatized. Machine learning algorithms and neural networks will permit sophisticated analysis resulting not only in major improvements in disease characterization through imaging, but also in the integration of multiple-omics data (i.e., derived from pathology, genomic, proteomics, and demographics) for multi-dimensional disease featuring. Nevertheless, to accelerate the transition of the theory to practice a sustainable development plan considering the multi-dimensional interactions between professionals, technology, industry, markets, policy, culture, and civil society directed by a mindset which will allow talents to thrive is necessary.",
        "DOI": "10.1186/s41824-020-00094-8",
        "paper_author": "Sollini M.",
        "affiliation_name": "Humanitas University",
        "affiliation_city": "Pieve Emanuele",
        "affiliation_country": "Italy",
        "affiliation_id": "60107210",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "On packet classification using a decision-tree ensemble",
        "publication": "CoNEXT Student Workshop 2020 - Proceedings of the 2020 Student Workshop, Part of CoNEXT 2020",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Different traffic flows get treated differently at routers, depending on the descriptions they fit as well as rules set by network administrators. Today's routers have their work cut out having to categorize these incoming flows based on preconfigured administrative policies. Purely hardware-based traffic classification solutions are expensive, of low capacity and consume a lot of power. This paper proposes the use of machine learning techniques to classify these flows for appropriate action in Software-Defined Networks.",
        "DOI": "10.1145/3426746.3434054",
        "paper_author": "Ezeh D.",
        "affiliation_name": "Drexel University College of Engineering",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60139971",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Forecasting S&amp;P 500 spikes: an SVM approach",
        "publication": "Digital Finance",
        "citied_by": "4",
        "cover_date": "2020-12-01",
        "Abstract": "In this study, we focus on forecasting long-tail events of the S&P 500 stock returns. The S&P 500 is widely considered as a bellwether for the overall US economy as it encompasses some of the largest—in terms of capitalization—corporations from both the NYSE and the NASDAQ stock exchanges. A timely and efficient forecast of such extreme changes is of great importance to market participants and policy makers, since they may trigger large scale selling or buying strategies that may significantly impact the specific market and the overall economy. We define as “spikes” the events where we have extreme upward or downward changes of the S&P 500 index; in our case, we use the returns that fall outside a two-standard deviations band. However, instead of simply using the unconditional overall standard deviation, in this paper we employ a GARCH (p,q) model to derive the conditional standard deviation of the returns. This is a more appropriate measure of immediate risk to market participants than the overall series’ unconditional standard deviation. Traditional forecasting models that rely on statistical analysis and traditional econometrics, assume that the returns follow some typical underlying distribution. These models usually fail to successfully and efficiently accommodate price spikes especially when it comes to forecasting. In our study, we use the atheoretical and data-driven Support Vector Machines methodology from the area of Machine Learning. This forecasting approach does not require any initial assumptions on the distribution of the data but rather exploits patterns that may be inhibited in the initial data space. These patterns may become more apparent and exploitable in the resulting feature space. We use 1860 daily observations from 01/01/2009 to 22/01/2017. Our overall optimum forecasting model achieved a 70.69% forecasting accuracy for the spikes and 73.25% for non-spikes.",
        "DOI": "10.1007/s42521-020-00024-0",
        "paper_author": "Papadimitriou T.",
        "affiliation_name": "Democritus University of Thrace",
        "affiliation_city": "Komotini",
        "affiliation_country": "Greece",
        "affiliation_id": "60030988",
        "affiliation_state": "Eastern Macedonia and Thrace"
    },
    {
        "paper_title": "Path Optimization of a Single Surveillance Drone Based on Reinforcement Learning",
        "publication": "International Journal of Mechanical Engineering and Robotics Research",
        "citied_by": "9",
        "cover_date": "2020-12-01",
        "Abstract": "A surveillance drone supervises designated area or sites against dangerous situation. In recent years, it is required to perform autonomous flight to achieve the supervision with path optimization based on minimization of the time lag. In this paper, we propose the reinforcement learning algorithm to optimize path for autonomous flight of surveillance drones. We present a simulation result of a single surveillance drone, which has reinforcement learning algorithm in an unknown grid area. A single surveillance drone finds the optimized path autonomously with minimization of the time lag. This paper provides the following two main contributions for autonomous flight of the surveillance drone. First, the surveillance drone finds the optimized path autonomously using proposed the reinforcement learning algorithm. Second, the traditional reinforcement learning was improved with parameter optimization including learning rate coefficient, convergence criteria, and adaptive error convergence detection for ε-greedy policy process.",
        "DOI": "10.18178/IJMERR.9.12.1541-1547",
        "paper_author": "Lee D.",
        "affiliation_name": "Korea Aerospace Research Institute",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60068719",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Revisiting Determinants of Investor Sentiment in the FX Option Market by Machine Learning Approaches",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "While FX option transactions are known to reflect risk perceptions of market participants, the over-the-counter nature of the FX option market has limited data availability on counterparty information, posing challenges to analyzing what factors could affect investor sentiment and how they may differ across investor types. With novel, granular FX option data based on the reporting from trade repositories and financial institutions in Japan, this paper employs machine learning approaches (Random Forest and XGBoost) to exploring the determinants of investor sentiment for USD/JPY by a different investor category, measured by the positioning of 'long call and short put (bullish for USD/JPY)' minus 'long put and short call (bearish for USD/JPY)'. The analysis shows that the uncertainty over the US trade policy is one of the most important variables for the sentiment of non-financial corporates, while the US yield curve appears to affect the sentiment of both non-financial corporates and institutional investors. The results imply that the recent increase in hedging behavior for a sharp fall of the dollar against the yen could be attributable to the US-China trade tensions and an inversion of the US yield curve which suggests a slowdown of global economy.",
        "DOI": "10.1109/SSCI47803.2020.9308341",
        "paper_author": "Washimi K.",
        "affiliation_name": "Bank of Japan",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60112314",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of data-based prediction methods in newsvendor problems subject to purchase price uncertainty",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "Poor procurement decisions, especially involving perishable or short life-cycled products, which will have to be disposed of, can cost companies large portions of their profits. The newsvendor problem addresses inventory decisions to assist retailers in deciding just the right order quantity while still subject to uncertainty. Efficient time series forecasting techniques, including the use of machine learning models, have helped reduce uncertainty and improve financial results by offering insight on future outcome-based decisions. This work proposes a hybrid model, exploring linear and nonlinear modeling capabilities of classic, modern and machine learning models which are applied to a financial time series in order to anticipate fluctuations in the price of supplies purchased by the newsvendor. This information is used to aid the decision-maker in an optimization problem involving both the decision on the order quantity and the best moment for the one-time per cycle newsvendor replenishment in situations where the purchase price fluctuates in time. The proposed model outperformed both SARIMA and Prophet models as efficient pointers to the best moment to place an order. A case study of a Brazilian supermarket chain which must place weekly orders of perishable goods, specifically of meat products, was chosen to illustrate the methodology.",
        "DOI": "10.1109/SSCI47803.2020.9308495",
        "paper_author": "Guimaraes M.S.",
        "affiliation_name": "Universidade Federal de Pernambuco",
        "affiliation_city": "Recife",
        "affiliation_country": "Brazil",
        "affiliation_id": "60031482",
        "affiliation_state": "PE"
    },
    {
        "paper_title": "Consumer Behavior Analysis using EEG Signals for Neuromarketing Application",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "20",
        "cover_date": "2020-12-01",
        "Abstract": "Neuromarketing is applying neuropsychology in marketing research studying consumer sensory-motor actions such as cognitive and affective responses to marketing stimuli with the help of modern technologies. It is one of the most recent marketing research strategies and may become the future of marketing research. Many research works have been carried out in this area to obtain better outcomes. However, literature shows that there is an opportunity for further improvement. Hence, in this study, a model is presented using data mining and machine learning algorithms for consumer behavior analysis from EEG signals. Time-frequency distribution features are extracted from EEG signals on which different classification algorithms are applied. Consumer's responses toward marketing strategies and their behavior towards purchasing or selecting goods can be studied and analyzed to understand the producer-consumer relationship. EEG signals from 25 people are collected where the participants varied in age and gender for a better understanding of consumer behavior towards a marketing policy. By analyzing the data, the reason behind how and why they like certain marketing policies was uncovered. The performance of our proposed model with an existing technique is compared. The accuracy of our model on the dataset is 95%, whereas the accuracy of the existing technique on the same dataset is 70%. We also evaluated whether neuropsychological measures can capture differences in consumer's actions according to different marketing stimuli. The experimental results on our model indicate that studies in this field can bring a change and improve marketing strategies for the betterment of both the producer and the consumer, resulting in an eventual mutual benefit.",
        "DOI": "10.1109/SSCI47803.2020.9308358",
        "paper_author": "Amin C.R.",
        "affiliation_name": "BRAC University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60008935",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Interpretable Machine Learning Tools: A Survey",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "53",
        "cover_date": "2020-12-01",
        "Abstract": "In recent years machine learning (ML) systems have been deployed extensively in various domains. But most MLbased frameworks lack transparency. To believe in ML models, an individual needs to understand the reasons behind the ML predictions. In this paper, we provide a survey of open-source software tools that help explore and understand the behavior of the ML models. Also, these tools include a variety of interpretable machine learning methods that assist people with understanding the connection between input and output variables through interpretation, validate the decision of a predictive model to enable lucidity, accountability, and fairness in the algorithmic decision making policies. Furthermore, we provide the state-of-the-art of interpretable machine learning (IML) tools, along with a comparison and a brief discussion of the implementation of those IML tools in various programming languages.",
        "DOI": "10.1109/SSCI47803.2020.9308260",
        "paper_author": "Agarwal N.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Memphis",
        "affiliation_country": "United States",
        "affiliation_id": "60280401",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Dynamic Behavior Predictions for Fast and Efficient Hybrid STT-MRAM Caches",
        "publication": "ACM Journal on Emerging Technologies in Computing Systems",
        "citied_by": "8",
        "cover_date": "2020-12-01",
        "Abstract": "Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM) is a promising candidate as a universal on-chip memory technology due to its non-volatility, high density, and scalability. However, high write energy and latency are its major shortcomings, particularly for fast cache applications. High write costs can efficiently be reduced by relaxing the STT-MRAM non-volatility requirements at the expense of significant increase in retention failure and read disturb rates resulting in data corruption. Hybrid STT-MRAM architecture combining non-volatile (NVM) and semi-volatile (SVM) STT-MRAM blocks has been proposed recently, which provides energy-efficiency, high storage capacity, better performance, and high reliability. However, a key and challenging requirement is efficient data mapping and migration between NVM and SVM sub-arrays to maximize the benefits of such hybrid caches. On-the-fly data migration decisions usually depend on the last seen data behavior, as it is assumed to be identical to the next one, which has very limited accuracy for rapidly varying workload behavior. In this article, we propose a simple but effective on-the-fly data management policy, which mainly relies on the supervised learning data-pattern classification for quick and highly accurate prediction of the data behavior in the oncoming execution time. Three prediction approaches are proposed and compared for a maximum and average achieved accuracy of 86% and 75%, respectively. Our data management policies aim to optimally leverage the specific features of NVM (high reliability) and SVM blocks (fast and energy-efficient write) of hybrid STT-MRAM memory with minimal migration costs (i.e., energy and performance overheads). Our experimental evaluation reports that for a hybrid STT-MRAM cache with the proposed prediction techniques, the total energy consumption can be reduced around 10.5%, on average, in comparison to the state-of-the-art.",
        "DOI": "10.1145/3423135",
        "paper_author": "Sayed N.",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany",
        "affiliation_id": "60102538",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Big data and actuarial science",
        "publication": "Big Data and Cognitive Computing",
        "citied_by": "22",
        "cover_date": "2020-12-01",
        "Abstract": "This article investigates the impact of big data on the actuarial sector. The growing fields of applications of data analytics and data mining raise the ability for insurance companies to conduct more accurate policy pricing by incorporating a broader variety of data due to increased data availability. The analyzed areas of this paper span from automobile insurance policy pricing, mortality and healthcare modeling to estimation of harvest-, climate-and cyber risk as well as assessment of catastrophe risk such as storms, hurricanes, tornadoes, geomagnetic events, earthquakes, floods, and fires. We evaluate the current use of big data in these contexts and how the utilization of data analytics and data mining contribute to the prediction capabilities and accuracy of policy premium pricing of insurance companies. We find a high penetration of insurance policy pricing in almost all actuarial fields except in the modeling and pricing of cyber security risk due to lack of data in this area and prevailing data asymmetries, for which we identify the application of artificial intelligence, in particular machine learning techniques, as a possible solution to improve policy pricing accuracy and results.",
        "DOI": "10.3390/bdcc4040040",
        "paper_author": "Hassani H.",
        "affiliation_name": "University of Tehran",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60022927",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "A model to rate strategies for managing disease due to COVID-19 infection",
        "publication": "Scientific Reports",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "Considering looming fatality and economic recession, effective policy making based on ongoing COVID-19 pandemic is an urgent and standing issue. Numerous issues for controlling infection have arisen from public discussion led by medical professionals. Yet understanding of these factors has been necessarily qualitative and control measures to correct unfavorable trends specific to an infection area have been lacking. The logical implement for control is a large scale stochastic model with countless parameters lacking robustness and requiring enormous data. This paper presents a remedy for this vexing problem by proposing an alternative approach. Machine learning has come to play a widely circulated role in the study of complex data in recent times. We demonstrate that when machine learning is employed together with the mechanistic framework of a mathematical model, there can be a considerably enhanced understanding of complex systems. A mathematical model describing the viral infection dynamics reveals two transmissibility parameters influenced by the management strategies in the area for the control of the current pandemic. Both parameters readily yield the peak infection rate and means for flattening the curve, which is correlated to different management strategies by employing machine learning, enabling comparison of different strategies and suggesting timely alterations. Treatment of population data with the model shows that restricted non-essential business closure, school closing and strictures on mass gathering influence the spread of infection. While a rational strategy for initiation of an economic reboot would call for a wider perspective of the local economics, the model can speculate on its timing based on the status of the infection as reflected by its potential for an unacceptably renewed viral onslaught.",
        "DOI": "10.1038/s41598-020-79817-7",
        "paper_author": "Wang S.",
        "affiliation_name": "Purdue University",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60009254",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Addressing health disparities in the Food and Drug Administration’s artificial intelligence and machine learning regulatory framework",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "41",
        "cover_date": "2020-12-01",
        "Abstract": "The exponential growth of health data from devices, health applications, and electronic health records coupled with the development of data analysis tools such as machine learning offer opportunities to leverage these data to mitigate health disparities. However, these tools have also been shown to exacerbate inequities faced by marginalized groups. Focusing on health disparities should be part of good machine learning practice and regulatory oversight of software as medical devices. Using the Food and Drug Administration (FDA)’s proposed framework for regulating machine learning tools in medicine, I show that addressing health disparities during the premarket and postmarket stages of review can help anticipate and mitigate group harms.",
        "DOI": "10.1093/jamia/ocaa133",
        "paper_author": "Ferryman K.",
        "affiliation_name": "NYU Tandon School of Engineering",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60108318",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Electronic health record–based disease surveillance systems: A systematic literature review on challenges and solutions",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "29",
        "cover_date": "2020-12-01",
        "Abstract": "Objective: Disease surveillance systems are expanding using electronic health records (EHRs). However, there are many challenges in this regard. In the present study, the solutions and challenges of implementing EHR-based disease surveillance systems (EHR-DS) have been reviewed. Materials and Methods: We searched the related keywords in ProQuest, PubMed, Web of Science, Cochrane Library, Embase, and Scopus. Then, we assessed and selected articles using the inclusion and exclusion criteria and, finally, classified the identified solutions and challenges. Results: Finally, 50 studies were included, and 52 unique solutions and 47 challenges were organized into 6 main themes (policy and regulatory, technical, management, standardization, financial, and data quality). The results indicate that due to the multifaceted nature of the challenges, the implementation of EHR-DS is not low cost and easy to implement and requires a variety of interventions. On the one hand, the most common challenges include the need to invest significant time and resources; the poor data quality in EHRs; difficulty in analyzing, cleaning, and accessing unstructured data; data privacy and security; and the lack of interoperability standards. On the other hand, the most common solutions are the use of natural language processing and machine learning algorithms for unstructured data; the use of appropriate technical solutions for data retrieval, extraction, identification, and visualization; the collaboration of health and clinical departments to access data; standardizing EHR content for public health; and using a unique health identifier for individuals. Conclusions: EHR systems have an important role in modernizing disease surveillance systems. However, there are many problems and challenges facing the development and implementation of EHR-DS that need to be appropriately addressed.",
        "DOI": "10.1093/jamia/ocaa186",
        "paper_author": "Aliabadi A.",
        "affiliation_name": "Iran University of Medical Sciences",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60024852",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Why to buy insurance? An explainable artificial intelligence approach",
        "publication": "Risks",
        "citied_by": "37",
        "cover_date": "2020-12-01",
        "Abstract": "We propose an Explainable AI model that can be employed in order to explain why a customer buys or abandons a non-life insurance coverage. The method consists in applying similarity clustering to the Shapley values that were obtained from a highly accurate XGBoost predictive classification algorithm. Our proposed method can be embedded into a technologically-based insurance service (Insurtech), allowing to understand, in real time, the factors that most contribute to customers’ decisions, thereby gaining proactive insights on their needs. We prove the validity of our model with an empirical analysis that was conducted on data regarding purchases of insurance micro-policies. Two aspects are investigated: the propensity to buy an insurance policy and the risk of churn of an existing customer. The results from the analysis reveal that customers can be effectively and quickly grouped according to a similar set of characteristics, which can predict their buying or churn behaviour well.",
        "DOI": "10.3390/risks8040137",
        "paper_author": "Gramegna A.",
        "affiliation_name": "Università degli Studi di Pavia",
        "affiliation_city": "Pavia",
        "affiliation_country": "Italy",
        "affiliation_id": "60015197",
        "affiliation_state": "PV"
    },
    {
        "paper_title": "How can social media analytics assist authorities in pandemic-related policy decisions? Insights from Australian states and territories",
        "publication": "Health Information Science and Systems",
        "citied_by": "47",
        "cover_date": "2020-12-01",
        "Abstract": "Background and objectives: Due to COVID-19, various countries introduced lockdowns and limited citizen movements. These restrictions triggered an increased use of digital technologies and platforms by the public. This provides an opportunity for the authorities to capture public perceptions on COVID-19 from social media channels to make informed decisions. The use of social media analytics during pandemics for decision-making, however, is an understudied area of research. Thus, this study aims to generate insights into how social media analytics can assist authorities in pandemic-related policy decisions. Methods: This study involved a social media analysis approach—i.e., systematic geo-Twitter analysis—that contains descriptive, content, sentiment, and spatial analyses. Australian states and territories are selected as the case study context for the empirical investigation. This study collected 96,666 geotagged tweets (originated from Australia between 1 January and 4 May 2020), and analysed 35,969 of them after data cleaning. Results: The findings disclose that: (a) Social media analytics is an efficient approach to capture the attitudes and perceptions of the public during a pandemic; (b) Crowdsourced social media data can guide interventions and decisions of the authorities during a pandemic, and; (c) Effective use of government social media channels can help the public to follow the introduced measures/restrictions. Conclusion: The findings are invaluable for authorities to understand community perceptions and identify communities in needs and demands in a pandemic situation, where authorities are not in a position to conduct direct and lengthily public consultations.",
        "DOI": "10.1007/s13755-020-00121-9",
        "paper_author": "Yigitcanlar T.",
        "affiliation_name": "Queensland University of Technology",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60011019",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "PipeArch: Generic and context-switch capable data processing on fpgas",
        "publication": "ACM Transactions on Reconfigurable Technology and Systems",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "Data processing systems based on FPGAs offer high performance and energy efficiency for a variety of applications. However, these advantages are achieved through highly specialized designs. The high degree of specialization leads to accelerators with narrow functionality and designs adhering to a rigid execution flow. For multi-tenant systems this limits the scope of applicability of FPGA-based accelerators, because, first, supporting a single operation is unlikely to have any significant impact on the overall performance of the system, and, second, serving multiple users satisfactorily is difficult due to simplistic scheduling policies enforced when using the accelerator. Standard operating system and database management system features that would help address these limitations, such as context-switching, preemptive scheduling, and thread migration are practically non-existent in current FPGA accelerator efforts. In this work, we propose PipeArch, an open-source project1 for developing FPGA-based accelerators that combine the high efficiency of specialized hardware designs with the generality and functionality known from conventional CPU threads. PipeArch provides programmability and extensibility in the accelerator without losing the advantages of SIMD-parallelism and deep pipelining. PipeArch supports context-switching and thread migration, thereby enabling for the first time new capabilities such as preemptive scheduling in FPGA accelerators within a high-performance data processing setting. We have used PipeArch to implement a variety of machine learning methods for generalized linear model training and recommender systems showing empirically their advantages over a high-end CPU and even over fully specialized FPGA designs.",
        "DOI": "10.1145/3418465",
        "paper_author": "Kara K.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Learning from urban form to predict building heights",
        "publication": "PLoS ONE",
        "citied_by": "45",
        "cover_date": "2020-12-01",
        "Abstract": "Understanding cities as complex systems, sustainable urban planning depends on reliable high-resolution data, for example of the building stock to upscale region-wide retrofit policies. For some cities and regions, these data exist in detailed 3D models based on real-world measurements. However, they are still expensive to build and maintain, a significant challenge, especially for small and medium-sized cities that are home to the majority of the European population. New methods are needed to estimate relevant building stock characteristics reliably and cost-effectively. Here, we present a machine learning based method for predicting building heights, which is based only on open-access geospatial data on urban form, such as building footprints and street networks. The method allows to predict building heights for regions where no dedicated 3D models exist currently. We train our model using building data from four European countries (France, Italy, the Netherlands, and Germany) and find that the morphology of the urban fabric surrounding a given building is highly predictive of the height of the building. A test on the German state of Brandenburg shows that our model predicts building heights with an average error well below the typical floor height (about 2.5 m), without having access to training data from Germany. Furthermore, we show that even a small amount of local height data obtained by citizens substantially improves the prediction accuracy. Our results illustrate the possibility of predicting missing data on urban infrastructure; they also underline the value of open government data and volunteered geographic information for scientific applications, such as contextual but scalable strategies to mitigate climate change.",
        "DOI": "10.1371/journal.pone.0242010",
        "paper_author": "Milojevic-Dupont N.",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Exploring optimal control of epidemic spread using reinforcement learning",
        "publication": "Scientific Reports",
        "citied_by": "33",
        "cover_date": "2020-12-01",
        "Abstract": "Pandemic defines the global outbreak of a disease having a high transmission rate. The impact of a pandemic situation can be lessened by restricting the movement of the mass. However, one of its concomitant circumstances is an economic crisis. In this article, we demonstrate what actions an agent (trained using reinforcement learning) may take in different possible scenarios of a pandemic depending on the spread of disease and economic factors. To train the agent, we design a virtual pandemic scenario closely related to the present COVID-19 crisis. Then, we apply reinforcement learning, a branch of artificial intelligence, that deals with how an individual (human/machine) should interact on an environment (real/virtual) to achieve the cherished goal. Finally, we demonstrate what optimal actions the agent perform to reduce the spread of disease while considering the economic factors. In our experiment, we let the agent find an optimal solution without providing any prior knowledge. After training, we observed that the agent places a long length lockdown to reduce the first surge of a disease. Furthermore, the agent places a combination of cyclic lockdowns and short length lockdowns to halt the resurgence of the disease. Analyzing the agent’s performed actions, we discover that the agent decides movement restrictions not only based on the number of the infectious population but also considering the reproduction rate of the disease. The estimation and policy of the agent may improve the human-strategy of placing lockdown so that an economic crisis may be avoided while mitigating an infectious disease.",
        "DOI": "10.1038/s41598-020-79147-8",
        "paper_author": "Ohi A.Q.",
        "affiliation_name": "Bangladesh University of Business and Technology",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60170531",
        "affiliation_state": "Dhaka"
    },
    {
        "paper_title": "Editors Introduction: An Update on the Status of the Journal",
        "publication": "Ultrasound Quarterly",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "NA",
        "DOI": "10.1097/RUQ.0000000000000551",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A social engineering model for poverty alleviation",
        "publication": "Nature Communications",
        "citied_by": "7",
        "cover_date": "2020-12-01",
        "Abstract": "Poverty, the quintessential denominator of a developing nation, has been traditionally defined against an arbitrary poverty line; individuals (or countries) below this line are deemed poor and those above it, not so! This has two pitfalls. First, absolute reliance on a single poverty line, based on basic food consumption, and not on total consumption distribution, is only a partial poverty index at best. Second, a single expense descriptor is an exogenous quantity that does not evolve from income-expenditure statistics. Using extensive income-expenditure statistics from India, here we show how a self-consistent endogenous poverty line can be derived from an agent-based stochastic model of market exchange, combining all expenditure modes (basic food, other food and non-food), whose parameters are probabilistically estimated using advanced Machine Learning tools. Our mathematical study establishes a consumption based poverty measure that combines labor, commodity, and asset market outcomes, delivering an excellent tool for economic policy formulation.",
        "DOI": "10.1038/s41467-020-20201-4",
        "paper_author": "Chattopadhyay A.K.",
        "affiliation_name": "Aston University",
        "affiliation_city": "Birmingham",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60014551",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "Comorbidity patterns of older lung cancer patients in Northeast China: An association rules analysis based on electronic medical records",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "16",
        "cover_date": "2020-12-01",
        "Abstract": "Purposes: This study aims to identify the comorbidity patterns of older men with lung cancer in China. Methods: We analyzed the electronic medical records (EMRs) of lung cancer patients over age 65 in the Jilin Province of China. The data studied were obtained from 20 hospitals of Jilin Province in 2018. In total, 1510 patients were identified. We conducted a rank–frequency analysis and social network analysis to identify the predominant comorbidities and comorbidity networks. We applied the association rules to mine the comorbidity combination with the values of confidence and lift. A heatmap was utilized to visualize the rules. Results: Our analyses discovered that (1) there were 31 additional medical conditions in older patients with lung cancer. The most frequent comorbidities were pneumonia, cerebral infarction, and hypertension. (2) The networkbased analysis revealed seven subnetworks. (3) The association rules analysis provided 41 interesting rules. The results revealed that hypertension, ischemic cardiomyopathy, and pneumonia are the most frequent comorbid combinations. Heart failure may not have a strong implicating role in these comorbidity patterns. Cerebral infarction was rarely combined with other diseases. In addition, glycoprotein metabolism disorder comorbid with hyponatremia or hypokalemia increased the risk of anemia by more than eight times in older lung cancer patients. Conclusions: This study provides evidence on the comorbidity patterns of older men with lung cancer in China. Understanding the comorbidity patterns of older patients with lung cancer can assist clinicians in their diagnoses and contribute to developing healthcare policies, as well as allocating resources.",
        "DOI": "10.3390/ijerph17239119",
        "paper_author": "Feng J.",
        "affiliation_name": "Jilin University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60007711",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Ticket sales prediction and dynamic pricing strategies in public transport",
        "publication": "Big Data and Cognitive Computing",
        "citied_by": "24",
        "cover_date": "2020-12-01",
        "Abstract": "In recent years, the demand for collective mobility services registered significant growth. In particular, the long-distance coach market underwent an important change in Europe, since FlixBus adopted a dynamic pricing strategy, providing low-cost transport services and an efficient and fast information system. This paper presents a methodology, called DA4PT (Data Analytics for Public Transport), for discovering the factors that influence travelers in booking and purchasing bus tickets. Starting from a set of 3.23 million user-generated event logs of a bus ticketing platform, the methodology shows the correlation rules between booking factors and purchase of tickets. Such rules are then used to train machine learning models for predicting whether a user will buy or not a ticket. The rules are also used to define various dynamic pricing strategies with the purpose of increasing the number of tickets sales on the platform and the related amount of revenues. The methodology reaches an accuracy of 95% in forecasting the purchase of a ticket and a low variance in results. Exploiting a dynamic pricing strategy, DA4PT is able to increase the number of purchased tickets by 6% and the total revenue by 9% by showing the effectiveness of the proposed approach.",
        "DOI": "10.3390/bdcc4040036",
        "paper_author": "Branda F.",
        "affiliation_name": "Università della Calabria",
        "affiliation_city": "Rende",
        "affiliation_country": "Italy",
        "affiliation_id": "60020261",
        "affiliation_state": "CS"
    },
    {
        "paper_title": "Assessing mediterranean diet adherence with the smartphone: The medipiatto project",
        "publication": "Nutrients",
        "citied_by": "12",
        "cover_date": "2020-12-01",
        "Abstract": "The Mediterranean diet (MD) is regarded as a healthy eating pattern with beneficial effects both for the decrease of the risk for non-communicable diseases and also for body weight reduction. In the current manuscript, we propose an automated smartphone application which monitors and evaluates the user’s adherence to MD using images of the food and drinks that they consume. We define a set of rules for automatic adherence estimation, which focuses on the main MD food groups. We use a combination of a convolutional neural network (CNN) and a graph convolutional network to detect the types of foods and quantities from the users’ food images and the defined set of rules to evaluate the adherence to MD. Our experiments show that our system outperforms a basic CNN in terms of recognizing food items and estimating quantity and yields comparable results as experienced dietitians when it comes to overall MD adherence estimation. As the system is novel, these results are promising; however, there is room for improvement of the accuracy by gathering and training with more data and certain refinements can be performed such as re-defining the set of rules to also be able to be used for sub-groups of MD (e.g., vegetarian type of MD).",
        "DOI": "10.3390/nu12123763",
        "paper_author": "Vasiloglou M.F.",
        "affiliation_name": "University of Bern, Faculty of Medicine",
        "affiliation_city": "Bern",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60026476",
        "affiliation_state": "BE"
    },
    {
        "paper_title": "KNN prototyping schemes for embedded human activity recognition with online learning",
        "publication": "Computers",
        "citied_by": "24",
        "cover_date": "2020-12-01",
        "Abstract": "The kNN machine learning method is widely used as a classifier in Human Activity Recognition (HAR) systems. Although the kNN algorithm works similarly both online and in offline mode, the use of all training instances is much more critical online than offline due to time and memory restrictions in the online mode. Some methods propose decreasing the high computational costs of kNN by focusing, e.g., on approximate kNN solutions such as the ones relying on Locality-Sensitive Hashing (LSH). However, embedded kNN implementations also need to address the target device’s memory constraints, especially as the use of online classification needs to cope with those constraints to be practical. This paper discusses online approaches to reduce the number of training instances stored in the kNN search space. To address practical implementations of HAR systems using kNN, this paper presents simple, energy/computationally efficient, and real-time feasible schemes to maintain at runtime a maximum number of training instances stored by kNN. The proposed schemes include policies for substituting the training instances, maintaining the search space to a maximum size. Experiments in the context of HAR datasets show the efficiency of our best schemes.",
        "DOI": "10.3390/computers9040096",
        "paper_author": "Ferreira P.J.S.",
        "affiliation_name": "Institute for Systems and Computer Engineering, Technology and Science",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60020432",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "Fast reinforcement learning with generalized policy updates",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "76",
        "cover_date": "2020-12-01",
        "Abstract": "The combination of reinforcement learning with deep learning is a promising approach to tackle important sequential decision-making problems that are currently intractable. One obstacle to overcome is the amount of data needed by learning systems of this type. In this article, we propose to address this issue through a divide-and-conquer approach. We argue that complex decision problems can be naturally decomposed into multiple tasks that unfold in sequence or in parallel. By associating each task with a reward function, this problem decomposition can be seamlessly accommodated within the standard reinforcement-learning formalism. The specific way we do so is through a generalization of two fundamental operations in reinforcement learning: policy improvement and policy evaluation. The generalized version of these operations allow one to leverage the solution of some tasks to speed up the solution of others. If the reward function of a task can be well approximated as a linear combination of the reward functions of tasks previously solved, we can reduce a reinforcement-learning problem to a simpler linear regression. When this is not the case, the agent can still exploit the task solutions by using them to interact with and learn about the environment. Both strategies considerably reduce the amount of data needed to solve a reinforcement-learning problem.",
        "DOI": "10.1073/pnas.1907370117",
        "paper_author": "Barreto A.",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60111161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Adaptive Optimal Control for Stochastic Multiplayer Differential Games Using On-Policy and Off-Policy Reinforcement Learning",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "54",
        "cover_date": "2020-12-01",
        "Abstract": "Control-theoretic differential games have been used to solve optimal control problems in multiplayer systems. Most existing studies on differential games either assume deterministic dynamics or dynamics corrupted with additive noise. In realistic environments, multidimensional environmental uncertainties often modulate system dynamics in a more complicated fashion. In this article, we study stochastic multiplayer differential games, where the players' dynamics are modulated by randomly time-varying parameters. We first formulate two differential games for systems of general uncertain linear dynamics, including the two-player zero-sum and multiplayer nonzero-sum games. We then show that optimal control policies, which constitute the Nash equilibrium solutions, can be derived from the corresponding Hamiltonian functions. Stability is proven using the Lyapunov type of analysis. In order to solve the stochastic differential games online, we integrate reinforcement learning (RL) and an effective uncertainty sampling method called the multivariate probabilistic collocation method (MPCM). Two learning algorithms, including the on-policy integral RL (IRL) and off-policy IRL, are designed for the formulated games, respectively. We show that the proposed learning algorithms can effectively find the Nash equilibrium solutions for the stochastic multiplayer differential games.",
        "DOI": "10.1109/TNNLS.2020.2969215",
        "paper_author": "Liu M.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Arlington",
        "affiliation_country": "United States",
        "affiliation_id": "60137461",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Shifting the paradigm: The dress-cov telegram bot as a tool for participatory medicine",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "12",
        "cover_date": "2020-12-01",
        "Abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic management is limited by great uncertainty, for both health systems and citizens. Facing this information gap requires a paradigm shift from traditional approaches to healthcare to the participatory model of improving health. This work describes the design and function of the Doing Risk sElf-assessment and Social health Support for COVID (Dress-COV) system. It aims to establish a lasting link between the user and the tool; thus, enabling modeling of the data to assess individual risk of infection, or developing complications, to improve the individual’s self-empowerment. The system uses bot technology of the Telegram application. The risk assessment includes the collection of user responses and the modeling of data by machine learning models, with increasing appropriateness based on the number of users who join the system. The main results reflect: (a) the individual’s compliance with the tool; (b) the security and versatility of the architecture; (c) support and promotion of self-management of behavior to accommodate surveillance system delays; (d) the potential to support territorial health providers, e.g., the daily efforts of general practitioners (during this pandemic, as well as in their routine practices). These results are unique to Dress-COV and distinguish our system from classical surveillance applications.",
        "DOI": "10.3390/ijerph17238786",
        "paper_author": "Franchini M.",
        "affiliation_name": "Istituto di Fisiologia Clinica del CNR",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60009071",
        "affiliation_state": "PI"
    },
    {
        "paper_title": "Artificial intelligence-based radiotherapy machine parameter optimization using reinforcement learning",
        "publication": "Medical Physics",
        "citied_by": "27",
        "cover_date": "2020-12-01",
        "Abstract": "Purpose: To develop and evaluate a volumetric modulated arc therapy (VMAT) machine parameter optimization (MPO) approach based on deep-Q reinforcement learning (RL) capable of finding an optimal machine control policy using previous prostate cancer patient CT scans and contours, and applying the policy to new cases to rapidly produce deliverable VMAT plans in a simplified beam model. Methods: A convolutional deep-Q network was employed to control the dose rate and multileaf collimator of a C-arm linear accelerator model using the current dose distribution and machine parameter state as input. A Q-value was defined as the discounted cumulative cost based on dose objectives, and experience-replay RL was performed to determine a policy to minimize the Q-value. A two-dimensional network design was employed which optimized each opposing leaf pair independently while monitoring the corresponding dose plane blocked by those leaves. This RL approach was applied to CT and contours from 40 retrospective prostate cancer patients. The dataset was split into training (15 patients) and validation (5 patients) groups to optimize the network, and its performance was tested in an independent cohort of 20 patients by comparing RL-based dose distributions to conformal arcs and clinical intensity modulated radiotherapy (IMRT) delivering a prescription dose of 78 Gy in 40 fractions. Results: Mean ± SD execution time of the RL VMAT optimization was 1.5 ± 0.2 s per slice. In the test cohort, mean ± SD (P-value) planning target volume (PTV), bladder, and rectum dose were 80.5 ± 2.0 Gy (P < 0.001), 44.2 ± 14.6 Gy (P < 0.001), and 43.7 ± 11.1 Gy (P < 0.001) for RL VMAT compared to 81.6 ± 1.1 Gy, 51.6 ± 12.9 Gy, and 36.0 ± 12.3 Gy for clinical IMRT. Conclusions: RL was applied to VMAT MPO using clinical patient contours without independently optimized treatment plans for training and achieved comparable target and normal tissue dose to clinical plans despite the application of a relatively simple network design originally developed for video-game control. These results suggest that extending a RL approach to a full three-dimensional beam model could enable rapid artificial intelligence-based optimization of deliverable treatment plans, reducing the time required for radiotherapy planning without requiring previous plans for training.",
        "DOI": "10.1002/mp.14544",
        "paper_author": "Hrinivich W.T.",
        "affiliation_name": "Johns Hopkins University School of Medicine",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60001117",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Using the lstm network to forecast the demand for electricity in poland",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "31",
        "cover_date": "2020-12-01",
        "Abstract": "The impact of environmental regulations introduced by the European Union is of key importance for electricity generation systems. The Polish fuel structure of electricity production is based on solid fuels. Moreover, the generating base is outdated and must gradually be withdrawn from the power system. In this context, Poland’s energy policy is undergoing a transformation as climate and environmental regulations are becoming increasingly stringent for the energy sector based on solid fuels (hard coal and lignite). However, the transformation process must be adapted to market demands, because the overriding goal is to ensure energy security by maintaining the continuity of energy supplies and an acceptable electricity price. This directly contributes to the development of the entire economy and the standard of living of the society, in accordance with the European Agreement establishing an association between the Republic of Poland and the European Communities and their Member States, signed on 16 December 1991, and the European Energy Charter, signed on 17 December 1991. Ensuring energy security is the most important goal of the energy policy. Therefore, energy companies must forecast the demand. The main goal of this article is to develop a mathematical model of electricity consumption by 2040 by all sectors of the economy: industry, transport, residential, commercial and public services, agriculture, forestry, and fishing. In order to achieve the intended goal, a model was developed by using Long Short-Term Memory (LSTM) artificial neural networks, which belong to deep learning techniques and reflect long-term relationships in time series for a small set of statistical data. The results show that the proposed model can significantly improve the accuracy of forecasts (1–3% of mean absolute percentage error (MAPE) for the analyzed sectors of the economy).",
        "DOI": "10.3390/app10238455",
        "paper_author": "Manowska A.",
        "affiliation_name": "Silesian University of Technology",
        "affiliation_city": "Gliwice",
        "affiliation_country": "Poland",
        "affiliation_id": "60009081",
        "affiliation_state": "Silesian"
    },
    {
        "paper_title": "The ironies of autonomy",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "28",
        "cover_date": "2020-12-01",
        "Abstract": "Current research on autonomous vehicles tends to focus on making them safer through policies to manage innovation, and integration into existing urban and mobility systems. This article takes social, cultural and philosophical approaches instead, critically appraising how human subjectivity, and human-machine relations, are shifting and changing through the application of big data and algorithmic techniques to the automation of driving. 20th century approaches to safety engineering and automation—be it in an airplane or automobile-have sought to either erase the human because she is error-prone and inefficient; have design compensate for the limits of the human; or at least mould human into machine through an assessment of the complementary competencies of each. The ‘irony of automation’ is an observation of the tensions emerging therein; for example, that the computationally superior and efficient machine actually needs human operators to ensure that it is working effectively; and that the human is inevitably held accountable for errors, even if the machine is more efficient or accurate. With the emergence of the autonomous vehicle (AV) as simultaneously AI/ ‘robot’, and automobile, and distributed, big data infrastructural platform, these beliefs about human and machine are dissolving into what I refer to as the ironies of autonomy. For example, recent AV crashes suggest that human operators cannot intervene in the statistical operations underlying automated decision-making in machine learning, but are expected to. And that while AVs promise ‘freedom’, human time, work, and bodies are threaded into, and surveilled by, data infrastructures, and re-shaped by its information flows. The shift that occurs is that human subjectivity has socio-economic and legal implications and is not about fixed attributes of human and machine fitting into each other. Drawing on Postphenomenological concepts of embodiment and instrumentation, and excerpts from fieldwork, this article argues that the emergence of AVs in society prompts a rethinking of the multiple relationalities that constitute humanity through machines.",
        "DOI": "10.1057/s41599-020-00646-0",
        "paper_author": "Ganesh M.I.",
        "affiliation_name": "Leuphana Universität Lüneburg",
        "affiliation_city": "Luneburg",
        "affiliation_country": "Germany",
        "affiliation_id": "60072202",
        "affiliation_state": "Niedersachsen"
    },
    {
        "paper_title": "Exploring the Potential of Twitter to Understand Traffic Events and Their Locations in Greater Mumbai, India",
        "publication": "IEEE Transactions on Intelligent Transportation Systems",
        "citied_by": "26",
        "cover_date": "2020-12-01",
        "Abstract": "Detecting traffic events and their locations is important for an effective transportation management system and better urban policy making. Traffic events are related to traffic accidents, congestion, parking issues, to name a few. Currently, traffic events are detected through static sensors e.g., CCTV camera, loop detectors. However they have limited spatial coverage and high maintenance cost, especially in developing regions. On the other hand, with Web 2.0 and ubiquitous mobile platforms, people can act as social sensors sharing different traffic events along with their locations. We investigated whether Twitter - a social media platform can be useful to understand urban traffic events from tweets in India. However, such tweets are informal and noisy and containing vernacular geographical information making the location retrieval task challenging. So far most authors have used geotagged tweets to identify traffic events which accounted for only 0.1%-3% or sometimes less than that. Recently Twitter has removed precise geotagging, further decreasing the utility of such approaches. To address these issues, this research explored how ungeotagged tweets could be used to understand traffic events in India. We developed a novel framework that does not only categorize traffic related tweets but also extracts the locations of the traffic events from the tweet content in Greater Mumbai. The results show that an SVM based model performs best detecting traffic related tweets. While extracting location information, a hybrid georeferencing model consists of a supervised learning algorithm and a number of spatial rules outperforms other models. The results suggest people in India, especially in Greater Mumbai often share traffic information along with location mentions, which can be used to complement existing physical transport infrastructure in a cost-effective manner to manage transport services in the urban environment.",
        "DOI": "10.1109/TITS.2019.2950782",
        "paper_author": "Das R.D.",
        "affiliation_name": "IBM Deutschland GmbH",
        "affiliation_city": "Ehningen",
        "affiliation_country": "Germany",
        "affiliation_id": "60077068",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Clinical Pharmacology and Therapeutics: 2020 in Review",
        "publication": "Clinical Pharmacology and Therapeutics",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "NA",
        "DOI": "10.1002/cpt.2061",
        "paper_author": "van der Graaf P.H.",
        "affiliation_name": "Certara, United Kingdom",
        "affiliation_city": "Canterbury",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60111602",
        "affiliation_state": "Kent"
    },
    {
        "paper_title": "Advances, gaps and opportunities in the detection of familial hypercholesterolemia: Overview of current and future screening and detection methods",
        "publication": "Current Opinion in Lipidology",
        "citied_by": "26",
        "cover_date": "2020-12-01",
        "Abstract": "Purpose of review Studies reaffirm that familial hypercholesterolemia is more prevalent than initially considered, with a population frequency of approximately one in 300. The majority of patients remains unidentified. This warrants critical evaluation of existing screening methods and exploration of novel methods of detection. Recent findings New public policy recommendations on the detection of familial hypercholesterolemia have been made by a global community of experts and advocates. Phenotypic tools for diagnosing index cases remain inaccurate. Genetic testing is the gold standard for familial hypercholesterolemia and a new international position statement has been published. Correction of LDL cholesterol (LDL-C) for the cholesterol content of lipoprotein(a) [Lp(a)] may increase the precision of the phenotypic diagnosis of familial hypercholesterolemia. Cascade cotesting for familial hypercholesterolemia and elevated Lp(a) levels provides a new opportunity to stratify risk in families. Digital technology and machine learning methods, coupled with clinical alert and decision support systems, lead the way in more efficient approaches for detecting and managing index cases. Universal screening of children, combined with child-parent cascade testing, appears to be the most effective method for underpinning a population strategy for maximizing the detection of familial hypercholesterolemia. Summary Detection of familial hypercholesterolemia can be enhanced by optimizing current diagnostic algorithms, probing electronic health records with novel information technologies and integrating universal screening of children with cascade testing of parents and other relatives.",
        "DOI": "10.1097/MOL.0000000000000714",
        "paper_author": "Ibrahim S.",
        "affiliation_name": "Universiteit van Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60002483",
        "affiliation_state": "Noord-Holland"
    },
    {
        "paper_title": "Making context the central concept in privacy engineering",
        "publication": "Research and Practice in Technology Enhanced Learning",
        "citied_by": "5",
        "cover_date": "2020-12-01",
        "Abstract": "There is a gap between people’s online sharing of personal data and their concerns about privacy. Till now, this gap is addressed by attempting to match individual privacy preferences with service providers’ options for data handling. This approach has ignored the role different contexts play in data sharing. This paper aims at giving privacy engineering a new direction putting context centre stage and exploiting the affordances of machine learning in handling contexts and negotiating data sharing policies. This research is explorative and conceptual, representing the first development cycle of a design science research project in privacy engineering. The paper offers a concise understanding of data privacy as a foundation for design extending the seminal contextual integrity theory of Helen Nissenbaum. This theory started out as a normative theory describing the moral appropriateness of data transfers. In our work, the contextual integrity model is extended to a socio-technical theory that could have practical impact in the era of artificial intelligence. New conceptual constructs such as ‘context trigger’, ‘data sharing policy’ and ‘data sharing smart contract’ are defined, and their application is discussed from an organisational and technical level. The constructs and design are validated through expert interviews; contributions to design science research are discussed, and the paper concludes with presenting a framework for further privacy engineering development cycles.",
        "DOI": "10.1186/s41039-020-00141-9",
        "paper_author": "Hoel T.",
        "affiliation_name": "OsloMet – StorbyUniversitetet",
        "affiliation_city": "Oslo",
        "affiliation_country": "Norway",
        "affiliation_id": "60068730",
        "affiliation_state": "Oslo"
    },
    {
        "paper_title": "Identifying and assessing the impact of key neighborhood-level determinants on geographic variation in stroke: a machine learning and multilevel modeling approach",
        "publication": "BMC Public Health",
        "citied_by": "9",
        "cover_date": "2020-12-01",
        "Abstract": "Background: Stroke is a chronic cardiovascular disease that puts major stresses on U.S. health and economy. The prevalence of stroke exhibits a strong geographical pattern at the state-level, where a cluster of southern states with a substantially higher prevalence of stroke has been called the stroke belt of the nation. Despite this recognition, the extent to which key neighborhood characteristics affect stroke prevalence remains to be further clarified. Methods: We generated a new neighborhood health data set at the census tract level on nearly 27,000 tracts by pooling information from multiple data sources including the CDC’s 500 Cities Project 2017 data release. We employed a two-stage modeling approach to understand how key neighborhood-level risk factors affect the neighborhood-level stroke prevalence in each state of the US. The first stage used a state-of-the-art Bayesian machine learning algorithm to identify key neighborhood-level determinants. The second stage applied a Bayesian multilevel modeling approach to describe how these key determinants explain the variability in stroke prevalence in each state. Results: Neighborhoods with a larger proportion of older adults and non-Hispanic blacks were associated with neighborhoods with a higher prevalence of stroke. Higher median household income was linked to lower stroke prevalence. Ozone was found to be positively associated with stroke prevalence in 10 states, while negatively associated with stroke in five states. There was substantial variation in both the direction and magnitude of the associations between these four key factors with stroke prevalence across the states. Conclusions: When used in a principled variable selection framework, high-performance machine learning can identify key factors of neighborhood-level prevalence of stroke from wide-ranging information in a data-driven way. The Bayesian multilevel modeling approach provides a detailed view of the impact of key factors across the states. The identified major factors and their effect mechanisms can potentially aid policy makers in developing area-based stroke prevention strategies.",
        "DOI": "10.1186/s12889-020-09766-3",
        "paper_author": "Ji J.",
        "affiliation_name": "Icahn School of Medicine at Mount Sinai",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60012981",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Machine learning approach for predicting under-five mortality determinants in Ethiopia: evidence from the 2016 Ethiopian Demographic and Health Survey",
        "publication": "Genus",
        "citied_by": "23",
        "cover_date": "2020-12-01",
        "Abstract": "There is a dearth of literature on the use of machine learning models to predict important under-five mortality risks in Ethiopia. In this study, we showed spatial variations of under-five mortality and used machine learning models to predict its important sociodemographic determinants in Ethiopia. The study data were drawn from the 2016 Ethiopian Demographic and Health Survey. We used three machine learning models such as random forests, logistic regression, and K-nearest neighbors as well as one traditional logistic regression model to predict under-five mortality determinants. For each machine learning model, measures of model accuracy and receiver operating characteristic curves were used to evaluate the predictive power of each model. The descriptive results show that there are considerable regional variations in under-five mortality rates in Ethiopia. The under-five mortality prediction ability was found to be between 46.3 and 67.2% for the models considered, with the random forest model (67.2%) showing the best performance. The best predictive model shows that household size, time to the source of water, breastfeeding status, number of births in the preceding 5 years, sex of a child, birth intervals, antenatal care, birth order, type of water source, and mother’s body mass index play an important role in under-five mortality levels in Ethiopia. The random forest machine learning model produces a better predictive power for estimating under-five mortality risk factors and may help to improve policy decision-making in this regard. Childhood survival chances can be improved considerably by using these important factors to inform relevant policies.",
        "DOI": "10.1186/s41118-020-00106-2",
        "paper_author": "Bitew F.H.",
        "affiliation_name": "The University of Texas at San Antonio",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States",
        "affiliation_id": "60003212",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "A machine learning analysis of serious misconduct among Australian police",
        "publication": "Crime Science",
        "citied_by": "18",
        "cover_date": "2020-12-01",
        "Abstract": "Fairness in policing, driven by the effective and transparent investigation and remediation of police misconduct, is vital to maintaining the legitimacy of policing agencies, and the capacity for police to function within society. Research into police misconduct in Australia has traditionally been performed on an ad-hoc basis, with limited access to law enforcement data. This research seeks to identify the antecedents of serious police misconduct, resulting in the dismissal or criminal charge of officers, among a large police misconduct dataset. Demographic and misconduct data were sourced for a sample of 600 officers who have committed instances of serious misconduct, and a matched sample of 600 comparison officers across a 13-year period. A machine learning analysis, random forest, was utilised to produce a robust predictive model, with Partial Dependence Plots employed to demonstrate within variable interaction with serious misconduct. Prior instances of serious misconduct were particularly predictive of further serious misconduct, while misconduct was most prominent around mid-career. Secondary employment, and performance issues were important predictors, while demographic variables typically outperformed complaint variables. This research suggests that serious misconduct is similarly prevalent among experienced officers, as it is junior officers, while secondary employment is an important indicator of misconduct risk. Findings provide guidance for misconduct prevention policy among policing agencies.",
        "DOI": "10.1186/s40163-020-00133-6",
        "paper_author": "Cubitt T.I.C.",
        "affiliation_name": "Western Sydney University",
        "affiliation_city": "Penrith",
        "affiliation_country": "Australia",
        "affiliation_id": "60017803",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Exploiting distributional temporal difference learning to deal with tail risk",
        "publication": "Risks",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "In traditional Reinforcement Learning (RL), agents learn to optimize actions in a dynamic context based on recursive estimation of expected values. We show that this form of machine learning fails when rewards (returns) are affected by tail risk, i.e., leptokurtosis. Here, we adapt a recent extension of RL, called distributional RL (disRL), and introduce estimation efficiency, while properly adjusting for differential impact of outliers on the two terms of the RL prediction error in the updating equations. We show that the resulting “efficient distributional RL” (e-disRL) learns much faster, and is robust once it settles on a policy. Our paper also provides a brief, nontechnical overview of machine learning, focusing on RL.",
        "DOI": "10.3390/risks8040113",
        "paper_author": "Bossaerts P.",
        "affiliation_name": "Brain, Mind &amp; Markets Laboratory",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118919",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "THE FUTURE OF MEDICINE, healthcare innovation through precision medicine: policy case study of Qatar",
        "publication": "Life Sciences, Society and Policy",
        "citied_by": "35",
        "cover_date": "2020-12-01",
        "Abstract": "In 2016, the World Innovation Summit for Health (WISH) published its Forum Report on precision medicine “PRECISION MEDICINE - A GLOBAL ACTION PLAN FOR IMPACT”. Healthcare is undergoing a transformation, and it is imperative to leverage new technologies to generate new data and support the advent of precision medicine (PM). Recent scientific breakthroughs and technological advancements have improved our disease knowledge and altered diagnosis and treatment approaches resulting in a more precise, predictive, preventative and personalized health care that is customized for the individual patient. Consequently, the big data revolution has provided an opportunity to apply artificial intelligence and machine learning algorithms to mine such a vast data set. Additionally, personalized medicine promises to revolutionize healthcare, with its key goal of providing the right treatment to the right patient at the right time and dose, and thus the potential of improving quality of life and helping to bring down healthcare costs. This policy briefing will look in detail at the issues surrounding continued development, sustained investment, risk factors, testing and approval of innovations for better strategy and faster process. The paper will serve as a policy bridge that is required to enhance a conscious decision among the powers-that-be in Qatar in order to find a way to harmonize multiple strands of activity and responsibility in the health arena. The end goal will be for Qatar to enhance public awareness and engagement and to integrate effectively the incredible advances in research into healthcare systems, for the benefit of all patients. The PM policy briefing provides concrete recommendations on moving forward with PM initiatives in Qatar and internationally. Equally important, integration of PM within a primary care setting, building a coalition of community champions through awareness and advocacy, finally, communicating PM value, patient engagement/empowerment and education/continued professional development programs of the healthcare workforce. Key recommendations for implementation of precision medicine inside and outside Qatar:1.Create Community Awareness and PM Education Programs2.Engage and Empower Patients3.Communicate PM Value4.Develop appropriate Infrastructure and Information Management Systems5.Integrate PM into standard Healthcare System and Ensure Access to Care PM is no longer futuristic. It is here. Implementing PM in routine clinical care does require some investment and infrastructure development. Invariably, cost and lack of expertise are cited as barriers to PM implementation. Equally consequential, are the curriculum and professional development of medical care experts. Policymakers need to lead and coordinate effort among stakeholders and consider cultural and faith perspectives to ensure success. It is essential that policymakers integrate PM approaches into national strategies to improve health and health care for all, and to drive towards the future of medicine precision health.",
        "DOI": "10.1186/s40504-020-00107-1",
        "paper_author": "Qoronfleh M.W.",
        "affiliation_name": "Qatar Foundation",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar",
        "affiliation_id": "60106067",
        "affiliation_state": "Ad-Dawhah"
    },
    {
        "paper_title": "Mass wasting susceptibility assessment of snow avalanches using machine learning models",
        "publication": "Scientific Reports",
        "citied_by": "53",
        "cover_date": "2020-12-01",
        "Abstract": "Snow avalanche is among the most harmful natural hazards with major socioeconomic and environmental destruction in the cold and mountainous regions. The devastating propagation and accumulation of the snow avalanche debris and mass wasting of surface rocks and vegetation particles threaten human life, transportation networks, built environments, ecosystems, and water resources. Susceptibility assessment of snow avalanche hazardous areas is of utmost importance for mitigation and development of land-use policies. This research evaluates the performance of the well-known machine learning methods, i.e., generalized additive model (GAM), multivariate adaptive regression spline (MARS), boosted regression trees (BRT), and support vector machine (SVM), in modeling the mass wasting hazard induced by snow avalanches. The key features are identified by the recursive feature elimination (RFE) method and used for the model calibration. The results indicated a good performance of the modeling process (Accuracy > 0.88, Kappa > 0.76, Precision > 0.84, Recall > 0.86, and AUC > 0.89), which the SVM model highlighted superior performance than others. Sensitivity analysis demonstrated that the topographic position index (TPI) and distance to stream (DTS) were the most important variables which had more contribution in producing the susceptibility maps.",
        "DOI": "10.1038/s41598-020-75476-w",
        "paper_author": "Choubin B.",
        "affiliation_name": "AREEO",
        "affiliation_city": "Urmia",
        "affiliation_country": "Iran",
        "affiliation_id": "116061806",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Targeted transfer learning to improve performance in small medical physics datasets",
        "publication": "Medical Physics",
        "citied_by": "44",
        "cover_date": "2020-12-01",
        "Abstract": "Purpose: To perform an in-depth evaluation of current state of the art techniques in training neural networks to identify appropriate approaches in small datasets. Method: In total, 112,120 frontal-view X-ray images from the NIH ChestXray14 dataset were used in our analysis. Two tasks were studied: unbalanced multi-label classification of 14 diseases, and binary classification of pneumonia vs non-pneumonia. All datasets were randomly split into training, validation, and testing (70%, 10%, and 20%). Two popular convolution neural networks (CNNs), DensNet121 and ResNet50, were trained using PyTorch. We performed several experiments to test: (a) whether transfer learning using pretrained networks on ImageNet are of value to medical imaging/physics tasks (e.g., predicting toxicity from radiographic images after training on images from the internet), (b) whether using pretrained networks trained on problems that are similar to the target task helps transfer learning (e.g., using X-ray pretrained networks for X-ray target tasks), (c) whether freeze deep layers or change all weights provides an optimal transfer learning strategy, (d) the best strategy for the learning rate policy, and (e) what quantity of data is needed in order to appropriately deploy these various strategies (N = 50 to N = 77 880). Results: In the multi-label problem, DensNet121 needed at least 1600 patients to be comparable to, and 10 000 to outperform, radiomics-based logistic regression. In classifying pneumonia vs non-pneumonia, both CNN and radiomics-based methods performed poorly when N < 2000. For small datasets (< 2000), however, a significant boost in performance (>15% increase on AUC) comes from a good selection of the transfer learning dataset, dropout, cycling learning rate, and freezing and unfreezing of deep layers as training progresses. In contrast, if sufficient data are available (>35 000), little or no tweaking is needed to obtain impressive performance. While transfer learning using X-ray images from other anatomical sites improves performance, we also observed a similar boost by using pretrained networks from ImageNet. Having source images from the same anatomical site, however, outperforms every other methodology, by up to 15%. In this case, DL models can be trained with as little as N = 50. Conclusions: While training DL models in small datasets (N < 2000) is challenging, no tweaking is necessary for bigger datasets (N > 35 000). Using transfer learning with images from the same anatomical site can yield remarkable performance in new tasks with as few as N = 50. Surprisingly, we did not find any advantage for using images from other anatomical sites over networks that have been trained using ImageNet. This indicates that features learned may not be as general as currently believed, and performance decays rapidly even by just changing the anatomical site of the images.",
        "DOI": "10.1002/mp.14507",
        "paper_author": "Romero M.",
        "affiliation_name": "University of San Francisco",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States",
        "affiliation_id": "60085748",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Intelligent spectrum management based on reinforcement learning schemes in cooperative cognitive radio networks",
        "publication": "Physical Communication",
        "citied_by": "9",
        "cover_date": "2020-12-01",
        "Abstract": "Cognitive Radio (CR) and Cooperative Communication provide key technologies for efficient utilization of available unused spectrum bands (called resources) to achieve a spectral efficient system with high throughput. But to achieve its full potential, it is essential to empower the brain of CR that is Cognitive Engine (CE), using machine learning algorithms to control the operation and adapt parameters according to the dynamic environment. However, in practical scenarios, it is difficult to formulate network model beforehand due to complex network dynamics. To address this issue, the most favorable machine learning scheme, Reinforcement Learning (RL) based schemes are proposed to empower CE without forming an explicit network model. The proposed schemes, Comparison based Cooperative Q-Learning (CCopQL) and Comparison based Cooperative State-Action-Reward-(next) State-(next) Action (CCopSARSA) for resource allocation, allows each CR to learn cooperatively. The cooperation among CRs is in the form of comparing and then exchanging Q-values to obtain an optimal policy. Though these schemes involve information exchange among CRs as compared to independent Q-Leaning and SARSA but it provides improved system performance with high system throughput. Numerical results reveal the significant benefits from exploiting the cooperative feature with RL, both proposed schemes outperform other existing schemes in terms of system throughput and expedite the convergence than individual CR learning with CCopSARSA and CCopQL respectively.",
        "DOI": "10.1016/j.phycom.2020.101226",
        "paper_author": "Kaur A.",
        "affiliation_name": "National Institute of Technology Hamirpur",
        "affiliation_city": "Hamirpur",
        "affiliation_country": "India",
        "affiliation_id": "60016077",
        "affiliation_state": "HP"
    },
    {
        "paper_title": "When financial literacy meets textual analysis: A conceptual review",
        "publication": "Journal of Behavioral and Experimental Finance",
        "citied_by": "25",
        "cover_date": "2020-12-01",
        "Abstract": "Financial Literacy plays a crucial role in individuals’ decision-making process. Existing studies have shown that lower level of financial literacy lead to irrational financial decision on investments, pension funds as well as savings and debts. While financial literacy is difficult to measure referring to its qualitative nature, constructing appropriate measurement for financial literacy is vital for both market professionals as well as policy makers. This study focuses on reviewing the measurements of financial literacy commonly used in current literature as well as the corresponding limitations. Then, the study surveys on the recent development and applications of textual analysis in finance domains, through which proposes future directions that textual analysis and financial literacy may merge for the purposes of better understanding about financial literacy as well as further developing effective schemes to improve investors’ financial literacy.",
        "DOI": "10.1016/j.jbef.2020.100402",
        "paper_author": "Li X.",
        "affiliation_name": "Nankai University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60018038",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Methodology minute: a machine learning primer for infection prevention and control",
        "publication": "American Journal of Infection Control",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "The use of machine-learning and predictive modeling in infection prevention and control activities is increasing dramatically. In order for infection preventionists to make informed decisions on the performance of any particular model as well as to determine if the output of the model will be useful for their program needs, a suitable understanding of the creation and evaluation of these models is necessary. The purpose of this primer is to introduce the infection preventionist to the most commonly used machine-learning method in infection prevention: supervised learning.",
        "DOI": "10.1016/j.ajic.2020.09.009",
        "paper_author": "Wiemken T.L.",
        "affiliation_name": "Saint Louis University School of Medicine",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60000945",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "How could the station-based bike sharing system and the free-floating bike sharing system be coordinated?",
        "publication": "Journal of Transport Geography",
        "citied_by": "40",
        "cover_date": "2020-12-01",
        "Abstract": "The station-based bike sharing system (SBBSS) and the free-floating bike sharing system (FFBSS) have been adopted on a large scale in China. However, the overlap between the services provided by these two systems often makes bike sharing inefficient. By comparing the factors that affect the usage of the two systems, this paper aims to propose appropriate strategies to promote their coordinated development. Using data collected in Nanjing, a predictive model is built to determine which system is more suitable at a given location. The influences of infrastructure, demand distribution, and land use attributes at the station level are examined via the support vector machine (SVM) approach. Our results show that the SBBSS tends to be favored in areas where there is a high concentration of travel demand, and close proximity to metro stations and commercial properties, whereas locations with a higher density of major roads and residential properties are associated with more frequent use of the FFBSS. With regard to the methods used, a comparison of several machine learning approaches shows that the SVM has the best predictive performance. Our findings could be used to help policy makers and transportation planners to optimize the deployment and redistribution of docked and dockless bikes.",
        "DOI": "10.1016/j.jtrangeo.2020.102896",
        "paper_author": "Cheng L.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60005244",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Impact on place of death in cancer patients: a causal exploration in southern Switzerland",
        "publication": "BMC Palliative Care",
        "citied_by": "9",
        "cover_date": "2020-12-01",
        "Abstract": "Background: Most terminally ill cancer patients prefer to die at home, but a majority die in institutional settings. Research questions about this discrepancy have not been fully answered. This study applies artificial intelligence and machine learning techniques to explore the complex network of factors and the cause-effect relationships affecting the place of death, with the ultimate aim of developing policies favouring home-based end-of-life care. Methods: A data mining algorithm and a causal probabilistic model for data analysis were developed with information derived from expert knowledge that was merged with data from 116 deceased cancer patients in southern Switzerland. This data set was obtained via a retrospective clinical chart review. Results: Dependencies of disease and treatment-related decisions demonstrate an influence on the place of death of 13%. Anticancer treatment in advanced disease prevents or delays communication about the end of life between oncologists, patients and families. Unknown preferences for the place of death represent a great barrier to a home death. A further barrier is the limited availability of family caregivers for terminal home care. The family’s preference for the last place of care has a high impact on the place of death of 51%, while the influence of the patient’s preference is low, at 14%. Approximately one-third of family systems can be empowered by health care professionals to provide home care through open end-of-life communication and good symptom management. Such intervention has an influence on the place of death of 17%. If families express a convincing preference for home care, the involvement of a specialist palliative home care service can increase the probability of home deaths by 24%. Conclusion: Concerning death at home, open communication about death and dying is essential. Furthermore, for the patient preference for home care to be respected, the family’s decision for the last place of care seems to be key. The early initiation of family-centred palliative care and the provision of specialist palliative home care for patients who wish to die at home are suggested.",
        "DOI": "10.1186/s12904-020-00664-4",
        "paper_author": "Kern H.",
        "affiliation_name": "Triangolo Association",
        "affiliation_city": null,
        "affiliation_country": "Switzerland",
        "affiliation_id": "125225480",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Risk estimation of SARS-CoV-2 transmission from bluetooth low energy measurements",
        "publication": "npj Digital Medicine",
        "citied_by": "22",
        "cover_date": "2020-12-01",
        "Abstract": "Digital contact tracing approaches based on Bluetooth low energy (BLE) have the potential to efficiently contain and delay outbreaks of infectious diseases such as the ongoing SARS-CoV-2 pandemic. In this work we propose a machine learning based approach to reliably detect subjects that have spent enough time in close proximity to be at risk of being infected. Our study is an important proof of concept that will aid the battery of epidemiological policies aiming to slow down the rapid spread of COVID-19.",
        "DOI": "10.1038/s41746-020-00340-0",
        "paper_author": "Sattler F.",
        "affiliation_name": "Fraunhofer-Institut für Nachrichtentechnik Heinrich-Hertz-Institut",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011055",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A deep learning solution to recommend laboratory reduction strategies in ICU",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "10",
        "cover_date": "2020-12-01",
        "Abstract": "Objective: To build a machine-learning model that predicts laboratory test results and provides a promising lab test reduction strategy, using spatial-temporal correlations. Materials and methods: We developed a global prediction model to treat laboratory testing as a series of decisions by considering contextual information over time and across modalities. We validated our method using a critical care database (MIMIC III), which includes 4,570,709 observations of 12 standard laboratory tests, among 38,773 critical care patients. Our deep-learning model made real-time laboratory reduction recommendations and predicted the properties of lab tests, including values, normal/abnormal (whether labs were within the normal range) and transition (normal to abnormal or abnormal to normal from the latest lab test). We reported area under the receiver operating characteristic curve (AUC) for predicting normal/abnormal, evaluated accuracy and absolute bias on prediction vs. observation against lab test reduction proportion. We compared our model against baseline models and analyzed the impact of variations on the recommended reduction strategy. Results: Our best model offered a 20.26 % reduction in the number of laboratory tests. By applying the recommended reduction policy on the hold-out dataset (7755 patients), our model predicted normality/abnormality of laboratory tests with a 98.27 % accuracy (AUC, 0.9885; sensitivity, 97.84 %; specificity, 98.80 %; PPV, 99.01 %; NPV, 97.39 %) on 20.26 % reduced lab tests, and recommended 98.10 % of transitions to be checked. Our model performed better than the greedy models, and the recommended reduction strategy was robust. Discussion: Strong spatial and temporal correlations between laboratory tests can be used to optimize policies for reducing laboratory tests throughout the hospital course. Our method allows for iterative predictions and provides a superior solution for the dynamic decision-making laboratory reduction problem. Conclusion: This work demonstrates a machine-learning model that assists physicians in determining which laboratory tests may be omitted.",
        "DOI": "10.1016/j.ijmedinf.2020.104282",
        "paper_author": "Yu L.",
        "affiliation_name": "School of Biomedical Informatics",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "109533563",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",
        "publication": "Ageing Research Reviews",
        "citied_by": "380",
        "cover_date": "2020-12-01",
        "Abstract": "One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",
        "DOI": "10.1016/j.arr.2020.101174",
        "paper_author": "Fang E.F.",
        "affiliation_name": "Akershus University Hospital",
        "affiliation_city": "Lorenskog",
        "affiliation_country": "Norway",
        "affiliation_id": "60068728",
        "affiliation_state": "Viken"
    },
    {
        "paper_title": "Leveraging Computational Modeling to Understand Infectious Diseases",
        "publication": "Current Pathobiology Reports",
        "citied_by": "24",
        "cover_date": "2020-12-01",
        "Abstract": "Purpose of Review: Computational and mathematical modeling have become a critical part of understanding in-host infectious disease dynamics and predicting effective treatments. In this review, we discuss recent findings pertaining to the biological mechanisms underlying infectious diseases, including etiology, pathogenesis, and the cellular interactions with infectious agents. We present advances in modeling techniques that have led to fundamental disease discoveries and impacted clinical translation. Recent Findings: Combining mechanistic models and machine learning algorithms has led to improvements in the treatment of Shigella and tuberculosis through the development of novel compounds. Modeling of the epidemic dynamics of malaria at the within-host and between-host level has afforded the development of more effective vaccination and antimalarial therapies. Similarly, in-host and host-host models have supported the development of new HIV treatment modalities and an improved understanding of the immune involvement in influenza. In addition, large-scale transmission models of SARS-CoV-2 have furthered the understanding of coronavirus disease and allowed for rapid policy implementations on travel restrictions and contract tracing apps. Summary: Computational modeling is now more than ever at the forefront of infectious disease research due to the COVID-19 pandemic. This review highlights how infectious diseases can be better understood by connecting scientists from medicine and molecular biology with those in computer science and applied mathematics.",
        "DOI": "10.1007/s40139-020-00213-x",
        "paper_author": "Jenner A.L.",
        "affiliation_name": "University of Montreal",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60009507",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Wetland conversion risk assessment of East Kolkata Wetland: A Ramsar site using random forest and support vector machine model",
        "publication": "Journal of Cleaner Production",
        "citied_by": "79",
        "cover_date": "2020-12-01",
        "Abstract": "East Kolkata Wetland (EKW) is a Ramsar site located adjacent to the Kolkata megacity. EKW is one of the resourceful wetland ecosystems of the world which offers a bundle of direct and indirect ecosystem services to the Kolkata megacity region. The rapid expansion of built-up in the surrounding urban agglomeration of the EKW is putting immense pressure on the EKW and the rate of wetland loss has been highest in recent decades. To ensure that this distinct ecosystem is conserved, an efficient means of identifying wetland conversion risk is needed. This study aims to assess the risk of EKW conversion using two advanced data-driven Machine Learning (ML) models, viz, Random Forest (RF), and Support Vector Machine (SVM). The novelty of the paper is in the fact that ML models have been widely applied to groundwater potential, flood susceptibility, and landslide susceptibility, their applicability to wetland conversion risk assessment has not yet been explored. The advantage of RF and SVM is that both of the ML models can overcome the limitations of pre-assumption based conventional methods of wetland risk assessment. A total of eight factors are selected which can be categorized into ecological, bio-physical, demographic, and physical infrastructure groups. Both results indicate that around 60% area under medium to very high-risk zones. A comparison is also made between these two methods to identify the most precise prediction method for this study area. The results of the models are quantitatively validated applying the Receiver Operating Characteristics (ROC) method, where both of this method identifies SVM as a more precise predictive model for this study with 91.12% accuracy. The spatial pattern of encroachment and shrinkage of EKW triggered by urban expansion is successfully captured by RF and ME. Policy analysts and land-use planners can use the outcome derived from RF and SVM models and associated maps to identify the risk zones, assess the effectiveness of wetland conservation programs, design effective policies to stop further degradation of the wetlands, and adopt long-term sustainable planning for this precious ecosystem.",
        "DOI": "10.1016/j.jclepro.2020.123475",
        "paper_author": "Ghosh S.",
        "affiliation_name": "Kazi Nazrul University",
        "affiliation_city": "Bardhaman",
        "affiliation_country": "India",
        "affiliation_id": "60111753",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Early identification of technological convergence in numerical control machine tool: a deep learning approach",
        "publication": "Scientometrics",
        "citied_by": "18",
        "cover_date": "2020-12-01",
        "Abstract": "The importance of technology convergence of multidisciplinary knowledge has increased recently, and it is a crucial way to spur emerging technologies. Therefore, to understand and identify the technology convergence, which refers to the combination of two or more technological elements for a new system with new functions, is an important issue for both the researchers and the company directors. To identify and investigate the patterns of technology convergence, this research examines the numerical control machine tool, which has typical characteristics of technology convergence in recent years. Based on the numerical control machine tool related publications published between 1997 and 2019, we perform a deep learning approach based on Graph Neural Network model using publication citation network topology and text information together, to identify the technology convergence trajectory and to examine the dynamic role of corresponding technology sub-fields in the technology convergence. The results show that there was an obvious increase for the interdisciplinary citations from information technology to NC machine tool in recent years, and the technology convergence on NC machine tool is signal processing in machining and application of intelligent algorithms in motion control and process planning. In addition, the revelation of the technology convergence early identification contributes to the formation theory of emerging technologies that are interdisciplinary, and is of great interest to researchers, policy makers, and industrialists.",
        "DOI": "10.1007/s11192-020-03696-y",
        "paper_author": "Kong D.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Fully automated carbonate petrography using deep convolutional neural networks",
        "publication": "Marine and Petroleum Geology",
        "citied_by": "71",
        "cover_date": "2020-12-01",
        "Abstract": "Carbonate rocks are important archives of past ocean conditions as well as hosts of economic resources such as hydrocarbons, water, and minerals. Geologists typically perform compositional analysis of grain, matrix, cement and pore types in order to interpret depositional environments, diagenetic modification, and reservoir quality of carbonate strata. Such information can be obtained primarily from petrographic analysis, a task that is costly, labor-intensive, and requires in-depth knowledge of carbonate petrology and micropaleontology. Recent studies have leveraged machine learning-based image analysis, including Deep Convolutional Neural Networks (DCNN), to automate description, classification and interpretation of thin sections, subsurface core images and seismic facies, which would accelerate data acquisition and reproducibility for these tasks. In carbonate rocks, this approach has been applied primarily to recognize carbonate lithofacies, and no attempt has been made to individually identify and quantify various types of carbonate grains, matrix, and cement. In this study, the applicability and performance of DCNN-based object detection and image classification approaches are assessed with respect to carbonate compositional analysis. The training data comprised of more than 13,000 individually labelled objects from nearly 4000 carbonate petrographic images. The dataset is grouped into six and nine different classes for the image classification and object detection tasks, respectively. Even with a small and relatively imbalanced training set, the DCNN was able to achieve an F1 score of 92% for image classification and 84% mean precision for object detection by combining one-cycle policy, class weight, and label mixup-smoothing methods. This study highlights the inefficiency of image classification as an approach to replicating human description and classification of carbonate petrography. By contrast, DCNN-based object detection appears capable of approaching human speed and accuracy in the area of carbonate petrography because it is able to individually locate and identify different carbonate components with greater cost-efficiency, speed, and reproducibility than conventional (human) petrographic analysis.",
        "DOI": "10.1016/j.marpetgeo.2020.104687",
        "paper_author": "Koeshidayatullah A.",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60012708",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Ranking sociodemographic, health behavior, prevention, and environmental factors in predicting neighborhood cardiovascular health: A Bayesian machine learning approach",
        "publication": "Preventive Medicine",
        "citied_by": "19",
        "cover_date": "2020-12-01",
        "Abstract": "Cardiovascular disease is the leading cause of death in the United States. While abundant research has been conducted to identify risk factors for cardiovascular disease at the individual level, less is known about factors that may influence population cardiovascular health outcomes at the neighborhood level. The purpose of this study is to use Bayesian Additive Regression Trees, a state-of-the-art machine learning approach, to rank sociodemographic, health behavior, prevention, and environmental factors in predicting neighborhood cardiovascular health. We created a new neighborhood health dataset by combining three datasets at the census tract level, including the 500 Cities Data from the Centers for Disease Control and Prevention, the 2011–2015 American Community Survey 5-Year Estimates from the Census Bureau, and the 2015–2016 Environmental Justice Screening database from the Environmental Protection Agency in the United States. Results showed that neighborhood behavioral factors such as the proportions of people who are obese, do not have leisure-time physical activity, and have binge drinking emerged as top five predictors for most of the neighborhood cardiovascular health outcomes. Findings from this study would allow public health researchers and policymakers to prioritize community-based interventions and efficiently use limited resources to improve neighborhood cardiovascular health.",
        "DOI": "10.1016/j.ypmed.2020.106240",
        "paper_author": "Hu L.",
        "affiliation_name": "Icahn School of Medicine at Mount Sinai",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60012981",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Artificial intelligence and business models in the sustainable development goals perspective: A systematic literature review",
        "publication": "Journal of Business Research",
        "citied_by": "613",
        "cover_date": "2020-12-01",
        "Abstract": "This paper investigates the literary corpus on the role of Artificial Intelligence (AI) in the construction of sustainable business models (SBMs). It provides a quantitative overview of the academic literature that constitutes the field. The paper discusses the relationships between AI and rapid developments in machine learning and sustainable development (SD). Specifically, the aim is to understand whether this branch of computer science can influence production and consumption patterns to achieve sustainable resource management according to Sustainable Development Goals (SDGs) outlined in the UN 2030 Agenda. Moreover, the paper aims to highlight the role of Knowledge Management Systems (KMS) in the cultural drift toward the spread of AI for SBMs. Despite the importance of the topic, there is no comprehensive review of the AI and SBM literature in light of SDGs. Based on a database containing 73 publications in English with publication dates from 1990 to 2019, a bibliometric analysis is conducted. The findings show that the innovation challenge involves ethical, social, economic, and legal aspects. Thus, considering that the development potential of AI is linked to the UN 2030 Agenda for SD, especially to SDG#12, our results also outline the framework of the existing literature on AI and SDGs, especially SDG#12, including AI's association with the cultural drift (CD) in the SBMs. The paper highlights the key contributions, which are: i) a comprehensive review of the key underlying relationship between AI and SBMs, offering a holistic view as needed, ii) identifying a research gap regarding KMS through AI, and iii) the implications of AI concerning SDG#12. Academic and managerial implications are also discussed regarding KMS in the SBMs, where the AI can represent the vehicle to meet the SDGs allowing for the identification of the cultural change required by enterprises to achieve sustainable goals. Thus, business companies, academic research practitioners, and state policy should focus on the further development of the use of AI in SBMs.",
        "DOI": "10.1016/j.jbusres.2020.08.019",
        "paper_author": "Di Vaio A.",
        "affiliation_name": "Parthenope University of Naples",
        "affiliation_city": "Naples",
        "affiliation_country": "Italy",
        "affiliation_id": "60025235",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Regional climate resilience index: A novel multimethod comparative approach for indicator development, empirical validation and implementation",
        "publication": "Ecological Indicators",
        "citied_by": "41",
        "cover_date": "2020-12-01",
        "Abstract": "High uncertainty in the occurrence of extreme events and disasters have made resilience-building an imperative part of society. Resilience assessment is an important tool in this context. Resilience is multidimensional as well as place-, scale- and time-specific, which requires a comprehensive approach for measuring and analysing. In this regard, composite indicators are preferred, and extensive literature is available on resilience indices on all spatial and temporal scales as well as hazard-specific or multi-hazard related indicators. However, transparent, robust, validated and transferable metrics are still missing from the scientific discourse. Hence, the research follows a novel composite index development approach: First, to develop and operationalise climate resilience on the county level in the state of Baden-Württemberg, Germany; second, to develop multiple composite indices in order to assess the impact of the construction methodology to increase transparency and decrease uncertainty; third, validating the index by statistical as well as empirical data and machine learning models - which is a novel endeavour so far. The results underscored that the two-step inclusive validation of data-driven statistical analysis in combination with empirical data proved to be essential in developing the index during the selection and aggregation of indicators. The results also highlighted a lower climate resilience of rural regions compared to metropolitan regions despite their better environmental status. Overall, machine learning proved to be essential in understanding and linking indicators and indices to policy, resilience and empirical data. The research contributes to a better understanding of climate resilience as well as to the methodological construction of composite indicators.",
        "DOI": "10.1016/j.ecolind.2020.106861",
        "paper_author": "Feldmeyer D.",
        "affiliation_name": "Universität Stuttgart",
        "affiliation_city": "Stuttgart",
        "affiliation_country": "Germany",
        "affiliation_id": "60015815",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Trajectories of informal care intensity among the oldest-old Chinese",
        "publication": "Social Science and Medicine",
        "citied_by": "18",
        "cover_date": "2020-12-01",
        "Abstract": "Countries around the world face increasing demand for long-term care in the older population. Yet, the longitudinal patterns of long-term care use and the underlying predictors have not been well understood, which impedes efficient care planning and timely service delivery. This study investigates the trajectories of informal care intensity in the oldest-old Chinese population and identifies the most important predictors of care trajectories. The data come from four waves of the Chinese Longitudinal Health Longevity Survey (CLHLS 2005–2014, N = 10,292). We conducted the latent trajectory analysis (LTA) to cluster people's diverse trajectories into a finite number of groups. We built machine learning (ML) models to predict people's care trajectories and ranked the relative importance of the predictors. The LTA identified three distinct trajectories of informal care intensity: the low, increased and high intensity trajectories. Care intensity increases in all three trajectories. Older people with more severe limitations, females, urban residents, people with a higher income, and people with more daughters in the first wave are more likely to follow the increased or high intensity trajectory rather than the low intensity trajectory in the following decade. The random forest classifier has the best overall prediction performance among the four machine learning models. Its prediction accuracy can be further improved via model optimisation. Oldest-old people in China follow divergent trajectories of care utilisation, and inequality of informal care intensity is discernible across time, demonstrating the need for timely and targeted delivery of government support to those who need it most. Accurate prediction of care trajectories will be of great value to policy makers and practitioners in relation to the planning of personalised care and the equitable allocation of care resources.",
        "DOI": "10.1016/j.socscimed.2020.113338",
        "paper_author": "Hu B.",
        "affiliation_name": "London School of Economics and Political Science",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60003059",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A data-driven approach for multi-scale GIS-based building energy modeling for analysis, planning and support decision making",
        "publication": "Applied Energy",
        "citied_by": "113",
        "cover_date": "2020-12-01",
        "Abstract": "Urban planners, local authorities, and energy policymakers often develop strategic sustainable energy plans for the urban building stock in order to minimize overall energy consumption and emissions. Planning at such scales could be informed by building stock modeling using existing building data and Geographic Information System-based mapping. However, implementing these processes involves several issues, namely, data availability, data inconsistency, data scalability, data integration, geocoding, and data privacy. This research addresses the aforementioned information challenges by proposing a generalized integrated methodology that implements bottom-up, data-driven, and spatial modeling approaches for multi-scale Geographic Information System mapping of building energy modeling. This study uses the Irish building stock to map building energy performance at multiple scales. The generalized data-driven methodology uses approximately 650,000 Irish Energy Performance Certificates buildings data to predict more than 2 million buildings’ energy performance. In this case, the approach delivers a prediction accuracy of 88% using deep learning algorithms. These prediction results are then used for spatial modeling at multiple scales from the individual building level to a national level. Furthermore, these maps are coupled with available spatial resources (social, economic, or environmental data) for energy planning, analysis, and support decision-making. The modeling results identify clusters of buildings that have a significant potential for energy savings within any specific region. Geographic Information System-based modeling aids stakeholders in identifying priority areas for implementing energy efficiency measures. Furthermore, the stakeholders could target local communities for retrofit campaigns, which would enhance the implementation of sustainable energy policy decisions.",
        "DOI": "10.1016/j.apenergy.2020.115834",
        "paper_author": "Ali U.",
        "affiliation_name": "University College Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland",
        "affiliation_id": "60005141",
        "affiliation_state": "Leinster"
    },
    {
        "paper_title": "Safe Intermittent Reinforcement Learning with Static and Dynamic Event Generators",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "78",
        "cover_date": "2020-12-01",
        "Abstract": "In this article, we present an intermittent framework for safe reinforcement learning (RL) algorithms. First, we develop a barrier function-based system transformation to impose state constraints while converting the original problem to an unconstrained optimization problem. Second, based on optimal derived policies, two types of intermittent feedback RL algorithms are presented, namely, a static and a dynamic one. We finally leverage an actor/critic structure to solve the problem online while guaranteeing optimality, stability, and safety. Simulation results show the efficacy of the proposed approach.",
        "DOI": "10.1109/TNNLS.2020.2967871",
        "paper_author": "Yang Y.",
        "affiliation_name": "University of Science and Technology Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60018273",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Robots join the care team: Making healthcare decisions safer with machine learning and robotics",
        "publication": "Healthcare",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.hjdsi.2020.100465",
        "paper_author": "Beckman A.L.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Flood susceptibility modeling in Teesta River basin, Bangladesh using novel ensembles of bagging algorithms",
        "publication": "Stochastic Environmental Research and Risk Assessment",
        "citied_by": "154",
        "cover_date": "2020-12-01",
        "Abstract": "Abstract: The flooding in Bangladesh during monsoon season is very common and frequently happens. Consequently, people have been experiencing tremendous damage to properties, infrastructures, and human casualties. Usually, floods are one of the devastating disasters from nature, but for developing nations like Bangladesh, flooding becomes worse. Due to the dynamic and complex nature of the flooding, the prediction of flooding sites was usually very difficult for flood management. But the artificial intelligence and advanced remote sensing techniques together could predict and identify the possible sites, which are vulnerable to flooding. The present work aimed to predict and identify the flooding sites or flood susceptible zones in the Teesta River basin by employing state-of-the-art novel ensemble machine learning algorithms. We developed ensembles of bagging with REPtree, random forest (RF), M5P, and random tree (RT) algorithms for obtaining reliable and highly accurate results. Twelve factors, which are considered as the conditioning factors, and 413 current and former flooding points were identified for flooding susceptibility modelling. The Information Gain ratio statistical technique was utilized to determine the influence of the factors for flooding. We applied receiver operating characteristic curve (ROC) for validation of the flood susceptible models. The Freidman test, Wilcoxon signed-rank test, Kruskal–Wallis test and Kolmogorov–Smirnov test were applied together for the first time in flood susceptibility modelling to compare the models with each other. Results showed that more than 800 km2 area was predicted as the very high flood susceptibility zones by all algorithms. The ROC curve showed that all models achieved more than 0.85 area under the curve indicating highly accurate flood models. For flood susceptibility modelling, the bagging with M5P performed superior, followed by bagging with RF, bagging with REPtree and bagging with RT. The methodology and solution-oriented results presented in this paper will assist the regional as well as local authorities and the policy-makers for mitigating the risks related to floods and also help in developing appropriate measures to avoid potential damages. Graphic abstract: [Figure not available: see fulltext.]",
        "DOI": "10.1007/s00477-020-01862-5",
        "paper_author": "Talukdar S.",
        "affiliation_name": "University of Gour Banga",
        "affiliation_city": "Malda",
        "affiliation_country": "India",
        "affiliation_id": "60116965",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Assessing urban growth in Ghana using machine learning and intensity analysis: A case study of the New Juaben Municipality",
        "publication": "Land Use Policy",
        "citied_by": "35",
        "cover_date": "2020-12-01",
        "Abstract": "Population growth coupled with economic, housing and environmental factors have significantly contributed into accelerated land use change in the New Juaben Municipality of Ghana. These factors have caused destruction of natural habitat and increased natural hazards such as flooding in the Municipality. Monitoring land use/land cover change is essential in respect to the dynamics of both human and natural factors that affect the biophysical and biochemical properties of the land surface. This research investigates the transitions among the major land use/land cover categories in the Municipality as a highly populated urban region that is facing some environmental challenges such as deforestation and degradation of the environment. Random Forest was adopted for the classification of 1985, 1991, 2002 and 2015 land cover maps while the analysis of the dynamics was conducted using intensity analysis. The unique contribution of this article is the combine usage of machine learning algorithm and intensity analysis to assess the changes in land use/land cover. The results showed that 1985–1991 and 2002–2015 periods experience fast change and the land use transformation has been accelerating over the whole period. The major changes were caused by the Built-up and Agricultural activities constituting 21.24 % and 13.19 % respectively in the category level. It is recommended that, authorities should consider several structural transformation measures within Ghana, including inter-sectoral land use harmonization policies (e.g. the Land Use and Spatial Planning Act 2016), land use planning and legal reforms to help address the underlying drivers of urban led deforestation.",
        "DOI": "10.1016/j.landusepol.2020.105057",
        "paper_author": "Nyamekye C.",
        "affiliation_name": "Koforidua Technical University",
        "affiliation_city": "Koforidua",
        "affiliation_country": "Ghana",
        "affiliation_id": "60087421",
        "affiliation_state": "Eastern Region"
    },
    {
        "paper_title": "Soul and machine (learning)",
        "publication": "Marketing Letters",
        "citied_by": "14",
        "cover_date": "2020-12-01",
        "Abstract": "Machine learning is bringing us self-driving cars, medical diagnoses, and language translation, but how can machine learning help marketers improve marketing decisions? Machine learning models predict extremely well, are scalable to “big data,” and are a natural fit to analyze rich media content, such as text, images, audio, and video. Examples of current marketing applications include identification of customer needs from online data, accurate prediction of consumer response to advertising, personalized pricing, and product recommendations. But without the human input and insight—the soul—the applications of machine learning are limited. To create competitive or cooperative strategies, to generate creative product designs, to be accurate for “what-if” and “but-for” applications, to devise dynamic policies, to advance knowledge, to protect consumer privacy, and avoid algorithm bias, machine learning needs a soul. The brightest future is based on the synergy of what the machine can do well and what humans do well. We provide examples and predictions for the future.",
        "DOI": "10.1007/s11002-020-09538-4",
        "paper_author": "Proserpio D.",
        "affiliation_name": "USC Marshall School of Business",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60099658",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Towards a comprehensive and consistent global aquatic land cover characterization framework addressing multiple user needs",
        "publication": "Remote Sensing of Environment",
        "citied_by": "18",
        "cover_date": "2020-12-01",
        "Abstract": "Aquatic land cover represents the land cover type that is significantly influenced by the presence of water over an extensive part of a year. Monitoring global aquatic land cover types plays an essential role in preserving aquatic ecosystems and maintaining the ecosystem service they provide for humans, while at the same time their accurate and consistent monitoring for multiple purposes (e.g. climate modelling, biodiversity conservation, water resource management) remains challenging. Although a number of global aquatic land cover (GALC) datasets are available for use to monitor aquatic ecosystems, there are prominent variabilities among these datasets, which is primarily caused by the inconsistency between different land versus water-related monitoring approaches and characterization schemes. As aquatic land cover exists in many different forms on Earth (e.g. wetland, open water) and can be mapped by different approaches, it is necessary to consider a much more consistent and comprehensive characterization framework that not only ensures the consistency in the monitoring of aquatic land cover but also serves the needs of multiple users (e.g. climate users, agricultural users) interested in different aspects of aquatic lands. In this study, we addressed this issue by 1) reviewing 33 GALC datasets and user needs identified from the citing papers of current datasets and international conventions, policies and agreements in relation to aquatic ecosystems, 2) proposing a global characterization framework for aquatic land cover based on the Land Cover Classification System (LCCS) classifier principles and the identified user needs, and 3) highlighting the opportunities and challenges provided by remote sensing techniques for the implementation of the proposed framework. Results show that users require or prefer various kinds of information on aquatic types including vegetation type, water persistence, the artificiality of cover (i.e. artificial vs natural), water salinity, and the accessibility to the sea (i.e. coastal vs inland). Datasets with medium to high spatial resolution, intra-annual dynamics and inter-annual changes are needed by many users. However, none of the existing datasets can meet all these requirements and a rigorous quantitative accuracy assessment is lacking to evaluate its quality for most of the GALC datasets. The proposed framework has three levels and users are allowed to derive their aquatic land cover types of interest by combining different levels and classifiers of information. This comprehensive mapping framework can help to bridge the gap between user needs and current GALC datasets as well as the gap between generic and aquatic land cover monitoring. The implementation of the framework can benefit from evolving satellite-data availability, improved computation capability and open-source machine learning algorithms, although at the same time it faces challenges mainly coming from the complexity of aquatic ecosystems. The framework proposed in this study provides insights for future operational aquatic land cover monitoring initiatives and will support better understanding and monitoring of complex aquatic ecosystems.",
        "DOI": "10.1016/j.rse.2020.112034",
        "paper_author": "Xu P.",
        "affiliation_name": "Wageningen University &amp; Research",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60004156",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "A critical review on computer vision and artificial intelligence in food industry",
        "publication": "Journal of Agriculture and Food Research",
        "citied_by": "322",
        "cover_date": "2020-12-01",
        "Abstract": "Emerging technologies such as computer vision and Artificial Intelligence (AI) are estimated to leverage the accessibility of big data for active training and yielding operational real time smart machines and predictable models. This phenomenon of applying vision and learning methods for the improvement of food industry is termed as computer vision and AI driven food industry. This review contributes to provide an insight into state-of-the-art AI and computer vision technologies that can assist farmers in agriculture and food processing. This paper investigates various scenarios and use cases of machine learning, machine vision and deep learning in global perspective with the lens of sustainability. It explains the increasing demand towards the AgTech industry using computer vision and AI which might be a path towards sustainable food production to feed the future. Also, this review tosses some implications regarding challenges and recommendations in inclusion of technologies in real time farming, substantial global policies and investments. Finally, the paper discusses the possibility of using Fourth Industrial Revolution [4.0 IR] technologies such as deep learning and computer vision robotics as a key for sustainable food production.",
        "DOI": "10.1016/j.jafr.2020.100033",
        "paper_author": "Kakani V.",
        "affiliation_name": "Inha University",
        "affiliation_city": "Incheon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60028876",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Intelligently modeling, detecting, and scheduling elephant flows in software defined energy cloud: A survey",
        "publication": "Journal of Parallel and Distributed Computing",
        "citied_by": "15",
        "cover_date": "2020-12-01",
        "Abstract": "Elephant flows (elephants) refer to the sequences of packets that contribute only 10% of the total volume but consume over 90% of the network bandwidth. They often cause network congestion and should be efficiently managed. Present cloud data centers often involve host- and switch-based approaches to detect and schedule elephants, but suffer (1) each host and switch in the network needs to be customized, and (2) dynamic models and advanced policies are difficult to be applied. Software Defined Cloud (SDC) addresses these issues by enabling controller-based approaches. With the aid of Machine Learning (ML) technologies, SDC can achieve learning-based models, flexible deployment, and early detection and schedule of elephants for the optimization of network performance and energy usage in a dynamic and intelligent manner. On this purpose, this article emphases the significance of models describing elephants, surveys the mechanisms that may apply to model, detect, and schedule elephants for SDC to optimize the network performance and energy usage. To the best of our knowledge, this work is the first effort that reviews the techniques in all these related subtopics simultaneously in the context of energy cloud.",
        "DOI": "10.1016/j.jpdc.2020.07.008",
        "paper_author": "Liao L.X.",
        "affiliation_name": "Gulin University of Aerospace Technology",
        "affiliation_city": null,
        "affiliation_country": "China",
        "affiliation_id": "124998699",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Survey on deep learning applied to predictive maintenance",
        "publication": "International Journal of Electrical and Computer Engineering",
        "citied_by": "9",
        "cover_date": "2020-12-01",
        "Abstract": "Prognosis health monitoring (PHM) plays an increasingly important role in the management of machines and manufactured products in today's industry, and deep learning plays an important part by establishing the optimal predictive maintenance policy. However, traditional learning methods such as unsupervised and supervised learning with standard architectures face numerous problems when exploiting existing data. Therefore, in this essay, we review the significant improvements in deep learning made by researchers over the last 3 years in solving these difficulties. We note that researchers are striving to achieve optimal performance in estimating the remaining useful life (RUL) of machine health by optimizing each step from data to predictive diagnostics. Specifically, we outline the challenges at each level with the type of improvement that has been made, and we feel that this is an opportunity to try to select a state-of-the-art architecture that incorporates these changes so each researcher can compare with his or her model. In addition, post-RUL reasoning and the use of distributed computing with cloud technology is presented, which will potentially improve the classification accuracy in maintenance activities. Deep learning will undoubtedly prove to have a major impact in upgrading companies at the lowest cost in the new industrial revolution, Industry 4.0.",
        "DOI": "10.11591/ijece.v10i6.pp5592-5598",
        "paper_author": "Maher Y.",
        "affiliation_name": "Université Hassan 1er",
        "affiliation_city": "Settat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60026692",
        "affiliation_state": "Casablanca-Settat"
    },
    {
        "paper_title": "A conversation with Sherri Rose, winner of the 2020 health policy statistics section mid-career award",
        "publication": "Health Services and Outcomes Research Methodology",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Sherri Rose, Ph.D. is an associate professor at Stanford University in the Center for Health Policy and Center for Primary Care and Outcomes Research as well as Co-Director of the joint Harvard–Stanford Health Policy Data Science Lab. A renowned expert in machine learning methodology for causal inference and prediction, her applied work has focused on risk adjustment, algorithmic fairness, health program evaluation, and comparative effectiveness research. Dr. Rose’s leadership positions include current roles as Co-Editor of Biostatistics and Chair of the American Statistical Association’s Biometrics Section. She is also a Fellow of the American Statistical Association. Dr. Rose earned a BS in Statistics from The George Washington University and a PhD in Biostatistics from the University of California, Berkeley before completing an NSF Mathematical Sciences Postdoctoral Research Fellowship at Johns Hopkins University. Prior to joining the faculty at Stanford University, she was on the faculty at Harvard Medical School in the Department of Health Care Policy. Below, an interview of Dr. Rose, conducted by her colleague, Dr. Laura Hatfield, on the occasion of her 2020 Mid-Career Award from the Health Policy Statistics Section (HPSS) of the American Statistical Association. This award recognizes leaders in health care policy and health services research who have made outstanding contributions through methodological or applied work and who show a promise of continued excellence at the frontier of statistical practice that advances the aims of HPSS.",
        "DOI": "10.1007/s10742-020-00216-6",
        "paper_author": "Hatfield L.A.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "A multi-stage method to predict carbon dioxide emissions using dimensionality reduction, clustering, and machine learning techniques",
        "publication": "Journal of Cleaner Production",
        "citied_by": "83",
        "cover_date": "2020-12-01",
        "Abstract": "The main purpose of this paper is to develop an efficient multi-stage methodology to predict carbon dioxide emissions based on two important variables including the energy consumption and economic growth using the clustering, prediction machine learning techniques, and dimensionality reduction. To do so, we use the self-organizing map clustering algorithm to cluster the data and the adaptive neuro-fuzzy inference system and artificial neural network to construct the prediction models in each cluster of the self-organizing map to predict carbon dioxide emissions considering a set of input parameters including economic growth and energy consumption in Group 20 nations. Furthermore, we use the singular value decomposition for dimensionality reduction and missing values’ prediction in the dataset. The results of the analysis of a real-world dataset found that the developed multi-stage approach was capable of predicting the carbon dioxide emissions on two indicators. To validate the proposed method, the results are compared with other existing methods. The outcomes demonstrate that the adaptive neuro-fuzzy inference system and artificial neural network techniques combined with the self-organizing map and singular value decomposition technique provide 0.065 accuracy in terms of the mean average error. In addition, when comparing singular value decomposition-self-organizing map-adaptive neuro-fuzzy inference system method with the singular value decomposition-self-organizing map-adaptive-artificial neural network method, the singular value decomposition-self-organizing map-adaptive neuro-fuzzy inference provides with 0.104 accuracy in predicting CO2 emissions. Moreover, the multiple linear regression provides the worst accuracy (0.522) results compared with the artificial neural network and adaptive neuro-fuzzy inference system techniques. The analysis regarding the relationship between economic development, carbon dioxide emissions, and the energy consumption is extremely vital from the energy and economic policy-making aspects in Group 20 countries given that the primary focus of this group has been the governance of the global economy.",
        "DOI": "10.1016/j.jclepro.2020.122942",
        "paper_author": "Mardani A.",
        "affiliation_name": "Ton-Duc-Thang University",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60078563",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Land use land cover mapping using advanced machine learning classifiers: A case study of Shiraz city, Iran",
        "publication": "Earth Science Informatics",
        "citied_by": "35",
        "cover_date": "2020-12-01",
        "Abstract": "Due to the recent climate changes and their consequences such as flash floods and droughts, there is a need for Land Use Land Cover mapping to monitor environmental changes which have effects on ecology, policy management, health, and disaster management. It should be noticed that recent droughts caused by climate change, and on the other hand, population growth has increased the rate of urbanization in Iran, where people are moving from rural areas to urban areas. In this study, two well-known machine learning classifiers, including Support Vector Machine (SVM) and Complex Tree (CTree), are used for land cover mapping. An advanced supervised algorithm, namely the Derivative-free Multi-layer Perceptron (FDMLP), which is based on the Multi-layer Perceptron (MLP) function, is developed in MATLAB programming language. The FDMLP uses a derivative-free function for the optimization of the MLP function parameters. Three different scenarios using Landsat-8 imagery with spatial resolutions of 30 and 15 m are defined to investigate the effects of data pre-processing on the final predicted Land Use Land Cover (LULC) maps. A Deep Neural Network (DNN) is used for LULC mapping as well. The FDMLP classifier has outperformed the other two well-known algorithms of the SVM and the CTree for the classification of the pixel-based Landsat-8 imagery and the object-based Landsat-8 imagery with a spatial resolution of 15 m in terms of the overall accuracy and index of kappa. Based on the test data, the DNN classifier for the object-based Landsat-8 imagery with a spatial resolution of 15 m with values of 91.28 and 88.57 percent for the OA and Kappa index has outperformed the other supervised classifiers. The worst results of classification are for the DNN algorithm for the pixel-based Landsat-8 imagery.",
        "DOI": "10.1007/s12145-020-00475-4",
        "paper_author": "Jamali A.",
        "affiliation_name": "Apadana Institute of Higher Education",
        "affiliation_city": "Shiraz",
        "affiliation_country": "Iran",
        "affiliation_id": "121901965",
        "affiliation_state": "Fars 71946-44635"
    },
    {
        "paper_title": "Deep reinforcement learning based preventive maintenance policy for serial production lines",
        "publication": "Expert Systems with Applications",
        "citied_by": "119",
        "cover_date": "2020-12-01",
        "Abstract": "In the manufacturing industry, the preventive maintenance (PM) is a common practice to reduce random machine failures by replacing/repairing the aged machines or parts. The decision on when and where the preventive maintenance needs to be carried out is nontrivial due to the complex and stochastic nature of a serial production line with intermediate buffers. In order to improve the cost efficiency of the serial production lines, a deep reinforcement learning based approach is proposed to obtain PM policy. A novel modeling method for the serial production line is adopted during the learning process. A reward function is proposed based on the system production loss evaluation. The algorithm based on the Double Deep Q-Network is applied to learn the PM policy. Using the simulation study, the learning algorithm is proved effective in delivering PM policy that leads to an increased throughput and reduced cost. Interestingly, the learned policy is found to frequently conduct “group maintenance” and “opportunistic maintenance”, although their concepts and rules are not provided during the learning process. This finding further demonstrates that the problem formulation, the proposed algorithm and the reward function setting in this paper are effective.",
        "DOI": "10.1016/j.eswa.2020.113701",
        "paper_author": "Huang J.",
        "affiliation_name": "University of Virginia School of Engineering and Applied Science",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States",
        "affiliation_id": "60152865",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Dialogue management in conversational agents through psychology of persuasion and machine learning",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "29",
        "cover_date": "2020-12-01",
        "Abstract": "To be really effective, conversational agents must integrate well with the characteristics of the humans with whom they interact. This exploratory study focuses on a method for integrating well-assessed methods from the field of social psychology in the design of task-oriented conversational agents in which the dialogue management module is developed through machine learning. In particular, the aim is to achieve agents whose policies could take into account the psychological features of the human interactants to deliver personalized and more effective messages. The paper presents the psychological study performed and outlines the overall theoretical architecture of the software framework proposed. On the psychosocial side, we first assessed the effectiveness of differently framed messages aimed to reducing red meat consumption taking the Theory of Planned Behavior (TPB) as the psychosocial model of reference. Turning to the machine learning field, the resulting Structural Equation Model (SEM) was first translated into a probabilistic predictor using Dynamic Bayesian Network (DBN). In turn, such DBN became the fundamental element of a Partially Observable Markov Decision Processes (POMDP) in a reinforcement learning setting. The possibility to elicit complete interaction policies was then studied by applying Neural Monte Carlo Tree Search (Neural MCTS) methods. The results thus obtained introduce the possibility to develop new multidisciplinary and integrated techniques for the development of automated dialogue managing systems.",
        "DOI": "10.1007/s11042-020-09178-w",
        "paper_author": "Carfora V.",
        "affiliation_name": "Università Cattolica del Sacro Cuore",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60024053",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Preventive healthcare policies in the US: solutions for disease management using Big Data Analytics",
        "publication": "Journal of Big Data",
        "citied_by": "21",
        "cover_date": "2020-12-01",
        "Abstract": "Data-driven healthcare policy discussions are gaining traction after the Covid-19 outbreak and ahead of the 2020 US presidential elections. The US has a hybrid healthcare structure; it is a system that does not provide universal coverage, albeit few years ago enacted a mandate (Affordable Care Act-ACA) that provides coverage for the majority of Americans. The US has the highest health expenditure per capita of all western and developed countries; however, most Americans don’t tap into the benefits of preventive healthcare. It is estimated that only 8% of Americans undergo routine preventive screenings. On a national level, very few states (15 out of the 50) have above-average preventive healthcare metrics. In literature, many studies focus on the cure of diseases (research areas such as drug discovery and disease prediction); whilst a minority have examined data-driven preventive measures—a matter that Americans and policy makers ought to place at the forefront of national issues. In this work, we present solutions for preventive practices and policies through Machine Learning (ML) methods. ML is morally neutral, it depends on the data that train the models; in this work, we make the case that Big Data is an imperative paradigm for healthcare. We examine disparities in clinical data for US patients by developing correlation and imputation methods for data completeness. Non-conventional patterns are identified. The data lifecycle followed is methodical and deliberate; 1000+ clinical, demographical, and laboratory variables are collected from the Centers for Disease Control and Prevention (CDC). Multiple statistical models are deployed (Pearson correlations, Cramer’s V, MICE, and ANOVA). Other unsupervised ML models are also examined (K-modes and K-prototypes for clustering). Through the results presented in the paper, pointers to preventive chronic disease tests are presented, and the models are tested and evaluated.",
        "DOI": "10.1186/s40537-020-00315-8",
        "paper_author": "Batarseh F.A.",
        "affiliation_name": "George Mason University",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States",
        "affiliation_id": "60018319",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "MitM detection and defense mechanism CBNA-RF based on machine learning for large-scale SDN context",
        "publication": "Journal of Ambient Intelligence and Humanized Computing",
        "citied_by": "45",
        "cover_date": "2020-12-01",
        "Abstract": "Software defined network (SDN) is a promising new network abstraction that aims to improve and facilitate network management. Due to its centralized architecture and the lack of intelligence on the data plane, SDN suffers from many security issues that slows down its deployment. Man in the Middle (MitM) attack is considered as one of the most devastating attacks in an SDN context. In fact, MitM attack allows the attackers to capture, duplicate and spoof flows by targeting southbound interfaces and SDN nodes. Furthermore, it’s very difficult to detect MitM attacks since it is performed passively at the SDN level. To reduce the impact of this attack, we generally set up security policies and authentication mechanisms. However, these techniques are not applicable for a large scale SDN architecture as they require complexes and static configurations and as they negatively influence on network performance. In this paper, we propose an intrusion detection and prevention framework by using machine learning techniques to detect and stop MitM attempts. To do so, we build a context-based node acceptance based on the random forest model (CBNA-RF), which helps to setting-up appropriate security policies and to automating defense operations on a large-scale SDN context. This mechanism can realize a quick and early detection of MitM attacks by automatically detecting malicious nodes without affecting performances. The evaluation of the proposed framework demonstrates that our model can correctly classify and detect malicious connections and nodes while keeping high accuracy and precision scores.",
        "DOI": "10.1007/s12652-020-02099-4",
        "paper_author": "Sebbar A.",
        "affiliation_name": "International University of Rabat",
        "affiliation_city": "Sale",
        "affiliation_country": "Morocco",
        "affiliation_id": "60111570",
        "affiliation_state": "Rabat-Sale-Kenitra"
    },
    {
        "paper_title": "Using publicly available satellite imagery and deep learning to understand economic well-being in Africa",
        "publication": "Nature Communications",
        "citied_by": "244",
        "cover_date": "2020-12-01",
        "Abstract": "Accurate and comprehensive measurements of economic well-being are fundamental inputs into both research and policy, but such measures are unavailable at a local level in many parts of the world. Here we train deep learning models to predict survey-based estimates of asset wealth across ~ 20,000 African villages from publicly-available multispectral satellite imagery. Models can explain 70% of the variation in ground-measured village wealth in countries where the model was not trained, outperforming previous benchmarks from high-resolution imagery, and comparison with independent wealth measurements from censuses suggests that errors in satellite estimates are comparable to errors in existing ground data. Satellite-based estimates can also explain up to 50% of the variation in district-aggregated changes in wealth over time, with daytime imagery particularly useful in this task. We demonstrate the utility of satellite-based estimates for research and policy, and demonstrate their scalability by creating a wealth map for Africa’s most populous country.",
        "DOI": "10.1038/s41467-020-16185-w",
        "paper_author": "Yeh C.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Multi-label classification and knowledge extraction from oncology-related content on online social networks",
        "publication": "Artificial Intelligence Review",
        "citied_by": "10",
        "cover_date": "2020-12-01",
        "Abstract": "This study aims at automatic processing and knowledge extraction from large amounts of oncology-related content from online social networks (OSN). In this context, a large number of OSN textual posts concerning major cancer types are automatically scraped and structured using natural language processing techniques. Machines are trained to assign multiple labels to these posts based on the type of knowledge enclosed, if any. Trained machines are used to automatically classify large-scale textual posts. Statistical inferences are made based on these predictions to extract general concepts and abstract knowledge. Different approaches for constructing document feature vectors showed no tangible effect on the classification accuracy. Among different classifiers, logistic regression achieved the highest overall accuracy (96.4%) and F1 ¯ (73.4) in a 13-way multi-label classification of textual posts. The most common topic was seeking or providing moral support for cancer patients, followed by providing technical information about cancer causes and treatments. The most common causes and treatments of different types of cancer on OSN are also automatically detected in this study. Seeking or providing moral support for cancer patients shared the largest overlap with other topics, i.e. moral support tends to be present even in OSN posts which focus on other topics. On the other hand, providing technical information about cancer diagnosis or prevention were the most isolated topics, where OSN posts tend not to allude to other topics. OSN posts which seek financial support only overlap with the moral support topic, if any. Our methodology and results provide public health professionals with an opportunity to monitor what topics and to which extent are being discussed on OSN, what specific information and knowledge are being disseminated over OSN, and to assess their veracity in close to real time. This helps them to develop policies that encourage, discourage, or modify the consumption of viral oncology-related information on OSN.",
        "DOI": "10.1007/s10462-020-09839-0",
        "paper_author": "Hashemi M.",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States",
        "affiliation_id": "60279735",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "EPBLA: energy-efficient consolidation of virtual machines using learning automata in cloud data centers",
        "publication": "Cluster Computing",
        "citied_by": "18",
        "cover_date": "2020-12-01",
        "Abstract": "High demand for computational power by business, science, and applications has led to the creation of large-scale data centers that consume enormous amounts of energy. This high energy consumption not only imposes a significant operating cost but also has a negative impact on the environment (greenhouse gas emissions). A promising solution to reduce the amount of energy used by data centers is the consolidation of virtual machines (VMs) that allows some hosts to enter low consuming sleep modes. Dynamic migration (replacement) of VMs between physical hosts is an effective strategy to achieve VM consolidation. Dynamic migration not only saves energy by migrating the VMs hosted by idle hosts but can also avoid hotspots by migrating VMs from over-utilized hosts. In this paper, we presented a new approach, called extended-placement by learning automata (EPBLA), based on learning automata for dynamic replacement of VMs in data centers to reduce power consumption. EPBLA consists of two parts (i) a linear reward penalty scheme which is a finite action-set learning automata that runs on each host to make a fully distributed VM placement considering CPU utilization as a metric to categorize the hosts, and (ii) a continuous action-set learning automata as a policy for selecting an underload host initiating the migration process. A real-world workload is used to evaluate the proposed method. Simulation results showed the efficiency of EPBLA in terms of reduction of energy consumption by 20% and 30% compared with PBLA and Firefly, respectively.",
        "DOI": "10.1007/s10586-020-03066-6",
        "paper_author": "Rasouli N.",
        "affiliation_name": "Islamic Azad University, Hashtgerd Branch",
        "affiliation_city": "Hashtgerd",
        "affiliation_country": "Iran",
        "affiliation_id": "60108694",
        "affiliation_state": "Alborz"
    },
    {
        "paper_title": "A reinforcement learning model for personalized driving policies identification",
        "publication": "International Journal of Transportation Science and Technology",
        "citied_by": "17",
        "cover_date": "2020-12-01",
        "Abstract": "Optimizing driving performance by addressing personalized aspects of driving behavior and without posing unrealistic restrictions on personal mobility may have far reaching implications to traffic safety, flow operations and the environment, as well as significant benefits for users. The present work addresses the problem of delivering personalized driving policies based on Reinforcement Learning for enhancing existing Intelligent Transportation Systems (ITS) to the benefit of traffic management and road safety. The proposed framework is implemented on appropriate driving behavior metrics derived from smartphone sensors’ data streams. Aggressiveness, speeding and mobile usage are considered to describe the driving profile per trip and are presented as inputs to the Q-learning algorithm. The implementation of the proposed methodological approach produces personalized quantified driving policies to be exploited for self-improvement. Finally, this paper establishes validation measures of the quality and effectiveness of the produced policies and methodological tools for comparing and classifying the examined drivers.",
        "DOI": "10.1016/j.ijtst.2020.03.002",
        "paper_author": "Vlachogiannis D.M.",
        "affiliation_name": "Department of Civil and Environmental Engineering",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60121457",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "PAP: power aware prediction based framework to reduce disk energy consumption",
        "publication": "Cluster Computing",
        "citied_by": "5",
        "cover_date": "2020-12-01",
        "Abstract": "Disk-based storage subsystems account for a significant portion of the energy consumption in both low and high end servers. Therefore, there is a dire need to reduce the server power consumption of the hard disks. In this work, the power-aware framework has been proposed, which efficiently switches the disk into standby, active and idle states, leading to the least power consumption. Firstly, the trace of a real-world application has been generated and processed. The frequently used queries from the trace have been analyzed and prefetched in SSD cache using the data placement policy which lead to 78.5% cache hits. Subsequently, the idle time threshold policy has been executed, which regularly monitors and compares the disk idle time with its threshold value. Later, the request arrival threshold policy predicts the breakeven time using the ensemble machine learning model, which yields 87% accuracy with 3.5% average error rate. Only upon exceeding the threshold values, the disk would smartly be placed in the standby mode; otherwise, it would remain in the idle state to avoid the high power spins in case of frequent requests. Finally, the experimental results have been validated with the existing benchmarks using SSD as a cache, which leads to 75% average power savings.",
        "DOI": "10.1007/s10586-020-03077-3",
        "paper_author": "Arora S.",
        "affiliation_name": "Computer Science and Engineering Department",
        "affiliation_city": "Patiala",
        "affiliation_country": "India",
        "affiliation_id": "121902285",
        "affiliation_state": "TG"
    },
    {
        "paper_title": "Land use and cover maps for Mato Grosso State in Brazil from 2001 to 2017",
        "publication": "Scientific Data",
        "citied_by": "36",
        "cover_date": "2020-12-01",
        "Abstract": "This paper presents a dataset of yearly land use and land cover classification maps for Mato Grosso State, Brazil, from 2001 to 2017. Mato Grosso is one of the world’s fast moving agricultural frontiers. To ensure multi-year compatibility, the work uses MODIS sensor analysis-ready products and an innovative method that applies machine learning techniques to classify satellite image time series. The maps provide information about crop and pasture expansion over natural vegetation, as well as spatially explicit estimates of increases in agricultural productivity and trade-offs between crop and pasture expansion. Therefore, the dataset provides new and relevant information to understand the impact of environmental policies on the expansion of tropical agriculture in Brazil. Using such results, researchers can make informed assessments of the interplay between production and protection within Amazon, Cerrado, and Pantanal biomes.",
        "DOI": "10.1038/s41597-020-0371-4",
        "paper_author": "Simoes R.",
        "affiliation_name": "Instituto Nacional de Pesquisas Espaciais",
        "affiliation_city": "Sao Jose dos Campos",
        "affiliation_country": "Brazil",
        "affiliation_id": "60012729",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "Socio-Sentic framework for sustainable agricultural governance",
        "publication": "Sustainable Computing: Informatics and Systems",
        "citied_by": "20",
        "cover_date": "2020-12-01",
        "Abstract": "Livelihood security plays a critical role in strengthening the socio- economic situation of a country. Agriculture is one such sector which is expected to provide a complete array of economic, social, and environmental services. Good governance and management of allied policies at all levels is favourable for long-term sustainability of agricultural sector. The accountability of government is a direct measure of its social responsibility and sustainability. Social media as a powerful online platform reinforces hype and provides opportunities to extract and analyze public opinion about various governmental schemes and policies including the ones related to agriculture. The e-participation platforms such as Twitter offer unparallel means to intelligently gauge the consensus and orientation of people towards an agricultural policy. Motivated by this, the work presented in this research, proffers a Socio-Sentic framework for sustainable agricultural governance which probes the sentiment polarity of user-content on Twitter pertaining to government policies, specifically agricultural policies. In this intelligent analytic framework, supervised machine learning algorithms have been implemented and compared using tweets on an Indian Agricultural Policy launched in 2016, ‘Pradhan Mantri Fasal Bima Yojana’ (PMFBY). The preliminary results indicate that the adoption of the proposed framework for soliciting and probing citizen feedback for government policy evaluation can lead to a sustainable agricultural development.",
        "DOI": "10.1016/j.suscom.2018.08.006",
        "paper_author": "Kumar A.",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60002874",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Learning Analysis of the Non-academic Employment Opportunities for Ph.D. Graduates in Australia",
        "publication": "Higher Education Policy",
        "citied_by": "26",
        "cover_date": "2020-12-01",
        "Abstract": "Can Australia’s Ph.D. graduates be better utilised in the non-academic workforce? There has been a historic structural decline in the ability of Ph.D. graduates to find work within academia for the last couple of decades (Forsyth in A history of the modern Australian University, New South Press, Sydney, 2014). Around 60% of Ph.D. graduates in Australia, now find jobs outside the academy, and the number is growing year on year (McGagh et al. in Securing Australia’s future: review of Australia’s research training system, https://acola.org.au/wp/PDF/SAF13/SAF13%20RTS%20report.pdf, 2016). The Ph.D. is a degree designed in the early twentieth century to credential the academic workforce. How to make it fit contemporary needs, when many, if not most, graduates do not work in academia, is a question that must be addressed by higher education managers and policymakers. Progress has been slow, partly because of the lack of reliable data-driven evidence to inform this work. This paper puts forward a novel hybrid quantitative/qualitative approach to the problem of analysing Ph.D. employability. We report on a project using machine learning (ML) and natural language processing to perform a ‘big data’ analysis on the text content of non-academic job advertisements. This paper discusses the use of ML in this context and its future utility for researchers. Using these methods, we performed an analysis of the extent of demand for Ph.D. student skills and capabilities in the Australian employment market. We show how these new methods allow us to handle large, complex datasets, which are often left unexplored because of human labour costs. This analysis could be reproduced outside of the Australian context, given an equivalent dataset. We give an outline of our approach and discuss some of the advantages and limitations. This paper will be of interest for those involved in reshaping Ph.D. programs and anyone interested in exploring new ML methods to inform education policy work.",
        "DOI": "10.1057/s41307-018-0098-4",
        "paper_author": "Mewburn I.",
        "affiliation_name": "The Australian National University",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia",
        "affiliation_id": "60008950",
        "affiliation_state": "ACT"
    },
    {
        "paper_title": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
        "publication": "Journal of Power Sources",
        "citied_by": "13",
        "cover_date": "2020-11-30",
        "Abstract": "This paper proposes a novel control framework and the corresponding strategy for power sources management in connected plug-in hybrid electric vehicles (cPHEVs). A mobile edge computation (MEC) based control framework is developed first, evolving the conventional on-board vehicle control unit (VCU) into the hierarchically asynchronous controller that is partly located in cloud. Elaborately contrastive analysis on the performance of processing capacity, communication frequency and communication delay manifests dramatic potential of the proposed framework in sustaining development of the cooperative control strategy for cPHEVs. On the basis of MEC based control framework, a specific cooperative strategy is constructed. The novel strategy accomplishes energy flow management between different power sources with incorporation of the active energy consumption plan and adaptive energy consumption management. The method to generate the reference battery state-of-charge (SOC) trajectories in energy consumption plan stage is emphatically investigated, fast outputting reference trajectories that are tightly close to results by global optimization methods. The estimation of distribution algorithm (EDA) is employed to output reference control policies under the specific terminal conditions assigned via the machine learning based method. Finally, simulation results highlight that the novel strategy attains superior performance in real-time application that is close to the offline global optimization solutions.",
        "DOI": "10.1016/j.jpowsour.2020.228650",
        "paper_author": "Zhang Y.",
        "affiliation_name": "Jilin University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60007711",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Deep reinforcement learning for optimization",
        "publication": "Research Anthology on Artificial Intelligence Applications in Security",
        "citied_by": "0",
        "cover_date": "2020-11-27",
        "Abstract": "Deep reinforcement learning (DRL) has transformed the field of artificial intelligence (AI) especially after the success of Google DeepMind. This branch of machine learning epitomizes a step toward building autonomous systems by understanding of the visual world. Deep reinforcement learning (RL) is currently applied to different sorts of problems that were previously obstinate. In this chapter, at first, the authors started with an introduction of the general field of RL and Markov decision process (MDP). Then, they clarified the common DRL framework and the necessary components RL settings. Moreover, they analyzed the stochastic gradient descent (SGD)-based optimizers such as ADAM and a non-specific multi-policy selection mechanism in a multi-objective Markov decision process. In this chapter, the authors also included the comparison for different Deep Q networks. In conclusion, they describe several challenges and trends in research within the deep reinforcement learning field. Copyright",
        "DOI": "10.4018/978-1-7998-7705-9.ch070",
        "paper_author": "Hasan M.M.",
        "affiliation_name": "Anglia Ruskin University",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60000913",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Exploring the impact of security policy on compliance",
        "publication": "Research Anthology on Artificial Intelligence Applications in Security",
        "citied_by": "0",
        "cover_date": "2020-11-27",
        "Abstract": "The objective of this chapter is to discuss the integration of advancements made in the field of artificial intelligence into the existing business intelligence tools. Specifically, it discusses how the business intelligence tool can integrate time series analysis, supervised and unsupervised machine learning techniques and natural language processing in it and unlock deeper insights, make predictions, and execute strategic business action from within the tool itself. This chapter also provides a high-level overview of current state of the art AI techniques and provides examples in the realm of business intelligence. The eventual goal of this chapter is to leave readers thinking about what the future of business intelligence would look like and how enterprise can benefit by integrating AI in it.",
        "DOI": "10.4018/978-1-7998-7705-9.ch017",
        "paper_author": "Yaokumah W.",
        "affiliation_name": "Pentecost University College",
        "affiliation_city": "Accra",
        "affiliation_country": "Ghana",
        "affiliation_id": "60121900",
        "affiliation_state": "Greater Accra"
    },
    {
        "paper_title": "ICBDR 2020 - Proceedings of the 4th International Conference on Big Data Research",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-11-27",
        "Abstract": "The proceedings contain 19 papers. The topics discussed include: analysis of measure fluctuation based on adtributor algorithm; research on data security protection method based on improved K-means clustering algorithm; data association rules mining method based on improved apriori algorithm; ESTemd: a distributed processing framework for environmental monitoring based on apache Kafka streaming engine; use of digital tools to promote understanding of the learning process in the tower of Hanoi game; short-term traffic flow prediction based on multi-auxiliary information; stock selection strategy based on support vector machine and extreme gradient boosting methods; prediction method of user's consumption behavior in e-commerce platform based on RNN optimization algorithm; research on EDP migration policy based on BP neural network and cellular automata model; and acquisition function selection: Bayesian optimization in neural network technique.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Bayesian decomposition of multi-modal dynamical systems for reinforcement learning",
        "publication": "Neurocomputing",
        "citied_by": "4",
        "cover_date": "2020-11-27",
        "Abstract": "In this paper, we present a model-based reinforcement learning system where the transition model is treated in a Bayesian manner. The approach naturally lends itself to exploit expert knowledge by introducing priors to impose structure on the underlying learning task. The additional information introduced to the system means that we can learn from small amounts of data, recover an interpretable model and, importantly, provide predictions with an associated uncertainty. To show the benefits of the approach, we use a challenging data set where the dynamics of the underlying system exhibit both operational phase shifts and heteroscedastic noise. Comparing our model to NFQ and BNN+LV, we show how our approach yields human-interpretable insight about the underlying dynamics while also increasing data-efficiency.",
        "DOI": "10.1016/j.neucom.2019.12.132",
        "paper_author": "Kaiser M.",
        "affiliation_name": "Siemens AG",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60028673",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Proceedings of the 4th International Conference on Future Networks and Distributed Systems, ICFNDS 2020",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-11-26",
        "Abstract": "The proceedings contain 52 papers. The topics discussed include: a homomorphic digit fragmentation encryption scheme based on the polynomial reconstruction problem; a salient object detection technique based on color divergence; edge computing resource allocation orchestration system for autonomous vehicles; enhancing communication efficiency in mobile networks using smartphone-enabled edge computing; machine learning approach to secure software defined network: machine learning and artificial intelligence; a novel access control security model based on ciphertext policy attribute-based encryption for smart homes; unmanned aerial vehicles routing formation using fisheye state routing for flying ad-hoc networks; polygons characterizing the joint statistical properties of the input and output sequences of the binary shift register; improve the firewall accuracy by using dynamic ontology; investigation of operating system security mechanisms for vulnerabilities; and mathematical modelling of the operation of a multistage flood control system using parallel computations.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "13th CMI Conference on Cybersecurity and Privacy - Digital Transformation - Potentials and Challenges, CMI 2020",
        "publication": "13th CMI Conference on Cybersecurity and Privacy - Digital Transformation - Potentials and Challenges, CMI 2020",
        "citied_by": "0",
        "cover_date": "2020-11-26",
        "Abstract": "The proceedings contain 18 papers. The topics discussed include: AI or human: the socio-ethical implications of AI-generated media content; media technologies and policies; affordances and IT design: a typology for social media and platform affordances; machine learning-based cocoa e-health system; critical infrastructure - what is it, and what are the implications?; the impact of game censorship and regulations on foreign game consoles in china; a survey and comparison of secure software development standards; the proposed Baltic Sea region cross-border business registration service; situated learning in teaching business English in the age of digital transformations; surveillance capitalism - a new techno-economic paradigm?; privacy in time of a pandemic; and the next-generation television broadcasting test platform in Copenhagen.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Learning approach for routing in satellite Mega-Constellations",
        "publication": "2020 International Symposium on Advanced Electrical and Communication Technologies, ISAECT 2020",
        "citied_by": "11",
        "cover_date": "2020-11-25",
        "Abstract": "Current packet-switched networks, and Internet in particular, are experiencing explosive growth in traffic, mainly due to the rapid development of new communication technologies and the associated applications. Existing network routing policies might not be sophisticated enough to cope with the ever-changing network conditions resulting from huge traffic growth, opening to possible inefficiencies. Deep learning, as a recent turning point in the area of Machine Learning, has received significant research attention in numerous areas of Artificial Intelligence, such as Computer Vision, Natural Language Processing, Autonomous Driving, Robotics Process Automation and so forth. Machine learning applications in network-related areas is relatively recent but it appears to represent an innovative approach to conFigure and manage networks in a more intelligent, efficient and autonomous way. On the other hand, we are witnessing as well the huge investments on satellite-based networks for global broadband Internet access, called mega-constellations, leveraging thousands of satellites in LEO orbit and expected to process Tbit/s. The aim of this paper is to describe the adoption of an innovative Machine Learning-driven and Data-driven approach applied to the routing of packets in such future generation of satellite mega constellations, enhancing services and applications QoS. In this work, we demonstrated the effectiveness of a Deep Learning based routing approach in comparison with the commonly used network routing approach of the Shortest Path, in a preliminary performance evaluation with few satellite nodes. The proposed approach can be applied to mega constellation satellite networks such as Starlink by SpaceX and conceptually applicable also to other (also terrestrial-only) networks.",
        "DOI": "10.1109/ISAECT50560.2020.9523672",
        "paper_author": "Cigliano A.",
        "affiliation_name": "Universita degli Studi Guglielmo Marconi",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60105927",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Understanding Online Public Sentiments: A Machine Learning-Based Analysis of English and Chinese Twitter Discourse during the 2019 Chinese National Day",
        "publication": "2020 2nd International Multidisciplinary Information Technology and Engineering Conference, IMITEC 2020",
        "citied_by": "1",
        "cover_date": "2020-11-25",
        "Abstract": "As the Internet gradually penetrates people's daily lives, individual citizens are empowered to demonstrate and exchange opinions and sentiments at any time anywhere. Online communities are increasingly participating in the agenda-setting of public affairs and official policies. However, how to depict online public opinion and to what degree does it influence the real world are still unclear. This study addresses the above problems by analyzing Twitter discourse during the 2019 Chinese National Day with a machine learning-based approach. Over 300,000 English and Chinese tweets were collected between Sept 30 and Oct 3, and a hybrid method of support vector machine (SVM) and dictionary was applied to evaluate the sentiments of the collected tweets. This method avoids complex structures while yielding an average accuracy of over 96% in most classifiers used in the study. The results indicate alignment between the time of National Day celebration activities and the peak of sentiments revealed in both English and Chinese tweets, although the sentiments of the two languages tend to be in opposite directions. The sentiments of tweets also diverge from nation to nation, but are generally consistent with the country's official relations with China. The linguistic features of the tweets suggest different concerns for Twitter users who have different sentiments towards China. Future studies should prolong the collecting period and refine the algorithms used. Specific attention can also be paid to important countries pairs like China and the United States.",
        "DOI": "10.1109/IMITEC50163.2020.9334093",
        "paper_author": "Xu Y.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Exploration of Machine Learning Models to Forecast the Unemployment Rate of South Africa: A Univariate Approach",
        "publication": "2020 2nd International Multidisciplinary Information Technology and Engineering Conference, IMITEC 2020",
        "citied_by": "6",
        "cover_date": "2020-11-25",
        "Abstract": "The South African unemployment rate is 29.1%, this is the highest unemployment rate that the country has recorded since the 1970s. The country is in the top ten countries with the highest unemployment rates in the world. COVID-19 threatens to increase the unemployment rate above the 50% mark. A public policy intervention is the most suitable instrument for the country in order to address this problem, however, policy is reliant on accurate and reliable forecasting. This paper explores univariate machine learning techniques to forecast the South African unemployment rate. Six traditional statistical models are compared with seven machine learning models. The multi-layer perceptron achieves the lowest error rate, whilst the ridge regression model achieved the highest R - squared. These are closely followed by ARIMA, LASSO, and the elastic net, showing that machine learning models can forecast the South African unemployment rate with higher accuracy than traditional statistical methods.",
        "DOI": "10.1109/IMITEC50163.2020.9334090",
        "paper_author": "Mulaudzi R.",
        "affiliation_name": "University of the Witwatersrand, Johannesburg",
        "affiliation_city": "Johannesburg",
        "affiliation_country": "South Africa",
        "affiliation_id": "60016218",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "High-resolution land value maps reveal underestimation of conservation costs in the United States",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "62",
        "cover_date": "2020-11-24",
        "Abstract": "The justification and targeting of conservation policy rests on reliable measures of public and private benefits from competing land uses. Advances in Earth system observation and modeling permit the mapping of public ecosystem services at unprecedented scales and resolutions, prompting new proposals for land protection policies and priorities. Data on private benefits from land use are not available at similar scales and resolutions, resulting in a data mismatch with unknown consequences. Here I show that private benefits from land can be quantified at large scales and high resolutions, and that doing so can have important implications for conservation policy models. I developed high-resolution estimates of fair market value of private lands in the contiguous United States by training tree-based ensemble models on 6 million land sales. The resulting estimates predict conservation cost with up to 8.5 times greater accuracy than earlier proxies. Studies using coarser cost proxies underestimate conservation costs, especially at the expensive tail of the distribution. This has led to underestimations of policy budgets by factors of up to 37.5 in recent work. More accurate cost accounting will help policy makers acknowledge the full magnitude of contemporary conservation challenges and can help improve the targeting of public ecosystem service investments.",
        "DOI": "10.1073/pnas.2012865117",
        "paper_author": "Nolte C.",
        "affiliation_name": "Boston University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60019674",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Developing a mobile application for smart real estate information",
        "publication": "International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",
        "citied_by": "4",
        "cover_date": "2020-11-23",
        "Abstract": "Successful land information management is an important issue for governments in regards to sustainable development. Reliable and comprehensive data about land and all related factors are essential for effective land policies. Various land related legal applications such as planning, taxation, property management, mortgage, and real estate investments require interoperable, extensive and realistic information about the land and real property. GIS provides greater insight into land by its capability to advance geographic analysis in different aspects. The statistical analysis capabilities of GIS increase the efficiency and accuracy of the evaluations related to land and real estate. Along with the developments of information and communication technologies, modern GIS technologies can handle large and complex data. Web-based and mobile GIS technologies provide the capability of operating and sharing local data and provide geographic analysis tools to users via the web. In this way, various mobile GIS applications can be developed in many different application areas. In this study, a mobile application titled as Smart Real Estate was developed for presenting urban real estate characteristics in different thematic groups by analysing data in different formats coming from different sources.",
        "DOI": "10.5194/isprs-archives-XLIV-4-W3-2020-89-2020",
        "paper_author": "Aydinoglu A.C.",
        "affiliation_name": "Gebze Teknik Üniversitesi",
        "affiliation_city": "Gebze",
        "affiliation_country": "Turkey",
        "affiliation_id": "60013071",
        "affiliation_state": "Kocaeli"
    },
    {
        "paper_title": "An integrated system for predicting students' academic performance in smart universities",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "4",
        "cover_date": "2020-11-20",
        "Abstract": "Due to the current situation with Coronavirus (COVID-19) the attendance of students in the academic life has changed and the educational process has been driven towards smart educational environments. Higher educational Institutes invest significant resources in reforming their educational programs so that it will support distance learning using asynchronous or synchronous methodologies and tools. In this work, we propose the development of a student profile using data from both asynchronous and synchronous e-learning platforms, using a multi-layered neural network in order to classify students' performance. A neural network is compared against Support Vector Machines, k-Nearest Neighbour and decision trees. The results indicate that the Neural network achieves better accuracy than the others, so using our methodology the instructors or the policy makers of the institute will be able to keep informed about the performance of the students, or take the appropriate actions in order to prevent student failure or low participation.",
        "DOI": "10.1145/3437120.3437353",
        "paper_author": "Chytas K.",
        "affiliation_name": "University of West Attica",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece",
        "affiliation_id": "60110806",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "A Deep Reinforcement Learning Approach to the Flexible Flowshop Scheduling Problem with Makespan Minimization",
        "publication": "Proceedings of 2020 IEEE 9th Data Driven Control and Learning Systems Conference, DDCLS 2020",
        "citied_by": "14",
        "cover_date": "2020-11-20",
        "Abstract": "Recent work has demonstrated the efficiency of deep reinforcement learning (DRL) in making optimization decisions in complex systems. Compared with other DRL algorithms, the proximal policy optimization (PPO) has higher stability and lower complexity. The typical flexible flowshop scheduling problem (FFSP) with identical parallel machines is an NP-hard problem. This paper is the first case to utilize PPO to solve the problem with makespan minimization. The particular state, action and reward function are designed for the FFSP to follow the Markov property. The efficiency of PPO is evaluated on the wafer pickling instance and random instances with different scales. The results show that PPO can always provide satisfactory solutions within a reasonable computational time.",
        "DOI": "10.1109/DDCLS49620.2020.9275080",
        "paper_author": "Zhu J.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting dementia diagnosis from cognitive footprints in electronic health records: A case-control study protocol",
        "publication": "BMJ Open",
        "citied_by": "7",
        "cover_date": "2020-11-19",
        "Abstract": "Introduction Dementia is a group of disabling disorders that can be devastating for persons living with it and for their families. Data-informed decision-making strategies to identify individuals at high risk of dementia are essential to facilitate large-scale prevention and early intervention. This population-based case-control study aims to develop and validate a clinical algorithm for predicting dementia diagnosis, based on the cognitive footprint in personal and medical history. Methods and analysis We will use territory-wide electronic health records from the Clinical Data Analysis and Reporting System (CDARS) in Hong Kong between 1 January 2001 and 31 December 2018. All individuals who were at least 65 years old by the end of 2018 will be identified from CDARS. A random sample of control individuals who did not receive any diagnosis of dementia will be matched with those who did receive such a diagnosis by age, gender and index date with 1:1 ratio. Exposure to potential protective/risk factors will be included in both conventional logistic regression and machine-learning models. Established risk factors of interest will include diabetes mellitus, midlife hypertension, midlife obesity, depression, head injuries and low education. Exploratory risk factors will include vascular disease, infectious disease and medication. The prediction accuracy of several state-of-the-art machine-learning algorithms will be compared. Ethics and dissemination This study was approved by Institutional Review Board of The University of Hong Kong/Hospital Authority Hong Kong West Cluster (UW 18-225). Patients' records are anonymised to protect privacy. Study results will be disseminated through peer-reviewed publications. Codes of the resulted dementia risk prediction algorithm will be made publicly available at the website of the Tools to Inform Policy: Chinese Communities' Action in Response to Dementia project (http://www.tip-card.hku.hk/).",
        "DOI": "10.1136/bmjopen-2020-043487",
        "paper_author": "Luo H.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Classifying and Understanding Tor Traffic Using Tree-Based Models",
        "publication": "Proceedings - 2020 IEEE Latin-American Conference on Communications, LATINCOM 2020",
        "citied_by": "3",
        "cover_date": "2020-11-18",
        "Abstract": "Over the past years the use of anonymization services has gained significant relevance as more users are interested in protecting their data and privacy on the internet. One of the most popular ways to achieve this result is Tor. The anonymity and untraceability that Tor provides, however, can also be used by ill-intentioned users who try to take advantage of bypassing security control and policies. The Cybersecurity and Infrastructure Security Agency (CISA) mentions two methods of recognizing Tor traffic in the enterprise: indicator- or behavior-based analysis. The first one uses log analysis and lists of Tor exit nodes to identify the suspicious activity while the latter inspects patterns in TCP and UDP ports, DNS queries and inspecting the payload of the packets. In this paper, we propose a different approach using white-box machine learning models such as decision trees and Random Forest. On the one hand, our classifier achieves accuracy levels above 95%. On the other hand, our approach is the first one to allow understanding the importance of each traffic feature in the classification. Our results demonstrate that the TCP window size, the frame size and time related traffic features can be used to identify Tor traffic. In this paper we will describe a Machine Learning methodology used to identify Tor network traffic utilizing decision trees C5.0 and Random Forest. We followed a white-box approach and accomplished accuracy of over 95% in the prediction in both models. We also present an analysis of the importance of the top predictor variables.",
        "DOI": "10.1109/LATINCOM50620.2020.9282317",
        "paper_author": "Calvo P.",
        "affiliation_name": "Universidad de Costa Rica",
        "affiliation_city": "San Jose",
        "affiliation_country": "Costa Rica",
        "affiliation_id": "60071929",
        "affiliation_state": "San Jose"
    },
    {
        "paper_title": "Track-assignment detailed routing using attention-based policy model with supervision",
        "publication": "MLCAD 2020 - Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD",
        "citied_by": "10",
        "cover_date": "2020-11-16",
        "Abstract": "Detailed routing is one of the most critical steps in analog circuit design. Complete routing has become increasingly more challenging in advanced node analog circuits, making advances in efficient automatic routers ever more necessary. In this work, we propose a machine learning driven method for solving the track-assignment detailed routing problem for advanced node analog circuits. Our approach adopts an attention-based reinforcement learning (RL) policy model. Our main insight and advancement over this RL model is the use of supervision as a way to leverage solutions generated by a conventional genetic algorithm (GA). For this, our approach minimizes the Kullback-Leibler divergence loss between the output from the RL policy model and a solution distribution obtained from the genetic solver. The key advantage of this approach is that the router can learn a policy in an offline setting with supervision, while improving the run-time performance nearly 100× over the genetic solver. Moreover, the quality of the solutions our approach produces matches well with those generated by GA. We show that especially for complex problems, our supervised RL method provides good quality solution similar to conventional attention-based RL without comprising run time performance. The ability to learn from example designs and train the router to get similar solutions with orders of magnitude run-time improvement can impact the design flow dramatically, potentially enabling increased design exploration and routability-driven placement.",
        "DOI": "10.1145/3380446.3430629",
        "paper_author": "Liao H.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60027950",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Adversarial attacks on malware detection models for smartphones using reinforcement learning: PhD forum abstract",
        "publication": "SenSys 2020 - Proceedings of the 2020 18th ACM Conference on Embedded Networked Sensor Systems",
        "citied_by": "2",
        "cover_date": "2020-11-16",
        "Abstract": "Malware analysis and detection is a rat race between malware designer and anti-malware community. Most of the current Smartphone antivirus(s) are based on the signature, heuristic and behaviour based mechanisms which are unable to detect advanced polymorphic and metamorphic malware. Recently, researchers have developed state-of-the-art Android malware detection systems based on machine learning and deep learning. However, these models are prone to adversarial attacks which threaten the anti-malware ecosystem. Therefore in this work, we are investigating the robustness of Android malware detection models against adversarial attacks. We crafted adversarial attacks using reinforcement learning against detection models built using a variety of machine learning (classical, bagging, boosting) and deep learning algorithms. We are designing two adversarial attack strategies, namely single-policy and multi-policy attack for white-box and grey-box scenarios which are based on adversary's knowledge about the system. We designed the attack using Q-learning where a malicious application(s) is modified to generate variants which will force the detection models to misclassify them. The goal of the attack policy is to convert maximum Android applications (such that they are misclassified) with minimum modifications while maintaining the functional and behavioural integrity of applications. Preliminary results show an average fooling rate of around 40% across twelve distinct detection models based on different classification algorithms. We are also designing defence against these adversarial attack using model retraining and distillation.",
        "DOI": "10.1145/3384419.3430576",
        "paper_author": "Rathore H.",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India",
        "affiliation_id": "60000414",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Reinforcement learning-based adaptive PID controller for DPS",
        "publication": "Ocean Engineering",
        "citied_by": "53",
        "cover_date": "2020-11-15",
        "Abstract": "A conventional PID controller for the DPS has limitations due to fixed gains and dependence on manual adjustment for its gains. Therefore, several previous studies developed a fuzzy-based adaptive PID controller for the DPS which tunes the gains based on the fuzzy logic. However, the fuzzy logic has its disadvantages due to a manual definition of fuzzy rules and fuzzy variables. To overcome those limitations, a deep reinforcement learning algorithm is adopted to learn the efficient adaptive gain-tuning strategy without human intuition behind since it does not require any prior knowledge about the dynamics of a ship or DPS. Finally, it is shown that the proposed system can result in better station-keeping performance without deterioration in its control efficiency.",
        "DOI": "10.1016/j.oceaneng.2020.108053",
        "paper_author": "Lee D.",
        "affiliation_name": "Korea Maritime and Ocean University",
        "affiliation_city": "Busan",
        "affiliation_country": "South Korea",
        "affiliation_id": "60013361",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Attribution of climate and human activities to vegetation change in China using machine learning techniques",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "123",
        "cover_date": "2020-11-15",
        "Abstract": "A series of policies and laws have been implemented to address climate change impacts in China since the 1980s. One of the most notable policies is ecological restoration engineering. However, there are many environmental factors that affect vegetation in the ecological restoration engineering zones. The relationships among different factors cannot be explained well by traditional statistical methods due to the existence of hidden non-linear features. Moreover, it is difficult to adopt threshold methods to accurately define vegetation areas fully, or to quantitatively analyze and assess the effects of climate factors and human activities on vegetation changes. The objective of this study was to determine vegetation area and distribution using Landsat TM/ETM/OLI images combined with a support vector machine (SVM) classification model. We analyzed the dynamic characteristics of vegetation area and greenness (NDVI, Normalized Difference Vegetation Index) in China's ecological restoration engineering zones from 1990 to 2015. Based on random forest regression (RFR) with a residual analysis method, the contributions of meteorological factors and human activities to vegetation greenness changes were quantitatively evaluated. Vegetation area and NDVI changed significantly in the study areas, increasing by more than 50% and 40%, respectively, from 1990 to 2015. Temperature, sunshine hours, and precipitation impacted vegetation greenness, which caused NDVI fluctuations in specific years. However, the NDVI increase was difficult to explain fully with meteorological factors. Using cross-validation, we predicted about 80% of the observed NDVI variation occurring from 1984 to 1994. Nine meteorological factors were related to vegetation growth, of which the average temperature, minimum temperature, maximum temperature, and average relative humidity were most critical. The combined effect of the nine climatic factors contributed less to NDVI increase than human activities. Human activity was the most important factor associated with NDVI increase, with contributions of more than 100% in most study areas. Human activities derived from national or local policies had large impacts on vegetation changes. The methods and results of this study can help to understand vegetation changes observed in ecological zones and provide guidance for evaluating ecological restoration policies.",
        "DOI": "10.1016/j.agrformet.2020.108146",
        "paper_author": "Shi Y.",
        "affiliation_name": "Northwest A&amp;F University",
        "affiliation_city": "Yangling",
        "affiliation_country": "China",
        "affiliation_id": "60031041",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Towards Certifiable Adversarial Sample Detection",
        "publication": "AISec 2020 - Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security",
        "citied_by": "6",
        "cover_date": "2020-11-13",
        "Abstract": "Convolutional Neural Networks (CNNs) are deployed in more and more classification systems, but adversarial samples can be maliciously crafted to trick them, and are becoming a real threat. There have been various proposals to improve CNNs' adversarial robustness but these all suffer performance penalties or have other limitations. In this paper, we offer a new approach in the form of a certifiable adversarial detection scheme, the Certifiable Taboo Trap (CTT). This system, in theory, can provide certifiable guarantees of detectability of a range of adversarial inputs for certain l-8 sizes. We develop and evaluate several versions of CTT with different defense capabilities, training overheads and certifiability on adversarial samples. In practice, against adversaries with various l-p norms, CTT outperforms existing defense methods that focus purely on improving network robustness. We show that CTT has small false positive rates on clean test data, minimal compute overheads when deployed, and can support complex security policies.",
        "DOI": "10.1145/3411508.3421381",
        "paper_author": "Shumailov I.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "A survey on application of machine learning to manage the virtual machines in cloud computing",
        "publication": "International Review of Applied Sciences and Engineering",
        "citied_by": "4",
        "cover_date": "2020-11-12",
        "Abstract": "Virtual machine (VM) management is a fundamental challenge in the cloud datacenter, as it requires not only scheduling and placement, but also optimization of the method to maintain the energy cost and service quality. This paper reviews the different areas of literature that deal with the resource utilization prediction, VM migration, VM placement and the selection of physical machines (PMs) for hosting the VMs. The main features of VM management policies were also examined using a comparative analysis of the current policies. Many research works include Machine Learning (ML) for detecting the PM overloading, the selection of VMs from over-utilized PM and VM placement as the main activities. This article aims to identify and classify research done in the area of scheduling and placement of VMs using the ML with resource utilization history. Energy efficiency, VM migration counts and Service quality were the key performance parameters that were used to assess the performance of the cloud datacenter.",
        "DOI": "10.1556/1848.2020.00065",
        "paper_author": "Barthwal V.",
        "affiliation_name": "H.N.B.Garhwal University",
        "affiliation_city": "Srinagar",
        "affiliation_country": "India",
        "affiliation_id": "60069550",
        "affiliation_state": "UK"
    },
    {
        "paper_title": "Sustainability assessment of phosphorus in the waste management system of Bangladesh using substance flow analysis",
        "publication": "Journal of Cleaner Production",
        "citied_by": "16",
        "cover_date": "2020-11-10",
        "Abstract": "Quantification of multi-year phosphorus flow through the waste sector of developing countries is essential for formulating effective policies towards sustainable global management of the phosphorus resource to ensure food and water security. However, such quantification is often difficult in developing countries due to data limitation. This study, first of its kind, develops a novel approach of training several machine learning regression models to fill the data gap for analyzing multi-year (2000–2018) phosphorus flow in both the urban and rural waste management systems of Bangladesh (a typical developing country in South Asia) using the substance flow analysis. The analysis indicates that average annual total phosphorus inflow in its waste sector was 103.3 kt over the study period, of which almost 70% remained there as an increase in stock. The country lost 31.6 kt (30.59% of total inflow) of phosphorus annually as waste discharge to its numerous rivers and water bodies, which may account for scattered instances of algal blooms and eutrophication throughout the country. On average only 0.12 kt phosphorus was recovered annually from the solid waste stream and reused as compost and livestock feed. There were significant annual losses from both the urban and rural wastewater subsystems, on average at 13.67 kt and 12.15 kt respectively. A high annual inflow of 60.1 kt was observed for the rural wastewater subsystem, which retained most of it as an increase in stock of 47.95 kt. On the other hand, inflow into the urban wastewater system was 25.57 kt of which 53% was lost as outflow to rivers. In a global comparison of phosphorus substitutability indices (calculated based on recycling efficiency), Bangladesh displays the lowest (0.12%) score among several developed and developing countries despite of having a handsome inflow to waste sector. The methods developed for quantifying multi-year phosphorus flow in a data deficient condition and specific policy recommendations provided in this study could be utilized for sustainable management of phosphorus in similar developing countries.",
        "DOI": "10.1016/j.jclepro.2020.122865",
        "paper_author": "Baroi A.R.",
        "affiliation_name": "North South University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60028220",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of FinTech, Machine learning and Artificial Intelligence in programmed decision making and the perceived benefits",
        "publication": "2020 International Conference on Decision Aid Sciences and Application, DASA 2020",
        "citied_by": "4",
        "cover_date": "2020-11-08",
        "Abstract": "The objective of this study is to examine the perceived benefits of the application of FinTech, Machine Learning and Artificial Intelligence (AI) or (FMAI) in programmed decision making for the consumers, producers or employers. The study is based on a theoretical model, developed step by step to explain consumers' satisfaction and employers' benefits when the company or the employer introduces FinTech, Machine learning and AI for implementing the policies in programmed decisions. The results and findings show that the application of FinTech, Machine learning and AI will maximize the consumers' satisfaction and employers' benefits. The application of FMAI saves time for the consumers, minimizes the number of trips to the offices, and reduces the confrontations with the unpleasant customer service representatives. FMAI are user friendly, and it has the potential to increase consumers' satisfaction as well as employers' benefits by nicely settling the issues with the consumers and other stakeholders. The consumers remain the focal point and will make sure that consumers will not desert the company. This is perhaps one of the latest studies which blends FMAI with programmed decision-making process and shows perceived benefits for both consumers and producers and thus society's total wellbeing will be the maximum.",
        "DOI": "10.1109/DASA51403.2020.9317266",
        "paper_author": "Selim M.",
        "affiliation_name": "University of Bahrain",
        "affiliation_city": "Zallaq",
        "affiliation_country": "Bahrain",
        "affiliation_id": "60000237",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine Learning for Strategic Decision Making during COVID-19 at Higher Education Institutes",
        "publication": "2020 International Conference on Decision Aid Sciences and Application, DASA 2020",
        "citied_by": "5",
        "cover_date": "2020-11-08",
        "Abstract": "Machine learning is becoming driving force for strategic decision making in higher educational institutions and it calls for cooperation between stakeholders and the use of efficient computation methods. Contrariwise, making decisions might consume much time, if there is no use of data and computational methods during the process of decision making. The utilization of machine learning is essential when coming up with an ultimate analysis of data and decision making. Besides, the technology which is under artificial intelligence could facilitates incredible output for educational institutes when it came to decision making. This paper analyses the output generated using machine learning algorithms that help in prediction of no detriment policy applicability rate in the case of e-learning during COVID-19. The study investigates the performance of machine learning algorithms for strategic decision making in the higher educational institutes, Global College of Engineering and Technology in particular, whether no detriment policy will be applicable for a particular student based on students performance before COVID-19. The study shown that Random Forest machine learning algorithm performance is higher as compare to Support Vector Machine, Decision Tree and Navie Bayes.",
        "DOI": "10.1109/DASA51403.2020.9317042",
        "paper_author": "Ahmed A.S.A.M.S.",
        "affiliation_name": "Global College of Engineering and Technology",
        "affiliation_city": "Muscat",
        "affiliation_country": "Oman",
        "affiliation_id": "120934093",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Autonomous Surface Vehicle Control Method Using Deep Reinforcement Learning",
        "publication": "Proceedings - 2020 Chinese Automation Congress, CAC 2020",
        "citied_by": "0",
        "cover_date": "2020-11-06",
        "Abstract": "Autonomous Surface Vehicle (ASV) provides a new platform for marine exploration and environmental monitoring. It is very important for ASV to have learning ability in the unknown environment. Reinforcement learning is a branch of machine learning. ASV can obtain control behaviors and improve adaptability and autonomy through environmental exploration. This paper carries out dynamic modeling on the four-thruster ASV, especially designs a controller using the DDPG (deep deterministic policy gradient) algorithm. Simulation results show that the DDPG controller can control MIMO (multiple-input multiple-output) nonlinear systems. After training, the ASV can perform fixed-point control, sinusoidal trajectory tracking, and the reconfigurable experiments of multiple ASVs in the absence of water flow or water flow interference. The algorithm proposed in this paper has strong robustness and lays a foundation for the research of cooperative control of multiple ASVs.",
        "DOI": "10.1109/CAC51589.2020.9327026",
        "paper_author": "Zhang S.",
        "affiliation_name": "Ocean University of China",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China",
        "affiliation_id": "60022422",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Knowledge Induced Deep Q-Network for Robot Push and Grasp Manipulation Skills Learning",
        "publication": "Proceedings - 2020 Chinese Automation Congress, CAC 2020",
        "citied_by": "2",
        "cover_date": "2020-11-06",
        "Abstract": "In the process of robotic push and grasp manipulation skills learning, the prior knowledge of object shape and environmental constraints can be employed to make corresponding manipulation policies. In this paper, a DQN decision model is proposed for learning multi-step push and grasp manipulation of different types of objects. The key of the proposed method is that the prior knowledge of object shape and environmental constraints is introduced into the reward system by a SVM classification model. Therefore, the reward system will continuously motivate the robot to approach to the target manipulation during training process. Simulated and actual verification of the trained model is carried out. The experimental results show that the trained model has a high success rate in grasping cube objects, and it can also successfully complete the task of pushing cylindrical objects to the constraint boundary.",
        "DOI": "10.1109/CAC51589.2020.9326745",
        "paper_author": "Gui B.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60005244",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Parallel Machine Workshop Scheduling Using the Integration of Proximal Policy Optimization Training and Monte Carlo Tree Search",
        "publication": "Proceedings - 2020 Chinese Automation Congress, CAC 2020",
        "citied_by": "5",
        "cover_date": "2020-11-06",
        "Abstract": "In this paper, a model called AlphaSchedule based on the ''search + training\" framework is proposed to solve the scheduling problem of minimizing weighted tardiness in parallel machine workshop. A Markov Decision Process (MDP) model was established based on the parallel machine problem, and we designed the state features of the workshop, the action space for job scheduling, and the reward function equivalent to the scheduling objective. The AlphaSchedule model uses proximal policy optimization (PPO) algorithm to train a scheduling Resnet network, and integrates the trained scheduling network with an improved Monte Carlo tree search (MCTS) algorithm. Multiple comparison experiments in the simulation workshop show that the AlphaSchedule model has a better scheduling performance than genetic algorithm (GA), particle swarm optimization (PSO), and pure MCTS algorithm. Additional experiments show that the PPO algorithm in the AlphaSchedule model has higher training efficiency than the Monte Carlo tree training method in the AlphaGo Zero model.",
        "DOI": "10.1109/CAC51589.2020.9327564",
        "paper_author": "Wang J.H.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Comparative Study of AI-based Predictive Models for Cardiovascular Disease (CVD) Prevention in Next Generation Primary Healthcare Services",
        "publication": "2020 IEEE International Conference for Innovation in Technology, INOCON 2020",
        "citied_by": "1",
        "cover_date": "2020-11-06",
        "Abstract": "Primary Healthcare Service (PHS) is an important area of concern for the policy makers of every nation. Key components of PHS include preventive services that require early disease detection. One major disease where mortality rate can be reduced significantly, if diagnosed early, is Cardio Vascular Disease (CVD). In this work, we have used different Machine Learning models for CVD prediction to compare their performances in terms of accuracy, and found Multilayer Perceptron as a better suited model. Since prediction of the model depends on data set, the model needs as usual continuous learning post deployment too.",
        "DOI": "10.1109/INOCON50539.2020.9298299",
        "paper_author": "Mandal T.",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India",
        "affiliation_id": "60079452",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Stock Price Prognosticator using Machine Learning Techniques",
        "publication": "Proceedings of the 4th International Conference on Electronics, Communication and Aerospace Technology, ICECA 2020",
        "citied_by": "3",
        "cover_date": "2020-11-05",
        "Abstract": "Stock market price prediction is one of the favourite research topics under consideration for professionals from various fields like mathematics, statistics, history, finance, computer science engineering etc., as it requires a set of skills to predict variation of price of shares in a very volatile and challenging share market scenario. Share market trading is mostly dependent on sentiments of investors and other factors like economic policies, political changes, natural disasters etc., Many theories were forwarded, mathematical and statistical applications in conjunction with probability, to simplify the complex process. After the advent of computers, it got further simplified but still challenging due to various external influential factors ruling the volatility of the market prices. Thus, AI and ML algorithms were being developed, but for only for next day using Linear Regression procedures.Our project aims to predict the prices of shares more precisely and accurately using special algorithms using RNN by improvising the back propagation, feedback routines to overcome the short-term memory loss involved in RNN thus providing efficiency in LSTM applications.Our project emphasizes how the LSTM applications perform with datasets of extreme, larger and minimal fluctuating data.",
        "DOI": "10.1109/ICECA49313.2020.9297644",
        "paper_author": "Nishitha S.N.T.",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India",
        "affiliation_id": "60079446",
        "affiliation_state": "AP"
    },
    {
        "paper_title": "Caching and machine learning integration methods on named data network: A survey",
        "publication": "Proceeding of 14th International Conference on Telecommunication Systems, Services, and Applications, TSSA 2020",
        "citied_by": "21",
        "cover_date": "2020-11-04",
        "Abstract": "The caching mechanism is an essential part of future network design because it can improve the Quality of Experience (QoE) for users. Therefore, recent studies have examined the most appropriate caching techniques for future networks. Named Data Networks (NDN) is a future data-centric network that uses a cache mechanism to store packets of data in content stores. The main problem of traditional caching techniques cannot transmit large data packets, which high speed and changing depending on customers' requests. Undoubtedly, Machine Learning (ML) and deep learning (DL) algorithms play essential roles in many fields. Recent research adds ML or DL functions to cache decisions, such as cache replacement, content selection based on popularity, and cache placement. This paper performs an in-depth review of integration methods of caching and ML algorithms in future networks. The aim is to understand the goals, contributions, selection of learning algorithms, network topology, caching strategies, and their impact on improving network performance. This paper divides caching techniques into four categories to help readers understand the opportunities of the caching method. Furthermore, we discuss how a joint optimization strategy using ML and DL greatly impacted the network.",
        "DOI": "10.1109/TSSA51342.2020.9310811",
        "paper_author": "Negara R.M.",
        "affiliation_name": "Institut Teknologi Bandung",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069382",
        "affiliation_state": "West Java"
    },
    {
        "paper_title": "A Model to Enhance Governance Issues through Opinion Extraction",
        "publication": "11th Annual IEEE Information Technology, Electronics and Mobile Communication Conference, IEMCON 2020",
        "citied_by": "19",
        "cover_date": "2020-11-04",
        "Abstract": "We live in a world where data is expanding exponentially. Most of the data is unstructured when obtained through the web. Many organizations, institutes, and governments worldwide gather public views regarding their products, services, or policies. With thousands of reviews about some product, service, or policy, it is impossible to conclude some kind of final thought from it. To handle this, there is a desperate need for a model that can extract meaningful information from data to make correct and timely decisions for the efficient growth of business and smooth running of an organization or government. Otherwise, the practice of collecting and storing data will be ineffective. In this study, we focused on conducting an extensive public survey on issues of Southern Punjab, carry out appropriate processing on collected data and predict trends in public opinion for decision-making. Natural Language Processing (NLP) and Machine Learning (ML) have dealt with this problem. Different data preprocessing techniques have been utilized to remove the noise from data. Our experiments stated that unemployment, poverty, education, and corruption are the major issues of the targeted region. This study will help government officials and non-governmental organizations to be focused on the extracted issues in the specific region.",
        "DOI": "10.1109/IEMCON51383.2020.9284876",
        "paper_author": "Shaukat K.",
        "affiliation_name": "The University of Newcastle, Australia",
        "affiliation_city": "Callaghan",
        "affiliation_country": "Australia",
        "affiliation_id": "60010571",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Primary diagnosis prediction from chief complaints",
        "publication": "JCSSE 2020 - 17th International Joint Conference on Computer Science and Software Engineering",
        "citied_by": "1",
        "cover_date": "2020-11-04",
        "Abstract": "Telemedicine is one of the primary health policies in Thailand to improve life quality of people by accessing medical service from anywhere anytime. Many rural areas still have difficulties to get medical services such as primary diagnosis. We propose a web-based application for chief complaint analysis that is publicly available. Our system takes input of chief complaint text then makes predictions of primary diagnosis using machine learning algorithm. Our experiment shows that the model has promising results at 0.77 of accuracy. Our system could be used as a patient screening tool that makes impact to operational excellence for Thailand healthcare.",
        "DOI": "10.1109/JCSSE49651.2020.9268265",
        "paper_author": "Pettakorn S.",
        "affiliation_name": "Ltd",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "127826622",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Recent land use and land cover change dynamics in the gran chaco Americano",
        "publication": "International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",
        "citied_by": "1",
        "cover_date": "2020-11-04",
        "Abstract": "Land transformation is one of the most significant human changes on the Earth's surface processes. Therefore, land use land cover time series are a key input for environmental monitoring, natural resources management, territorial planning enforcement at national scale. We here capitalize from the MapBiomas initiative to characterize land use land cover (LULC) change in the Gran Chaco between 2010 and 2017. Specifically we sought to a) quantify annual changes in the main LULC classes; b) identify the main LULC transitions and c) relate these transitions to current land use policies. Within the MapBiomas project, Landsat based annual maps depicting natural woody vegetation, natural herbaceous vegetation, dispersed natural vegetation, cropland, pastures, bare areas and water. We used Random Forest machine learning algorithms trained by samples produced by visual interpretation of high resolution images. Annual overall accuracy ranged from 0,73 to 0,74. Our results showed that, between 2010 and 2017, agriculture and pasture lands increased ca. 3.7 Mha while natural forestry decreased by 2.3 Mha. Transitions from forests to agriculture accounted for 1.14% of the overall deforestation while 86% was associated to pastures and natural herbaceous vegetation. In Argentina, forest loss occurred primarily (39%) on areas non considered by the territorial planning Law, followed by medium (33%), high (19%) and low (9%) conservation priority classes. These results illustrate the potential contribution of remote sensing to characterize complex human environmental interactions occurring over extended areas and timeframes.",
        "DOI": "10.5194/isprs-archives-XLII-3-W12-2020-369-2020",
        "paper_author": "Banchero S.",
        "affiliation_name": "Instituto Nacional de Tecnología Agropecuaria Buenos Aires",
        "affiliation_city": "Buenos Aires",
        "affiliation_country": "Argentina",
        "affiliation_id": "60009264",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Converging artificial intelligence and blockchain technology using oracle contract in ethereum blockchain platform",
        "publication": "2020 5th International Conference on Informatics and Computing, ICIC 2020",
        "citied_by": "4",
        "cover_date": "2020-11-03",
        "Abstract": "Artificial Intelligence (AI) and blockchain are two emerging concepts that explored exponentially in recent years. In software development, artificial Intelligence offers a sophisticated enhancement on the programming logic, while blockchain technology provides transparency and relief the obligation to trust in a central party. Both are two different technologies but considered a disruptive technology in recent years. Artificial Intelligence faces several issues related to the validity of data, algorithms, and policies, while blockchain is called so 'friendly' with transparency, trust, and immutability. Both technologies are still in the early stages of their development age. Always, the opportunity for both technologies to converge in some ways would be an exciting area to be explored. This research elaborates on the technical possibilities of application development on the blockchain platform that communicate with AI to do prediction task. Oracle contract allows the data inside Ethereum blockchain to interact with the external data source.",
        "DOI": "10.1109/ICIC50835.2020.9288611",
        "paper_author": "Richard ",
        "affiliation_name": "Bina Nusantara University",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60103610",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "From PIace2Vec to Multi-Scale Built-Environment Representation: A General-Purpose Distributional Embedding for Urban Data Analysis",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "3",
        "cover_date": "2020-11-03",
        "Abstract": "Built environments like cities, roads, communities are rich sources of urban data. Many downstream applications require comprehensive analysis like geographic information retrieval, recommender systems, geographic knowledge graphs, and in general, understanding urban spaces [28]. Points of Interests (POI), as one of the most researched aspects of urban data, has been successfully modeled using concepts borrowed from Machine Learning (ML) and Natural Language Processing (NLP). In the work of Place2Vec [28], a Word2Vec-like statistical model is proposed to represent spatial adjacency with a continuous embedding space. This method successfully models the functional semantics of POIs with regard to several human-assessment based evaluations. However, though the Place2Vec model addresses the distributional heterogeneity within a given spatial context with ITDL augmentation, it does not address the spatial heterogeneity among different regions. To solve this problem, we propose to introduce a hierarchical, density-based, self-adjusting clustering mechanism. The boundary of relatedness and unrelatedness is learned from the given context, where denser areas have tighter bounds while sparser areas have looser ones. We train our model on both the baseline Yelp hierarchical dataset [28] and our OpenStreetMap dataset. We demonstrate that 1) our model significantly improves the performance on 2 of the 3 baseline tasks and the stability of training, and 2) our model generalizes excellently across 112 cities of radically different scales (minimum 1725 POIs, maximum 2694070 POIs), regions (North America, Europe, Asia, Africa) and types (commercial, touristy, industrial, etc.) without the need of adjusting or tuning any hyperparameters. We also demonstrate that our model can be used to discover interesting facts about cities like inter-city semantic analogy and intra-city connectivity, which can be very useful in urban planning, social computing and public policy making.",
        "DOI": "10.1145/3423334.3431450",
        "paper_author": "Wang Z.",
        "affiliation_name": "University of California, Santa Barbara",
        "affiliation_city": "Santa Barbara",
        "affiliation_country": "United States",
        "affiliation_id": "60029241",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Generator Model Parameter Calibration Using Reinforcement Learning",
        "publication": "2020 IEEE Green Energy and Smart Systems Conference, IGESSC 2020",
        "citied_by": "4",
        "cover_date": "2020-11-02",
        "Abstract": "Numerical models play important roles in power system operation. They are widely used for planning studies to identify and mitigate issues, determine transfer capability, and develop transmission reinforcement plans. These models need to be accurate and updated regularly to serve these purposes faithfully over time. In this paper, we formulate the problem of parameter calibration for machine models in a power system into the framework of reinforcement learning and demonstrate the feasibility of applying Deep Deterministic Policy Gradient (DDPG) for a two-parameter generator model calibration on a 4-bus system. To improve the efficiency and accuracy of DDPG, we introduce memory forgetting mechanism and dynamic range adjustment (DRA) into the original DDPG, i.e., DRA-DDPG. To reduce the parameter estimation errors due to partially observable disturbance states in the power system, we introduce the concept of maximal K-Nearest-Neighbor (KNN) reward to enable our reinforcement learning algorithm to accommodate a finite set (K) of unknown disturbance states in the system. Our experimental results show that the proposed DRA-DDPG outperforms the baseline DDPG in terms of accuracy and efficiency and the proposed maximal KNN reward is well-suited for resolving the uncertainties from partially observable system states.",
        "DOI": "10.1109/IGESSC50231.2020.9285022",
        "paper_author": "Wu W.",
        "affiliation_name": "University of Rochester",
        "affiliation_city": "Rochester",
        "affiliation_country": "United States",
        "affiliation_id": "60027165",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "State of Energy Prediction in Renewable Energy-driven Mobile Edge Computing using CNN-LSTM Networks",
        "publication": "2020 IEEE Green Energy and Smart Systems Conference, IGESSC 2020",
        "citied_by": "18",
        "cover_date": "2020-11-02",
        "Abstract": "Renewable energy (RE) is a promising solution to save grid power in mobile edge computing (MEC) systems and thus reducing the carbon footprints. However, to effectively operate the RE-based MEC system, a method for predicting the state of energy (SoE) in the battery is essential, not only to prevent the battery from over-charging or over-discharging, but also allowing the MEC applications to adjust their loads in advance based on the energy availability. In this work, we consider RE-powered MEC systems at the Road-side Unit (RSU) and focus on predicting its battery's SoE by using machine learning technique. We developed a real-world RE-powered RSU testbed consisting of edge computing devices, small cell base station, and solar as well as wind power generators. By operating RE-powered RSU for serving real-world computation task offloading demands, we collect the corresponding data sequences of battery's SoE and other observable parameters of the MEC systems that impact the SoE. Using a variant of Long Short-Term Memory (LSTM) model with additional convolutional layers, we form a CNN-LSTM model which can predict the SoE accurately with very low prediction error. Our results show that CNN-LSTM outperforms other Recurrent Neural Networks (RNN) based models for predicting intra-hour and hour-Ahead SoE.",
        "DOI": "10.1109/IGESSC50231.2020.9285102",
        "paper_author": "Ku Y.J.",
        "affiliation_name": "Electrical and Computer Engineering Department",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States",
        "affiliation_id": "60121655",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Using reinforcement learning to allocate and manage SFC in cellular networks",
        "publication": "16th International Conference on Network and Service Management, CNSM 2020, 2nd International Workshop on Analytics for Service and Application Management, AnServApp 2020 and 1st International Workshop on the Future Evolution of Internet Protocols, IPFuture 2020",
        "citied_by": "2",
        "cover_date": "2020-11-02",
        "Abstract": "In this paper, we propose the use of reinforcement learning to deploy a service function chain (SFC) of cellular network service and manage the VNFs operation. We consider that the SFC is deployed by the reinforcement learning agent considering a scenario with distributed data centers, where the virtual network functions (VNFs) are deployed in virtual machines in commodity servers. The VNF management is related to create, delete, and restart the VNFs. The main purpose is to reduce the number of lost packets taking into account the energy consumption of the servers. We use the Proximal Policy Optimization (PPO2) algorithm to implement the agent and preliminary results show that the agent is able to allocate the SFC and manage the VNFs, reducing the number of lost packets.",
        "DOI": "10.23919/CNSM50824.2020.9269088",
        "paper_author": "Santos G.L.",
        "affiliation_name": "Universidade Federal de Pernambuco",
        "affiliation_city": "Recife",
        "affiliation_country": "Brazil",
        "affiliation_id": "60031482",
        "affiliation_state": "PE"
    },
    {
        "paper_title": "Spatial and temporal human settlement growth differentiation with symbolic machine learning for verifying spatial policy targets: Assiut governorate, Egypt as a case study",
        "publication": "Remote Sensing",
        "citied_by": "4",
        "cover_date": "2020-11-02",
        "Abstract": "Since 2005, Egypt has a new land-use development policy to control unplanned human settlement growth and prevent outlying growth. This study assesses the impact of this policy shift on settlement growth in Assiut Governorate, Egypt, between 1999 and 2020. With symbolic machine learning, we extract built-up areas from Landsat images of 2005, 2010, 2015, and 2020 and a Landscape Expansion Index with a new QGIS plugin tool (Growth Classifier) developed to classify settlement growth types. The base year, 1999, was produced by the national remote sensing agency. After extracting the built-up areas from the Landsat images, eight settlement growth types (infill, expansion, edge-ribbon, linear branch, isolated cluster, proximate cluster, isolated scattered, and proximate scattered) were identified for four periods (1999:2005, 2005:2010, 2010:2015, and 2015:2020). The results show that prior to the policy shift of 2005, the growth rate for 1999–2005 was 11% p.a. In all subsequent periods, the growth rate exceeded the target rate of 1% p.a., though by varying amounts. The observed settlement growth rates were 5% (2005:2010), 7.4% (2010:2015), and 5.3% (2015:2020). Although the settlements in Assiut grew primarily through expansion and infill, with the latter growing in importance during the last two later periods, outlying growth is also evident. Using four class metrics (number of patches, patch density, mean patch area, and largest patch index) for the eight growth types, all types showed a fluctuated trend between all periods, except for expansion, which always tends to increase. To date, the policy to control human settlement expansion and outlying growth has been unsuccessful.",
        "DOI": "10.3390/rs12223799",
        "paper_author": "Abdelkader M.",
        "affiliation_name": "Faculty of Geo-Information Science and Earth Observation – ITC",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60017915",
        "affiliation_state": "Overijssel"
    },
    {
        "paper_title": "Ensemble of machine-learning methods for predicting gully erosion susceptibility",
        "publication": "Remote Sensing",
        "citied_by": "68",
        "cover_date": "2020-11-02",
        "Abstract": "Gully formation through water-induced soil erosion and related to devastating land degradation is often a quasi-normal threat to human life, as it is responsible for huge loss of surface soil. Therefore, gully erosion susceptibility (GES) mapping is necessary in order to reduce the adverse effect of land degradation and diminishes this type of harmful consequences. The principle goal of the present research study is to develop GES maps for the Garhbeta I Community Development (C.D.) Block; West Bengal, India, by using a machine learning algorithm (MLA) of boosted regression tree (BRT), bagging and the ensemble of BRT-bagging with K-fold cross validation (CV) resampling techniques. The combination of the aforementioned MLAs with resampling approaches is state-of-the-art soft computing, not often used in GES evaluation. In further progress of our research work, here we used a total of 20 gully erosion conditioning factors (GECFs) and a total of 199 gully head cut points for modelling GES. The variables’ importance, which is responsible for gully erosion, was determined based on the random forest (RF) algorithm among the several GECFs used in this study. The output result of the model’s performance was validated through a receiver operating characteristics-area under curve (ROC-AUC), sensitivity, specificity, positive predictive value (PPV) and negative predictive value (NPV) statistical analysis. The predicted result shows that the ensemble of BRT-bagging is the most well fitted for GES where AUC value in K-3 fold is 0.972, whereas the value of AUC in sensitivity, specificity, PPV and NPV is 0.94, 0.93, 0.96 and 0.93, respectively, in a training dataset, and followed by the bagging and BRT model. Thus, from the predictive performance of this research study it is concluded that the ensemble of BRT-Bagging can be applied as a new approach for further studies in spatial prediction of GES. The outcome of this work can be helpful to policy makers in implementing remedial measures to minimize damages caused by gully erosion.",
        "DOI": "10.3390/rs12223675",
        "paper_author": "Pal S.C.",
        "affiliation_name": "The University of Burdwan",
        "affiliation_city": "Bardhaman",
        "affiliation_country": "India",
        "affiliation_id": "60030482",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Artificial Intelligence in Health Care: Current Applications and Issues",
        "publication": "World Journal of Orthopedics",
        "citied_by": "75",
        "cover_date": "2020-11-02",
        "Abstract": "In recent years, artificial intelligence (AI) technologies have greatly advanced and become a reality in many areas of our daily lives. In the health care field, numerous efforts are being made to implement the AI technology for practical medical treatments. With the rapid developments in machine learning algorithms and improvements in hardware performances, the AI technology is expected to play an important role in effectively analyzing and utilizing extensive amounts of health and medical data. However, the AI technology has various unique characteristics that are different from the existing health care technologies. Subsequently, there are a number of areas that need to be supplemented within the current health care system for the AI to be utilized more effectively and frequently in health care. In addition, the number of medical practitioners and public that accept AI in the health care is still low; moreover, there are various concerns regarding the safety and reliability of AI technology implementations. Therefore, this paper aims to introduce the current research and application status of AI technology in health care and discuss the issues that need to be resolved.",
        "DOI": "10.3346/jkms.2020.35.e379",
        "paper_author": "Park C.W.",
        "affiliation_name": "Samsung Medical Center, Sungkyunkwan university",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60020857",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A semantically rich framework for knowledge representation of code of federal regulations",
        "publication": "Digital Government: Research and Practice",
        "citied_by": "7",
        "cover_date": "2020-11-01",
        "Abstract": "Federal government agencies and organizations doing business with them have to adhere to the Code of Federal Regulations (CFR). The CFRs are currently available as large text documents that are not machine processable and so require extensive manual effort to parse and comprehend, especially when sections cross-reference topics spread across various titles. We have developed a novel framework to automatically extract knowledge from CFRs and represent it using a semantically rich knowledge graph. The framework captures knowledge in the form of key terms, rules, topic summaries, relationships between various terms, semantically similar terminologies, deontic expressions, and cross-referenced facts and rules. We built our framework using deep learning technologies like TensorFlow for word embeddings and text summarization, Gensim for topic modeling, and Semantic Web technologies for building the knowledge graph. In this article, we describe our framework in detail and present the results of our analysis of the Title 48 CFR knowledge base that we have built using this framework. Our framework and knowledge graph can be adopted by federal agencies and businesses to automate their internal processes that reference the CFR rules and policies.",
        "DOI": "10.1145/3425192",
        "paper_author": "Joshi K.P.",
        "affiliation_name": "University of Maryland, Baltimore County (UMBC)",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60024997",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "A Learning-based Fetch Thread Gating Mechanism for A Simultaneous Multithreading Processor",
        "publication": "Proceedings - 2020 8th International Symposium on Computing and Networking, CANDAR 2020",
        "citied_by": "1",
        "cover_date": "2020-11-01",
        "Abstract": "Simultaneous Multithreading (SMT) technology is widely adopted in modern high-end processors to maximize on-chip hardware utilization. In an SMT processor, multiple threads are executed in parallel, sharing hardware resources. This technique aggregates potential efficiency which will not be available in a single thread processor. However, when a data cache miss or a branch prediction miss occurs, every thread competing for hardware resources causes the degradation of hardware utilization. Therefore, instruction fetch policies have been proposed to manage hardware resources efficiently in SMT processors. The fetch policies distribute hardware resources indirectly, through fetch bandwidth control. Conventionally, a fetch policy selects fetch threads based only on the resource usage at the moment, while the characteristics of threads are not exploited on decision. Therefore most conventional fetch control schemes only take effects only after an outstanding event occurs. Capability of resource restriction is limited even with an aggressive fetch control scheme. In this paper, we propose a Fetch Gate Estimator (FGE) that is a fetch gating mechanism based on machine learning, which is implemented as a hardware module. The FGE evaluates each thread to decide whether an instruction fetch from a thread should be gated. The FGE is trained dynamically by the execution statistics resulted from the inferences, so that characteristics of each thread are encoded into a learning model. Thus, the FGE is trained dynamically in parallel with execution of programs. We applied a single layer perceptron as learning model inside the FGE for circuit simplicity, and investigated performance impacts. Evaluation results show that the perceptron-based FGE can train itself from acquired execution statistics to identify inefficient threads adaptively, adjusting resources through the fetch gate control mechanism.",
        "DOI": "10.1109/CANDAR51075.2020.00011",
        "paper_author": "Ide Y.",
        "affiliation_name": "Keio University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60025997",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Proceedings - 2020 8th International Symposium on Computing and Networking, CANDAR 2020",
        "publication": "Proceedings - 2020 8th International Symposium on Computing and Networking, CANDAR 2020",
        "citied_by": "0",
        "cover_date": "2020-11-01",
        "Abstract": "The proceedings contain 32 papers. The topics discussed include: an in-network parameter aggregation using DPDK for multi-GPU deep learning; virtual machine monitor-based hiding method for access to debug registers; ProgressiveNN: achieving computational scalability without network alteration by MSB-first accumulative computation; face completion with pyramid semantic attention and latent codes; on the loop suppression method by utilizing information of master terminals for neighboring terminals in Bluetooth MANETs; a learning-based fetch thread gating mechanism for a simultaneous multithreading processor; bandit-based run-time adaptation of cache replacement policies in content management systems; and derived metrics for the game of go – intrinsic network strength assessment and cheat-detection.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Towards Online Learning and Concept Drift for Offloading Complex Event Processing in the Edge",
        "publication": "Proceedings - 2020 IEEE/ACM Symposium on Edge Computing, SEC 2020",
        "citied_by": "2",
        "cover_date": "2020-11-01",
        "Abstract": "Edge computing has enabled the usage of Complex Event Processing (CEP) closer to data sources, delivering on time response to critical applications. One of the challenges in this context is how to support this processing and keep an optimal resource usage (e.g., Memory, CPU). State-of-art solutions have suggested computational offloading techniques to distribute processing across the nodes and reach such optimization. Most of them take the offloading decision through predefined policies or adaptive solutions with the usage of machine learning algorithms. However, these techniques are not able to incrementally learn without any historical data or to adapt to changes on statistical data properties. This research aims to use online learning and concept drift detection on offloading decision to optimize resource usage and keep the learning model up-to-date. The feasibility of our approach was noticed through preliminary evaluations.",
        "DOI": "10.1109/SEC50012.2020.00024",
        "paper_author": "Neto J.A.",
        "affiliation_name": "Universidade Federal de Pernambuco",
        "affiliation_city": "Recife",
        "affiliation_country": "Brazil",
        "affiliation_id": "60031482",
        "affiliation_state": "PE"
    },
    {
        "paper_title": "SUESSA: Sustainable Ultra-Elastic Stack Security Architecture for Securing IoT Networks of Future Smart Cities",
        "publication": "Proceedings - 2020 8th International Symposium on Computing and Networking Workshops, CANDARW 2020",
        "citied_by": "4",
        "cover_date": "2020-11-01",
        "Abstract": "Recently, the concept of a super smart city has received special attention and has become the most popular agenda among city planners, policy makers and IT industries around the globe. In this paper, we proposed a novel Sustainable Ultra-Elastic Stack Security Architecture (SUESSA) which can address various future security challenges of artificial intelligence (AI), big data and communication networks. Our architecture employs the holistic approach based on sustainability of network security which is different than that of the prevailing security practices. We propose to apply the sustainable approach in the Network security architecture through augmentation of cloud, networks and end-point level, our approach provides a robust and ultra-elastic mechanism of security that surpasses the prevailing architecture. We evaluated the feasibility and performance of the security stack containing a machine learning component, Elastic search engine, Kibana and Logstash as the building blocks of the architecture. Based on our survey, SUESSA architecture overcomes the disadvantages of current architecture specifically solving the problem of sustainability strongly demanded in security architecture of the future smart cities.",
        "DOI": "10.1109/CANDARW51189.2020.00079",
        "paper_author": "Gautam B.P.",
        "affiliation_name": "Kanazawa Gakuin University",
        "affiliation_city": "Kanazawa",
        "affiliation_country": "Japan",
        "affiliation_id": "60004720",
        "affiliation_state": "Ishikawa"
    },
    {
        "paper_title": "Fooling Edge Computation Offloading via Stealthy Interference Attack",
        "publication": "Proceedings - 2020 IEEE/ACM Symposium on Edge Computing, SEC 2020",
        "citied_by": "2",
        "cover_date": "2020-11-01",
        "Abstract": "There is a growing interest in developing deep learning methods to solve many resource management problems in wireless edge computing systems where model-based designs are infeasible. While deep learning is known to be vulnerable to adversarial example attacks, the security risk of learningbased designs in the context of edge computing is not well understood. In this paper, we propose and study a new adversarial example attack, called stealthy interference attack (SIA), in deep reinforcement learning (DRL)-based edge computation offloading systems. In SIA, the attacker exerts a carefully determined level of interference signal to change the input states of the DRL-based policy, thereby fooling the mobile device in selecting a target and compromised edge server for computation offloading while evading detection. Simulation results demonstrate the effectiveness of SIA, and show that our algorithm outperforms existing adversarial machine learning algorithms in terms of a higher attack success probability and a lower power consumption.",
        "DOI": "10.1109/SEC50012.2020.00062",
        "paper_author": "Zhang L.",
        "affiliation_name": "University of Miami College of Engineering",
        "affiliation_city": "Coral Gables",
        "affiliation_country": "United States",
        "affiliation_id": "60155661",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Thread-placement learning",
        "publication": "Proceedings - International Conference on Distributed Computing Systems",
        "citied_by": "1",
        "cover_date": "2020-11-01",
        "Abstract": "In a non-uniform memory access machine, the placement of software threads to hardware cores can have a significant effect on the performance of concurrent applications. Detecting the best possible placement for each application is a necessity for thread scheduling. Yet, due to the difficulty of this problem, operating-system schedulers do not really try to understand the needs of applications, but rather focus on (non-portable) scheduling heuristics. In this paper, we introduce thread-placement learning (TPLE), a technique for understanding the placement requirements of applications. TPLE utilizes machine learning and performance counters for choosing between different placement policies. To feed the machine learning model, TPLE requires a set of portable microbenchmarks that produce training data—i.e., performance counter measurements—for all the target placement policies. We use this data to train a classifier that is able to choose between these policies online in order to change the thread-placement of a running application. We demonstrate the practicality of TPLE by implementing a thread-placement algorithm, named Slate. Slate is able to automatically and online (i.e., in runtime) select between the two most commonly-used placement policies, namely locality and round-robin placement on the nodes of a multicore. To the best of our knowledge, Slate is the first online thread-placement algorithm that utilizes machine learning in combination with performance counters. We evaluate Slate and show that it achieves up to 93% accuracy in its decisions and outperforms the Linux scheduler by up to 16%.",
        "DOI": "10.1109/ICDCS47774.2020.00050",
        "paper_author": "Antoniadis K.",
        "affiliation_name": "EPFL",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland",
        "affiliation_id": "114451121",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mechanisms for a no-regret agent: Beyond the common prior",
        "publication": "Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",
        "citied_by": "15",
        "cover_date": "2020-11-01",
        "Abstract": "A rich class of mechanism design problems can be understood as incomplete-information games between a principal who commits to a policy and an agent who responds, with payoffs determined by an unknown state of the world. Traditionally, these models require strong and often-impractical assumptions about beliefs (a common prior over the state). In this paper, we dispense with the common prior. Instead, we consider a repeated interaction where both the principal and the agent may learn over time from the state history. We reformulate mechanism design as a reinforcement learning problem and develop mechanisms that attain natural benchmarks without any assumptions on the state-generating process. Our results make use of novel behavioral assumptions for the agent-based on counterfactual internal regret-that capture the spirit of rationality without relying on beliefs. 11For the full version of this paper, see https://arxiv.org/abs/2009.05518.",
        "DOI": "10.1109/FOCS46700.2020.00033",
        "paper_author": "Camara M.K.",
        "affiliation_name": "Robert R. McCormick School of Engineering and Applied Science",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States",
        "affiliation_id": "60147353",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Digital pathology: Advantages, limitations and emerging perspectives",
        "publication": "Journal of Clinical Medicine",
        "citied_by": "191",
        "cover_date": "2020-11-01",
        "Abstract": "Digital pathology is on the verge of becoming a mainstream option for routine diagnostics. Faster whole slide image scanning has paved the way for this development, but implementation on a large scale is challenging on technical, logistical, and financial levels. Comparative studies have published reassuring data on safety and feasibility, but implementation experiences highlight the need for training and the knowledge of pitfalls. Up to half of the pathologists are reluctant to sign out reports on only digital slides and are concerned about reporting without the tool that has represented their profession since its beginning. Guidelines by international pathology organizations aim to safeguard histology in the digital realm, from image acquisition over the setup of work-stations to long-term image archiving, but must be considered a starting point only. Cost-efficiency analyses and occupational health issues need to be addressed comprehensively. Image analysis is blended into the traditional work-flow, and the approval of artificial intelligence for routine diagnostics starts to challenge human evaluation as the gold standard. Here we discuss experiences from past digital pathology implementations, future possibilities through the addition of artificial intelligence, technical and occupational health challenges, and possible changes to the pathologist’s profession.",
        "DOI": "10.3390/jcm9113697",
        "paper_author": "Jahn S.W.",
        "affiliation_name": "Medizinische Universität Graz",
        "affiliation_city": "Graz",
        "affiliation_country": "Austria",
        "affiliation_id": "60006224",
        "affiliation_state": "Styria"
    },
    {
        "paper_title": "An Experimental Study of Spammer Detection on Chinese Microblogs",
        "publication": "International Journal of Software Engineering and Knowledge Engineering",
        "citied_by": "1",
        "cover_date": "2020-11-01",
        "Abstract": "With the development of Web 2.0, social media such as Twitter and Sina Weibo have become an essential platform for disseminating hot events. Simultaneously, due to the free policy of microblogging services, users can post user-generated content freely on microblogging platforms. Accordingly, more and more hot events on microblogging platforms have been labeled as spammers. Spammers will not only hurt the healthy development of social media but also introduce many economic and social problems. Therefore, the government and enterprises must distinguish whether a hot event on microblogging platforms is a spammer or is a naturally-developing event. In this paper, we focus on the hot event list on Sina Weibo and collect the relevant microblogs of each hot event to study the detecting methods of spammers. Notably, we develop an integral feature set consisting of user profile, user behavior, and user relationships to reflect various factors affecting the detection of spammers. Then, we employ typical machine learning methods to conduct extensive experiments on detecting spammers. We use a real data set crawled from the most prominent Chinese microblogging platform, Sina Weibo, and evaluate the performance of 10 machine learning models with five sampling methods. The results in terms of various metrics show that the Random Forest model and the over-sampling method achieve the best accuracy in detecting spammers and non-spammers.",
        "DOI": "10.1142/S021819402040029X",
        "paper_author": "Liang J.",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China",
        "affiliation_id": "60019118",
        "affiliation_state": "Anhui"
    },
    {
        "paper_title": "A Novel Scheme for Access Control Policy Generating and Evaluating in IoT based on Machine Learning",
        "publication": "Proceedings - IEEE Congress on Cybermatics: 2020 IEEE International Conferences on Internet of Things, iThings 2020, IEEE Green Computing and Communications, GreenCom 2020, IEEE Cyber, Physical and Social Computing, CPSCom 2020 and IEEE Smart Data, SmartData 2020",
        "citied_by": "2",
        "cover_date": "2020-11-01",
        "Abstract": "The ever-increasing demand for data exchanges has boosted the development of the Internet of Things (IoT). IoT has brought a new revolution to a variety of industries by integrating smart devices as well as information and communication technologies into traditional systems. However, due to the dynamic and heterogeneous structure of IoT, unauthorized access and data leakage may be much easier. Attribute-based access control (ABAC) is suitable for complex and changeable access control environments due to its flexibility and universality in capturing authorizations in terms of the attributes of users and resources. However, the dynamic nature of IoT bring new challenges to access control. On the one hand, new services and applications continue to be deployed, administrators need to formulate new policies for those services and applications. Therefore, manual development of ABAC polices in IoT environment is time consuming and expensive. On the other hand, because the access environment is constantly changing, access control policies may become unsuitable for current environment. Manual identification of these low-quality rules is often after they cause severe consequences. To address the above two problems, we propose a scheme for generating and evaluating polices in IoT based on machine learning. This scheme referred to as PGEML, contains two module, policy generalization (PG) and policy evaluation (PE). In the PG module, we define a novel measure, resource similarity, and integrate it into policy mining so that policies could generalize among related resources. In the PE module, we introduce a quantitative method to assess rules and prune rules of low-quality. We conduct our experiments on a real-world enterprise access logs from Amazon. The experimental results has qualitatively and quantitatively showed the effectiveness of our proposed scheme.",
        "DOI": "10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00079",
        "paper_author": "Zhao Y.",
        "affiliation_name": "Nanjing University of Science and Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60010080",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "A Platform for Disease Intervention Planning",
        "publication": "2020 IEEE International Conference on Healthcare Informatics, ICHI 2020",
        "citied_by": "2",
        "cover_date": "2020-11-01",
        "Abstract": "The research and development of new tools and strategies for disease intervention planning requires resources, data, and computation spread across multiple institutions and individuals. Whether this is towards an objective such as drug discovery or informing intervention policy, it should be possible for these tools to be flexibly deployed to meet the decision support needs of the Global Health community. In this work we introduce a new platform to demonstrate the utility of a scalable computational infrastructure, blockchain based validation and machine learning (ML) algorithms, to assist in the generation of validated novel policies for malaria control. We have conducted preliminary tests in the generation of simulation-based evidence to guide policy level decision making. Specifically to assess the performance of; the scalable infrastructure under different simulation complexities and distributed compute; Hyperledger Fabric to provide validation of shared information within our application; and ML approaches to generate novel policy insights. Finally the components of the platform may be leveraged via a non-Technical user or policy-maker through an Interactive Dashboard, bridging the gap between research and immediate needs in Disease Intervention Planning.",
        "DOI": "10.1109/ICHI48887.2020.9374384",
        "paper_author": "Wachira C.M.",
        "affiliation_name": "IBM Research",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States",
        "affiliation_id": "60011048",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "SEM: Adaptive Staged Experience Access Mechanism for Reinforcement Learning",
        "publication": "Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",
        "citied_by": "2",
        "cover_date": "2020-11-01",
        "Abstract": "Experience memory, which stores and replays experience from the past for off-policy reinforcement learning (RL) agents, has become an essential component of cutting-edge algorithms in recent years. In most previous work, experience memory emphasizes recently acquired experiences while neglects long-Ago ones, which causes high variance and catastrophic forgetting in continual learning. To solve the problem, we introduce the Staged Experience Mechanism(SEM)-a novel management mechanism of experience memory. SEM adaptively regulates the proportion of experiences based on the current learning stages, enabling agents not only to learn from new experiences but also from very old ones given limited memory capacity. In the experiment, SEM is coupled with two state-of-The-Art off-policy algorithms compared with classic experience replay mechanisms on the suite of MuJoCo tasks. The result shows that RL with SEM is more stable and less variable than its counterparts in most tested continuous control environments, which reduces the training variance by 5% ∼ 104% while ensuring optimal scoring performance.",
        "DOI": "10.1109/ICTAI50040.2020.00166",
        "paper_author": "Wang J.",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60023813",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Dangerous prediction in roads by using machine learning models",
        "publication": "Ingenierie des Systemes d'Information",
        "citied_by": "1",
        "cover_date": "2020-11-01",
        "Abstract": "Many vulnerable, heinous acts that are coming about in the society especially at Roads, most specifically affecting women in the society, are more in recent days. Though new technologies are developing day by day, the fatality rate is not in control to date. Without proper guidance to the people about the particular place where there is a big scope of occurrence of a greater number of accidents, this menace cannot be regulated. It is required to highlight the District-wise data and Roads where the accidents and fatalities are more. The data would help the policymakers to put in place Focused Initiatives regarding those top dangerous roads to address the menace of rising road accidents and resultant fatalities. In this, we created a dataset in Andhra Pradesh where we include those attributes that are helpful for our analysis to predict which road is the most dangerous one. We applied various Machine Learning models such as Logistic regression, Random forest classifier, Gradient Boosting Classifier, Gaussian Naive Bayes, Decision Tree Classifier, K- Nearest Neighbour Classifier and SVM to predict the dangerous roads. It is observed that Logistic Regression provides good accuracy with 87.14.",
        "DOI": "10.18280/ISI.250511",
        "paper_author": "Satla S.P.",
        "affiliation_name": "Vignans Foundation for Science Technology and Research University",
        "affiliation_city": "Guntur",
        "affiliation_country": "India",
        "affiliation_id": "60104649",
        "affiliation_state": "AP"
    },
    {
        "paper_title": "Towards quantum computing based community detection",
        "publication": "Computer Science Review",
        "citied_by": "17",
        "cover_date": "2020-11-01",
        "Abstract": "Over the past decade, social network analysis has earned pivotal eminence in the area of web mining and information retrieval. Community detection, being the indispensable part of social network analysis; has garnered far reaching usance in business analytics, healthcare, security, research and policy making. With the embodiment of copious domains to social networks and unprecedented rise in the data-produced, accessed and stored globally; the task of handling the unpredictable, dynamic and ever evolving topological nature of social networks has become arduous. In this regard, quantum computing (QC) has emerged as the most promising trailblazer guaranteeing unprecedented data storage and manipulation capabilities by-dynamic allocation of cluster size and architecture, quantum parallelism, reduced parameter dependency, etc. QC based algorithms have registered exponential speedup over many classical problems with better efficiency and abated time complexity; apart from solving NP-hard problems that were unrealizable classically. Accordingly, a comprehensive literature survey has been presented for social network analysis and community detection highlighting the limitations prevalent in the current technologies. A brief insight into quantum computing and its proficiency in rendering to larger storage systems has been presented; as a solution to the inherent problems present in the existing community detection approaches. A systematic account of quantum computing based community detection techniques has been summarized and discussed as a more prudent future alternative to social network analysis and community detection. Lastly, complexity analysis and modularity based comparison of QC based algorithms with other state of the art algorithms has been carried out to establish the supremacy of quantum algorithms in community detection.",
        "DOI": "10.1016/j.cosrev.2020.100313",
        "paper_author": "Akbar S.",
        "affiliation_name": "Maulana Azad National Institute of Technology",
        "affiliation_city": "Bhopal",
        "affiliation_country": "India",
        "affiliation_id": "60021318",
        "affiliation_state": "MP"
    },
    {
        "paper_title": "Learning to discretize: Solving 1D scalar conservation laws via deep reinforcement learning",
        "publication": "Communications in Computational Physics",
        "citied_by": "17",
        "cover_date": "2020-11-01",
        "Abstract": "Conservation laws are considered to be fundamental laws of nature. It has broad applications in many fields, including physics, chemistry, biology, geology, and engineering. Solving the differential equations associated with conservation laws is a major branch in computational mathematics. The recent success of machine learning, especially deep learning in areas such as computer vision and natural language processing, has attracted a lot of attention from the community of computational mathematics and inspired many intriguing works in combining machine learning with traditional methods. In this paper, we are the first to view numerical PDE solvers as an MDP and to use (deep) RL to learn new solvers. As proof of concept, we focus on 1-dimensional scalar conservation laws. We deploy the machinery of deep reinforcement learning to train a policy network that can decide on how the numerical solutions should be approximated in a sequential and spatial-temporal adaptive manner. We will show that the problem of solving conservation laws can be naturally viewed as a sequential decision-making process, and the numerical schemes learned in such a way can easily enforce long-term accuracy. Furthermore, the learned policy network is carefully designed to determine a good local discrete approximation based on the current state of the solution, which essentially makes the proposed method a meta-learning approach. In other words, the proposed method is capable of learning how to discretize for a given situation mimicking human experts. Finally, we will provide details on how the policy network is trained, how well it performs compared with some state-of-the-art numerical solvers such as WENO schemes, and supervised learning based approach L3D and PINN, and how well it generalizes.",
        "DOI": "10.4208/CICP.OA-2020-0194",
        "paper_author": "Wang Y.",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60136640",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Modeling and Abstraction of Network and Environment States Using Deep Learning",
        "publication": "IEEE Network",
        "citied_by": "4",
        "cover_date": "2020-11-01",
        "Abstract": "CANs promise to apply cognition to overcome shortcomings of self-organizing networks, such as limited flexibility and adaptability to changing environments. in CAN, machine-learning-based network automation functions, called CFS, learn context-specific policies for automating network operations. For this, CFS need a common abstract description of the network states to which they respond. This article presents a design and implementation of an EMA engine that could be tasked with learning the required abstract states in a consistent way across multiple CFS.",
        "DOI": "10.1109/MNET.001.2000031",
        "paper_author": "Mwanje S.S.",
        "affiliation_name": "Nokia Bell Labs",
        "affiliation_city": "Murray",
        "affiliation_country": "United States",
        "affiliation_id": "60021378",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Twitter discussions and emotions about the COVID-19 pandemic: Machine learning approach",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "269",
        "cover_date": "2020-11-01",
        "Abstract": "Background: It is important to measure the public response to the COVID-19 pandemic. Twitter is an important data source for infodemiology studies involving public response monitoring. Objective: The objective of this study is to examine COVID-19-related discussions, concerns, and sentiments using tweets posted by Twitter users. Methods: We analyzed 4 million Twitter messages related to the COVID-19 pandemic using a list of 20 hashtags (eg, “coronavirus,” “COVID-19,” “quarantine”) from March 7 to April 21, 2020. We used a machine learning approach, Latent Dirichlet Allocation (LDA), to identify popular unigrams and bigrams, salient topics and themes, and sentiments in the collected tweets. Results: Popular unigrams included “virus,” “lockdown,” and “quarantine.” Popular bigrams included “COVID-19,” “stay home,” “corona virus,” “social distancing,” and “new cases.” We identified 13 discussion topics and categorized them into 5 different themes: (1) public health measures to slow the spread of COVID-19, (2) social stigma associated with COVID-19, (3) COVID-19 news, cases, and deaths, (4) COVID-19 in the United States, and (5) COVID-19 in the rest of the world. Across all identified topics, the dominant sentiments for the spread of COVID-19 were anticipation that measures can be taken, followed by mixed feelings of trust, anger, and fear related to different topics. The public tweets revealed a significant feeling of fear when people discussed new COVID-19 cases and deaths compared to other topics. Conclusions: This study showed that Twitter data and machine learning approaches can be leveraged for an infodemiology study, enabling research into evolving public discussions and sentiments during the COVID-19 pandemic. As the situation rapidly evolves, several topics are consistently dominant on Twitter, such as confirmed cases and death rates, preventive measures, health authorities and government policies, COVID-19 stigma, and negative psychological reactions (eg, fear). Real-time monitoring and assessment of Twitter discussions and concerns could provide useful data for public health emergency responses and planning. Pandemic-related fear, stigma, and mental health concerns are already evident and may continue to influence public trust when a second wave of COVID-19 occurs or there is a new surge of the current pandemic.",
        "DOI": "10.2196/20550",
        "paper_author": "Xue J.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Psychosocial effects of the COVID-19 pandemic: Large-scale quasi-experimental study on social media",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "107",
        "cover_date": "2020-11-01",
        "Abstract": "Background: The COVID-19 pandemic has caused several disruptions in personal and collective lives worldwide. The uncertainties surrounding the pandemic have also led to multifaceted mental health concerns, which can be exacerbated with precautionary measures such as social distancing and self-quarantining, as well as societal impacts such as economic downturn and job loss. Despite noting this as a “mental health tsunami”, the psychological effects of the COVID-19 crisis remain unexplored at scale. Consequently, public health stakeholders are currently limited in identifying ways to provide timely and tailored support during these circumstances. Objective: Our study aims to provide insights regarding people's psychosocial concerns during the COVID-19 pandemic by leveraging social media data. We aim to study the temporal and linguistic changes in symptomatic mental health and support expressions in the pandemic context. Methods: We obtained about 60 million Twitter streaming posts originating from the United States from March 24 to May 24, 2020, and compared these with about 40 million posts from a comparable period in 2019 to attribute the effect of COVID-19 on people's social media self-disclosure. Using these data sets, we studied people's self-disclosure on social media in terms of symptomatic mental health concerns and expressions of support. We employed transfer learning classifiers that identified the social media language indicative of mental health outcomes (anxiety, depression, stress, and suicidal ideation) and support (emotional and informational support). We then examined the changes in psychosocial expressions over time and language, comparing the 2020 and 2019 data sets. Results: We found that all of the examined psychosocial expressions have significantly increased during the COVID-19 crisis-mental health symptomatic expressions have increased by about 14%, and support expressions have increased by about 5%, both thematically related to COVID-19. We also observed a steady decline and eventual plateauing in these expressions during the COVID-19 pandemic, which may have been due to habituation or due to supportive policy measures enacted during this period. Our language analyses highlighted that people express concerns that are specific to and contextually related to the COVID-19 crisis. Conclusions: We studied the psychosocial effects of the COVID-19 crisis by using social media data from 2020, finding that people's mental health symptomatic and support expressions significantly increased during the COVID-19 period as compared to similar data from 2019. However, this effect gradually lessened over time, suggesting that people adapted to the circumstances and their “new normal.” Our linguistic analyses revealed that people expressed mental health concerns regarding personal and professional challenges, health care and precautionary measures, and pandemic-related awareness. This study shows the potential to provide insights to mental health care and stakeholders and policy makers in planning and implementing measures to mitigate mental health risks amid the health crisis.",
        "DOI": "10.2196/22600",
        "paper_author": "Saha K.",
        "affiliation_name": "College of Computing",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60097290",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Integration of data analytics with cloud services for safer process systems, application examples and implementation challenges",
        "publication": "Journal of Loss Prevention in the Process Industries",
        "citied_by": "12",
        "cover_date": "2020-11-01",
        "Abstract": "Emerging sensors, computers, network technologies, and connected platforms result potentially in an immeasurable collection of data within plant operations. This creates the possibility of solving problems innovatively. Because most of the data appear to be unstructured or semi-structured, organizations shall design and adopt new strategies. Further, workflow architectures with data analytics are needed including machine learning tools and artificial intelligence techniques before proto-type solutions can be developed. We shall discuss several prospects of using (big) data analytics integrated with cloud services to produce solutions for improving plant operations. The paper outlines the vision and a systematic framework highlighting the data analytics lifecycle in the area of plant operation, process safety, and environmental protection. Four rather diverse example case studies are demonstrated including (1) deep learning-based predictive maintenance monitoring modeling, (2) Natural Language Processing (NLP) for mining text, (3) barrier assessment for dynamic risk mapping (DRA), and (4) correlation development for sustainability indicators. It further discusses the challenges in both research and implementation of proposed solutions in the industry. It is concluded that a well-balanced integrated approach including machine supporting decisions integrated with expert knowledge and available information from various key resources is required to enable more informed policy, strategic, and operational risk decision-making leading to safer, reliable and more efficient operations.",
        "DOI": "10.1016/j.jlp.2020.104316",
        "paper_author": "Goel P.",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60020547",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Learning to Search for MIMO Detection",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "62",
        "cover_date": "2020-11-01",
        "Abstract": "This paper proposes a novel learning to learn method, called learning to learn iterative search algorithm (LISA), for signal detection in a multi-input multi-output (MIMO) system. The idea is to regard the signal detection problem as a decision making problem over tree. The goal is to learn the optimal decision policy. In LISA, deep neural networks are used as parameterized policy function. Through training, optimal parameters of the neural networks are learned and thus optimal policy can be approximated. Different neural network-based architectures are used for fixed and varying channel models, respectively. LISA provides soft decisions and does not require any information about the additive white Gaussian noise. Simulation results show that LISA 1) obtains near maximum likelihood detection performance in both fixed and varying channel models under QPSK modulation; 2) achieves significantly better bit error rate (BER) performance than classical detectors and recently proposed deep/machine learning based detectors at various modulations and signal to noise (SNR) ratios both under i.i.d and correlated Rayleigh fading channels in the simulation experiments; 3) is robust to MIMO detection problems with imperfect channel state information; and 4) generalizes very well against channel correlation and SNRs.",
        "DOI": "10.1109/TWC.2020.3012785",
        "paper_author": "Sun J.",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60018308",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "An Autonomous Lane-Changing System with Knowledge Accumulation and Transfer Assisted by Vehicular Blockchain",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "36",
        "cover_date": "2020-11-01",
        "Abstract": "Inappropriate lane following and changing behaviors of connected and autonomous vehicles (CAVs) can result in accidents, such as rear-end collision and side collision. To remedy that, the use of deep reinforcement learning (DRL) for autonomous driving decisions is currently a widely used promising solution. In this case, the accuracy and effectiveness of such a machine learning (ML) model is quite essential for this artificial intelligence (AI)-enabled CAVs. This article proposes a blockchain-based collective learning (BCL) framework for autonomous lane-changing systems. Four key issues, namely, learning efficiency, data security, users' privacy, as well as communication burden, are addressed by applying collective learning, vehicular blockchain, and knowledge transfer. First, we model the lane-changing problem as a DRL process and learn the autonomous lane-changing strategy through the deep deterministic policy gradient (DDPG) algorithm. Second, a single CAV involves a limited number of driving scenarios, and the independent learning method has the problem of inefficiency. Therefore, we propose a collective learning framework to utilize the 'collective intelligence' shared by CAVs. Third, a vehicular blockchain is then applied to ensure the security and privacy of the user and data. In addition, the introduction of the blockchain can incentivize more users to participate in collective learning. Finally, in order to accelerate the learning process and achieve higher level performance while further reducing the communication burden, we use the corresponding knowledge extracted from the ML model such as human learning, as privileged information for sharing instead of directly sharing local ML models. Extensive simulation results validate the effectiveness and efficiency of our proposal in terms of learning efficiency, driving safety, as well as system security and robustness.",
        "DOI": "10.1109/JIOT.2020.2994975",
        "paper_author": "Fu Y.",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60025578",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Age of Information Aware Trajectory Planning of UAVs in Intelligent Transportation Systems: A Deep Learning Approach",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "142",
        "cover_date": "2020-11-01",
        "Abstract": "Unmanned aerial vehicles (UAVs) are envisioned to play a key role in intelligent transportation systems to complement the communication infrastructure in future smart cities. UAV-assisted vehicular networking research typically adopts throughput and latency as the main performance metrics. These conventional metrics, however, are not adequate to reflect the freshness of the information, an attribute that has been recently identified as a critical requirement to enable services such as autonomous driving and accident prevention. In this paper, we consider a UAV-assisted single-hop vehicular network, wherein sensors (e.g., LiDARs and cameras) on vehicles generate time sensitive data streams, and UAVs are used to collect and process this data while maintaining a minimum age of information (AoI). We aim to jointly optimize the trajectories of UAVs and find scheduling policies to keep the information fresh under minimum throughput constraints. The formulated optimization problem is shown to be mixed integer non-linear program (MINLP) and generally hard to be solved. Motivated by the success of machine learning (ML) techniques particularly deep learning in solving complex problems with low complexity, we reformulate the trajectories and scheduling policies problem as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we develop deep reinforcement learning (DRL) to learn the vehicular environment and its dynamics in order to handle UAVs' trajectory and scheduling policy. In particular, we leverage Deep Deterministic Policy Gradient (DDPG) for learning the trajectories of the deployed UAVs to efficiently minimize the Expected Weighted Sum AoI (EWSA). Simulations results demonstrate the effectiveness of the proposed design and show the deployed UAVs adapt their velocities during the data collection mission in order to minimize the AoI.",
        "DOI": "10.1109/TVT.2020.3023861",
        "paper_author": "Samir M.",
        "affiliation_name": "Concordia University",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60033154",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Impact of Systematic Factors on the Outbreak Outcomes of the Novel COVID-19 Disease in China: Factor Analysis Study",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "12",
        "cover_date": "2020-11-01",
        "Abstract": "Background: The novel COVID-19 disease has spread worldwide, resulting in a new pandemic. The Chinese government implemented strong intervention measures in the early stage of the epidemic, including strict travel bans and social distancing policies. Prioritizing the analysis of different contributing factors to outbreak outcomes is important for the precise prevention and control of infectious diseases. We proposed a novel framework for resolving this issue and applied it to data from China. Objective: This study aimed to systematically identify national-level and city-level contributing factors to the control of COVID-19 in China. Methods: Daily COVID-19 case data and related multidimensional data, including travel-related, medical, socioeconomic, environmental, and influenza-like illness factors, from 343 cities in China were collected. A correlation analysis and interpretable machine learning algorithm were used to evaluate the quantitative contribution of factors to new cases and COVID-19 growth rates during the epidemic period (ie, January 17 to February 29, 2020). Results: Many factors correlated with the spread of COVID-19 in China. Travel-related population movement was the main contributing factor for new cases and COVID-19 growth rates in China, and its contributions were as high as 77% and 41%, respectively. There was a clear lag effect for travel-related factors (previous vs current week: new cases, 45% vs 32%; COVID-19 growth rates, 21% vs 20%). Travel from non-Wuhan regions was the single factor with the most significant impact on COVID-19 growth rates (contribution: new cases, 12%; COVID-19 growth rate, 26%), and its contribution could not be ignored. City flow, a measure of outbreak control strength, contributed 16% and 7% to new cases and COVID-19 growth rates, respectively. Socioeconomic factors also played important roles in COVID-19 growth rates in China (contribution, 28%). Other factors, including medical, environmental, and influenza-like illness factors, also contributed to new cases and COVID-19 growth rates in China. Based on our analysis of individual cities, compared to Beijing, population flow from Wuhan and internal flow within Wenzhou were driving factors for increasing the number of new cases in Wenzhou. For Chongqing, the main contributing factor for new cases was population flow from Hubei, beyond Wuhan. The high COVID-19 growth rates in Wenzhou were driven by population-related factors. Conclusions: Many factors contributed to the COVID-19 outbreak outcomes in China. The differential effects of various factors, including specific city-level factors, emphasize the importance of precise, targeted strategies for controlling the COVID-19 outbreak and future infectious disease outbreaks.",
        "DOI": "10.2196/23853",
        "paper_author": "Cao Z.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021182",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "The hardest thing about learning is unlearning: Why systematic review replication should be reconsidered",
        "publication": "JBI Evidence Synthesis",
        "citied_by": "1",
        "cover_date": "2020-11-01",
        "Abstract": "NA",
        "DOI": "10.11124/JBIES-20-00452",
        "paper_author": "Jordan Z.",
        "affiliation_name": "Faculty of Health and Medical Sciences",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia",
        "affiliation_id": "60189792",
        "affiliation_state": "SA"
    },
    {
        "paper_title": "The Internet of Things: Impact and Implications for Health Care Delivery",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "260",
        "cover_date": "2020-11-01",
        "Abstract": "The Internet of Things (IoT) is a system of wireless, interrelated, and connected digital devices that can collect, send, and store data over a network without requiring human-to-human or human-to-computer interaction. The IoT promises many benefits to streamlining and enhancing health care delivery to proactively predict health issues and diagnose, treat, and monitor patients both in and out of the hospital. Worldwide, government leaders and decision makers are implementing policies to deliver health care services using technology and more so in response to the novel COVID-19 pandemic. It is now becoming increasingly important to understand how established and emerging IoT technologies can support health systems to deliver safe and effective care. The aim of this viewpoint paper is to provide an overview of the current IoT technology in health care, outline how IoT devices are improving health service delivery, and outline how IoT technology can affect and disrupt global health care in the next decade. The potential of IoT-based health care is expanded upon to theorize how IoT can improve the accessibility of preventative public health services and transition our current secondary and tertiary health care to be a more proactive, continuous, and coordinated system. Finally, this paper will deal with the potential issues that IoT-based health care generates, barriers to market adoption from health care professionals and patients alike, confidence and acceptability, privacy and security, interoperability, standardization and remuneration, data storage, and control and ownership. Corresponding enablers of IoT in current health care will rely on policy support, cybersecurity-focused guidelines, careful strategic planning, and transparent policies within health care organizations. IoT-based health care has great potential to improve the efficiency of the health system and improve population health.",
        "DOI": "10.2196/20135",
        "paper_author": "Kelly J.T.",
        "affiliation_name": "Menzies Health Institute Queensland",
        "affiliation_city": "Southport",
        "affiliation_country": "Australia",
        "affiliation_id": "60189943",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Development of Fault Diagnosis Program for reducing Power Loss Cost of the Photovoltaic Power System using Actual Operation Data",
        "publication": "Transactions of the Korean Institute of Electrical Engineers",
        "citied_by": "5",
        "cover_date": "2020-11-01",
        "Abstract": "Countries are looking for a pathway toward a sustainable transition from fossil-based to less or zero-carbon sources in energy sector in order to reduce its impact from climate change. Among different renewable resources, photovoltaic power system (PV) is considered as one of the most promising technology, which has the biggest potential for increasing renewable energy. However, its profit can be varied depending on operation and management, which possibly causes performance degradation and safety issues due to faults. Therefore, we have collected actual operation data from the PV monitoring system which located in Changwon. Gyeong-nam province during one year. While most of the PV system has security function which is limited to its inverter protection, in this study, based on fault data software program is developed for fault diagnosis in order to increase robustness of the PV system and minimize operation cost. Also, the program comprises machine learning algorithm based on fault data to classify its types of faults. It also presents economic loss of each PV module considering mean time to repair (Mi IK) occurred from the event of faults in the PV system As a result, the program helps faster fault diagnosis of the PV system and decreasing overall operation cost for the system operator.",
        "DOI": "10.5370/KIEE.2020.69.11.1682",
        "paper_author": "Cho K.H.",
        "affiliation_name": "Pusan National University",
        "affiliation_city": "Busan",
        "affiliation_country": "South Korea",
        "affiliation_id": "60008783",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Exploring Edge Computing for Multitier Industrial Control",
        "publication": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
        "citied_by": "32",
        "cover_date": "2020-11-01",
        "Abstract": "Industrial automation traditionally relies on local controllers implemented on microcontrollers or programmable logic controllers. With the emergence of edge computing, however, industrial automation evolves into a distributed two-tier computing architecture comprising local controllers and edge servers that communicate over wireless networks. Compared to local controllers, edge servers provide larger computing capacity at the cost of data loss over wireless networks. This article presents switching multitier control (SMC) to exploit edge computing for industrial control. SMC dynamically optimizes control performance by switching between local and edge controllers in response to changing network conditions. SMC employs a data-driven approach to derive switching policies based on classification models trained based on simulations while guaranteeing system stability based on an extended Simplex approach tailored for two-tier platforms. To evaluate the performance of industrial control over edge computing platforms, we have developed WCPS-EC, a real-time hybrid simulator that integrates simulated plants, real computing platforms, and real or simulated wireless networks. In a case study of an industrial robotic control system, SMC significantly outperformed both a local controller and an edge controller in face of varying data loss in a wireless network.",
        "DOI": "10.1109/TCAD.2020.3012648",
        "paper_author": "Ma Y.",
        "affiliation_name": "McKelvey School of Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60105336",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Optimizing Discharge Efficiency of Reconfigurable Battery with Deep Reinforcement Learning",
        "publication": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
        "citied_by": "8",
        "cover_date": "2020-11-01",
        "Abstract": "Cell imbalance in a multicell battery occurs over time due to varying operating environments. This imbalance leads to overall inefficiency in battery discharging due to the relatively weak cells in the battery. Reconfiguring the cells in the battery is one option for addressing the problem, but relevant circuits may lead to severe safety issues. In this article, we aim to optimize the discharge efficiency of a multicell battery using safety-supplemented hardware. To this end, we first design a cell string-level reconfiguration scheme that is safe in hardware operations and also provides scalability due to the low switching complexity. Second, we propose a machine learning-based run-time switch control that considers various battery-related factors, such as the state of charge, state of health, temperature, and current distributions. Specifically, by exploiting the deep reinforcement learning (DRL) technique, we train the complex relationship among the battery factors and derive the best switch configuration in run-time. We implemented a hardware prototype, validated its functionalities, and evaluated the efficacy of the DRL-based control policy. The experimental results showed that the proposed scheme, along with the optimization method, improves the discharge efficiency of multicell batteries. In particular, the discharge efficiency gain is maximized when the cells constituting the battery are unevenly distributed in terms of cell health and exposed temperature.",
        "DOI": "10.1109/TCAD.2020.3012230",
        "paper_author": "Jeon S.",
        "affiliation_name": "Yonsei University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60016912",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Constructing a novel early warning algorithm for global budget payments",
        "publication": "Mathematics",
        "citied_by": "2",
        "cover_date": "2020-11-01",
        "Abstract": "The National Health Insurance Administration of Taiwan has implemented global budget payments, the Diagnosis-Related Group (DRG) inpatient diagnosis-related group payment system, and the same-disease payment system, in order to decrease the financial burden of medical expenditure. However, the benefit system reduces the income of doctors and hospitals. This study proposed an early warning payment algorithm that applies data analytics technology to diabetes hospitalizationand treatment-related fees. A model was constructed based on the characteristics of the Exponentially Weighted Moving Average (EWMA) algorithm to develop control charts, which were first employed using the 2001–2017 health insurance statistical database released by the Department of Health Insurance (DHI). This model was used to simulate data from inpatients with diabetes, to create an early warning algorithm for diagnosis-related groups’ (DRGs’) medical payments as well as to measure its accuracy. This study will provide a reference for the formulation of payment policies by the DHI.",
        "DOI": "10.3390/math8112006",
        "paper_author": "Chang C.W.",
        "affiliation_name": "National Taiwan University of Sport",
        "affiliation_city": "Taichung",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60013720",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The hidden pandemic of family violence during COVID-19: Unsupervised learning of tweets",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "105",
        "cover_date": "2020-11-01",
        "Abstract": "Background: Family violence (including intimate partner violence/domestic violence, child abuse, and elder abuse) is a hidden pandemic happening alongside COVID-19. The rates of family violence are rising fast, and women and children are disproportionately affected and vulnerable during this time. Objective: This study aims to provide a large-scale analysis of public discourse on family violence and the COVID-19 pandemic on Twitter. Methods: We analyzed over 1 million tweets related to family violence and COVID-19 from April 12 to July 16, 2020. We used the machine learning approach Latent Dirichlet Allocation and identified salient themes, topics, and representative tweets. Results: We extracted 9 themes from 1,015,874 tweets on family violence and the COVID-19 pandemic: (1) increased vulnerability: COVID-19 and family violence (eg, rising rates, increases in hotline calls, homicide); (2) types of family violence (eg, child abuse, domestic violence, sexual abuse); (3) forms of family violence (eg, physical aggression, coercive control); (4) risk factors linked to family violence (eg, alcohol abuse, financial constraints, guns, quarantine); (5) victims of family violence (eg, the LGBTQ [lesbian, gay, bisexual, transgender, and queer or questioning] community, women, women of color, children); (6) social services for family violence (eg, hotlines, social workers, confidential services, shelters, funding); (7) law enforcement response (eg, 911 calls, police arrest, protective orders, abuse reports); (8) social movements and awareness (eg, support victims, raise awareness); and (9) domestic violence–related news (eg, Tara Reade, Melissa DeRosa). Conclusions: This study overcomes limitations in the existing scholarship where data on the consequences of COVID-19 on family violence are lacking. We contribute to understanding family violence during the pandemic by providing surveillance via tweets. This is essential for identifying potentially useful policy programs that can offer targeted support for victims and survivors as we prepare for future outbreaks.",
        "DOI": "10.2196/24361",
        "paper_author": "Xue J.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Q-Rank: Reinforcement Learning for Recommending Algorithms to Predict Drug Sensitivity to Cancer Therapy",
        "publication": "IEEE Journal of Biomedical and Health Informatics",
        "citied_by": "20",
        "cover_date": "2020-11-01",
        "Abstract": "In personalized medicine, a challenging task is to identify the most effective treatment for a patient. In oncology, several computational models have been developed to predict the response of drugs to therapy. However, the performance of these models depends on multiple factors. This paper presents a new approach, called Q-Rank, to predict the sensitivity of cell lines to anti-cancer drugs. Q-Rank integrates different prediction algorithms and identifies a suitable algorithm for a given application. Q-Rank is based on reinforcement learning methods to rank prediction algorithms on the basis of relevant features (e.g., omics characterization). The best-ranked algorithm is recommended and used to predict the response of drugs to therapy. Our experimental results indicate that Q-Rank outperforms the integrated models in predicting the sensitivity of cell lines to different drugs.",
        "DOI": "10.1109/JBHI.2020.3004663",
        "paper_author": "Daoud S.",
        "affiliation_name": "Ecole Nationale d'Ingénieurs de Sfax",
        "affiliation_city": "Sfax",
        "affiliation_country": "Tunisia",
        "affiliation_id": "60070321",
        "affiliation_state": "Sfax"
    },
    {
        "paper_title": "GIS-enabled digital twin system for sustainable evaluation of carbon emissions: A case study of Jeonju city, south Korea",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "36",
        "cover_date": "2020-11-01",
        "Abstract": "Despite the growing interest in digital twins (DTs) in geospatial technology, the scientific literature is still at the early stage, and concepts of DTs vary. In common perspectives, the primary goals of DTs are to reduce the uncertainty of the physical systems in real-world projects to reduce cost. Thus, this study is aimed at developing a structural schematic of a geographic information system (GIS)-enabled DT system and exploring geospatial technologies that can aid in deploying a DT system for a real-world project—in particular, for the sustainable evaluation of carbon emissions. The schematic includes three major phases: (1) data collection and visualization, (2) analytics, and (3) deployment. Three steps are designed to propose an optimal strategy to reduce carbon emissions in an urban area. In the analytics phase, mapping, machine learning algorithms, and spatial statistics are applied, mapping an ideal counterpart to physical assets. Furthermore, not only are GIS maps able to analyze geographic data that represent the counterparts of physical assets but can also display and analyze spatial relationships between physical assets. In the first step of the analytics phase, a GIS map spatially represented the most vulnerable area based on the values of carbon emissions computed according to the Intergovernmental Panel on Climate Change (IPCC) guidelines. Next, the radial basis function (RBF) kernel algorithm, a machine learning technique, was used to forecast spatial trends of carbon emissions. A backpropagation neural network (BPNN) was used to quantitatively determine which factor was the most influential among the four data sources: electricity, city gas, household waste, and vehicle. Then, a hot spot analysis was used to assess where high values of carbon emissions clustered in the study area. This study on the development of DTs contributes the following. First, with DTs, sustainable urban management systems will be improved and new insights developed more publicly. Ultimately, such improvements can reduce the failures of projects associated with urban planning and management. Second, the structural schematic proposed here is a data-driven approach; consequently, its outputs are more reliable and feasible. Ultimately, innovative approaches become available and services are transformed. Consequently, urban planners or policy makers can apply the system to scenario-based approaches.",
        "DOI": "10.3390/su12219186",
        "paper_author": "Park J.",
        "affiliation_name": "Myongji University",
        "affiliation_city": "Yongin",
        "affiliation_country": "South Korea",
        "affiliation_id": "60014200",
        "affiliation_state": "Gyeonggi-do"
    },
    {
        "paper_title": "Application of google earth engine cloud computing platform, sentinel imagery, and neural networks for crop mapping in Canada",
        "publication": "Remote Sensing",
        "citied_by": "67",
        "cover_date": "2020-11-01",
        "Abstract": "The ability of the Canadian agriculture sector to make better decisions and manage its operations more competitively in the long term is only as good as the information available to inform decision-making. At all levels of Government, a reliable flow of information between scientists, practitioners, policy-makers, and commodity groups is critical for developing and supporting agricultural policies and programs. Given the vastness and complexity of Canada’s agricultural regions, space-based remote sensing is one of the most reliable approaches to get detailed information describing the evolving state of the country’s environment. Agriculture and Agri-Food Canada (AAFC)-the Canadian federal department responsible for agriculture-produces the Annual Space-Based Crop Inventory (ACI) maps for Canada. These maps are valuable operational space-based remote sensing products which cover the agricultural land use and non-agricultural land cover found within Canada’s agricultural extent. Developing and implementing novel methods for improving these products are an ongoing priority of AAFC. Consequently, it is beneficial to implement advanced machine learning and big data processing methods along with open-access satellite imagery to effectively produce accurate ACI maps. In this study, for the first time, the Google Earth Engine (GEE) cloud computing platform was used along with an Artificial Neural Networks (ANN) algorithm and Sentinel-1,-2 images to produce an object-based ACI map for 2018. Furthermore, different limitations of the proposed method were discussed, and several suggestions were provided for future studies. The Overall Accuracy (OA) and Kappa Coefficient (KC) of the final 2018 ACI map using the proposed GEE cloud method were 77% and 0.74, respectively. Moreover, the average Producer Accuracy (PA) and User Accuracy (UA) for the 17 cropland classes were 79% and 77%, respectively. Although these levels of accuracies were slightly lower than those of the AAFC’s ACI map, this study demonstrated that the proposed cloud computing method should be investigated further because it was more efficient in terms of cost, time, computation, and automation.",
        "DOI": "10.3390/rs12213561",
        "paper_author": "Amani M.",
        "affiliation_name": "Wood Environment and Infrastructure Solutions",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "124654923",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Machine learning for prediction of energy in wheat production",
        "publication": "Agriculture (Switzerland)",
        "citied_by": "25",
        "cover_date": "2020-11-01",
        "Abstract": "The global population growth has led to a considerable rise in demand for wheat. Today, the amount of energy consumption in agriculture has also increased due to the need for sufficient food for the growing population. Thus, agricultural policymakers in most countries rely on prediction models to influence food security policies. This research aims to predict and reduce the amount of energy consumption in wheat production. Data were collected from the farms of Estahban city in Fars province of Iran by the Jihad Agricultural Department’s experts for 20 years from 1994 to 2013. In this study, a novel prediction method based on consumed energy in the production period is proposed. The model is developed based on artificial intelligence to forecast the output energy in wheat production and uses extreme learning machine (ELM) and support vector regression (SVR). In the experimental stage, the value of elevation metrics for the EVM and ELM was reported to be equal to 0.000000409 and 0.9531, respectively. Total input energy (consumed) is found to be 1,460,503.1 Mega Joules (MJ), and output energy (produced wheat) is 1,401,011.945 MJ for the Estahban. The result indicates the superiority of the ELM model to enhance the decisions of the agricultural policymakers.",
        "DOI": "10.3390/agriculture10110517",
        "paper_author": "Mostafaeipour A.",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60111656",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An lstm based generative adversarial architecture for robotic calligraphy learning system",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "7",
        "cover_date": "2020-11-01",
        "Abstract": "Robotic calligraphy is a very challenging task for the robotic manipulators, which can sustain industrial manufacturing. The active mechanism of writing robots require a large sized training set including sequence information of the writing trajectory. However, manual labelling work on those training data may cause the time wasting for researchers. This paper proposes a machine calligraphy learning system using a Long Short-Term Memory (LSTM) network and a generative adversarial network (GAN), which enables the robots to learn and generate the sequences of Chinese character stroke (i.e., writing trajectory). In order to reduce the size of the training set, a generative adversarial architecture combining an LSTM network and a discrimination network is established for a robotic manipulator to learn the Chinese calligraphy regarding its strokes. In particular, this learning system converts Chinese character stroke image into the trajectory sequences in the absence of the stroke trajectory writing sequence information. Due to its powerful learning ability in handling motion sequences, the LSTM network is used to explore the trajectory point writing sequences. Each generation process of the generative adversarial architecture contains a number of loops of LSTM. In each loop, the robot continues to write by following a new trajectory point, which is generated by LSTM according to the previously written strokes. The written stroke in an image format is taken as input to the next loop of the LSTM network until the complete stroke is finally written. Then, the final output of the LSTM network is evaluated by the discriminative network. In addition, a policy gradient algorithm based on reinforcement learning is employed to aid the robot to find the best policy. The experimental results show that the proposed learning system can effectively produce a variety of high-quality Chinese stroke writing.",
        "DOI": "10.3390/su12219092",
        "paper_author": "Chao F.",
        "affiliation_name": "Xiamen University",
        "affiliation_city": "Xiamen",
        "affiliation_country": "China",
        "affiliation_id": "60018205",
        "affiliation_state": "Fujian"
    },
    {
        "paper_title": "Forecasting spatio-temporal dynamics on the land surface using earth observation data—a review",
        "publication": "Remote Sensing",
        "citied_by": "22",
        "cover_date": "2020-11-01",
        "Abstract": "Reliable forecasts on the impacts of global change on the land surface are vital to inform the actions of policy and decision makers to mitigate consequences and secure livelihoods. Geospatial Earth Observation (EO) data from remote sensing satellites has been collected continuously for 40 years and has the potential to facilitate the spatio-temporal forecasting of land surface dynamics. In this review we compiled 143 papers on EO-based forecasting of all aspects of the land surface published in 16 high-ranking remote sensing journals within the past decade. We analyzed the literature regarding research focus, the spatial scope of the study, the forecasting method applied, as well as the temporal and technical properties of the input data. We categorized the identified forecasting methods according to their temporal forecasting mechanism and the type of input data. Time-lagged regressions which are predominantly used for crop yield forecasting and approaches based on Markov Chains for future land use and land cover simulation are the most established methods. The use of external climate projections allows the forecasting of numerical land surface parameters up to one hundred years into the future, while auto-regressive time series modeling can account for intra-annual variances. Machine learning methods have been increasingly used in all categories and multivariate modeling that integrates multiple data sources appears to be more popular than univariate auto-regressive modeling despite the availability of continuously expanding time series data. Regardless of the method, reliable EO-based forecasting requires high-level remote sensing data products and the resulting computational demand appears to be the main reason that most forecasts are conducted only on a local scale. In the upcoming years, however, we expect this to change with further advances in the field of machine learning, the publication of new global datasets, and the further establishment of cloud computing for data processing.",
        "DOI": "10.3390/rs12213513",
        "paper_author": "Koehler J.",
        "affiliation_name": "Deutsches Zentrum für Luft- und Raumfahrt (DLR)",
        "affiliation_city": "Koln",
        "affiliation_country": "Germany",
        "affiliation_id": "60007798",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Dynamic topology reconfiguration of boltzmann machines on quantum annealers",
        "publication": "Entropy",
        "citied_by": "8",
        "cover_date": "2020-11-01",
        "Abstract": "Boltzmann machines have useful roles in deep learning applications, such as generative data modeling, initializing weights for other types of networks, or extracting efficient representations from high-dimensional data. Most Boltzmann machines use restricted topologies that exclude looping connectivity, as such connectivity creates complex distributions that are difficult to sample. We have used an open-system quantum annealer to sample from complex distributions and implement Boltzmann machines with looping connectivity. Further, we have created policies mapping Boltzmann machine variables to the quantum bits of an annealer. These policies, based on correlation and entropy metrics, dynamically reconfigure the topology of Boltzmann machines during training and improve performance.",
        "DOI": "10.3390/e22111202",
        "paper_author": "Liu J.",
        "affiliation_name": "USC Viterbi School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60143535",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "The temperature prediction of permanent magnet synchronous machines based on proximal policy optimization",
        "publication": "Information (Switzerland)",
        "citied_by": "6",
        "cover_date": "2020-11-01",
        "Abstract": "Accurate temperature prediction plays an important role in the thermal protection of permanent magnet synchronous motors. A temperature prediction method of permanent magnet synchronous machines (PMSMs) based on proximal policy optimization is proposed. In the proposed method, the actor-critic framework of reinforcement learning is introduced to model the effective temperature prediction mechanism, and the correlations between the input features are then analyzed to select the appropriate input features. Finally, the simplified proximal policy optimization algorithm is introduced to optimize the value of the prediction temperature of PMSMs. Experimental results reveal the high accuracy and reliability of the proposed method compared with an exponential weighted moving average method (EWMA), a recurrent neural network (RNN), and long short-term memory (LSTM).",
        "DOI": "10.3390/info11110495",
        "paper_author": "Cen Y.",
        "affiliation_name": "Zhejiang University of Science and Technology",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60017431",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Battery-Involved Energy Management for Hybrid Electric Bus Based on Expert-Assistance Deep Deterministic Policy Gradient Algorithm",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "161",
        "cover_date": "2020-11-01",
        "Abstract": "Energy management is an enabling technique to guarantee the reliability and economy of hybrid electric systems. This paper proposes a novel machine learning-based energy management strategy for a hybrid electric bus (HEB), with an emphasized consciousness of both thermal safety and degradation of the onboard lithium-ion battery (LIB) system. Firstly, the deep deterministic policy gradient (DDPG) algorithm is combined with an expert-assistance system, for the first time, to enhance the 'cold start' performance and optimize the power allocation of HEB. Secondly, in the framework of the proposed algorithm, the penalties to over-temperature and LIB degradation are embedded to improve the management quality in terms of the thermal safety enforcement and overall driving cost reduction. The proposed strategy is tested under different road missions to validate its superiority over state-of-the-art techniques in terms of training efficiency and optimization performance.",
        "DOI": "10.1109/TVT.2020.3025627",
        "paper_author": "Wu J.",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016835",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Coactive design of explainable agent-based task planning and deep reinforcement learning for human-UAVs teamwork",
        "publication": "Chinese Journal of Aeronautics",
        "citied_by": "50",
        "cover_date": "2020-11-01",
        "Abstract": "Unmanned Aerial Vehicles (UAVs) are useful in dangerous and dynamic tasks such as search-and-rescue, forest surveillance, and anti-terrorist operations. These tasks can be solved better through the collaboration of multiple UAVs under human supervision. However, it is still difficult for human to monitor, understand, predict and control the behaviors of the UAVs due to the task complexity as well as the black-box machine learning and planning algorithms being used. In this paper, the coactive design method is adopted to analyze the cognitive capabilities required for the tasks and design the interdependencies among the heterogeneous teammates of UAVs or human for coherent collaboration. Then, an agent-based task planner is proposed to automatically decompose a complex task into a sequence of explainable subtasks under constrains of resources, execution time, social rules and costs. Besides, a deep reinforcement learning approach is designed for the UAVs to learn optimal policies of a flocking behavior and a path planner that are easy for the human operator to understand and control. Finally, a mixed-initiative action selection mechanism is used to evaluate the learned policies as well as the human's decisions. Experimental results demonstrate the effectiveness of the proposed methods.",
        "DOI": "10.1016/j.cja.2020.05.001",
        "paper_author": "WANG C.",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60024350",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Face hallucination by attentive sequence optimization with reinforcement learning",
        "publication": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citied_by": "26",
        "cover_date": "2020-11-01",
        "Abstract": "Face hallucination is a domain-specific super-resolution problem that aims to generate a high-resolution (HR) face image from a low-resolution (LR) input. In contrast to the existing patch-wise super-resolution models that divide a face image into regular patches and independently apply LR to HR mapping to each patch, we implement deep reinforcement learning and develop a novel attention-aware face hallucination (Attention-FH) framework, which recurrently learns to attend a sequence of patches and performs facial part enhancement by fully exploiting the global interdependency of the image. Specifically, our proposed framework incorporates two components: a recurrent policy network for dynamically specifying a new attended region at each time step based on the status of the super-resolved image and the past attended region sequence, and a local enhancement network for selected patch hallucination and global state updating. The Attention-FH model jointly learns the recurrent policy network and local enhancement network through maximizing a long-term reward that reflects the hallucination result with respect to the whole HR image. Extensive experiments demonstrate that our Attention-FH significantly outperforms the state-of-the-art methods on in-the-wild face images with large pose and illumination variations.",
        "DOI": "10.1109/TPAMI.2019.2915301",
        "paper_author": "Shi Y.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021182",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Predicting Coronavirus Disease 2019 Infection Risk and Related Risk Drivers in Nursing Homes: A Machine Learning Approach",
        "publication": "Journal of the American Medical Directors Association",
        "citied_by": "32",
        "cover_date": "2020-11-01",
        "Abstract": "Objective: Inform coronavirus disease 2019 (COVID-19) infection prevention measures by identifying and assessing risk and possible vectors of infection in nursing homes (NHs) using a machine-learning approach. Design: This retrospective cohort study used a gradient boosting algorithm to evaluate risk of COVID-19 infection (ie, presence of at least 1 confirmed COVID-19 resident) in NHs. Setting and Participants: The model was trained on outcomes from 1146 NHs in Massachusetts, Georgia, and New Jersey, reporting COVID-19 case data on April 20, 2020. Risk indices generated from the model using data from May 4 were prospectively validated against outcomes reported on May 11 from 1021 NHs in California. Methods: Model features, pertaining to facility and community characteristics, were obtained from a self-constructed dataset based on multiple public and private sources. The model was assessed via out-of-sample area under the receiver operating characteristic curve (AUC), sensitivity, and specificity in the training (via 10-fold cross-validation) and validation datasets. Results: The mean AUC, sensitivity, and specificity of the model over 10-fold cross-validation were 0.729 [95% confidence interval (CI) 0.690‒0.767], 0.670 (95% CI 0.477‒0.862), and 0.611 (95% CI 0.412‒0.809), respectively. Prospective out-of-sample validation yielded similar performance measures (AUC 0.721; sensitivity 0.622; specificity 0.713). The strongest predictors of COVID-19 infection were identified as the NH's county's infection rate and the number of separate units in the NH; other predictors included the county's population density, historical Centers of Medicare and Medicaid Services cited health deficiencies, and the NH's resident density (in persons per 1000 square feet). In addition, the NH's historical percentage of non-Hispanic white residents was identified as a protective factor. Conclusions and Implications: A machine-learning model can help quantify and predict NH infection risk. The identified risk factors support the early identification and management of presymptomatic and asymptomatic individuals (eg, staff) entering the NH from the surrounding community and the development of financially sustainable staff testing initiatives in preventing COVID-19 infection.",
        "DOI": "10.1016/j.jamda.2020.08.030",
        "paper_author": "Sun C.L.F.",
        "affiliation_name": "MIT Sloan School of Management",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60014228",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Patient coded severity and payment penalties under the hospital readmissions reduction program: A machine learning approach",
        "publication": "Medical Care",
        "citied_by": "1",
        "cover_date": "2020-11-01",
        "Abstract": "Objective:The objective of this study was to examine variation in hospital responses to the Centers for Medicare and Medicaid's expansion of allowable secondary diagnoses in January 2011 and its association with financial penalties under the Hospital Readmission Reduction Program (HRRP).Data Sources/Study Setting:Medicare administrative claims for discharges between July 2008 and June 2011 (N=3102 hospitals).Research Design:We examined hospital variation in response to the expansion of secondary diagnoses by describing changes in comorbidity coding before and after the policy change. We used random forest machine learning regression to examine hospital characteristics associated with coded severity. We then used a 2-part model to assess whether variation in coded severity was associated with readmission penalties.Results:Changes in severity coding varied considerably across hospitals. Random forest models indicated that greater baseline levels of condition categories, case-mix index, and hospital size were associated with larger changes in condition categories. Hospital coding of an additional condition category was associated with a nonsignificant 3.8 percentage point increase in the probability for penalties under the HRRP (SE=2.2) and a nonsignificant 0.016 percentage point increase in penalty amount (SE=0.016).Conclusion:Changes in patient coded severity did not affect readmission penalties.",
        "DOI": "10.1097/MLR.0000000000001396",
        "paper_author": "Li J.",
        "affiliation_name": "Maxwell School of Citizenship and Public Affairs",
        "affiliation_city": "Syracuse",
        "affiliation_country": "United States",
        "affiliation_id": "60118347",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Investigating the capabilities of information technologies to support policymaking in COVID-19 crisis management; a systematic review and expert opinions",
        "publication": "European Journal of Clinical Investigation",
        "citied_by": "14",
        "cover_date": "2020-11-01",
        "Abstract": "Background: Today, numerous countries are fighting to protect themselves against the Covid-19 crisis, while the policymakers are confounded and empty handed in dealing with this chaotic circumstance. The infection and its impacts have made it difficult to make optimal and suitable decisions. New information technologies play significant roles in such critical situations to address and relieve stress during the coronavirus crisis. This article endeavours to recognize the challenges policymakers have typically experienced during pandemic diseases, including Covid-19, and, accordingly, new information technology capabilities to encounter with them. Material and methods: The current study utilizes the synthesis of findings of experts’ opinions within the systematic review process as the research method to recognize the best available evidence drawn from text and opinion to offer practical guidance for policymakers. Results: The results illustrate that the challenges fall into two categories including; encountering the disease and reducing the results of the disease. Furthermore, Internet of things, cloud computing, machine learning and social networking play the most significant roles to address these challenges.",
        "DOI": "10.1111/eci.13391",
        "paper_author": "Mehraeen M.",
        "affiliation_name": "Ferdowsi University of Mashhad",
        "affiliation_city": "Mashhad",
        "affiliation_country": "Iran",
        "affiliation_id": "60001800",
        "affiliation_state": "Razavi Khorasan"
    },
    {
        "paper_title": "Answerable and Unanswerable Questions in Risk Analysis with Open-World Novelty",
        "publication": "Risk Analysis",
        "citied_by": "5",
        "cover_date": "2020-11-01",
        "Abstract": "Decision analysis and risk analysis have grown up around a set of organizing questions: what might go wrong, how likely is it to do so, how bad might the consequences be, what should be done to maximize expected utility and minimize expected loss or regret, and how large are the remaining risks? In probabilistic causal models capable of representing unpredictable and novel events, probabilities for what will happen, and even what is possible, cannot necessarily be determined in advance. Standard decision and risk analysis questions become inherently unanswerable (“undecidable”) for realistically complex causal systems with “open-world” uncertainties about what exists, what can happen, what other agents know, and how they will act. Recent artificial intelligence (AI) techniques enable agents (e.g., robots, drone swarms, and automatic controllers) to learn, plan, and act effectively despite open-world uncertainties in a host of practical applications, from robotics and autonomous vehicles to industrial engineering, transportation and logistics automation, and industrial process control. This article offers an AI/machine learning perspective on recent ideas for making decision and risk analysis (even) more useful. It reviews undecidability results and recent principles and methods for enabling intelligent agents to learn what works and how to complete useful tasks, adjust plans as needed, and achieve multiple goals safely and reasonably efficiently when possible, despite open-world uncertainties and unpredictable events. In the near future, these principles could contribute to the formulation and effective implementation of more effective plans and policies in business, regulation, and public policy, as well as in engineering, disaster management, and military and civil defense operations. They can extend traditional decision and risk analysis to deal more successfully with open-world novelty and unpredictable events in large-scale real-world planning, policymaking, and risk management.",
        "DOI": "10.1111/risa.13553",
        "paper_author": "Cox L.A.",
        "affiliation_name": "University of Colorado Denver",
        "affiliation_city": "Denver",
        "affiliation_country": "United States",
        "affiliation_id": "60010307",
        "affiliation_state": "CO"
    },
    {
        "paper_title": "Synthesizing neighborhood preferences for automated vehicles",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "19",
        "cover_date": "2020-11-01",
        "Abstract": "Automated Vehicles (AVs) have gained substantial attention in recent years as the technology has matured. Researchers and policymakers envision that AV deployment will change transportation, development patterns, and other urban systems. Researchers have examined AVs and their potential impacts with two methods: (1) survey-based studies of AV preferences and (2) simulation-based estimation of secondary impacts of varied AV deployment strategies, such as Shared AVs (SAVs) and Privately-owned AVs (PAVs). While the preference survey literature can inform AV simulation studies, preference study results have so far not been integrated into simulation-based research. This lack of integration stems from the absence of data that measure preferences towards PAVs and SAVs at the neighborhood level. Existing preference studies usually investigate adoption likelihood without collecting appropriate information to link preferences to precise locations or neighborhoods. This study develops a microsimulation approach, incorporating machine learning and population synthesizing, to fill this data gap, leveraging a national AV perception survey (NAVPS) and the latest National Household Travel Survey (NHTS) data. The model is applied to San Francisco, CA, and Austin, TX, to test the concept. We validate the proposed model by comparing the spatial distributions of synthesized ride-hailing users and observed ride-hailing trips. High correlations between our synthesized user density and empirical trip distributions in two study areas, to some extent, verify our proposed modeling approach.",
        "DOI": "10.1016/j.trc.2020.102774",
        "paper_author": "Zhang W.",
        "affiliation_name": "Edward J. Bloustein School of Planning and Public Policy",
        "affiliation_city": "New Brunswick",
        "affiliation_country": "United States",
        "affiliation_id": "60119853",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "“The innovation governance dilemma: Alternatives to the precautionary principle”",
        "publication": "Technology in Society",
        "citied_by": "18",
        "cover_date": "2020-11-01",
        "Abstract": "This article reviews the four innovation governance approaches (the precautionary principle, responsible innovation, permissionless innovation, and the innovation principle), including definitions, important attributes, and weaknesses found in each approach, and when utilizing an affinity diagram as a tool of analysis, identifies their distinctive characteristics and common relationships. A discussion section summarizes the paper's findings and offers insights into where there is common relationships for further possible convergence between two innovation governance approaches – responsible innovation and permissionless innovation – that conceptually share substantially more in common than they contrast with each other. For addressing this challenge, the study recommends the following policy proposals: embrace artificial intelligence/machine learning/data analytics for risk management and regulatory adaptability; consider “soft law”as an option to public regulation; and substitute corporate citizenship for corporate social responsibility.",
        "DOI": "10.1016/j.techsoc.2020.101381",
        "paper_author": "Hemphill T.A.",
        "affiliation_name": "University of Michigan-Flint",
        "affiliation_city": "Flint",
        "affiliation_country": "United States",
        "affiliation_id": "60021492",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Network-level synchronized pavement repair and work zone policies: Optimal solution and rule-based approximation",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "21",
        "cover_date": "2020-11-01",
        "Abstract": "In pavement management systems, it is beneficial to consider the economies of scale stemming from the synchronization of repairs conducted on neighboring sections within a single work zone. However, finding the globally optimal solution of the repair and work zone policy for a large-scale pavement network along a long-term planning horizon can be computationally cumbersome. In this study, as a benchmark, we first propose an exact solution algorithm based on dynamic programming. Then we second propose a computationally feasible methodology, a time-invariant simplified rule, to determine desirable (near-optimal) policies. The proposed methodology is applied to two numerical studies: (i) Case 1 for a small-scale road pavement system to compare life cycle costs and computational times between the rule-based methodology and the exact solution algorithm, and (ii) Case 2 for a real-scale road pavement system to discuss the effectiveness of the rule-based methodology. In Case 1, the rule-based methodology derives a near-optimal solution with a significantly shorter computational time than the exact solution algorithm. Case 2 shows that the rule-based methodology can find a superior policy to the aggregation of the optimal solutions independently found for each of decomposed sub-systems in a feasible computational time. Through sensitivity analyses, we find that the repair and work zone policies should vary depending on the deterioration process, cost factors, and weight between agency and user costs for society's view or available budget for the agency's perspective.",
        "DOI": "10.1016/j.trc.2020.102797",
        "paper_author": "Mizutani D.",
        "affiliation_name": "Tohoku University",
        "affiliation_city": "Sendai",
        "affiliation_country": "Japan",
        "affiliation_id": "60008435",
        "affiliation_state": "Miyagi"
    },
    {
        "paper_title": "Explaining yield and gross margin gaps for sustainable intensification of the wheat-based systems in a Mediterranean climate",
        "publication": "Agricultural Systems",
        "citied_by": "30",
        "cover_date": "2020-11-01",
        "Abstract": "Closing the attainable yield and gross margin gaps are important for improving food security and reducing poverty in developing world. Closing these gaps requires quantifying them, identifying major factors constraining the attainable yield and gross margins, and developing mitigation measures. Past literature predominantly focused only on quantification of yield gaps, using yields from experimental stations as the potentially attainable yields. This body of literature overlooked the gaps in gross margins, and more importantly, factors responsible for these gaps – thereby failing to provide sufficient policy guidance to increase productivity. We used a random sample of 2296 fields in 21 major wheat-growing provinces of Morocco as a case study to carry analysis of both yield and gross margin gaps. We used the random forest model to identify factors responsible for variations in yield and gross margins. Our results show that average yield in rainfed areas was 0.9 t ha−1 with yield and gross margin gaps of 41% and 75%, respectively. In irrigated areas, average yield stands at 4.0 t ha−1 with yield and gross margin gaps of 29% and 34%, respectively – indicating that there is substantial scope for increasing yields and gross margins in both environments. In the rainfed environment, tillage method was the most important variable in determining yield, followed by quantity of phosphorus and nitrogen fertilizer, seed quality, and type of preceding crop. In the irrigated environment, preceding crop was the most important variable in explaining yield gap, followed by variety, seed quality, and quantities of nitrogen and phosphorus fertilizers. Grain yield and grain price were the most important variables explaining gross margins. Top performer farmers in both environments had applied higher quantities of inputs and hence incurred higher costs but still had higher nitrogen and phosphorus use efficiencies and higher gross margins than the rest as the yield gains more-than offset the increases in costs. Policy and institutional implications of these results are: 1) The irrigated environments should be targeted with efforts and incentives to motivate wider adoption of legume-based rotations; 2) Incentive mechanisms should be created to encourage farmers in the rainfed environments to adopt no-tillage, use more phosphorus and nitrogen fertilizers, and buy certified seeds; 3) Legume-based rotations reduce need for nitrogen and enhance phosphorus use efficiency in subsequent crop, targeting rainfed environments also with rotation can be used as a strategy to enhance sustainability of the production system and reducing financial burden of higher doses of chemical inputs.",
        "DOI": "10.1016/j.agsy.2020.102946",
        "paper_author": "Devkota M.",
        "affiliation_name": "International Center for Agricultural Research in the Dry Areas Syria",
        "affiliation_city": "Beirut",
        "affiliation_country": "Lebanon",
        "affiliation_id": "60072772",
        "affiliation_state": "Beirut Governorate"
    },
    {
        "paper_title": "Quantifying the impact of industrialization on blue carbon storage in the coastal area of Metropolitan Semarang, Indonesia",
        "publication": "Applied Geography",
        "citied_by": "46",
        "cover_date": "2020-11-01",
        "Abstract": "This study investigated the impact of the coastal industrialization policy which began in 2015 in Indonesia. Because this policy has effected physical change on the environment, it requires quantification to determine its driving factors, and to formulate solutions to its problems. In doing so, this research used remote sensing and machine learning techniques. Satellite data from Sentinel-2A were acquired for the years 2015 and 2019 for LULC model, and Landsat 8 OLI for industrial growth model in coastal area. The data were processed using QGIS 3.8 software with machine learning techniques, the Random Forest algorithm, and sci-kit learn library from Dzetsaka tools. The results showed that changes in land use and land cover areas significantly contributed to the loss of blue carbon storage of more than 20%. This finding confirms that the industrialization policy on the coastal area needs to be reviewed, and land use monitoring must be more strictly regulated.",
        "DOI": "10.1016/j.apgeog.2020.102319",
        "paper_author": "Sejati A.W.",
        "affiliation_name": "Universitas Diponegoro",
        "affiliation_city": "Semarang",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069385",
        "affiliation_state": "Central Java"
    },
    {
        "paper_title": "Why Is Modeling Coronavirus Disease 2019 So Difficult?",
        "publication": "Chest",
        "citied_by": "5",
        "cover_date": "2020-11-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.chest.2020.06.014",
        "paper_author": "Subramanian V.",
        "affiliation_name": "Case Western Reserve University",
        "affiliation_city": "Cleveland",
        "affiliation_country": "United States",
        "affiliation_id": "60000305",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Classification of multi-lingual tweets, into multi-class model using Naïve Bayes and semi-supervised learning",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "11",
        "cover_date": "2020-11-01",
        "Abstract": "Twitter is a social media platform which has been proven to be a great tool for insights of emotions about products, policies etc. through a 280-character message called tweet, containing direct and unfiltered emotions by a large amount of user population. Twitter has attracted the attention of many researchers owing to the fact that every tweet is by default, public in nature which is not the case with Facebook. This paper proposes a model for multi-lingual (English and Roman Urdu) classification of tweets over diversely ranged classes (non-hierarchical architecture). Previous work in tweet classification is narrowly focused either on single language or either on uniform set of classes at most (Positive, Extremely Positive, Negative and Extremely Negative). The proposed model is based on semi-supervised learning and proposed feature selection approach makes it less dependent and highly adaptive for grabbing trending terms. This makes it a strong contender of choice for streaming data. In the methodology, using Naïve Bayes learning algorithm for each phase, obtained remarkable accuracy of up to 87.16% leading from both KNN and SVM models which are popular for NLP and Text classification domains.",
        "DOI": "10.1007/s11042-020-09512-2",
        "paper_author": "Khan A.H.",
        "affiliation_name": "Habib University",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60194972",
        "affiliation_state": "Sindh"
    },
    {
        "paper_title": "Improving healthcare access management by predicting patient no-show behaviour",
        "publication": "Decision Support Systems",
        "citied_by": "33",
        "cover_date": "2020-11-01",
        "Abstract": "Low attendance levels in medical appointments have been associated with poor health outcomes and efficiency problems for service providers. To address this problem, healthcare managers could aim at improving attendance levels or minimizing the operational impact of no-shows by adapting resource allocation policies. However, given the uncertainty of patient behaviour, generating relevant information regarding no-show probabilities could support the decision-making process for both approaches. In this context many researchers have used multiple regression models to identify patient and appointment characteristics than can be used as good predictors for no-show probabilities. This work develops a Decision Support System (DSS) to support the implementation of strategies to encourage attendance, for a preventive care program targeted at underserved communities in Bogotá, Colombia. Our contribution to literature is threefold. Firstly, we assess the effectiveness of different machine learning approaches to improve the accuracy of regression models. In particular, Random Forest and Neural Networks are used to model the problem accounting for non-linearity and variable interactions. Secondly, we propose a novel use of Layer-wise Relevance Propagation in order to improve the explainability of neural network predictions and obtain insights from the modelling step. Thirdly, we identify variables explaining no-show probabilities in a developing context and study its policy implications and potential for improving healthcare access. In addition to quantifying relationships reported in previous studies, we find that income and neighbourhood crime statistics affect no-show probabilities. Our results will support patient prioritization in a pilot behavioural intervention and will inform appointment planning decisions.",
        "DOI": "10.1016/j.dss.2020.113398",
        "paper_author": "Barrera Ferro D.",
        "affiliation_name": "Southampton Business School",
        "affiliation_city": "Southampton",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60176937",
        "affiliation_state": "Hampshire"
    },
    {
        "paper_title": "Recurrent neural network reveals overwhelming sentiment against 2017 review of US monuments from humans and bots",
        "publication": "Conservation Letters",
        "citied_by": "3",
        "cover_date": "2020-11-01",
        "Abstract": "In the United States, the conservation of federal lands reflects a social history of public advocacy, public policy, and public comments. US federal agencies solicit public comments to scope for ideas, solve problems, and use the best available science for policy-making, legislation, and management. Online comment submission has led to staggering numbers of comments that are challenging to summarize. Here, we analyze comments received by the Department of the Interior in response to the proposed executive review of 27 national monuments designated and expanded between 1996 and 2016. We used a deep recurrent neural network (AWD-LSTM) to classify sentiment of 754,707 comments with higher precision and recall (F1-score = 0.98) than support vector machine and Naïve Bayes approaches. Over 97% of unique comments opposed the executive review, suggesting overwhelming support for maintaining national monument designations. Using cosine similarity, we also found that duplicates or potential automated software bots comprised over two-thirds of comments. We offer recommendations for comment submission, collection, and analysis in the current techno-political climate.",
        "DOI": "10.1111/conl.12747",
        "paper_author": "McDonough MacKenzie C.",
        "affiliation_name": "University of Maine",
        "affiliation_city": "Orono",
        "affiliation_country": "United States",
        "affiliation_id": "60008279",
        "affiliation_state": "ME"
    },
    {
        "paper_title": "Remote sensing-based framework to predict and assess the interannual variability of maize yields in Pakistan using Landsat imagery",
        "publication": "Computers and Electronics in Agriculture",
        "citied_by": "24",
        "cover_date": "2020-11-01",
        "Abstract": "Predicting crop yields and their spatio-temporal variability under a changing climate is a challenging but essential undertaking for crop management and policymaking purposes. The availability of information on risks associated with effects of climatic variability on agricultural activity outcomes is critical for stakeholders ranging from individual landowners to national economists alike. This research was conducted as a pilot study to (1) develop satellite remote sensing based estimates of maize acreage in a typical Maize growing region in Pakistan, (2) to develop a statistical-empirical model for prediction of maize yields, and finally, (3) to assess the influence of temperature on inter-annual variability in maize yields across a decade. A total of eight machine learning algorithms were tested for identifying maize growing operations in the Faisalabad district of Pakistan using Landsat 8 imagery. Classification models were evaluated via 200 randomly selected ground-verified points across the study region. Results of the maize mapping exercise were used to estimate interannual maize yields using Landsat-derived multi-temporal normalized difference vegetation index (NDVI) and land surface temperature (LST) data as predictors. Predictors for the yield forecasting model were selected via principal component screening and were fed into a least absolute shrinkage and selection (LASSO) regression model. The yield model thus developed was applied to 10 years of past data (2006-2017) and validated against data recorded by government sources. Finally, predictions spanning the ten years were tested for effects of temperature variability to find evidence of influence of ambient temperature on maize yields. Results indicate that support vector machine classifiers work the best in this landscape (accuracies >90%) and reveal that maize cropping area may be underestimated in government sources by as much as 14%. The LASSO regression models also showed very good fits (validation R2 = 0.95) and were fairly accurate in tracking interannual variations in maize yields (R2 = 0.78.) Results also indicate that the maximum temperature has significant negative influence (R2 = 0.76, P < 0.0001) on maize yields in Faisalabad district. Methods presented in this study should be of use to policymakers for better formulating export-import policies and decisions governing food security issues in the larger region.",
        "DOI": "10.1016/j.compag.2020.105732",
        "paper_author": "Ahmad I.",
        "affiliation_name": "COMSATS University Islamabad",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60089631",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Urban ambient air temperature estimation using hyperlocal data from smart vehicle-borne sensors",
        "publication": "Computers, Environment and Urban Systems",
        "citied_by": "18",
        "cover_date": "2020-11-01",
        "Abstract": "High-quality temperature data at a finer spatio-temporal scale is critical for analyzing the risk of heat exposure and hazards in urban environments. The variability of urban landscapes makes cities a challenging environment for quantifying heat exposure. Most of the existing heat hazard studies have inherent limitations on two fronts; first, the spatio-temporal granularities are too coarse, and second, the inability to track the ambient air temperature (AAT) instead of land surface temperature (LST). Overcoming these limitations requires developing models for mapping the variability in heat exposure in urban environments. We investigated an integrated approach for mapping urban heat hazards by harnessing a diverse set of high-resolution measurements, including both ground-based and satellite-based temperature data. We mounted vehicle-borne mobile sensors on city buses to collect high-frequency temperature data throughout 2018 and 2019. Our research also incorporated key biophysical parameters and Landsat 8 LST data into Random Forest regression modeling to map the hyperlocal variability of heat hazard over areas not covered by the buses. The vehicle-borne temperature sensor data showed large temperature differences within the city, with the largest variations of up to 10 °C and morning-afternoon diurnal changes at a magnitude around 20 °C. Random Forest modeling on noontime (11:30 am – 12:30 pm) data to predict AAT produced accurate results with a mean absolute error of 0.29 °C and successfully showcased the enhanced granularity in urban heat hazard mapping. These maps revealed well-defined hyperlocal variabilities in AAT, which were not evident with other research approaches. Urban core and dense residential areas revealed larger than 5 °C AAT differences from their nearby green spaces. The sensing framework developed in this study can be easily implemented in other urban areas, and findings from this study will be beneficial in understanding the heat vulnerabilities of individual communities. It can be used by the local government to devise targeted hazard mitigation efforts such as increasing green space, developing better heat-safety policies, and exposure warning for workers.",
        "DOI": "10.1016/j.compenvurbsys.2020.101538",
        "paper_author": "Yin Y.",
        "affiliation_name": "University of Georgia",
        "affiliation_city": "Athens",
        "affiliation_country": "United States",
        "affiliation_id": "60029747",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "A cross-scale assessment of productivity–diversity relationships",
        "publication": "Global Ecology and Biogeography",
        "citied_by": "43",
        "cover_date": "2020-11-01",
        "Abstract": "Aim: Biodiversity and ecosystem productivity vary across the globe, and considerable effort has been made to describe their relationships. Biodiversity and ecosystem functioning research has traditionally focused on how experimentally controlled species richness affects net primary productivity (S → NPP) at small spatial grains. In contrast, the influence of productivity on richness (NPP → S) has been explored at many grains in naturally assembled communities. Mismatches in spatial scale between approaches have fuelled debate about the strength and direction of biodiversity–productivity relationships. Here, we examine the direction and strength of the influence of productivity on diversity (NPP → S) and the influence of diversity on productivity (S → NPP) and how these vary across spatial grains. Location: Contiguous USA. Time period: 1999–2015. Major taxa studied: Woody species (angiosperms and gymnosperms). Methods: Using data from North American forests at grains from local (672 m2) to coarse spatial units (median area = 35,677 km2), we assess relationships between diversity and productivity using structural equation and random forest models, while accounting for variation in climate, environmental heterogeneity, management and forest age. Results: We show that relationships between S and NPP strengthen with spatial grain. Within each grain, S → NPP and NPP → S have similar magnitudes, meaning that processes underlying S → NPP and NPP → S either operate simultaneously or that one of them is real and the other is an artefact. At all spatial grains, S was one of the weakest predictors of forest productivity, which was largely driven by biomass, temperature and forest management and age. Main conclusions: We conclude that spatial grain mediates relationships between biodiversity and productivity in real-world ecosystems and that results supporting predictions from each approach (NPP → S and S → NPP) serve as an impetus for future studies testing underlying mechanisms. Productivity–diversity relationships emerge at multiple spatial grains, which should widen the focus of national and global policy and research to larger spatial grains.",
        "DOI": "10.1111/geb.13165",
        "paper_author": "Craven D.",
        "affiliation_name": "Universidad Mayor",
        "affiliation_city": "Providencia",
        "affiliation_country": "Chile",
        "affiliation_id": "60005881",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Cooperative Wind Farm Control with Deep Reinforcement Learning and Knowledge-Assisted Learning",
        "publication": "IEEE Transactions on Industrial Informatics",
        "citied_by": "111",
        "cover_date": "2020-11-01",
        "Abstract": "Cooperative wind farm control is a complex problem due to wake effect, and it is hard to find the proper model. Reinforcement learning can find the optimal policy in a dynamic environment using 'trial and error,' but may damage the machine and cause high cost during the learning process. In order to address this challenge, this article proposes the knowledge-assisted reinforcement learning framework by combining the low-fidelity analytical model with a reinforcement learning framework. Moreover, the knowledge-assisted deep deterministic policy gradient (KA-DDPG) algorithm and three kinds of knowledge-assisted learning methods are proposed based on the framework. The proposed methods are tested in nine different scenarios of WFSim. The simulation results show that the KA-DDPG algorithm can reach the maximum power output and ensure safety during learning. In addition, the learning cost is reduced by accelerating the learning process.",
        "DOI": "10.1109/TII.2020.2974037",
        "paper_author": "Zhao H.",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60108865",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Almost politically acceptable criminal justice risk assessment",
        "publication": "Criminology and Public Policy",
        "citied_by": "7",
        "cover_date": "2020-11-01",
        "Abstract": "Research Summary: In criminal justice risk forecasting, one can prove that it is impossible to optimize accuracy and fairness at the same time. One can also prove that usually it is impossible optimize simultaneously all of the usual group definitions of fairness. In policy settings, one necessarily is left with tradeoffs about which many stakeholders will adamantly disagree. The result is a contentious stalemate. In this article, we offer a different approach. We do not seek perfectly accurate and perfectly fair risk assessments. We seek politically acceptable risk assessments. We describe and apply a machine learning approach that addresses many of the most visible claims of “racial bias” to arraignment data on 300,000 offenders. Regardless of whether such claims are true, we adjust our procedures to compensate. We train the algorithm on White offenders only and compute risk with test data separately for White offenders and Black offenders. Thus, the fitted, algorithm structure is the same for both groups; the algorithm treats all offenders as if they are White. But because White and Black offenders can bring different predictors distributions to the White-trained algorithm, we provide additional adjustments as needed. Policy Implications: Insofar as conventional machine learning procedures do not produce the accuracy and fairness that some stakeholders require, it is possible to alter conventional practice to respond explicitly to many salient stakeholder claims even if they are unsupported by the facts. The results can be a politically acceptable risk assessment tools.",
        "DOI": "10.1111/1745-9133.12500",
        "paper_author": "Berk R.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60006297",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Energy consumption prediction and diagnosis of public buildings based on support vector machine learning: A case study in China",
        "publication": "Journal of Cleaner Production",
        "citied_by": "180",
        "cover_date": "2020-11-01",
        "Abstract": "As one of the three major fields of building energy consumption, public buildings (PBs)are under pressure regarding energy saving and emission reductions, with PB energy consumption accounting for 38% of the total consumption. Thus, CO2 emissions released in PBs have become crucial for China in achieving its emission mitigation goal in the “Post Paris” period. This paper is the first to develop a support vector machine (SVM) method to predict and diagnose PB energy consumption based on 11 input parameters, including historical energy consumption data, climatic factors and time-cycle factors. Months with air-conditioning energy consumption in Wuhan were considered the study period, and we used June and July data for model prediction training, August data as the test set, and September data to diagnose the air conditioner energy consumption anomaly. The results show that air conditioning energy consumption was abnormal for four days in September. Relevant policies and suggestions are proposed based on the causal analysis. This research is expected to provide theoretical guidance and a practical data reference for building operations management.",
        "DOI": "10.1016/j.jclepro.2020.122542",
        "paper_author": "Liu Y.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60029306",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Energy management using non-intrusive load monitoring techniques – State-of-the-art and future research directions",
        "publication": "Sustainable Cities and Society",
        "citied_by": "177",
        "cover_date": "2020-11-01",
        "Abstract": "In recent years, the development of smart sustainable cities has become the primary focus among urban planners and policy makers to make responsible use of resources, conserve the environment and improve the well-being of the society. Energy management is an integral part of the smart sustainable cities development programme which involves conscious and efficient use of available energy resources towards attaining sustainability and self-reliance on energy systems. Building sector is one of the key sectors that utilize more energy. Therefore, efforts are being made to monitor and manage energy consumption effectively in residential and commercial buildings. In recent years, non-intrusive load monitoring (NILM) technique has become a popular and emerging approach to monitor events (on/off) and energy consumption of appliances/electrical utilities in buildings using single energy meter. The information about the energy consumption at the appliance level would help consumers to understand their appliance usage behavior and take necessary steps for reducing energy consumption. In this paper, we present the comprehensive review of state-of-the-art algorithms that have been explored by the researchers towards developing an accurate NILM system for effective energy management. Finally, potential applications of NILM in different domains and its future research directions are discussed.",
        "DOI": "10.1016/j.scs.2020.102411",
        "paper_author": "Gopinath R.",
        "affiliation_name": "Central Scientific Instruments Organization Chandigarh",
        "affiliation_city": "Chandigarh",
        "affiliation_country": "India",
        "affiliation_id": "60069478",
        "affiliation_state": "CH"
    },
    {
        "paper_title": "Land-based wind energy cost trends in Germany, Denmark, Ireland, Norway, Sweden and the United States",
        "publication": "Applied Energy",
        "citied_by": "44",
        "cover_date": "2020-11-01",
        "Abstract": "This paper presents work by the International Energy Agency's Task 26 ‘Cost of Wind Energy’ on technological and cost trends in land-based wind energy in six participating countries (Denmark, Germany, Ireland, Norway, Sweden, United States) and the European Union between 2008 and 2016. Results indicate that there is a general trend towards larger, taller machines with lower specific powers resulting in higher capacity factors, despite small falls in new site wind resources in most countries, while wind project capital costs and project finance costs also fell. This resulted in an average levelized cost of energy (LCOE) fall of 33% for new projects to 48€/MWh at the end of the study period. Analysis of the components of levelized cost change indicated that changes in specific power, financing cost and capital cost accounted for 45%, 25% and 17% respectively of the estimated reduction. It is therefore important that trends in technological factors such as specific power are considered when assessing wind energy learning rates, rather than just capital costs, which has been the primary focus heretofore. While LCOEs have fallen, the value of wind energy has fallen proportionately more, meaning grid parity appears no closer than at the beginning of the study. Policymakers must therefore consider both the cost and value of wind energy, and understand the volatility of this gap when designing land-based wind energy policy measures.",
        "DOI": "10.1016/j.apenergy.2020.114777",
        "paper_author": "Duffy A.",
        "affiliation_name": "Technological University Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland",
        "affiliation_id": "60012873",
        "affiliation_state": "Leinster"
    },
    {
        "paper_title": "Fuzzy-based computational intelligence to support screening decision in environmental impact assessment: A complementary tool for a case-by-case project appraisal",
        "publication": "Environmental Impact Assessment Review",
        "citied_by": "16",
        "cover_date": "2020-11-01",
        "Abstract": "Screening is a key stage in environmental impact assessment (EIA), but the most common approach based on policy delineation are inherently arbitrary. On the other hand, a case-by-case approach can be complex, slow, and costly. This paper introduces a computational intelligence based on hybrid fuzzy inference system (h-FIS), combining data-driven and expert knowledge, in order to assess its capability of supporting a case-by-case screening in project appraisal. For empirical research, a dataset with appraisal variables of projects highway was made available by a Brazilian environmental protection agency (EPA). Firstly, using this dataset, multivariate analyses were performed to find criteria (xi) capable of indicating statistically significant differences among projects, previously screened by EPA experts into three types (simplified, preliminary, and comprehensive) of environmental impact study (EIS). Then, h-FIS was built through machine learning, using the FRBCS·W algorithm, with xi as input predictors and the type of EIS as the output target. The performances of alternative approaches were compared using cross-validation accuracy tests and the kappa index, with a significance level of 0.05. As a result, the h-FIS achieved accuracy of 92.6% and a kappa index of 0.88, which represented almost perfect agreement between the screening decision provided by the h-FIS and the one performed by the EPA experts. In conclusion, the fuzzy-based computational intelligence was capable of dealing with the complexity involved in screening decision. Therefore h-FIS be considered a promising complementary tool for a case-by-case project appraisal in EIA. For further advances, future research should assess other algorithms, such as genetic fuzzy systems, in order to strengthen the proposed system and make it generally applicable in other projects subject to EIA.",
        "DOI": "10.1016/j.eiar.2020.106446",
        "paper_author": "Bressane A.",
        "affiliation_name": "Universidade Estadual Paulista \"Júlio de Mesquita Filho\"",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil",
        "affiliation_id": "60006028",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "Grounded reality meets machine learning: A deep-narrative analysis framework for energy policy research",
        "publication": "Energy Research and Social Science",
        "citied_by": "25",
        "cover_date": "2020-11-01",
        "Abstract": "Text-based data sources like narratives and stories have become increasingly popular as critical insight generator in energy research and social science. However, their implications in policy application usually remain superficial and fail to fully exploit state-of-the-art resources which digital era holds for text analysis. This paper illustrates the potential of deep-narrative analysis in energy policy research using text analysis tools from the cutting-edge domain of computational social sciences, notably topic modelling. We argue that a nested application of topic modelling and grounded theory in narrative analysis promises advances in areas where manual-coding driven narrative analysis has traditionally struggled with directionality biases, scaling, systematisation and repeatability. The nested application of the topic model and the grounded theory goes beyond the frequentist approach of narrative analysis and introduces insight generation capabilities based on the probability distribution of words and topics in a text corpus. In this manner, our proposed methodology deconstructs the corpus and enables the analyst to answer research questions based on the foundational element of the text data structure. We verify theoretical compatibility through a meta-analysis of a state-of-the-art bibliographic database on energy policy, narratives and computational social science. Furthermore, we establish a proof-of-concept using a narrative-based case study on energy externalities in slum rehabilitation housing in Mumbai, India. We find that the nested application contributes to the literature gap on the need for multidisciplinary methodologies that can systematically include qualitative evidence into policymaking.",
        "DOI": "10.1016/j.erss.2020.101704",
        "paper_author": "Debnath R.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Can social media usage of scientific literature predict journal indices of AJG, SNIP and JCR? An altmetric study of economics",
        "publication": "Scientometrics",
        "citied_by": "15",
        "cover_date": "2020-11-01",
        "Abstract": "Altmetrics are often praised as an alternative or complement to classic bibliometric metrics, especially in the social sciences discipline. However, empirical investigations of altmetrics concerning the social sciences are scarce. This study investigates the extent to which economic research is shared on social media platforms with an emphasis on mentions in policy documents in addition to other mentions such as Twitter or Facebook. Moreover, this study explores machine learning models to predict the likelihood of a research article being classified into the top-quality tier of a journal ranking based on the altmetric mentions. The included journal rankings are the academic journal guide (AJG), source normalized impact per paper (SNIP) and journal citation reports (JCR). The investigated journals have been selected based on the AJG list and extracted from Altmetric.com data. After applying extensive data cleaning on the extracted data, a final set of 55,560 journal article records is obtained. The results indicate that the average number of policy mentions of the publications of economics journals is higher than the other subject areas included in the AJG list. Moreover, the publications in top-ranking economic journals are more likely to have a higher average number of policy mentions. Policy and Twitter mentions are presented as the most significant and informative social media mentions in demonstrating the broader impact and dissemination of Economics discipline followed by Blogs, Facebook, Wikipedia, and News. The results show that Support Vector Machine and Logistic Regression performed best in classifying the journal ranking tiers i.e. SNIP-based with 77% accuracy, JCR-based with 71% accuracy, and AJG-based with 66% accuracy. The models classified the ranking tier AJG18 with lower accuracy than SNIP and JCR. This might be because the AJG18 rankings are based on expert opinion, whereas SNIP and JCR are based on citations.",
        "DOI": "10.1007/s11192-020-03613-3",
        "paper_author": "Drongstrup D.",
        "affiliation_name": "Syddansk Universitet",
        "affiliation_city": "Odense",
        "affiliation_country": "Denmark",
        "affiliation_id": "60019160",
        "affiliation_state": "Syddanmark"
    },
    {
        "paper_title": "Examining the potential of textual big data analytics for public policy decision-making: A case study with driverless cars in Denmark",
        "publication": "Transport Policy",
        "citied_by": "33",
        "cover_date": "2020-11-01",
        "Abstract": "The simultaneous growth of textual data and the advancements within Text Analytics enables organisations to exploit this kind of unstructured data, and tap into previously hidden knowledge. However, the utilisation of this valuable resource is still insufficiently unveiled in terms of transport policy decision-making. This research aims to further examine the potential of textual big data analytics in transportation through a real-life case study. The case study, framed together with the Danish Road Directorate or Vejdirektoratet, was designed to assess public opinion towards the adoption of driverless cars in Denmark. Traditionally, the opinion of the public has often been captured by means of surveys for the problem owner. Our study provides demonstrations in which opinion towards the adoption of driverless cars is examined through the analysis of newspaper articles and tweets using topic modelling, document classification, and sentiment analysis. In this way, the research attends to the collective as well as individualised characteristics of public opinion. The analyses establish that Text Analytics may be used as a complement to surveys, in order to extract additional knowledge which may not be captured through the use of surveys. In this regard, the Danish Road Directorate could find the usefulness while understanding the barriers in the results generated from our study, for supplementing their future data collection strategies. However there are also some methodological limitations that need to be addressed before a broader adoption of textual big data analytics for transport policy decision-making may take place.",
        "DOI": "10.1016/j.tranpol.2020.05.026",
        "paper_author": "Kinra A.",
        "affiliation_name": "Universität Bremen",
        "affiliation_city": "Bremen",
        "affiliation_country": "Germany",
        "affiliation_id": "60008293",
        "affiliation_state": "Bremen"
    },
    {
        "paper_title": "Feasibility of a citizen-driven hackathon to increase public engagement and solutions to address the opioid crisis",
        "publication": "Journal of Substance Use",
        "citied_by": "4",
        "cover_date": "2020-11-01",
        "Abstract": "Background: Interdisciplinary approaches are needed to address complex societal problems, such as the opioid crisis. We sought to explore the feasibility and potential issues encountered in planning and implementing a 24-hour hackathon competition to bring together teams from law enforcement, public health, and data science to develop solutions to the opioid epidemic. Methods: We enlisted an advisory board and planning committee, including key stakeholders (e.g., high-level representatives from government agencies) to plan the event. Teams completed an online registration form with questions about team composition. Each team captain completed a survey at the event describing prior experiences with their team, knowledge and interest around the opioid epidemic, and hackathon expectations. Results: Twenty-nine teams (108 individuals) registered. Seventy-six percent had a technical/engineering background. Participants were from industry (55%), academia (30%), public health/medicine (9%), and government/public policy (6%). Nineteen teams attended the event. Team captains were primarily 18–29 years of age, had moderate experience and interest in the opioid crisis, and had never attended an opioid-related event. Conclusions: It is feasible to implement a 24-hour opioid-focused hackathon and recruit teams/participants from a broad range of disciplines. We discuss the solutions developed, barriers encountered, and insights gained throughout the planning and implementation process.",
        "DOI": "10.1080/14659891.2020.1753833",
        "paper_author": "Soliz S.",
        "affiliation_name": "University of California, Los Angeles",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60027550",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Disaggregating “China, Inc.”: The Hierarchical Politics of WTO Entry",
        "publication": "Comparative Political Studies",
        "citied_by": "12",
        "cover_date": "2020-11-01",
        "Abstract": "How does state structure affect responses to globalization? This article examines why some parts of the Chinese state enacted more liberalizing policies than others in response to World Trade Organization (WTO) entry. It shows that, despite single-party rule, China’s WTO-era policy trajectories were neither top-down nor monolithic. Instead, central and subnational governments diverged in their policy responses. The study identifies three competing economic strategies from which these responses are drawn: market-replacing (directive), market-shaping (developmental), and market-enhancing (regulatory). The analysis uses an original dataset of Chinese industry regulations from 1978 to 2014 and employs machine learning methods in text analysis to identify words associated with each strategy. Combining tariff, industry, and textual data, the article demonstrates that the divergent strategies adopted by central and subnational governments are driven by each unit’s differential accountability to the WTO and by the diversity of that unit’s industrial base.",
        "DOI": "10.1177/0010414020912267",
        "paper_author": "Tan Y.",
        "affiliation_name": "University of Oregon",
        "affiliation_city": "Eugene",
        "affiliation_country": "United States",
        "affiliation_id": "60012317",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Why your neighbor matters: Positions in preferential trade agreement networks and export growth in global value chains",
        "publication": "Economics and Politics",
        "citied_by": "6",
        "cover_date": "2020-11-01",
        "Abstract": "In rapidly expanding global and regional preferential trade agreements (PTA) networks, policy-makers are keen to situate their countries in a better position, believing that a better position in PTA networks will help their economies trade more and grow faster. In this paper, we provide a theory that explains how changes in countries' PTA network positions affect their trade performance. We argue that a dense and deep “neighbor network” provides a country with a wide access to global value chains, better protection to investment, and strong credibility to their policy commitments. To measure trade performance, we compute value-added exports at the country, year, and industry level across 43 countries, 56 industries, and 15 years (2000–14). The estimation of network position effects is done by panel fixed-effects methods and the sample-splitting and cross-fitting double machine-learning method. The findings show that as a country's neighbors have deeper and wider PTA networks, the country's value-added exports grow faster. Also, the industry-level analysis shows that sectors heavily engaging in the fragmentation of production stages exhibit faster growth with the improvement of neighbor networks.",
        "DOI": "10.1111/ecpo.12152",
        "paper_author": "Park J.H.",
        "affiliation_name": "Seoul National University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60013682",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Complexity vulnerability analysis using symbolic execution",
        "publication": "Software Testing Verification and Reliability",
        "citied_by": "5",
        "cover_date": "2020-11-01",
        "Abstract": "We describe techniques based on symbolic execution for finding software vulnerabilities that are due to algorithmic complexity. Such vulnerabilities allow an attacker to mount denial-of-service attacks to deny service to benign users or to otherwise disable a software system. The techniques use an efficient guided symbolic execution of a program to compute bounds on the worst-case complexity (for increasing input sizes) and to generate test values that trigger the worst-case behaviours. The resulting bounds are fitted to a function to obtain a prediction of the worst-case program behaviour at any input size. Scalability is achieved by using path policies that guide the symbolic execution towards worst-case paths. The policies are learned from the worst-case results obtained with exhaustive exploration at small input sizes and are applied to guide exploration at larger input sizes, where unguided exhaustive exploration is not possible. To achieve precision in the analysis, the path policies take into account the history of choices made along the path when deciding which branch to execute next. Furthermore, the computation is contextpreserving, meaning that the decision for each branch depends on the history computed with respect to the enclosing method. We further report preliminary results on a complementary technique that uses machine learning for building the path policies that guide the search. The techniques are implemented in open-source projects that build on the Symbolic Pathfinder tool for analysing Java programs. Experimental evaluation shows that the techniques can find vulnerabilities in complex Java programs and can outperform previous symbolic approaches.",
        "DOI": "10.1002/stvr.1716",
        "paper_author": "Luckow K.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60027950",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Reinforcement Learning-Based Nearly Optimal Control for Constrained-Input Partially Unknown Systems Using Differentiator",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "18",
        "cover_date": "2020-11-01",
        "Abstract": "In this article, a synchronous reinforcement-learning-based algorithm is developed for input-constrained partially unknown systems. The proposed control also alleviates the need for an initial stabilizing control. A first-order robust exact differentiator is employed to approximate unknown drift dynamics. Critic, actor, and disturbance neural networks (NNs) are established to approximate the value function, the control policy, and the disturbance policy, respectively. The Hamilton-Jacobi-Isaacs equation is solved by applying the value function approximation technique. The stability of the closed-loop system can be ensured. The state and weight errors of the three NNs are all uniformly ultimately bounded. Finally, the simulation results are provided to verify the effectiveness of the proposed method.",
        "DOI": "10.1109/TNNLS.2019.2957287",
        "paper_author": "Guo X.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Learning-agent-based simulation for queue network systems",
        "publication": "Journal of the Operational Research Society",
        "citied_by": "6",
        "cover_date": "2020-11-01",
        "Abstract": "Established simulation methods generally require from the modeller a broad and detailed knowledge of the system under study. This paper proposes the application of Reinforcement Learning in an Agent-Based Simulation model to enable agents to define the necessary interaction rules. The model is applied to queue network systems, which are a proxy for broader applications, in order to be validated. Simulation tests compare results obtained from learning agents and results obtained from known good rules. The comparison shows that the learning model is able to learn efficient policies on the go, providing an interesting framework for simulation.",
        "DOI": "10.1080/01605682.2019.1633232",
        "paper_author": "Fuller D.B.",
        "affiliation_name": "Universidade Federal do Rio de Janeiro",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil",
        "affiliation_id": "60000036",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Characterising JUUL-related posts on Instagram",
        "publication": "Tobacco Control",
        "citied_by": "87",
        "cover_date": "2020-11-01",
        "Abstract": "Background JUUL, a high-tech, popular vaping device, was the first major electronic cigarette (e-cigarette) brand to incorporate social media into its marketing strategy. There is growing concern around the increasing use of JUUL and other electronic nicotine delivery devices among youth, and their potential to addict a new generation to nicotine. The current study analysed the amount and characteristics of JUUL-related posts on Instagram, a social media platform used frequently among youth and young adults. Methods Hashtag-based keyword queries (n=50) were used to collect JUUL-related posts from the Instagram application programming interface, March 2018-May 2018. Using a combination of machine learning methods, keyword algorithms and human coding, posts were characterised as featuring content related to product promotion, nicotine and addiction, youth culture and lifestyle. Results Keyword queries captured 14 838 JUUL-relevant posts by 5201 unique users. Over one-third of posts were promotional (eg, linked to commercial website) and 11% contained nicotine and addiction-related information. Approximately half of posts featured content related to youth (55%) or lifestyle (57%). Youth-related content or lifestyle appeals were also notably present within promotional posts and nicotine and addiction-related posts, respectively. Nicotine and addiction-related posts featured memes, hashtags (eg, #nichead, #juulbuzz) and tag lines (eg, 'more flavor, more buzz'). Conclusions Findings reveal a proliferation of JUUL-related content on Instagram, which focused on product promotion and nicotine and addiction that included youth culture and lifestyle appeals. Regulatory actions should focus on restricting promotional efforts for e-cigarette products, particularly on social media platforms where young people are a primary audience.",
        "DOI": "10.1136/tobaccocontrol-2018-054824",
        "paper_author": "Czaplicki L.",
        "affiliation_name": "Truth Initiative",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60033135",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Community College Students Who Attained a 4-Year Degree Accrued Lower Student Loan Debt than 4-Year Entrants Over 2 Decades: Is a 10 Percent Debt Accumulation Reduction Worth the Added “Risk”? If So, for Whom?",
        "publication": "Research in Higher Education",
        "citied_by": "13",
        "cover_date": "2020-11-01",
        "Abstract": "The study of student loan debt remains a timely and relevant higher education finance research and policy-oriented topic, especially when considering the alarming growth rates of student loan debt balances. The Quarterly Report on Household Debt and Credit released in May of 2018 shows that among all debt balances, student loans remain the only form of debt that virtually sextupled over the last 15-years, and this trend is not slowing down. Although aggregated trends are important, by definition they are limited in their capabilities to providing researchers, policy- and decision-makers with insights related to individual debt accumulation and, perhaps more importantly, with knowledge about the factors associated with variation of individual debt burden. Accordingly, the overarching goal of this study is to ameliorate this limitation in three meaningful ways. First, this is the first study that offers inferential estimates of the magnitude of student debt accumulation increase across two different decades (1991–2013) and institutional sectors (public 2- and 4-year colleges). Second, these estimates are based on student level undergraduate non-self-reported longitudinal loan debt disbursements. Third, the estimates not only account for individuals’ baseline differences at the moment of college entry, but also account for institution- and state-level indicators that took place during college enrollment and that may be related to the variation of student loan debt reliance. Two nationally representative samples (NELS and ELS) complemented with other institution- and state-level data were analyzed using doubly robust estimators build from propensity score weights and entropy balancing approaches that were robust to unobservable selection issues using Oster’s approach (J Bus Econ Stat 37(2):1–18, 2017). The results consistently indicated that, among all participants, student borrowing participation increased by 15 percentage points in the 2000s, compared to the 1990s, and individual debt accumulation at least doubled across decades. Notably, among 4-year degree holders, the 2-year path toward a 4-year degree consistently resulted in about 10% lower debt accumulation compared to the 4-year path toward a 4-year degree. Students who did not attain a 4-year degree were better served by having started college in the 2-year sector. In terms of overall debt increase, 4-year degree holders accrued about $8000 more on average than their counterparts did during the 1990s, however, the recent cohort also repaid about $11,000 more, on average (or three times as much), than participants did in the 1990s. These higher repayment behaviors observed among 4-year degree holders, resulted in similar amounts of their respective debt balances across decades. The implications are clear: students with higher propensities toward a 4-year degree attainment are likely to incur lower debt if they start college in the community college sector. However, before fully recommending this pathway, 2- and 4-year colleges’ articulation agreements should be strengthened to ease transfer and eventual degree completion. Without recommending consolidation or merger between 2- and 4-year institutions, researchers and policy makers can learn from the strategies implemented by successful cases such as Perimeter College and Georgia State. Finally, 4-year entrants with lower likelihood to attain a 4-year degree may be better served by beginning college in the 2-year sector instead. Predictive analytics and machine learning techniques can be used to identify these cases, as depicted in the discussion section of the study.",
        "DOI": "10.1007/s11162-019-09565-9",
        "paper_author": "González Canché M.S.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60006297",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "A blockchain-based federated learning: Concepts and applications",
        "publication": "Multidisciplinary Functions of Blockchain Technology in AI and IoT Applications",
        "citied_by": "1",
        "cover_date": "2020-10-30",
        "Abstract": "Conventional machine learning (ML) needs centralized training data to be present on a given machine or datacenter. The healthcare, finance, and other institutions where data sharing is prohibited require an approach for training ML models in secured architecture. Recently, techniques such as federated learning (FL), MIT Media Lab's Split Neural networks, blockchain, aim to address privacy and regulation of data. However, there are difference between the design principles of FL and the requirements of Institutions like healthcare, finance, etc., which needs blockchain-orchestrated FL having the following features: clients with their local data can define access policies to their data and define how updated weights are to be encrypted between the workers and the aggregator using blockchain technology and also prepares audit trail logs undertaken within network and it keeps actual list of participants hidden. This is expected to remove barriers in a range of sectors including healthcare, finance, security, logistics, governance, operations, and manufacturing.",
        "DOI": "10.4018/978-1-7998-5876-8.ch008",
        "paper_author": "Barai A.K.",
        "affiliation_name": "Indian Institute of Information Technology, Nagpur",
        "affiliation_city": "Nagpur",
        "affiliation_country": "India",
        "affiliation_id": "60272716",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "A mining policy based malicious encrypted traffic detection scheme",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "3",
        "cover_date": "2020-10-30",
        "Abstract": "Malicious encrypted traffic poses a great threat to cyber space owing to its ability to bypass traditional traffic detection schemes. Malicious encrypted traffic detection is a challenging task and has attracted researchers' attention nowadays. Specifically, the detection task is subject to difficult feature mining and unsatisfactory results. Therefore, a mining policy based detection scheme is proposed, which mines more efficient features based on a rule based mining strategy and achieves well learning effect with machine learning algorithm-LightGBM. In this scheme, raw traffic is parsed to log files with Bro and features are extracted based on connection-tetrad. Accordingly, the rule-based feature mining strategy is proposed based on several rules. Then features are fed to LightGBM to train a detection model. A set of experiments show that the feature mining strategy is effective and our work improves malicious encrypted traffic detection effect.",
        "DOI": "10.1145/3436369.3436479",
        "paper_author": "Chao D.",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022281",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Real time implementation of terminal security policies selection based on edge computing",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "1",
        "cover_date": "2020-10-30",
        "Abstract": "There are many kinds of terminals in the smart grid system, which have different functions and risks in the system. Different security policies are needed to protect the terminals. At the same time, the terminals will be subject to various attacks in operation. These attacks will change the security protection performance of terminals. Therefore, it is necessary to adjust the security policies in their operation. This paper proposes a real-time implementation method of terminal security policy selection under the edge computing based on the machine learning methods, which makes full use of the computing power of edge devices, adopts offline training and online judgment. The training of machine learning parameters can be completed in the edge side or in the cloud while the security strategies selection continues going on the edge computing side. By this way, the real-time training update and real-time selection of security policy in edge computing system are realized.",
        "DOI": "10.1088/1742-6596/1646/1/012061",
        "paper_author": "Xu A.",
        "affiliation_name": "China Southern Power Grid",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021684",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "CCSW'20: 2020 Cloud Computing Security Workshop",
        "publication": "Proceedings of the ACM Conference on Computer and Communications Security",
        "citied_by": "3",
        "cover_date": "2020-10-30",
        "Abstract": "Clouds and massive-scale computing infrastructures are starting to dominate computing and will likely continue to do so for the foreseeable future. Major cloud operators are now comprising millions of cores hosting substantial fractions of corporate and government IT infrastructure. CCSW is the world's premier forum bringing together researchers and practitioners in all security aspects of cloud-centric and outsourced computing, including: Side channel attacks; Practical cryptographic protocols for cloud security; Secure cloud resource virtualization mechanisms; Secure data management outsourcing (e.g., database as a service); Practical privacy and integrity mechanisms for outsourcing; Foundations of cloud-centric threat models; Secure computation outsourcing; Remote attestation mechanisms in clouds; Sandboxing and VM-based enforcements; Trust and policy management in clouds; Secure identity management mechanisms; New cloud-aware web service security paradigms and mechanisms; Cloud-centric regulatory compliance issues and mechanisms; Business and security risk models and clouds; Cost and usability models and their interaction with security in clouds; Scalability of security in global-size clouds; Trusted computing technology and clouds; Binary analysis of software for remote attestation and cloud protection; Network security (DOS, IDS etc.) mechanisms for cloud contexts; Security for emerging cloud programming models; Energy/cost/efficiency of security in clouds; Machine learning for cloud protection CCSW especially encourages novel paradigms and controversial ideas that are not on the above list. The workshop has historically acted as a fertile ground for creative debate and interaction in security-sensitive areas of computing impacted by clouds. This year marked the 11th anniversary of CCSW. In the past decade, CCSW has had a significant impact in our research community. As of August 2019, in the Google Scholar Metrics entry for ACM CCS (which encompasses CCSW), 20% of the top 20 cited papers come from CCSW. One way to look at it is that authors are as likely or perhaps more likely to have a top-20 paper publishing in CCSW than in CCS! This year, CCSW received 40 submissions out of which 12 full papers (30%) and 5 blitz abstracts were accepted.",
        "DOI": "10.1145/3372297.3416242",
        "paper_author": "Sion R.",
        "affiliation_name": "Stony Brook University",
        "affiliation_city": "Stony Brook",
        "affiliation_country": "United States",
        "affiliation_id": "60026415",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "FPGA implementation of multinomial logistic regression for vibrotactile feedback in a robotic hand",
        "publication": "2020 8th E-Health and Bioengineering Conference, EHB 2020",
        "citied_by": "1",
        "cover_date": "2020-10-29",
        "Abstract": "In this study, the aim was to generate real-time noninvasive vibrotactile feedback signals using Field-Programmable Gate Array (FPGA) with Multinomial Logistic Regression for the robotic hand. This work built a base for performing real-time vibrotactile feedback using the DESC policy, and it can be used in other FPGA studies. The hand conducted grasping type tasks with soft and hard objects and without any object. The force and bend sensors data were sent to the input ports of the National Instruments (NI) FPGA card by analog output of a NI data acquisition card to use real-time classification. The training was done in MATLAB, and the training parameters were used in FPGA for classification. The results showed that Multinomial Logistic Regression worked very well for the object type classification. However, the accuracies for the movement and combined type classifications were not as good as offline MATLAB classifications. Accuracies can be improved with different machine learning algorithms.",
        "DOI": "10.1109/EHB50910.2020.09280239",
        "paper_author": "Erbas I.",
        "affiliation_name": "Boğaziçi Üniversitesi",
        "affiliation_city": "Bebek",
        "affiliation_country": "Turkey",
        "affiliation_id": "60005803",
        "affiliation_state": "Istanbul"
    },
    {
        "paper_title": "The intersection of genomics and big data with public health: Opportunities for precision public health",
        "publication": "PLoS Medicine",
        "citied_by": "34",
        "cover_date": "2020-10-29",
        "Abstract": "• The field of precision public health (PPH) has emerged as a response to the increasing availability of genomics, biobanks, and other sources of big data in healthcare and public health. • The field has evolved starting with genomics to include multiple practical applications such as pathogen genomics that address population health. • PPH can expand understanding of health disparities, advance strategic public health science, and demonstrate the need for innovation and workforce development. • In the coronavirus disease 2019 (COVID-19) era, rapidly evolving scientific innovation can have a long-lasting impact on PPH beyond the pandemic. • Further developments in PPH will require global, national, and local leadership and stakeholder engagement.",
        "DOI": "10.1371/journal.pmed.1003373",
        "paper_author": "Khoury M.J.",
        "affiliation_name": "Centers for Disease Control and Prevention",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60021658",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Heterogeneous formation control of multiple UAVs with limited-input leader via reinforcement learning",
        "publication": "Neurocomputing",
        "citied_by": "35",
        "cover_date": "2020-10-28",
        "Abstract": "In this brief, a distributed optimal control method via reinforcement learning is proposed to address the heterogeneous unmanned aerial vehicle (UAV) formation trajectory tracking problem. The UAV formation is composed of a virtual leader with limited nonzero input and several follower vehicles with different unknown dynamics. The proposed control law contains a distributed observer and a model-free off-policy reinforcement learning (RL) protocol. The distributed optimal trajectory tracking problem is formulated for the heterogeneous formation system. A RL algorithm is designed to obtain the optimal control input online without any knowledge of the followers’ dynamics. Simulation example illustrates the effectiveness of the proposed method.",
        "DOI": "10.1016/j.neucom.2020.06.040",
        "paper_author": "Liu H.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013789",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Twitter Data Analysis Using Machine Learning to Evaluate Community Compliance in Preventing the Spread of COVID-19",
        "publication": "2020 2nd International Conference on Cybernetics and Intelligent System, ICORIS 2020",
        "citied_by": "6",
        "cover_date": "2020-10-27",
        "Abstract": "The Covid-19 pandemic that has hit the world, including Indonesia, has forced the government to take policies to prevent the spread of this deadly virus. One of the efforts is socialization to gain people's awareness to keep their distance and stay home. One of the media that can be used for this purpose is Twitter. However, even socialization efforts have been carried out, the spread of Covid-19 cases still has not yet decreased. Many aspects have to be evaluated to fix the situation. One of them is to evaluate the level of community compliance compared to the spread of Covid-19. This study aims to determine the level of community compliance to stay at home and its correlation with the number of positive cases of Covid-19 in Indonesia. This study takes the data from the tweets of the Indonesian people. The algorithms used are logistic regression and random forest combined with the ensemble algorithm, namely bagging. Twitter data taken are those that contain the word covid19, tetapdirumah, stayathome, mudik, psbb; location in Indonesia within a period of March 3rd to July 7th 2020. The data obtained from 705 tweets shows that non-compliance community has increased starting mid-June 2020 which is in line with the increasing data trend on the Covid-19 cases in Indonesia.",
        "DOI": "10.1109/ICORIS50180.2020.9320816",
        "paper_author": "Wibowo N.S.",
        "affiliation_name": "Universitas Amikom Yogyakarta",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60135980",
        "affiliation_state": "Java"
    },
    {
        "paper_title": "Safety considerations in deep control policies with safety barrier certificates under uncertainty",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "4",
        "cover_date": "2020-10-24",
        "Abstract": "Recent advances in Deep Machine Learning have shown promise in solving complex perception and control loops via methods such as reinforcement and imitation learning. However, guaranteeing safety for such learned deep policies has been a challenge due to issues such as partial observability and difficulties in characterizing the behavior of the neural networks. While a lot of emphasis in safe learning has been placed during training, it is non-trivial to guarantee safety at deployment or test time. This paper extends how under mild assumptions, Safety Barrier Certificates can be used to guarantee safety with deep control policies despite uncertainty arising due to perception and other latent variables. Specifically for scenarios where the dynamics are smooth and uncertainty has a finite support, the proposed framework wraps around an existing deep control policy and generates safe actions by dynamically evaluating and modifying the policy from the embedded network. Our framework utilizes control barrier functions to create spaces of control actions that are safe under uncertainty, and when the original actions are found to be in violation of the safety constraint, uses quadratic programming to minimally modify the original actions to ensure they lie in the safe set. Representations of the environment are built through Euclidean signed distance fields that are then used to infer the safety of actions and to guarantee forward invariance. We implement this method in simulation in a drone-racing environment and show that our method results in safer actions compared to a baseline that only relies on imitation learning to generate control actions.",
        "DOI": "10.1109/IROS45743.2020.9341315",
        "paper_author": "Hirshberg T.",
        "affiliation_name": "Technion - Israel Institute of Technology",
        "affiliation_city": "Haifa",
        "affiliation_country": "Israel",
        "affiliation_id": "60022403",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep learning-based autonomous scanning electron microscope",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "1",
        "cover_date": "2020-10-24",
        "Abstract": "By virtue of their ultra high resolution, scanning electron microscopes (SEMs) are essential to study topography, morphology, composition, and crystallography of materials, and thus are widely used for advanced researches in physics, chemistry, pharmacy, geology, etc. The major hindrance of using SEMs is that obtaining high quality images from SEMs requires a professional control of many control parameters. Therefore, it is not an easy task even for an experienced researcher to get high quality sample images without any help from SEM experts. In this paper, we propose and implement a deep learning-based autonomous SEM machine, which assesses image quality and controls parameters autonomously to get high quality sample images just as if human experts do. This world's first autonomous SEM machine may be the first step to bring SEMs, previously used only for advanced researches due to its difficulty in use, into much broader applications such as education, manufacture, and mechanical diagnosis, which are previously meant for optical microscopes.",
        "DOI": "10.1109/IROS45743.2020.9341041",
        "paper_author": "Jang J.",
        "affiliation_name": "Ulsan National Institute of Science and Technology",
        "affiliation_city": "Ulsan",
        "affiliation_country": "South Korea",
        "affiliation_id": "60103153",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement learning-based hierarchical control for path following of a salamander-like robot",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "5",
        "cover_date": "2020-10-24",
        "Abstract": "Path following is a challenging task for legged robots. In this paper, we present a hierarchical control architecture for path following of a quadruped salamander-like robot, in which, the tracking problem is decomposed into two sub-tasks: high-level policy learning based on the framework of reinforcement learning (RL) and low-level traditional controller design. More specifically, the high-level policy is learned in a physics simulator with a low-level controller designed in advance. To improve the tracking accuracy and to eliminate static errors, a soft Actor-Critic algorithm with state integral compensation is proposed. Additionally, to enhance the generalization and transferability, a compact state representation, which only contains the information of the target path and the abstract action similar to front-back and left-right, is proposed. The proposed algorithm is trained offline in the simulation environment and tested on the self-developed real quadruped salamander-like robot for different path following tasks. Simulation and experiments results validate the satisfactory performance of the proposed method.",
        "DOI": "10.1109/IROS45743.2020.9341656",
        "paper_author": "Zhang X.",
        "affiliation_name": "Nankai University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60018038",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Towards RL-based hydraulic excavator automation",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "31",
        "cover_date": "2020-10-24",
        "Abstract": "In this article we present a data-driven approach for automated arm control of a hydraulic excavator. Except for the link lengths of the excavator, our method does not require machine-specific knowledge nor gain tuning. Using data collected during operation of the excavator, we train a general purpose model to effectively represent the highly non-linear dynamics of the hydraulic actuation and joint linkage. Together with the link lengths a simulation is set up to train a neural network control policy for end-effector position tracking using reinforcement learning (RL). The control policy directly outputs the actuator commands that can be applied to the machine without unfounded filtering or modification. The proposed method is implemented and tested on a 12t hydraulic excavator, controlling its 4 main arm joints to track desired positions of the shovel in free-space. The results demonstrate the feasibility of directly applying control policies trained in simulation to the physical excavator for accurate and stable position tracking.",
        "DOI": "10.1109/IROS45743.2020.9341598",
        "paper_author": "Egli P.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Learning domain randomization distributions for training robust locomotion policies",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "10",
        "cover_date": "2020-10-24",
        "Abstract": "This paper considers the problem of learning behaviors in simulation without knowledge of the precise dynamical properties of the target robot platform(s). In this context, our learning goal is to mutually maximize task efficacy on each environment considered and generalization across the widest possible range of environmental conditions. The physical parameters of the simulator are modified by a component of our technique that learns the Domain Randomization (DR) that is appropriate at each learning epoch to maximally challenge the current behavior policy, without being overly challenging, which can hinder learning progress. This so-called sweet spot distribution is a selection of simulated domains with the following properties: 1) The trained policy should be successful in environments sampled from the domain randomization distribution; and 2) The DR distribution made as wide as possible, to increase variability in the environments. These properties aim to ensure the trajectories encountered in the target system are close to those observed during training, as existing methods in machine learning are better suited for interpolation than extrapolation. We show how adapting the DR distribution while training context-conditioned policies results in improvements on jump-start and asymptotic performance when transferring a learned policy to the target environment1.",
        "DOI": "10.1109/IROS45743.2020.9341019",
        "paper_author": "Mozian M.",
        "affiliation_name": "Université McGill",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60002494",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Learning human navigation behavior using measured human trajectories in crowded spaces",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "12",
        "cover_date": "2020-10-24",
        "Abstract": "As humans and mobile robots increasingly coexist in public spaces, their close proximity demands that robots navigate following navigation strategies similar to those exhibited by humans. This could be achieved by learning directly from human demonstration trajectories in a machine learning framework. In this paper, we present a method to learn human navigation behaviors using an imitation learning approach based on generative adversarial imitation learning (GAIL), which has the ability of directly extracting navigation policy. Specifically, we use a large open human trajectory dataset that was experimentally collected in a crowded public space. We then recreate these human trajectories in a 3D robotic simulator, and generate demonstration data using a LIDAR sensor onboard a robot with the robot following the measured human trajectories. We then propose a GAIL based algorithm, which uses occupancy maps generated using LIDAR data as the input, and outputs the navigation policy for robot navigation. Simulation experiments are conducted, and performance evaluation shows that the learned navigation policy generates trajectories qualitatively and quantitatively similar to human trajectories. Compared with existing works using analytical models (such as social force model) to generate human demonstration trajectories, our method learns directly from intrinsic human trajectories, thus exhibits more human-like navigation behaviors.",
        "DOI": "10.1109/IROS45743.2020.9341038",
        "paper_author": "Fahad M.",
        "affiliation_name": "National Oilwell Varco",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "60074461",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Learning visuomotor policies for aerial navigation using cross-modal representations",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "28",
        "cover_date": "2020-10-24",
        "Abstract": "Machines are a long way from robustly solving open-world perception-control tasks, such as first-person view (FPV) aerial navigation. While recent advances in end-to- end Machine Learning, especially Imitation Learning and Reinforcement appear promising, they are constrained by the need of large amounts of difficult-to-collect labeled real- world data. Simulated data, on the other hand, is easy to generate, but generally does not render safe behaviors in diverse real-life scenarios. In this work we propose a novel method for learning robust visuomotor policies for real-world deployment which can be trained purely with simulated data. We develop rich state representations that combine supervised and unsupervised environment data. Our approach takes a cross-modal perspective, where separate modalities correspond to the raw camera data and the system states relevant to the task, such as the relative pose of gates to the drone in the case of drone racing. We feed both data modalities into a novel factored architecture, which learns a joint lowdimensional embedding via Variational Auto Encoders. This compact representation is then fed into a control policy, which we trained using imitation learning with expert trajectories in a simulator. We analyze the rich latent spaces learned with our proposed representations, and show that the use of our cross-modal architecture significantly improves control policy performance as compared to end-to-end learning or purely unsupervised feature extractors. We also present real-world results for drone navigation through gates in different track configurations and environmental conditions. Our proposed method, which runs fully onboard, can successfully generalize the learned representations and policies across simulation and reality, significantly outperforming baseline approaches.",
        "DOI": "10.1109/IROS45743.2020.9341049",
        "paper_author": "Bonatti R.",
        "affiliation_name": "The Robotics Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60104841",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Reinforcement co-learning of deep and spiking neural networks for energy-efficient mapless navigation with neuromorphic hardware",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "57",
        "cover_date": "2020-10-24",
        "Abstract": "Energy-efficient mapless navigation is crucial for mobile robots as they explore unknown environments with limited on-board resources. Although the recent deep rein-forcement learning (DRL) approaches have been successfully applied to navigation, their high energy consumption limits their use in several robotic applications. Here, we propose a neuromorphic approach that combines the energy-efficiency of spiking neural networks with the optimality of DRL and benchmark it in learning control policies for mapless navigation. Our hybrid framework, spiking deep deterministic policy gradient (SDDPG), consists of a spiking actor network (SAN) and a deep critic network, where the two networks were trained jointly using gradient descent. The co-learning enabled synergistic information exchange between the two networks, allowing them to overcome each other's limitations through a shared representation learning. To evaluate our approach, we deployed the trained SAN on Intel's Loihi neuromorphic processor. When validated on simulated and real-world complex environments, our method on Loihi consumed 75 times less energy per inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate of successful navigation to the goal, which ranged from 1% to 4.2% and depended on the forward-propagation timestep size. These results reinforce our ongoing efforts to design brain-inspired algorithms for controlling autonomous robots with neuromorphic hardware.",
        "DOI": "10.1109/IROS45743.2020.9340948",
        "paper_author": "Tang G.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Piscataway",
        "affiliation_country": "United States",
        "affiliation_id": "60120529",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "A hybrid spectrum sensing approach to select suitable spectrum band for cognitive users",
        "publication": "Computer Networks",
        "citied_by": "23",
        "cover_date": "2020-10-24",
        "Abstract": "In recent years, the usage of wireless devices and wireless service has been increased exponentially and it results in spectrum scarcity. The policies of regulatory authority employ static spectrum allocation methods and assign new spectrum band for offering new kind of services to the users. These approaches lead to poor utilization of available spectrum bands. The cognitive radio (CR) provides better solution to these problems and it mainly focuses on efficient utilization of available spectrum bands. CR network (CRN) has to adopt spectrum management techniques to assign the unused spectrum band to the CR users by following a sequence of actions such as spectrum sensing, decision and management. Spectrum sensing is a vital process in spectrum allocation. In the traditional approaches, sensing accuracy is brought down by the probabilities of misdetection and false alarm rate and hence, sensing accuracy becomes low. As a result, the Cognitive Users (CUs) face the challenge of prolonged time to complete perfect cognitive radio communication. To overcome this issue, a cooperative spectrum sensing technique with a characteristic based cluster classifier has been proposed. This classifier learns the states and their transitions in the radio frequency environment, as well as the primary user activities at regular time intervals to support the spectrum decision technique. The novelty of the work is to propose a hybrid approach which combines clustering with expected maximization (EM) algorithm and reinforcement learning (RL) techniques. This hybrid approach enhances the system performance with accurate sensing results and by identifying the optimum spectrum band through hierarchical access model using interweaving approach, energy consumption is minimized. The simulation results show that by decreasing the probabilities of error ratio, false alarm rate and missed detection, the accuracy of sensing results is improved. Further, this hybrid approach outperforms the traditional approaches in terms of probability of detection even in low SNR values.",
        "DOI": "10.1016/j.comnet.2020.107387",
        "paper_author": "Rajaguru R.",
        "affiliation_name": "Sethu Institute of Technology",
        "affiliation_city": "Kariapatti",
        "affiliation_country": "India",
        "affiliation_id": "60106283",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "2020 4th Cyber Security in Networking Conference, CSNet 2020",
        "publication": "2020 4th Cyber Security in Networking Conference, CSNet 2020",
        "citied_by": "0",
        "cover_date": "2020-10-21",
        "Abstract": "The proceedings contain 16 papers. The topics discussed include: safe traffic adaptation model in wireless mesh networks; using probabilistic availability measures for predicting targeted attacks on network nodes; a policy-based interaction protocol between software defined security controller and virtual security functions; unsupervised machine learning techniques for network intrusion detection on modern data; a decentralized resource discovery using attribute based encryption for Internet of things; and cloud assisted privacy preserving using homomorphic encryption.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine Learning and the Pursuit of High-Value Health Care",
        "publication": "NEJM Catalyst Innovations in Care Delivery",
        "citied_by": "16",
        "cover_date": "2020-10-21",
        "Abstract": "The United States faces unsustainable growth in health care costs despite limited return on this investment in the form of health outcomes, prompting efforts to improve the value of health care. Artificial intelligence has the potential to enable high-value decision-making from the perspectives of the patient, clinician, and health system, but it also could worsen value. This article assesses these opportunities and challenges, separates reality from hype, and proposes policy approaches for contemporary artificial intelligence — specifically, machine learning — to contribute to rather than detract from high-value care. The conclusion is that it is critical to consider value — in particular, the cost component — in all machine-learning work and to let humans and algorithms each do what they do best.",
        "DOI": "10.1056/CAT.20.0094",
        "paper_author": "Ganguli I.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Machine Learning Algorithm for Intelligent Prediction for Military Logistics and Planning",
        "publication": "International Conference on ICT Convergence",
        "citied_by": "7",
        "cover_date": "2020-10-21",
        "Abstract": "This paper compares various machine learning algorithms for predicting availability and possible reorder level of military logistics. As a case scenario, dataset of price of petroleum product was used to test the accuracy of the proposed algorithm. In most Military, facilities, machines and equipment relied heavily on the availability of petroleum products. Military logistics must be intelligent, based on informed deductions. Machine learning is now pervasive and is readily applied to various areas of life including the military. Result of the evaluation shows that artificial neural network (ANN)- 85.57% and logistic regression- 78.44% performed better than k-nearest neighbour (KNN)-74.98%, random forest(RF)-72.81% and Naive Bayes(NB)-74.85%. If used in Military logistics, there could be attendant benefit such as: accurate price policy formulation; proper budgeting estimation; meeting production and demand targets; proactive supply chain and value chain derivations; informed and intelligent decision making process; competitive advantage and continuous availability of supply critical to military; trigger of further research on innovative emergent technologies in this area, amongst other intangible benefits.",
        "DOI": "10.1109/ICTC49870.2020.9289286",
        "paper_author": "Okechukwu Ajakwe S.",
        "affiliation_name": "Kumoh National Institute of Technology",
        "affiliation_city": "Gumi",
        "affiliation_country": "South Korea",
        "affiliation_id": "60019209",
        "affiliation_state": "Gyeongsangbuk-do"
    },
    {
        "paper_title": "Learning quadrupedal locomotion over challenging terrain",
        "publication": "Science Robotics",
        "citied_by": "766",
        "cover_date": "2020-10-21",
        "Abstract": "Legged locomotion can extend the operational domain of robots to some of the most challenging environments on Earth. However, conventional controllers for legged locomotion are based on elaborate state machines that explicitly trigger the execution of motion primitives and reflexes. These designs have increased in complexity but fallen short of the generality and robustness of animal locomotion. Here, we present a robust controller for blind quadrupedal locomotion in challenging natural environments. Our approach incorporates proprioceptive feedback in locomotion control and demonstrates zero-shot generalization from simulation to natural environments. The controller is trained by reinforcement learning in simulation. The controller is driven by a neural network policy that acts on a stream of proprioceptive signals. The controller retains its robustness under conditions that were never encountered during training: deformable terrains such as mud and snow, dynamic footholds such as rubble, and overground impediments such as thick vegetation and gushing water. The presented work indicates that robust locomotion in natural environments can be achieved by training in simple domains.",
        "DOI": "10.1126/SCIROBOTICS.ABC5986",
        "paper_author": "Lee J.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "A composite learning method for multi-ship collision avoidance based on reinforcement learning and inverse control",
        "publication": "Neurocomputing",
        "citied_by": "51",
        "cover_date": "2020-10-21",
        "Abstract": "Model-free reinforcement learning methods have potentials in ship collision avoidance under unknown environments. To defect the low efficiency problem of the model-free reinforcement learning, a composite learning method is proposed based on an asynchronous advantage actor-critic (A3C) algorithm, a long short-term memory neural network (LSTM) and Q-learning. The proposed method uses Q-learning for adaptive decisions between a LSTM inverse model-based controller and the model-free A3C policy. Multi-ship collision avoidance simulations are conducted to verify the effectiveness of the model-free A3C method, the proposed inverse model-based method and the composite learning method. The simulation results indicate that the proposed composite learning based ship collision avoidance method outperforms the A3C learning method and a traditional optimization-based method.",
        "DOI": "10.1016/j.neucom.2020.05.089",
        "paper_author": "Xie S.",
        "affiliation_name": "Wuhan University of Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60022414",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "A TD3-based multi-agent deep reinforcement learning method in mixed cooperation-competition environment",
        "publication": "Neurocomputing",
        "citied_by": "69",
        "cover_date": "2020-10-21",
        "Abstract": "We explored the problem about function approximation error and complex mission adaptability in multi-agent deep reinforcement learning. This paper proposes a new multi-agent deep reinforcement learning algorithm framework named multi-agent time delayed deep deterministic policy gradient. Our work reduces the overestimation error of neural network approximation and variance of estimation result using dual-centered critic, group target network smoothing and delayed policy updating. According to experiment results, it improves the ability to adapt complex missions eventually. Then, we discuss that there is an inevitable overestimation issue about existing multi-agent algorithms about approximating real action-value equations with neural network. We also explain the approximate error of equations in the multi-agent deep deterministic policy gradient algorithm mathematically and experimentally. Finally, the application of our algorithm in the mixed cooperative competition experimental environment further demonstrates the effectiveness and generalization of our algorithm, especially improving the group's ability of adapting complex missions and completing more difficult missions.",
        "DOI": "10.1016/j.neucom.2020.05.097",
        "paper_author": "Zhang F.",
        "affiliation_name": "Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60016521",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Challenges and Solutions to the Student Dropout Prediction Problem in Online Courses",
        "publication": "International Conference on Information and Knowledge Management, Proceedings",
        "citied_by": "16",
        "cover_date": "2020-10-19",
        "Abstract": "Online courses and e-degrees, although present since the mid-1990, have received enormous attention only in the last decade. Moreover, the new Coronavirus disease (COVID-19) outbreak forced many nations (e.g. Italy, the US, and other countries) to massively push their education system towards an online environment. Academics now are also looking at the crisis as an opportunity for universities to adopt digital technologies for teaching more broadly. But they will have to understand what possible ways of evaluating and effectively teaching will be in this new scenario. The depicted overview, in conjunction with the utility and ubiquitous access to the educational platforms of online courses, entails a vast amount of enrolments. Nevertheless, a high enrolment rate usually translates into a significant dropout (or withdrawal) rate of students (40-80% of online students drop out). Student dropout prediction (SDP) consists of modelling and fore-casting student behaviour when interacting with e-learning platforms. It is a significant phenomenon that has repercussions on online institutions, the involved students and professors. Early approaches tended to perform manual analytic examinations to devise retention strategies. Recent research has adopted automated policies to thoroughly exploit the advantages of student activities(hereafter e-tivities) in the e-platforms and identify at-risk students. These approaches include machine learning and deep learning techniques to predict the student dropout status. Therefore, being able to cope with the trend shifting of student interactions with the course platforms in real-time has become of paramount importance. In this tutorial, we comprehensively overview the SDP problem in the literature. We provide mathematical formalisation to the different definitions proposed, and we introduce simple and complex predictive methods adhering to the following: Student dropout definition, Input modelling, Underlying machine and deep learning techniques, Evaluation measures, Datasets, and privacy concerns.",
        "DOI": "10.1145/3340531.3412172",
        "paper_author": "Prenkaj B.",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60032350",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "PrivacyCheck v2: A Tool that Recaps Privacy Policies for You",
        "publication": "International Conference on Information and Knowledge Management, Proceedings",
        "citied_by": "27",
        "cover_date": "2020-10-19",
        "Abstract": "Despite the efforts to regulate privacy policies to protect user privacy, these policies remain lengthy and hard to comprehend. Powered by machine learning, our publicly available browser extension, PrivacyCheck v2, automatically summarizes any privacy policy by answering 20 questions based upon User Control and the General Data Protection Regulation. Furthermore, PrivacyCheck v2 incorporates a competitor analysis tool that highlights the top competitors with the best privacy policies in the same market sector. PrivacyCheck v2 enhances the users' understanding of privacy policies and empowers them to make informed decisions when it comes to selecting services with better privacy policies.",
        "DOI": "10.1145/3340531.3417469",
        "paper_author": "Nokhbeh Zaeem R.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Impact of micronutrient supplementation on chronic childhood malnutrition in Peru",
        "publication": "Revista Medica Herediana",
        "citied_by": "3",
        "cover_date": "2020-10-16",
        "Abstract": "Chronic childhood malnutrition (CCM) affects mental and physical development of children. In the long-term, a high incidence of CCM generates a vicious circle of inequality and poverty. Therefore, evaluating the impact of interventions to ameliorate CCM may be a useful indicator of implemented policies. Objective: to evaluate the impact of micronutrient supplementation on chronic childhood malnutrition in Peru from 2014-2017. Methods: Data from Encuesta Demográfica y de Salud Familiar (ENDES) from 2014-2017 including children from 6 to 59 months of age were gathered. A two-step quantitative estimation was applied. First, the sample was balanced using Entropy Balancing (EB) and Machine Learning (ML). Second, differences in two variables were estimated, probability of having CCM and the Z score among those with CCM. Results: having consumed some micronutrient increases the probability of having CCM. A positive effect on the Z score was found above 54.1 sachets consumed. Results did not change after adjusting for covariates. Conclusions: micronutrient supplementation has a negative effect in reducing CCM, a positive effect was found at bigger consumptions.",
        "DOI": "10.20453/RMH.V31I3.3803",
        "paper_author": "Francke P.",
        "affiliation_name": "Pontificia Universidad Catolica del Peru",
        "affiliation_city": "Lima",
        "affiliation_country": "Peru",
        "affiliation_id": "60071236",
        "affiliation_state": "Lima"
    },
    {
        "paper_title": "Responsible AI and Ethical Issues for Businesses and Governments",
        "publication": "Responsible AI and Ethical Issues for Businesses and Governments",
        "citied_by": "3",
        "cover_date": "2020-10-16",
        "Abstract": "The research surrounding artificial intelligence (AI) is vast and quite diverse in both its applied and theoretical fields. AI tools and techniques, such as machine learning, data mining, neural networks, and advanced analytics, are evolving at a high speed, creating a consistent need for updated research. This is especially relevant with frequent developments for the application of AI technology in many science and industry sectors. This rapid expansion created a need for research that focuses on the questions surrounding the development of AI such as ethical issues, responsible AI methods and applications, and its widespread implementation. Within the answers to these questions is the prevailing notion that AI should be accountable, explainable, transparent, and fair for all organizations and individuals. Responsible AI and Ethical Issues for Businesses and Governments widens the understanding of AI outside of the \"narrow\" technical perspective to a broader viewpoint that embraces the links between AI theory, practice, and policy. The chapters in this book discuss the basic philosophical and conceptual foundations of AI and explores the responsible application of AI tools and methods, the moral aspects of AI, practical issues, and responsible AI implementation across a range of industries. While highlighting topics that include digital transformation, ethical competence, information literacy in AI, and the interaction between AI and humans, this book is ideally designed for IT specialists, technology developers, technologists, ethicists, practitioners, stakeholders, academicians, students, and researchers who are interested in learning more about the ethical and responsible use of AI.",
        "DOI": "10.4018/978-1-7998-4285-9",
        "paper_author": "Vassileva B.",
        "affiliation_name": "University of Economics - Varna",
        "affiliation_city": "Varna",
        "affiliation_country": "Bulgaria",
        "affiliation_id": "60070361",
        "affiliation_state": "Varna"
    },
    {
        "paper_title": "Introduction to precision agriculture: Overview, concepts, world interest, policy, and economics",
        "publication": "Precision Agriculture Technologies for Food Security and Sustainability",
        "citied_by": "0",
        "cover_date": "2020-10-16",
        "Abstract": "The global population is increasing at a tremendous speed; thus, the demand for safe and secure food to meet this population is in demand. Therefore, traditional farming methods are insufficient to meet this demand; thus, the next revolution in agriculture is required, which is Precision Agriculture (PA), the Fourth Agriculture Revolution. PA is a technology where the concept of farm management is based on observation, measuring, and responding to inter- and intra-field variability in crops. The technologies used for performing precision agriculture are mapping, global positioning system (GPS), yield monitoring and mapping, grid soil sampling application, variable-rate fertilizer application, remote sensing, geographic information systems (GIS), quantifying on farm variability, soil variation, variability of soil water content, time and space scales, robots, drones, satellite imagery, the internet of things, smartphone, and machine learning. Hence, the current chapter will be emphasizing the overview, concepts, history, world interest, benefits, disadvantages, and precision farming needs.",
        "DOI": "10.4018/978-1-7998-5000-7.ch001",
        "paper_author": "Tendulkar A.",
        "affiliation_name": "Malaysia University of Science and Technology",
        "affiliation_city": "Petaling Jaya",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60094276",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Multi-Agent Reinforcement Learning for Dynamic Spare Parts Inventory Control",
        "publication": "2020 Global Reliability and Prognostics and Health Management, PHM-Shanghai 2020",
        "citied_by": "2",
        "cover_date": "2020-10-16",
        "Abstract": "Spare parts inventory control is an important research topic in operational research, which aims to guarantee machine availability and reduce inventory costs. Existing inventory policy described by a limited number of parameters, is not flexible, not necessary the optimal. This paper developed a multi-agent reinforcement learning method based on the Dueling Double Deep Q-network framework to solve a two-echelon spare parts inventory control problem, where the fixed time window and lateral transshipment are considered. Numerical examples are demonstrated to investigate the performance of the proposed multi-agent reinforcement learning method. The result shows that the proposed method outperforms the genetic algorithm that derives the (s, S) policy.",
        "DOI": "10.1109/PHM-Shanghai49105.2020.9280935",
        "paper_author": "Yu C.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60005244",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Depth insight for data scientist with RapidMiner « an innovative tool for AI and big data towards medical applications»",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "12",
        "cover_date": "2020-10-15",
        "Abstract": "RapidMiner tool is considered among the advanced analytics and powerful platform services in the field of artificial intelligence besides the Big Data storage. This solution has emerged towards several industries such as Financial Services, Energy, Logistics, Life Science and Healthcare and has shown a crucial impact for predictive decisions in this area. This work seeks to describe the solution strategy of this tool for data scientist by depicting a depth insight of this concept which contains more 1500 native algorithms, data preparation and data science functions. This features allows professionals to support any machine learning libraries and integrate python and R codes. RapidMiner offers three different modalities to access to their products which are the main Platform, the automated data science and the AI cloud.",
        "DOI": "10.1145/3423603.3424059",
        "paper_author": "Bjaoui M.",
        "affiliation_name": "University of Sfax",
        "affiliation_city": "Sfax",
        "affiliation_country": "Tunisia",
        "affiliation_id": "60064746",
        "affiliation_state": "Sfax"
    },
    {
        "paper_title": "Deep Q-network-based adaptive alert threshold selection policy for payment fraud systems in retail banking",
        "publication": "ICAIF 2020 - 1st ACM International Conference on AI in Finance",
        "citied_by": "8",
        "cover_date": "2020-10-15",
        "Abstract": "Machine learning models have widely been used in fraud detection systems. Most of the research and development efforts have been concentrated on improving the performance of the fraud scoring models. Yet, the downstream fraud alert systems still have limited to no model adoption and rely on manual steps. Alert systems are pervasively used across all payment channels in retail banking and play an important role in the overall fraud detection process. Current fraud detection systems end up with large numbers of dropped alerts due to their inability to account for the alert processing capacity. Ideally, alert threshold selection enables the system to maximize the fraud detection while balancing the upstream fraud scores and the available bandwidth of the alert processing teams. However, in practice, fixed thresholds that are used for their simplicity do not have this ability. In this paper, we propose an enhanced threshold selection policy for fraud alert systems. The proposed approach formulates the threshold selection as a sequential decision making problem and uses Deep Q-Network based reinforcement learning. Experimental results show that this adaptive approach outperforms the current static solutions by reducing the fraud losses as well as improving the operational efficiency of the alert system.",
        "DOI": "10.1145/3383455.3422563",
        "paper_author": "Shen H.",
        "affiliation_name": "The University of Alabama in Huntsville",
        "affiliation_city": "Huntsville",
        "affiliation_country": "United States",
        "affiliation_id": "60020583",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "Sim-to-real reinforcement learning applied to end-to-end vehicle control",
        "publication": "2020 23rd IEEE International Symposium on Measurement and Control in Robotics, ISMCR 2020",
        "citied_by": "13",
        "cover_date": "2020-10-15",
        "Abstract": "In this work, we study vision-based end-to-end reinforcement learning on vehicle control problems, such as lane following and collision avoidance. Our controller policy is able to control a small-scale robot to follow the right-hand lane of a real two-lane road, while its training was solely carried out in a simulation. Our model, realized by a simple, convolutional network, only relies on images of a forward-facing monocular camera and generates continuous actions that directly control the vehicle. To train this policy we used Proximal Policy Optimization, and to achieve the generalization capability required for real performance we used domain randomization. We carried out thorough analysis of the trained policy, by measuring multiple performance metrics and comparing these to baselines that rely on other methods. To assess the quality of the simulation-to-reality transfer learning process and the performance of the controller in the real world, we measured simple metrics on a real track and compared these with results from a matching simulation. Further analysis was carried out by visualizing salient object maps.",
        "DOI": "10.1109/ISMCR51255.2020.9263751",
        "paper_author": "Kalapos A.",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary",
        "affiliation_id": "60030035",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Control of an Inverted Pendulum by Reinforcement Learning Method in PLC Environment",
        "publication": "Proceedings - 2020 Innovations in Intelligent Systems and Applications Conference, ASYU 2020",
        "citied_by": "6",
        "cover_date": "2020-10-15",
        "Abstract": "The aim of this study is to implement Q-learning algorithm to move an inverted pendulum from the downright position to upright position in a PLC environment. Instead of using classical control algorithms that need a linear model of the system to be controlled, we used model-free control algorithm, i.e. Q-learning, and relaxed the linearity assumption. We demonstrate that reinforcement learning can be successfully used in industrial machine learning applications to learn complex control policies without having a detailed model of the controlled system. An experimental set up is designed using PLC controlled mechanical parts, and the code is written in PLC. After about three hours of learning stage, the Q learning algorithm successfully moved inverted pendulum from downright position to upright position and keep it in balanced upright position.",
        "DOI": "10.1109/ASYU50717.2020.9259890",
        "paper_author": "Demirkiran G.",
        "affiliation_name": "Yaşar Üniversitesi",
        "affiliation_city": "Izmir",
        "affiliation_country": "Turkey",
        "affiliation_id": "60028947",
        "affiliation_state": "Izmir"
    },
    {
        "paper_title": "Long-Term Planning with Deep Reinforcement Learning on Autonomous Drones",
        "publication": "Proceedings - 2020 Innovations in Intelligent Systems and Applications Conference, ASYU 2020",
        "citied_by": "11",
        "cover_date": "2020-10-15",
        "Abstract": "In this paper, we study a long-term planning scenario that is based on drone racing competitions held in real life. We conducted this experiment on a framework created for 'Game of Drones: Drone Racing Competition' at NeurIPS 2019. The racing environment was created using Microsoft's AirSim Drone Racing Lab. We have trained a reinforcement learning agent, simulated quadrotor in our case, with the Policy Proximal Optimization (PPO) algorithm. After training process it was successfully able to compete against another simulated quadrotor that was running a classical path planning algorithm. Agent observations consist of data from IMU sensors, GPS coordinates of drone obtained through simulation and opponent drone GPS information. Using opponent drone GPS information during training helps dealing with complex state spaces which serves as expert guidance. This approach allows efficient and stable training process. Our work fits into Clought's level 10 UAV autonomy categorization. All experiments performed in this paper can be found and reproduced with code at our GitHub repository.",
        "DOI": "10.1109/ASYU50717.2020.9259811",
        "paper_author": "Ates U.",
        "affiliation_name": "Gebze Teknik Üniversitesi",
        "affiliation_city": "Gebze",
        "affiliation_country": "Turkey",
        "affiliation_id": "60013071",
        "affiliation_state": "Kocaeli"
    },
    {
        "paper_title": "Multi-agent deep reinforcement learning based demand response for discrete manufacturing systems energy management",
        "publication": "Applied Energy",
        "citied_by": "119",
        "cover_date": "2020-10-15",
        "Abstract": "With advances in smart grid technologies, demand response has played a major role in improving the reliability of grids and reduce the cost for customers. Implementing the demand response scheme for industry is more necessary than for other sectors, because its energy consumption is often considered the largest. This paper proposes a multi-agent deep reinforcement learning based demand response scheme for energy management of discrete manufacturing systems. In this regard, the industrial manufacturing system is initially formulated as a partially-observable Markov game; then, a multi-agent deep deterministic policy gradient algorithm is adopted to obtain the optimal schedule for different machines. A typical lithium-ion battery assembly manufacturing system is used to demonstrate the effectiveness of the proposed scheme. Simulation results show that the presented demand response algorithm can minimize electricity costs and maintain production tasks, as compared to a benchmark without demand response. Moreover, the performance of the multi-agent deep reinforcement learning approach against a mathematical model method is investigated.",
        "DOI": "10.1016/j.apenergy.2020.115473",
        "paper_author": "Lu R.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Industry ties and evidence in public comments on the FDA framework for modifications to artificial intelligence/machine learning-based medical devices: A cross sectional study",
        "publication": "BMJ Open",
        "citied_by": "9",
        "cover_date": "2020-10-14",
        "Abstract": "Objectives To determine the extent and disclosure of financial ties to industry and use of scientific evidence in comments on a US Food and Drug Administration (FDA) regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD). Design Cross-sectional study. Setting We searched all publicly available comments on the FDA a € Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) - Discussion Paper and Request for Feedback' from 2 April 2019 to 8 August 2019. Main outcome measures The proportion of articles submitted by parties with financial ties to industry, disclosing those ties, citing scientific articles, citing systematic reviews and meta-analyses, and using a systematic process to identify relevant literature. Results We analysed 125 comments submitted on the proposed framework. 79 (63%) comments came from parties with financial ties; for 36 (29%) comments, it was not clear and the absence of financial ties could only be confirmed for 10 (8%) comments. No financial ties were disclosed in any of the comments that were not from industry submitters. The vast majority of submitted comments (86%) did not cite any scientific literature, just 4% cited a systematic review or meta-analysis and no comments indicated that a systematic process was used to identify relevant literature. Conclusions Financial ties to industry were common and undisclosed, and scientific evidence, including systematic reviews and meta-analyses, were rarely cited. To ensure regulatory frameworks best serve patient interests, the FDA should mandate disclosure of potential conflicts of interest (including financial ties) in comments, encourage the use of scientific evidence, and encourage engagement from non-conflicted parties.",
        "DOI": "10.1136/bmjopen-2020-039969",
        "paper_author": "Smith J.A.",
        "affiliation_name": "University of Oxford Medical Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60002634",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Reducing Vibration of A Rotating Machine with Deep Reinforcement Learning",
        "publication": "2020 IEEE International Conference on Mechatronics and Automation, ICMA 2020",
        "citied_by": "5",
        "cover_date": "2020-10-13",
        "Abstract": "Reducing vibration of a high-speed rotating machine is an important task as the vibration can damage equipment, increase costs and reduce quality. Faced with the problems, in this paper, we proposed a control tool with several pads and sensors to actively dampening the vibration of the machine. Using Deep Reinforcement Learning (RL) to learn a policy that determines whether to stretch out a pad and the speed of the pads according to the information collected by sensors, our approach can change the displacement of the rotating machine in space by generating an opposite force with a pad while it touches the wall so as to reduce the vibration. We evaluate our approach against two baselines, a control method with all the pads stretched out and a method without equipping the control tool. Our results indicate that simple RL algorithms in controlling the pad tool have effectiveness in reducing the vibration of the machine.",
        "DOI": "10.1109/ICMA49215.2020.9233736",
        "paper_author": "Tao Z.",
        "affiliation_name": "Key Laboratory of Machine Perception, Ministry of Education",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60124572",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning congestion over millimeter-wave channels",
        "publication": "International Conference on Wireless and Mobile Computing, Networking and Communications",
        "citied_by": "1",
        "cover_date": "2020-10-12",
        "Abstract": "This paper studies how learning techniques can be used by the congestion control algorithms employed by transport protocols over 5G wireless channels, in particular millimeter waves. We show how metrics measured at the transport layer might be valuable to ascertain the congestion level. In situations characterized by a high correlation between such parameters and the actual congestion, it is observed that the performance of unsupervised learning methods is comparable to supervised learning approaches. Exploiting the ns-3 platform to perform an in-depth, realistic assessment, allows us to study the impact of various layers of the protocol stack. We also consider different scheduling policies to discriminate whether the allocation of radio resources impacts the performance of the proposed scheme.",
        "DOI": "10.1109/WiMob50308.2020.9253443",
        "paper_author": "Diez L.",
        "affiliation_name": "Universidad de Cantabria",
        "affiliation_city": "Santander",
        "affiliation_country": "Spain",
        "affiliation_id": "60015179",
        "affiliation_state": "Cantabria"
    },
    {
        "paper_title": "TentNet: Deep Learning Tent Detection Algorithm Using A Synthetic Training Approach",
        "publication": "Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",
        "citied_by": "6",
        "cover_date": "2020-10-11",
        "Abstract": "Homelessness is a complex social problem and there have been limited attempts to use machine learning algorithms to understand the various issues that public health agencies would like to solve. For instance, it is important for the policy makers to know where homeless populations live so that they can provide necessary services accordingly. This article presents a satellite image tent-detection solution with three deep learning methods that utilize transfer learning from the ResNetV2, InceptionV3, and MobileNetV2 models, trained on ImageNet, attached to a unique architecture referred to as \"TentNet\". The performance of these models are first shown in detecting planes and ships within satellite imagery in previously defined datasets as a baseline. Then, a new dataset is created from a compilation of tents from the xView project to use for testing, along with another dataset of synthetic images from the generative adversarial networks StyleGAN2 and DCGAN for training. After training on a dataset containing only synthetic images for the tents class, the ResNetV2 architecture achieved the highest accuracy of 73.68% when testing on the real satellite imagery.",
        "DOI": "10.1109/SMC42975.2020.9283377",
        "paper_author": "Fisher A.",
        "affiliation_name": "Lakehead University",
        "affiliation_city": "Thunder Bay",
        "affiliation_country": "Canada",
        "affiliation_id": "60025949",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Deception in the Game of Guarding Multiple Territories: A Machine Learning Approach",
        "publication": "Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",
        "citied_by": "8",
        "cover_date": "2020-10-11",
        "Abstract": "In this paper, a deceptive version of guarding a territory in a grid world is proposed. Like the original version, a defender tries to intercept an invader before it invades the targets. However, the discerning invader can deceive the defender about its real goal so that it can improve its performance. On the other hand, the defender tries to confront the invader by guessing its true goal. A two-level policy is obtained via reinforcement learning (RL). In the lower level, the invader and the defender learn their optimal policies to invade or defend a particular territory. In the higher level, the invader learns which territory it should pretend to invade in order to manipulate the defender's belief function. A multiagent reinforcement learning (MARL) algorithm is implemented for obtaining the optimal policies via the minimax Q-learning algorithm at the lower level. Whereas for the higher-level policy a single-agent Q-learning algorithm is utilized. Results of different reward functions are compared. The results show that the invader can improve its performance by taking advantage of deception.",
        "DOI": "10.1109/SMC42975.2020.9283173",
        "paper_author": "Asgharnia A.",
        "affiliation_name": "Carleton University",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60017592",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Learning-to-fly RL: Reinforcement learning-based collision avoidance for scalable urban air mobility",
        "publication": "AIAA/IEEE Digital Avionics Systems Conference - Proceedings",
        "citied_by": "2",
        "cover_date": "2020-10-11",
        "Abstract": "As hundreds of Unmanned Aircraft System (UAS) operate within urban airspaces, automated and decentralized UAS traffic management (UTM) will be critical to maintain safe and efficient operations. In this work, we present Learning-to-Fly with Reinforcement Learning (L2F-RL), a decentralized, on-demand Collision Avoidance (CA) framework that systematically combines machine learning with cooperative model predictive control for UAS collision avoidance while retaining satisfaction of higher-level mission objectives. L2F-RL consists of: 1) RL-based policy for conflict resolution (CR) with discrete-decision making, 2) decentralized, cooperative model predictive control for CA. To accelerate training with RL, we utilize reward shaping and curriculum learning. Our approach outperforms baseline approaches with a 99.10% separation rate (ratio of success to total test cases) in the worst case, improving to 100% in the best case with a 1000X improvement in computation time compared to centralized methods. Our results demonstrate the potential of combining learning approaches with optimization-based control, making it a significant contribution towards scalable, decentralized UTM.",
        "DOI": "10.1109/DASC50938.2020.9256710",
        "paper_author": "Jang K.",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60102562",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "On the Performance of Data-Driven Reinforcement Learning for Commercial HVAC Control",
        "publication": "2020 IEEE Industry Applications Society Annual Meeting, IAS 2020",
        "citied_by": "5",
        "cover_date": "2020-10-10",
        "Abstract": "Commercial heating, ventilation and air conditioning (HVAC ) system consumes large portion of the building energy use. With the abundance of the available data in the building automation systems (BAS) of commercial buildings, ample opportunities have emerged to help develop adequate data-driven control of HVAC systems. This paper proposes the use of data-driven reinforcement learning (RL) that can evaluate control policies and develop new ones. A Q- learning algorithm is used as a type of reinforcement learning to minimize the building energy consumption cost while maintaining the comfort level. The proposed Q-learning algorithm is trained using actual data where the data is first used to develop temperature and energy models. Four different machine learning methodologies are used to obtain these models which are linear regression, deep neural network, support vector machines and random forests. The performance of the Q- learning algorithm under each methodology is tested and compared with the others. The algorithm is validated using a decent physics-based model of a 3-floor office/classroom building. The results showed that though all the four methodologies yield satisfactory results, the Q-learning algorithm performed the best under support vector machine and random forest.",
        "DOI": "10.1109/IAS44978.2020.9334865",
        "paper_author": "Faddel S.",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States",
        "affiliation_id": "60154598",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Analysis of the Profit Model of Online Education Companies",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "2",
        "cover_date": "2020-10-09",
        "Abstract": "With the development of the Internet, online learning has entered our lives and has been quickly accepted by people. Nowadays, learning with mobile phones and computers has become a normal thing. Many companies have also broken through the scope of traditional education and have begun to develop online learning products. There are many market segments for personalized needs in this market. X Online Education Company is mainly engaged in the development and sales of language learning tools and course products. This article is to use this online education company as an example to explore the profit model of such online education industry enterprises. This paper first expounds the relevant theory of profit model and points out its concept and element composition. Then, the analysis of the industry and the company's internal situation is carried out for the profit environment of X Online Education Company, and the five aspects of the online education company's profit model are explained in combination with the actual situation. In the end, the advantages and problems of the online education company's profit model are analyzed, and reasonable suggestions are made for the problem, which must be given to other companies of the same type. Through the analysis of the profit model of online education companies, it is concluded that they mainly attract customers through the free APP, and charge for other paid courses and shopping malls, and earn profits through course tuition income and commodity income. The profit model is more common in the current online education for the purpose of quality education. The advantage is that the input-output ratio is huge, and it is easy to launch new projects. At the same time, there are certain problems, such as a single profit point and market competition. In this respect, X Online Education Company should continue to improve the operation mode and product quality of existing projects, and actively develop into other market segments, and expand other markets that do not have a large number of enterprises to settle in. machine. Since the government introduced the relevant policies of the online education industry, the entry barriers and general measures of the online education industry have been stricter. The whole industry is facing shuffling, and there are too many homogenized products in the market, only to recognize their own advantages and Only after solving the problem can we maintain long-Term profitability and remain invincible.",
        "DOI": "10.1145/3436209.3436881",
        "paper_author": "Wang Q.",
        "affiliation_name": "Qingdao No.2 Middle School",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China",
        "affiliation_id": "126428740",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Dynamical Perspective of Machine Learning: An Introductory Review",
        "publication": "IEEE International Conference on Control and Automation, ICCA",
        "citied_by": "0",
        "cover_date": "2020-10-09",
        "Abstract": "In this paper, we will briefly introduce the recent progress on machine learning based on the dynamical perspective. By combining machine learning with the dynamics, we get many continuous time algorithms. By discretizing the continuous time dynamic equations, we can not only review the existing algorithms, but also get new discrete-time algorithms. Firstly, gradient based algorithms is presented, which include the accelerated algorithm, policy gradient algorithm and stochastic gradient algorithm. Then, we come to the non-gradient algorithms, including the Pontryagins maximum principle based successive approximation algorithm and the optimal tensor algorithm. Next, continuous-time perspective of machine learning is reviewed, which to some extent establish a theoretical basis for machine learning. And in the end, we propose the advantage and the disadvantage of the above achievements, and try to give our own opinion about the application prospect and the development direction.",
        "DOI": "10.1109/ICCA51439.2020.9264352",
        "paper_author": "Zhang Y.",
        "affiliation_name": "Nankai University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60018038",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting employee turnover intention in ITITeS industry using machine learning algorithms",
        "publication": "Proceedings of the 4th International Conference on IoT in Social, Mobile, Analytics and Cloud, ISMAC 2020",
        "citied_by": "7",
        "cover_date": "2020-10-07",
        "Abstract": "Employee' determination to leave the organization is one of the significant factors impacting the performance of the organizations since it affects the overall profitability. Organizations need to strategize to reduce the turnover goals of the workers to have a competitive advantage over other organizations. By understanding the factors impacting the employee's intent to leave the organization, the management can intervene with strategic policies and decisions so that intent of the employees to leave the organization will be reduced substantially and thus increasing the employee's engagement towards work. This research paper uses machine learning algorithms to predict an employee's intention to leave the organization in the near future and identifies the significant features impacting the employee's intention to leave the organization. Data has been collected from 416 employees working in IT and ITES companies using convenience sampling and structure questionnaire. Research also used text mining to analyse the open-ended questionnaire filled by the employees there by mining the frequently used words and employee sentiments. From the study, it is found that among the Classification algorithms used for predicting employee's turnover intention, XG boost performed relatively better with high accuracy, recall, precision and f score. Using Logistic Regression, it is found that alternative job opportunity, gender, education, willing to relocate from the workplace, alternative job opportunity, job stress and attitude towards COVID affects the employee's intent to leave the organization to a greater extent.",
        "DOI": "10.1109/I-SMAC49090.2020.9243552",
        "paper_author": "Monisaa Tharani S.K.",
        "affiliation_name": "Kumaraguru College of Technology",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India",
        "affiliation_id": "60012454",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Efficient hyperparameter optimization through model-based reinforcement learning",
        "publication": "Neurocomputing",
        "citied_by": "60",
        "cover_date": "2020-10-07",
        "Abstract": "Hyperparameter tuning is critical for the performance of machine learning algorithms. However, a noticeable limitation is the high computational cost of algorithm evaluation for complex models or for large datasets, which makes the tuning process highly inefficient. In this paper, we propose a novel model-based method for efficient hyperparameter optimization. Firstly, we frame this optimization process as a reinforcement learning problem and then employ an agent to tune hyperparameters sequentially. In addition, a model that learns how to evaluate an algorithm is used to speed up the training. However, model inaccuracy is further exacerbated by long-term use, resulting in collapse performance. We propose a novel method for controlling the model use by measuring the impact of the model on the policy and limiting it to a proper range. Thus, the horizon of the model use can be dynamically adjusted. We apply the proposed method to tune the hyperparameters of the extreme gradient boosting and convolutional neural networks on 101 tasks. The experimental results verify that the proposed method achieves the highest accuracy on 86.1% of the tasks, compared with other state-of-the-art methods and the average ranking of runtime is significant lower than all methods by using the predictive model.",
        "DOI": "10.1016/j.neucom.2020.06.064",
        "paper_author": "Wu J.",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60005465",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Analyzing Air Quality to Model Human Livability using Machine Learning Techniques",
        "publication": "2020 Global Conference on Wireless and Optical Technologies, GCWOT 2020",
        "citied_by": "0",
        "cover_date": "2020-10-06",
        "Abstract": "Pollutants (mostly gases) found in the air that cause damage and negative changes in the environment is termed as air pollution. Air pollutants when released into the environment effects human health directly or in an indirect manner. Along with this it causes multiple environmental changes, such as ozone depletion, global climate change, eutrophication and forest damages. These pollutants also effect on wildlife and crops. Since the science behind air pollution has remained steady, we have made an attempt to develop a model for human livability based on the quantities of four major air pollutants in the air, namely; Sulphur Dioxide (SO2), Nitrogen Dioxide (NO2), Carbon Monoxide (CO), and ground level ozone (O3). The results of this study would help researchers to assess human livability conditions in different areas, using data collected for the aforementioned pollutants in that area. Results are also helpful in drafting policies for improving the quality of living in different places, in a more organized fashion.",
        "DOI": "10.1109/GCWOT49901.2020.9391626",
        "paper_author": "Khan M.K.",
        "affiliation_name": "Karachi Institute of Economics and Technology",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60166769",
        "affiliation_state": "Sindh"
    },
    {
        "paper_title": "Harnessing advances in agricultural technologies to optimize resource utilization in the food-energy-water nexus",
        "publication": "Annual Review of Resource Economics",
        "citied_by": "36",
        "cover_date": "2020-10-06",
        "Abstract": "The food-energy-water (FEW) nexus is facing grand challenges in meeting increasing demand resulting from global changes in climate, economy, and population. Emerging technologies are expected to play a critical role in responding to these challenges. Focusing on four types of prominent emerging technologies (namely precision agriculture coupled with big data and machine learning, gene editing, second-generation biofuels, and agrivoltaics), this article reviews existing studies regarding opportunities and challenges of these emerging technologies to address issues of the FEW nexus. Drivers of innovation and adoption of these emerging technologies as well as the role of public policies that interact with these drivers are reviewed. Finally, this review also discusses research gaps that need to be filled to harness the potential benefits of these emerging technologies.",
        "DOI": "10.1146/annurev-resource-110319-115428",
        "paper_author": "Miao R.",
        "affiliation_name": "Auburn University",
        "affiliation_city": "Auburn",
        "affiliation_country": "United States",
        "affiliation_id": "60011754",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "Churn Prediction Estimation Based on Machine Learning Methods",
        "publication": "2020 IEEE 2nd International Conference on System Analysis and Intelligent Computing, SAIC 2020",
        "citied_by": "3",
        "cover_date": "2020-10-05",
        "Abstract": "Customer churn prediction is classic task of machine learning, the relevance of which continues to grow. This is due to the fact that business companies collect more data about their customers and their behavior every year. A model that predicts whether a customer churn will occur in the future allows a business to build an optimal personalized pricing policy to retain a customer. Existing approaches for solving the problem of churn prediction for different areas are analyzed. A strategy for determining the period of customer churn is proposed and the optimal variant of data labeling is selected, which allows to convert the problem to a typical binary classification problem. A set of data from the Prozorro system was chosen for practical application of the approaches. Ensemble tree methods (Random Forest, XGBoost, LightGBM) were chosen as learning algorithms. Customer churn prediction is one of the many applications in today's world. Knowledge of mathematics and machine learning algorithms, along with the correct ability to build a problem statement - are the key skills of a specialist who studies it.",
        "DOI": "10.1109/SAIC51296.2020.9239230",
        "paper_author": "Malyar M.",
        "affiliation_name": "Uzhhorod National University",
        "affiliation_city": "Uzhorod",
        "affiliation_country": "Ukraine",
        "affiliation_id": "60068539",
        "affiliation_state": "Zakarpattia"
    },
    {
        "paper_title": "Machine learning modeling for energy consumption of residential and commercial sectors",
        "publication": "Energies",
        "citied_by": "31",
        "cover_date": "2020-10-05",
        "Abstract": "Energy has a strategic role in the economic and social development of countries. In the last few decades, energy demand has been increasing exponentially across the world, and predicting energy demand has become one of the main concerns in many countries. The residential and commercial sectors constitute about 34.7% of global energy consumption. Anticipating energy demand in these sectors will help governments to supply energy sources and to develop their sustainable energy plans such as using renewable and non-renewable energy potentials for the development of a secure and environmentally friendly energy system. Modeling energy consumption in the residential and commercial sectors enables identification of the influential economic, social, and technological factors, resulting in a secure level of energy supply. In this paper, we forecast residential and commercial energy demands in Iran using three different machine learning methods, including multiple linear regression, logarithmic multiple linear regression methods, and nonlinear autoregressive with exogenous input artificial neural networks. These models are developed based on several factors, including the share of renewable energy sources in final energy consumption, gross domestic production, population, natural gas price, and the electricity price. According to the results of the three machine learning methods applied in our study, by 2040, Iranian residential and commercial energy consumption will be 76.97, 96.42 and 128.09 Mtoe, respectively. Results show that Iran must develop and implement new policies to increase the share of renewable energy supply in final energy consumption.",
        "DOI": "10.3390/EN13195171",
        "paper_author": "Nabavi S.A.",
        "affiliation_name": "Shahid Beheshti University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60032873",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Exploring the injury severity risk factors in fatal crashes with neural network",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "39",
        "cover_date": "2020-10-02",
        "Abstract": "A better understanding of circumstances contributing to the severity outcome of traffic crashes is an important goal of road safety studies. An in-depth crash injury severity analysis is vital for the proactive implementation of appropriate mitigation strategies. This study proposes an improved feed-forward neural network (FFNN) model for predicting injury severity associated with individual crashes using three years (2017–2019) of crash data collected along 15 rural highways in the Kingdom of Saudi Arabia (KSA). A total of 12,566 crashes were recorded during the study period with a binary injury severity outcome (fatal or non-fatal injury) for the variable to be predicted. FFNN architecture with back-propagation (BP) as a training algorithm, logistic as activation function, and six number of hidden neurons in the hidden layer yielded the best model performance. Results of model prediction for the test data were analyzed using different evaluation metrics such as overall accuracy, sensitivity, and specificity. Prediction results showed the adequacy and robust performance of the proposed method. A detailed sensitivity analysis of the optimized NN was also performed to show the impact and relative influence of different predictor variables on resulting crash injury severity. The sensitivity analysis results indicated that factors such as traffic volume, average travel speeds, weather conditions, on-site damage conditions, road and vehicle type, and involvement of pedestrians are the most sensitive variables. The methods applied in this study could be used in big data analysis of crash data, which can serve as a rapid-useful tool for policymakers to improve highway safety.",
        "DOI": "10.3390/ijerph17207466",
        "paper_author": "Jamal A.",
        "affiliation_name": "King Fahd University of Petroleum and Minerals",
        "affiliation_city": "Dhahran",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60009506",
        "affiliation_state": "Ash Sharqiyah"
    },
    {
        "paper_title": "The Path Planning of Mobile Robot by Neural Networks and Hierarchical Reinforcement Learning",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "99",
        "cover_date": "2020-10-02",
        "Abstract": "Existing mobile robots cannot complete some functions. To solve these problems, which include autonomous learning in path planning, the slow convergence of path planning, and planned paths that are not smooth, it is possible to utilize neural networks to enable to the robot to perceive the environment and perform feature extraction, which enables them to have a fitness of environment to state action function. By mapping the current state of these actions through Hierarchical Reinforcement Learning (HRL), the needs of mobile robots are met. It is possible to construct a path planning model for mobile robots based on neural networks and HRL. In this article, the proposed algorithm is compared with different algorithms in path planning. It underwent a performance evaluation to obtain an optimal learning algorithm system. The optimal algorithm system was tested in different environments and scenarios to obtain optimal learning conditions, thereby verifying the effectiveness of the proposed algorithm. Deep Deterministic Policy Gradient (DDPG), a path planning algorithm for mobile robots based on neural networks and hierarchical reinforcement learning, performed better in all aspects than other algorithms. Specifically, when compared with Double Deep Q-Learning (DDQN), DDPG has a shorter path planning time and a reduced number of path steps. When introducing an influence value, this algorithm shortens the convergence time by 91% compared with the Q-learning algorithm and improves the smoothness of the planned path by 79%. The algorithm has a good generalization effect in different scenarios. These results have significance for research on guiding, the precise positioning, and path planning of mobile robots.",
        "DOI": "10.3389/fnbot.2020.00063",
        "paper_author": "Yu J.",
        "affiliation_name": "Chongqing University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China",
        "affiliation_id": "60023380",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Lstm-based forecasting for urban construction waste generation",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "37",
        "cover_date": "2020-10-02",
        "Abstract": "Accurate forecasts of construction waste are important for recycling the waste and formulating relevant governmental policies. Deficiencies in reliable forecasting methods and historical data hinder the prediction of this waste in long-or short-term planning. To effectively forecast construction waste, a time-series forecasting method is proposed in this study, based on a three-layer long short-term memory (LSTM) network and univariate time-series data with limited sample points. This method involves network structure design and implementation algorithms for network training and the forecasting process. Numerical experiments were performed with statistical construction waste data for Shanghai and Hong Kong. Compared with other time-series forecasting models such as ridge regression (RR), support vector regression (SVR), and back-propagation neural networks (BPNN), this paper demonstrates that the proposed LSTM-based forecasting model is effective and accurate in predicting construction waste generation.",
        "DOI": "10.3390/su12208555",
        "paper_author": "Huang L.",
        "affiliation_name": "Hohai University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60010851",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Design of a reinforcement learning-based lane keeping planning agent for automated vehicles",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "33",
        "cover_date": "2020-10-02",
        "Abstract": "Reinforcement learning-based approaches are widely studied in the literature for solving different control tasks for Connected and Autonomous Vehicles, from which this paper deals with the problem of lateral control of a dynamic nonlinear vehicle model, performing the task of lane-keeping. In this area, the appropriate formulation of the goals and environment information is crucial, for which the research outlines the importance of lookahead information, enabling to accomplish maneuvers with complex trajectories. Another critical part is the real-time manner of the problem. On the one hand, optimization or search based methods, such as the presented Monte Carlo Tree Search method, can solve the problem with the trade-off of high numerical complexity. On the other hand, single Reinforcement Learning agents struggle to learn these tasks with high performance, though they have the advantage that after the training process, they can operate in a real-time manner. Two planning agent structures are proposed in the paper to resolve this duality, where the machine learning agents aid the tree search algorithm. As a result, the combined solution provides high performance and low computational needs.",
        "DOI": "10.3390/app10207171",
        "paper_author": "Kővári B.",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary",
        "affiliation_id": "60030035",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Interpretable policy derivation for reinforcement learning based on evolutionary feature synthesis",
        "publication": "Complex and Intelligent Systems",
        "citied_by": "16",
        "cover_date": "2020-10-01",
        "Abstract": "Reinforcement learning based on the deep neural network has attracted much attention and has been widely used in real-world applications. However, the black-box property limits its usage from applying in high-stake areas, such as manufacture and healthcare. To deal with this problem, some researchers resort to the interpretable control policy generation algorithm. The basic idea is to use an interpretable model, such as tree-based genetic programming, to extract policy from other black box modes, such as neural networks. Following this idea, in this paper, we try yet another form of the genetic programming technique, evolutionary feature synthesis, to extract control policy from the neural network. We also propose an evolutionary method to optimize the operator set of the control policy for each specific problem automatically. Moreover, a policy simplification strategy is also introduced. We conduct experiments on four reinforcement learning environments. The experiment results reveal that evolutionary feature synthesis can achieve better performance than tree-based genetic programming to extract policy from the neural network with comparable interpretability.",
        "DOI": "10.1007/s40747-020-00175-y",
        "paper_author": "Zhang H.",
        "affiliation_name": "East China Normal University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60021200",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Good systems, bad data?: Interpretations of AI hype and failures",
        "publication": "Proceedings of the Association for Information Science and Technology",
        "citied_by": "25",
        "cover_date": "2020-10-01",
        "Abstract": "Artificial intelligence (AI), including machine learning (ML), is widely viewed as having substantial transformative potential across society, and novel implementations of these technologies promise new modes of living, working, and community engagement. Data and the algorithms that operate upon it thus operate under an expansive ethical valence, bearing consequence to both the development of these potentially transformative technologies and our understanding of how best to manage and support its impact. This paper reports upon an interview-driven study of stakeholders engaged with technology development, policy, and law relating to AI. Among our participating stakeholders, unexpected outcomes and flawed implementations of AI, especially those leading to negative social consequences, are often attributed to ill-structured, incomplete, or biased data, and the algorithms and interpretations that might produce negative social consequence are seen as neutrally representing the data, or otherwise blameless in that consequence. We propose a more complex infrastructural view of the tools, data, and operation of AI systems as necessary to the production of social good, and explore how representations of the successes and failures of these systems, even among experts, tend to valorize algorithmic analysis and locate fault at the quality of the data rather than the implementation of systems.",
        "DOI": "10.1002/pra2.275",
        "paper_author": "Slota S.C.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "The open data challenge: An analysis of 124,000 data availability statements and an ironic lesson about data management plans",
        "publication": "Data Intelligence",
        "citied_by": "6",
        "cover_date": "2020-10-01",
        "Abstract": "Data availability statements can provide useful information about how researchers actually share research data. We used unsupervised machine learning to analyze 124,000 data availability statements submitted by research authors to 176 Wiley journals between 2013 and 2019. We categorized the data availability statements, and looked at trends over time. We found expected increases in the number of data availability statements submitted over time, and marked increases that correlate with policy changes made by journals. Our open data challenge becomes to use what we have learned to present researchers with relevant and easy options that help them to share and make an impact with new research data.",
        "DOI": "10.1162/dint_a_00061",
        "paper_author": "Graf C.",
        "affiliation_name": "Wiley",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "118642695",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Evaluation Method of Company Payment Status Based on Historical Data of Provident Fund Payment",
        "publication": "Proceedings - 2020 International Conference on Big Data and Artificial Intelligence and Software Engineering, ICBASE 2020",
        "citied_by": "1",
        "cover_date": "2020-10-01",
        "Abstract": "The housing provident fund system is the state's incentive policy to solve the housing problems of low-income families, and more and more companies are beginning to pay provident funds. In the past, there is little research on the evaluation method of the company provident fund payment status. To effectively evaluate the willingness and ability of the company to pay the provident fund, this paper designs an evaluation method of the company's payment status based on historical data of the provident fund. This method can be used as a basis for future provident fund evaluations. First, construct a feature set from multi-source data, and use Spearman correlation coefficient to extract the optimal feature subset. Then, according to the two features that have the greatest impact on the provident fund, the provident fund payment rating is calculated. Finally, we select random samples as the training set, and train in models such as LightGBM Random Forest XGBoost DeepGBM. The results show that LightGBM can be better applied to the evaluation of historical provident fund data.",
        "DOI": "10.1109/ICBASE51474.2020.00032",
        "paper_author": "Xiong W.",
        "affiliation_name": "Chongqing Housing Provident Fund Management Center",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China",
        "affiliation_id": "110231331",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Decentralized vs. Distributed Organization: Blockchain, Machine Learning and the Future of the Digital Platform",
        "publication": "Organization Theory",
        "citied_by": "99",
        "cover_date": "2020-10-01",
        "Abstract": "The terms decentralized organization and distributed organization are often used interchangeably, despite describing two distinct phenomena. I propose distinguishing decentralization, as the dispersion of organizational communications, from distribution, as the dispersion of organizational decision-making. Organizations can be distributed without being decentralized (and vice versa), and having multiple management layers directly affects only distribution – not decentralization. This proposed distinction has implications for understanding the growth of digital platforms (e.g. amazon.com), which dominate the global economy in the 21st century. While prominent platforms typically use machine learning as their core technology to transform inputs (e.g. data) into outputs (e.g. matchmaking services), blockchain has emerged as an alternative technological blueprint. I argue that blockchain enables platforms that are both decentralized and distributed (e.g. Bitcoin), whereas machine learning fosters centralized communications and the concentration of decision-making (e.g. Facebook Inc.). This distinction has crucial implications for antitrust policy, which, I contend, should shift both its analysis and its target of action away from the corporate level and focus instead on the data level. Based on this essay’s framework, I make several predictions regarding the future of competition between centralized and decentralized platforms, the evolution of government regulation, and broader implications for managers in the digital economy and for the business schools charged with their education. I conclude with reflections on the opportunity to revive cybernetic thinking for preventing a dystopian future dominated by a handful of platform behemoths.",
        "DOI": "10.1177/2631787720977052",
        "paper_author": "Vergne J.P.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The static game model and application of private equity companies' compliance management and government supervision",
        "publication": "Proceedings - 2020 2nd International Conference on Machine Learning, Big Data and Business Intelligence, MLBDBI 2020",
        "citied_by": "0",
        "cover_date": "2020-10-01",
        "Abstract": "In recent years, China's private equity market has gradually developed and expanded, and potential risks have become increasingly prominent. Although the government has introduced a series of regulatory policies, the current private equity market in China is still dominated by self-discipline, with low market access thresholds and risk monitoring mechanisms. The system is not sound and the supervision is insufficient. In this context, this article is based on game theory to study the regulatory and regulated game behaviors between private equity fund companies (hereinafter referred to as private equity companies) and regulatory agencies. This article mainly analyzes the four game modes of strong supervision and weak supervision of regulators, and compliant management and violating management of private equity companies, and constructs a static game model between private equity companies and regulators. Then analyze the relevant factors that affect the decision-making of regulators and private equity companies. Finally, actual data is selected to analyze relevant influencing factors. The research in this article has practical reference value for the supervision of the private equity market.",
        "DOI": "10.1109/MLBDBI51377.2020.00085",
        "paper_author": "Wei M.",
        "affiliation_name": "School of Business",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao",
        "affiliation_id": "60199590",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Research on E-Commerce Security and Data Analysis Platform in the Era of Big Data",
        "publication": "Proceedings - 2020 2nd International Conference on Machine Learning, Big Data and Business Intelligence, MLBDBI 2020",
        "citied_by": "1",
        "cover_date": "2020-10-01",
        "Abstract": "With the rapid development of e-commerce and mobile communication in China, e-commerce platform has been widely used in various industries. How much e-commerce stores, whether it can guarantee the security of transaction information, whether it can analyze and study structured and unstructured data, and whether it can guarantee the security of stored data are all the key factors we need to consider. In this paper, the data and e-commerce security together, and to analyze the security system of e-commerce and discuss the prevention of hidden security policy. When the emergence of e-commerce big data technology can effectively solve the problems existing in e-commerce security, the Hadoop structure is introduced through Apache Hadoop and the Hadoop product Yarn is analyzed with emphasis. From the perspective of electronic security data, the hidden dangers of e-commerce can be effectively analyzed, and the security system of e-commerce can be effectively improved.",
        "DOI": "10.1109/MLBDBI51377.2020.00087",
        "paper_author": "Tan Q.",
        "affiliation_name": "Shandong University of Finance and Economics",
        "affiliation_city": "Jinan",
        "affiliation_country": "China",
        "affiliation_id": "60122420",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "LEGION: Visually compare modeling techniques for regression",
        "publication": "Proceedings - 2020 IEEE Visualization in Data Science, VDS 2020",
        "citied_by": "3",
        "cover_date": "2020-10-01",
        "Abstract": "People construct machine learning (ML) models for various use cases in varied domains such as in healthcare, finance, public-policy, etc. In doing so they aim to improve a models' performance by adopting various strategies, such as changing input data (data augmentation), tuning model hyperparameters, performing feature engineering that includes feature extraction, feature augmentation or feature transformation. However, how would users know which of these model construction strategies to adopt for their problem Following any or all of these approaches allows the construction of a gigantic set of models, from which users may select model(s) suited to their data analytic task. This problem of model selection is non-trivial because in real-world use cases many of the best performing models (in relation to a specified metric) may appear to serve users' goal but often exhibits nuances and tradeoffs (e.g, may weight features differently, varying compute times to train, or may predict relevant data instances differently etc.). This paper aims to solve the problem of how to construct models and how to select a preferred modeling strategy by allowing users to compare the differences and similarities between multiple regression models, and then learn not only about the model but also about their data. This learning further empowers them to select model(s) that more precisely suit their analysis goals. We present LEGION, a visual analytic tool that helps users to compare and select regression models constructed either by tuning their hyperparameters or by feature engineering. We also present two use cases on real world datasets validating the utility and effectiveness of our tool.",
        "DOI": "10.1109/VDS51726.2020.00006",
        "paper_author": "Das S.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "A convolutional neural network model for marble quality classification",
        "publication": "SN Applied Sciences",
        "citied_by": "2",
        "cover_date": "2020-10-01",
        "Abstract": "The fundamental policy of marble industries is to establish sustainable high-quality products in a standardized manner. Identification and classification of different types of marbles is a critical task that is usually carried out by human experts. However, marble quality classification by humans can be time-consuming, error-prone, inconsistent, and subjective. Automated and computerized approaches are required to obtain faster, more reliable, and less subjective results. In this study, a deep learning model is developed to perform multi-classification of marble slab images with six different quality types. Blur filter, 5 ✕ 5 low-pass 2D linear separable convolution filter using Gaussian kernel, and erosion filter were applied to the images for data augmentation, and a special convolutional neural network (CNN) architecture was designed and implemented. It has been observed that the data augmentation approach for marble image samples has significantly improved the accuracy of the CNN model ranging between 0.922 and 0.961.",
        "DOI": "10.1007/s42452-020-03520-5",
        "paper_author": "Karaali İ.",
        "affiliation_name": "Dokuz Eylül Üniversitesi",
        "affiliation_city": "Izmir",
        "affiliation_country": "Türkiye",
        "affiliation_id": "60014930",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Load Balancing model based on Machine Learning and Segment Routing in SDN",
        "publication": "2020 International Conference Automatics and Informatics, ICAI 2020 - Proceedings",
        "citied_by": "12",
        "cover_date": "2020-10-01",
        "Abstract": "Because of increased number of network devices in the world, as well as the need for the network environment to provide dynamics of faults and adaptability to load changes, it is difficult and complicated network to be managed. By applying an approach called Software Defined Networks (SDN), the separation of the control and data planes is achieved. This allows the creation and deployment of new network applications to be easier, as well as provides simplification and flexibility in network policy enforcement, facilitating network configuration and management. The main problems in SDN are load balancing and segment routing. This paper proposes a model which aims to reduce not only the overall load on the network, but also to reduce the bandwidth and improve the routing mechanism on the SDN networks. It combines segment routing algorithm and load balancing mechanisms based on machine learning.",
        "DOI": "10.1109/ICAI50593.2020.9311385",
        "paper_author": "Todorov D.",
        "affiliation_name": "Technical University of Varna",
        "affiliation_city": "Varna",
        "affiliation_country": "Bulgaria",
        "affiliation_id": "60005700",
        "affiliation_state": "Varna"
    },
    {
        "paper_title": "Proactive container auto-scaling for cloud native machine learning services",
        "publication": "IEEE International Conference on Cloud Computing, CLOUD",
        "citied_by": "23",
        "cover_date": "2020-10-01",
        "Abstract": "Understanding the resource usage behaviors of the ever-increasing machine learning workloads are critical to cloud providers offering Machine Learning (ML) services. Capable of auto-scaling resources for customer workloads can significantly improve resource utilization, thus greatly reducing the cost. Here we leverage the AI4DL framework [1] to characterize workload and discover resource consumption phases. We advance the existing technology to an incremental phase discovery method that applies to more general types of ML workload for both training and inference. We use a time-window MultiLayer Perceptron (MLP) to predict phases in containers with different types of workload. Then, we propose a predictive vertical auto-scaling policy to resize the container dynamically according to phase predictions. We evaluate our predictive auto-scaling policies on 561 long-running containers with multiple types of ML workloads. The predictive policy can reduce up to 38% of allocated CPU compared to the default resource provisioning policies by developers. By comparing our predictive policies with commonly used reactive auto-scaling policies, we find that they can accurately predict sudden phase transitions (with an F1-score of 0.92) and significantly reduce the number of out-of-memory errors (350 vs. 20). Besides, we show that the predictive auto-scaling policy maintains the number of resizing operations close to the best reactive policies.",
        "DOI": "10.1109/CLOUD49709.2020.00070",
        "paper_author": "Buchaca D.",
        "affiliation_name": "Centro Nacional de Supercomputación",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain",
        "affiliation_id": "60097745",
        "affiliation_state": "Barcelona"
    },
    {
        "paper_title": "Prevention and Control of Emerging Infectious Diseases in Human Populations",
        "publication": "Proceedings - 2020 19th Distributed Computing and Applications for Business Engineering and Science, DCABES 2020",
        "citied_by": "4",
        "cover_date": "2020-10-01",
        "Abstract": "The prevention, control and prediction of emerging infectious diseases are vital in order to effectively manage their spread and impact. Over the years many modelling techniques have been developed for the management of infectious diseases. However, emerging diseases are linked to selective pressures caused by humans, for example environmental pressure such as urbanisation and habitat fragmentation. In this paper we present a new approach, which combines human behavioural factors together with advanced mathematical modelling and machine learning, for preventing, monitoring and predicting future epidemics. This will help medical professionals and policy makers to optimize, in real-Time, response efforts to major outbreaks.",
        "DOI": "10.1109/DCABES50732.2020.00092",
        "paper_author": "Khaddaj S.",
        "affiliation_name": "Artemedis International",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "125617907",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Estimating countries' peace index through the lens of the world news as monitored by GDELT",
        "publication": "Proceedings - 2020 IEEE 7th International Conference on Data Science and Advanced Analytics, DSAA 2020",
        "citied_by": "6",
        "cover_date": "2020-10-01",
        "Abstract": "Peacefulness is a principal dimension of well-being, and its measurement has lately drawn the attention of researchers and policy-makers. During the last years, novel digital data streams have drastically changed research in this field. In the current study, we exploit information extracted from Global Data on Events, Location, and Tone (GDELT) digital news database, to capture peacefulness through the Global Peace Index (GPI). Applying machine learning techniques, we demonstrate that news media attention, sentiment, and social stability from GDELT can be used as proxies for measuring GPI at a monthly level. Additionally, through the variable importance analysis, we show that each country's socio-economic, political, and military profile emerges. This could bring added value to researchers interested in \"Data Science for Social Good\", to policy-makers, and peacekeeping organizations since they could monitor peacefulness almost real-time, and therefore facilitate timely and more efficient policy-making.",
        "DOI": "10.1109/DSAA49011.2020.00034",
        "paper_author": "Voukelatou V.",
        "affiliation_name": "Istituto di Scienza e Tecnologie dell'Informazione A. Faedo",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60085207",
        "affiliation_state": "PI"
    },
    {
        "paper_title": "Designing high-fidelity multi-qubit gates for semiconductor quantum dots through deep reinforcement learning",
        "publication": "Proceedings - IEEE International Conference on Quantum Computing and Engineering, QCE 2020",
        "citied_by": "3",
        "cover_date": "2020-10-01",
        "Abstract": "In this paper, we present a machine learning framework to design high-fidelity multi-qubit gates for quantum processors based on quantum dots in silicon, with qubits encoded in the spin of single electrons. In this hardware architecture, the control landscape is vast and complex, so we use the deep reinforcement learning method to design optimal control pulses to achieve high fidelity multi-qubit gates. In our learning model, a simulator models the physical system of quantum dots and performs the time evolution of the system, and a deep neural network serves as the function approximator to learn the control policy. We evolve the Hamiltonian in the full state-space of the system, and enforce realistic constraints to ensure experimental feasibility.",
        "DOI": "10.1109/QCE49297.2020.00014",
        "paper_author": "Daraeizadeh S.",
        "affiliation_name": "Intel Corporation",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States",
        "affiliation_id": "60033010",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Core Placement Optimization for Multi-chip Many-core Neural Network Systems with Reinforcement Learning",
        "publication": "ACM Transactions on Design Automation of Electronic Systems",
        "citied_by": "14",
        "cover_date": "2020-10-01",
        "Abstract": "Multi-chip many-core neural network systems are capable of providing high parallelism benefited from decentralized execution, and they can be scaled to very large systems with reasonable fabrication costs. As multi-chip many-core systems scale up, communication latency related effects will take a more important portion in the system performance. While previous work mainly focuses on the core placement within a single chip, there are two principal issues still unresolved: the communication-related problems caused by the non-uniform, hierarchical on/off-chip communication capability in multi-chip systems, and the scalability of these heuristic-based approaches in a factorially growing search space. To this end, we propose a reinforcement-learning-based method to automatically optimize core placement through deep deterministic policy gradient, taking into account information of the environment by performing a series of trials (i.e., placements) and using convolutional neural networks to extract spatial features of different placements. Experimental results indicate that compared with a naive sequential placement, the proposed method achieves 1.99× increase in throughput and 50.5% reduction in latency; compared with the simulated annealing, an effective technique to approximate the global optima in an extremely large search space, our method improves the throughput by 1.22× and reduces the latency by 18.6%. We further demonstrate that our proposed method is capable to find optimal placements taking advantages of different communication properties caused by different system configurations, and work in a topology-agnostic manner.",
        "DOI": "10.1145/3418498",
        "paper_author": "Wu N.",
        "affiliation_name": "University of California, Santa Barbara",
        "affiliation_city": "Santa Barbara",
        "affiliation_country": "United States",
        "affiliation_id": "60029241",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A Real-time Prediction Method of Curbside Parking Occupancy Incorporating Dynamic Management Policies",
        "publication": "Jiaotong Yunshu Xitong Gongcheng Yu Xinxi/Journal of Transportation Systems Engineering and Information Technology",
        "citied_by": "3",
        "cover_date": "2020-10-01",
        "Abstract": "This paper proposes a machine learning method to predict curbside parking occupancy in dynamic parking policies. We apply the convolutional long short term memory neural network (ConvLSTM) to learn the temporal and spatial features of the data simultaneously. Based on the 4.92 million transaction records of parking meters in San Francisco, we train a policy model that incorporates the information of dynamic pricing and parking limits, and a non-policy model without other information. The results show that both the policy and non-policy model can predict the curbside parking occupancy, and the policy model has better performance in training efficiency and prediction accuracy. Meanwhile, the errors of the non-policy model increase with different parking policies, whereas the policy model can always obtain high prediction accuracy.",
        "DOI": "10.16097/j.cnki.1009-6744.2020.05.016",
        "paper_author": "Zhao C.",
        "affiliation_name": "Key Laboratory of Road and Traffic Engineering of the State Ministry of Education",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60129238",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A machine learning approach to the digitalization of bank customers: Evidence from random and causal forests",
        "publication": "PLoS ONE",
        "citied_by": "49",
        "cover_date": "2020-10-01",
        "Abstract": "Understanding the digital jump of bank customers is key to design strategies to bring on board and keep online users, as well as to explain the increasing competition from new providers of financial services (such as BigTech and FinTech). This paper employs a machine learning approach to examine the digitalization process of bank customers using a comprehensive consumer finance survey. By employing a set of algorithms (random forests, conditional inference trees and causal forests) this paper identities the features predicting bank customers’ digitalization process, illustrates the sequence of consumers’ decision-making actions and explores the existence of causal relationships in the digitalization process. Random forests are found to provide the highest performance–they accurately predict 88.41% of bank customers’ online banking adoption and usage decisions. We find that the adoption of digital banking services begins with information-based services (e.g., checking account balance), conditional on the awareness of the range of online services by customers, and then is followed by transactional services (e.g., online/mobile money transfer). The diversification of the use of online channels is explained by the consciousness about the range of services available and the safety perception. A certain degree of complementarity between bank and non-bank digital channels is also found. The treatment effect estimations of the causal forest algorithms confirm causality of the identified explanatory factors. These results suggest that banks should address the digital transformation of their customers by segmenting them according to their revealed preferences and offering them personalized digital services. Additionally, policymakers should promote financial digitalization, designing policies oriented towards making consumers aware of the range of online services available.",
        "DOI": "10.1371/journal.pone.0240362",
        "paper_author": "Carbo-Valverde S.",
        "affiliation_name": "Universidad de Granada",
        "affiliation_city": "Granada",
        "affiliation_country": "Spain",
        "affiliation_id": "60027844",
        "affiliation_state": "Granada"
    },
    {
        "paper_title": "Factors affecting COVID-19 infected and death rates inform lockdown-related policymaking",
        "publication": "PLoS ONE",
        "citied_by": "78",
        "cover_date": "2020-10-01",
        "Abstract": "Background After claiming nearly five hundred thousand lives globally, the COVID-19 pandemic is showing no signs of slowing down. While the UK, USA, Brazil and parts of Asia are bracing themselves for the second wave—or the extension of the first wave—it is imperative to identify the primary social, economic, environmental, demographic, ethnic, cultural and health factors contributing towards COVID-19 infection and mortality numbers to facilitate mitigation and control measures. Methods We process several open-access datasets on US states to create an integrated dataset of potential factors leading to the pandemic spread. We then apply several supervised machine learning approaches to reach a consensus as well as rank the key factors. We carry out regression analysis to pinpoint the key pre-lockdown factors that affect post-lockdown infection and mortality, informing future lockdown-related policy making. Findings Population density, testing numbers and airport traffic emerge as the most discriminatory factors, followed by higher age groups (above 40 and specifically 60+). Post-lockdown infected and death rates are highly influenced by their pre-lockdown counterparts, followed by population density and airport traffic. While healthcare index seems uncorrelated with mortality rate, principal component analysis on the key features show two groups: states (1) forming early epicenters and (2) experiencing strong second wave or peaking late in rate of infection and death. Finally, a small case study on New York City shows that days-to-peak for infection of neighboring boroughs correlate better with inter-zone mobility than the inter-zone distance. Interpretation States forming the early hotspots are regions with high airport or road traffic resulting in human interaction. US states with high population density and testing tend to exhibit consistently high infected and death numbers. Mortality rate seems to be driven by individual physiology, preexisting condition, age etc., rather than gender, healthcare facility or ethnic predisposition. Finally, policymaking on the timing of lockdowns should primarily consider the pre-lockdown infected numbers along with population density and airport traffic.",
        "DOI": "10.1371/journal.pone.0241165",
        "paper_author": "Roy S.",
        "affiliation_name": "UNC School of Medicine",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States",
        "affiliation_id": "60020469",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Opportunities and Challenges Surrounding the Use of Data from Wearable Sensor Devices in Health Care: Qualitative Interview Study",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "37",
        "cover_date": "2020-10-01",
        "Abstract": "Background: Wearable sensors connected via networked devices have the potential to generate data that may help to automate processes of care, engage patients, and increase health care efficiency. The evidence of effectiveness of such technologies is, however, nascent and little is known about unintended consequences. Objective: Our objective was to explore the opportunities and challenges surrounding the use of data from wearable sensor devices in health care. Methods: We conducted a qualitative, theoretically informed, interview-based study to purposefully sample international experts in health care, technology, business, innovation, and social sciences, drawing on sociotechnical systems theory. We used in-depth interviews to capture perspectives on development, design, and use of data from wearable sensor devices in health care, and employed thematic analysis of interview transcripts with NVivo to facilitate coding. Results: We interviewed 16 experts. Although the use of data from wearable sensor devices in health and care has significant potential in improving patient engagement, there are a number of issues that stakeholders need to negotiate to realize these benefits. These issues include the current gap between data created and meaningful interpretation in health and care contexts, integration of data into health care professional decision making, negotiation of blurring lines between consumer and medical care, and pervasive monitoring of health across previously disconnected contexts. Conclusions: Stakeholders need to actively negotiate existing challenges to realize the integration of data from wearable sensor devices into electronic health records. Viewing wearables as active parts of a connected digital health and care infrastructure, in which various business, personal, professional, and health system interests align, may help to achieve this.",
        "DOI": "10.2196/19542",
        "paper_author": "Azodo I.",
        "affiliation_name": "Edinburgh Medical School",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60110825",
        "affiliation_state": "Scotland"
    },
    {
        "paper_title": "Call for Special Issue Papers: Evaluation and Experimental Design in Data Mining and Machine Learning",
        "publication": "Big data",
        "citied_by": "0",
        "cover_date": "2020-10-01",
        "Abstract": "NA",
        "DOI": "10.1089/big.2020.29037.cfp2",
        "paper_author": "Ntoutsi E.",
        "affiliation_name": "Gottfried Wilhelm Leibniz Universität Hannover",
        "affiliation_city": "Hannover",
        "affiliation_country": "Germany",
        "affiliation_id": "60004935",
        "affiliation_state": "Niedersachsen"
    },
    {
        "paper_title": "CRSAL: Conversational recommender systems with adversarial learning",
        "publication": "ACM Transactions on Information Systems",
        "citied_by": "44",
        "cover_date": "2020-10-01",
        "Abstract": "Recommender systems have been attracting much attention from both academia and industry because of their ability to capture user interests and generate personalized item recommendations. As the life pace in contemporary society speeds up, traditional recommender systems are inevitably limited by their disconnected interaction styles and low adaptivity to users' evolving demands. Consequently, conversational recommender systems emerge as a prospective research area, where an intelligent dialogue agent is integrated with a recommender system. Conversational recommender systems possess the ability to accurately understand end-users' intent or request and generate human-like dialogue responses when performing recommendations. However, existing conversational recommender systems only allow the systems to ask users for more preference information, while users' further questions and concerns about the recommended items (e.g., enquiring the location of a recommended restaurant) can hardly be addressed. Though the recent task-oriented dialogue systems allow for two-way communications, they are not easy to train because of their high dependence on human guidance in terms of user intent recognition and system response generation. Hence, to enable two-way human-machine communications and tackle the challenges brought by manually crafted rules, we propose Conversational Recommender System with Adversarial Learning (CRSAL), a novel end-To-end system to tackle the task of conversational recommendation. In CRSAL, we innovatively design a fully statistical dialogue state tracker coupled with a neural policy agent to precisely capture each user's intent from limited dialogue data and generate conversational recommendation actions. We further develop an adversarial Actor-Critic reinforcement learning approach to adaptively refine the quality of generated system actions, thus ensuring coherent human-like dialogue responses. Extensive experiments on two benchmark datasets fully demonstrate the superiority of CRSAL on conversational recommendation tasks.",
        "DOI": "10.1145/3394592",
        "paper_author": "Ren X.",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60031004",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Research on the transformation path of the green intelligent port: Outlining the perspective of the evolutionary game “government–port–third-party organization”",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "16",
        "cover_date": "2020-10-01",
        "Abstract": "While promoting the global economy and trade, ports impose serious pollution on the global ocean and atmosphere. Therefore, the development of ports is restrained by the policies and measures of governments and international organizations used to cope with climate change and environmental protection. With the development of information technology, the operation and expansion of ports is facing forms of green and intelligent reform. This research aims to link the development of green intelligent ports, government policies, and third-party organizations to find the most suitable evolutionary path for the development of green intelligent ports. This paper assumes that governments will push ports to transform into green intelligent ports from the perspective of benefiting long-term interests, that the goal of ports is to maximize their profits, and that third-party organizations will actively promote the development of green intelligent ports. Based on these assumptions, this paper has established an evolutionary game theory model of “government–port–third-party organization” regarding the development of green intelligent ports. The Jacobian matrix of the game theory system was constructed by using the replicator dynamic equation, and local stability analysis was performed to obtain the equilibrium stability point of the entire system. This research reveals the limitations of the development of green intelligent ports without government involvement and explores the ability of third-party organizations to promote the implementation of policies, confirming the role of government regulation and control in promoting the development of green intelligent ports. This paper may be helpful for the development of green intelligent ports in the future. The results show that: (1) The main factors affecting the choice of port strategy are the benefits of building a green intelligent port, the intensity of government regulation, and the quantitative influence of third-party evaluation results on the port strategy selection. (2) Government decision-making plays an important role in port transformation. If the relevant government chooses the wrong strategy, then the transformation of the port will be delayed. (3) Government regulation and control need to change with the change of the evolution stage. (4) Compared with the macro-control policies of the government, the influence of the third-party organization on the port is significantly smaller.",
        "DOI": "10.3390/su12198072",
        "paper_author": "Meng B.",
        "affiliation_name": "Dalian Maritime University",
        "affiliation_city": "Dalian",
        "affiliation_country": "China",
        "affiliation_id": "60029322",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Identifying tree traits for cooling urban heat islands—a cross-city empirical analysis",
        "publication": "Forests",
        "citied_by": "30",
        "cover_date": "2020-10-01",
        "Abstract": "Research Highlights: This paper presents a cross-city empirical study on micro-climatic thermal benefits of urban trees, using machine-learning analysis to identify the importance of several in situ measured tree physiognomy traits for cooling. Background and Objectives: Green infrastructure and trees in particular play a key role in mitigating the urban heat island (UHI) effect. A more detailed understanding of the cooling potential of urban trees and specific tree traits is necessary to support tree management decisions for cooling our progressively hot cities. The goal of this study was to identify the influence and importance of various tree traits and site conditions. Materials and Methods: Surface temperature, air temperature at 1.1 m and at tree crown height, as well as wet bulb globe-temperature of shaded and fully sun-exposed reference areas, were used to study the cooling effect of seven different urban tree species. For all 100 individuals, tree height, crown base, trunk circumference, crown volume, crown area, leaf area index (LAI) and leaf area density (LAD) were measured. Measurements were conducted in the cities of Dresden, Salzburg, Szeged, and Vienna as representatives for middle European cities in different climate zones. Results: Beside site conditions, tree species, height, height of crown base, as well as trunk circumference, have a great influence on the cooling effect for city dwellers. The trunk circumference is a very valuable indicator for estimating climate regulating ecosystem services and therefore a highly robust estimator for policy makers and tree management practitioners when planning and managing urban green areas for improving the availability and provision of ecosystem services.",
        "DOI": "10.3390/f11101064",
        "paper_author": "Helletsgruber C.",
        "affiliation_name": "Universität Salzburg",
        "affiliation_city": "Salzburg",
        "affiliation_country": "Austria",
        "affiliation_id": "60002963",
        "affiliation_state": "Salzburg"
    },
    {
        "paper_title": "Enzyme activities predicted by metabolite concentrations and solvent capacity in the cell: Enzyme activities predicted by metabolite concentrations and solvent capacity in the cell",
        "publication": "Journal of the Royal Society Interface",
        "citied_by": "6",
        "cover_date": "2020-10-01",
        "Abstract": "Experimental measurements or computational model predictions of the post-translational regulation of enzymes needed in a metabolic pathway is a difficult problem. Consequently, regulation is mostly known only for well-studied reactions of central metabolism in various model organisms. In this study, we use two approaches to predict enzyme regulation policies and investigate the hypothesis that regulation is driven by the need to maintain the solvent capacity in the cell. The first predictive method uses a statistical thermodynamics and metabolic control theory framework while the second method is performed using a hybrid optimization-reinforcement learning approach. Efficient regulation schemes were learned from experimental data that either agree with theoretical calculations or result in a higher cell fitness using maximum useful work as a metric. As previously hypothesized, regulation is herein shown to control the concentrations of both immediate and downstream product concentrations at physiological levels. Model predictions provide the following two novel general principles: (1) the regulation itself causes the reactions to be much further from equilibrium instead of the common assumption that highly non-equilibrium reactions are the targets for regulation; and (2) the minimal regulation needed to maintain metabolite levels at physiological concentrations maximizes the free energy dissipation rate instead of preserving a specific energy charge. The resulting energy dissipation rate is an emergent property of regulation which may be represented by a high value of the adenylate energy charge. In addition, the predictions demonstrate that the amount of regulation needed can be minimized if it is applied at the beginning or branch point of a pathway, in agreement with common notions. The approach is demonstrated for three pathways in the central metabolism of E. coli (gluconeogenesis, glycolysis-tricarboxylic acid (TCA) and pentose phosphate-TCA) that each require different regulation schemes. It is shown quantitatively that hexokinase, glucose 6-phosphate dehydrogenase and glyceraldehyde phosphate dehydrogenase, all branch points of pathways, play the largest roles in regulating central metabolism.",
        "DOI": "10.1098/rsif.2020.0656",
        "paper_author": "Britton S.",
        "affiliation_name": "University of California, Riverside",
        "affiliation_city": "Riverside",
        "affiliation_country": "United States",
        "affiliation_id": "60029526",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "HFEL: Joint Edge Association and Resource Allocation for Cost-Efficient Hierarchical Federated Edge Learning",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "336",
        "cover_date": "2020-10-01",
        "Abstract": "Federated Learning (FL) has been proposed as an appealing approach to handle data privacy issue of mobile devices compared to conventional machine learning at the remote cloud with raw user data uploading. By leveraging edge servers as intermediaries to perform partial model aggregation in proximity and relieve core network transmission overhead, it enables great potentials in low-latency and energy-efficient FL. Hence we introduce a novel Hierarchical Federated Edge Learning (HFEL) framework in which model aggregation is partially migrated to edge servers from the cloud. We further formulate a joint computation and communication resource allocation and edge association problem for device users under HFEL framework to achieve global cost minimization. To solve the problem, we propose an efficient resource scheduling algorithm in the HFEL framework. It can be decomposed into two subproblems: resource allocation given a scheduled set of devices for each edge server and edge association of device users across all the edge servers. With the optimal policy of the convex resource allocation subproblem for a set of devices under a single edge server, an efficient edge association strategy can be achieved through iterative global cost reduction adjustment process, which is shown to converge to a stable system point. Extensive performance evaluations demonstrate that our HFEL framework outperforms the proposed benchmarks in global cost saving and achieves better training performance compared to conventional federated learning.",
        "DOI": "10.1109/TWC.2020.3003744",
        "paper_author": "Luo S.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021182",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Using the machine learning method to study the environmental footprints embodied in chinese diet",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "7",
        "cover_date": "2020-10-01",
        "Abstract": "The food system profoundly affects the sustainable development of the environment and resources. Numerous studies have shown that the food consumption patterns of Chinese residents will bring certain pressure to the environment. Food consumption patterns have individual differences. Therefore, reducing the pressure of food consumption patterns on the environment requires the precise positioning of people with high consumption tendencies. Based on the related concepts of the machine learning method, this paper designs an identification method of the population with a high environmental footprint by using a decision tree as the core and realizes the automatic identification of a large number of users. By using the microdata provided by CHNS(the China Health and Nutrition Survey), we study the relationship between residents' dietary intake and environmental resource consumption. First, we find that the impact of residents' food system on the environment shows a certain logistic normal distribution trend. Then, through the decision tree algorithm, we find that four demographic characteristics of gender, income level, education level, and region have the greatest impact on residents' environmental footprint, where the consumption trends of different characteristics are also significantly different. At the same time, we also use the decision tree to identify the population characteristics with high consumption tendency. This method can effectively improve the identification coverage and accuracy rate and promotes the improvement of residents' food consumption patterns.",
        "DOI": "10.3390/ijerph17197349",
        "paper_author": "Liang Y.",
        "affiliation_name": "China Agricultural University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013551",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Multiagent DDPG-Based Deep Learning for Smart Ocean Federated Learning IoT Networks",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "113",
        "cover_date": "2020-10-01",
        "Abstract": "This article proposes a novel multiagent deep reinforcement learning-based algorithm which can realize federated learning (FL) computation with Internet-of-Underwater-Things (IoUT) devices in the ocean environment. According to the fact that underwater networks are relatively not easy to set up reliable links by huge fading compared to wireless free-space air medium, gathering all training data for conducting centralized deep learning training is not easy. Therefore, FL-based distributed deep learning can be a suitable solution for this application. In this IoUT network (IoUT-Net) scenario, the FL system needs to construct a global learning model by aggregating the local model parameters that are obtained from individual IoUT devices. In order to reliably deliver the parameters from IoUT devices to a centralized FL machine, base station like devices are needed. Therefore, a joint cell association and resource allocation (JCARA) method is required and it is designed inspired by multiagent deep deterministic policy gradient (MADDPG) to deal with distributed situations and unexpected time-varying states. The performance evaluation results show that our proposed MADDPG-based algorithm achieves 80% and 41% performance improvements than the standard actor-critic and DDPG, respectively, in terms of the downlink throughput.",
        "DOI": "10.1109/JIOT.2020.2988033",
        "paper_author": "Kwon D.",
        "affiliation_name": "Research Laboratory",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "100475380",
        "affiliation_state": "Seoul 04798"
    },
    {
        "paper_title": "Train-Centric CBTC Meets Age of Information in Train-to-Train Communications",
        "publication": "IEEE Transactions on Intelligent Transportation Systems",
        "citied_by": "47",
        "cover_date": "2020-10-01",
        "Abstract": "Quality of service (QoS) guarantee is critical in urban rail transit. In this paper, the train-centric communication-based train control (CBTC) systems through train-to-train (T2T) wireless communication is introduced based on the modification of LTE vehicle-to-everything (LTE-V2X). To be specific, a novel train-centric CBTC systems is established based on T2T wireless communication where distributed sensing-based semi-persistent scheduling (DS-SPS) is served as the resource allocation scheme in the T2T scenario. The quantized age of information (AoI) is used as an integrated system QoS indicator of the CBTC wireless communication systems in urban rail transit. Machine learning techniques especially Q-learning is further utilized to improve system AoI performance. Simulation results show that the proposed LTE-T2T based wireless communication systems in train-centric CBTC with Q-learning can achieve improved system AoI and peak AoI performance compared with fixed SPS policy. Furthermore, the system performance of the designed LTE-T2T based wireless communication systems in train-centric CBTC with Q-learning is shown to be better than traditional LTE-M and WLAN based wireless communication systems.",
        "DOI": "10.1109/TITS.2019.2936219",
        "paper_author": "Wang X.",
        "affiliation_name": "Virginia Tech College of Engineering",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States",
        "affiliation_id": "60157272",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "A Survey on Task-Oriented Dialogue Systems",
        "publication": "Jisuanji Xuebao/Chinese Journal of Computers",
        "citied_by": "13",
        "cover_date": "2020-10-01",
        "Abstract": "The human-machine dialogue system is the core technology in the field of artificial intelligence. It is a new way of harmonious human-computer interaction, whose purpose is to provide useful information and help for users by communicating with humans in a natural and fluid language. In recent years, the breakthrough progress in deep learning technology has greatly promoted the development of human-machine dialogue technology. Therefore, human-machine dialogue technology has made substantial progress in various areas, including virtual personal assistants, entertainment, emotional chaperone, and conversational recommendation. In this paper, we first systematically describe the development process of human-machine dialogue system, and divide the human-machine dialogue system into two types according to different application scenarios, namely task-oriented dialogue systems and non-task-oriented dialogue systems. As a key branch of human machine dialogue system, task-oriented dialogue systems provide a convenient interface to help users complete tasks and have been used in a variety of applications. The non-task-oriented dialogue systems, also called known as chat robot, are different from the task-oriented dialogue systems. There are used in the open field scenarios and can handle a wide variety of problems, relying on various information and ontology in the real world to solve those problems. Secondly, from the perspectives of theoretical model, research progress, usability, problems and limitations, we analyze two main methods of task-oriented dialogue systems deeply, including pipeline method and end-to-end method. For the pipeline method, there are three modules to be introduced: Natural Language Understanding (NLU), Dialogue Management (DM), and Natural Language Generation (NLG). In the last part of this section, we summarize the advantages and disadvantages of the pipeline model. Among them, we divide the three tasks of the NLU module into text classification problems and sequence labeling problems. We describe the technical development of these two types of problems respectively, and finally summarize the current latest technological developments and trends of NLU. In the DM section, we divide the DM into dialogue state tracking (DST) task and dialogue policy learning (DPL) task. And we not only analyze and compare the representative algorithms for deep learning and reinforcement learning for DST and DP, but also describe the difficulties of the three challenging scenarios faced in the DPL process. In the end of DM section, we summarize the latest solutions and ideas to difficulties of the DM model in the task-oriented dialogue system. For the NLG module, we focus on the analysis of the relevant traditional methods and the deep learning techniques, and compare and analyze the two technologies. For the end-to-end method, there are two frameworks to build an end-to-end dialogue system, including a framework based on supervised learning and a framework of optimizing end-to-end dialog systems using reinforcement learning. At the end of this section, we summarize the advantages and limitations of the end-to-end method. Finally, we summarize the current issues that limit the development of task-oriented dialogue systems, and we discuss some of the potential trends in the future development of task-oriented dialogue systems, including low-resource task-oriented dialogue system, task-oriented dialogue system with domain adaptability and task-oriented dialogue system with domain knowledge and common sense, enhancing the understanding and reasoning ability of system.",
        "DOI": "10.11897/SP.J.1016.2020.01862",
        "paper_author": "Zhao Y.Y.",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60024542",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Monitoring forest change in the amazon using multi-temporal remote sensing data and machine learning classification on Google Earth Engine",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "80",
        "cover_date": "2020-10-01",
        "Abstract": "Deforestation causes diverse and profound consequences for the environment and species. Direct or indirect effects can be related to climate change, biodiversity loss, soil erosion, floods, landslides, etc. As such a significant process, timely and continuous monitoring of forest dynamics is important, to constantly follow existing policies and develop new mitigation measures. The present work had the aim of mapping and monitoring the forest change from 2000 to 2019 and of simulating the future forest development of a rainforest region located in the Pará state, Brazil. The land cover dynamics were mapped at five-year intervals based on a supervised classification model deployed on the cloud processing platform Google Earth Engine. Besides the benefits of reduced computational time, the service is coupled with a vast data catalogue providing useful access to global products, such as multispectral images of the missions Landsat five, seven, eight and Sentinel-2. The validation procedures were done through photointerpretation of highresolution panchromatic images obtained from CBERS (China-Brazil Earth Resources Satellite). The more than satisfactory results allowed an estimation of peak deforestation rates for the period 2000- 2006; for the period 2006-2015, a significant decrease and stabilization, followed by a slight increase till 2019. Based on the derived trends a forest dynamics was simulated for the period 2019-2028, estimating a decrease in the deforestation rate. These results demonstrate that such a fusion of satellite observations, machine learning, and cloud processing, benefits the analysis of the forest dynamics and can provide useful information for the development of forest policies.",
        "DOI": "10.3390/ijgi9100580",
        "paper_author": "Brovelli M.A.",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60023256",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Accelerating evidence-informed decision-making for the Sustainable Development Goals using machine learning",
        "publication": "Nature Machine Intelligence",
        "citied_by": "38",
        "cover_date": "2020-10-01",
        "Abstract": "The United Nations Sustainable Development Goal 2 (SDG 2) is to achieve zero hunger by 2030. We have designed Persephone, a machine learning model, to support a diverse volunteer network of 77 researchers from 23 countries engaged in creating interdisciplinary evidence syntheses in support of SDG 2. Such evidence syntheses, whatever the specific topic, assess original studies to determine the effectiveness of interventions. By gathering and summarizing current evidence and providing objective recommendations they can be valuable aids to decision-makers. However, they are time-consuming; estimates range from 18 months to three years to produce a single review. Persephone analysed 500,000 unstructured text summaries from prominent sources of agricultural research, determining with 90% accuracy the subset of studies that would eventually be selected by expert researchers. We demonstrate that machine learning models can be invaluable in placing evidence into the hands of policymakers.",
        "DOI": "10.1038/s42256-020-00235-5",
        "paper_author": "Porciello J.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Spatial variation of land use/cover composition and impact on surface urban heat island in a tropical sub-Saharan City of Accra, Ghana",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "28",
        "cover_date": "2020-10-01",
        "Abstract": "Rapid urbanization is one of the most crucial issues in the world of the 21st century. Notably, the urban heat island phenomenon is becoming more prominent in megacities and their hinterlands in temperate and subtropical climatic regions. In the daytime in summer, there exists a high possibility of accelerating the land surface temperature (LST) in desert cities, due to the alterations made by human beings in the natural environment. In this study, we investigate the spatial formation of LST in a tropical sub-Saharan city of Accra, a gateway to West Africa, using Landsat data in 2003 and 2017. Machine learning techniques and the different spatial and statistical methods such as tasseled cap transformation (TCT), urban-rural gradient, and multiresolution grid-based and landscape metrics were employed to examine procured land use/cover (LUC) and LST maps. LUC was classified into five categories: Built up, Green 1, Green 2, Bare land, and Water. The results of the analysis indicate that Built up, Green 2, and Bare land had caused the highest heating effect while Green 1 and Water had caused the considerable cooling effect during the daytime in Accra. The urban-rural difference in LST recorded 1.4 °C in 2003 and 0.28 °C in 2017. The mean size, mean shape, largest patch, and aggregation of Built up, Green 1, and Green 2 had a strong relationship with the mean LST. It is essential for urban planners to carefully examine the formation and effect of the urban heat island (UHI) for sustainable urban development and landscape policy toward mitigation and adaptation planning in Accra.",
        "DOI": "10.3390/SU12197953",
        "paper_author": "Athukorala D.",
        "affiliation_name": "University of Tsukuba",
        "affiliation_city": "Tsukuba",
        "affiliation_country": "Japan",
        "affiliation_id": "60014256",
        "affiliation_state": "Ibaraki"
    },
    {
        "paper_title": "Systematizing and upscaling urban climate change mitigation",
        "publication": "Environmental Research Letters",
        "citied_by": "12",
        "cover_date": "2020-10-01",
        "Abstract": "The question of what cities can contribute to mitigation and adapting to climate change is gaining traction among researchers and policy makers alike. However, while the field is rich with case studies, methods that provide rich data across municipalities and potentially at global scale remain underdeveloped, and comparative insights remain scarce. Here we summarize contributions to the focus issue on 'Systematizing and Upscaling Urban Climate Solutions', also drawing from presentations given at an accompanying conference in 2018. We highlight four core areas for systematizing and upscaling urban climate mitigation solutions. First, with more and better (big) data and associated machine learning methods, there is increasing potential to compare types of cities and leverage collective understanding. Second, while urban climate assessments have mostly emphasized urban planning, demand-side action as related to both behavioral change and modified social practices relevant to urban space deserve more academic attention and integration across a diverse set of social sciences. Third, climate mitigation would be intangible as a single objective at the urban scale, and measures and solutions that coordinate mitigation coherently with adaptation and broader sustainable development goals require explicit conceptualization and systematization. Forth, all insights should come together to develop governance frameworks that translate scientific exercises into concrete, realistic and organized action plans on the ground, for all cities.",
        "DOI": "10.1088/1748-9326/abb0b2",
        "paper_author": "Creutzig F.",
        "affiliation_name": "Mercator Research Institute on Global Commons and Climate Change",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60159447",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "No perfect storm for crop yield failure in Germany",
        "publication": "Environmental Research Letters",
        "citied_by": "82",
        "cover_date": "2020-10-01",
        "Abstract": "Large-scale crop yield failures are increasingly associated with food price spikes and food insecurity and are a large source of income risk for farmers. While the evidence linking extreme weather to yield failures is clear, consensus on the broader set of weather drivers and conditions responsible for recent yield failures is lacking. We investigate this for the case of four major crops in Germany over the past 20 years using a combination of machine learning and process-based modelling. Our results confirm that years associated with widespread yield failures across crops were generally associated with severe drought, such as in 2018 and to a lesser extent 2003. However, for years with more localized yield failures and large differences in spatial patterns of yield failures between crops, no single driver or combination of drivers was identified. Relatively large residuals of unexplained variation likely indicate the importance of non-weather related factors, such as management (pest, weed and nutrient management and possible interactions with weather) explaining yield failures. Models to inform adaptation planning at farm, market or policy levels are here suggested to require consideration of cumulative resource capture and use, as well as effects of extreme events, the latter largely missing in process-based models. However, increasingly novel combinations of weather events under climate change may limit the extent to which data driven methods can replace process-based models in risk assessments.",
        "DOI": "10.1088/1748-9326/aba2a4",
        "paper_author": "Webber H.",
        "affiliation_name": "Leibniz-Zentrum für Agrarlandschaftsforschung (ZALF) e. V.",
        "affiliation_city": "Muncheberg",
        "affiliation_country": "Germany",
        "affiliation_id": "60075693",
        "affiliation_state": "Brandenburg"
    },
    {
        "paper_title": "Wastewater quality estimation through spectrophotometry-based statistical models",
        "publication": "Sensors (Switzerland)",
        "citied_by": "24",
        "cover_date": "2020-10-01",
        "Abstract": "Local administrations are increasingly demanding real-time continuous monitoring of pollution in the sanitation system to improve and optimize its operation, to comply with EU environmental policies and to reach European Green Deal targets. The present work shows a full-scale Wastewater Treatment Plant field-sampling campaign to estimate COD, BOD5, TSS, P, TN and NO3−N in both influent and effluent, in the absence of pre-treatment or chemicals addition to the samples, resulting in a reduction of the duration and cost of analysis. Different regression models were developed to estimate the pollution load of sewage systems from the spectral response of wastewater samples measured at 380–700 nm through multivariate linear regressions and machine learning genetic algorithms. The tests carried out concluded that the models calculated by means of genetic algorithms can estimate the levels of five of the pollutants under study (COD, BOD5, TSS, TN and NO3−N), including both raw and treated wastewater, with an error rate below 4%. In the case of the multilinear regression models, these are limited to raw water and the estimate is limited to COD and TSS, with less than a 0.5% error rate.",
        "DOI": "10.3390/s20195631",
        "paper_author": "Carreres-Prieto D.",
        "affiliation_name": "Universidad Politecnica de Cartagena",
        "affiliation_city": "Cartagena",
        "affiliation_country": "Spain",
        "affiliation_id": "60014907",
        "affiliation_state": "Murcia"
    },
    {
        "paper_title": "Uav autonomous tracking and landing based on deep reinforcement learning strategy",
        "publication": "Sensors (Switzerland)",
        "citied_by": "35",
        "cover_date": "2020-10-01",
        "Abstract": "Unmanned aerial vehicle (UAV) autonomous tracking and landing is playing an increasingly important role in military and civil applications. In particular, machine learning has been successfully introduced to robotics-related tasks. A novel UAV autonomous tracking and landing approach based on a deep reinforcement learning strategy is presented in this paper, with the aim of dealing with the UAV motion control problem in an unpredictable and harsh environment. Instead of building a prior model and inferring the landing actions based on heuristic rules, a model-free method based on a partially observable Markov decision process (POMDP) is proposed. In the POMDP model, the UAV automatically learns the landing maneuver by an end-to-end neural network, which combines the Deep Deterministic Policy Gradients (DDPG) algorithm and heuristic rules. A Modular Open Robots Simulation Engine (MORSE)-based reinforcement learning framework is designed and validated with a continuous UAV tracking and landing task on a randomly moving platform in high sensor noise and intermittent measurements. The simulation results show that when the moving platform is moving in different trajectories, the average landing success rate of the proposed algorithm is about 10% higher than that of the Proportional-Integral-Derivative (PID) method. As an indirect result, a state-of-the-art deep reinforcement learning-based UAV control method is validated, where the UAV can learn the optimal strategy of a continuously autonomous landing and perform properly in a simulation environment.",
        "DOI": "10.3390/s20195630",
        "paper_author": "Xie J.",
        "affiliation_name": "National Space Science Center",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022860",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Investigating user perceptions of mobile app privacy: An analysis of user-submitted app reviews",
        "publication": "International Journal of Information Security and Privacy",
        "citied_by": "12",
        "cover_date": "2020-10-01",
        "Abstract": "Mobile devices and third-party applications are used by over 4.5 billion people worldwide. Third-party applications often request or even require authorized access to personal information through mobile device components. Application developers explain the need for access in their privacy policies, yet many users are concerned about the privacy implications of allowing access to their personal information. This article explores how user perceptions of privacy affect user sentiment by analyzing over five million user-submitted text reviews and star ratings collected over a four-year period. The authors use supervised machine learning to classify privacy and non-privacy-related reviews. The authors then use natural language processing sentiment analysis to compare differences between the groups. Additionally, the article explores various aspects of both privacy and non-privacy-related reviews using self-reported measurements such as star rating and helpfulness tags.",
        "DOI": "10.4018/IJISP.2020100105",
        "paper_author": "Besmer A.R.",
        "affiliation_name": "Winthrop University",
        "affiliation_city": "Rock Hill",
        "affiliation_country": "United States",
        "affiliation_id": "60026305",
        "affiliation_state": "SC"
    },
    {
        "paper_title": "Deep reinforcement learning for indoor mobile robot path planning",
        "publication": "Sensors (Switzerland)",
        "citied_by": "135",
        "cover_date": "2020-10-01",
        "Abstract": "This paper proposes a novel incremental training mode to address the problem of Deep Reinforcement Learning (DRL) based path planning for a mobile robot. Firstly, we evaluate the related graphic search algorithms and Reinforcement Learning (RL) algorithms in a lightweight 2D environment. Then, we design the algorithm based on DRL, including observation states, reward function, network structure as well as parameters optimization, in a 2D environment to circumvent the time-consuming works for a 3D environment. We transfer the designed algorithm to a simple 3D environment for retraining to obtain the converged network parameters, including the weights and biases of deep neural network (DNN), etc. Using these parameters as initial values, we continue to train the model in a complex 3D environment. To improve the generalization of the model in different scenes, we propose to combine the DRL algorithm Twin Delayed Deep Deterministic policy gradients (TD3) with the traditional global path planning algorithm Probabilistic Roadmap (PRM) as a novel path planner (PRM+TD3). Experimental results show that the incremental training mode can notably improve the development efficiency. Moreover, the PRM+TD3 path planner can effectively improve the generalization of the model.",
        "DOI": "10.3390/s20195493",
        "paper_author": "Gao J.",
        "affiliation_name": "Guangdong University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60007155",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Poster: Performance Testing Driven by Reinforcement Learning",
        "publication": "Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation, ICST 2020",
        "citied_by": "5",
        "cover_date": "2020-10-01",
        "Abstract": "Performance testing remains a challenge, particularly for complex systems. Different application-, platform-and workload-based factors can influence the performance of software under test. Common approaches for generating platform-and workload-based test conditions are often based on system model or source code analysis, real usage modeling and use-case based design techniques. Nonetheless, creating a detailed performance model is often difficult, and also those artifacts might not be always available during the testing. On the other hand, test automation solutions such as automated test case generation can enable effort and cost reduction with the potential to improve the intended test criteria coverage. Furthermore, if the optimal way (policy) to generate test cases can be learnt by testing system, then the learnt policy can be reused in further testing situations such as testing variants, evolved versions of software, and different testing scenarios. This capability can lead to additional cost and computation time saving in the testing process. In this research, we present an autonomous performance testing framework which uses a model-free reinforcement learning augmented by fuzzy logic and self-adaptive strategies. It is able to learn the optimal policy to generate platform-and workload-based test conditions which result in meeting the intended testing objective without access to system model and source code. The use of fuzzy logic and self-adaptive strategy helps to tackle the issue of uncertainty and improve the accuracy and adaptivity of the proposed learning. Our evaluation experiments show that the proposed autonomous performance testing framework is able to generate the test conditions efficiently and in a way adaptive to varying testing situations.",
        "DOI": "10.1109/ICST46399.2020.00048",
        "paper_author": "Moghadam M.H.",
        "affiliation_name": "RISE Research Institutes of Sweden AB",
        "affiliation_city": "Gothenburg",
        "affiliation_country": "Sweden",
        "affiliation_id": "60107281",
        "affiliation_state": "Vastra Gotaland"
    },
    {
        "paper_title": "Changing the Nature of Quantitative Biology Education: Data Science as a Driver",
        "publication": "Bulletin of Mathematical Biology",
        "citied_by": "17",
        "cover_date": "2020-10-01",
        "Abstract": "We live in a data-rich world with rapidly growing databases with zettabytes of data. Innovation, computation, and technological advances have now tremendously accelerated the pace of discovery, providing driverless cars, robotic devices, expert healthcare systems, precision medicine, and automated discovery to mention a few. Even though the definition of the term data science continues to evolve, the sweeping impact it has already produced on society is undeniable. We are at a point when new discoveries through data science have enormous potential to advance progress but also to be used maliciously, with harmful ethical and social consequences. Perhaps nowhere is this more clearly exemplified than in the biological and medical sciences. The confluence of (1) machine learning, (2) mathematical modeling, (3) computation/simulation, and (4) big data have moved us from the sequencing of genomes to gene editing and individualized medicine; yet, unsettled policies regarding data privacy and ethical norms could potentially open doors for serious negative repercussions. The data science revolution has amplified the urgent need for a paradigm shift in undergraduate biology education. It has reaffirmed that data science education interacts and enhances mathematical education in advancing quantitative conceptual and skill development for the new generation of biologists. These connections encourage us to strive to cultivate a broadly skilled workforce of technologically savvy problem-solvers, skilled at handling the unique challenges pertaining to biological data, and capable of collaborating across various disciplines in the sciences, the humanities, and the social sciences. To accomplish this, we suggest development of open curricula that extend beyond the job certification rhetoric and combine data acumen with modeling, experimental, and computational methods through engaging projects, while also providing awareness and deep exploration of their societal implications. This process would benefit from embracing the pedagogy of experiential learning and involve students in open-ended explorations derived from authentic inquiries and ongoing research. On this foundation, we encourage development of flexible data science initiatives for the education of life science undergraduates within and across existing models.",
        "DOI": "10.1007/s11538-020-00785-0",
        "paper_author": "Robeva R.S.",
        "affiliation_name": "Randolph-Macon College",
        "affiliation_city": "Ashland City",
        "affiliation_country": "United States",
        "affiliation_id": "60015087",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Reply: The Competitive Advantage of Adaptability in the Approach to Heart Failure Populations",
        "publication": "JACC: Heart Failure",
        "citied_by": "0",
        "cover_date": "2020-10-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.jchf.2020.08.003",
        "paper_author": "Jing L.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence, drug repurposing and peer review",
        "publication": "Nature Biotechnology",
        "citied_by": "55",
        "cover_date": "2020-10-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41587-020-0686-x",
        "paper_author": "Levin J.M.",
        "affiliation_name": "Ovid Therapeutics",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "117078416",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Spatial conservation action planning in heterogenous landscapes",
        "publication": "Biological Conservation",
        "citied_by": "33",
        "cover_date": "2020-10-01",
        "Abstract": "A key challenge in conservation is the efficient allocation of limited resources to maximise benefits for biodiversity. Decision-support tools that account for landscape heterogeneity are needed to identify spatially-explicit actions that will achieve the greatest biodiversity benefits with available resources. We developed a raster-based, landscape-scale, spatial conservation action planning tool (SCAP) that offers significant advances for prioritising local and regional scale conservation actions in heterogenous landscapes. The SCAP tool was developed for the state of Victoria, Australia, to integrate heterogeneity of landscapes, species distributions, threats, and management costs and benefits across the state. We used empirical data to derive current and pre-European settlement distributions for 4400 native terrestrial species, and developed spatially explicit models of 19 threats to biodiversity. We coupled structured expert-elicitation techniques with machine learning to map the expected benefits to species, and the implementation costs, of 17 management actions – alone and in combination. We then ranked location-specific actions by their cost-effective contribution to an overall objective of minimizing the risk of species loss in Victoria over the next 50 years, using a modified implementation of the Zonation conservation planning framework. The SCAP tool provides decision makers with a transparent decision-support tool for identifying the cost-effective management actions at scales relevant to management.",
        "DOI": "10.1016/j.biocon.2020.108735",
        "paper_author": "Thomson J.",
        "affiliation_name": "Arthur Rylah Institute for Environmental Research",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60026050",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Classification algorithm accuracy improvement for student graduation prediction using ensemble model",
        "publication": "International Journal of Information and Education Technology",
        "citied_by": "12",
        "cover_date": "2020-10-01",
        "Abstract": "According to National Center for Education Statistics, almost half of the first-time freshmen full time students who began seeking a bachelor’s degree do not graduate. The imbalance between the student enrolment and student graduation can be solved by early predicting and identifying students who are prone of not having graduation on time, so proper remediation and retention policies can be formulated and implemented by institutions. The study focused on the application of the ensemble models in predicting student graduation. Ensemble modeling is the process of running two or more related but different analytical models and then synthesizing the results into a single score or spread in order to improve the accuracy of predictive analytics and data mining applications. The study recorded an increase of classification accuracy in predicting student graduation using ensemble models and combining multiple algorithms.",
        "DOI": "10.18178/ijiet.2020.10.10.1449",
        "paper_author": "Lagman A.C.",
        "affiliation_name": "FEU Institute of Technology",
        "affiliation_city": "Manila",
        "affiliation_country": "Philippines",
        "affiliation_id": "60110905",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Comment on Azad et al.'s “Cost-utility of colorectal cancer screening at age 40 years old for average-risk patients”",
        "publication": "Preventive Medicine",
        "citied_by": "1",
        "cover_date": "2020-10-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.ypmed.2020.106140",
        "paper_author": "McNamara C.",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States",
        "affiliation_id": "60032179",
        "affiliation_state": "WI"
    },
    {
        "paper_title": "Analysis and prediction of crop production in Andhra region using deep convolutional regression network",
        "publication": "International Journal of Intelligent Engineering and Systems",
        "citied_by": "7",
        "cover_date": "2020-10-01",
        "Abstract": "Agriculture planning plays a significant role in economic growth and the food security of agro-based country. Crop yield prediction and selection of crops are the most challenging tasks in agricultural domain and it depends on different parameters such as production rate, market price and government policies. Among the two primary tasks, the crop yield prediction is one of the most demanding tasks for every nation. Due to uncertain climatic changes, farmers are struggling to attain a satisfactory amount of yield from the crops. Many researchers have studied on the prediction of weather, prediction of yield rate of crop, crop classification and soil classification for agriculture planning using statistical methods or machine learning techniques. This study focuses on the prediction of major crops in Andhra Pradesh region and presents an enhanced algorithm known as Deep Convolutional Regression Network (DCRN), which is trained and tested on agricultural data collected from farmers. The experimental results showed that the DCRN method achieved nearly 97% prediction accuracy when compared with existing methods like Decision Tree (DT), Self-Organizing Map (SOM).",
        "DOI": "10.22266/ijies2020.1031.01",
        "paper_author": "Talasila V.",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India",
        "affiliation_id": "60079446",
        "affiliation_state": "AP"
    },
    {
        "paper_title": "Comparative Analysis of ANN-ICA and ANN-GWO for Crop Yield Prediction",
        "publication": "Proceedings - 2020 RIVF International Conference on Computing and Communication Technologies, RIVF 2020",
        "citied_by": "31",
        "cover_date": "2020-10-01",
        "Abstract": "Prediction of crops yield is essential for food security policymaking, planning, and trade. The objective of the current study is to propose novel crop yield prediction models based on hybrid machine learning methods. In this study the performance of artificial neural networks-imperialist competitive algorithm (ANN-ICA) and artificial neural networks-gray wolf optimizer (ANN-GWO) models for the crop yield prediction are evaluated. According to the results, ANN-GWO, with R of 0.48, RMSE of 3.19, and MEA of 26.65, proved a better performance in the crop yield prediction compared to the ANN-ICA model. The results can be used by either practitioners, researchers or policymakers for food security.",
        "DOI": "10.1109/RIVF48685.2020.9140786",
        "paper_author": "Nosratabadi S.",
        "affiliation_name": "Oxford Brookes University",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60014564",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Towards ensuring the reliability and dependability of vehicular crowd-sensing data in GPS-less location tracking",
        "publication": "Pervasive and Mobile Computing",
        "citied_by": "11",
        "cover_date": "2020-10-01",
        "Abstract": "This paper presents a participatory framework to improve the reliability of sensor emulation by using non-dedicated and crowdsourced sensory data to cover several dedicated sensors in smart environments. To this end, GPS-less vehicle localization in a public transportation network by vehicular crowd-sensing and machine intelligence is considered as a potential use case. Our proposed architecture aims to mimic the functionality of GPS through built-in sensors in smart devices (e.g. smartphones and tablets). Sensor readings acquired from the participants recruited by the platform are fed into an unsupervised machine learning algorithm, the performance of which is a function of the trustworthiness of participants and reliability of sensor readings acquired through participants. Therefore, we study the impact of reliability-aware participant recruitment policies over a reliability-unaware participant recruitment policy. We devised two reliability-aware recruitment policies: Reliability-driven naive recruitment (RDNR) and Reliability-driven exclusive recruitment (RDER) and both of them assess the trustworthiness of individual participants and eliminates the sensor readings if their reliability is under a threshold. On the other hand, our reliability-unaware recruitment policy, Non-restricted recruitment (NRR), accepts all sensor readings from the participants. Our simulation results lead to approximately 98% accuracy for GPS-less localization of public transportation vehicles with RDER policy when compared to the NRR policy, which yields approximately 93% accuracy. Furthermore, sustainability study of our framework shows that participant comfort can be ensured by reducing the battery drain of GPS sensor by 38%–46%.",
        "DOI": "10.1016/j.pmcj.2020.101248",
        "paper_author": "Boukerche A.",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60028897",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Defensive Escort Teams for Navigation in Crowds via Multi-Agent Deep Reinforcement Learning",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "11",
        "cover_date": "2020-10-01",
        "Abstract": "Coordinated defensive escorts can aid a navigating payload by positioning themselves strategically in order to maintain the safety of the payload from obstacles. In this letter, we present a novel, end-to-end solution for coordinating an escort team for protecting high-value payloads in a space crowded with interacting obstacles. Our solution employs deep reinforcement learning in order to train a team of escorts to maintain payload safety while navigating alongside the payload. The escorts utilize a trained centralized policy in a distributed fashion (i.e., no explicit communication between the escorts), relying only on range-limited positional information of the environment. Given this observation, escorts automatically prioritize obstacles to intercept and determine where to intercept them, using their repulsive interaction force to actively manipulate the environment. When compared to a payload navigating with a state-of-art algorithm for obstacle avoidance our defensive escort team increased navigation success up to 83% over escorts in static formation, up to 69% over orbiting escorts, and up to 66% compared to an analytic method providing guarantees in crowded environments. We also show that our learned solution is robust to several adaptations in the scenario including: a changing number of escorts in the team, changing obstacle density, unexpected obstacle behavior, changes in payload conformation, and added sensor noise.",
        "DOI": "10.1109/LRA.2020.3010203",
        "paper_author": "Hasan Y.A.",
        "affiliation_name": "University of New Mexico School of Engineering",
        "affiliation_city": "Albuquerque",
        "affiliation_country": "United States",
        "affiliation_id": "60138187",
        "affiliation_state": "NM"
    },
    {
        "paper_title": "Analyzing network-wide patterns of rail transit delays using Bayesian network learning",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "23",
        "cover_date": "2020-10-01",
        "Abstract": "Rail transit delays are generally discussed in terms of on-time performance or problems at individual stops. Such stop-scale approaches ignore the fact that delays are also caused and perpetuated by network-wide factors (e.g., bottlenecks caused by shared tracks by multiple transit lines). The objective of this paper is to develop a network model and metrics that can quantify the delay dependencies between transit network stops, and identify local sources of network-wide issues. For this purpose, Bayesian network learning (at the intersection of machine learning and network science) was utilized. Based on the calculated Bayesian networks (BNs), network metrics (inducer and susceptible) were formulated to quantify the network-wide impacts of the delays experienced at the stops. To implement the proposed framework, the delays at Long Island Rail Road (LIRR) were gathered through a crowdsourced real-time transit information app called onTime. The developed BN model was tested through cross-validation, yielded promising accuracy results, successfully identified the problematic stops based on LIRR reports, and provided further insights on network impacts. The BN model and the developed metrics were further tested using a natural experiment, i.e., a before and after study focusing on a recently completed track expansion project at LIRR. The findings imply that BN learning can successfully identify the network dependencies and indicate the rail links/corridors that are the best candidate for subsequent improvement investments. Overall, the developed metrics can quantify the delay dependencies between stops and they can be used by policy makers and practitioners for investment and improvement decisions.",
        "DOI": "10.1016/j.trc.2020.102749",
        "paper_author": "Ulak M.B.",
        "affiliation_name": "Universiteit Twente",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60020599",
        "affiliation_state": "Overijssel"
    },
    {
        "paper_title": "Exploring the relationship between CO<inf>2</inf> emissions from on-farm use of diesel fuel and costs associated with forage harvesting–A win-to-win situation",
        "publication": "Acta Agriculturae Scandinavica A: Animal Sciences",
        "citied_by": "0",
        "cover_date": "2020-10-01",
        "Abstract": "The aims of this paper were to explore which factors explain (i) the direct emission of CO2 from on-farm use of fuel to harvest forage and (ii) the costs of different harvesting management practices. Data on harvesting practices, CO2 emission and forage costs were collected through farm visits on 184 dairy farms in all regions of Norway in 2017 and 2018. To analyze data, machine learning methods were used. The findings show that forage harvesting capacity and forage yield are associated with CO2 emissions from on-farm use of diesel fuel and harvesting costs. Factors that mitigate CO2 emissions from harvesting coincide with factors that contribute to reduced harvesting costs. Thus the findings suggest a ‘win-to-win’ relationship between the interests of the farming business and environmental sustainability. The findings have implications for dairy farmers and policy makers.",
        "DOI": "10.1080/09064702.2020.1804993",
        "paper_author": "Hansen B.G.",
        "affiliation_name": "TINE SA",
        "affiliation_city": "Oslo",
        "affiliation_country": "Norway",
        "affiliation_id": "60080290",
        "affiliation_state": "Oslo"
    },
    {
        "paper_title": "Citizen science and habitat modelling facilitates conservation planning for crabeater seals in the Weddell Sea",
        "publication": "Diversity and Distributions",
        "citied_by": "17",
        "cover_date": "2020-10-01",
        "Abstract": "Aim: Creating a network of marine protected areas in the Southern Ocean requires extensive knowledge on species’ abundances, distributions and population trends especially in the Weddell Sea where year-round pack ice makes most of the Weddell Sea inaccessible. We combine satellite images and citizen science to model habitat suitability for crabeater seals (Lobodon carcinophaga) throughout the Weddell Sea. Location: Weddell Sea, Antarctica. Methods: High-resolution satellite images covering 18,219 km2 of the Weddell Sea during crabeater seal breeding season (October—November) were hosted on the crowd-sourcing platform Tomnod (DigitalGlobe). Citizen scientists marked “maps” where seals were present/absent and these votes were compared with the votes of an experienced observer. Correction factors were used to correct votes to either a continuous probability of seal presence, or a binary seal presence/absence value. We modelled probability of seal presence using ensemble models of Random Forests (RF), Boosted Regression Trees (BRT) and Support Vector Machines (SVM), and used fitted Maxent models to model seal presence/absence data. Results: Model predictive power was low (RF: R2 = 0.076 ± 0.002: BRT: R2 = 0.086 ± 0.0008; SVM: R2 = 0.082 ± 0.003) to average (Maxent: AUC = 0.71 ± 0.004). Distance to the ice edge and bathymetry were the most important variables that influenced crabeater seal distribution. Main conclusions: Crabeater seals were more likely to be present over abyssal water, which coincides with typical adult Antarctic krill habitat — crabeater seal preferred prey. Where ice concentrations were more variable, that is more accessible, crabeater seals were also more likely to occur. Results agreed with the known ecology of crabeaters seals and the abundance, distribution and ecology of Antarctic krill. We were able to survey the largest area ever surveyed in the Weddell Sea and provide a model to assist furthering policy around the proposed protected area.",
        "DOI": "10.1111/ddi.13120",
        "paper_author": "Wege M.",
        "affiliation_name": "University of Canterbury",
        "affiliation_city": "Christchurch",
        "affiliation_country": "New Zealand",
        "affiliation_id": "60020585",
        "affiliation_state": "CAN"
    },
    {
        "paper_title": "Spatial estimation of chronic respiratory diseases based on machine learning procedures—an approach using remote sensing data and environmental variables in quito, Ecuador",
        "publication": "Applied Geography",
        "citied_by": "30",
        "cover_date": "2020-10-01",
        "Abstract": "Over the last few years, the use of remote sensing data in different applications such as estimation of air pollution concentration and health applications has become very popular and new. Thus, some studies have established a possible relationship between environmental variables and respiratory health parameters. This study proposes to estimate the prevalence of Chronic Respiratory Diseases, where there is a relationship between remote sensing data (Landsat 8) and environmental variables (air pollution and meteorological data) to determine the number of hospital discharges of patients with chronic respiratory diseases in Quito, Ecuador, between 2013 and 2017. The main objective of this study is to establish and evaluate an alternative LUR model that is capable of estimate the prevalence of chronic respiratory diseases, in contrast with traditional LUR models, which typically assess air pollutants. Moreover, this study also evaluates different analytic techniques (multiple linear regression, multilayer perceptron, support vector regression, and random forest regression) that often form the basis of spatial models. The results show that machine learning techniques, such as support vector machine, are the most effective in computing such models, presenting the lowest root-mean-square error (RMSE). Additionally, in this study, we show that the most significant remote sensing predictors are the blue and infrared bands. Our proposed model is a spatial modeling approach that is capable of determining the prevalence of chronic respiratory diseases in the city of Quito, which can serve as a useful tool for health authorities in policy- and decision-making.",
        "DOI": "10.1016/j.apgeog.2020.102273",
        "paper_author": "Alvarez-Mendoza C.I.",
        "affiliation_name": "Universidad Politécnica Salesiana, Quito",
        "affiliation_city": "Quito",
        "affiliation_country": "Ecuador",
        "affiliation_id": "60105797",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep reinforcement learning algorithm for dynamic pricing of express lanes with multiple access locations",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "32",
        "cover_date": "2020-10-01",
        "Abstract": "This article develops a deep reinforcement learning (Deep-RL) framework for dynamic pricing on managed lanes with multiple access locations and heterogeneity in travelers’ value of time, origin, and destination. This framework relaxes assumptions in the literature by considering multiple origins and destinations, multiple access locations to the managed lane, en route diversion of travelers, partial observability of the sensor readings, and stochastic demand and observations. The problem is formulated as a partially observable Markov decision process (POMDP) and policy gradient methods are used to determine tolls as a function of real-time observations. Tolls are modeled as continuous and stochastic variables and are determined using a feedforward neural network. The method is compared against a feedback control method used for dynamic pricing. We show that Deep-RL is effective in learning toll policies for maximizing revenue, minimizing total system travel time, and other joint weighted objectives, when tested on real-world transportation networks. The Deep-RL toll policies outperform the feedback control heuristic for the revenue maximization objective by generating revenues up to 8.5% higher than the heuristic and for the objective minimizing total system travel time (TSTT) by generating TSTT up to 8.4% lower than the heuristic. We also propose reward shaping methods for the POMDP to overcome the undesired behavior of toll policies, like the jam-and-harvest behavior of revenue-maximizing policies. Additionally, we test transferability of the algorithm trained on one set of inputs for new input distributions and offer recommendations on real-time implementations of Deep-RL algorithms. The source code for our experiments is available online at https://github.com/venktesh22/ExpressLanes_Deep-RL.",
        "DOI": "10.1016/j.trc.2020.102715",
        "paper_author": "Pandey V.",
        "affiliation_name": "Cockrell School of Engineering",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60150401",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Prediction of survival outcome based on clinical features and pretreatment <sup>18</sup>FDG-PET/CT for HNSCC patients",
        "publication": "Computer Methods and Programs in Biomedicine",
        "citied_by": "10",
        "cover_date": "2020-10-01",
        "Abstract": "Background and objective: In this study, we have analysed pretreatment positron-emission tomography/ computed tomography (PET/CT) images of head and neck squamous cell carcinoma (HNSCC) patients. We have used a publicly available dataset for our analysis. The clinical features of the patient, PET quantitative parameters, and textural indices from pretreatment PET-CT images are selected for the study. The main objective of the study is to use classifiers to predict the outcome for HNSCC patients and compare the performance of the model with the conventional statistical model (CoxPH). Methods: We have applied a 40% fixed SUV threshold method for tumour delineation. Clinical features of each patient are provided in the dataset, and other features are calculated using LIFEx software. For predicting the outcome, we have implemented three classifiers - Random Forest classifier, Gradient Boosted Decision tree (GBDT) and Decision tree classifier. We have trained each model using 93 data points and test the model performance using 39 data points. The best model - GBDT is chosen based on the performance metrics. Results: It is observed that typically three features: MTV (Metabolic tumour Volume), primary tumour site and GLCM_correlation are significant for prediction of survival outcome. For testing cohort, GBDT achieves a balanced accuracy of 88%, where conventional statistical model reported a balanced accuracy of 81.5%. Conclusions: The proposed classifier achieves higher accuracy than the state of the art technique. Using this classifier we can estimate the HNSCC patient's outcome, and depending upon the outcome treatment policy can be selected.",
        "DOI": "10.1016/j.cmpb.2020.105669",
        "paper_author": "Ghosh S.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India",
        "affiliation_id": "60004750",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Machine learning based aspect level sentiment analysis for Amazon products",
        "publication": "Spatial Information Research",
        "citied_by": "72",
        "cover_date": "2020-10-01",
        "Abstract": "The field of sentiment analysis is widely utilized for analyzing the text data and then extracting the sentiment component out of that. The online commercial websites generates a huge amount of textual data via customer’s reviews, comments, feedbacks and tweets every day. Aspect level analysis of this data provides a great help to retailers in better understanding of customer’s expectations and then shaping their policies accordingly. However, a number of algorithms are existing these days to do aspect level sentiment detection on specified domains, but a few consider bipolar words (words which changes polarity according to context) while doing analyses. In this paper, a novel approach has been presented that utilize aspect level sentiment detection, which focuses on the features of the item. The work has been implemented and tested on Amazon customer reviews (crawled data) where aspect terms are identified first for each review. The system performs pre-processing operations like stemming, tokenization, casing, stop-word removal on the dataset to extract meaningful information and finally gives a rank for its classification in negativity or positivity.",
        "DOI": "10.1007/s41324-020-00320-2",
        "paper_author": "Nandal N.",
        "affiliation_name": "Manav Rachna University",
        "affiliation_city": "Faridabad",
        "affiliation_country": "India",
        "affiliation_id": "60104574",
        "affiliation_state": "HR"
    },
    {
        "paper_title": "Monte Carlo Tree Search with Last-Good-Reply Policy for Cognitive Optimization of Cloud-Ready Optical Networks",
        "publication": "Journal of Network and Systems Management",
        "citied_by": "17",
        "cover_date": "2020-10-01",
        "Abstract": "The rapid development of Cloud Computing and Content Delivery Networks (CDNs) brings a significant increase in data transfers that leads to new optimization challenges in inter-data center networks. In this article, we focus on the cross-stratum optimization of an inter-data center Elastic Optical Network (EON). We develop an optimization approach that employs machine learning Monte Carlo Tree Search (MCTS) algorithm for the simulation of future traffic to improve the performance of the network regarding the request blocking and the operational cost. The key novelty of our approach is using various selection strategies applied to the phase of building a search tree under different network scenarios. We evaluate the performance of these selection strategies using representative topologies and real-data provided by Amazon Web Services. The main conclusion is that the approach based on the policy of Last-Good-Reply with Forgetting enables more efficient cloud resource allocation, which results in lower request blocking, thus, reduces the operational cost of the network.",
        "DOI": "10.1007/s10922-020-09555-8",
        "paper_author": "Aibin M.",
        "affiliation_name": "British Columbia Institute of Technology",
        "affiliation_city": "Burnaby",
        "affiliation_country": "Canada",
        "affiliation_id": "60004982",
        "affiliation_state": "BC"
    },
    {
        "paper_title": "Adoption of autonomous mining system in Pakistan – Policy, skillset, awareness and preparedness of stakeholders",
        "publication": "Resources Policy",
        "citied_by": "19",
        "cover_date": "2020-10-01",
        "Abstract": "Autonomous mining systems comprise of the latest, innovative, and automated technology designed to improve mine productivity, efficiency, and workplace safety. These automated systems have already been adopted in developed countries like Australia and the United States. In recent years research has emerged to address the awareness and preparedness of stakeholders towards the adaption of Autonomous Mining Systems dedicated towards African countries. The present study is a novel effort in evaluating the current scale of knowledge and skills of mining engineers working in Pakistan's mining industry, government sector, and academia. The study focuses on exploring the awareness about the understanding of the autonomous mining systems, and the level of preparedness of all the stakeholders towards the adoption of this modern technology, along with the resulting social impacts, in a developing country like Pakistan. This paper employed closed and open-ended questionnaires, distributed in electronic formats, to achieve the aforementioned objective. The results were analyzed qualitatively using thematic analysis and quantitatively using results synthesis employing statistical analysis in Python. Substantial evidence has been provided indicating a huge knowledge gap and severe lack of planning and policy enforcement towards the adoption of autonomous mining systems in Pakistan. More than 74% of the respondents, with the majority of them belonging to industry and academia, appeared willing to accept the adoption of autonomous mining systems in Pakistan, due to the resulting improvements in safety and productivity. However, government agencies had varied opinions, with the knowledge gap and the fear of increased unemployment being the major reasons for their resistance to technology adoption. The majority of the graduate mining engineers (60.35%) mentioned the inadequacy of the undergraduate and graduate coursework for providing skills needed to work with autonomous systems. Therefore, it is recommended that the mining curriculum be revised to contain more courses that are relevant to gaining skills in autonomous mining. A government-industry-academia collaboration is also recommended to fund and develop facilities that can help bridge this existing knowledge gap, thus facilitating an early adoption of modern technology in Pakistan's mining sector.",
        "DOI": "10.1016/j.resourpol.2020.101796",
        "paper_author": "Ali D.",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Rolla",
        "affiliation_country": "United States",
        "affiliation_id": "60146648",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Precursors of intellectual property rights enforcement in East and Southeast Asia",
        "publication": "Industrial Marketing Management",
        "citied_by": "4",
        "cover_date": "2020-10-01",
        "Abstract": "In this study we identify the main determinants of perceived strength of intellectual property rights in four developed (Japan, Singapore, South Korea, and Taiwan) and five emerging (China, Indonesia, Malaysia, the Philippines, and Thailand) Asian countries over the period 2003–2016. We use a panel model with additive unobserved individual-specific heterogeneity in a high-dimensional setting. The setting allows the number of time-varying regressors to exceed the sample size. Based on the Cluster–Lasso approach, we found that (1) bribery and corruption (inverse), equal opportunity, administration of justice, knowledge transfer, personal security and private property rights, and qualified engineers are significant determinants of intellectual property rights for developed countries; (2) adaptability of government policy, bribery and corruption (inverse), bureaucracy (inverse), and science in schools are significant determinants of intellectual property rights for emerging countries. Policy makers may use these results to strengthen IP rights and thus encourage indigenous innovation as well as foreign direct investment.",
        "DOI": "10.1016/j.indmarman.2020.06.013",
        "paper_author": "Liu Y.",
        "affiliation_name": "National Tsing Hua University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60018029",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Can smart energy information interventions help householders save electricity? A SVR machine learning approach",
        "publication": "Environmental Science and Policy",
        "citied_by": "21",
        "cover_date": "2020-10-01",
        "Abstract": "Smart energy monitors (SEMs), which enable householders to measure electricity usages of different appliances in real-time, have been widely deployed by utilities across many different countries. However, the actual electricity saving effects of smart information interventions via the SEM connected to the smart energy management system (SEMS) remain inconclusive, due to failures of the existing statistical models in capturing non-linear relationships. To address the non-linearity challenge and to observe the effects of smart information interventions on electricity savings among the public housing householders in Hong Kong, we initiate a longitudinal electricity consumption behavioural study in Hong Kong. We propose a machine-learning approach to capture any non-linearity identified from our SVR machine learning model. In particular, we identify the correlation between the different combinations of three smart information interventions and the percentage of electricity savings at the household-level in Hong Kong. Smart Energy Management System (SEMS), consisting of a smartphone app and a SEM installed respectively on the smartphone and the participant household of our participants in a public housing estate in Hong Kong, have been developed and deployed by the HKU AI-WiSe team. An innovative technological intervention cum environmental behavioural study was conducted on representative of 14 households residing in a public housing estate in Hong Kong, across a one-year period, from 2018 to 2019. Three types of smart information interventions were introduced to our household participants, including their (1) current electricity consumption profile (2) historical electricity consumption profile, and (3) ranking in electricity savings as compared to other participating households. Our study concludes that the overall average electricity savings across all 14 households is 7.1 %. However, as different households have displayed different electricity consumption characteristics, the electricity savings vary significantly across 14 households, from slightly negative or almost zero savings, to significantly positive savings. Our results show that with respect to the three types of smart information interventions, Type (1) and Type (2) display a stronger electricity saving effect when compared to the ranking-based smart information intervention. We conclude our study by identifying the right electricity policies for the HKSAR Government to promote household electricity savings via SEMs and SEMS in HK. To the best of our understanding, our study represents the very first attempt to capture the non-linear statistical correlation between smart information interventions and household electricity savings via the machine-learning SVR approach. Our approach is generic and scalable; it can be applicable to other related electricity consumption experimental studies, across any geographical scale and sample size.",
        "DOI": "10.1016/j.envsci.2020.07.003",
        "paper_author": "Wang A.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An approach for combining ethical principles with public opinion to guide public policy",
        "publication": "Artificial Intelligence",
        "citied_by": "15",
        "cover_date": "2020-10-01",
        "Abstract": "We propose a framework for incorporating public opinion into policy making in situations where values are in conflict. This framework advocates creating vignettes representing value choices, eliciting the public's opinion on these choices, and using machine learning to extract principles that can serve as succinct statements of the policies implied by these choices and rules to guide the behavior of autonomous systems.",
        "DOI": "10.1016/j.artint.2020.103349",
        "paper_author": "Awad E.",
        "affiliation_name": "University of Exeter",
        "affiliation_city": "Exeter",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026479",
        "affiliation_state": "Devon"
    },
    {
        "paper_title": "Predicting differential improvements in annual pollutant concentrations and exposures for regulatory policy assessment",
        "publication": "Environment International",
        "citied_by": "15",
        "cover_date": "2020-10-01",
        "Abstract": "Over the past decade, researchers and policy-makers have become increasingly interested in regulatory and policy interventions to reduce air pollution concentrations and improve human health. Studies have typically relied on relatively sparse environmental monitoring data that lack the spatial resolution to assess small-area improvements in air quality and health. Few studies have integrated multiple types of measures of an air pollutant into one single modeling framework that combines spatially- and temporally-rich monitoring data. In this paper, we investigated the differential effects of California emissions reduction plan on reducing air pollution between those living in the goods movement corridors (GMC) that are within 500 m of major highways that serve as truck routes to those farther away or adjacent to routes that prohibit trucks. A mixed effects Deletion/Substitution/Addition (D/S/A) machine learning algorithm was developed to model annual pollutant concentrations of nitrogen dioxide (NO2) by taking repeated measures into consideration and by integrating multiple types of NO2 measurements, including those through government regulatory and research-oriented saturation monitoring into a single modeling framework. Difference-in-difference analysis was conducted to identify whether those living in GMC demonstrated statistically larger reductions in air pollution exposure. The mixed effects D/S/A machine learning modeling result indicated that GMC had 2 ppb greater reductions in NO2 concentrations from pre- to post-policy period than far away areas. The difference-in-difference analysis demonstrated that the subjects living in GMC experienced statistically significant greater reductions in NO2 exposure than those living in the far away areas. This study contributes to scientific knowledge by providing empirical evidence that improvements in air quality via the emissions reductions plan policies impacted traffic-related air pollutant concentrations and associated exposures most among low-income Californians with chronic conditions living in GMC. The identified differences in pollutant reductions across different location domains may be applicable to other states or other countries if similar policies are enacted.",
        "DOI": "10.1016/j.envint.2020.105942",
        "paper_author": "Su J.G.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Future prospects research on offshore wind power scale in China based on signal decomposition and extreme learning machine optimized by principal component analysis",
        "publication": "Energy Science and Engineering",
        "citied_by": "10",
        "cover_date": "2020-10-01",
        "Abstract": "In recent years, China has promoted many new energy projects in order to meet the growing demand for electricity. Therefore, China's offshore wind power installed capacity has grown rapidly. China has a long coastline and abundant offshore wind energy resources. Offshore wind power is an important area for the development of renewable energy, which can promote wind power technology advancement and energy structure adjustment. Therefore, conducting effective research and forecast on the cumulative installed capacity of China's offshore wind power will help the government to rationally deploy and reduce the risk of investment in offshore wind power. In order to accurately predict the future prospects of offshore wind power in China, this paper firstly constructed a set of influencing factors and used gray correlation analysis to screen the main influencing factors. Then, this paper proposed a novel forecasting model named e-VMD-PCA-RELM. The algorithm is based on the traditional RELM (robust extreme learning machine) algorithm, which effectively processes the noise information through the PCA (principal component analysis) algorithm, and extracted the feature elements of the RELM hidden layer to reduce the information redundancy. At the same time, the e-VMD (variational mode decomposition optimized by entropy) algorithm is used to decompose the original time series to obtain multiple components. By comparing with the other forecasting algorithms, it is proved that the proposed forecasting model has strong generalization ability and has achieved good prediction result. Finally, the e-VMD-PCA-RELM model is used to predict the scale of offshore wind farms in China from 2019 to 2035. We find that the cumulative installed capacity of China's offshore wind power will exceed 60 GW in 2035, and the installed capacity will increase year by year. In 2030, there will be a large increase, with a relative growth rate of 20%.",
        "DOI": "10.1002/ese3.761",
        "paper_author": "Liu D.",
        "affiliation_name": "North China Electric Power University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60021227",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting Brazilian and American COVID-19 cases based on artificial intelligence coupled with climatic exogenous variables",
        "publication": "Chaos, Solitons and Fractals",
        "citied_by": "95",
        "cover_date": "2020-10-01",
        "Abstract": "The novel coronavirus disease (COVID-19) is a public health problem once according to the World Health Organization up to June 24th, 2020, more than 9.1 million people were infected, and more than 470 thousand have died worldwide. In the current scenario, the Brazil and the United States of America present a high daily incidence of new cases and deaths. Therefore, it is important to forecast the number of new cases in a time window of one week, once this can help the public health system developing strategic planning to deals with the COVID-19. The application of the forecasting artificial intelligence (AI) models has the potential of deal with dynamical behavior of time-series like of COVID-19. In this paper, Bayesian regression neural network, cubist regression, k-nearest neighbors, quantile random forest, and support vector regression, are used stand-alone, and coupled with the recent pre-processing variational mode decomposition (VMD) employed to decompose the time series into several intrinsic mode functions. All AI techniques are evaluated in the task of time-series forecasting with one, three, and six-days-ahead the cumulative COVID-19 cases in five Brazilian and American states, with a high number of cases up to April 28th, 2020. Previous cumulative COVID-19 cases and exogenous variables as daily temperature and precipitation were employed as inputs for all forecasting models. The models’ effectiveness are evaluated based on the performance criteria. In general, the hybridization of VMD outperformed single forecasting models regarding the accuracy, specifically when the horizon is six-days-ahead, the hybrid VMD–single models achieved better accuracy in 70% of the cases. Regarding the exogenous variables, the importance ranking as predictor variables is, from the upper to the lower, past cases, temperature, and precipitation. Therefore, due to the efficiency of evaluated models to forecasting cumulative COVID-19 cases up to six-days-ahead, the adopted models can be recommended as a promising models for forecasting and be used to assist in the development of public policies to mitigate the effects of COVID-19 outbreak.",
        "DOI": "10.1016/j.chaos.2020.110027",
        "paper_author": "da Silva R.G.",
        "affiliation_name": "Pontifícia Universidade Católica do Paraná",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil",
        "affiliation_id": "60020004",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "Energy consumption analysis and prediction of electric vehicles based on real-world driving data",
        "publication": "Applied Energy",
        "citied_by": "194",
        "cover_date": "2020-10-01",
        "Abstract": "With increasing mass-adoption of electric vehicles, the energy consumption has become a key performance index to electric vehicle drivers, automakers and policy-makers. Accurate and real-time energy consumption prediction under real-world driving conditions is essential for alleviating the ‘range anxiety’ and can provide support for optimal battery sizing, energy-efficient route planning and charging infrastructures operation. In this paper, real-world driving data collected from fifty-five electric taxis in Beijing city are obtained and divided into three-level driving fragments. The influencing factors of energy consumption, including vehicle-, environment-, and driver-related factors, are extracted and studied. With the extracted key influencing factors, a novel machine learning-based energy consumption prediction framework integrated with driving condition prediction is proposed and used in actual energy consumption prediction. The real-world trip test results show that a root mean squared error of 0.159kWh (RMSE) and a mean absolute percentage error 12.68% (MAPE) are reached, the RMSE and the MAPE are respectively reduced by 32.05% and by 30.14% compared to the conventional method.",
        "DOI": "10.1016/j.apenergy.2020.115408",
        "paper_author": "Zhang J.",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016835",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Estimating annual runoff in response to forest change: A statistical method based on random forest",
        "publication": "Journal of Hydrology",
        "citied_by": "63",
        "cover_date": "2020-10-01",
        "Abstract": "Population growth and climate change have put pressure on policy makers in southwest Western Australia to increase water supply to urban areas. A potential contribution to solving this problem is thinning of forested catchments to increase runoff. This study uses a machine learning approach, random forest, to relate catchment annual runoff to a range of predictors including climate variables and catchment attributes, and to estimate runoff increases from forest thinning. This approach identifies important predictors and enables prediction. The most important predictor is ‘ForestIndex’ calculated from calibrated satellite imagery and providing a consistent surrogate measure of forest density. This approach estimates annual runoff and carefully assesses potential model predictability by three modes of cross-validation. Our approach leads to more accurate annual runoff predictions than linear regression and the Fu's model (e.g. reducing RMSE by 41% and 63% respectively). We provide an example to predict the change in annual runoff in response to forest reduction under certain rainfall scenarios. The predicted runoff increase varies greatly amongst catchments from zero to 60 mm per 5 unit ForestIndex reduction.",
        "DOI": "10.1016/j.jhydrol.2020.125168",
        "paper_author": "Li M.",
        "affiliation_name": "Commonwealth Scientific and Industrial Research Organisation",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia",
        "affiliation_id": "60029470",
        "affiliation_state": "ACT"
    },
    {
        "paper_title": "Modelling of instantaneous emissions from diesel vehicles with a special focus on NO<inf>x</inf>: Insights from machine learning techniques",
        "publication": "Science of the Total Environment",
        "citied_by": "62",
        "cover_date": "2020-10-01",
        "Abstract": "Accurate instantaneous vehicle emissions models are vital for evaluating the impacts of road transport on air pollution at high temporal and spatial resolution. In this study, we apply machine learning techniques to a dataset of 70 diesel vehicles tested in real-world driving conditions to: (i) cluster vehicles with similar emissions performance, and (ii) model instantaneous emissions. The application of dynamic time warping and clustering analysis by NOx emissions resulted in 17 clusters capturing 88% of trips in the dataset. We show that clustering effectively groups vehicles with similar emissions profiles, however no significant correlation between emissions and vehicle characteristics (i.e. engine size, vehicle weight) were found. For each cluster, we evaluate three instantaneous emissions models: a look-up table (LT) approach, a non-linear regression (NLR) model and a neural network multi-layer perceptron (MLP) model. The NLR model provides accurate instantaneous NOx predictions, on par with the MLP: relative errors in prediction of emission factors are below 20% for both models, average fractional biases are −0.01 (s.d. 0.02) and −0.0003 (s.d. 0.04), and average normalised mean squared errors are 0.25 (s.d. 0.14) and 0.29 (s.d. 0.16), for the NLR and MLP models respectively. However, neural networks are better able to deal with vehicles not belonging to a specific cluster. The new models that we present rely on simple inputs of vehicle speed and acceleration, which could be extracted from existing sources including traffic cameras and vehicle tracking devices, and can therefore be deployed immediately to enable fast and accurate prediction of vehicle NOx emissions. The speed and the ease of use of these new models make them an ideal operational tool for policy makers aiming to build emission inventories or evaluate emissions mitigation strategies.",
        "DOI": "10.1016/j.scitotenv.2020.139625",
        "paper_author": "Le Cornec C.M.A.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Discerning the success of sustainable planning: A comparative analysis of urban heat island dynamics in Korean new towns",
        "publication": "Sustainable Cities and Society",
        "citied_by": "45",
        "cover_date": "2020-10-01",
        "Abstract": "UHI is an important measure for understanding the urban landscape, especially in terms of thermal agglomeration and disturbance. This research aims to discern the success of sustainability planning by examining and comparing the different characteristics of UHIs through the combination of machine learning and statistical methods. To achieve this, we analyze 4 new towns in Korea, which include two ‘old’ new towns and two ‘recent’ new towns. The key difference between our test towns lies on whether or not the sustainability policies were applied to their development plans. We visualize LST and conduct a k-mean clustering to find and quantify spatial patterning in the resulting UHI measures. We then compare the statistical relations between LST and 6 UHI driven variables across the towns. Using comparative analysis, this research reveals that sustainable development policies have a notable effect on the patterns and intensities of UHI. Urban structures, planned under development policies, including green and blue space ratios, road networks, and housing distributions, were found to affect UHI significantly. We quantifiably confirm that the sustainability policies implemented in planning the ‘recent’ new towns allow the towns to experience less aggravated UHIs than the ‘old’ new towns. However, we also claim a need to develop appropriate, long-term UHI management regulations for the ‘recent’ new towns. This paper provides a solid basis for improving Korean new town planning and managing the environmental issues in urban systems for planners, designers, and decision-makers to establish the sustainable built environment.",
        "DOI": "10.1016/j.scs.2020.102341",
        "paper_author": "Kwak Y.",
        "affiliation_name": "University of Illinois Urbana-Champaign",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States",
        "affiliation_id": "60000745",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Computer-aided diagnosis for characterization of colorectal lesions: comprehensive software that includes differentiation of serrated lesions",
        "publication": "Gastrointestinal Endoscopy",
        "citied_by": "38",
        "cover_date": "2020-10-01",
        "Abstract": "Background and Aims: Endoscopy guidelines recommend adhering to policies such as resect and discard only if the optical biopsy is accurate. However, accuracy in predicting histology can vary greatly. Computer-aided diagnosis (CAD) for characterization of colorectal lesions may help with this issue. In this study, CAD software developed at the University of Adelaide (Australia) that includes serrated polyp differentiation was validated with Japanese images on narrow-band imaging (NBI) and blue-laser imaging (BLI). Methods: CAD software developed using machine learning and densely connected convolutional neural networks was modeled with NBI colorectal lesion images (Olympus 190 series - Australia) and validated for NBI (Olympus 290 series) and BLI (Fujifilm 700 series) with Japanese datasets. All images were correlated with histology according to the modified Sano classification. The CAD software was trained with Australian NBI images and tested with separate sets of images from Australia (NBI) and Japan (NBI and BLI). Results: An Australian dataset of 1235 polyp images was used as training, testing, and internal validation sets. A Japanese dataset of 20 polyp images on NBI and 49 polyp images on BLI was used as external validation sets. The CAD software had a mean area under the curve (AUC) of 94.3% for the internal set and 84.5% and 90.3% for the external sets (NBI and BLI, respectively). Conclusions: The CAD achieved AUCs comparable with experts and similar results with NBI and BLI. Accurate CAD prediction was achievable, even when the predicted endoscopy imaging technology was not part of the training set.",
        "DOI": "10.1016/j.gie.2020.02.042",
        "paper_author": "Zorron Cheng Tao Pu L.",
        "affiliation_name": "The University of Adelaide",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia",
        "affiliation_id": "60009512",
        "affiliation_state": "SA"
    },
    {
        "paper_title": "Forecasting electricity consumption using a novel hybrid model",
        "publication": "Sustainable Cities and Society",
        "citied_by": "71",
        "cover_date": "2020-10-01",
        "Abstract": "In recent years, the electricity industry has become increasingly important to social and economic development. For sustainability of the power industrial business, an accurate electricity consumption forecasting model can be used to adjust the production and consumption patterns of electricity, it can also support energy policy decision-making, such as load unit commitment, operational security of plants, and economic load dispatching. Using electricity consumption data to study electricity production and consumption patterns is useful in identifying the regulation of electricity economic development. This paper combines several machine learning approaches (the empirical mode decomposition (EMD) method, the support vector regression (SVR) model, and the particle swarm optimization (PSO) algorithm), thermal reaction dynamics theory, and the econometric model (AR-GARCH model), to develop a novel hybrid forecasting model, namely EMD-SVR-PSO-AR-GARCH model, for forecasting electricity consumption. It adopts a new perspective on electricity usage and consuming economic behaviors. Using electricity consumption data from the New South Wales (NSW, Australia) market, the developed model is used to forecast electricity consumption. Then, the Nash equilibrium and Porter's five-force model are used to analyze the complex electricity usage and consuming economic behaviors, to identify the regulation of electricity and economic development, supporting the sustainable development of electricity.",
        "DOI": "10.1016/j.scs.2020.102320",
        "paper_author": "Fan G.F.",
        "affiliation_name": "Pingdingshan University",
        "affiliation_city": "Pingdingshan",
        "affiliation_country": "China",
        "affiliation_id": "60136206",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "A framework with efficient extraction and analysis of Twitter data for evaluating public opinions on transportation services",
        "publication": "Travel Behaviour and Society",
        "citied_by": "43",
        "cover_date": "2020-10-01",
        "Abstract": "Public opinion is a valuable source for evaluating the performance of transportation services, which can guide management and policy adjustment. In contrast to traditional surveying methods, which are often inefficient and high-cost, social media has become a popular channel to collect public opinion due to its large data volume and accessibility characteristics. However, existing research lack efficient methods to extract and interpret Twitter data for transportation services evaluation. Therefore, this paper presents a comprehensive framework that enables high-efficient extraction and analysis of public opinions on transportation services from Twitter. The transportation system of Miami-Dade County is chosen as the case study to describe the framework development and validation process. First, Twitter data in a defined area over a certain period are collected and preprocessed to clean erroneous and redundant information. Then, the Twitter data that relate to personal opinions on transportation services (POTS) are filtered hieratically using text classification models trained by manually labeled dataset. Next, timeline analysis using Post Intensity (PI) and Average Sentiment Value (ASV) is implemented on the selected Twitter data to explore the public perceptions towards the transportation-related events. Topic modeling and tokenization techniques are also adopted to extract relevant semantic content needed for data analysis. Significantly, the developed framework can improve the efficiency of Twitter data extraction and analysis. Many manual steps are involved in the development process of the framework while can be avoided when generalized to other applications. The framework can be used as a tool for stakeholders to enable a holistic understanding of public opinions on transportation services and increase the degree of public participation in transportation management.",
        "DOI": "10.1016/j.tbs.2020.05.005",
        "paper_author": "Qi B.",
        "affiliation_name": "University of Florida",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States",
        "affiliation_id": "60013959",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Modeling pedestrian evacuation for near-field tsunamis fusing ALCD and agent-based approaches: A case study of Rincón, PR",
        "publication": "International Journal of Disaster Risk Reduction",
        "citied_by": "12",
        "cover_date": "2020-10-01",
        "Abstract": "Phenomena like tsunamis cannot be predicted, and simulation models are continuously being used in an attempt to understand how individuals will react in an emergency evacuation event. More specifically, pedestrian evacuation simulation can be used to better understand how pedestrians will escape an at-risk area. This work presents a pedestrian evacuation model (PEM) for the municipality of Rincón, Puerto Rico. This PEM provides insight on the vulnerability of Rincón to tsunamis using an iterative, optimization-based algorithm that fuses anisotropic least cost distance (ALCD) and agent-based (AB) approaches. This work advances the ALCD literature by providing a computationally-feasible PEM implementation capable of: (1) strategically initializing the location of pedestrians based on infrastructure and land use considerations, (2) managing individual as well as group-based evacuation, (3) assigning evacuation speeds and responses using probability and machine learning approaches, and (4) penalizing evacuation times using fatigue and reaction delays. The results of this PEM will provide emergency managers with a more realistic depiction of the time to reach safety using a systematic framework. Results, based on the worst-case scenario, indicate that 32.44% of the population in the tsunami evacuation zone (TEZ) would reach safety under 5 min, 41.96% between 5 and 15 min, and 25.60% would require more than 15 min. Unless effective public policy and mitigation strategies take place, the aftermath of a tsunami that inundates the Rincón coastline in less than 5 min could amount to up to 3312 casualties or 68% of the population in the TEZ.",
        "DOI": "10.1016/j.ijdrr.2020.101606",
        "paper_author": "Faucher J.E.",
        "affiliation_name": "Accenture",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States",
        "affiliation_id": "60032170",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Outbreak Trends of Coronavirus Disease-2019 in India: A Prediction",
        "publication": "Disaster Medicine and Public Health Preparedness",
        "citied_by": "133",
        "cover_date": "2020-10-01",
        "Abstract": "Objective: The objective of this paper is to prepare the government and citizens of India to take or implement the control measures proactively to reduce the impact of coronavirus disease 2019 (COVID-19). Method: In this work, the COVID-19 outbreak in India has been predicted based on the pattern of China using a machine learning approach. The model is built to predict the number of confirmed cases, recovered cases, and death cases based on the data available between January 22, 2020, and April 3, 2020. The time series forecasting method is used for prediction models. Results: The COVID-19 effects are predicted to be at peak between the third and fourth weeks of April 2020 in India. This outbreak is predicted to be controlled around the end of May 2020. The total number of predicted confirmed cases of COVID-19 might reach around 68 978, and the number of deaths due to COVID-19 are predicted to be 1557 around April 25, 2020, in India. If this outbreak is not controlled by the end of May 2020, then India will face a severe shortage of hospitals, and it will make this outbreak even worse. Conclusion: The COVID-19 pandemic may be controlled if the Government of India takes proactive steps to aggressively implement a lockdown in the country and extend it further. This presented epidemiological model is an effort to predict the future forecast of COVID-19 spread, based on the present scenario, so that the government can frame policy decisions, and necessary actions can be initiated.",
        "DOI": "10.1017/dmp.2020.115",
        "paper_author": "Tiwari S.",
        "affiliation_name": "Govind Ballabh Pant Engineering College",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60114760",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Artificial Intelligence and Predicting Illegal Immigration to the USA",
        "publication": "International Migration",
        "citied_by": "14",
        "cover_date": "2020-10-01",
        "Abstract": "The number of Mexican immigrants in the USA tripled between 1990 and 2015. In 2015, about 12 million undocumented immigrants lived in the USA, including 6.6 million undocumented Mexican immigrants. More than half of the undocumented immigrants in the USA enter the USA legally and overstay their visas. Therefore, it is essential to predict whether visa applicants overstay their visas or not. We use a set of pre-immigration variables for more than 6,281 individuals from Mexico to predict their legal status in the USA. By using eight machine learning techniques, we conclude that we can predict correctly the legal status of 80 per cent of Mexicans who migrate to the USA.",
        "DOI": "10.1111/imig.12695",
        "paper_author": "Azizi S.S.",
        "affiliation_name": "Purdue University Northwest",
        "affiliation_city": "Westville",
        "affiliation_country": "United States",
        "affiliation_id": "60122606",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Reinforcement learning applied to airline revenue management",
        "publication": "Journal of Revenue and Pricing Management",
        "citied_by": "30",
        "cover_date": "2020-10-01",
        "Abstract": "Reinforcement learning (RL) is an area of machine learning concerned with how agents take actions to optimize a given long-term reward by interacting with the environment they are placed in. Some well-known recent applications include self-driving cars and computers playing games with super-human performance. One of the main advantages of this approach is that there is no need to explicitly model the nature of the interactions with the environment. In this work, we present a new airline Revenue Management System (RMS) based on RL, which does not require a demand forecaster. The optimization module remains but works in a different way. It is theoretically proven that RL converges to the optimal solution; however, in practice, the system may require a significant amount of data (a booking history with millions of daily departures) to learn the optimal policies. To overcome these difficulties, we present a novel model that integrates domain knowledge with a deep neural network trained on GPUs. The results are very encouraging in different scenarios and open the door for a new generation of RMSs that could automatically learn by directly interacting with customers.",
        "DOI": "10.1057/s41272-020-00228-4",
        "paper_author": "Bondoux N.",
        "affiliation_name": "Amadeus S.A.S.",
        "affiliation_city": "Sophia Antipolis",
        "affiliation_country": "France",
        "affiliation_id": "101759187",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Reinforcement Learning Approach to Autonomous Decision Making of Intelligent Vehicles on Highways",
        "publication": "IEEE Transactions on Systems, Man, and Cybernetics: Systems",
        "citied_by": "136",
        "cover_date": "2020-10-01",
        "Abstract": "Autonomous decision making is a critical and difficult task for intelligent vehicles in dynamic transportation environments. In this paper, a reinforcement learning approach with value function approximation and feature learning is proposed for autonomous decision making of intelligent vehicles on highways. In the proposed approach, the sequential decision making problem for lane changing and overtaking is modeled as a Markov decision process with multiple goals, including safety, speediness, smoothness, etc. In order to learn optimized policies for autonomous decision-making, a multiobjective approximate policy iteration (MO-API) algorithm is presented. The features for value function approximation are learned in a data-driven way, where sparse kernel-based features or manifold-based features can be constructed based on data samples. Compared with previous RL algorithms such as multiobjective Q-learning, the MO-API approach uses data-driven feature representation for value and policy approximation so that better learning efficiency can be achieved. A highway simulation environment using a 14 degree-of-freedom vehicle dynamics model was established to generate training data and test the performance of different decision-making methods for intelligent vehicles on highways. The results illustrate the advantages of the proposed MO-API method under different traffic conditions. Furthermore, we also tested the learned decision policy on a real autonomous vehicle to implement overtaking decision and control under normal traffic on highways. The experimental results also demonstrate the effectiveness of the proposed method.",
        "DOI": "10.1109/TSMC.2018.2870983",
        "paper_author": "Xu X.",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60024350",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Methodologically grounded semantic analysis of large volume of chilean medical literature data applied to the analysis of medical research funding efficiency in Chile",
        "publication": "Journal of Biomedical Semantics",
        "citied_by": "4",
        "cover_date": "2020-09-29",
        "Abstract": "Background: Medical knowledge is accumulated in scientific research papers along time. In order to exploit this knowledge by automated systems, there is a growing interest in developing text mining methodologies to extract, structure, and analyze in the shortest time possible the knowledge encoded in the large volume of medical literature. In this paper, we use the Latent Dirichlet Allocation approach to analyze the correlation between funding efforts and actually published research results in order to provide the policy makers with a systematic and rigorous tool to assess the efficiency of funding programs in the medical area. Results: We have tested our methodology in the Revista Médica de Chile, years 2012-2015. 50 relevant semantic topics were identified within 643 medical scientific research papers. Relationships between the identified semantic topics were uncovered using visualization methods. We have also been able to analyze the funding patterns of scientific research underlying these publications. We found that only 29% of the publications declare funding sources, and we identified five topic clusters that concentrate 86% of the declared funds. Conclusions: Our methodology allows analyzing and interpreting the current state of medical research at a national level. The funding source analysis may be useful at the policy making level in order to assess the impact of actual funding policies, and to design new policies.",
        "DOI": "10.1186/s13326-020-00226-w",
        "paper_author": "Wolff P.",
        "affiliation_name": "Universidad de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile",
        "affiliation_id": "60012464",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "An Energy Efficient 3D-Heterogeneous Main Memory Architecture for Mobile Devices",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2020-09-28",
        "Abstract": "The demand for main memory capacity is ever increasing in mobile devices and embedded systems. Dynamic Random Access Memories (DRAMs) can not keep pace with the required main memory capacities because of the restrictions in improving the cell density due to the slowdown in scaling and the high leakage power consumption. Contrary, emerging Non-Volatile Memories (NVMs), primarily Resistive Random Access Memories (RRAMs), offer a high scaling potential and consume less leakage power than DRAMs. However, they are not suitable to completely replace DRAMs as the main memory, owing to their large read and write access latencies and limited endurance. In this paper, we present the architecture of a novel heterogeneous 3D-stacked on-chip main memory system composed of DRAMs and RRAMs that can fulfill the memory capacity demands of future mobile devices. We evaluate the energy savings of the new architecture for several applications, including some emerging machine learning tasks on mobile devices, by conducting system-level simulations in gem5 using ARM CPU models. We explore and analyze the impacts of different hybrid memory organizations and data allocation policies on reducing the energy and total number of RRAM writes. On average, the new 3D-hybrid architecture consumes 73% lesser energy and 61% lower average power than a 2D-Hybrid memory architecture for applications from the PARSEC benchmark. For a neural network training application, the 3D-hybrid memory saves up to 60% energy in comparison with a DDR4 DRAM-only main memory.",
        "DOI": "10.1145/3422575.3422786",
        "paper_author": "M. Mathew D.",
        "affiliation_name": "Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau",
        "affiliation_city": "Kaiserslautern",
        "affiliation_country": "Germany",
        "affiliation_id": "60280671",
        "affiliation_state": "Rheinland-Pfalz"
    },
    {
        "paper_title": "Designing freeform imaging systems based on reinforcement learning",
        "publication": "Optics Express",
        "citied_by": "16",
        "cover_date": "2020-09-28",
        "Abstract": "The design of complex freeform imaging systems with advanced system specification is often a tedious task that requires extensive human effort. In addition, the lack of design experience or expertise that result from the complex and uncertain nature of freeform optics, in addition to the limited history of usage, also contributes to the design difficulty. In this paper, we propose a design framework of freeform imaging systems using reinforcement learning. A trial-and-error method employing different design routes that use a successive optimization process is applied in different episodes under an \"-greedy policy. An \"exploitation-exploration, evaluation and back-up\" approach is used to interact with the environment and discover optimal policies. Design results with good imaging performance and related design routes can be found automatically. The design experience can be further summarized using the obtained data directly or through other methods such as clustering-based machine learning. The experience offers valuable insight for completing other related design tasks. Human effort can be significantly reduced in both the design process and the tedious process of summarizing experience. This design framework can be integrated into optical design software and runs nonstop in the background or on servers to complete design tasks and acquire experience automatically for various types of systems.",
        "DOI": "10.1364/OE.404808",
        "paper_author": "Yang T.",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016835",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Association of working conditions including digital technology use and systemic inflammation among employees: Study protocol for a systematic review",
        "publication": "Systematic Reviews",
        "citied_by": "7",
        "cover_date": "2020-09-28",
        "Abstract": "Background: With the dynamic advancement of digitalization, working environments are changing and risk for employee stress may be increasing. Work stress has been associated with a dysregulation of inflammatory processes as a component of immune function. Systemic low-grade inflammation is discussed as a key player in the relation between stress exposure and chronic illness, such as cardiovascular diseases. The objective of this investigation will be to evaluate the association of working conditions including digital technology use and systemic inflammation among employees. Methods: We designed and registered a study protocol for a systematic review of randomized controlled trials and prospective non-randomized studies (e.g., cohort, interrupted time series, or before-after studies). We will include studies conducted among adult workers reporting associations of working conditions and inflammatory activity. The outcome will be biomarkers of systemic low-grade inflammation on cell, plasma molecule and intracellular level, such as C-reactive protein, or different types of leukocytes, cytokines, etc. Literature searches will be conducted in several electronic databases (from January 1982 onwards), including PubMed/MEDLINE, Embase, PsycINFO, Web of Science, and CENTRAL. Two reviewers will independently screen all retrieved records, full-text articles, and extract data. The study methodological quality (or bias) will be appraised using appropriate tools. Our results will be described qualitatively. Random effects meta-analysis will be conducted, if feasible and appropriate. Additional analyses will be performed to explore potential sources of heterogeneity. Discussion: This systematic review and meta-analysis will provide a synthesis of studies evaluating the association of working conditions and systemic inflammation. We anticipate our findings to identify knowledge gaps in the literature that future research should address. Moreover, results of our review may provide implications for corporate and public policy action for employee health promotion and prevention of occupational stress. Systematic review registration: PROSPERO ID: CRD42020166887",
        "DOI": "10.1186/s13643-020-01463-x",
        "paper_author": "Kaltenegger H.C.",
        "affiliation_name": "Klinikum der Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60000291",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "A systematic review of statistical models and outcomes of predicting fatal and serious injury crashes from driver crash and offense history data",
        "publication": "Systematic Reviews",
        "citied_by": "8",
        "cover_date": "2020-09-28",
        "Abstract": "Background: Expenditure on driver-related behavioral interventions and road use policy is often justified by their impact on the frequency of fatal and serious injury crashes. Given the rarity of fatal and serious injury crashes, offense history, and crash history of drivers are sometimes used as an alternative measure of the impact of interventions and changes to policy. The primary purpose of this systematic review was to assess the rigor of statistical modeling used to predict fatal and serious crashes from offense history and crash history using a purpose-made quality assessment tool. A secondary purpose was to explore study outcomes. Methods: Only studies that used observational data and presented a statistical model of crash prediction from offense history or crash history were included. A quality assessment tool was developed for the systematic evaluation of statistical quality indicators across studies. The search was conducted in June 2019. Results: One thousand one hundred and five unique records were identified, 252 full texts were screened for inclusion, resulting in 20 studies being included in the review. The results indicate substantial and important limitations in the modeling methods used. Most studies demonstrated poor statistical rigor ranging from low to middle quality. There was a lack of confidence in published findings due to poor variable selection, poor adherence to statistical assumptions relating to multicollinearity, and lack of validation using new data. Conclusions: It was concluded that future research should consider machine learning to overcome correlations in the data, use rigorous vetting procedures to identify predictor variables, and validate statistical models using new data to improve utility and generalizability of models. Systematic review registration: PROSPERO CRD42019137081",
        "DOI": "10.1186/s13643-020-01475-7",
        "paper_author": "Slikboer R.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Mapping the Land Development Processes Using Data Transformation and Clustering Methods",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "1",
        "cover_date": "2020-09-26",
        "Abstract": "Understanding the historical trend of land development provides an invaluable source of information for policy-makers, environmental planners, and regional scientists. This information is useful in the study of the impacts of past decisions and natural conditions on the patterns of the trend. In this study, we built a hybrid algorithm that benefits from various techniques of land change detection to map the land development process in a given region. Data transformation and band differencing were used to construct a new feature class from the temporal satellite data. For data of three consecutive decades, a pairwise comparison of images was conducted. A clustering algorithm was applied to the constructed feature class to identify the location of new land developments. The results indicate a user's and producer's accuracy of 90.3%. The findings of this study are useful in the study of historic trends in land development and its patterns.",
        "DOI": "10.1109/IGARSS39084.2020.9323510",
        "paper_author": "Pourmohammadi P.",
        "affiliation_name": "Benjamin M. Statler College of Engineering and Mineral Resources",
        "affiliation_city": "Morgantown",
        "affiliation_country": "United States",
        "affiliation_id": "60157687",
        "affiliation_state": "WV"
    },
    {
        "paper_title": "Identifying Metro Trip Purpose using Multi-source Geographic Big Data and Machine Learning Approach",
        "publication": "Journal of Geo-Information Science",
        "citied_by": "8",
        "cover_date": "2020-09-25",
        "Abstract": "Identifying metro trip purpose using Smart Card Data (SCD) is important to expand the application of SCD in transport research and transport planning. This paper integrates different types of big data and combines the theories on the interaction between transport and land use. By taking Beijing as a case, we firstly analyze the metro trip purposes of individual passengers using travel survey data from 5565 respondents. Secondly, we investigate the land use features of trip origin and destination using Point of Interest(POI) data. Thirdly, a metro trip dataset is developed which includes the information of trip purpose, trip duration, and spatial distribution of trip origin and destination. Fourthly, a Random Forest (RF) algorithm is used to establish a RF classifier using the metro trip dataset as training data. Finally, this trained classifier is used to classify each metro trip recorded by the SCD to identify the metro trip purpose and the spatial distribution of metro trips for different purposes. The results of analysis show that the random forest classifier trained in this study can effectively identify metro trip purposes from SCD. For trips with \"go to work\" and \"go home\" purposes, the accuracy of identification can reach over 90%. One reason for the high identification accuracy is that land use information is included in the RF classifier. Our results confirm the theory of spatial-temporal interactions between transport and land use. There is an increasing availability of multi-source geographic big data and traffic survey data of residents in large cities, which means that the method developed in this study would have a high value in metro trip predicting and monitoring, transport planning, and land use policy-making around the metro stations. Also, our results enhance our knowledge of metro travel behavior in megacities.",
        "DOI": "10.12082/dqxxkx.2020.200134",
        "paper_author": "Zhao P.",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60014966",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Cooperative content delivery in UAV-RSU assisted vehicular networks",
        "publication": "DroneCom 2020 - Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond",
        "citied_by": "10",
        "cover_date": "2020-09-25",
        "Abstract": "Intelligent Transportation Systems (ITS) are gaining substantial attention owing to the great benefits offered to the vehicle users. In ITS paradigm, content data is normally obtained from road side units (RSUs). However, in some scenarios, terrestrial networks are partially/temporarily out-of-service. Unmanned Aerial Vehicle (UAV) or drone cells are expected to be one of the pillars of future networks to assist the vehicular networks in such scenarios. To this end, we propose a collaborative framework between UAVs and in-service RSUs to partial service vehicles. Our objective is to maximize the amount of downloaded contents to vehicles while considering the dynamic nature of the network. Motivated by the success of machine learning (ML) techniques particularly deep Reinforcement learning in solving complex problems, we formulate the scheduling and content management policy problem as a Markov Decision Process (MDP) where the system state space considers the vehicular network dynamics. Proximal Policy Optimization (PPO) is utilized to govern the content decisions in the vehicular network. The simulation-based results show that during the mission time, the proposed algorithm learns the vehicular environment and its dynamics to handle the complex action space.",
        "DOI": "10.1145/3414045.3415947",
        "paper_author": "Al-Hilo A.",
        "affiliation_name": "Concordia University",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60033154",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Analysis on the Situation of Internet Public Opinion Research",
        "publication": "Proceedings - 2020 12th International Conference on Computational Intelligence and Communication Networks, CICN 2020",
        "citied_by": "8",
        "cover_date": "2020-09-25",
        "Abstract": "Network public opinion analysis is of great significance to grasp the development trend of hot events and provide policy guidance. Therefore, systematically sorting out the evolutionary trends and research hotspots of research in this field can provide references and references for conducting network public opinion analysis as well as provide guidance for public opinion monitoring of regulatory authorities. To this end, 677 articles firstly selected in the field of network public opinion analysis that published in from 2014 to 2020 from the core database of Web of Science (WOS). Then Citespace was used to perform scientific measurement and visual analysis on them by building and analyzing knowledge graphs from multiple perspectives such as the distribution of research power of countries, institutions, authors and journals, etc. Finally, this paper discovered the research hotspots and evolution trends of the research in this field. Research methods have undergone an evolutionary process from statistics-based, machine learning algorithms to sentiment analysis. Sentiment analysis, social media and opinion discovery have become the hotspots in present research as well as the trend in future research.",
        "DOI": "10.1109/CICN49253.2020.9242578",
        "paper_author": "Wang J.",
        "affiliation_name": "Northeast Electric Power University",
        "affiliation_city": "Jilin",
        "affiliation_country": "China",
        "affiliation_id": "60073562",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "The Oxford english dictionary",
        "publication": "The Cambridge Companion to English Dictionaries",
        "citied_by": "1",
        "cover_date": "2020-09-24",
        "Abstract": "Known as 'the definitive record of the English language', the Oxford English Dictionary (OED) is the largest dictionary of English in the world. This chapter traces its creation from the mid-nineteenth century to the present day - through the publication of the first edition, supplement volumes, second edition, and the current third edition and OED Online website. The lexicograhic policies and practices of the various editors are also discussed, e.g. from Herbert Coleridge, Frederick Furnivall, and James Murray to Henry Bradley, Charles Onions, William Craigie, Robet Burchfield, John Simpson, Ed Weiner, and Michael Proffitt. This chapter also discusses the OED's current efforts to move from seeing the dictionary as a discrete text to seeing the dictionary as data which can be used in machine learning, natural language processing, and artificial intelligence.",
        "DOI": "10.1017/9781108553780.015",
        "paper_author": "Ogilvie S.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Principles of Tech-Okonomie: Future of economics for 2050",
        "publication": "The Circular Economy in the European Union: An Interim Review",
        "citied_by": "1",
        "cover_date": "2020-09-23",
        "Abstract": "The term \"Economics\" can be traced back to the ancient times when Greeks used to restrict it for the household frugality. Centuries later, we are living in a world where again technological advancements have brought in focus the \"Oikos\" or house. Digitalisation, technology and innovations have led us to enter into the next phase of revolution where Big Data, Internet of things (IoT), machine learning and artificial intelligence (AI) will prevail. In this paper, it is proposed that \"Tech-Okonomie\" be treated as a new form of Economics which subsists on the interplay of local ecosystem and household level data with respect to global scenario. Future of Economics shall not be held hostage to the old schools of Economics rather we should let our future generations bloom into an intertwined common world. It is postulated that the tide of data usages shall be harnessed to energise the growth engine of global economy with each \"eco-unit\" and \"household\" as a central theme. All forms of Economics whether at micro-level or macro-level needs such a Tech-Okonomie transformation into reality by the year 2050. This paper illustrates how the analysis of production, distribution and consumption of goods and services can permeate into economic policy changes which are based on the pulse of the \"eco-unit\" and \"household\". Principles of Tech-Okonomie emphasises upon a strategy for transformation of economies into such circular economies where human subsystems merge into a global ecosystem in sustainable manner. Governance should shift from the \"production of wealth\" to the \"survival of planet\". We should now shift towards inclusive \"planet-centric economic growth models\" from the earlier exclusive \"human-centric development models\".",
        "DOI": "10.1007/978-3-030-50239-3_15",
        "paper_author": "Bhardwaj A.",
        "affiliation_name": "Geological Society of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "116582189",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A machine learning approach to improve UHF RFID gate operation",
        "publication": "2020 5th International Conference on Smart and Sustainable Technologies, SpliTech 2020",
        "citied_by": "1",
        "cover_date": "2020-09-23",
        "Abstract": "The aim of this work is to improve the operation of a UHF RFID gate using a supervised learning approach based on Artificial Neural Networks (ANNs). In our setup, we assume that boxes containing items are inventoried using an RFID gate with random perturbations in the box positions as well as random items inside boxes. The gate has two bistatic dislocated antenna pairs and, for each box, it is possible to choose a particular pair or mix both (the antenna selection policy). Based on the interrogation statistics (tags read and average received signal strength) from initial reference frames it is possible to obtain a signature of the interrogation process to predict the probability of identifying the whole batch of items contained in the box. Predictions are carried out using the ANN, which is trained with data generated using a simulator. This system can be used online to select the best policy during operation, in order to minimize the time penalties caused by inventory faults.",
        "DOI": "10.23919/SpliTech49282.2020.9243800",
        "paper_author": "Vales-Alonso J.",
        "affiliation_name": "Universidad Politecnica de Cartagena",
        "affiliation_city": "Cartagena",
        "affiliation_country": "Spain",
        "affiliation_id": "60014907",
        "affiliation_state": "Murcia"
    },
    {
        "paper_title": "Improving Maternal Risk Analysis in Public Health Systems",
        "publication": "2020 5th International Conference on Smart and Sustainable Technologies, SpliTech 2020",
        "citied_by": "4",
        "cover_date": "2020-09-23",
        "Abstract": "There are several efforts in intelligent approaches in the literature dealing with maternal death risk prediction. Solutions focused on surveillance and monitoring maternal health contributes to reduce mortality rates, especially in low and middle-income countries. Data required by artificial intelligence systems are usually sensitive and restricted by privacy policies. High quality and trusted maternal health data are essential to obtain reliable predictive models. This study applies the Recursive Feature Elimination (RFE) strategy associated with decision tree-based classifier identifying a relevant set of features among an extensive list of maternal predictive information considered in a decision-making process. This study applies a systematic process of data preparation, analysis, and modeling to develop trusted models from maternal Electronic health registries (eRegistries). Also, this research presents an experiment pipeline to evaluate six well-known supervised machine learning models, namely Random Forest (RF), Support Vector Machine (SVM), Multilayer Perceptron (MLP), Adaptive Boosting (AdaBoost), Decision Tree (DT), and Gaussian Naive Bayes (GNB), with different combinations of ranked features. Results show that the feature ranking strategy was useful to reduce data dimensionality without affecting the performance of predictive models. The RFE-based predictive models achieves high Accuracy (ACC) and Area Under the Receiver Operating Characteristic Curve (AUC) with only eight maternal features.",
        "DOI": "10.23919/SpliTech49282.2020.9243769",
        "paper_author": "Pereira S.S.L.",
        "affiliation_name": "Instituto Federal de Educação, Ciência e Tecnologia do Ceará, Aracati",
        "affiliation_city": "Aracati",
        "affiliation_country": "Brazil",
        "affiliation_id": "60111727",
        "affiliation_state": "CE"
    },
    {
        "paper_title": "Human biases in government algorithms",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-09-23",
        "Abstract": "Machine learning is used in data-driven decision making and in governmental application of algorithms. Along with its many benefits, literature shows that machine learning solutions can introduce human bias to their results that they from training data. In this paper the authors study sentiment analysis algorithms to see if they show human bias, by interchanging lists of names associated with gender, race and political orientation in a synthetic neutral template sentence and then observing how the resulting sentiment values change. As a result, the authors find that names as subjects and objects in English language texts alone do not introduce human bias to the sentences' sentiment values. The findings also suggest that pseudonymization might be a better solution to the anonymization of social media postings for data protection compliance purposes than research so far suggested, owing to the general lack of sentiment distortion of the method introduced in this paper.",
        "DOI": "10.1145/3428502.3428529",
        "paper_author": "Thurnay L.",
        "affiliation_name": "University for Continuing Education Krems",
        "affiliation_city": "Krems an der Donau",
        "affiliation_country": "Austria",
        "affiliation_id": "60004038",
        "affiliation_state": "Lower Austria"
    },
    {
        "paper_title": "Social media enabled e-Participation: A lexicon-based sentiment analysis using unsupervised machine learning",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "10",
        "cover_date": "2020-09-23",
        "Abstract": "With the emerging and increasing use of ICT, electronic participation (e-participation) has appeared as an effort to involve people in policymaking effectively. Many e-participation projects have evolved over the past years, yet several of them have failed to reach a decent level of citizens engagement in decision-making processes. Even after integrating social media platforms that are known to promote better networking, data exchange, and user dissemination of data, there remains the challenge of enhancing public participation in social media-led participation. This study is composed of three (3) folds. First, it explores why citizens engage in social media-enabled e-Participation in the context of the Philippines' proposed house bill of decreasing the minimum age of criminal liability. Second, to support the findings in the first fold, this study investigates explicitly the sentiments and opinions felt by most Filipinos regarding the issue. Third, this paper examines how social media platform can provide an opportunity to improve civic involvement in e-Participation. It applies a lexicon-based model in analyzing sentiments and uses unsupervised machine learning-based algorithm in determining and classifying emotions in the dataset captured from Facebook. This also employs content analysis to triangulate the themes that emerged from the model vis-À-vis the dataset. Results have shown that 42% of the sentiments are Negative and that the sense of joy or happiness is 54% of the entire corpus. Of the eight (8) themes, the Expression of Refute covers 70%. Based on the findings, this article concludes that citizens engaged in social media-led e-Participation have varied emotions and views; and social media can be a forum for a higher level of engagement when decision-makers have an online presence and a commitment to dialogue with people.",
        "DOI": "10.1145/3428502.3428581",
        "paper_author": "Pitogo V.A.",
        "affiliation_name": "Caraga State University",
        "affiliation_city": "Butuan",
        "affiliation_country": "Philippines",
        "affiliation_id": "60280144",
        "affiliation_state": "Agusan Del Norte"
    },
    {
        "paper_title": "AI for monitoring the Sustainable Development Goals and supporting and promoting action and policy development",
        "publication": "2020 IEEE / ITU International Conference on Artificial Intelligence for Good, AI4G 2020",
        "citied_by": "8",
        "cover_date": "2020-09-21",
        "Abstract": "The United Nations sustainable development goals (SDGs) were ratified with much enthusiasm by all UN member states in 2015. However, subsequent progress to meet these goals has been hampered by a lack of data available to measure the SDG indicators (SDIs), and a lack of evidence-based insights to inform effective policy responses. We outline an interdisciplinary program of research into the use of artificial intelligence techniques to support measurement of the SDIs, using both machine learning methods to model SDI measurements and explainable AI techniques to present the outputs in a human-friendly manner. As well as addressing the technical concerns, we will investigate the governance issues of what forms of evidence, methods of collecting that evidence and means of its communication will most usefully inform effective policy development. By addressing these fundamental challenges, we aim to provide policy makers with the evidence needed to take effective action towards realising the Sustainable Development Goals.",
        "DOI": "10.1109/AI4G50087.2020.9311014",
        "paper_author": "Miller L.",
        "affiliation_name": "Monash University",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60019578",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "2020 IEEE / ITU International Conference on Artificial Intelligence for Good, AI4G 2020",
        "publication": "2020 IEEE / ITU International Conference on Artificial Intelligence for Good, AI4G 2020",
        "citied_by": "0",
        "cover_date": "2020-09-21",
        "Abstract": "The proceedings contain 38 papers. The topics discussed include: a conceptual framework for AI system development and sustainable social equality; digital crop health monitoring by analyzing social media streams; maximizing value of frugal soil moisture sensors for precision agriculture applications; misinformation in crises: a conceptual framework for examining human-machine interactions; a novel application for the efﬁcient and accessible diagnosis of ADHD using machine learning; DASSL: dynamic, AI-assisted, scalable system for labelling used bottle images; AI for monitoring the sustainable development goals and supporting and promoting action and policy development; and theory of machine learning based in quantum mechanics.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Global Surveillance of COVID-19 by mining news media using a multi-source dynamic embedded topic model",
        "publication": "Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics, BCB 2020",
        "citied_by": "15",
        "cover_date": "2020-09-21",
        "Abstract": "As the COVID-19 pandemic continues to unfold, understanding the global impact of non-pharmacological interventions (NPI) is important for formulating effective intervention strategies, particularly as many countries prepare for future waves. We used a machine learning approach to distill latent topics related to NPI from large-scale international news media. We hypothesize that these topics are informative about the timing and nature of implemented NPI, dependent on the source of the information (e.g., local news versus official government announcements) and the target countries. Given a set of latent topics associated with NPI (e.g., self-quarantine, social distancing, online education, etc), we assume that countries and media sources have different prior distributions over these topics, which are sampled to generate the news articles. To model the source-specific topic priors, we developed a semi-supervised, multi-source, dynamic, embedded topic model. Our model is able to simultaneously infer latent topics and learn a linear classifier to predict NPI labels using the topic mixtures as input for each news article. To learn these models, we developed an efficient end-To-end amortized variational inference algorithm. We applied our models to news data collected and labelled by the World Health Organization (WHO) and the Global Public Health Intelligence Network (GPHIN). Through comprehensive experiments, we observed superior topic quality and intervention prediction accuracy, compared to the baseline embedded topic models, which ignore information on media source and intervention labels. The inferred latent topics reveal distinct policies and media framing in different countries and media sources, and also characterize reaction to COVID-19 and NPI in a semantically meaningful manner. Our PyTorch code is available on Github (htps://github.com/li-lab-mcgill/covid19_media).",
        "DOI": "10.1145/3388440.3412418",
        "paper_author": "Li Y.",
        "affiliation_name": "McGill Centre for Bioinformatics",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60083670",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Modelling and mapping the intra-urban spatial distribution of Plasmodium falciparum parasite rate using very-high-resolution satellite derived indicators",
        "publication": "International Journal of Health Geographics",
        "citied_by": "15",
        "cover_date": "2020-09-21",
        "Abstract": "Background: The rapid and often uncontrolled rural-urban migration in Sub-Saharan Africa is transforming urban landscapes expected to provide shelter for more than 50% of Africa's population by 2030. Consequently, the burden of malaria is increasingly affecting the urban population, while socio-economic inequalities within the urban settings are intensified. Few studies, relying mostly on moderate to high resolution datasets and standard predictive variables such as building and vegetation density, have tackled the topic of modeling intra-urban malaria at the city extent. In this research, we investigate the contribution of very-high-resolution satellite-derived land-use, land-cover and population information for modeling the spatial distribution of urban malaria prevalence across large spatial extents. As case studies, we apply our methods to two Sub-Saharan African cities, Kampala and Dar es Salaam. Methods: Openly accessible land-cover, land-use, population and OpenStreetMap data were employed to spatially model Plasmodium falciparum parasite rate standardized to the age group 2-10 years (PfPR2-10) in the two cities through the use of a Random Forest (RF) regressor. The RF models integrated physical and socio-economic information to predict PfPR2-10 across the urban landscape. Intra-urban population distribution maps were used to adjust the estimates according to the underlying population. Results: The results suggest that the spatial distribution of PfPR2-10 in both cities is diverse and highly variable across the urban fabric. Dense informal settlements exhibit a positive relationship with PfPR2-10 and hotspots of malaria prevalence were found near suitable vector breeding sites such as wetlands, marshes and riparian vegetation. In both cities, there is a clear separation of higher risk in informal settlements and lower risk in the more affluent neighborhoods. Additionally, areas associated with urban agriculture exhibit higher malaria prevalence values. Conclusions: The outcome of this research highlights that populations living in informal settlements show higher malaria prevalence compared to those in planned residential neighborhoods. This is due to (i) increased human exposure to vectors, (ii) increased vector density and (iii) a reduced capacity to cope with malaria burden. Since informal settlements are rapidly expanding every year and often house large parts of the urban population, this emphasizes the need for systematic and consistent malaria surveys in such areas. Finally, this study demonstrates the importance of remote sensing as an epidemiological tool for mapping urban malaria variations at large spatial extents, and for promoting evidence-based policy making and control efforts.",
        "DOI": "10.1186/s12942-020-00232-2",
        "paper_author": "Georganos S.",
        "affiliation_name": "Université Libre de Bruxelles",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "60000145",
        "affiliation_state": "BRU"
    },
    {
        "paper_title": "A Scalable Data Analytics and Visualization System for City-wide Traffic Signal Data-sets",
        "publication": "2020 IEEE 23rd International Conference on Intelligent Transportation Systems, ITSC 2020",
        "citied_by": "2",
        "cover_date": "2020-09-20",
        "Abstract": "The advent of new traffic data collection tools such as high-resolution signalized intersection controller logs opens up a new space of possibilities for traffic management. In this work, we describe the high resolution datasets, apply appropriate machine learning methods to obtain relevant information from the said datasets and develop visualization tools to provide traffic engineers with suitable interfaces, thereby enabling new insights into traffic signal performance management. The eventual goal of this study is to enable automated analysis and help create operational performance measures for signalized intersections while aiding traffic administrators in their quest to design 21st century signal policies.",
        "DOI": "10.1109/ITSC45102.2020.9294738",
        "paper_author": "Mahajan D.",
        "affiliation_name": "Herbert Wertheim College of Engineering",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States",
        "affiliation_id": "60154244",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Causal effect of environmental factors, economic indicators and domestic material consumption using frequency domain causality test",
        "publication": "Science of the Total Environment",
        "citied_by": "31",
        "cover_date": "2020-09-20",
        "Abstract": "Economic growth-induced climate change is multifaceted with different dimensions, hence, requires scientific scrutiny. Herein, an assessment of the causal effect of environmental factors, economic assessment and domestic material consumption is presented. We utilized the novel Breitung-Candelon spectral Granger-causality aka frequency domain causality and parameter stability tests to account for the direction of causality. These tests, a resemblance to machine learning algorithm were required to examine the sequential shock of unobserved features of series not reported in traditional Granger-causality tests. The empirical results found a short-run relationship between renewables and economic growth, suggesting a strong effect of wealth on renewable energy consumption. We confirmed a strong and long-term metallurgical coal-controlled metal footprint through steelmaking, and coal-driven energy-based economic structure. The feedback hypothesis was validated between biomass consumption and economic growth. There was evidence that metal ore consumption predicts economic growth, income level and renewable energy consumption while it causes ambient air pollution. From a policy perspective, the study demonstrates that the diversification of the energy mix with renewable energy sources will reduce fossil fuel footprint.",
        "DOI": "10.1016/j.scitotenv.2020.139602",
        "paper_author": "Sarkodie S.A.",
        "affiliation_name": "Nord Universitet",
        "affiliation_city": "Bodo",
        "affiliation_country": "Norway",
        "affiliation_id": "60021876",
        "affiliation_state": "Nordland"
    },
    {
        "paper_title": "Proceedings - 36th International Conference on Logic Programming, ICLP 2020",
        "publication": "Electronic Proceedings in Theoretical Computer Science, EPTCS",
        "citied_by": "0",
        "cover_date": "2020-09-19",
        "Abstract": "The proceedings contain 30 papers. The topics discussed include: applications of answer set programming where theory meets practice; when is it morally acceptable to break the rules? a preference-based approach; formal reasoning methods for explainability in machine learning; from probabilistic logics to neuro-symbolic artificial intelligence; norms, policy and laws: modeling, compliance and violation; datalog-based systems can use incremental SMT solving; formal semantics and scalability for datalog with aggregates: a cardinality-based solution; a logic programming approach to regression based repair of incorrect initial belief states; and a hybrid neuro-symbolic approach for complex event processing.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting sales and return products for retail corporations and bridging among them",
        "publication": "Demand Forecasting and Order Planning in Supply Chains and Humanitarian Logistics",
        "citied_by": "0",
        "cover_date": "2020-09-18",
        "Abstract": "The purpose of this study is to show how we can bridge sales and return forecasts for every product of a retail store by using the best model among several forecasting models. Managers can utilize this information to improve customer's satisfaction, inventory management, or re-define policy for after sales support for specific products. The authors investigate multi-product sales and return forecasting by choosing the best forecasting model. To this aim, some machine learning algorithms including ARIMA, Holt-Winters, STLF, bagged model, Timetk, and Prophet are utilized. For every product, the best forecasting model is chosen after comparing these models to generate sales and return forecasts. This information is used to classify every product as \"profitable,\" \"risky,\" and \"neutral,\" The experiment has shown that 3% of the total products have been identified as \"risky\" items for the future. Managers can utilize this information to make some crucial decisions.",
        "DOI": "10.4018/978-1-7998-3805-0.ch009",
        "paper_author": "Chowdhury M.M.H.",
        "affiliation_name": "Freedom Mobile (Telecom Operator)",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "128510928",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Comparison of Evolutionary Strategies for Reinforcement Learning in a Swarm Aggregation Behaviour",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "3",
        "cover_date": "2020-09-18",
        "Abstract": "This article studies the performance of different evolutionary strategies for deep reinforcement learning policy optimization. The policy will be centred in an important swarm robotic task: the aggregation of simple robots in the environment. The main inspiration for robotic swarm comes from the observation of social animals. Ants, bees, birds, and fish are some examples of how simple individuals can succeed when they gather in groups. In addition, is important to highlight that aggregation may be considered as a previous requirement to tackle another tasks. Due the design of a swarm behaviour is a comprehensive process of experimentation, one of the current solutions is learn a policy able to control a robot. Gradient descent techniques have demonstrated their learning power in the field of neural networks and reinforcement learning, among others. But some of these techniques are difficult to be applied in the field of robotics because the requirements needed to calculate the gradient to be informative are not met. For that reason, in this article we are going to use and compare the evolutionary strategies CMA-ES, PEPG, SES, GA y OpenAI-ES. A fast simulator, based in the differential robot Mbot Ranger, will be used. Once the aggregation task is learned we will compare each strategy for different swarm sizes to analyse the convergence time, the quality of the policies, its scalability and its capacity to generalize.",
        "DOI": "10.1145/3426826.3426835",
        "paper_author": "Rais Martínez J.",
        "affiliation_name": "Universitat d'Alacant",
        "affiliation_city": "Alicante",
        "affiliation_country": "Spain",
        "affiliation_id": "60010844",
        "affiliation_state": "Alicante"
    },
    {
        "paper_title": "Swarm AGV Optimization Using Deep Reinforcement Learning",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "6",
        "cover_date": "2020-09-18",
        "Abstract": "Behavior design for Automated Guided Vehicles (AGV) systems is an active research area, fundamental for robotics, industrial systems automation. The rise of machine learning neural systems and deep learning make promising results in a multitude of areas including warehouse environments. In this paper, several different policies will be obtained by using reinforcement learning on a heterogeneous swarm robotic system, applied for solving logistical tasks in Automated Guided Vehicles. More specifically, two different types of agents will be used: the vehicles that collect, transport and deposit their package and the traffic lights that regulate the number of vehicles that circulate on the tracks. The main objective of our work is to learn simultaneously two different control policies, one for each kind of agent. The obtained policies have shown their ability to correctly learn the package transport behavior in addition to balance traffic flow to facilitate agent mobility and avoid collisions. Furthermore, the scalability of the system and the behavior performance for different number of vehicles has been shown.",
        "DOI": "10.1145/3426826.3426839",
        "paper_author": "Arques Corrales P.",
        "affiliation_name": "Universitat d'Alacant",
        "affiliation_city": "Alicante",
        "affiliation_country": "Spain",
        "affiliation_id": "60010844",
        "affiliation_state": "Alicante"
    },
    {
        "paper_title": "Quantifying the impacts of pre-occurred ENSO signals on wheat yield variation using machine learning in Australia",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "26",
        "cover_date": "2020-09-15",
        "Abstract": "Australia is one of the top wheat exporting countries in the world and the reliable prediction of wheat production plays a key role in ensuring regional and global food security. However, wheat yield in Australia is highly exposed to the impacts of climate variability, especially seasonal rainfall, as wheat is mostly grown in the drylands. Previous studies showed that El Niño Southern Oscillation (ENSO) has a strong influence on Australia's climate and found the ENSO-related phenomena have prognostic features for future climatic conditions. Therefore, we examined the predictability of state-scale variation in Australian wheat yields based on ENSO-related large-scale climate precursors using machine learning techniques. Here, we firstly established a set of random forest (RF, a machine learning method) models based on pre-occurred climate indices to forecast spring rainfall for the four major wheat producing states of Australia, the forecasted rainfall was then combined with selected precedent climate drivers to predict yield variations using another set of RF models for each state. We explored the most influential variables in determining spring rainfall and yield variation. We found that the first set of RF models accounted for 43-59% of the change in spring rainfall across the four states. By incorporating forecasted spring rainfall with selected ENSO climate indices, the RF model accounted for 33-66% of the variation in yield which was greater than the 22-50% of yield variations explained by ENSO-related indices alone. The results suggest that wheat yield variation at a state level could be reliably forecasted at lead-times of three months prior to the commencement of harvest. We also found that forecasted spring rainfall and precedent Southern Oscillation Index (SOI) in July were the most important factors in estimation of crop yield in the winter dominant rainfall states. ENSO climate indices are easy to obtain and can be rapidly used to drive the forecasting model. Therefore, we believe the proposed models for predicting wheat yield variations at three-month lead time would be helpful for state governments and policy makers to develop effective planning to reduce monetary loss and ensure food security.",
        "DOI": "10.1016/j.agrformet.2020.108043",
        "paper_author": "Wang B.",
        "affiliation_name": "Northwest A&amp;F University",
        "affiliation_city": "Yangling",
        "affiliation_country": "China",
        "affiliation_id": "60031041",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "What is the resource footprint of a computer science department? Place, people, and Pedagogy",
        "publication": "Data and Policy",
        "citied_by": "1",
        "cover_date": "2020-09-11",
        "Abstract": "Internet and Communication Technology/electrical and electronic equipment (ICT/EEE) form the bedrock of today's knowledge economy. This increasingly interconnected web of products, processes, services, and infrastructure is often invisible to the user, as are the resource costs behind them. This ecosystem of machine-to-machine and cyber-physical-system technologies has a myriad of (in)direct impacts on the lithosphere, biosphere, atmosphere, and hydrosphere. As key determinants of tomorrow's digital world, academic institutions are critical sites for exploring ways to mitigate and/or eliminate negative impacts. This Report is a self-deliberation provoked by the question How do we create more resilient and healthier computer science departments: living laboratories for teaching and learning about resource-constrained computing, computation, and communication? Our response for University College London (UCL) Computer Science is to reflect on how, when, and where resources - energy, (raw) materials including water, space, and time - are consumed by the building (place), its occupants (people), and their activities (pedagogy). This perspective and attendant first-of-its-kind assessment outlines a roadmap and proposes high-level principles to aid our efforts, describing challenges and difficulties hindering quantification of the Department's resource footprint. Qualitatively, we find a need to rematerialise the ICT/EEE ecosystem: to reveal the full costs of the seemingly intangible information society by interrogating the entire life history of paraphernalia from smartphones through servers to underground/undersea cables; another approach is demonstrating the corporeality of commonplace phrases and Nature-inspired terms such as artificial intelligence, social media, Big Data, smart cities/farming, the Internet, the Cloud, and the Web. We sketch routes to realising three interlinked aims: cap annual power consumption and greenhouse gas emissions, become a zero waste institution, and rejuvenate and (re)integrate the natural and built environments.",
        "DOI": "10.1017/dap.2020.12",
        "paper_author": "Mian I.S.",
        "affiliation_name": "UCL Engineering",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60176024",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Internal control quality, equity pledge financing and investment efficiency",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "7",
        "cover_date": "2020-09-11",
        "Abstract": "In the present situation of difficult enterprise-financing, the equity pledge of corporate controlling shareholders is a effective channel for enterprises to relieve financing constraints. Whether an enterprise can formulate a reasonable investment policy to obtain investment income effectively and achieve financial goals, determines whether an enterprise can develop in the long-tern future. The target of this paper is to approach how the investment efficiency of an enterprise will change with the increase in the portion of controlling shareholder equity pledge (CSEQ), and how the internal control system of the enterprise regulates the contact between controlling shareholder equity pledge and investment efficiency. The article found that the controlling shareholder's equity pledge (CSEQ) affects the enterprise's inefficient investment behavior, and the controlling shareholder's equity pledge ratio has a positive interrelationship with the inefficient investment. According to the previous studies, this paper carries out further research, innovatively introduces the internal control quality index, discusses the influence of internal control quality on equity pledge and investment efficiency sensitivity. The result show that the higher internal control quality can restrain the excessive investment behavior of enterprises",
        "DOI": "10.1088/1742-6596/1629/1/012081",
        "paper_author": "Mu W.",
        "affiliation_name": "Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60016521",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Quantitative study on factors affecting the price of residential real estate multiple linear regression model",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "4",
        "cover_date": "2020-09-11",
        "Abstract": "To study the impact of the \"zero threshold\"household entry policy on the fluctuation of residential commodity housing prices in Jinan, this paper uses the average sales price data of residential commodity housing in Jinan from 2006 to 2018, selects 6 relevant indicators including the total population at the end of the year, and constructs a multiple linear regression. The model uses Eviews7.2 software, innovatively implies variables such as equivalent sound level, performs stepwise regression analysis, weighted correction regression model correction, and performs statistical tests such as heteroscedasticity and sequence correlation. The results show that the local general public budget expenditure and the average equivalent sound level of roads and environment have a positive impact on prices, while the local general public budget revenue and the total population at the end of the year have a negative impact on prices.",
        "DOI": "10.1088/1742-6596/1629/1/012071",
        "paper_author": "Cui F.",
        "affiliation_name": "Shandong Institute of Commerce and Technology",
        "affiliation_city": "Jinan",
        "affiliation_country": "China",
        "affiliation_id": "110345756",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Research on the impact of energy saving policies on subsidy income for regulated food enterprises: Based on PSM-DID method",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2020-09-11",
        "Abstract": "Taking the \"Energy Saving and Low Carbon Action in Ten-thousand Enterprises\"officially implemented in 2012 as the target of the energy saving policy, based on the data of food enterprises which are extracted from China Industry Business Performance Data, and by using the one-by-one propensity score matching method (one-by-one PSM), the balanced panel data of regulated enterprises (totalling 617) and unregulated food enterprises (totalling 617) from 2010 to 2013 are obtained through matching. Later, the difference-in-difference model (DID) with energy saving policy treatment variables is used for estimation to quantitatively evaluate the \"net\"effect of the energy-saving policy on subsidy income for regulated food enterprises. The results indicate that: The proportion of subsidized enterprises in all regulated food enterprises is higher than that of subsidized enterprises in unregulated food enterprises. Regulated food enterprises can obtain more subsidies than unregulated enterprises, which means, the proportion of subsidies in regulated enterprises is 43.1% higher than that in unregulated enterprises.",
        "DOI": "10.1088/1742-6596/1629/1/012031",
        "paper_author": "Chen J.",
        "affiliation_name": "Fujian Agriculture and Forestry University",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China",
        "affiliation_id": "60004630",
        "affiliation_state": "Fujian"
    },
    {
        "paper_title": "Economic analysis of the change of tea production layout in China",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "7",
        "cover_date": "2020-09-11",
        "Abstract": "In the context of deepening supply-side reform in China, based on the national tea planting area and yield data from 1993 to 2018, combined with GIS technology and spatial center of gravity statistical models, this paper analyzes the characteristics of China's tea development and change in 25 years in detail, and comprehensively analyses the driving mechanism of the changes. The following conclusions are drawn: China's tea production space has changed significantly, and the country's tea planting area and output have been on the rise, but the changes are inconsistent; The continuous westward shift of the center of tea production in China is caused by the joint influence of nature, economy and society, among which resource endowment and policy support are the most important driving forces.",
        "DOI": "10.1088/1742-6596/1629/1/012048",
        "paper_author": "Wu Q.",
        "affiliation_name": "Fujian Agriculture and Forestry University",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China",
        "affiliation_id": "60004630",
        "affiliation_state": "Fujian"
    },
    {
        "paper_title": "A diagnosis-based approach to assess specific risks of river degradation in a multiple pressure context: Insights from fish communities",
        "publication": "Science of the Total Environment",
        "citied_by": "14",
        "cover_date": "2020-09-10",
        "Abstract": "In the context of increasing pressure on water bodies, many fish-based indices have been developed to evaluate the ecological status of rivers. However, most of these indices suffer from several limitations, which hamper the capacity of water managers to select the most appropriate measures of restoration. Those limitations include: (i) being dependent on reference conditions, (ii) not satisfactorily handling complex and non-linear biological responses to pressure gradients, and (iii) being unable to identify specific risks of stream degradation in a multi-pressure context. To tackle those issues, we developed a diagnosis-based approach using Random Forest models to predict the impairment probabilities of river fish communities by 28 pressure categories (chemical, hydromorphological and biological). In addition, the database includes the abundances of 72 fish species collected from 1527 sites in France, sampled between 2005 and 2015; and fish taxonomic and biological information. Twenty random forest models provided at least good performances when evaluating impairment probabilities of fish communities by those pressures. The best performing models indicated that fish communities were impacted, on average, by 7.34 ± 0.03 abiotic pressure categories (mean ± SE), and that hydromorphological alterations (5.27 ± 0.02) were more often detected than chemical ones (2.06 ± 0.02). These models showed that alterations in longitudinal continuity, and contaminations by Polycyclic Aromatic Hydrocarbons were respectively the most frequent hydromorphological and chemical pressure categories in French rivers. This approach has also efficiently detected the functional impact of invasive alien species. Identifying and ranking the impacts of multiple anthropogenic pressures that trigger functional shifts in river biological communities is essential for managers to prioritize actions and to implement appropriate restoration programmes. Actually implemented in an R package, this approach has the capacity to detect a variety of impairments, resulting in an efficient assessment of ecological risks across various spatial and temporal scales.",
        "DOI": "10.1016/j.scitotenv.2020.139467",
        "paper_author": "Dézerald O.",
        "affiliation_name": "L'Institut Agro Rennes-Angers",
        "affiliation_city": "Rennes",
        "affiliation_country": "France",
        "affiliation_id": "60025758",
        "affiliation_state": "Brittany"
    },
    {
        "paper_title": "Farm efficiency estimation using a hybrid approach of machine-learning and data envelopment analysis: Evidence from rural eastern India",
        "publication": "Journal of Cleaner Production",
        "citied_by": "38",
        "cover_date": "2020-09-10",
        "Abstract": "In agricultural sector, farm efficiency evaluation is an important means of farm management. To evaluate the farm efficiency for effective allocation of agricultural resources, data envelopment analysis (DEA) is used. Commonly, a two-stage regression analysis is used to treat the obtained efficiency values on a set of explanatory variables. However, majority of the past studies explained the variables influencing efficiency rather than efficiency prediction. This paper aims to use DEA in combination with Machine learning approach to examine and predict the impact of environmental variables on farms’ performance. Random forest (RF) algorithm has been employed, which is one of the most useful machine learning algorithms of recent times. First, DEA was used to evaluate efficiency of all the farms. Then the RF method was employed to examine the variables crucial in predicting farm performance. This multi-stage model was applied to 450 paddy producers in rural Eastern India. The results of the RF algorithm revealed that land ownership, Kisan Credit Card (KCC), and educational status were the most crucial variables which affected the performance of the paddy producers. With the identification of the major factors influencing agricultural production, new policy actions may be developed to assist the small farmers. Furthermore, this joint DEA-Machine-learning approach may help future researchers not only to investigate but also to predict the impact of the important environmental variables on farms’ performance.",
        "DOI": "10.1016/j.jclepro.2020.122106",
        "paper_author": "Nandy A.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India",
        "affiliation_id": "60004750",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Predicting geographical suitability of geothermal power plants",
        "publication": "Journal of Cleaner Production",
        "citied_by": "51",
        "cover_date": "2020-09-10",
        "Abstract": "A large and increasing number of countries use geothermal energy as power source for domestic and industrial applications. Geothermal power plants produce energy out of this natural and renewable source in a sustainable way and contribute to reduce global warming. However, power plants effectiveness depends on the suitability of an area to geothermal energy production, which is a complex and unknown combination of many environmental factors. Nowadays, geothermal suitability assessments require invasive inspections, high costs, and legal permissions. Thus, having a global suitability map of geothermal sites as reference would be useful prior knowledge during assessments, and would help saving time and money. In this paper, the first suitability map of potential geothermal sites at global scale is presented. The map is the result of the application of data collection and preparation processes, and a Maximum Entropy model, to geospatial data potentially correlated with geothermal site suitability and geothermal plants operation. The reliability of our map is assessed against currently active and planned geothermal power plants. Our approach follows the Open Science paradigm that guarantees results reproduction and transparency, and allows stakeholders to reuse the produced standardised data, services, and Web interfaces in other experiments or to generate new maps at regional scale. Overall, our results can help scientists, industry operators, and policy makers in geothermal sites assessments. Also, our approach supports communication with citizens whose territories are involved in probing and assessments, in order to transparently inform them about the reasons driving the selection of their territory and the potential future benefits.",
        "DOI": "10.1016/j.jclepro.2020.121874",
        "paper_author": "Coro G.",
        "affiliation_name": "Istituto di Scienza e Tecnologie dell'Informazione A. Faedo",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60085207",
        "affiliation_state": "PI"
    },
    {
        "paper_title": "Privacy is dead-solutions for privacy-enabled collections and use of personal health information in digital era",
        "publication": "Studies in Health Technology and Informatics",
        "citied_by": "6",
        "cover_date": "2020-09-04",
        "Abstract": "Today's digital information systems and applications collect every day a huge amount of personal health information (PHI) from sensor and surveillance systems, and every time we use personal computers or mobile phones. Collected data is processed in clouds, platforms and ecosystems by digital algorithms and machine learning. Pervasive technology, insufficient and ineffective privacy legislation, strong ICT industry and low political will to protect data subject's privacy have together made it almost impossible for a user to know what PHI is collected, how it is used and to whom it is disclosed. Service providers' and organizations' privacy policy documents are cumbersome and they do not guarantee that PHI is not misused. Instead, service users are expected to blindly trust in privacy promises made. In spite of that, majority of individuals are concerned of their privacy, and governments' assurance that they meet the responsibility to protect citizens in real life privacy is actually dead. Because PHI is probably the most sensitive data we have, and the authors claim it cannot be a commodity or public good, they have studied novel privacy approaches to find a way out from the current unsatisfactory situation. Based on findings got, the authors have developed a promising solution for privacy-enabled use of PHI. It is a combination of the concept of information fiduciary duty, Privacy as Trust approach, and privacy by smart contract. This approach shifts the onus of privacy protection onto data collectors and service providers. A specific information fiduciary duty law is needed to harmonize privacy requirements and force the acceptance of proposed solutions. Furthermore, the authors have studied strengths and weaknesses of existing or emerging solutions.",
        "DOI": "10.3233/SHTI200616",
        "paper_author": "Ruotsalainen P.",
        "affiliation_name": "Tampere University",
        "affiliation_city": "Tampere",
        "affiliation_country": "Finland",
        "affiliation_id": "60011170",
        "affiliation_state": "Pirkanmaa"
    },
    {
        "paper_title": "Apprenticeship learning of flight trajectories prediction with inverse reinforcement learning",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "5",
        "cover_date": "2020-09-02",
        "Abstract": "One of the primary goals of Artificial Intelligence research is to develop machines with human-like intelligence, perception and reasoning. In this direction teaching apprentice agents by observing demonstrations delivered by experts is a framework of imitation learning that can provide improved solutions and it is possible to significantly outperform the demonstrator. Inverse reinforcement learning (IRL) is a paradigm relying on Markov Decision Processes (MDPs) that has a twofold target: to learn optimum policies of autonomous agents for solving complex tasks from successful demonstrations, and also to discover the unknown reward function that could explain the expert behavior. In this article we are addressing the trajectory prediction problem in the aviation domain by using an IRL approach. The proposed learning scheme provides an imitation process where the algorithm tries to imitate demonstrated trajectories, exploiting raw trajectory data enriched with contextual features and learn an efficient reward model that is learned during imitation and has generalization capabilities to unknown cases. We show several experimental results using real trajectory data from the Spanish FIR that confirms the effectiveness of our approach in automatically predicting trajectories.",
        "DOI": "10.1145/3411408.3411427",
        "paper_author": "Spatharis C.",
        "affiliation_name": "University of Ioannina",
        "affiliation_city": "Ioannina",
        "affiliation_country": "Greece",
        "affiliation_id": "60004716",
        "affiliation_state": "Epirus"
    },
    {
        "paper_title": "Europe’s war against covid-19: A map of countries’ disease vulnerability using mortality indicators",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "11",
        "cover_date": "2020-09-02",
        "Abstract": "Specific and older age-associated comorbidities increase mortality risk in severe forms of coronavirus disease (COVID-19). We matched COVID-19 comorbidities with causes of death in 28 EU countries for the total population and for the population above 65 years and applied a machine-learning-based tree clustering algorithm on shares of death for COVID-19 comorbidities and for influenza and on their growth rates between 2011 and 2016. We distributed EU countries in clusters and drew a map of the EU populations’ vulnerabilities to COVID-19 comorbidities and to influenza. Noncommunicable diseases had impressive shares of death in the EU but with substantial differences between eastern and western countries. The tree clustering algorithm accurately indicated the presence of western and eastern country clusters, with significantly different patterns of disease shares of death and growth rates. Western populations displayed higher vulnerability to malignancy, blood-related diseases, and diabetes mellitus and lower respiratory diseases, while eastern countries’ populations suffered more from ischaemic heart, cerebrovascular, and circulatory diseases. Dissimilarities between EU countries were also present when influenza was considered. The heat maps of EU populations’ vulnerability to diseases based on mortality indicators constitute the basis for more targeted health policy strategies in a collaborative effort at the EU level.",
        "DOI": "10.3390/ijerph17186565",
        "paper_author": "Horobet A.",
        "affiliation_name": "Bucharest University of Economic Studies",
        "affiliation_city": "Bucharest",
        "affiliation_country": "Romania",
        "affiliation_id": "60107810",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Survey Opinion using Sentiment Analysis",
        "publication": "Journal of Applied Data Sciences",
        "citied_by": "7",
        "cover_date": "2020-09-01",
        "Abstract": "Sentiment analysis or opinion mining is a computational study of the opinions, judgments, attitudes, and emotions of a person towards an entity, individual, issue, event, topic, and attributes. This task is very challenging technically but very useful in practice. For example, a business always wants to seek opinion about its products and services from the public or the consumers. Additionally, potential consumers want to learn what users think they have when using a service or purchasing a product. To get public opinion on food habits, ad strategies, political trends, social issues and business policy, this is a very critical factor. This paper will explain a survey of key sentiment-extraction approaches.",
        "DOI": "10.47738/jads.v1i1.10",
        "paper_author": "Hariguna T.",
        "affiliation_name": "Universitas Amikom Purwokerto",
        "affiliation_city": "Purwokerto",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60109777",
        "affiliation_state": "Central Java"
    },
    {
        "paper_title": "How can customs better leverage emerging ai technologies for more sustainable and smarter operations?",
        "publication": "World Customs Journal",
        "citied_by": "3",
        "cover_date": "2020-09-01",
        "Abstract": "Technological innovation is happening at a faster pace than ever before, creating new opportunities as well as challenges for many industries. This research paper aims to contribute to the efforts deployed by many customs administrations to leverage artificial intelligence (AI)–driven technologies in order to support smarter operations and efficiency. It makes recommendations to identify the organisational processes that could benefit from AI and machine learning (ML)–based initiatives. The result of this paper is a set of practical frameworks coupled with technical, organisational and policy recommendations, which form a coherent business innovation kit to assist customs administrations to successfully start or scale their digital transformation journey.1.",
        "DOI": "10.55596/001c.116424",
        "paper_author": "Kafando I.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting the growth and trend of COVID-19 pandemic using machine learning and cloud computing",
        "publication": "Internet of Things (Netherlands)",
        "citied_by": "377",
        "cover_date": "2020-09-01",
        "Abstract": "The outbreak of COVID-19 Coronavirus, namely SARS-CoV-2, has created a calamitous situation throughout the world. The cumulative incidence of COVID-19 is rapidly increasing day by day. Machine Learning (ML) and Cloud Computing can be deployed very effectively to track the disease, predict growth of the epidemic and design strategies and policies to manage its spread. This study applies an improved mathematical model to analyse and predict the growth of the epidemic. An ML-based improved model has been applied to predict the potential threat of COVID-19 in countries worldwide. We show that using iterative weighting for fitting Generalized Inverse Weibull distribution, a better fit can be obtained to develop a prediction framework. This has been deployed on a cloud computing platform for more accurate and real-time prediction of the growth behavior of the epidemic. A data driven approach with higher accuracy as here can be very useful for a proactive response from the government and citizens. Finally, we propose a set of research opportunities and setup grounds for further practical applications.",
        "DOI": "10.1016/j.iot.2020.100222",
        "paper_author": "Tuli S.",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60032730",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Two become one: Improving the targeting of conditional cash transfers with a predictive model of school dropout",
        "publication": "Economia",
        "citied_by": "0",
        "cover_date": "2020-09-01",
        "Abstract": "This paper offers a methodology to improve targeting design and assessment when two or more groups need to be considered, and trade-offs exist between using different targeting mechanisms. The paper builds from the multidimensional targeting challenge facing conditional cash transfers (CCTs). I analyze whether a common CCT targeting mechanism, namely, a proxy means test (PMT), can identify the poor and future school dropouts effectively. Despite both being key target groups for CCTs, students at risk of dropping out are rarely considered for CCT allocation or in targeting assessments. Using rich administrative data sets from Chile to simulate different targeting mechanisms, I compare the targeting effectiveness of a PMT and other mechanisms based on a predictive model of school dropout. I build this model using machine learning algorithms. Using two novel metrics, I show that combining the outputs of the predictive model with the PMT increases targeting effectiveness except when the social valuation of the poor and future school dropouts differs to a large extent. More generally, public officials who value their key target groups equally may improve policy targeting by modifying their allocation procedures.",
        "DOI": "10.1353/eco.2020.0011",
        "paper_author": "Crespo C.",
        "affiliation_name": "London School of Economics and Political Science",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60003059",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Integration of remote sensing, county-level census, and machine learning for century-long regional cropland distribution data reconstruction",
        "publication": "International Journal of Applied Earth Observation and Geoinformation",
        "citied_by": "13",
        "cover_date": "2020-09-01",
        "Abstract": "The Lower Mississippi Alluvial Valley (LMAV) was home to about ten million hectare bottomland hardwood (BLH) forests in the Southern U.S. It experienced over 80 % area loss of the BLH forests in the past centuries and large-scale afforestation in recent decades. Due to the lack of a high-resolution cropland dataset, impacts of land use change (LUC) on the LMAV ecosystem services have not been fully understood. In this study, we developed a novel framework by integrating the machine learning algorithm, county-level agricultural census, and satellite-based cropland products to reconstruct the LMAV cropland distribution during 1850–2018 at a 30-m resolution. Results showed that the LMAV cropland area increased from 0.78 × 104 km2 in 1850 to 6.64 × 104 km2 in 1980 and then decreased to 6.16 × 104 km2 in 2018. Cropland expansion rate was the largest in the 1960s (749 km2 yr−1) but decreased rapidly thereafter, whereas cropland abandonment rate increased substantially in recent decades with the largest rate of 514 km2 yr−1 in the 2010s. Our dataset has three notable features: (1) the depiction of fine spatial details, (2) the integration of the county-level census, and (3) the inclusion of a machine-learning algorithm trained by satellite-based land cover product. Most importantly, our dataset well captured the continuous increasing trend in cropland area from 1930–1960, which was misrepresented by other cropland datasets reconstructed from the state-level census. Our dataset would be important to accurately evaluate the impacts of historical deforestation and recent afforestation efforts on regional ecosystem services, attribute the observed hydrological changes to anthropogenic and natural driving factors, and investigate how the socioeconomic factors control regional LUC pattern. Our framework and dataset are crucial to developing managerial and policy strategies for conserving natural resources and enhancing ecosystem services in the LMAV.",
        "DOI": "10.1016/j.jag.2020.102151",
        "paper_author": "Yang J.",
        "affiliation_name": "College of Forest Resources",
        "affiliation_city": "Mississippi State",
        "affiliation_country": "United States",
        "affiliation_id": "60141090",
        "affiliation_state": "MS"
    },
    {
        "paper_title": "Science map of cochrane systematic reviews receiving the most altmetric attention score: A network analysis",
        "publication": "Journal of Scientometric Research",
        "citied_by": "1",
        "cover_date": "2020-09-01",
        "Abstract": "The present study aimed to analyze and visualize the science map of Cochrane systematic reviews (CSRs) with high Altmetric attention score (AAS). On 2020-07-29, the altmetric data of the Cochrane Database of Systematic Reviews were obtained from the Altmetric database (Altmetric LLP, London, UK). Bibliometric data of the top 5% AAS of CSRs were extracted from the Web of Science. Keyword co-occurrence, co-authorship and co-citation network analyses were then employed using VOSviewer software. The random forest model was used to rank the importance of the altmetric resource. A total of 11222 CSRs with AAS were found (Total mentions: 305265), with Twitter being the most popular Altmetric resource. Consequently, the top 5% AAS (649 articles, mean AAS: 204.95, 95% confidence level: 18.95, mean citations: 123.68, 95% confidence level: 13.9) were included. Density mapping revealed female, adult and child as the most popular author keywords. According to network visualization, Helen V. Worthington (University of Manchester, Manchester, UK), the University of Oxford and UK had the greatest impact on the network at the author, organization and country levels respectively. AAS were weekly correlated with citations (rs=0.21) although citations were moderately correlated with policy document and blog mentions (rs=0.46 and rs=0.43). Cochrane systematic reviews received high levels of online attention, particularly in the Twittersphere and mostly from the UK. However, CSRs were rarely publicized and discussed using recently developed academic tools, such as F1000 prime, Publons and PubPeer.",
        "DOI": "10.5530/JSCIRES.9.3.36",
        "paper_author": "Kolahi J.",
        "affiliation_name": "Founder and Associate Editor of Dental Hypotheses",
        "affiliation_city": "Isfahan",
        "affiliation_country": "Iran",
        "affiliation_id": "125720901",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning Mobility Flows from Urban Features with Spatial Interaction Models and Neural Networks**To appear in the Proceedings of 2020 IEEE International Conference on Smart Computing (SMARTCOMP 2020)",
        "publication": "Proceedings - 2020 IEEE International Conference on Smart Computing, SMARTCOMP 2020",
        "citied_by": "9",
        "cover_date": "2020-09-01",
        "Abstract": "A fundamental problem of interest to policy makers, urban planners, and other stakeholders involved in urban development is assessing the impact of planning and construction activities on mobility flows. This is a challenging task due to the different spatial, temporal, social, and economic factors influencing urban mobility flows. These flows, along with the influencing factors, can be modelled as attributed graphs with both node and edge features characterising locations in a city and the various types of relationships between them. In this paper, we address the problem of assessing origin-destination (OD) car flows between a location of interest and every other location in a city, given their features and the structural characteristics of the graph. We propose three neural network architectures, including graph neural networks (GNN), and conduct a systematic comparison between the proposed methods and state-of-the-art spatial interaction models, their modifications, and machine learning approaches. The objective of the paper is to address the practical problem of estimating potential flow between an urban project location and other locations in the city, where the features of the project location are known in advance. We evaluate the performance of the models on a regression task using a custom data set of attributed car OD flows in London. We also visualise the model performance by showing the spatial distribution of flow residuals across London.",
        "DOI": "10.1109/SMARTCOMP50058.2020.00028",
        "paper_author": "Yeghikyan G.",
        "affiliation_name": "Scuola Normale Superiore di Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60030674",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "AFDM: An Analytical Framework of Dialogue Manager",
        "publication": "8th Iranian Joint Congress on Fuzzy and Intelligent Systems, CFIS 2020",
        "citied_by": "0",
        "cover_date": "2020-09-01",
        "Abstract": "A computer system which provides the possibility of human-like conversation with the system for users, is called dialogue system. A dialogue system consists of different components. Dialogue manager is the core component of every dialogue system composed of Dialog State Tracker and Policy Learning. A dialogue management system is able to direct a conversation between agents, including both human and computer. A variety of models have been developed for dialogue manager. This paper provides an Analytical Framework for Dialogue Managers (AFDM) which overview wide range of techniques applied for developing dialogue manager component. AFDM framework works in three parts including: 1) a classification of current approaches applied to dialogue management task, 2) introducing the evaluation measures and 3) analytical evaluations. Also, we discuss the main qualitative properties of each approach. This framework is designed in order to pave the way for future research with the aim of a) improving current models, b) selecting a method based on its properties, or c) comparing future strategies.",
        "DOI": "10.1109/CFIS49607.2020.9238732",
        "paper_author": "Keyvanpour M.R.",
        "affiliation_name": "Alzahra University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60008542",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Towards Improved Network Security Requirements and Policy: Domain-Specific Completeness Analysis via Topic Modeling",
        "publication": "Proceedings - 7th International Workshop on Artificial Intelligence and Requirements Engineering, AIRE 2020",
        "citied_by": "0",
        "cover_date": "2020-09-01",
        "Abstract": "Network security policies contain requirements-including system and software features as well as expected and desired actions of human actors. In this paper, we present a framework for evaluation of textual network security policies as requirements documents to identify areas for improvement. Specifically, our framework concentrates on completeness. We use topic modeling coupled with expert evaluation to learn the complete list of important topics that should be addressed in a network security policy. Using these topics as a checklist, we evaluate (students) a collection of network security policies for completeness, i.e., the level of presence of these topics in the text. We developed three methods for topic recognition to identify missing or poorly addressed topics. We examine network security policies and report the results of our analysis: preliminary success of our approach.",
        "DOI": "10.1109/AIRE51212.2020.00019",
        "paper_author": "Huffman Hayes J.",
        "affiliation_name": "Stanley and Karen Pigman College of Engineering",
        "affiliation_city": "Lexington",
        "affiliation_country": "United States",
        "affiliation_id": "60025173",
        "affiliation_state": "KY"
    },
    {
        "paper_title": "An Analysis of the Italian Lockdown in Retrospective Using Particle Swarm Optimization in Machine Learning Applied to an Epidemiological Model",
        "publication": "Physics (Switzerland)",
        "citied_by": "7",
        "cover_date": "2020-09-01",
        "Abstract": "A critical analysis of the open data provided by the Italian Civil Protection Centre during phase 1 of Covid-19 epidemic—the so-called Italian lockdown—is herein proposed in relation to four of the most affected Italian regions, namely Lombardy, Reggio Emilia, Valle d’Aosta, and Veneto. A possible bias in the data induced by the extent in the use of medical swabs is found in relation to Valle d’Aosta and Veneto. Observed data are then interpreted using a Susceptible-Infectious-Recovered (SIR) epidemiological model enhanced with asymptomatic (infected and recovered) compartments, including lockdown effects through time-dependent model parameters. The initial number of susceptible individuals for each region is also considered as a parameter to be identified. The issue of parameters identification is herein addressed by a robust machine learning approach based on particle swarm optimization. Model predictions provide relevant information for policymakers in terms of the effect of lockdown measures in the different regions. The number of susceptible individuals involved in the epidemic, important for a safe release of lockdown during the next phases, is predicted to be around 10% of the population for Lombardy, 16% for Reggio Emilia, 18% for Veneto, and 40% for Valle d’Aosta.",
        "DOI": "10.3390/physics2030020",
        "paper_author": "Paggi M.",
        "affiliation_name": "Scuola IMT Alti Studi Lucca",
        "affiliation_city": "Lucca",
        "affiliation_country": "Italy",
        "affiliation_id": "60102060",
        "affiliation_state": "LU"
    },
    {
        "paper_title": "Short-Term Load Forecasting by Machine Learning",
        "publication": "2020 International Symposium on Community-Centric Systems, CcS 2020",
        "citied_by": "2",
        "cover_date": "2020-09-01",
        "Abstract": "In the global energy transition, Taiwan government has legislated the law to require large-scale power consumers with the obligation to partially use renewable energy. Many companies choose to follow the regulation by purchasing green energy. To purchase the energy effectively, it is necessary to understand its own electricity consumption. In this paper, electricity load forecasting models are studied and compared. The impact of the holiday adjustment policy of Taiwan on the forecasting is investigated. Experimental results demonstrated that the recent, deep-learning technique LSTM achieved the best performance. On the 9-month test data, MAPE of the LSTM was 1.85%.",
        "DOI": "10.1109/CcS49175.2020.9231499",
        "paper_author": "Hsu C.C.",
        "affiliation_name": "National Yunlin University of Science and Technology",
        "affiliation_city": "Douliou",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60014261",
        "affiliation_state": "Yunlin"
    },
    {
        "paper_title": "Bandit-based relay selection in cooperative networks over unknown stationary channels",
        "publication": "IEEE International Workshop on Machine Learning for Signal Processing, MLSP",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "In recent years, wireless node density has increased rapidly, as more base stations, users, and machines coexist. Exploiting this node density, cooperative relaying has been deployed to improve connectivity throughout the network. Such a configuration, however, often demands relay scheduling, which comes with increased channel estimation and signaling overheads. To reduce these overheads, in this paper, we propose low-complexity relay scheduling mechanisms with the aid of a multi-armed bandit (MAB) framework. More specifically, this MAB framework is used for relay scheduling, based only on observing the acknowledgements/negative-acknow-ledgements (ACK/NACK) of packet transmissions. Hence, a bandit-based opportunistic relay selection (BB - ORS) mechanism is developed, recovering eventually the performance of classical opportunistic relay selection (0RS) when channel state information (CSI) is available without requiring any CSI. In addition, a distributed implementation of BB - ORS is presented, herein called d - BB - ORS, where distributed timers are used at the relays for relay selection, thus reducing the signaling overhead significantly. BB - ORS is compared to optimal scheduling with full CSI and the negligible performance gap is compensated by the low-complexity low-overhead implementation, while it surpasses the performance of ORS with outdated CSI.",
        "DOI": "10.1109/MLSP49062.2020.9231604",
        "paper_author": "Nomikos N.",
        "affiliation_name": "University of the Aegean",
        "affiliation_city": "Mytilene",
        "affiliation_country": "Greece",
        "affiliation_id": "60017404",
        "affiliation_state": "North Aegean"
    },
    {
        "paper_title": "Emerging scientific field detection using citation networks and topic models—a case study of the nanocarbon field",
        "publication": "Applied System Innovation",
        "citied_by": "15",
        "cover_date": "2020-09-01",
        "Abstract": "In fields with high science linkage, such as the nanocarbon field, trends in academic papers are particularly important for identifying future technological trends. The use of the number of citations allows us to predict the qualitative trends on a paper-by-paper basis. At the same time, it is necessary to be able to comprehensively discuss both qualitative and quantitative aspects in the subject area. This study aimed to detect emerging areas in the nanocarbon field using network models and topic models. It was possible to not only construct a model that exceeded an 86.2% F1 measure but also to focus on an area that could not be detected by the prediction model. This was accomplished by focusing on paper units, such as the research on the chemical synthesis of zigzag single-walled carbon nanotubes. Thus, it is possible to obtain knowledge that contributes to diversified R&D strategies and innovation policies by considering the emergence of new fields from multiple perspectives.",
        "DOI": "10.3390/asi3030040",
        "paper_author": "Sasaki H.",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60025272",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Trust-region variational inference with gaussian mixture models",
        "publication": "Journal of Machine Learning Research",
        "citied_by": "7",
        "cover_date": "2020-09-01",
        "Abstract": "Many methods for machine learning rely on approximate inference from intractable probability distributions. Variational inference approximates such distributions by tractable models that can be subsequently used for approximate inference. Learning sufficiently accurate approximations requires a rich model family and careful exploration of the relevant modes of the target distribution. We propose a method for learning accurate GMM approximations of intractable probability distributions based on insights from policy search by using information-geometric trust regions for principled exploration. For efficient improvement of the GMM approximation, we derive a lower bound on the corresponding optimization objective enabling us to update the components independently. Our use of the lower bound ensures convergence to a stationary point of the original objective. The number of components is adapted online by adding new components in promising regions and by deleting components with negligible weight. We demonstrate on several domains that we can learn approximations of complex, multimodal distributions with a quality that is unmet by previous variational inference methods, and that the GMM approximation can be used for drawing samples that are on par with samples created by state-of-theart MCMC samplers while requiring up to three orders of magnitude less computational resources.",
        "DOI": "NA",
        "paper_author": "Arenz O.",
        "affiliation_name": "Technische Universität Darmstadt",
        "affiliation_city": "Darmstadt",
        "affiliation_country": "Germany",
        "affiliation_id": "60011226",
        "affiliation_state": "Hessen"
    },
    {
        "paper_title": "Sentiment analysis techniques to analyze hse situational awareness at oil and gas platforms using machine learning",
        "publication": "Indian Journal of Computer Science and Engineering",
        "citied_by": "3",
        "cover_date": "2020-09-01",
        "Abstract": "Health Safety & Environment (HSE) situational awareness is a very important aspect of any risky workplace. Negligence in complying with HSE policies and practices might lead to unwanted incidents, critical injuries, death, spread of diseases and environmental pollution. In most corporations, information on HSE related incidents is disseminated through formal channels such as reports. Employees on the other hand frequently use social media to share, complain and discuss HSE-related issues. The issues are discussed through an informal platform, it is difficult to analyze opinions for further action. Therefore, this study will investigate existing sentiment analysis models and formulate a suitable sentiment analysis model using machine learning technique. Through literature review, Naïve Bayes model was found to be the most efficient text classification in sentiment analysis. This technique still needs further enhancement as the accuracy is not within requirement. Upon enhancing the Naïve Bayes model, a better outcome can be attained.",
        "DOI": "10.21817/indjcse/2020/v11i5/201105244",
        "paper_author": "Dafaallah D.E.",
        "affiliation_name": "Universiti Teknologi PETRONAS",
        "affiliation_city": "Seri Iskandar",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60001278",
        "affiliation_state": "Perak"
    },
    {
        "paper_title": "Machine Learning Approach to Analyze Classification Result for Twitter Sentiment",
        "publication": "Proceedings - International Conference on Smart Electronics and Communication, ICOSEC 2020",
        "citied_by": "9",
        "cover_date": "2020-09-01",
        "Abstract": "Monitoring of social media has been growing day by day and analyzing social data helps in identifying behavior of people. News and media play a biased role in conveying a particular incident or policies. Thus the analysis of social media data such as twitter comments uses sentiment analysis that examines the opinion of people on certain government policy declared by the central government. In this paper, twitter sentiment analysis using SVM and NN has been proposed that analyzing the twitter dataset of particular policies and finding its polarity of sentiment. With a quick increase in the use of the Internet, people can raise out their opinion on social media about a particular topic. This work compares the accuracy between the two classification algorithms namely Back Propagation Neural Network (BPNN) and Support Vector Machine (SVM). These two algorithms are supervised algorithms, which mean that the model trains itself with the use of a training dataset and performs testing with the help of the testing dataset. This work proposes the ANN and SVM classification algorithm which is used to classify the emotion behind the text, which can achieve acceptable accuracy in classifying results. It is trained over five hundred epochs. The resulting confusion matrix is obtained by comparing predicted with actual labels. Experiments demonstrate that Support Vector Machine outperforms the accuracy when compared with BPNN..",
        "DOI": "10.1109/ICOSEC49089.2020.9215278",
        "paper_author": "Kalaivani P.",
        "affiliation_name": "St. Joseph's College of Engineering",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60100946",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Intrusion Detection System using Machine Learning Techniques: A Review",
        "publication": "Proceedings - International Conference on Smart Electronics and Communication, ICOSEC 2020",
        "citied_by": "61",
        "cover_date": "2020-09-01",
        "Abstract": "The rapid growth in the use of computer networks results in the issues of maintaining the network availability, integrity, and confidentiality. This necessitates the network administrators to adopt various types of intrusion detection systems (IDS) that help in monitoring the network traffics for unauthorized and malicious activities. Intrusion is the breach of security policy with malicious intent. Therefore, intrusion detection system monitors traffic flowing on a network through computer systems to search for malicious activities and known threats, sending up alerts when it finds those threats. The detection of malicious activities is of two types, the misuse or signature-based detection in which the IDS collects information, analyzes it and then compares it to the attack signatures stored in a large database. The second detection is the anomaly detection which assumes malicious activity as any action that deviates from normal behavior. The proposed paper presents an overview of various works being done on building an efficient IDS using single, hybrid and ensemble machine learning (ML) classifiers, evaluated using seven different datasets. The results obtained by various works were discussed and compared which gives a clear path and guide for future work..",
        "DOI": "10.1109/ICOSEC49089.2020.9215333",
        "paper_author": "Musa U.S.",
        "affiliation_name": "Sharda University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India",
        "affiliation_id": "60108680",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Impact of Prediction Errors on High Throughput Predictive Resource Allocation",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "8",
        "cover_date": "2020-09-01",
        "Abstract": "Predictive resource allocation (PRA) can leverage machine learning and historical data to boost the performance of mobile networks, say to support high throughput or improve the quality of service. While the large gain of PRA has been demonstrated by assuming perfect prediction or by optimizing with modeled prediction errors, how the prediction errors translate to the performance loss of PRA and how the future information should be predicted are not well understood. In this paper, we consider high throughput PRA policy for non-real-time (NRT) mobile users when the base stations also serve real-time (RT) users, where the future average rates of NRT users in a prediction window need to be predicted. The average rate can be predicted in various ways, where one typical way is to predict the rate directly from the historical average rates and another typical way is to predict the rate indirectly by first predicting traffic load and user trajectory. Given that the traffic load and user location can be gathered easily in cellular networks, we consider such an indirect prediction and analyze the impact of prediction errors of traffic load and trajectory on the prediction errors of average data rate. To this end, we first find the relation between the RT traffic load and the residual bandwidth after serving the RT users by resorting to effective capacity and effective bandwidth theory. To further justify why we analyze the indirect prediction, we compare the predictability of the time series used for the typical direct prediction and indirect prediction with entropy theory. Since different machine learning techniques lead to different prediction bias and prediction error variance, we then derive the relation between the prediction error statistics of the average data rate and those of traffic load and trajectory. We evaluate the performance loss of PRA using both modeled prediction errors and real predictions with deep learning. Our analyses show that for a network busy with RT service, the prediction errors of RT traffic load have larger impact on those of average data rate than the prediction errors of trajectory. The prediction bias has a larger impact on the throughput loss of PRA than the prediction error variance. This provides a guidance of designing learning techniques for predicting the required information.",
        "DOI": "10.1109/TVT.2020.3004552",
        "paper_author": "Guo J.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013789",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An analysis of the rising concerns of an insider threat for sustainable it development",
        "publication": "Journal of Green Engineering",
        "citied_by": "0",
        "cover_date": "2020-09-01",
        "Abstract": "Insider threats are occurring across all the organizations and it is causing a great damage to the business.Some of the threats like stealing confidential data or secrets related to business activities.Insider threat can happen when any employ misuse the access and also due to negligence that means he is leaving the system without locking.It also occurs because of the personal benefits of the employs and also competition between the different organization.Insider threats can be stopped by implementing programs related to insider threats and also some strategies for preventing threats.In Insider threat program every employ must participate and they should get awareness regarding the privacy at work.We can also prevent them by having policies,procedures,security controls etc.In this paper,we discussed all the existing machine learning algorithms used for Insider threat detection.We also discussed on tools,products used for Insider threat detection.",
        "DOI": "NA",
        "paper_author": "Sashi Kumar M.S.V.",
        "affiliation_name": "Vasavi College of Engineering",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India",
        "affiliation_id": "60099690",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "A Joint Decentralized Federated Learning and Communications Framework for Industrial Networks",
        "publication": "IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks, CAMAD",
        "citied_by": "14",
        "cover_date": "2020-09-01",
        "Abstract": "Industrial wireless networks are pushing towards distributed architectures moving beyond traditional server-client transactions. Paired with this trend, new synergies are emerging among sensing, communications and Machine Learning (ML) co-design, where resources need to be distributed across different wireless field devices, acting as both data producers and learners. Considering this landscape, Federated Learning (FL) solutions are suitable for training a ML model in distributed systems. In particular, decentralized FL policies target scenarios where learning operations must be implemented collaboratively, without relying on the server, and by exchanging model parameters updates rather than training data over capacity-constrained radio links. This paper proposes a real-time framework for the analysis of decentralized FL systems running on top of industrial wireless networks rooted in the popular Time Slotted Channel Hopping (TSCH) radio interface of the IEEE 802.15.4e standard. The proposed framework is suitable for neural networks trained via distributed Stochastic Gradient Descent (SGD), it quantifies the effects of model pruning, sparsification and quantization, as well as physical and link layer constraints, on FL convergence time and learning loss. The goal is to set the fundamentals for comprehensive methods and procedures supporting decentralized FL pre-deployment design. The proposed tool can be thus used to optimize the deployment of the wireless network and the ML model before its actual installation. It has been verified based on real data targeting smart robotic-assisted manufacturing.",
        "DOI": "10.1109/CAMAD50429.2020.9209305",
        "paper_author": "Savazzi S.",
        "affiliation_name": "Consiglio Nazionale delle Ricerche",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60021199",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Modified Machine Learning Techique for Curve Fitting on Regression Models for COVID-19 projections",
        "publication": "IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks, CAMAD",
        "citied_by": "33",
        "cover_date": "2020-09-01",
        "Abstract": "COrona VIrus Disease 2019 (COVID-19) is a disease caused by Severe Acute Respiratory Syndrome Corona Virus 2 (SARS-CoV-2) and was first diagnosed in China in December, 2019. Dr. Tedros Adhanom Ghebreyesus, World Health Organization (WHO) director-general on March 11th declared the COVID-19 pandemic. The cumulative cases of infected individuals and deaths due to COVID-19 develop a graph that could be interpreted by an exponential function. Mathematical models are therefore fundamental to understanding the evolution of the pandemic. Applying machine learning prediction methods in conjunction with cloud computing to such models will be beneficial in designing effective control strategies for the current or future spread of infectious diseases. Initially, we compare the trendlines of the following three models: linear, exponential and polynomial using R-squared, to determine which model best interprets the prevailing data sets of cumulative infectious cases and cumulative deaths due to COVID-19 disease. We propose the development of an improved mathematical forecasting framework based on machine learning and the cloud computing system with data from a real-time cloud data repository. Our goal is to predict the progress of the curve as accurately as possible in order to understand the spread of the virus from an early stage so that strategies and policies can be implemented.",
        "DOI": "10.1109/CAMAD50429.2020.9209264",
        "paper_author": "Andreas A.",
        "affiliation_name": "University of Nicosia",
        "affiliation_city": "Nicosia",
        "affiliation_country": "Cyprus",
        "affiliation_id": "60104028",
        "affiliation_state": "Nicosia"
    },
    {
        "paper_title": "State Complexity Reduction in Reinforcement Learning based Adaptive Traffic Signal Control",
        "publication": "Proceedings Elmar - International Symposium Electronics in Marine",
        "citied_by": "13",
        "cover_date": "2020-09-01",
        "Abstract": "The throughput of a signalized intersection can be increased by appropriate adjustment of the signal program using Adaptive Traffic Signal Control (ATSC). One possible approach is to use Reinforcement Learning (RL). It enables model-free learning of the control law for the reduction of the negative impacts of traffic congestion. RL based ATSC achieves good results but requires many learning iterations to train optimal control policy due to high state-Action complexity. In this paper, a novel approach for state complexity reduction in RL by using Self-Organizing Maps (SOM) is presented. With SOM, the convergence rate of RL and system stability in the later stages of learning is increased. The proposed approach is evaluated against the traditional RL approach that uses Q-Learning on a simulated isolated intersection calibrated according to realistic traffic data. Presented simulation results prove the effectiveness of the proposed approach regarding learning stability and traffic measures of effectiveness.",
        "DOI": "10.1109/ELMAR49956.2020.9219024",
        "paper_author": "Miletic M.",
        "affiliation_name": "University of Zagreb, Faculty of Transport and Traffic Sciences",
        "affiliation_city": "Zagreb",
        "affiliation_country": "Croatia",
        "affiliation_id": "60159856",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mitigation of privacy threats due to encrypted traffic analysis through a policy-based framework and MUD profiles",
        "publication": "Symmetry",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "It has been proven in research literature that the analysis of encrypted traffic with statistical analysis and machine learning can reveal the type of activities performed by a user accessing the network, thus leading to privacy risks. In particular, different types of traffic (e.g., skype, web access) can be identified by extracting time based features and using them in a classifier. Such privacy attacks are asymmetric because a limited amount of resources (e.g., machine learning algorithms) can extract information from encrypted traffic generated by cryptographic systems implemented with a significant amount of resources. To mitigate privacy risks, studies in research literature have proposed a number of techniques, but in most cases only a single technique is applied, which can lead to limited effectiveness. This paper proposes a mitigation approach for privacy risks related to the analysis of encrypted traffic which is based on the integration of three main components: (1) A machine learning component which proactively analyzes the encrypted traffic in the network to identify potential privacy threats and evaluate the effectiveness of various mitigation techniques (e.g., obfuscation), (2) a policy based component where policies are used to enforce privacy mitigation solutions in the network and (3) a network node profile component based on the Manufacturer Usage Description (MUD) standard to enable changes in the network nodes in the cases where the first two components are not effective in mitigating the privacy risks. This paper describes the different components and how they interact in a potential deployment scenario. The approach is evaluated on the public dataset ISCXVPN2016 and the results show that the privacy threat can be mitigated significantly by removing completely the identification of specific types of traffic or by decreasing the probability of their identification as in the case of VOIP by 50%, Chat by 40% and Browsing by 33%, thus reducing significantly the privacy risk.",
        "DOI": "10.3390/SYM12091576",
        "paper_author": "Baldini G.",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "60103695",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ambulance emergency response optimization in developing countries",
        "publication": "Operations Research",
        "citied_by": "52",
        "cover_date": "2020-09-01",
        "Abstract": "The lack of emergency medical transportation is viewed as the main barrier to the access and availability of emergency medical care in low- and middle-income countries (LMICs). In this paper, we present a robust optimization approach to optimize both the location and routing of emergency response vehicles, accounting for uncertainty in travel times and spatial demand characteristic of LMICs. We traveled to Dhaka, Bangladesh, the sixth largest and third most densely populated city in the world, to conduct field research resulting in the collection of two unique data sets that inform our approach. These data are leveraged to estimate demand for emergency medical services in an LMIC setting and to predict the travel time between any two locations in the road network for different times of day and days of the week. We combine our prediction-optimization framework with a simulation model and real data to provide an in-depth investigation into three policy-related questions. First, we demonstrate that outpost locations optimized for weekday rush hour lead to good performance for all times of day and days of the week. Second, we find that the performance of the current system could be replicated using one third of the current outpost locations and one half of the current number of ambulances. Finally, we show that a fleet of small ambulances has the potential to significantly outperform traditional ambulance vans. In particular, they are able to capture approximately three times more demand while reducing the median average response time by roughly 10%–18% over the entire week and 24%–35% during rush hour because of increased routing flexibility offered by more nimble vehicles on a larger road network. Our results provide practical insights for emergency response optimization that can be leveraged by hospital-based and private ambulance providers in Dhaka and other urban centers in developing countries.",
        "DOI": "10.1287/opre.2019.1969",
        "paper_author": "Boutilier J.J.",
        "affiliation_name": "UW-Madison College of Engineering",
        "affiliation_city": "Madison",
        "affiliation_country": "United States",
        "affiliation_id": "60153131",
        "affiliation_state": "WI"
    },
    {
        "paper_title": "Evidence-based mapping of the wildland-urban interface to better identify human communities threatened by wildfires",
        "publication": "Environmental Research Letters",
        "citied_by": "41",
        "cover_date": "2020-09-01",
        "Abstract": "The wildland-urban interface (WUI) is the spatial manifestation of human communities coupled with vegetated ecosystems. Spatial delineation of the WUI is important for wildfire policy and management, but is typically defined according to spatial relationships between housing development and wildland vegetation without explicit consideration of fire risk. A fire risk-based definition of WUI can enable a better distribution of management investment so as to maximize social return. We present a novel methodological approach to delineate the WUI based on a fire risk assessment. The approach establishes a geographical framework to model fire risk via machine learning and generate multi-scale, variable-specific spatial thresholds for translating fire probabilities into mapped output. To determine whether fire-based WUI mapping better captures the spatial congruence of houses and wildfires than conventional methods, we compared national and subnational fire-based WUI maps for Chile to WUI maps generated only with housing and vegetation thresholds. The two mapping approaches exhibited broadly similar spatial patterns, the WUI definitions covering almost the same area and containing similar proportions of the housing units in the area under study (17.1% vs. 17.9%), but the fire-based WUI accounted for 13.8% more spatial congruence of fires and people (47.1% vs. 33.2% of ignitions). Substantial regional variability was found in fire risk drivers and the corresponding spatial mapping thresholds, suggesting there are benefits to developing different WUI maps for different scales of application. We conclude that a dynamic, multi-scale, fire-based WUI mapping approach should provide more targeted and effective support for decision making than conventional approaches.",
        "DOI": "10.1088/1748-9326/ab9be5",
        "paper_author": "Miranda A.",
        "affiliation_name": "Universidad de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile",
        "affiliation_id": "60012464",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Detection of non-technical losses in power utilities—A comprehensive systematic review",
        "publication": "Energies",
        "citied_by": "43",
        "cover_date": "2020-09-01",
        "Abstract": "Electricity theft and fraud in energy consumption are two of the major issues for power distribution companies (PDCs) for many years. PDCs around the world are trying different methodologies for detecting electricity theft. The traditional methods for non-technical losses (NTLs) detection such as onsite inspection and reward and penalty policy have lost their place in the modern era because of their ineffective and time-consuming mechanism. With the advancement in the field of Artificial Intelligence (AI), newer and efficient NTL detection methods have been proposed by different researchers working in the field of data mining and AI. The AI-based NTL detection methods are superior to the conventional methods in terms of accuracy, efficiency, time-consumption, precision, and labor required. The importance of such AI-based NTL detection methods can be judged by looking at the growing trend toward the increasing number of research articles on this important development. However, the authors felt the lack of a comprehensive study that can provide a one-stop source of information on these AI-based NTL methods and hence became the motivation for carrying out this comprehensive review on this significant field of science. This article systematically reviews and classifies the methods explored for NTL detection in recent literature, along with their benefits and limitations. For accomplishing the mentioned objective, the opted research articles for the review are classified based on algorithms used, features extracted, and metrics used for evaluation. Furthermore, a summary of different types of algorithms used for NTL detection is provided along with their applications in the studied field of research. Lastly, a comparison among the major NTL categories, i.e., data-based, network-based, and hybrid methods, is provided on the basis of their performance, expenses, and response time. It is expected that this comprehensive study will provide a one-stop source of information for all the new researchers and the experts working in the mentioned area of research.",
        "DOI": "10.3390/en13184727",
        "paper_author": "Saeed M.S.",
        "affiliation_name": "Universiti Teknologi Malaysia",
        "affiliation_city": "Johor Bahru",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60021005",
        "affiliation_state": "Johor"
    },
    {
        "paper_title": "A Data-Driven Framework to Characterize State-Level Water Use in the United States",
        "publication": "Water Resources Research",
        "citied_by": "16",
        "cover_date": "2020-09-01",
        "Abstract": "Access to credible estimates of water use is critical for making optimal operational decisions and investment plans to ensure reliable and affordable provisioning of water. Furthermore, identifying the key predictors of water use is important for regulators to promote sustainable development policies to reduce water use. In this paper, we propose a data-driven framework, grounded in statistical learning theory, to develop a rigorously evaluated predictive model of state-level, per capita water use in the United States as a function of various geographic, climatic, and socioeconomic variables. Specifically, we compare the accuracy of various statistical methods in predicting the state-level, per capita water use and find that the model based on the random forest algorithm outperforms all other models. We then leverage the random forest model to identify key factors associated with high water-usage intensity among different sectors in the United States. More specifically, irrigated farming, thermoelectric energy generation, and urbanization were identified as the most water-intensive anthropogenic activities, on a per capita basis. Among the climate factors, precipitation was found to be a key predictor of per capita water use, with drier conditions associated with higher water usage. Overall, our study highlights the utility of leveraging data-driven modeling to gain valuable insights related to the water use patterns across expansive geographical areas.",
        "DOI": "10.1029/2019WR024894",
        "paper_author": "Wongso E.",
        "affiliation_name": "Edwardson School of Industrial Engineering",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60015178",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Climate change mitigation in cities: A systematic scoping of case studies",
        "publication": "Environmental Research Letters",
        "citied_by": "51",
        "cover_date": "2020-09-01",
        "Abstract": "A growing number of researchers and stakeholders have started to address climate change from the bottom up: By devising scientific models, climate plans, low-carbon strategies and development policies with climate co-benefits. Little is known about the comparative characteristics of these interventions, including their relative efficacy, potentials and emissions reductions. A more systematic understanding is required to delineate the urban mitigation space and inform decision-making. Here, we utilize bibliometric methods and machine learning to meta-analyze 5635 urban case studies of climate change mitigation. We identify 867 studies that explicitly consider technological or policy instruments, and categorize these studies according to policy type, sector, abatement potential, and socio-technological composition to obtain a first heuristic of what is their pattern. Overall, we find 41 different urban solutions with an average GHG abatement potential ranging from 5.2% to 105%, most of them clustering in the building and transport sectors. More than three-fourth of the solutions are on demand side. Less than 10% of all studies were ex-post policy evaluations. Our results demonstrate that technology-oriented interventions in urban waste, transport and energy sectors have the highest marginal abatement potential, while system-wide interventions, e.g. urban form related measures have lower marginal abatement potential but wider scope. We also demonstrate that integrating measures across urban sectors realizes synergies in GHG emission reductions. Our results reveal a rich evidence of techno-policy choices that together enlarge the urban solutions space and augment actions currently considered in global assessments of climate mitigation.",
        "DOI": "10.1088/1748-9326/ab99ff",
        "paper_author": "Sethi M.",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning-based approach to predict energy consumption of renewable and nonrenewable power sources",
        "publication": "Energies",
        "citied_by": "81",
        "cover_date": "2020-09-01",
        "Abstract": "In today’s world, renewable energy sources are increasingly integrated with nonrenewable energy sources into electric grids and pose new challenges because of their intermittent and variable nature. Energy prediction using soft-computing techniques plays a vital role in addressing these challenges. As electricity consumption is closely linked to other energy sources such as natural gas and oil, forecasting electricity consumption is essential for making national energy policies. In this paper, we utilize various data mining techniques, including preprocessing historical load data and the load time series’s characteristics. We analyzed the power consumption trends from renewable energy sources and nonrenewable energy sources and combined them. A novel machine learning-based hybrid approach, combining multilayer perceptron (MLP), support vector regression (SVR), and CatBoost, is proposed in this paper for power forecasting. A thorough comparison is made, taking into account the results obtained using other prediction methods.",
        "DOI": "10.3390/en13184870",
        "paper_author": "Khan P.W.",
        "affiliation_name": "Jeju National University",
        "affiliation_city": "Jeju",
        "affiliation_country": "South Korea",
        "affiliation_id": "60117634",
        "affiliation_state": "Jeju-do"
    },
    {
        "paper_title": "Toward a sustainable cybersecurity ecosystem",
        "publication": "Computers",
        "citied_by": "48",
        "cover_date": "2020-09-01",
        "Abstract": "Cybersecurity issues constitute a key concern of today’s technology-based economies. Cybersecurity has become a core need for providing a sustainable and safe society to online users in cyberspace. Considering the rapid increase of technological implementations, it has turned into a global necessity in the attempt to adapt security countermeasures, whether direct or indirect, and prevent systems from cyberthreats. Identifying, characterizing, and classifying such threats and their sources is required for a sustainable cyber-ecosystem. This paper focuses on the cybersecurity of smart grids and the emerging trends such as using blockchain in the Internet of Things (IoT). The cybersecurity of emerging technologies such as smart cities is also discussed. In addition, associated solutions based on artificial intelligence and machine learning frameworks to prevent cyber-risks are also discussed. Our review will serve as a reference for policy-makers from the industry, government, and the cybersecurity research community.",
        "DOI": "10.3390/computers9030074",
        "paper_author": "Sadik S.",
        "affiliation_name": "University of Chittagong",
        "affiliation_city": "Chittagong",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60033059",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The united states' clothing imports from asian countries along the belt and road: An extended gravity trade model with application of artificial neural network",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "11",
        "cover_date": "2020-09-01",
        "Abstract": "In 2013, China announced the Belt and Road Initiative (BRI), which aims to promote the connectivity of Asia, Europe, and Africa and deepen mutually beneficial economic cooperation among member countries. Past studies have reported a positive impact of the BRI on trade between China and its partner countries along the Belt and Road (B&R). However, less is known about its effect on the sectoral trade between the B&R countries and countries that show little support of the BRI. To address that gap, this study examines the changing patterns of clothing imports by the United States (US) from China and 14 B&R countries in Asia. An extended gravity model with a policy variable BRI is built to explain bilateral clothing trade flow. A panel regression model and artificial neural network (ANN) are developed based on the data collected from 1998 to 2018 and applied to predict the trade pattern of 2019. The results show a positive effect of the BRI on the clothing exports of some Asian developing countries along the B&R to the US and demonstrate the superior predictive power of the ANN. More research is needed to examine the balance between economic growth and the social and environmental sustainability of developing countries and to apply more advanced machine learning algorithms to examine global trade flow under the BRI.",
        "DOI": "10.3390/SU12187433",
        "paper_author": "Ho D.C.K.",
        "affiliation_name": "The Hang Seng University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60086451",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Abandonment and recultivation of agricultural lands in Slovakia-patterns and determinants from the past to the future",
        "publication": "Land",
        "citied_by": "48",
        "cover_date": "2020-09-01",
        "Abstract": "Central and Eastern Europe has experienced fundamental land use changes since the collapse of socialism around 1990. We analyzeanalyzed the patterns and determinants of agricultural land abandonment and recultivation in Slovakia during the transition from a state-controlled economy to an open-market economy (1986 to 2000) and the subsequent accession to the European Union (2000 to 2010). We quantified agricultural land-use change based on available maps derived from 30-m multi-seasonal Landsat imagery and analyzeanalyzed the socioeconomic and biophysical determinants of the observed agricultural land-use changes using boosted regression trees. We used a scenario-based approach to assess future agricultural land abandonment and recultivation until 2060. The maps of agricultural land use analysis reveal that cropland abandonment was the dominant land use process on 11% of agricultural land from 1986 to 2000, and on 6% of the agricultural land from 2000 to 2010. Recultivation occurred on approximately 2% of agricultural land in both periods. Although most abandoned land was located in the plains, the rate of abandonment was twice as high in the mountainous landscapes. The likelihood of abandonment increased with increased distance from the national capital (Bratislava), decreased with an increase of annual mean temperatures and was higher in proximity to forest edges and on steeper slopes. Recultivation was largely determined by the opposite effects. The scenario for 2060 suggests that future agricultural land abandonment and recultivation may largely be determined by climate and terrain conditions and, to a lesser extent, by proximity to economic centers. Our study underscores the value of synergetic use of satellite data and land-use modeling to provide the input for land planning, and to anticipate the potential effects of changing environmental and policy conditions.",
        "DOI": "10.3390/LAND9090316",
        "paper_author": "Pazúr R.",
        "affiliation_name": "Eidgenössische Forschungsanstalt für Wald, Schnee und Landschaft WSL",
        "affiliation_city": "Birmensdorf",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60008588",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Association of violence with urban points of interest",
        "publication": "PLoS ONE",
        "citied_by": "7",
        "cover_date": "2020-09-01",
        "Abstract": "The association between alcohol outlets and violence has long been recognised, and is commonly used to inform policing and licensing policies (such as staggered closing times and zoning). Less investigated, however, is the association between violent crime and other urban points of interest, which while associated with the city centre alcohol consumption economy, are not explicitly alcohol outlets. Here, machine learning (specifically, LASSO regression) is used to model the distribution of violent crime for the central 9 km2 of ten large UK cities. Densities of 620 different Point of Interest types (sourced from Ordnance Survey) are used as predictors, with the 10 most explanatory variables being automatically selected for each city. Cross validation is used to test generalisability of each model. Results show that the inclusion of additional point of interest types produces a more accurate model, with significant increases in performance over a baseline univariate alcohol-outlet only model. Analysis of chosen variables for city-specific models shows potential candidates for new strategies on a per-city basis, with combined-model variables showing the general trend in POI/violence association across the UK. Although alcohol outlets remain the best individual predictor of violence, other points of interest should also be considered when modelling the distribution of violence in city centres. The presented method could be used to develop targeted, city-specific initiatives that go beyond alcohol outlets and also consider other locations.",
        "DOI": "10.1371/journal.pone.0239840",
        "paper_author": "Redfern J.",
        "affiliation_name": "Cardiff University",
        "affiliation_city": "Cardiff",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60023998",
        "affiliation_state": "South Glamorgan, Wales"
    },
    {
        "paper_title": "Bioethical aspects of artificial intelligence: COVID-19 &amp; end of life",
        "publication": "Revista da Associacao Medica Brasileira",
        "citied_by": "2",
        "cover_date": "2020-09-01",
        "Abstract": "NA",
        "DOI": "10.1590/1806-9282.66.S2.5",
        "paper_author": "da Motta O.J.R.",
        "affiliation_name": "Universidade Federal do Rio de Janeiro",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil",
        "affiliation_id": "60000036",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Using inverse reinforcement learning with real trajectories to get more trustworthy pedestrian simulations",
        "publication": "Mathematics",
        "citied_by": "15",
        "cover_date": "2020-09-01",
        "Abstract": "Reinforcement learning is one of the most promising machine learning techniques to get intelligent behaviors for embodied agents in simulations. The output of the classic Temporal Difference family of Reinforcement Learning algorithms adopts the form of a value function expressed as a numeric table or a function approximator. The learned behavior is then derived using a greedy policy with respect to this value function. Nevertheless, sometimes the learned policy does not meet expectations, and the task of authoring is difficult and unsafe because the modification of one value or parameter in the learned value function has unpredictable consequences in the space of the policies it represents. This invalidates direct manipulation of the learned value function as a method to modify the derived behaviors. In this paper, we propose the use of Inverse Reinforcement Learning to incorporate real behavior traces in the learning process to shape the learned behaviors, thus increasing their trustworthiness (in terms of conformance to reality). To do so, we adapt the Inverse Reinforcement Learning framework to the navigation problem domain. Specifically, we use Soft Q-learning, an algorithm based on the maximum causal entropy principle, with MARL-Ped (a Reinforcement Learning-based pedestrian simulator) to include information from trajectories of real pedestrians in the process of learning how to navigate inside a virtual 3D space that represents the real environment. A comparison with the behaviors learned using a Reinforcement Learning classic algorithm (Sarsa(λ) shows that the Inverse Reinforcement Learning behaviors adjust significantly better to the real trajectories.",
        "DOI": "10.3390/math8091479",
        "paper_author": "Martinez-Gil F.",
        "affiliation_name": "Universitat de València",
        "affiliation_city": "Valencia",
        "affiliation_country": "Spain",
        "affiliation_id": "60002644",
        "affiliation_state": "Valencia"
    },
    {
        "paper_title": "Social sensing for Urban land use identification",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "14",
        "cover_date": "2020-09-01",
        "Abstract": "The utilization of urban land use maps can reveal the patterns of human behavior through the extraction of the socioeconomic and demographic characteristics of urban land use. Remote sensing that holds detailed and abundant information on spectral, textual, contextual, and spatial configurations is crucial to obtaining land use maps that reveal changes in the urban environment. However, social sensing is essential to revealing the socioeconomic and demographic characteristics of urban land use. This data mining approach is related to data cleaning/outlier removal and machine learning, and is used to achieve land use classification from remote and social sensing data. In bicycle and taxi density maps, the daytime destination and nighttime origin density reflects work-related land uses, including commercial and industrial areas. By contrast, the nighttime destination and daytime origin density pattern captures the pattern of residential areas. The accuracy assessment of land use classified maps shows that the integration of remote and social sensing, using the decision tree and random forest methods, yields accuracies of 83% and 86%, respectively. Thus, this approach facilitates an accurate urban land use classification. Urban land use identification can aid policy makers in linking human activities to the socioeconomic consequences of different urban land uses.",
        "DOI": "10.3390/ijgi9090550",
        "paper_author": "Anugraha A.S.",
        "affiliation_name": "National Cheng Kung University",
        "affiliation_city": "Tainan",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60014982",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessing the impact of public rental housing on the housing prices in proximity: Based on the regional and local level of price prediction models using long short-term memory (LSTM)",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "16",
        "cover_date": "2020-09-01",
        "Abstract": "Providing adequate public rental housing (PRH) of a decent quality at a desirable location is a major challenge in many cities. Often, a prominent opponent of PRH development is its host community, driven by a belief that PRH depreciates nearby property values. While this is a persistent issue in many cities around the world, this study proposed a new approach to assessing the impact of PRH on nearby property value. This study utilized a machine learning technique called long short-term memory (LSTM) to construct a set of housing price prediction models based on 547,740 apartment transaction records from the city of Busan, South Korea. A set of apartment characteristics and proximity measures to PRH were included in the modeling process. Four geographic boundaries were analyzed: The entire region of Busan, all neighborhoods of PRH, the neighborhoods of PRH in the \"favorable,\" and the \"less favorable\" local housing market. The study produced accurate and reliable price predictions, which indicated that the proximity to PRH has a meaningful impact on nearby housing prices both at the city and the neighborhood level. The approach taken by the study can facilitate improved decision making for future PRH policies and programs.",
        "DOI": "10.3390/su12187520",
        "paper_author": "Kim H.",
        "affiliation_name": "Pusan National University",
        "affiliation_city": "Busan",
        "affiliation_country": "South Korea",
        "affiliation_id": "60008783",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Spatial mapping of short-term solar radiation prediction incorporating geostationary satellite images coupled with deep convolutional LSTM networks for South Korea",
        "publication": "Environmental Research Letters",
        "citied_by": "32",
        "cover_date": "2020-09-01",
        "Abstract": "A practical approach to continuously monitor and provide real-time solar energy prediction can help support reliable renewable energy supply and relevant energy security systems. In this study on the Korean Peninsula, contemporaneous solar radiation images obtained from the Communication, Ocean and Meteorological Satellite (COMS) Meteorological Imager (MI) system, were used to design a convolutional neural network and a long short-term memory network predictive model, ConvLSTM. This model was applied to predict one-hour ahead solar radiation and spatially map solar energy potential. The newly designed ConvLSTM model enabled reliable prediction of solar radiation, incorporating spatial changes in atmospheric conditions and capturing the temporal sequence-to-sequence variations that are likely to influence solar driven power supply and its overall stability. Results showed that the proposed ConvLSTM model successfully captured cloud-induced variations in ground level solar radiation when compared with reference images from a physical model. A comparison with ground pyranometer measurements indicated that the short-term prediction of global solar radiation by the proposed ConvLSTM had the highest accuracy [root mean square error (RMSE) = 83.458 W • m-2, mean bias error (MBE) = 4.466 W • m-2, coefficient of determination (R2) = 0.874] when compared with results of conventional artificial neural network (ANN) [RMSE = 94.085 W • m-2, MBE =-6.039 W • m-2, R2 = 0.821] and random forest (RF) [RMSE = 95.262 W • m-2, MBE =-11.576 W • m-2, R2 = 0.839] models. In addition, ConvLSTM better captured the temporal variations in predicted solar radiation, mainly due to cloud attenuation effects when compared with two selected ground stations. The study showed that contemporaneous satellite images over short-term or near real-time intervals can successfully support solar energy exploration in areas without continuous environmental monitoring systems, where satellite footprints are available to model and monitor solar energy management systems supporting real-life power grid systems.",
        "DOI": "10.1088/1748-9326/ab9467",
        "paper_author": "Yeom J.M.",
        "affiliation_name": "Korea Aerospace Research Institute",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60068719",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "India nudges to contain COVID-19 pandemic: A reactive public policy analysis using machine-learning based topic modelling",
        "publication": "PLoS ONE",
        "citied_by": "75",
        "cover_date": "2020-09-01",
        "Abstract": "India locked down 1.3 billion people on March 25, 2020, in the wake of COVID-19 pandemic. The economic cost of it was estimated at USD 98 billion, while the social costs are still unknown. This study investigated how government formed reactive policies to fight coronavirus across its policy sectors. Primary data was collected from the Press Information Bureau (PIB) in the form press releases of government plans, policies, programme initiatives and achievements. A text corpus of 260,852 words was created from 396 documents from the PIB. An unsupervised machine-based topic modelling using Latent Dirichlet Allocation (LDA) algorithm was performed on the text corpus. It was done to extract high probability topics in the policy sectors. The interpretation of the extracted topics was made through a nudge theoretic lens to derive the critical policy heuristics of the government. Results showed that most interventions were targeted to generate endogenous nudge by using external triggers. Notably, the nudges from the Prime Minister of India was critical in creating herd effect on lockdown and social distancing norms across the nation. A similar effect was also observed around the public health (e.g., masks in public spaces; Yoga and Ayurveda for immunity), transport (e.g., old trains converted to isolation wards), micro, small and medium enterprises (e.g., rapid production of PPE and masks), science and technology sector (e.g., diagnostic kits, robots and nano-technology), home affairs (e.g., surveillance and lockdown), urban (e.g. drones, GIS-tools) and education (e.g., online learning). A conclusion was drawn on leveraging these heuristics are crucial for lockdown easement planning.",
        "DOI": "10.1371/journal.pone.0238972",
        "paper_author": "Debnath R.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Developing employment environments where individuals with asd thrive: Using machine learning to explore employer policies and practices",
        "publication": "Brain Sciences",
        "citied_by": "11",
        "cover_date": "2020-09-01",
        "Abstract": "An online survey instrument was developed to assess employers’ perspectives on hiring job candidates with Autism Spectrum Disorder (ASD). The investigators used K-means clustering to categorize companies in clusters based on their hiring practices related to individuals with ASD. This methodology allowed the investigators to assess and compare the various factors of businesses that successfully hire employees with ASD versus those that do not. The cluster analysis indicated that company structures, policies and practices, and perceptions, as well as the needs of employers and employees, were important in determining who would successfully hire individuals with ASD. Key areas that require focused policies and practices include recruitment and hiring, training, accessibility and accommodations, and retention and advancement.",
        "DOI": "10.3390/brainsci10090632",
        "paper_author": "Griffiths A.J.",
        "affiliation_name": "Chapman University",
        "affiliation_city": "Orange",
        "affiliation_country": "United States",
        "affiliation_id": "60016569",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Predicting renewable energy investment using machine learning",
        "publication": "Energies",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "In order to combat climate change, many countries have promised to bolster Renewable Energy (RE) production following the Paris Agreement with some countries even setting a goal of 100% by 2025. The reasons are twofold: Capitalizing on carbon emissions whilst concomitantly benefiting from reduced fossil fuel dependence and the fluctuations associated with imported fuel prices. However, numerous countries have not yet made preparations to increase RE production and integration. In many instances, this reluctance seems to be predominant in energy-rich countries, which typically provide heavy subsidies on electricity prices. With such subsidies, there is no incentive to invest in RE since the time taken to recoup such investments would be significant. We develop a model using a Neural Network (NN) regression algorithm to quantitatively illustrate this conjecture and also use it to predict the reduction in electricity price subsidies required to achieve a specified RE production target. The model was trained using 10 leading metrics from 53 countries. It is envisaged that policymakers and researchers can use this model to plan future RE targets to satisfy the Nationally Determined Contributions (NDC) and determine the required electricity subsidy reductions. The model can easily be modified to predict what changes in other country factors can be made to stimulate growth in RE production. We illustrate this approach with a sample use case.",
        "DOI": "10.3390/en13174494",
        "paper_author": "Hosein G.",
        "affiliation_name": "The University of the West Indies, St. Augustine Campus",
        "affiliation_city": "St Augustine",
        "affiliation_country": "Trinidad and Tobago",
        "affiliation_id": "60071706",
        "affiliation_state": "Tunapuna–Piarco"
    },
    {
        "paper_title": "A survey of multi-task deep reinforcement learning",
        "publication": "Electronics (Switzerland)",
        "citied_by": "113",
        "cover_date": "2020-09-01",
        "Abstract": "Driven by the recent technological advancements within the field of artificial intelligence research, deep learning has emerged as a promising representation learning technique across all of the machine learning classes, especially within the reinforcement learning arena. This new direction has given rise to the evolution of a new technological domain named deep reinforcement learning, which combines the representational learning power of deep learning with existing reinforcement learning methods. Undoubtedly, the inception of deep reinforcement learning has played a vital role in optimizing the performance of reinforcement learning-based intelligent agents with model-free based approaches. Although these methods could improve the performance of agents to a greater extent, they were mainly limited to systems that adopted reinforcement learning algorithms focused on learning a single task. At the same moment, the aforementioned approach was found to be relatively data-inefficient, particularly when reinforcement learning agents needed to interact with more complex and rich data environments. This is primarily due to the limited applicability of deep reinforcement learning algorithms to many scenarios across related tasks from the same environment. The objective of this paper is to survey the research challenges associated with multi-tasking within the deep reinforcement arena and present the state-of-the-art approaches by comparing and contrasting recent solutions, namely DISTRAL (DIStill & TRAnsfer Learning), IMPALA(Importance Weighted Actor-Learner Architecture) and PopArt that aim to address core challenges such as scalability, distraction dilemma, partial observability, catastrophic forgetting and negative knowledge transfer.",
        "DOI": "10.3390/electronics9091363",
        "paper_author": "Varghese N.V.",
        "affiliation_name": "Ontario Tech University",
        "affiliation_city": "Oshawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60002146",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Disturbance-Observer-Based Tracking Controller for Neural Network Driving Policy Transfer",
        "publication": "IEEE Transactions on Intelligent Transportation Systems",
        "citied_by": "9",
        "cover_date": "2020-09-01",
        "Abstract": "The neural network policies are widely explored in the autonomous driving field, thanks to their capability of handling complicated driving tasks. However, the practical deployment of such policies is slowed down due to their lack of robustness against modeling gap and external disturbances. In our prior work, we proposed a planner-controller architecture and applied a disturbance-observer-based (DOB) robust tracking controller to reject the disturbances and achieved zero-shot policy transfer. In this paper, we present our latest progress on improving the policy transfer performance under this framework. Concretely, we applied adaptive DOB, so as to more accurately model the inverse system dynamics and increase the cut-off frequency of the Q-filter in the DOB. A closed-loop reference path smoothing algorithm is introduced to alleviate the step disturbance input imposed by the reference trajectory re-planning. On the neural network control policy side, we applied the parallel attribute networks, a hierarchical modular policy network to dynamically handle various driving tasks. We have carried out various simulations and experiments to validate the capability of our proposed method to achieve sim-to-sim and sim-to-real policy transfer. The proposed method achieves the most outstanding performance among a series of baseline control schemes.",
        "DOI": "10.1109/TITS.2019.2951362",
        "paper_author": "Tang C.",
        "affiliation_name": "Department of Mechanical Engineering",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60121383",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Reinforcement Learning Tracking Control for Robotic Manipulator with Kernel-Based Dynamic Model",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "49",
        "cover_date": "2020-09-01",
        "Abstract": "Reinforcement learning (RL) is an efficient learning approach to solving control problems for a robot by interacting with the environment to acquire the optimal control policy. However, there are many challenges for RL to execute continuous control tasks. In this article, without the need to know and learn the dynamic model of a robotic manipulator, a kernel-based dynamic model for RL is proposed. In addition, a new tuple is formed through kernel function sampling to describe a robotic RL control problem. In this algorithm, a reward function is defined according to the features of tracking control in order to speed up the learning process, and then an RL tracking controller with a kernel-based transition dynamic model is proposed. Finally, a critic system is presented to evaluate the policy whether it is good or bad to the RL control tasks. The simulation results illustrate that the proposed method can fulfill the robotic tracking tasks effectively and achieve similar and even better tracking performance with much smaller inputs of force/torque compared with other learning algorithms, demonstrating the effectiveness and efficiency of the proposed RL algorithm.",
        "DOI": "10.1109/TNNLS.2019.2945019",
        "paper_author": "Hu Y.",
        "affiliation_name": "Shenyang Institute of Automation Chinese Academy of Sciences",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60021474",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Intelligent control based on a neural network for aircraft landing gear with a magnetorheological damper in different landing scenarios",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "14",
        "cover_date": "2020-09-01",
        "Abstract": "A typical oleo-pneumatic shock-absorbing strut (classic traditional passive damper) in aircraft landing gear has a metering pin extending through the orifice, which can vary the orifice area with the compression and extension of the damper strut. Because the metering pin is designed in a single landing condition, the traditional passive damper cannot adjust its damping force in multiple landing conditions. Magnetorheological (MR) dampers have been receiving significant attention as an alternative to traditional passive dampers. An MR damper, which is a typical semi-active suspension system, can control the damping force created by MR fluid under the magnetic field. Thus, it can be controlled by electric current. This paper adopts a neural network controller trained by two different methods, which are genetic algorithm and policy gradient estimation, for aircraft landing gear with an MR damper that considers different landing scenarios. The controller learns from a large number of trials, and accordingly, the main advantage is that it runs autonomously without requiring system knowledge. Moreover, comparative numerical simulations are executed with a passive damper and adaptive hybrid controller under various aircraft masses and sink speeds for verifying the effectiveness of the proposed controller. The main simulation results show that the proposed controller exhibits comparable performance to the adaptive hybrid controller without any needs for the online estimation of landing conditions.",
        "DOI": "10.3390/app10175962",
        "paper_author": "Luong Q.V.",
        "affiliation_name": "Korea Aerospace University",
        "affiliation_city": "Goyang",
        "affiliation_country": "South Korea",
        "affiliation_id": "60080732",
        "affiliation_state": "Gyeonggi-do"
    },
    {
        "paper_title": "Massive data initiatives and AI provide testbed for pandemic forecasting",
        "publication": "Nature Biotechnology",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41587-020-0671-4",
        "paper_author": "Sheridan C.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Using machine learning models and actual transaction data for predicting real estate prices",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "66",
        "cover_date": "2020-09-01",
        "Abstract": "Real estate price prediction is crucial for the establishment of real estate policies and can help real estate owners and agents make informative decisions. The aim of this study is to employ actual transaction data and machine learning models to predict prices of real estate. The actual transaction data contain attributes and transaction prices of real estate that respectively serve as independent variables and dependent variables for machine learning models. The study employed four machine learning models-namely, least squares support vector regression (LSSVR), classification and regression tree (CART), general regression neural networks (GRNN), and backpropagation neural networks (BPNN), to forecast real estate prices. In addition, genetic algorithms were used to select parameters of machine learning models. Numerical results indicated that the least squares support vector regression outperforms the other three machine learning models in terms of forecasting accuracy. Furthermore, forecasting results generated by the least squares support vector regression are superior to previous related studies of real estate price prediction in terms of the average absolute percentage error. Thus, the machine learning-based model is a substantial and feasible way to forecast real estate prices, and the least squares support vector regression can provide relatively competitive and satisfactory results.",
        "DOI": "10.3390/app10175832",
        "paper_author": "Pai P.F.",
        "affiliation_name": "National Chi Nan University",
        "affiliation_city": "Puli",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60022907",
        "affiliation_state": "Nantou"
    },
    {
        "paper_title": "An online paper authoring tool (PAT) to improve reporting of, and synthesis of evidence from, trials in behavioral sciences",
        "publication": "Health Psychology",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "The Science of Behavior Change project represents a major advance in the way we approach the study of behavior and behavior change; the protocols in this special issue reflect the innovative approach to intervention development. Digital technology is transforming the way we conduct science and can greatly assist with developing protocols, reporting studies, and evidence synthesis. The journal Addiction has developed an online Paper Authoring Tool (PAT) for reporting full-scale randomized controlled trials that could also be used for reporting protocols and early phase trials. PAT aims to help authors ensure that they include all the required information and present it in a way that is clear and consistent in terms of language and phrasing. It also generates a computer-readable record that should greatly facilitate automation of evidence synthesis. PAT is intended to represent the first step in creation of a supportive ecosystem for the conduct of science, linking grant applications, study protocols, study reports, measures, reviews and study data in a coordinated online knowledge base.",
        "DOI": "10.1037/hea0000927",
        "paper_author": "West R.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Fighting pandemics with digital epidemiology",
        "publication": "EClinicalMedicine",
        "citied_by": "16",
        "cover_date": "2020-09-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.eclinm.2020.100512",
        "paper_author": "Tarkoma S.",
        "affiliation_name": "Helsingin Yliopisto",
        "affiliation_city": "Helsinki",
        "affiliation_country": "Finland",
        "affiliation_id": "60002952",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "A monitoring system for online fault detection and classification in photovoltaic plants",
        "publication": "Sensors (Switzerland)",
        "citied_by": "72",
        "cover_date": "2020-09-01",
        "Abstract": "Photovoltaic (PV) energy use has been increasing recently, mainly due to new policies all over the world to reduce the application of fossil fuels. PV system efficiency is highly dependent on environmental variables, besides being affected by several kinds of faults, which can lead to a severe energy loss throughout the operation of the system. In this sense, we present a Monitoring System (MS) to measure the electrical and environmental variables to produce instantaneous and historical data, allowing to estimate parameters that ar related to the plant efficiency. Additionally, using the same MS, we propose a recursive linear model to detect faults in the system, while using irradiance and temperature on the PV panel as input signals and power as output. The accuracy of the fault detection for a 5 kW power plant used in the test is 93.09%, considering 16 days and around 143 hours of faults in different conditions. Once a fault is detected by this model, a machine-learning-based method classifies each fault in the following cases: short-circuit, open-circuit, partial shadowing, and degradation. Using the same days and faults applied in the detection module, the accuracy of the classification stage is 95.44% for an Artificial Neural Network (ANN) model. By combining detection and classification, the overall accuracy is 92.64%. Such a result represents an original contribution of this work, since other related works do not present the integration of a fault detection and classification approach with an embedded PV plant monitoring system, allowing for the online identification and classification of different PV faults, besides real-time and historical monitoring of electrical and environmental parameters of the plant.",
        "DOI": "10.3390/s20174688",
        "paper_author": "Lazzaretti A.E.",
        "affiliation_name": "Universidade Tecnológica Federal do Paraná",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil",
        "affiliation_id": "60027294",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "Digital entrepreneurs in artificial intelligence and data analytics: Who are they?",
        "publication": "Journal of Open Innovation: Technology, Market, and Complexity",
        "citied_by": "22",
        "cover_date": "2020-09-01",
        "Abstract": "Digital technologies are key resources for entrepreneurial activities and there is great interest in digital entrepreneurship. While much research has focused on the role of digital technologies in entrepreneurship and how they are shaping the field, there has been relatively little research on those key players of digital entrepreneurship. Using data from Crunchbase and Twitter API and a learning machine, this study attempts to answer the question of \"who are digital entrepreneurs?\" This study reports that digital entrepreneurs in the artificial intelligence and data analytics (AIDA) industry are more likely to be male and to be active and connected online than non-digital entrepreneurs. In addition, they tend to be more extroverted and less conscientious and agreeable than other, non-digital, entrepreneurs. Our findings help to develop a clearer picture of digital entrepreneurs, which would be of great interest to investors, policy makers, current and future digital entrepreneurs and educators.",
        "DOI": "10.3390/JOITMC6030056",
        "paper_author": "Chae B.(.",
        "affiliation_name": "Kansas State University",
        "affiliation_city": "Manhattan",
        "affiliation_country": "United States",
        "affiliation_id": "60000689",
        "affiliation_state": "KS"
    },
    {
        "paper_title": "Weakly-supervised domain adaptation for built-up region segmentation in aerial and satellite imagery",
        "publication": "ISPRS Journal of Photogrammetry and Remote Sensing",
        "citied_by": "39",
        "cover_date": "2020-09-01",
        "Abstract": "This paper proposes a novel domain adaptation algorithm to handle the challenges posed by the satellite and aerial imagery, and demonstrates its effectiveness on the built-up region segmentation problem. Built-up area estimation is an important component in understanding the human impact on the environment, effect of public policy and in general urban population analysis. The diverse nature of aerial and satellite imagery (capturing different geographical locations, terrains and weather conditions) and lack of labeled data covering this diversity makes machine learning algorithms difficult to generalize for such tasks, especially across multiple domains. Re-training for new domain is both computationally and labor expansive mainly due to the cost of collecting pixel level labels required for the segmentation task. Domain adaptation algorithms have been proposed to enable algorithms trained on images of one domain (source) to work on images from other dataset (target). Unsupervised domain adaptation is a popular choice since it allows the trained model to adapt without requiring any ground-truth information of the target domain. On the other hand, due to the lack of strong spatial context and structure, in comparison to the ground imagery, application of existing unsupervised domain adaptation methods results in the sub-optimal adaptation. We thoroughly study limitations of existing domain adaptation methods and propose a weakly-supervised adaptation strategy where we assume image level labels are available for the target domain. More specifically, we design a built-up area segmentation network (as encoder-decoder), with image classification head added to guide the adaptation. The devised system is able to address the problem of visual differences in multiple satellite and aerial imagery datasets, ranging from high resolution (HR) to very high resolution (VHR), by investigating the latent space as well as the structured output space. A realistic and challenging HR dataset is created by hand-tagging the 73.4 sq-km of Rwanda, capturing a variety of build-up structures over different terrain. The developed dataset is spatially rich compared to existing datasets and covers diverse built-up scenarios including built-up areas in forests and deserts, mud houses, tin and colored rooftops. Extensive experiments are performed by adapting from the single-source domain datasets, such as Massachusetts Buildings Dataset, to segment out the target domain. We achieve high gains ranging 11.6–52% in IoU over the existing state-of-the-art methods.",
        "DOI": "10.1016/j.isprsjprs.2020.07.001",
        "paper_author": "Iqbal J.",
        "affiliation_name": "Information Technology University",
        "affiliation_city": "Lahore",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60105219",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Policy strategies for personalising medicine “in the data moment”",
        "publication": "Health Policy and Technology",
        "citied_by": "4",
        "cover_date": "2020-09-01",
        "Abstract": "Objective: ‘Data’ is relevant in evolving value-based healthcare that involves machine learning and artificial intelligence-based technologies which are increasingly changing the landscape of personalised medicine (PM). However, a lack in adequate data for decision making may lead to new forms of health inequalities spite of the advancement in the technological front. There exists a dearth in alignment between incentive structures for innovation and policy measures for collective action and data transparency. Against this background, this article identifies the legal challenges for a data-driven PM in Europe. Transparency, data protection and Intellectual property rights (IP) are major legal challenges for data-oriented personalised research in Europe. Consequently, there is a need for restructuring public policy strategies in the interest of patients. Method: Legal dogmatic analysis of structural inefficiencies within interrelated legal paradigm over data that limits a functional development of a data-driven PM. Result: Engaging in the data movement in personalised health care calls for special attention to strategic tools such as co-regulation and self-regulation that bridge the gap in law and practice.",
        "DOI": "10.1016/j.hlpt.2020.07.003",
        "paper_author": "Rajam N.",
        "affiliation_name": "Københavns Universitet",
        "affiliation_city": "Copenhagen",
        "affiliation_country": "Denmark",
        "affiliation_id": "60030840",
        "affiliation_state": "Hovedstaden"
    },
    {
        "paper_title": "Cluster analysis application to identify groups of individuals with high health expenditures",
        "publication": "Health Services and Outcomes Research Methodology",
        "citied_by": "7",
        "cover_date": "2020-09-01",
        "Abstract": "We compare and demonstrate the effectiveness of two clustering methods with the main purpose of identifying characteristic profiles of high utilizers of health care. In this work, we use three sets of mutually independent longitudinal data that are nationally representative of the US adult working-age civilian non-institutionalized population. We compare k-means, a commonly used clustering method, with a k-medoids algorithm called Partitioning Around Medoids. We use one cohort of data to create clusters based on similar characteristics of individuals for both clustering methods. We examine these characteristic compositions of the highest three average total expenditure clusters from this cohort. We also examine the health expenditure distributions for this cohort over the following two years. We validate the approach by applying the centers of the clusters to two other cohorts of similar data. We form clusters based on demographic, economic, and health-related characteristics that are commonly used in studies of health care utilization. We demonstrate the consistency of our results across the three cohorts of data and across different types of health expenditures, such as office-based/outpatient and drug. Clusters can be formed with other more homogeneous data, such as Medicaid, Medicare, employer sponsored insurance, or individual private plans issued under the Affordable Care Act. This approach can be used to follow similar groups over time for other types of health outcomes.",
        "DOI": "10.1007/s10742-020-00214-8",
        "paper_author": "Agterberg J.",
        "affiliation_name": "Johns Hopkins University",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60005248",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Author Correction: Remote sensing northern lake methane ebullition (Nature Climate Change, (2020), 10, 6, (511-517), 10.1038/s41558-020-0762-8)",
        "publication": "Nature Climate Change",
        "citied_by": "1",
        "cover_date": "2020-09-01",
        "Abstract": "The following code availability statement had not previously been provided for this Letter: “The eddy4R v0.2.0 eddy-covariance software framework used to generate airborne flux estimates is described in ref. 56 and can be freely accessed at https://github.com/NEONScience/ eddy4R. The eddy4R Environmental Response Functions v0.0.5 advanced software module of ref. 49 was accessed under Terms of Use for this study (https://www.eol.ucar.edu/content/cheesehead-code-policy-appendix) and is available upon request.” As a result, a new ref. 56 has been added “Metzger, S. et al. eddy4R 0.2.0: a DevOps model for community-extensible processing and analysis of eddy-covariance data based on R, Git, Docker, and HDF5. Geosci. Model Dev. 10, 3189–3206 (2017)”. In addition, the following sentence was not included in the Acknowledgements: “We thank S. Metzger for processing the airborne EC raw data and for advice on the machine-learning steps in creating the regional airborne EC flux map using the free eddy4R software framework.” The online versions of this Letter have now been amended.",
        "DOI": "10.1038/s41558-020-0882-1",
        "paper_author": "Engram M.",
        "affiliation_name": "College of Engineering &amp; Mines University of Alaska Fairbanks",
        "affiliation_city": "Fairbanks",
        "affiliation_country": "United States",
        "affiliation_id": "60152932",
        "affiliation_state": "AK"
    },
    {
        "paper_title": "Festschrift for Leonard Bickman: Introduction to The Future of Children’s Mental Health Services Special Issue",
        "publication": "Administration and Policy in Mental Health and Mental Health Services Research",
        "citied_by": "0",
        "cover_date": "2020-09-01",
        "Abstract": "This introductory article describes the genesis of the Festschrift for Leonard Bickman and of this Festschrift special issue entitled, The Future of Children’s Mental Health Services. The special issue includes a collection of 11 original children’s mental health services research articles, broadly organized in accordance with three themes (i.e., Improving Precision and Use of Service Data to Guide Policy and Practice, Implementation and Dissemination, and Preparing for Innovation), followed by an interview-style article with Bickman. Then follows a featured manuscript by Bickman himself, three invited commentaries, and a compilation of letters and notes in which colleagues reflect on his career and on their experiences of him. The introduction concludes with a few thoughts about the future of children’s mental health services portended by the extraordinary scholarly contributions of Bickman and those who have been inspired by him.",
        "DOI": "10.1007/s10488-020-01070-x",
        "paper_author": "Schoenwald S.K.",
        "affiliation_name": "Oregon Social Learning Center",
        "affiliation_city": "Eugene",
        "affiliation_country": "United States",
        "affiliation_id": "60027525",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications",
        "publication": "IEEE Transactions on Cybernetics",
        "citied_by": "785",
        "cover_date": "2020-09-01",
        "Abstract": "Reinforcement learning (RL) algorithms have been around for decades and employed to solve various sequential decision-making problems. These algorithms, however, have faced great challenges when dealing with high-dimensional environments. The recent development of deep learning has enabled RL methods to drive optimal policies for sophisticated and capable agents, which can perform efficiently in these challenging environments. This article addresses an important aspect of deep RL related to situations that require multiple agents to communicate and cooperate to solve complex tasks. A survey of different approaches to problems related to multiagent deep RL (MADRL) is presented, including nonstationarity, partial observability, continuous state and action spaces, multiagent training schemes, and multiagent transfer learning. The merits and demerits of the reviewed methods will be analyzed and discussed with their corresponding applications explored. It is envisaged that this review provides insights about various MADRL methods and can lead to the future development of more robust and highly useful multiagent learning methods for solving real-world problems.",
        "DOI": "10.1109/TCYB.2020.2977374",
        "paper_author": "Nguyen T.T.",
        "affiliation_name": "Deakin University",
        "affiliation_city": "Geelong",
        "affiliation_country": "Australia",
        "affiliation_id": "60018805",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Adherence to vaccination policy among public health professionals: Results of a national survey in Italy",
        "publication": "Vaccines",
        "citied_by": "17",
        "cover_date": "2020-09-01",
        "Abstract": "Starting from 2013, the number of unvaccinated people alarmingly increased in Italy; therefore, in 2017 a new Vaccine National Plan was approved. Healthcare workers (HCWs), especially public health professionals (PHPs, i.e., workers in in the sector of hygiene and preventive medicine), have an important role in informing and promoting vaccinations. In this context, the Italian Study Group of Hospital Hygiene of the Italian Society of Hygiene, Preventive Medicine and Public Health (GISIO-SItI) conducted a national survey to assess knowledge, attitude, and practices towards recommended vaccinations among PHPs. The survey was conducted during October 2019 with an anonymous questionnaire distributed to PHPs attending the 52◦ SItI National Congress. Overall, 57.1% of operators answered correctly to all seven recommended vaccinations, 12.8% reported to be vaccinated for all seven recommended vaccinations, while 30% were naturally immunized. A higher immunization coverage was reported for anti-hepatitis B (88.9%) and measles (86.1%), and 81.3% of the participants reported being offered the influenza vaccination during the 2018/2019 season. The majority of our sample indicated that hepatitis B (95%) and influenza (93.7%) were the recommended vaccines for HCWs, while less was known regarding varicella, pertussis, diphtheria, and tetanus boosters every 10 years. PHPs who were vaccinated (or who intended to be vaccinated) were more likely to recommend vaccinations to their patients and provided a reassuring example to those hesitant patients. Finally, this is the first study that identified good algorithms (using the techniques of machine learning as Random Forest and Deep Learning) to predict the knowledge of PHPs regarding recommended vaccinations with possible applications in other national and international contexts.",
        "DOI": "10.3390/vaccines8030379",
        "paper_author": "Montagna M.T.",
        "affiliation_name": "Università degli studi di Bari Aldo Moro",
        "affiliation_city": "Bari",
        "affiliation_country": "Italy",
        "affiliation_id": "60022778",
        "affiliation_state": "BA"
    },
    {
        "paper_title": "Hybrid operations of human driving vehicles and automated vehicles with data-driven agent-based simulation",
        "publication": "Transportation Research Part D: Transport and Environment",
        "citied_by": "31",
        "cover_date": "2020-09-01",
        "Abstract": "Automated vehicles (AVs) receive tremendous attention and achieve rapid development. It is foreseeable that hybrid operations of human driving vehicles and automated vehicles in the urban transportation environment will be a long-standing state. To investigate the influence of AVs on the hybrid ride-hailing market, data-driven agent-based modeling and simulation (D2ABMS) for large-scale transportation networks is proposed, in which human drivers, automated vehicles, and passengers form three types of agents. D2ABMS goes beyond existing approaches by employing data-driven multi-objective deep learning to learn ride-sourcing drivers' offline/online behavior. E mbedding is used to represent the hidden attributes of different classes of drivers. Ride-sourcing data collected from the city of Hangzhou, China, are used to train and validate the drivers' decision-making model. Hybrid operations of human driving vehicles and automated vehicles with D2ABMS are comprehensively tested in various scenarios. The results show that a small proportion of automated vehicles in the hybrid ride-hailing market can significantly reduce the average waiting time of passengers. Besides, compared to the human driving scenario, the total exhaust emissions and vehicle kilometers traveled can be reduced by 12.3% in the AVs scenario. The proposed D2ABMS system has the potential to help transportation planners and ride-hailing platforms to assess their policies and operations management strategies in the era of shared mobility and automated vehicles.",
        "DOI": "10.1016/j.trd.2020.102469",
        "paper_author": "Yao F.",
        "affiliation_name": "College of Civil Engineering and Architecture Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117841",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "The ethics of AI in health care: A mapping review",
        "publication": "Social Science and Medicine",
        "citied_by": "362",
        "cover_date": "2020-09-01",
        "Abstract": "This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched to support the following research question: how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be ‘ethically mindful? A series of screening stages were carried out—for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)—yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new ‘AI winter’ could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care.",
        "DOI": "10.1016/j.socscimed.2020.113172",
        "paper_author": "Morley J.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175816",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Machine learning model to project the impact of COVID-19 on US motor gasoline demand",
        "publication": "Nature Energy",
        "citied_by": "62",
        "cover_date": "2020-09-01",
        "Abstract": "Owing to the global lockdowns that resulted from the COVID-19 pandemic, fuel demand plummeted and the price of oil futures went negative in April 2020. Robust fuel demand projections are crucial to economic and energy planning and policy discussions. Here we incorporate pandemic projections and people’s resulting travel and trip activities and fuel usage in a machine-learning-based model to project the US medium-term gasoline demand and study the impact of government intervention. We found that under the reference infection scenario, the US gasoline demand grows slowly after a quick rebound in May, and is unlikely to fully recover prior to October 2020. Under the reference and pessimistic scenario, continual lockdown (no reopening) could worsen the motor gasoline demand temporarily, but it helps the demand recover to a normal level quicker. Under the optimistic infection scenario, gasoline demand will recover close to the non-pandemic level by October 2020.",
        "DOI": "10.1038/s41560-020-0662-1",
        "paper_author": "Ou S.",
        "affiliation_name": "Oak Ridge National Laboratory",
        "affiliation_city": "Oak Ridge",
        "affiliation_country": "United States",
        "affiliation_id": "60024266",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Mapping croplands of Europe, Middle East, Russia, and Central Asia using Landsat, Random Forest, and Google Earth Engine",
        "publication": "ISPRS Journal of Photogrammetry and Remote Sensing",
        "citied_by": "134",
        "cover_date": "2020-09-01",
        "Abstract": "Accurate and timely information on croplands is important for environmental, food security, and policy studies. Spatially explicit cropland datasets are also required to derive information on crop type, crop yield, cropping intensity, as well as irrigated areas. Large area – defined as continental to global – cropland mapping is challenging due to differential manifestation of croplands, wide range of cultivation practices and limited reference data availability. This study presents the results of a cropland extent mapping of 64 countries covering large parts of Europe, Middle East, Russia and Central Asia. To cover such a vast area, roughly 160,000 Landsat scenes from 3351 footprints between 2014 and 2016 were processed within the Google Earth Engine (GEE) platform. We used a pixel-based Random Forest (RF) machine learning algorithm with a set of satellite data inputs capturing diverse spectral, temporal and topographical characteristics across twelve agroecological zones (AEZs). The reference data to train the classification model were collected from very high spatial resolution imagery (VHRI) and ancillary datasets. The result is a binary map showing cultivated/non-cultivated areas ca. 2015. The map produced an overall accuracy of 93.8% with roughly 14% omission and commission errors for the cropland class based on a large set of independent validation samples. The map suggests the entire study area has a total 546 million hectares (Mha) of net croplands (nearly 30% of global net cropland areas) occupying 18% of the study land area. Comparison between national cropland area estimates from United Nations Food and Agricultural Organizations (FAO) and those derived from this work also showed an R-square value of 0.95. This Landsat-derived 30-m cropland product (GFSAD30) provided 10–30% greater cropland areas compared to UN FAO in the 64 Countries. Finally, the map-to-map comparison between GFSAD30 with several other cropland products revealed that the best similarity matrix was with the 30 m global land cover (GLC30) product providing an overall similarity of 88.8% (Kappa 0.7) with producer's cropland similarity of 89.2% (errors of omissions = 10.8%) and user's cropland similarity of 81.8% (errors of commissions = 8.1%). GFSAD30 captured the missing croplands in GLC30 product around significantly irrigated agricultural areas in Germany and Belgium and rainfed agriculture in Italy. This study also established that the real strengths of GFSAD30 product, compared to other products, were: 1. identifying precise location of croplands, and 2. capturing fragmented croplands. The cropland extent map dataset is available through NASA's Land Processes Distributed Active Archive Center (LP DAAC) at https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30EUCEARUMECE.001, while the training and reference data as well as visualization are available at the Global Croplands <https://croplands.org> website, GEE code is accessible at: https://code.earthengine.google.com/1666e8bed34e0ce2b2aaf1235ad8c6bd.",
        "DOI": "10.1016/j.isprsjprs.2020.06.022",
        "paper_author": "Phalke A.R.",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States",
        "affiliation_id": "60032179",
        "affiliation_state": "WI"
    },
    {
        "paper_title": "Machine learning for research on climate change adaptation policy integration: an exploratory UK case study",
        "publication": "Regional Environmental Change",
        "citied_by": "35",
        "cover_date": "2020-09-01",
        "Abstract": "Understanding how climate change adaptation is integrated into existing policy sectors and organizations is critical to ensure timely and effective climate actions across multiple levels and scales. Studying climate change adaptation policy has become increasingly difficult, particularly given the increasing volume of potentially relevant data available, the validity of existing methods handling large volumes of data, and comprehensiveness of assessing processes of integration across all sectors and public sector organizations over time. This article explores the use of machine learning to assist researchers when conducting adaptation policy research using text as data. We briefly introduce machine learning for text analysis, present the steps of training and testing a neural network model to classify policy texts using data from the UK, and demonstrate its usefulness with quantitative and qualitative illustrations. We conclude the article by reflecting on the merits and pitfalls of using machine learning in our case study and in general for researching climate change adaptation policy.",
        "DOI": "10.1007/s10113-020-01677-8",
        "paper_author": "Biesbroek R.",
        "affiliation_name": "Wageningen University &amp; Research",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60004156",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Multi-Objective reinforcement learning approach for improving safety at intersections with adaptive traffic signal control",
        "publication": "Accident Analysis and Prevention",
        "citied_by": "46",
        "cover_date": "2020-09-01",
        "Abstract": "Adaptive traffic signal control (ATSC) systems improve traffic efficiency, but their impacts on traffic safety vary among different implementations. To improve the traffic safety pro-actively, this study proposes a safety-oriented ATSC algorithm to optimize traffic efficiency and safety simultaneously. A multi-objective deep reinforcement learning framework is utilized as the backend algorithm. The proposed algorithm was trained and evaluated on a simulated isolated intersection built based on real-world traffic data. A real-time crash prediction model was calibrated to provide the safety measure. The performance of the algorithm was evaluated by the real-world signal timing provided by the local jurisdiction. The results showed that the algorithm improves both traffic efficiency and safety compared with the benchmark. A control policy analysis of the proposed ATSC revealed that the abstracted control rules could help the traditional signal controllers to improve traffic safety, which might be beneficial if the infrastructure is not ready to adopt ATSCs. A hybrid controller is also proposed to provide further traffic safety improvement if necessary. To the best of the authors’ knowledge, the proposed algorithm is the first successful attempt in developing adaptive traffic signal system optimizing traffic safety.",
        "DOI": "10.1016/j.aap.2020.105655",
        "paper_author": "Gong Y.",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States",
        "affiliation_id": "60154598",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Enhancing predictions of patient conveyance using emergency call handler free text notes for unconscious and fainting incidents reported to the London Ambulance Service",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "13",
        "cover_date": "2020-09-01",
        "Abstract": "Objective: Pre-hospital emergency medical services use clinical decision support systems (CDSS) to triage calls. Call handlers often supplement this by making free text notes covering key incident information. We investigate whether machine learning approaches using features from such free text notes can improve prediction of unconscious patients who require conveyance. Materials and methods: We analysed a subset of all London Ambulance Service calls that were triaged through the Medical Priority Dispatch System (MPDS) as involving an unconscious or fainting patient in 2018. We use and compare two machine learning algorithms: random forest (RF) and gradient boosting machine (GBM). For each incident, we predict whether the patient will be conveyed to a hospital emergency department or equivalent using as features 1) the MPDS code, 2) the free text notes and 3) the two together. We evaluate model performance using the area under the curve (AUC) metric. Given the imbalance of outcomes (patient conveyed 71 %, not conveyed 29 %), we also consider sensitivity and specificity. Results: Using only the MPDS code resulted in an AUC of 0.57. Using the text notes gave an improved AUC score of 0.63 and combining the two gave an AUC score of 0.64 (scores were similar for RF and GBM). GBM models scored better on sensitivity (0.93 vs 0.62 for RF in the combined model), but specificity was lower (0.17 vs. 0.56 for RF in the combined model). Conclusions: Using information contained in the free text notes made by call handlers in combination with MPDS improves prediction of unconscious and fainting patients requiring conveyance to a hospital emergency department (or equivalent) when compared with machine learning models using MPDS codes only. This suggests there is some useful information in unstructured data captured by emergency call handlers that complements MPDS codes. Quantifying this gain can help inform emergency medical service policy when evaluating the decision to expand or augment existing CDSS.",
        "DOI": "10.1016/j.ijmedinf.2020.104179",
        "paper_author": "Tollinton L.",
        "affiliation_name": "King's College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60011520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Pride and prejudice–What can we learn from peer review?",
        "publication": "Medical Teacher",
        "citied_by": "17",
        "cover_date": "2020-09-01",
        "Abstract": "Objectives: Peer review is a powerful tool that steers the education and practice of medical researchers but may allow biased critique by anonymous reviewers. We explored factors unrelated to research quality that may influence peer review reports, and assessed the possibility that sub-types of reviewers exist. Our findings could potentially improve the peer review process. Methods: We evaluated the harshness, constructiveness and positiveness in 596 reviews from journals with open peer review, plus 46 reviews from colleagues’ anonymously reviewed manuscripts. We considered possible influencing factors, such as number of authors and seasonal trends, on the content of the review. Finally, using machine-learning we identified latent types of reviewer with differing characteristics. Results: Reviews provided during a northern-hemisphere winter were significantly harsher, suggesting a seasonal effect on language. Reviews for articles in journals with an open peer review policy were significantly less harsh than those with an anonymous review process. Further, we identified three types of reviewers: nurturing, begrudged, and blasé. Conclusion: Nurturing reviews were in a minority and our findings suggest that more widespread open peer reviewing could improve the educational value of peer review, increase the constructive criticism that encourages researchers, and reduce pride and prejudice in editorial processes.",
        "DOI": "10.1080/0142159X.2020.1774527",
        "paper_author": "Le Sueur H.",
        "affiliation_name": "Faculty of Biology, Medicine and Health",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60172345",
        "affiliation_state": "Greater Manchester"
    },
    {
        "paper_title": "DeepGuard: Efficient Anomaly Detection in SDN with Fine-Grained Traffic Flow Monitoring",
        "publication": "IEEE Transactions on Network and Service Management",
        "citied_by": "62",
        "cover_date": "2020-09-01",
        "Abstract": "Software-Defined Networking (SDN) leverages the implementation of reliable, flexible and efficient network security mechanisms which make use of novel techniques such as artificial intelligence (AI) and machine learning (ML). In particular, these techniques - together with SDN - are the key enablers for the design of anomaly detection methods which are based on efficient traffic flow monitoring. In this paper, we tackle this problem by proposing an efficient anomaly detection framework, denoted as DeepGuard, which improves the detection performance of cyberattacks in SDN based networks by adopting a fine-grained traffic flow monitoring mechanism. Specifically, the proposed framework utilizes a deep reinforcement learning technique, i.e., Double Deep {Q} -Network (DDQN), to learn traffic flow matching strategies maximizing the traffic flow granularity while proactively protecting the SDN data plane from being overloaded. Afterwards, by implementing the learned optimal traffic flow matching control policy, the most beneficial traffic information for anomaly detection is acquired at runtime - thereby improving the cyberattack detection performance. The performance of the proposed framework is validated by extensive experiments, and the results show that DeepGuard yields significant performance improvements compared to existing traffic flow matching mechanisms regarding the level of traffic flow granularity. In the case of distributed denial-of-service (DDoS) attacks, DeepGuard achieves a remarkable attack detection performance while effectively preventing forwarding performance degradation in the SDN data plane.",
        "DOI": "10.1109/TNSM.2020.3004415",
        "paper_author": "Phan T.V.",
        "affiliation_name": "Technische Universität Chemnitz",
        "affiliation_city": "Chemnitz",
        "affiliation_country": "Germany",
        "affiliation_id": "60008069",
        "affiliation_state": "Sachsen"
    },
    {
        "paper_title": "Promote transit via hardening first-and-last-mile accessibility: Learned from modeling commuters’ transit use",
        "publication": "Transportation Research Part D: Transport and Environment",
        "citied_by": "42",
        "cover_date": "2020-09-01",
        "Abstract": "To understand how transit ridership would be increased via hardening first-and-last mile (F&LM) connections, the paper explores a quantity-based method to measure the effect of F&LM access when estimating workers’ commuting transit use in Hamilton County, Ohio. Considering variations in the spatial distribution of socioeconomics, built environment, and transportation services, a geographically weighted lasso (GWL) based structure is applied in modeling transit use so as to capture spatial heterogeneous role of F&LM access and to deal with local variable multicollinearity. In the GWL model, transit use is formulated as a function of transit service coverage, job accessibility by transit, and other socioeconomic, built environment, and transportation variables. The transit service coverage is articulated with choices of different F&LM modes (i.e., walking and biking), F&LM network connectivity to transit, and land use density; and job accessibility by transit is measured using the number of destination jobs covered by transit and transit journey time to destinations. The GWL modeling results suggest that a 10% growth in population covered by transit and job accessibility by transit can increase transit usage by 5.9% and 6.6% respectively, especially attracting more riders in the urban fringe. Then, the effectiveness of policy interventions such as dense development, promotion of bike usage, and increased bike connectivity in increasing transit ridership are subsequently estimated. Additionally, results indicate that providing improved F&LM access to car-less population, minority, and low-income people who tend to rely more on transit than others is more effective in promoting transit use.",
        "DOI": "10.1016/j.trd.2020.102446",
        "paper_author": "Zuo T.",
        "affiliation_name": "College of Engineering and Applied Science",
        "affiliation_city": "Cincinnati",
        "affiliation_country": "United States",
        "affiliation_id": "60142887",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Characterizing vaping posts on instagram by using unsupervised machine learning",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "38",
        "cover_date": "2020-09-01",
        "Abstract": "Electronic cigarettes (e-cigarettes) usage has surged substantially across the globe, particularly among adolescents and young adults. The ever-increasing prevalence of social media makes it highly convenient to access and engage with content on numerous substances, including e-cigarettes. A comprehensive dataset of 560,414 image posts with a mention of #vaping (shared from 1 June 2019 to 31 October 2019) was retrieved by using the Instagram application-programming interface. Deep neural networks were used to extract image features on which unsupervised machine-learning methods were leveraged to cluster and subsequently categorize the images. Descriptive analysis of associated metadata was further conducted to assess the influence of different entities and the use of hashtags within different categories. Seven distinct categories of vaping related images were identified. A majority of the images (40.4 %) depicted e-liquids, followed by e-cigarettes (15.4 %). Around one-tenth (9.9 %) of the dataset consisted of photos with person(s). Considering the number of likes and comments, images portraying person(s) gained the highest engagement. In almost every category, business accounts shared more posts on average compared to the individual accounts. The findings illustrate the high degree of e-cigarettes promotion on a social platform prevalent among youth. Regulatory authorities should enforce policies to restrict product promotion in youth-targeted social media, as well as require measures to prevent underage users' access to this content. Furthermore, a stronger presence of anti-tobacco portrayals on Instagram by public health agencies and anti-tobacco campaigners is needed.",
        "DOI": "10.1016/j.ijmedinf.2020.104223",
        "paper_author": "Ketonen V.",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland",
        "affiliation_id": "60103653",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "How Big Data Confers Market Power to Big Tech: Leveraging the Perspective of Data Science",
        "publication": "Antitrust Bulletin",
        "citied_by": "16",
        "cover_date": "2020-09-01",
        "Abstract": "Data-hungry applications are central to the largest online platforms. Using a novel approach that leverages data science to inform the economics, we demonstrate how data is a source of market power. We highlight the importance of data heterogeneity, whereby small feature differences translate into large value differences. We examine how concept drift, the existence of a nonstationary relationship between the predictive and target variables, implies that access to a continuous stream of data is competitively advantageous. We analyze how an information bottleneck and high sample complexity in existing applications lead to increasing returns to data. Finally, we show how user interaction control enables personalization that raises switching costs. The combined effect is a potent data barrier to entry that endows substantial market power to only the largest online platforms. Competition policy should focus on enabling entrants unfettered access to vast continuous data streams similar to those available to platform incumbents.",
        "DOI": "10.1177/0003603X20934212",
        "paper_author": "Santesteban C.",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States",
        "affiliation_id": "60015481",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Policy Change and Public Opinion: Measuring Shifting Political Sentiment With Social Media Data",
        "publication": "American Politics Research",
        "citied_by": "24",
        "cover_date": "2020-09-01",
        "Abstract": "This article uses Twitter data and machine-learning methods to analyze the causal impact of the Supreme Court’s legalization of same-sex marriage at the federal level in the United States on political sentiment and discourse toward gay rights. In relying on social media text data, this project constructs a large data set of expressed political opinions in the short time frame before and after the Obergefell v. Hodges decision. Due to the variation in state laws regarding the legality of same-sex marriage prior to the Supreme Court’s decision, I use a difference-in-difference estimator to show that, in those states where the Court’s ruling produced a policy change, there was relatively more negative movement in public opinion toward same-sex marriage and gay rights issues as compared with other states. This confirms previous studies that show Supreme Court decisions polarize public opinion in the short term, extends previous results by demonstrating opinion becomes relatively more negative in states where policy is overturned, and demonstrates how to use social media data to engage in causal analyses.",
        "DOI": "10.1177/1532673X20920263",
        "paper_author": "Adams-Cohen N.J.",
        "affiliation_name": "California Institute of Technology",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States",
        "affiliation_id": "60031581",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Energy-efficient and damage-recovery slithering gait design for a snake-like robot based on reinforcement learning and inverse reinforcement learning",
        "publication": "Neural Networks",
        "citied_by": "42",
        "cover_date": "2020-09-01",
        "Abstract": "Similar to real snakes in nature, the flexible trunks of snake-like robots enhance their movement capabilities and adaptabilities in diverse environments. However, this flexibility corresponds to a complex control task involving highly redundant degrees of freedom, where traditional model-based methods usually fail to propel the robots energy-efficiently and adaptively to unforeseeable joint damage. In this work, we present an approach for designing an energy-efficient and damage-recovery slithering gait for a snake-like robot using the reinforcement learning (RL) algorithm and the inverse reinforcement learning (IRL) algorithm. Specifically, we first present an RL-based controller for generating locomotion gaits at a wide range of velocities, which is trained using the proximal policy optimization (PPO) algorithm. Then, by taking the RL-based controller as an expert and collecting trajectories from it, we train an IRL-based controller using the adversarial inverse reinforcement learning (AIRL) algorithm. For the purpose of comparison, a traditional parameterized gait controller is presented as the baseline and the parameter sets are optimized using the grid search and Bayesian optimization algorithm. Based on the analysis of the simulation results, we first demonstrate that this RL-based controller exhibits very natural and adaptive movements, which are also substantially more energy-efficient than the gaits generated by the parameterized controller. We then demonstrate that the IRL-based controller cannot only exhibit similar performances as the RL-based controller, but can also recover from the unpredictable damage body joints and still outperform the model-based controller, which has an undamaged body, in terms of energy efficiency. Videos can be viewed at https://videoviewsite.wixsite.com/rlsnake.",
        "DOI": "10.1016/j.neunet.2020.05.029",
        "paper_author": "Bing Z.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Encoding primitives generation policy learning for robotic arm to overcome catastrophic forgetting in sequential multi-tasks learning",
        "publication": "Neural Networks",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "Continual learning, a widespread ability in people and animals, aims to learn and acquire new knowledge and skills continuously. Catastrophic forgetting usually occurs in continual learning when an agent attempts to learn different tasks sequentially without storing or accessing previous task information. Unfortunately, current learning systems, e.g., neural networks, are prone to deviate the weights learned in previous tasks after training new tasks, leading to catastrophic forgetting, especially in a sequential multi-tasks scenario. To address this problem, in this paper, we propose to overcome catastrophic forgetting with the focus on learning a series of robotic tasks sequentially. Particularly, a novel hierarchical neural network's framework called Encoding Primitives Generation Policy Learning (E-PGPL) is developed to enable continual learning with two components. By employing a variational autoencoder to project the original state space into a meaningful low-dimensional feature space, representative state primitives could be sampled to help learn corresponding policies for different tasks. In learning a new task, the feature space is required to be close to the previous ones so that previously learned tasks can be protected. Extensive experiments on several simulated robotic tasks demonstrate our method's efficacy to learn control policies for handling sequentially arriving multi-tasks, delivering improvement substantially over some other continual learning methods, especially for the tasks with more diversity.",
        "DOI": "10.1016/j.neunet.2020.06.003",
        "paper_author": "Xiong F.",
        "affiliation_name": "Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60019499",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "What Catalyzes Research Universities to Commit to Interdisciplinary Research?",
        "publication": "Research in Higher Education",
        "citied_by": "21",
        "cover_date": "2020-09-01",
        "Abstract": "For decades, science policy has been promoting interdisciplinary research (IDR), but universities have not responded uniformly. To explain this variation, we integrate insights from the organizational literature, especially research on microfoundations, and highlight the role of both administrators and faculty. We collect and, with the help of machine learning, code vast amounts of textual data from 156 universities nationwide to measure universities’ structural commitment to IDR as well as key explanatory variables, including top-down administrative support for, and bottom-up faculty engagement with, IDR. We integrate these measures with extant data from the Survey of Earned Doctorates, Higher Education R&D Expenditures Survey, NIH, NSF, and IPEDS to analyze how internal university dynamics influence the degree to which a university commits to IDR. Our results reveal that the level of structural commitment to IDR differs at universities with and without medical schools, as do the precursors to this commitment. At universities with medical schools, we find that bottom-up engagement is positively associated with structural commitment to IDR, and that status moderates the relationship between top-down administrative support and structural commitment to IDR. For universities with low levels of supportive administrative discourse status significantly impacted their structural commitment to IDR. At universities without medical schools, top-down support and bottom-up engagement are interrelated and mutually reinforcing such that universities with high levels of both administrative support and interdisciplinary research grants have higher levels of structural commitment to IDR. We discuss the implications of these findings for university administrators, policy makers, and researchers.",
        "DOI": "10.1007/s11162-020-09603-x",
        "paper_author": "Barringer S.N.",
        "affiliation_name": "Southern Methodist University",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States",
        "affiliation_id": "60017536",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Deep convolutional neural networks to monitor coralligenous reefs: Operationalizing biodiversity and ecological assessment",
        "publication": "Ecological Informatics",
        "citied_by": "14",
        "cover_date": "2020-09-01",
        "Abstract": "Monitoring the ecological status of natural habitats is crucial to the conservation process, as it enables the implementation of efficient conservation policies. Nowadays, it is increasingly possible to automate species identification, given the availability of very large image databases and state-of-the-art computational power which makes the training of automated machine learning-based classification models an increasingly viable tool for monitoring marine habitats. Coralligenous reefs are an underwater habitat of particular importance, found in the Mediterranean. This habitat is of a similar biocomplexity to coral reefs. They have been monitored in French waters since 2010 using manually annotated photo quadrats (RECOR monitoring network). Based on the large database of annotations accumulated therein, we have trained convolutional neural networks to automatically recognise coralligenous species using the data gathered from photo quadrats. Previous studies conducted on similar habitats performed well, but were only able to consider a limited number of classes, resulting in a very coarse description of these often-complex habitats. We therefore designed a custom network based on off-the-shelf architectures which is able to discriminate between 61 classes with 72.59% accuracy. Our results showed that confusion errors were for the most part taxonomically coherent, showing accuracy performances of 84.47% when the task was simplified to 15 major categories, thereby outperforming the human accuracy previously recorded in a similar study. In light of this, we built a semi-automated tool to reject unsure results and reduce error risk, for when a higher level of accuracy is required. Finally, we used our model to assess the biodiversity and ecological status of coralligenous reefs with the Coralligenous Assemblage Index (CAI) and the Shannon Index. Our results showed that whilst the prediction of the CAI was only moderately accurate (pearson correlation between observed and predicted CAI = 0.61), the prediction of Shannon Index was more accurate (pearson correlation = 0.74). In conclusion, it will be argued that the approach outlined by this study offers a cost and time-effective tool for the analysis of coralligenous assemblages which is suitable for integration into a large-scale monitoring network of this habitat.",
        "DOI": "10.1016/j.ecoinf.2020.101110",
        "paper_author": "Marre G.",
        "affiliation_name": "Andromède Océanologie",
        "affiliation_city": "Montpellier",
        "affiliation_country": "France",
        "affiliation_id": "117066013",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Spatiotemporal distributions of surface ozone levels in China from 2005 to 2017: A machine learning approach",
        "publication": "Environment International",
        "citied_by": "163",
        "cover_date": "2020-09-01",
        "Abstract": "In recent years, ground-level ozone has become a severe ambient pollutant in major urban areas of China, which has adverse impacts on population health. However, in-situ measurements of the ozone concentration before 2013 in China are quite scarce, which cannot facilitate the assessment of the long-term trends and effects of ozone pollution. In this study, we used daily maximum 8-hour average (MDA8) ozone observations from 2013 to 2017 combined with concurrent ozone retrievals, aerosol reanalysis, meteorological parameters, and land-use data to establish a nationwide MDA8 prediction model based on the eXtreme Gradient Boosting (XGBoost) algorithm. The model achieves high prediction accuracy compared with other studies, with R2 values for the by-year, site-based, and sample-based cross-validation (CV) schemes of 0.61, 0.64, and 0.78, respectively, at the daily level. External testing with regional measurements from 2005 to 2012 and nationwide data in 2018 have shown that the model is robust and reliable for historical data prediction, with external model testing R2 values ranging from 0.60 to 0.87 at the month level in different years. Using the final estimator, we obtained nationwide monthly mean ozone concentrations from 2005 to 2012 and daily MDA8 ozone concentrations from 2013 to 2017 at a resolution of 0.1° × 0.1°. According to the average number of days exceeding the standard and the average of the 90th percentile of the MDA8 ozone concentrations, the Beijing-Tianjin-Hebei (BTH), the Yangtze River Delta, the Pearl River Delta, the Jianghan Plain, the Sichuan Basin, and the Northeast Plain regions were identified as pollution hotspots. During the research period, the overall ozone levels fluctuated slightly, and their trends were not spatially continuous. There was a significant increasing trend in the BTH region by 1.37 (95% CI: 0.46,2.29) μg/m3/year between 2013 and 2017. In 2017, 26.24% of the population lived in areas exceeding the Chinese grade II national air quality standard, which shows that ozone pollution has posed an obvious threat to population health in China. Our products will provide reliable support for future long-term nationwide health impact studies and policy-making for pollution control and prevention.",
        "DOI": "10.1016/j.envint.2020.105823",
        "paper_author": "Liu R.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60033100",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Slipping through the net: Can data science approaches help target clean cooking policy interventions?",
        "publication": "Energy Policy",
        "citied_by": "7",
        "cover_date": "2020-09-01",
        "Abstract": "Reliance on solid biomass cooking fuels in India has negative health and socio-economic consequences for households, yet policies aimed at promoting uptake of LPG for cooking have not always been effective at promoting sustained transition to cleaner cooking amongst intended beneficiaries. This paper uses a two step approach combining predictive and descriptive analyses of the IHDS panel dataset to identify different groups of households that switched stove between 2004/5 and 2011/12. A tree-based ensemble machine learning predictive analysis identifies key determinants of a switch from biomass to non-biomass stoves. A descriptive clustering analysis is used to identify groups of stove-switching households that follow different transition pathways. There are three key findings of this study: firstly non-income determinants of stove switching do not have a linear effect on stove switching, in particular variables on time of use and appliance ownership which offer a proxy for household energy practices; secondly location specific factors including region, infrastructure availability, and dwelling quality are found to be key determinants and as a result policies must be tailored to take into account local variations; thirdly some groups of households that adopt non-biomass stoves continue using biomass and interventions should be targeted to reduce their biomass use.",
        "DOI": "10.1016/j.enpol.2020.111650",
        "paper_author": "Neto-Bradley A.P.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Phase portraits as movement primitives for fast humanoid robot control",
        "publication": "Neural Networks",
        "citied_by": "6",
        "cover_date": "2020-09-01",
        "Abstract": "Currently, usual approaches for fast robot control are largely reliant on solving online optimal control problems. Such methods are known to be computationally intensive and sensitive to model accuracy. On the other hand, animals plan complex motor actions not only fast but seemingly with little effort even on unseen tasks. This natural sense to infer temporal dynamics and coordination motivates us to approach robot control from a motor skill learning perspective to design fast and computationally light controllers that can be learned autonomously by the robot under mild modeling assumptions. This article introduces Phase Portrait Movement Primitives (PPMP), a primitive that predicts dynamics on a low dimensional phase space which in turn is used to govern the high dimensional kinematics of the task. The stark difference with other primitive formulations is a built-in mechanism for phase prediction in the form of coupled oscillators that replaces model-based state estimators such as Kalman filters. The policy is trained by optimizing the parameters of the oscillators whose output is connected to a kinematic distribution in the form of a phase portrait. The drastic reduction in dimensionality allows us to efficiently train and execute PPMPs on a real human-sized, dual-arm humanoid upper body on a task involving 20 degrees-of-freedom. We demonstrate PPMPs in interactions requiring fast reactions times while generating anticipative pose adaptation in both discrete and cyclic tasks.",
        "DOI": "10.1016/j.neunet.2020.04.007",
        "paper_author": "Maeda G.",
        "affiliation_name": "Advanced Telecommunications Research Institute International (ATR)",
        "affiliation_city": "Kyoto",
        "affiliation_country": "Japan",
        "affiliation_id": "60001271",
        "affiliation_state": "Kyoto"
    },
    {
        "paper_title": "Corporate environmental performance prediction in China: An empirical study of energy service companies",
        "publication": "Journal of Cleaner Production",
        "citied_by": "39",
        "cover_date": "2020-09-01",
        "Abstract": "Businesses are constrained by and dependent upon nature and institutional context. The global climate crisis has put pressure on and increased firm sensitivity to environmental issues. Predicting corporate environmental performance can help plan for environmental impact mitigation by adjusting organizational practices. Lack of environment-related information makes it difficult to make such predictions. This paper tends to provide useful insights into corporate environmental performance among firms to facilitate better environmental management for both government and firms. A theoretical framework informed by the natural-resource-based view (NRBV) of the firm and institutional theory is used to identify variables for predicting corporate environmental performance. Five dimensions including institutional context, governance capability, information management capability, system capability, and technology-related capability, populated with 14 variables are used to empirically investigate the relationship of these variables with corporate environmental performance. Using 1100 data points on energy service companies (ESCOs) from 2011 to 2015 in mainland China, the Extreme Gradient Boosting (XGBoost) algorithm, a statistical nonlinear machine learning approach, is utilized to predict corporate environmental performance. The results demonstrate that the XGBoost model can be effective for ESCO environmental performance prediction, with satisfactory prediction accuracy. This study also adopted the SHapley Additive exPlanations (SHAP) values for model interpretation, indicating that total assets, amount of proactive environmental costs, proportion of technicians and number of patents contribute most to corporate environmental performance. Several policies and environmental strategies for improving corporate environmental performance in the ESCO industry are derived from this analysis.",
        "DOI": "10.1016/j.jclepro.2020.121395",
        "paper_author": "Zheng S.",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008928",
        "affiliation_state": "Hong Kong"
    },
    {
        "paper_title": "Measuring megaregional structure in the Pearl River Delta by mobile phone signaling data: A complex network approach",
        "publication": "Cities",
        "citied_by": "71",
        "cover_date": "2020-09-01",
        "Abstract": "Understanding the spatial structure of a megaregion, like the Pearl River Delta (PRD) or the emerging Guangdong-Hong Kong-Macao Greater Bay Area in China, is important for regional planning and governance. However, few studies have conceptualized varying regional spatial structure via the network perspective. This study thus develops a complex network approach, particularly by adopting a novel machine-learning-based weighted stochastic block model and visual analytics, to measuring potential spatial mesoscale structures in PRD. We build a finer-grained commuting network with 60 sub-city divisions as nodes by aggregating a large set of mobile phone signaling data collected in 2018. Results detect a hybrid polycentric configuration of two community components, each with a core-periphery structure inside. One community centered on Guangzhou has a semi-core commuting belt alongside the intercity railway and high-speed rails, while the other centered on Shenzhen exhibits a concentric commuting ring. Intercity transport infrastructure, spatial proximity, and regional integration policies appear to play important roles in shaping spatial and network structures in the megaregion, while the constraint of administrative boundary is dissolving. This study finally discusses the implication for regional coordination policies and spatial planning strategies in PRD and the Greater Bay Area.",
        "DOI": "10.1016/j.cities.2020.102809",
        "paper_author": "Zhang W.",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60014966",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Unsupervised learning for deploying smart charging public infrastructure for electric vehicles in sprawling cities",
        "publication": "Journal of Cleaner Production",
        "citied_by": "13",
        "cover_date": "2020-09-01",
        "Abstract": "This paper presents a novel methodology to study the deployment of public smart charging stations (CS) of electric vehicles (EV) in a sprawling Latin American city. A relevant difference between developed and emerging economies is the reduced access to home charging in emerging economies, which is the case in Latin American cities. Thus, developing public charging stations represents a crucial factor in the mass adoption of EVs by road commuters. We develop herein a methodology for optimizing the deployment of smart charging stations under the sprawling phenomenon perspective. Our method comprises two steps. In step one, we applied principal component analysis (PCA) to facilitate the analysis of a sprawling city, and then we define candidates for potential locations from ‘demand clusters’ within an urbanized area, by K-means clustering analysis. In the second step, a stochastic programming model was employed to optimize the integration of infrastructural facilities with distributed energy resources (DERs) and EV charging stations using a collaborative strategy to minimize its energy consumption cost under demand uncertainty. We demonstrate the capabilities of this approach through a case study in the city of Lima. Experimental results reveal managerial insights for different stakeholders (i.e., government, industry, academia, and civil society) to promote policies, investment, and incentives.",
        "DOI": "10.1016/j.jclepro.2020.121926",
        "paper_author": "Marino C.A.",
        "affiliation_name": "CENTRUM PUCP Escuela de Negocios",
        "affiliation_city": "Lima",
        "affiliation_country": "Peru",
        "affiliation_id": "60199399",
        "affiliation_state": "Lima"
    },
    {
        "paper_title": "Deep reinforcement learning for pedestrian collision avoidance and human-machine cooperative driving",
        "publication": "Information Sciences",
        "citied_by": "75",
        "cover_date": "2020-09-01",
        "Abstract": "With the development of intelligent driving technology, human-machine cooperative driving is significant to improve driving safety in abnormal situations, such as distraction or incorrect operations of drivers. For human-machine cooperative driving, the capacity of pedestrian collision avoidance is fundamental and important. This paper proposes a novel learning-based human-machine cooperative driving scheme (L-HMC) with active collision avoidance capacity using deep reinforcement learning. Firstly, an improved deep Q-network (DQN) method is designed to learn the optimal driving policy for pedestrian collision avoidance. In the improved DQN method, two replay buffers with nonuniform samples are designed to shorten the learning process of the optimal driving policy. Then, a human-machine cooperative driving scheme is proposed to assist human drivers with the learned driving policy for pedestrian collision avoidance when the driving behavior of human drivers is dangerous to the pedestrian. The effectiveness of the human-machine cooperative driving scheme is verified on the simulation platform PreScan using a real vehicle dynamic model. The results demonstrate that the deep reinforcement learning-based method can learn an effective driving policy for pedestrian collision avoidance with a fast convergence rate. Meanwhile, the proposed human-machine cooperative driving scheme L-HMC can avoid potential pedestrian collisions through flexible policies in typical scenarios, therefore improving driving safety.",
        "DOI": "10.1016/j.ins.2020.03.105",
        "paper_author": "Li J.",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60024350",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Conversational receptiveness: Improving engagement with opposing views",
        "publication": "Organizational Behavior and Human Decision Processes",
        "citied_by": "78",
        "cover_date": "2020-09-01",
        "Abstract": "We examine “conversational receptiveness” – the use of language to communicate one's willingness to thoughtfully engage with opposing views. We develop an interpretable machine-learning algorithm to identify the linguistic profile of receptiveness (Studies 1A-B). We then show that in contentious policy discussions, government executives who were rated as more receptive - according to our algorithm and their partners, but not their own self-evaluations - were considered better teammates, advisors, and workplace representatives (Study 2). Furthermore, using field data from a setting where conflict management is endemic to productivity, we show that conversational receptiveness at the beginning of a conversation forestalls conflict escalation at the end. Specifically, Wikipedia editors who write more receptive posts are less prone to receiving personal attacks from disagreeing editors (Study 3). We develop a “receptiveness recipe” intervention based on our algorithm. We find that writers who follow the recipe are seen as more desirable partners for future collaboration and their messages are seen as more persuasive (Study 4). Overall, we find that conversational receptiveness is reliably measurable, has meaningful relational consequences, and can be substantially improved using our intervention (183 words).",
        "DOI": "10.1016/j.obhdp.2020.03.011",
        "paper_author": "Yeomans M.",
        "affiliation_name": "Harvard Business School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60019666",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Expanded Access as a source of real-world data: An overview of FDA and EMA approvals",
        "publication": "British Journal of Clinical Pharmacology",
        "citied_by": "36",
        "cover_date": "2020-09-01",
        "Abstract": "Aims: To identify, characterize and compare all Food and Drug Administration (FDA) and European Medicines Agency (EMA) approvals that included real-world data on efficacy from expanded access (EA) programmes. Methods: Cross-sectional study of FDA (1955–2018) and EMA (1995–2018) regulatory approval documentation. We automated searching for terms related to EA in 22,506 documents using machine learning techniques. We included all approvals where EA terms appeared in the regulatory documentation. Our main outcome was the inclusion of EA data as evidence of clinical efficacy. Characterization was based on approval date, disease area, orphan designation and whether the evidence was supportive or pivotal. Results: EA terms appeared in 693 out of 22,506 (3.1%) documents, which referenced 187 approvals. For 39 approvals, data from EA programmes were used to inform on clinical efficacy. The yearly number of approvals with EA data increased from 1.25 for 1993–2013 to 4.6 from 2014–2018. In 13 cases, these programmes formed the main evidence for approval. Of these, patients in EA programmes formed over half (median 71%, interquartile range: 34–100) of the total patient population available for efficacy evaluation. Almost all (12/13) approvals were granted orphan designation. In 8/13, there were differences between regulators in approval status and valuation of evidence. Strikingly, 4 treatments were granted approval based solely on efficacy from EA. Conclusion: Sponsors and regulators increasingly include real-world data from EA programmes in the efficacy profile of a treatment. The indications of the approved treatments are characterized by orphan designation and high unmet medical need.",
        "DOI": "10.1111/bcp.14284",
        "paper_author": "Polak T.B.",
        "affiliation_name": "Erasmus MC",
        "affiliation_city": "Rotterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60032114",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Assessment of agricultural energy consumption of Turkey by MLR and Bayesian optimized SVR and GPR models",
        "publication": "Journal of Forecasting",
        "citied_by": "26",
        "cover_date": "2020-09-01",
        "Abstract": "Agricultural productivity highly depends on the cost of energy required for cultivation. Thus prior knowledge of energy consumption is an important step for energy planning and policy development in agriculture. The aim of the present study is to evaluate the application potential of multiple linear regression (MLR) and machine learning tools such as support vector regression (SVR) and Gaussian process regression (GPR) to forecast the agricultural energy consumption of Turkey. In the development of the models, widespread indicators such as agricultural value-added, total arable land, gross domestic product share of agriculture, and population data were used as input parameters. Twenty-eight-year historical data from 1990 to 2017 were utilized for the training and testing stages of the models. A Bayesian optimization method was applied to improve the prediction capability of SVR and GPR models. The performance of the models was measured by various statistical tools. The results indicated that the Bayesian optimized GPR (BGPR) model with exponential kernel function showed a superior prediction capability over MLR and Bayesian optimized SVR model. The root mean square error, mean absolute deviation, mean absolute percentage error, and coefficient of determination (R2) values for the BGPR model were determined as 0.0022, 0.0005, 0.2041, and 0.9999 in the training phase and 0.0452, 0.0310, 7.7152, and 0.9677 in the testing phase, respectively. As a result, it can be concluded that the proposed BGPR model is an efficient technique and has the potential to predict agricultural energy consumption with high accuracy.",
        "DOI": "10.1002/for.2673",
        "paper_author": "Ceylan Z.",
        "affiliation_name": "Samsun University",
        "affiliation_city": "Samsun",
        "affiliation_country": "Turkey",
        "affiliation_id": "60193849",
        "affiliation_state": "Samsun"
    },
    {
        "paper_title": "Failure prediction of tasks in the cloud at an earlier stage: a solution based on domain information mining",
        "publication": "Computing",
        "citied_by": "13",
        "cover_date": "2020-09-01",
        "Abstract": "In a large-scale data center, it is vital to precisely recognize the termination statuses of applications at an early stage. In recent years, many machine learning techniques have been applied to this issue, which is beneficial for optimizing the scheduling policy and improving the efficiency of resource utilization. However, if the application’s dynamic information is insufficient at the early stage, the generalization performance of the machine learning model will be lessened, and the prediction accuracy could be low. To overcome this problem, a novel failure prediction method that is based on the association relationships between similar jobs is proposed in this paper to jointly predict task’s termination statuses at an earlier stage. The similar jobs whose tasks have similar changing modes of consumed resources, an inherent structural correlation may exist, and the correlation information is significant for improving the prediction model’s generalization performance. First, a job clustering algorithm is proposed for identifying the jobs with higher similarity from jobs that have various numbers of tasks. Second, based on the job clustering results, the robust multi-task learning algorithm is introduced to effectively utilize the domain information among jobs (i.e. interactional relationship among jobs on the termination statuses of task). Experiments are conducted on a Google cluster workload traces dataset. The results show that the proposed method can realize higher prediction accuracy, lower misjudgment rate, and higher predictive stability than several state-of-the-art methods at 1/3 the running time of the tasks.",
        "DOI": "10.1007/s00607-020-00800-1",
        "paper_author": "Liu C.",
        "affiliation_name": "Henan Normal University",
        "affiliation_city": "Xinxiang",
        "affiliation_country": "China",
        "affiliation_id": "60029943",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "Optimal forecast combination based on ensemble empirical mode decomposition for agricultural commodity futures prices",
        "publication": "Journal of Forecasting",
        "citied_by": "61",
        "cover_date": "2020-09-01",
        "Abstract": "Improving the prediction accuracy of agricultural product futures prices is important for investors, agricultural producers, and policymakers. This is to evade risks and enable government departments to formulate appropriate agricultural regulations and policies. This study employs the ensemble empirical mode decomposition (EEMD) technique to decompose six different categories of agricultural futures prices. Subsequently, three models—support vector machine (SVM), neural network (NN), and autoregressive integrated moving average (ARIMA)—are used to predict the decomposition components. The final hybrid model is then constructed by comparing the prediction performance of the decomposition components. The predicting performance of the combination model is then compared with the benchmark individual models: SVM, NN, and ARIMA. Our main interest in this study is on short-term forecasting, and thus we only consider 1-day and 3-day forecast horizons. The results indicate that the prediction performance of the EEMD combined model is better than that of individual models, especially for the 3-day forecasting horizon. The study also concluded that the machine learning methods outperform the statistical methods in forecasting high-frequency volatile components. However, there is no obvious difference between individual models in predicting low-frequency components.",
        "DOI": "10.1002/for.2665",
        "paper_author": "Fang Y.",
        "affiliation_name": "South China Agricultural University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60032203",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Vision-Based Obstacle Avoidance for UAVs via Imitation Learning with Sequential Neural Networks",
        "publication": "International Journal of Aeronautical and Space Sciences",
        "citied_by": "19",
        "cover_date": "2020-09-01",
        "Abstract": "This paper explores the feasibility of a framework for vision-based obstacle avoidance techniques that can be applied to unmanned aerial vehicles, where such decision-making policies are trained upon supervision of actual human flight data. The neural networks are trained based on aggregated flight data from human experts, learning the implicit policy for visual obstacle avoidance by extracting the necessary features within the image. The images and flight data are collected from a simulated environment provided by Gazebo, and Robot Operating System is used to provide the communication nodes for the framework. The framework is tested and validated in various environments with respect to four types of neural network including fully connected neural networks, two- and three-dimensional convolutional neural networks (CNNs), and recurrent neural networks (RNNs). Among the networks, sequential neural networks (i.e., 3D-CNNs and RNNs) provide the better performance due to its ability to explicitly consider the dynamic nature of the obstacle avoidance problem.",
        "DOI": "10.1007/s42405-020-00254-x",
        "paper_author": "Park B.",
        "affiliation_name": "Rensselaer Polytechnic Institute",
        "affiliation_city": "Troy",
        "affiliation_country": "United States",
        "affiliation_id": "60025534",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Improving coordination in small-scale multi-agent deep reinforcement learning through memory-driven communication",
        "publication": "Machine Learning",
        "citied_by": "40",
        "cover_date": "2020-09-01",
        "Abstract": "Deep reinforcement learning algorithms have recently been used to train multiple interacting agents in a centralised manner whilst keeping their execution decentralised. When the agents can only acquire partial observations and are faced with tasks requiring coordination and synchronisation skills, inter-agent communication plays an essential role. In this work, we propose a framework for multi-agent training using deep deterministic policy gradients that enables concurrent, end-to-end learning of an explicit communication protocol through a memory device. During training, the agents learn to perform read and write operations enabling them to infer a shared representation of the world. We empirically demonstrate that concurrent learning of the communication device and individual policies can improve inter-agent coordination and performance in small-scale systems. Our experimental results show that the proposed method achieves superior performance in scenarios with up to six agents. We illustrate how different communication patterns can emerge on six different tasks of increasing complexity. Furthermore, we study the effects of corrupting the communication channel, provide a visualisation of the time-varying memory content as the underlying task is being solved and validate the building blocks of the proposed memory device through ablation studies.",
        "DOI": "10.1007/s10994-019-05864-5",
        "paper_author": "Pesce E.",
        "affiliation_name": "University of Warwick",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022020",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "Dynamic Beam Hopping Method Based on Multi-Objective Deep Reinforcement Learning for Next Generation Satellite Broadband Systems",
        "publication": "IEEE Transactions on Broadcasting",
        "citied_by": "144",
        "cover_date": "2020-09-01",
        "Abstract": "When regarding the inherent uncertainty of differentiated services requirements as well as the non-uniform spatial distribution of capacity requests, it is essential to flexibility adjust resources of the satellite to satisfy the different conditions. How to match the system capacity demand with efficient utilization of beam is a brand-new challenge. The convention beam hopping methods ignores the intrinsic correlation between decisions, do not consider the long-term reward, and only achieve the optimal solution at the current time. Therefore, system complexity increases significantly as the increase of the demand for differentiated services or beam number. This paper investigates the optimal policy for beam hopping in DVB-S2X satellite with multiple purposes of assuring the fairness of each beam services, minimizing the delay of real-time services transmission, and maximizing the throughput of non-instant services transmission. Since wireless channel conditions, differentiated services arrival rates have stochastic properties, and the multi-beam satellite environment's dynamics are unknown, the model-free multi-objective deep reinforcement learning approach is used to learn the optimal policy through interactions with the situation. To solve the problem with action dimensional disaster, a novel multi-action selection method based on a Double-Loop Learning (DLL) is proposed. Moreover, the multi-dimensional state is reformulated and obtained by the deep neural network. Under realistic conditions achieving evaluation results demonstrate that the proposed method can pursue multiple objectives simultaneously, and it can also allocate resource intelligently adapting to the user requirements and channel conditions.",
        "DOI": "10.1109/TBC.2019.2960940",
        "paper_author": "Hu X.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Estimating individualized treatment regimes from crossover designs",
        "publication": "Biometrics",
        "citied_by": "1",
        "cover_date": "2020-09-01",
        "Abstract": "The field of precision medicine aims to tailor treatment based on patient-specific factors in a reproducible way. To this end, estimating an optimal individualized treatment regime (ITR) that recommends treatment decisions based on patient characteristics to maximize the mean of a prespecified outcome is of particular interest. Several methods have been proposed for estimating an optimal ITR from clinical trial data in the parallel group setting where each subject is randomized to a single intervention. However, little work has been done in the area of estimating the optimal ITR from crossover study designs. Such designs naturally lend themselves to precision medicine since they allow for observing the response to multiple treatments for each patient. In this paper, we introduce a method for estimating the optimal ITR using data from a 2 × 2 crossover study with or without carryover effects. The proposed method is similar to policy search methods such as outcome weighted learning; however, we take advantage of the crossover design by using the difference in responses under each treatment as the observed reward. We establish Fisher and global consistency, present numerical experiments, and analyze data from a feeding trial to demonstrate the improved performance of the proposed method compared to standard methods for a parallel study design.",
        "DOI": "10.1111/biom.13186",
        "paper_author": "Nguyen C.T.",
        "affiliation_name": "UNC Gillings School of Global Public Health",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States",
        "affiliation_id": "60016639",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Two-stage optimization for machine learning workflow",
        "publication": "Information Systems",
        "citied_by": "18",
        "cover_date": "2020-09-01",
        "Abstract": "Machine learning techniques play a preponderant role in dealing with massive amount of data and are employed in almost every possible domain. Building a high quality machine learning model to be deployed in production is a challenging task, from both, the subject matter experts and the machine learning practitioners. For a broader adoption and scalability of machine learning systems, the construction and configuration of machine learning workflow need to gain in automation. In the last few years, several techniques have been developed in this direction, known as AUTOML. In this paper, we present a two-stage optimization process to build data pipelines and configure machine learning algorithms. First, we study the impact of data pipelines compared to algorithm configuration in order to show the importance of data preprocessing over hyperparameter tuning. The second part presents policies to efficiently allocate search time between data pipeline construction and algorithm configuration. Those policies are agnostic from the metaoptimizer. Last, we present a metric to determine if a data pipeline is specific or independent from the algorithm, enabling fine-grain pipeline pruning and meta-learning for the coldstart problem.",
        "DOI": "10.1016/j.is.2019.101483",
        "paper_author": "Quemy A.",
        "affiliation_name": "IBM Polska Sp. z o.o.",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60108032",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting likelihood of legitimate data loss in email DLP",
        "publication": "Future Generation Computer Systems",
        "citied_by": "15",
        "cover_date": "2020-09-01",
        "Abstract": "The volume and variety of data collected for modern organisations has increased significantly over the last decade necessitating the detection and prevention of disclosure of sensitive data. Data loss prevention is an embedded process used to protect against disclosure of sensitive data to external uncontrolled environments. A typical Data Loss Prevention (DLP) system uses custom policies to identify and prevent accidental and malicious data leakage producing large number of security alerts including significant volume of false positives. Consequently, identifying legitimate data loss can be very challenging as each incident comprises of different characteristics often requiring extensive intervention by a domain expert to review alerts individually. This limits the ability to detect data loss alerts in real-time making organisations vulnerable to financial and reputational damages. The aim of this research is to strengthen data loss detection capabilities of a DLP system by implementing a machine learning model to predict the likelihood of legitimate data loss. We conducted extensive experimentation using Decision Tree and Random Forest algorithms with historical email incident data collected by a globally established telecommunication enterprise. The final model produced with Random Forest algorithm was identified as the most effective as it was successfully able to predict approximately 95% data loss incidents accurately with an average true positive value of 90%. Furthermore, the proposed solution successfully enables identification of legitimate data loss in email DLP whilst facilitating prioritisation of real data loss through human-understandable explanation of the decision thereby improving the efficiency of the process.",
        "DOI": "10.1016/j.future.2019.11.004",
        "paper_author": "Faiz M.F.",
        "affiliation_name": "University of West London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60004814",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Using machine learning approaches to predict high-cost chronic obstructive pulmonary disease patients in China",
        "publication": "Health Informatics Journal",
        "citied_by": "25",
        "cover_date": "2020-09-01",
        "Abstract": "The accurate identification and prediction of high-cost Chronic obstructive pulmonary disease (COPD) patients is important for addressing the economic burden of COPD. The objectives of this study were to use machine learning approaches to identify and predict potential high-cost patients and explore the key variables of the forecasting model, by comparing differences in the predictive performance of different variable sets. Machine learning approaches were used to estimate the medical costs of COPD patients using the Medical Insurance Data of a large city in western China. The prediction models used were logistic regression, random forest (RF), and extreme gradient boosting (XGBoost). All three models had good predictive performance. The XGBoost model outperformed the others. The areas under the ROC curve for Logistic Regression, RF and XGBoost were 0.787, 0.792 and 0.801. The precision and accuracy metrics indicated that the methods achieved correct and reliable results. The results of this study can be used by healthcare data analysts, policy makers, insurers, and healthcare planners to improve the delivery of health services.",
        "DOI": "10.1177/1460458219881335",
        "paper_author": "Luo L.",
        "affiliation_name": "Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60016521",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "An Interpretable Algorithm on Post-injury Health Service Utilization Patterns to Predict Injury Outcomes",
        "publication": "Journal of Occupational Rehabilitation",
        "citied_by": "8",
        "cover_date": "2020-09-01",
        "Abstract": "Purpose Post-injury health service utilization (HSU) contributes to injury outcomes, but limited studies investigated their relationship. This study aims to group injured patients in transport accidents based on minimal historical information of their HSU so that the groups are meaningfully associated with the outcome of interest. Methods The data include 20,692 injured patients who had compensation claims over 3 years. We propose a hybrid approach, combining unsupervised and supervised machine learning methods. Based on the first week post-injury data, we identify a proper clustering of patients best associated with total cost to recovery, as well as the discovery of HSU patterns. This allows developing models to accurately predict the outcome of interest using the discovered patterns. Furthermore, we propose to use decision tree classifiers to accurately classify future patients into the discovered clusters using their first week post-injury information. Results Our hybrid approach has identified eight patient groups. The compactness of the resulted clusters, assessed by Average Silhouette Width metric, is 0.71 indicating well-defined clusters. The resulted patient groups are highly predictive of injury outcomes. They improve the cost predictability more than twice in comparison with predictors such as gender, age and injury type. These groups also have substantial association with patients’ recovery. The transparency and interpretability of decision trees allow integrating the resulting classification rules conveniently in operational processes. Conclusions This study provides a framework to discover knowledge and useful insights for health service providers and policy makers to control injury outcomes, and consequently to reduce the severity of transport accidents.",
        "DOI": "10.1007/s10926-019-09863-0",
        "paper_author": "Akbarzadeh Khorshidi H.",
        "affiliation_name": "School of Computing and Information Systems",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118847",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Optimal setpoint learning of a thruster-assisted position mooring system using a deep deterministic policy gradient approach",
        "publication": "Journal of Marine Science and Technology (Japan)",
        "citied_by": "2",
        "cover_date": "2020-09-01",
        "Abstract": "Thruster-assisted position mooring (PM) systems use both mooring lines and thrusters for station keeping of marine structures in ocean environments. To operate in an energy-efficient manner in moderate sea conditions, setpoints need to be appropriately chosen for the setpoint controller, so that the mooring system counteracts main environmental loads, while the thrusters reduce oscillatory motions of the marine structure. In this paper, reinforcement learning is used to design a decision-making agent for setpoint selection. In particular, a deep deterministic policy gradient (DDPG) approach is adopted with the powerful actor–critic architecture to continuously modify the setpoint setting at an optimal position. Extensive numerical experiments demonstrated that with the DDPG-based PM system, the intelligent agent is able to successfully identify the optimal positioning region in an unknown and stochastic environment, and the power consumption of the thrusters is maintained at a considerably low level.",
        "DOI": "10.1007/s00773-019-00678-5",
        "paper_author": "Yu S.",
        "affiliation_name": "State Key Laboratory of Ocean Engineering",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60123520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Evaluating smart grid renewable energy accommodation capability with uncertain generation using deep reinforcement learning",
        "publication": "Future Generation Computer Systems",
        "citied_by": "30",
        "cover_date": "2020-09-01",
        "Abstract": "Due to environment-friendliness, renewable energy like solar power and wind power is more and more introduced to energy systems all over the world. Simultaneously, high penetrations of wind and solar generation also have brought severe curtailment of wind and solar. How to alleviate curtailment of wind and solar is a crucial problem in evaluating accommodation capability of renewable energy, which reflects the extent of utilization of renewable energy and economic benefits. The uncertainty of renewable energy brings challenges to precisely describe renewable generation, which leads to difficulty in designing effective mechanisms for accommodation capability of renewable energy. Existing work suffers from high computation overhead from frequently updated data, and low precision of describing renewable energy, which leads to less effective policies for renewable energy accommodation and underestimated accommodation capability. To make the most of renewable energy, an algorithm AccCap-DRL based on deep reinforcement learning is proposed. AccCap-DRL partitions a distribution into segments by time intervals, employs WGAN to describe distributions of renewable energy data, and employs DDPG to obtain approximate policies for renewable energy accommodation in different scenarios. Simulation results from real power generation and users’ demand data show high effectiveness of the proposed algorithm, and high efficiency of evaluating accommodation capability.",
        "DOI": "10.1016/j.future.2019.09.036",
        "paper_author": "Liu Y.",
        "affiliation_name": "Heilongjiang University",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60033495",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Adaptive image-based visual servoing for hovering control of quad-rotor",
        "publication": "IEEE Transactions on Cognitive and Developmental Systems",
        "citied_by": "17",
        "cover_date": "2020-09-01",
        "Abstract": "Image-based visual servoing (IBVS) achieves precise positioning and motion control for a relatively stationary target by visual feedback, but problems persist with convergence and stability. Appropriate servoing gains for the IBVS are critical to the convergence and stability, but this control gain is heuristically a constant for most IBVS applications. This paper proposes an integrated method that allows adaptive adjustment of the servoing gain by reinforcement learning (RL) for IBVS control. The proposed method learns a policy to determine the value of the servoing gain on the fly. To ensure rapid convergence for the RL, truncating {Q}-learning (TQL) with faster convergence is used as learning algorithm, which uses truncated temporal differences (TDs) to update the TD. A nonuniform state space partitioning as a state encoder for RL allows more efficient policy. A strategy that uses the Metropolis derived from the simulated annealing is introduced for selecting the action, in order to balance exploration and exploitation so as to accelerate the learning speed. The integrated IBVS control system is tested using experiments involving a quad-rotor helicopter hovering control. The results of simulation and experiment show that the integrated IBVS method increases stability and ensures more rapid convergence than other methods.",
        "DOI": "10.1109/TCDS.2019.2908923",
        "paper_author": "Shi H.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Critic-only adaptive dynamic programming algorithms’ applications to the secure control of cyber–physical systems",
        "publication": "ISA Transactions",
        "citied_by": "11",
        "cover_date": "2020-09-01",
        "Abstract": "Industrial cyber–physical systems generally suffer from the malicious attacks and unmatched perturbation, and thus the security issue is always the core research topic in the related fields. This paper proposes a novel intelligent secure control scheme, which integrates optimal control theory, zero-sum game theory, reinforcement learning and neural networks. First, the secure control problem of the compromised system is converted into the zero-sum game issue of the nominal auxiliary system, and then both policy-iteration-based and value-iteration-based adaptive dynamic programming methods are introduced to solve the Hamilton–Jacobi–Isaacs equations. The proposed secure control scheme can mitigate the effects of actuator attacks and unmatched perturbation, and stabilize the compromised cyber–physical systems by tuning the system performance parameters, which is proved through the Lyapunov stability theory. Finally, the proposed approach is applied to the Quanser helicopter to verify the effectiveness.",
        "DOI": "10.1016/j.isatra.2019.02.012",
        "paper_author": "Jiang H.",
        "affiliation_name": "College of Information Science and Engineering, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60118697",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Study report on Indian agriculture with IoT",
        "publication": "International Journal of Electrical and Computer Engineering",
        "citied_by": "22",
        "cover_date": "2020-08-31",
        "Abstract": "Most of the population of our country are depends on agriculture for their survival. Agriculture plays an important role in our country economy. but since past few years production from agriculture sector is decreasing drastically. Agriculture sector saw a drastic downfall in its productivity from past few years, there are many reasons for this downfall. In this paper we will discuss about past, present and future of agriculture in our country, agricultural policies which are provided by government to improve the growth of agriculture and reasons why we are not able see the growth in agriculture. And also we will see how can we adopt automation into agriculture using various emerging technologies like IoT (Internet of Things), data mining, cloud computing and machine learning and some authors done some quality work previously on this topic we will discuss that also. Here we will see previous work done by various authors which can be useful to increase the productivity of agriculture sector.",
        "DOI": "10.11591/ijece.v10i3.pp2322-2328",
        "paper_author": "Balakrishna G.",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India",
        "affiliation_id": "60079446",
        "affiliation_state": "AP"
    },
    {
        "paper_title": "Multi-Agent Reinforcement Learning for the Energy Optimization of Cyber-Physical Production Systems",
        "publication": "Canadian Conference on Electrical and Computer Engineering",
        "citied_by": "8",
        "cover_date": "2020-08-30",
        "Abstract": "The paper proposes an artificial intelligence-based solution for the efficient operation of a heterogeneous cluster of flexible manufacturing machines with energy generation and storage capabilities in an electricity micro-grid featuring high volatility of electricity prices. The problem of finding the optimal control policy is first formulated as a game-theoretic sequential decision-making problem under uncertainty, where at every time step the uncertainty is characterized by future weather-dependent energy prices, high demand fluctuation, as well as random unexpected disturbances on the factory floor. Because of the parallel interaction of the machines with the grid, the local viewpoints of an agent are non-stationary and non-Markovian. Therefore, traditional methods such as standard reinforcement learning approaches that learn a specialized policy for a single machine are not applicable. To address this problem, we propose a multi-agent actor-critic method that takes into account the policies of other participants to achieve explicit coordination between a large numbers of actors. We show the strength of our approach in mixed cooperative and competitive scenarios where different production machines were able to discover different coordination strategies in order to increase the energy efficiency of the whole factory floor.",
        "DOI": "10.1109/CCECE47787.2020.9255795",
        "paper_author": "Bakakeu J.",
        "affiliation_name": "Friedrich-Alexander-Universität Erlangen-Nürnberg",
        "affiliation_city": "Erlangen",
        "affiliation_country": "Germany",
        "affiliation_id": "60000765",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "The impact of FinTech on Financial Services in India: Past, Present, and Future Trends",
        "publication": "Innovative Strategies for Implementing FinTech in Banking",
        "citied_by": "11",
        "cover_date": "2020-08-28",
        "Abstract": "Fintech is a new buzz word in the fourth industrial revolution environment. No financial services across the globe are left unaffected by the new technologies. Artificial intelligence, machine learning, block-chain, and data analytics have immensely influenced many aspects of financial services such as deposits, transactions, billings, remittances, credits (B2B and P2P), underwriting, insurance, and so on. Fintech companies are enabling larger financial inclusion, improvement of lives of humans, better decisionmaking, and lots more. This chapter covers the development, opportunities, and challenges of financial sectors because of new technologies in India. This chapter throws the light on opportunities that emerged because of demographic dividend, high penetration, and access to the latest and affordable technology, affordable cost of smartphones, and government policies such as Digital India, Startup India, Make in India, and so on. Lastly, this chapter portrays the untapped potentials of Fintech in India.",
        "DOI": "10.4018/978-1-7998-3257-7.ch012",
        "paper_author": "Kukreja G.",
        "affiliation_name": "Ahlia University",
        "affiliation_city": "Manama",
        "affiliation_country": "Bahrain",
        "affiliation_id": "60103935",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "FinTech Adoption in China: Challenges, Regulations, and Opportunities",
        "publication": "Innovative Strategies for Implementing FinTech in Banking",
        "citied_by": "1",
        "cover_date": "2020-08-28",
        "Abstract": "Almost all financial services (especially digital payments) in China are affected by new innovations and technologies. New technologies such as blockchain, artificial intelligence, machine learning, deep learning, and data analytics have immensely influenced all most all aspects of financial services such as deposits, transactions, billings, remittances, credits (B2B and P2P), underwriting, insurance, and so on. Fintech companies are enabling larger financial inclusion, changing in lifestyle and expenditure behavior, better and fast financial services, and lots more. This chapter covers the development, opportunities, and challenges of financial sectors because of new technologies in China. This chapter throws the light on opportunities that emerged because of the large population of 1.4 billion people, high penetration, and access to the latest and affordable technology, affordable cost of smartphones, and government policies and regulations. Lastly, this chapter portrays the untapped potentials of Fintech in China.",
        "DOI": "10.4018/978-1-7998-3257-7.ch010",
        "paper_author": "Kukreja G.",
        "affiliation_name": "Ahlia University",
        "affiliation_city": "Manama",
        "affiliation_country": "Bahrain",
        "affiliation_id": "60103935",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting the Risk of Type II Diabetes using Reinforcement Learning",
        "publication": "2020 Joint 9th International Conference on Informatics, Electronics and Vision and 2020 4th International Conference on Imaging, Vision and Pattern Recognition, ICIEV and icIVPR 2020",
        "citied_by": "41",
        "cover_date": "2020-08-26",
        "Abstract": "Type II Diabetes (T2D) is one of the most common lifestyle diseases which is characterized by insulin resistance. Lack of insulin's proper working causes uncontrollable blood glucose rise in the body which leads to life taking situations. Therefore, early detection of T2D is imperative to save many lives. Towards this goal, this work presents a machine learning-based prediction model to detect T2D. The Q-learning algorithm belonging to the Reinforcement Learning (RL) paradigm has been applied to the PIMA Indian Women diabetes dataset in developing the detection model. The model identifies patients with T2D using three factors (such as Body Mass Index, glucose level and age of subject) by generating an off-policy based RL and making the learning agent to find an optimal policy for the factors. The information of a subject can be in any of 330 possible states. The proposed RL model's accuracy, Precision, Recall, F-measure and AUC values have been compared with the state-of-the-art techniques such as K Nearest Neighbors and Decision Tree. The performance of the proposed RL-based T2D prediction outperforms the K Nearest Neighbors and Decision Tree.",
        "DOI": "10.1109/ICIEVicIVPR48672.2020.9306653",
        "paper_author": "Zohora M.F.",
        "affiliation_name": "Jahangirnagar University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60029276",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An effective maximum entropy exploration approach for deceptive game in reinforcement learning",
        "publication": "Neurocomputing",
        "citied_by": "8",
        "cover_date": "2020-08-25",
        "Abstract": "Deceptive games are games that utilize the reward structure to keep the agent away from the global optimization and have been grown up to become a huge challenge in the field of deep reinforcement learning intelligent exploration. Most of the cutting-edge exploration approaches, such as count-based and curiosity-driven, even with intrinsic motivation, which achieves better performance in the sparse reward game, still easily fall into local optimal traps in the deceptive game. To address this shortfall, we introduce a further exploration approach called Maximum Entropy Explore (MEE). Based on entropy rewards and the off-policy actor-critic reinforcement learning algorithm, we divided the agent exploration policy into two independent parts, namely, the target policy and the explorer policy. The explorer policy, taking the maximum entropy of the target policy as the optimization goal, is used to interact with the environment and generated trajectories for the target policy. The target policy regards the maximization of external reward as the optimization goal to achieve the global solution. To alleviate the catastrophic forgetting problem which leads to the training of the agent not stabilized during the off-policy exploration phrase, the optimal experience replay is applied. An on-policy mode switch trick is used to validly prevent the unstable and diverge which caused by the deadly triad. We conduct experiments comparing our approach with state-of-the-art deep reinforcement learning algorithm and exploration methods in the grid world and StarCraft II environments with deceptive reward. The experiment indicates that the MME approach sets out to be in the present paper effectively avoids the deceptive reward trap and learns the global optimal strategy.",
        "DOI": "10.1016/j.neucom.2020.04.068",
        "paper_author": "Li C.",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60018308",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Energy Usage Prediction for Smart Home with Regression Based Ensemble Model",
        "publication": "2020 8th International Conference on Information Technology and Multimedia, ICIMU 2020",
        "citied_by": "4",
        "cover_date": "2020-08-24",
        "Abstract": "Residential sectors using energy mainly though lighting and HV AC (Heating, Ventilation and Air-Conditioning) have become a significant consumer of world energy and it is expected to grow especially with the trend of increasing smart homes. To provide an optimum, accurate and reliable electricity distribution, load prediction is a prerequisite policy and operational implementation. Smart homes with the use of various sensors create big data that gives a favorable opportunity for developing data-driven energy usage prediction models. In this paper, a novel regression-based ensemble prediction model with inbuilt automated optimization for parameters is proposed to predict the demand of electricity. The model explains the 0.998 correlation between the features and their label, and achieved root mean squared error (RMSE) and Normalized Absolute Error as low as 5.508 and 0.0508 respectively. We have also proposed a novel data-driven classification of the energy usage by unsupervised learning through clustering.",
        "DOI": "10.1109/ICIMU49871.2020.9243578",
        "paper_author": "Hoque M.S.",
        "affiliation_name": "Universiti Tenaga Nasional",
        "affiliation_city": "Kajang",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60005762",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Fleet control using coregionalized gaussian process policy iteration",
        "publication": "Frontiers in Artificial Intelligence and Applications",
        "citied_by": "2",
        "cover_date": "2020-08-24",
        "Abstract": "In many settings, as for example wind farms, multiple machines are instantiated to perform the same task, which is called a fleet. The recent advances with respect to the Internet of Things allow control devices and/or machines to connect through cloud-based architectures in order to share information about their status and environment. Such an infrastructure allows seamless data sharing between fleet members, which could greatly improve the sample-efficiency of reinforcement learning techniques. However in practice, these machines, while almost identical in design, have small discrepancies due to production errors or degradation, preventing control algorithms to simply aggregate and employ all fleet data. We propose a novel reinforcement learning method that learns to transfer knowledge between similar fleet members and creates member-specific dynamical models for control. Our algorithm uses Gaussian processes to establish cross-member covariances. This is significantly different from standard transfer learning methods, as the focus is not on sharing information over tasks, but rather over system specifications. We demonstrate our approach on two benchmarks and a realistic wind farm setting. Our method significantly outperforms two baseline approaches, namely individual learning and joint learning where all samples are aggregated, in terms of the median and variance of the results.",
        "DOI": "10.3233/FAIA200266",
        "paper_author": "Verstraeten T.",
        "affiliation_name": "Vrije Universiteit Brussel",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "60026810",
        "affiliation_state": "BRU"
    },
    {
        "paper_title": "Toward a generic automl-based assistant for contracts negotiation",
        "publication": "Frontiers in Artificial Intelligence and Applications",
        "citied_by": "0",
        "cover_date": "2020-08-24",
        "Abstract": "Contracts are the cornerstone of legal agreements in the industry. As essential legal documents, contracts are subject to negotiations, demanding extensive analysis and evaluation efforts. Although the emergence of machine learning has enabled assistance tools for text analysis tasks, the specificity and constraints of each business context remain obstacles for the automation of contracts evaluation. In this paper, we propose an AutoML based approach for automated negotiation assistance that uses expert annotated contracts and the business-specific knowledge of acceptance policies. Driven by policies rules, our approach generates a classification process composed of hierarchies of complementary classifiers, each being automatically prepared according, but not limited to, feature extraction, learning model and data granularity. Experiments conducted on real-world service contracts have yielded promising results.",
        "DOI": "10.3233/FAIA200432",
        "paper_author": "Bendraou Y.",
        "affiliation_name": "Ilyeum Insights",
        "affiliation_city": "Ilyeum, Paris",
        "affiliation_country": "France",
        "affiliation_id": "130708810",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "MobiSenseUs: Inferring aggregate objective and subjectivewell-being from mobile data",
        "publication": "Frontiers in Artificial Intelligence and Applications",
        "citied_by": "3",
        "cover_date": "2020-08-24",
        "Abstract": "Assessing the well-being of a population is of utmost importance for policy and decision makers so they can design appropriate policies and interventions to improve the quality of life of their citizens. Traditional methods to determine aggregate well-being consist of surveys which are expensive to obtain and difficult to scale. Thanks to the availability of large-scale human behavioral data, new methods to assess well-being might be possible. In this paper we describe one of such methods: MobiSenseUs, a machine-learning based system to automatically estimate geographically aggregated objective and subjective well-being measures in the UK from mobile data. We propose a comprehensive battery of features that capture different aspects of human behavior - i.e. Communication patterns, mobile app usage and spatial mobility - from two sources of pseudonymized mobile data of more than one million smartphone users. We are the first to build machine-learning models to predict both objective (IMD) and subjective (SWB) indicators in the UK from these mobile features. We find that the IMD can be predicted more accurately than SWB, reaching 99% and 78% average accuracies in a binary classification task for the IMD and SWB, respectively. We analyze the most predictive features and derive implications for the design of data-driven machine-learning public health policy systems.",
        "DOI": "10.3233/FAIA200297",
        "paper_author": "Hillebrand M.",
        "affiliation_name": "Vodafone",
        "affiliation_city": "Newbury",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60008652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Dynamic algorithm configuration: Foundation of a new meta-algorithmic framework",
        "publication": "Frontiers in Artificial Intelligence and Applications",
        "citied_by": "41",
        "cover_date": "2020-08-24",
        "Abstract": "The performance of many algorithms in the fields of hard combinatorial problem solving, machine learning or AI in general depends on parameter tuning. Automated methods have been proposed to alleviate users from the tedious and error-prone task of manually searching for performance-optimized configurations across a set of problem instances. However, there is still a lot of untapped potential through adjusting an algorithm's parameters online since different parameter values can be optimal at different stages of the algorithm. Prior work showed that reinforcement learning is an effective approach to learn policies for online adjustments of algorithm parameters in a data-driven way. We extend that approach by formulating the resulting dynamic algorithm configuration as a contextual MDP, such that RL not only learns a policy for a single instance, but across a set of instances. To lay the foundation for studying dynamic algorithm configuration with RL in a controlled setting, we propose white-box benchmarks covering major aspects that make dynamic algorithm configuration a hard problem in practice and study the performance of various types of configuration strategies for them. On these white-box benchmarks, we show that (i) RL is a robust candidate for learning configuration policies, outperforming standard parameter optimization approaches, such as classical algorithm configuration; (ii) based on function approximation, RL agents can learn to generalize to new types of instances; and (iii) self-paced learning can substantially improve the performance by selecting a useful sequence of training instances automatically.",
        "DOI": "10.3233/FAIA200122",
        "paper_author": "Biedenkapp A.",
        "affiliation_name": "Universität Freiburg",
        "affiliation_city": "Freiburg im Breisgau",
        "affiliation_country": "Germany",
        "affiliation_id": "60025641",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "AutoGrow: Automatic Layer Growing in Deep Convolutional Networks",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "18",
        "cover_date": "2020-08-23",
        "Abstract": "Depth is a key component of Deep Neural Networks (DNNs), however, designing depth is heuristic and requires many human efforts. We proposeAutoGrow to automate depth discovery in DNNs: starting from a shallow seed architecture,AutoGrow grows new layers if the growth improves the accuracy; otherwise, stops growing and thus discovers the depth. We propose robust growing and stopping policies to generalize to different network architectures and datasets. Our experiments show that by applying the same policy to different network architectures,AutoGrow can always discover near-optimal depth on various datasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet. For example, in terms of accuracy-computation trade-off,AutoGrow discovers a better depth combination in \\resnets than human experts. OurAutoGrow is efficient. It discovers depth within similar time of training a single DNN. Our code is available at \\urlhttps://github.com/wenwei202/autogrow.",
        "DOI": "10.1145/3394486.3403126",
        "paper_author": "Wen W.",
        "affiliation_name": "Duke University",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60008724",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Treatment Policy Learning in Multiobjective Settings with Fully Observed Outcomes",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "4",
        "cover_date": "2020-08-23",
        "Abstract": "In several medical decision-making problems, such as antibiotic prescription, laboratory testing can provide precise indications for how a patient will respond to different treatment options. This enables us to \"fully observe\" all potential treatment outcomes, but while present in historical data, these results are infeasible to produce in real-time at the point of the initial treatment decision. Moreover, treatment policies in these settings often need to trade off between multiple competing objectives, such as effectiveness of treatment and harmful side effects. We present, compare, and evaluate three approaches for learning individualized treatment policies in this setting: First, we consider two indirect approaches, which use predictive models of treatment response to construct policies optimal for different trade-offs between objectives. Second, we consider a direct approach that constructs such a set of policies without intermediate models of outcomes. Using a medical dataset of Urinary Tract Infection (UTI) patients, we show that all approaches learn policies that achieve strictly better performance on all outcomes than clinicians, while also trading off between different objectives. We demonstrate additional benefits of the direct approach, including flexibly incorporating other goals such as deferral to physicians on simple cases.",
        "DOI": "10.1145/3394486.3403245",
        "paper_author": "Boominathan S.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "A pathway to better livestock health",
        "publication": "Veterinary Record",
        "citied_by": "0",
        "cover_date": "2020-08-22",
        "Abstract": "NA",
        "DOI": "10.1136/vr.m3296",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement learning control for six-phase permanent magnet synchronous motor position servo drive",
        "publication": "Proceedings of the 3rd IEEE International Conference on Knowledge Innovation and Invention 2020, ICKII 2020",
        "citied_by": "8",
        "cover_date": "2020-08-21",
        "Abstract": "Since the permanent magnet synchronous motor (PMSM) has nonlinear dynamic behavior characteristics, it is difficult to develop an ideal controller. In this paper, we develop a novel method for the six-phase PMSM (6PPMSM) position servo drive based on deep reinforcement learning (RL). Comparison studies between the proposed controller and the recurrent fuzzy neural cerebellar model articulation network (RFNCMAN) controller are presented. The results show that our controller can follow the reference trajectories more precisely in general cases, where the average tracking error obtained is 90% smaller than that of RFNCMAN.",
        "DOI": "10.1109/ICKII50300.2020.9318882",
        "paper_author": "Peng W.L.",
        "affiliation_name": "National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60005429",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Claim frequency predicting based on lightgbm",
        "publication": "Journal of Nonlinear and Convex Analysis",
        "citied_by": "3",
        "cover_date": "2020-08-21",
        "Abstract": "Based on LightGBM, this paper proposes a probability analysis model to remove the harsh assumptions and limitation in GLMs. In the empirical study, this paper extract characteristic variables from owner's attributes, motor vehicle attributes and policy attributes, and generates tree-like judgment rules according to LightGBM algorithm, which provides a concrete calculation basis for the prediction of claim frequency of automobile insurance. Compared with GLMs and traditional learning machines, this model has the highest accuracy, optimal classification effect and robustness in predicting claim frequency.",
        "DOI": "NA",
        "paper_author": "Chen Y.",
        "affiliation_name": "University of International Business and Economics",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013503",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks",
        "publication": "Frontiers in Robotics and AI",
        "citied_by": "1",
        "cover_date": "2020-08-21",
        "Abstract": "Visual reasoning is a critical stage in visual question answering (Antol et al., 2015), but most of the state-of-the-art methods categorized the VQA tasks as a classification problem without taking the reasoning process into account. Various approaches are proposed to solve this multi-modal task that requires both abilities of comprehension and reasoning. The recently proposed neural module network (Andreas et al., 2016b), which assembles the model with a few primitive modules, is capable of performing a spatial or arithmetical reasoning over the input image to answer the questions. Nevertheless, its performance is not satisfying especially in the real-world datasets (e.g., VQA 1.0& 2.0) due to its limited primitive modules and suboptimal layout. To address these issues, we propose a novel method of Dual-Path Neural Module Network which can implement complex visual reasoning by forming a more flexible layout regularized by the pairwise loss. Specifically, we first use the region proposal network to generate both visual and spatial information, which helps it perform spatial reasoning. Then, we advocate to process a pair of different images along with the same question simultaneously, named as a “complementary pair,” which encourages the model to learn a more reasonable layout by suppressing the overfitting to the language priors. The model can jointly learn the parameters in the primitive module and the layout generation policy, which is further boosted by introducing a novel pairwise reward. Extensive experiments show that our approach significantly improves the performance of neural module networks especially on the real-world datasets.",
        "DOI": "10.3389/frobt.2020.00109",
        "paper_author": "Su K.",
        "affiliation_name": "Beijing National Research Center for Information Science and Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60104026",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Optimization of depth-graded multilayer structure for x-ray optics using machine learning",
        "publication": "Journal of Applied Physics",
        "citied_by": "8",
        "cover_date": "2020-08-21",
        "Abstract": "We present a general machine-learning-based approach to solve the inverse design problem of depth-graded multilayer structures (so-called supermirrors) for x-ray optics. Our model uses Monte Carlo tree search (MCTS) with policy gradient in combination with a reflectivity simulation. MCTS is an iterative design method that showed competitive efficiency in materials design and discovery problems. A policy gradient algorithm with a neural network was added to optimize the tree expansion. The policy gradient is a reinforcement learning method that optimizes parametrized policies toward an expected return using gradient descent. This approach is applied to design a depth-graded multilayer structure that maximizes mean reflectivity in an angular range for Cu K α radiation by selecting the optimal thickness and material for each layer in the structure. Mean reflectivity of 0.80 was achieved in an angular range of 0.45-0.55 °. Alternating materials are selected from a predetermined set of materials. We confirmed that the policy gradient enhances the efficiency of MCTS. This approach can be applied autonomously on several x-ray applications without any parameter tuning or pre-available data.",
        "DOI": "10.1063/5.0012351",
        "paper_author": "Dieb S.",
        "affiliation_name": "National Institute for Materials Science",
        "affiliation_city": "Tsukuba",
        "affiliation_country": "Japan",
        "affiliation_id": "60002414",
        "affiliation_state": "Ibaraki"
    },
    {
        "paper_title": "High-resolution spatiotemporal measurement of air and environmental noise pollution in Sub-Saharan African cities: Pathways to Equitable Health Cities Study protocol for Accra, Ghana",
        "publication": "BMJ Open",
        "citied_by": "24",
        "cover_date": "2020-08-20",
        "Abstract": "Introduction Air and noise pollution are emerging environmental health hazards in African cities, with potentially complex spatial and temporal patterns. Limited local data are a barrier to the formulation and evaluation of policies to reduce air and noise pollution. Methods and analysis We designed a year-long measurement campaign to characterise air and noise pollution and their sources at high-resolution within the Greater Accra Metropolitan Area (GAMA), Ghana. Our design uses a combination of fixed (year-long, n=10) and rotating (week-long, n =∼130) sites, selected to represent a range of land uses and source influences (eg, background, road traffic, commercial, industrial and residential areas, and various neighbourhood socioeconomic classes). We will collect data on fine particulate matter (PM 2.5), nitrogen oxides (NO x), weather variables, sound (noise level and audio) along with street-level time-lapse images. We deploy low-cost, low-power, lightweight monitoring devices that are robust, socially unobtrusive, and able to function in Sub-Saharan African (SSA) climate. We will use state-of-the-art methods, including spatial statistics, deep/machine learning, and processed-based emissions modelling, to capture highly resolved temporal and spatial variations in pollution levels across the GAMA and to identify their potential sources. This protocol can serve as a prototype for other SSA cities. Ethics and dissemination This environmental study was deemed exempt from full ethics review at Imperial College London and the University of Massachusetts Amherst; it was approved by the University of Ghana Ethics Committee (ECH 149/18-19). This protocol is designed to be implementable in SSA cities to map environmental pollution to inform urban planning decisions to reduce health harming exposures to air and noise pollution. It will be disseminated through local stakeholder engagement (public and private sectors), peer-reviewed publications, contribution to policy documents, media, and conference presentations.",
        "DOI": "10.1136/bmjopen-2019-035798",
        "paper_author": "Clark S.N.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Rapid Prediction of Chemical Ecotoxicity through Genetic Algorithm Optimized Neural Network Models",
        "publication": "ACS Sustainable Chemistry and Engineering",
        "citied_by": "24",
        "cover_date": "2020-08-17",
        "Abstract": "Evaluating potentially hazardous effects of chemicals on ecosystems has always been an important research topic traditionally studied using laboratory or field experiments. Experiment-based ecotoxicity test results are only available for a limited number of chemicals due to the extensive experimental effort and cost. Given the ever-increasing number of chemicals involved in the modern production process and products, rapidly characterizing chemical ecotoxicity at lower costs has become critical for guiding technology and policy development for chemical risk management. In this study, artificial neural network models are developed to predict chemical ecotoxicity (HC50) based on experimental data to fill data gaps in a widely used database (USEtox). To reduce the manual tuning effort on optimal network architecture, a genetic algorithm is investigated to automatically search and configure the network architecture. The resulting neural network model reached an average test R2 of 0.632 and had a trivial difference with the global optimal regarding validation MSE. The findings of this study can rapidly predict the ecotoxicity of chemicals and further help to understand the potential risk of chemicals and develop strategies for risk management.",
        "DOI": "10.1021/acssuschemeng.0c03660",
        "paper_author": "Hou P.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60025778",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Predicting the deforestation probability using the binary logistic regression, random forest, ensemble rotational forest, REPTree: A case study at the Gumani River Basin, India",
        "publication": "Science of the Total Environment",
        "citied_by": "94",
        "cover_date": "2020-08-15",
        "Abstract": "Rapid population growth and its corresponding effects like the expansion of human settlement, increasing agricultural land, and industry lead to the loss of forest area in most parts of the world especially in such highly populated nations like India. Forest canopy density (FCD) is a useful measure to assess the forest cover change in its own as numerous works of forest change have been done using only FCD with the help of remote sensing and GIS. The coupling of binary logistic regression (BLR), random forest (RF), ensemble of rotational forest and reduced error pruning trees (RTF-REPTree) with FCD makes it more convenient to find out the deforestation probability. Advanced vegetation index (AVI), bare soil index (BSI), shadow index (SI), and scaled vegetation density (VD) derived from Landsat imageries are the main input parameters to identify the FCD. After preparing the FCDs of 1990, 2000, 2010 and 2017 the deforestation map of the study area was prepared and considered as dependent parameter for deforestation probability modelling. On the other hand, twelve deforestation determining factors were used to delineate the deforestation probability with the help of BLR, RF and RTF-REPTree models. These deforestation probability models were validated through area under curve (AUC), receiver operating characteristics (ROC), efficiency, true skill statistics (TSS) and Kappa co-efficient. The validation result shows that all the models like BLR (AUC = 0.874), RF (AUC = 0.886) and RTF-REPTree (AUC = 0.919) have good capability of assessing the deforestation probability but among them, RTF-REPTree has the highest accuracy level. The result also shows that low canopy density area i.e. not under the dense forest cover has increased by 9.26% from 1990 to 2017. Besides, nearly 30% of the forested land is under high to very high deforestation probable zone, which needs to be protected with immediate measures.",
        "DOI": "10.1016/j.scitotenv.2020.139197",
        "paper_author": "Saha S.",
        "affiliation_name": "University of Gour Banga",
        "affiliation_city": "Malda",
        "affiliation_country": "India",
        "affiliation_id": "60116965",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "TURBULENCE ON THE GLOBAL ECONOMY INFLUENCED BY ARTIFICIAL INTELLIGENCE AND FOREIGN POLICY INEFFICIENCIES",
        "publication": "Journal of Liberty and International Affairs",
        "citied_by": "2",
        "cover_date": "2020-08-14",
        "Abstract": "It is said that Data and Information are the new oil. One, who handles the data, handles the emerging future of the global economy. Complex algorithms and intelligence-based filter programs are utilized to manage, store, handle, and maneuver vast amounts of data for the fulfillment of specific purposes. This paper seeks to find the bridge between artificial intelligence and its impact on international policy implementation in the light of geopolitical influence, the global economy, and the future of labor markets. We hypothesize that the distortion in the labor markets caused by artificial intelligence can be mitigated by a collaborative international foreign policy on the deployment of AI in the industrial circles. We, in this paper, then proceed to propose a disposition forth essentials of AI-based foreign policy and implementation, while asking questions such as: could AI become the real ‘invisible hand’ discussed by economists?",
        "DOI": "10.47305/JLIA2020113ob",
        "paper_author": "Bonsu K.O.",
        "affiliation_name": "Zhejiang Gongshang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60012581",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "DeepBGP: A machine learning approach for BGP configuration synthesis",
        "publication": "NetAI 2020 - Proceedings of the 2020 Workshop on Network Meets AI and ML",
        "citied_by": "12",
        "cover_date": "2020-08-14",
        "Abstract": "Border Gateway Protocol (BGP) is the standard inter-domain routing protocol that is used to exchange reachability information among Wide Area Networks (WANs). BGP is a policy-based routing protocol that introduces a lot of flexibility. However, this flexibility increases the configuration complexity. In this research, we introduce DeepBGP as a neural network-based system that synthesizes network configuration given a high-level operator intent. We adopt Graph Neural Network (GNN) to represent network topology and generate partial network configuration. A validation unit is then used to calculate a reward based on which an Evolution Strategies (ES) optimizer updates neural network parameters. Since ES does not require backpropagation, they provide a significant reduction in calculation time. Further, the recent advances in deep learning with strong hardware acceleration and the parallelization capabilities offered by ES provide great potential in scaling the proposed solution to larger topologies. We demonstrate experimentally that DeepBGP can generate a network-wide configuration for both Huawei and Cisco devices while fulfilling operator requirements. We also show how Deep-BGP scales when the network size increases, and how hardware acceleration could improve the scalability of the system.",
        "DOI": "10.1145/3405671.3405816",
        "paper_author": "Bahnasy M.",
        "affiliation_name": "Huawei Technologies Co., Ltd.",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60092530",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Can machine learning algorithms associated with text mining from internet data improve housing price prediction performance?",
        "publication": "International Journal of Strategic Property Management",
        "citied_by": "15",
        "cover_date": "2020-08-14",
        "Abstract": "Housing frenzies in China have attracted widespread global attention over the past few years, but the key is how to more accurately forecast housing prices in order to establish an effective real estate policy. Based on the ubiquitousness and immediacy of Internet data, this research adopts a broader version of text mining to search for keywords in relation to housing prices and then evaluates the predictive abilities using machine learning algorithms. Our findings indicate that this new method, especially random forest, not only detects turning points, but also offers prediction ability that clearly outperforms traditional regression analysis. Overall, the prediction based on online search data through a machine learning mechanism helps us better understand the trends of house prices in China.",
        "DOI": "10.3846/ijspm.2020.12742",
        "paper_author": "Guo J.Q.",
        "affiliation_name": "Shandong University, Weihai",
        "affiliation_city": "Weihai",
        "affiliation_country": "China",
        "affiliation_id": "60108071",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A multimethod approach for county-scale geospatial analysis of emerging infectious diseases: A cross-sectional case study of COVID-19 incidence in Germany",
        "publication": "International Journal of Health Geographics",
        "citied_by": "73",
        "cover_date": "2020-08-13",
        "Abstract": "Background: As of 13 July 2020, 12.9 million COVID-19 cases have been reported worldwide. Prior studies have demonstrated that local socioeconomic and built environment characteristics may significantly contribute to viral transmission and incidence rates, thereby accounting for some of the spatial variation observed. Due to uncertainties, non-linearities, and multiple interaction effects observed in the associations between COVID-19 incidence and socioeconomic, infrastructural, and built environment characteristics, we present a structured multimethod approach for analysing cross-sectional incidence data within in an Exploratory Spatial Data Analysis (ESDA) framework at the NUTS3 (county) scale. Methods: By sequentially conducting a geospatial analysis, an heuristic geographical interpretation, a Bayesian machine learning analysis, and parameterising a Generalised Additive Model (GAM), we assessed associations between incidence rates and 368 independent variables describing geographical patterns, socioeconomic risk factors, infrastructure, and features of the build environment. A spatial trend analysis and Local Indicators of Spatial Autocorrelation were used to characterise the geography of age-adjusted COVID-19 incidence rates across Germany, followed by iterative modelling using Bayesian Additive Regression Trees (BART) to identify and measure candidate explanatory variables. Partial dependence plots were derived to quantify and contextualise BART model results, followed by the parameterisation of a GAM to assess correlations. Results: A strong south-to-north gradient of COVID-19 incidence was identified, facilitating an empirical classification of the study area into two epidemic subregions. All preliminary and final models indicated that location, densities of the built environment, and socioeconomic variables were important predictors of incidence rates in Germany. The top ten predictor variables' partial dependence exhibited multiple non-linearities in the relationships between key predictor variables and COVID-19 incidence rates. The BART, partial dependence, and GAM results indicate that the strongest predictors of COVID-19 incidence at the county scale were related to community interconnectedness, geographical location, transportation infrastructure, and labour market structure. Conclusions: The multimethod ESDA approach provided unique insights into spatial and aspatial non-stationarities of COVID-19 incidence in Germany. BART and GAM modelling indicated that geographical configuration, built environment densities, socioeconomic characteristics, and infrastructure all exhibit associations with COVID-19 incidence in Germany when assessed at the county scale. The results suggest that measures to implement social distancing and reduce unnecessary travel may be important methods for reducing contagion, and the authors call for further research to investigate the observed associations to inform prevention and control policy.",
        "DOI": "10.1186/s12942-020-00225-1",
        "paper_author": "Scarpone C.",
        "affiliation_name": "Toronto Metropolitan University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60030838",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Determining Optimal Lag Time Selection Function with Novel Machine Learning Strategies for Better Agricultural Commodity Prices Forecasting in Malaysia",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "20",
        "cover_date": "2020-08-12",
        "Abstract": "In 2018, agriculture remains an important sector of Malaysia's economy, contributing around 7.54% to national GDP and 11.09% to the total employment. However, in agriculture, price volatility is often unpredictable due to the reliability of agricultural production on natural phenomena. Instability of prices endanger the development of Malaysia's economy and the food accessibility by consumers, which may lead to food insecurity, hunger and malnutrition. Thus, the need of an accurate forecasting model for agricultural commodity price is acute, especially for government and farmers to propose new policies and better plantation plan to deal with potential risks in the markets. In the context of forecasting, optimal lag selection is important to improve the forecast performance in terms of time and accuracy. The main goal of this research is to study and design novel machine learning strategies with optimal lag time selection function to forecast agricultural commodity price more accurately in order to improve plantation plan in Malaysia.",
        "DOI": "10.1145/3417473.3417480",
        "paper_author": "Yuan C.Z.",
        "affiliation_name": "The University of Nottingham Malaysia Campus",
        "affiliation_city": "Semenyih",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090616",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "FastFE: Accelerating ML-based Traffic Analysis with Programmable Switches",
        "publication": "Proceedings of the 2020 ACM SIGCOMM Workshop on Secure Programmable Network Infrastructure, SPIN 2020",
        "citied_by": "14",
        "cover_date": "2020-08-10",
        "Abstract": "Modern traffic analysis applications are usually designed to identify malicious behaviors by inferring sensitive information with machine learning (ML) techniques from network traffic, and they are of great importance to security with the growing use of encryption and other evasion techniques that make classic content-based analysis infeasible. However, with the soaring throughput of networks reaching hundreds of Gbps, it becomes more and more challenging for traffic analysis applications to keep up with today's high-speed large-volume network traffic. In particular, existing feature extractor components in traffic analysis are suffering from undesirable communications, storage, and computation bottleneck. To this end, this paper presents FastFE, a high-speed feature extractor that leverages the capability of new-generation programmable switches to generate desired traffic features flexibly and efficiently. We provide a set of general, easy-to-use, and expressive interfaces for operators to express which traic features they desire, and a policy enforcement engine that can effectively translate these policies into underlying primitives in programmable switches and commodity servers. Our case study on a state-of-the-art ML-based traffic analysis application, Kitsune, demonstrates the significant advancement of FastFE and its low overheads. As an ongoing work, we are working on a full prototype design and implementation, and hope FastFE can serve as a crucial build block for future ML-based traffic analysis applications.",
        "DOI": "10.1145/3405669.3405818",
        "paper_author": "Bai J.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Sustainable soil use and management: An interdisciplinary and systematic approach",
        "publication": "Science of the Total Environment",
        "citied_by": "215",
        "cover_date": "2020-08-10",
        "Abstract": "Soil is a key component of Earth's critical zone. It provides essential services for agricultural production, plant growth, animal habitation, biodiversity, carbon sequestration and environmental quality, which are crucial for achieving the United Nations' Sustainable Development Goals (SDGs). However, soil degradation has occurred in many places throughout the world due to factors such as soil pollution, erosion, salinization, and acidification. In order to achieve the SDGs by the target date of 2030, soils may need to be used and managed in a manner that is more sustainable than is currently practiced. Here we show that research in the field of sustainable soil use and management should prioritize the multifunctional value of soil health and address interdisciplinary linkages with major issues such as biodiversity and climate change. As soil is the largest terrestrial carbon pool, as well as a significant contributor of greenhouse gases, much progress can be made toward curtailing the climate crisis by sustainable soil management practices. One identified option is to increase soil organic carbon levels, especially with recalcitrant forms of carbon (e.g., biochar application). In general, soil health is primarily determined by the actions of the farming community. Therefore, information management and knowledge sharing are necessary to improve the sustainable behavior of practitioners and end-users. Scientists and policy makers are important actors in this social learning process, not only to disseminate evidence-based scientific knowledge, but also in generating new knowledge in close collaboration with farmers. While governmental funding for soil data collection has been generally decreasing, newly available 5G telecommunications, big data and machine learning based data collection and analytical tools are maturing. Interdisciplinary studies that incorporate such advances may lead to the formation of innovative sustainable soil use and management strategies that are aimed toward optimizing soil health and achieving the SDGs.",
        "DOI": "10.1016/j.scitotenv.2020.138961",
        "paper_author": "Hou D.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "User Preference and Activity Aware Content Sharing in Wireless D2D Caching Networks",
        "publication": "2020 IEEE/CIC International Conference on Communications in China, ICCC 2020",
        "citied_by": "2",
        "cover_date": "2020-08-09",
        "Abstract": "Device-to-Device (D2D) content sharing has emerged as an important tool to alleviate the backhaul pressure. Most of prior works optimize D2D caching policies with known content popularity, which may not be the case in reality. In this paper, we investigate a D2D caching optimization problem with unknown content popularity in wireless D2D caching networks. To maximize the overall D2D caching hit rate, we propose a distributed caching policy by learning user preferences and user activity levels. For the first time, we exploit the sliding time window method to predict real-time user activity levels. And we employ a logistic regression model to describe the user preference. By predicting user activity levels and user preferences in real time, the proposed policy not only can significantly improve the overall D2D caching hit rate, but also reduce the traffic load of the base station compared to existing policies. Simulation results with MovieLens dataset further show that the overall D2D caching hit rate of our proposed policy is close to that of the optimal caching policy.",
        "DOI": "10.1109/ICCC49849.2020.9238810",
        "paper_author": "Qi Y.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "WorkerFirst: Worker-Centric Model Selection for Federated Learning in Mobile Edge Computing",
        "publication": "2020 IEEE/CIC International Conference on Communications in China, ICCC 2020",
        "citied_by": "5",
        "cover_date": "2020-08-09",
        "Abstract": "Federated Learning (FL) is viewed as a promising manner of distributed machine learning, because it leverages the rich local datasets of various participants while preserving their privacy. Particularly under the fifth-generation communications (5G) networks, FL shows its overwhelming advantages in the context of mobile edge computing (MEC). However, from the participant's viewpoint, a puzzle is how to guarantee the tradeoff between the profit brought by participating in FL training and the restriction of its battery capacity. Because communicating with the FL server and training an FL model locally are energy-hungry. To address such a puzzle, different from existing studies, we particularly formulate the model-selection problem from the standpoint of mobile participants (i.e., workers). We then exploit the framework of deep reinforcement learning (DRL) to reformulate a joint optimization for all FL participants, by considering the energy consumption, training timespan, and communication overheads of workers, simultaneously. To address the proposed worker-centric selection problem, we devised a double deep Q-learning Network (DDQN) algorithm and a deep Q-Learning (DQL) algorithm to strive for the adaptive model-selection decisions of each energy-sensitive participant under a varying MEC environment. The simulation results show that the proposed DDQN and DQL algorithms can quickly learn a good policy without knowing any prior knowledge of network conditions, and outperform other baselines.",
        "DOI": "10.1109/ICCC49849.2020.9238867",
        "paper_author": "Huang H.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021182",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Using Bayesian networks to clarify interpretation of exposure–response regression coefficients: blood lead–mortality association as an example",
        "publication": "Critical Reviews in Toxicology",
        "citied_by": "6",
        "cover_date": "2020-08-08",
        "Abstract": "We examine how Bayesian network (BN) learning and analysis methods can help to meet several methodological challenges that arise in interpreting significant regression coefficients in exposure–response regression modeling. As a motivating example, we consider the challenge of interpreting positive regression coefficients for blood lead level (BLL) as a predictor of mortality risk for nonsmoking men. We first note that practices such as dichotomizing or categorizing continuous confounders (e.g. income), omitting potentially important socioeconomic confounders (e.g. education), and assuming specific parametric regression model forms leave unclear to what extent a positive regression coefficient reflects these modeling choices, rather than a direct dependence of mortality risk on exposure. Therefore, significant exposure–response coefficients in parametric regression models do not necessarily reveal the extent to which reducing exposure-related variables (e.g. BLL) alone, while leaving fixed other correlates of exposure and mortality risks (e.g. education, income, etc.) would reduce adverse outcome risks (e.g. mortality risks). We then consider how BN structure-learning and inference algorithms and nonparametric estimation methods (partial dependence plots) can be used to clarify dependencies between variables, variable selection, confounding, and quantification of joint effects of multiple factors on risk, including possible high-order interactions and nonlinearities. We conclude that these details must be carefully modeled to determine whether a data set provides evidence that exposure itself directly affects risks; and that BN and nonparametric effect estimation and uncertainty quantification methods can complement regression modeling and help to improve the scientific basis for risk management decisions and policy-making by addressing these issues.",
        "DOI": "10.1080/10408444.2020.1787329",
        "paper_author": "Cox L.A.",
        "affiliation_name": "University of Colorado Denver",
        "affiliation_city": "Denver",
        "affiliation_country": "United States",
        "affiliation_id": "60010307",
        "affiliation_state": "CO"
    },
    {
        "paper_title": "Application of remote sensing and google earth engine for monitoring environmental degradation in the nilgiri biosphere reserve and its ecosystem of Western Ghats, India",
        "publication": "International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",
        "citied_by": "11",
        "cover_date": "2020-08-06",
        "Abstract": "Biosphere Reserves are archetypal parts of natural and cultural landscapes encompassing over large area of different ecosystem, it represents bio-geographic zones of an region. Globally, the areas of biosphere reserve is shrinking and exploiting due to the extreme climatic condition, natural calamities and anthropogenic activities, which leads to environmental and land degradation. In this paper Nilgiri Biosphere Reserve (NBSR) area has been selected and it represents a biodiversity-rich ecosystem in the Western Ghats and includes two of the ten biogeographical provinces of India. Amongst the most insubstantial ecosystems in the world, the Nilgiri Biosphere Reserve is bearing the substance of climate change evident in increasingly unpredictable rainfall and higher temperatures during recent years. The region was mostly unscathed till two centuries ago, but has witnessed large-scale destruction ever since. In this scenario, a need of application of remote sensing and advance machine learning techniques to monitor environmental degradation and its ecosystem in NBSR is more essential. The objective of the present study is to develop satellite image classification techniques that can reliably to map forest cover and land use, and provide the basis for long-term monitoring. Advanced image classification techniques on the cloud-based platform Google Earth Engine (GEE) for mapping vegetation and land use types, and analyse their spatial distributions. To restore degraded ecosystems to their natural conditions through proper management and conservation practices. In order to understand the nature of environmental degradation and its ecosystem in Nilgiri Biosphere Reserve; following thematic criteria's were grouped in to four major indicators such as Terrain Indicator (TI), Environmental Indicator (EI), Hydro-Meteorological Indicator (HMI) and Socio-Economic Indicator (SEI). The utilisation of remote sensing product of huge datasets and various data product in analysis and advanced machine learning algorithm through Google earth engine are indispensable. After extraction of all the thematic layers by using multi criteria decision and fuzzy linear member based weight and ranks were assigned and overlay in GIS environment at a common pixel size of 30 m. Based on the analysis the resultant layer has been classified into five environmental degraded classes i.e., very high, high, moderate, slight and no degradation. This study is help to identify the degradation and long term monitoring and suggest the appropriate conservation, management and policies, it is a time to implement and protect the Nilgiri biosphere reserves without hindering present stage of natural environment in a sustainable manner.",
        "DOI": "10.5194/isprs-archives-XLIII-B3-2020-933-2020",
        "paper_author": "Abdul Rahaman S.",
        "affiliation_name": "Bharathidasan University",
        "affiliation_city": "Tiruchirappalli",
        "affiliation_country": "India",
        "affiliation_id": "60028488",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Android botnet detection using convolutional neural networks",
        "publication": "2020 28th Iranian Conference on Electrical Engineering, ICEE 2020",
        "citied_by": "22",
        "cover_date": "2020-08-04",
        "Abstract": "Today, Android devices are capable of providing various services. They support applications for different purposes, such as entertainment, business, health, education, and banking services. Because of the functionality and popularity of Android devices as well as the open-source policy of Android OS, they have become a suitable target for attackers. An Android botnet is one of the most dangerous malware because an attacker called botmaster can remotely control that to perform destructive attacks. Several researchers have used different well-known Machine Learning (ML) methods to recognize Android botnets from benign applications. However, these conventional methods are not capable of detecting new sophisticated Android botnets. In this paper, we propose a novel method based on Android permissions and Convolutional Neural Networks (CNNs) to detect Android botnet applications. Being the first developed method that applies CNNs for this aim, we also proposed a novel method to represent each application as an image that is constructed based on the co-occurrence of permissions given to that application. The proposed CNN is a binary classifier that is trained using these images. Evaluating the proposed method on 5450 Android applications consist of botnet and benign samples, the obtained results show the accuracy of 97.2% and recall of 96%, which is a promising result only using Android permissions.",
        "DOI": "10.1109/ICEE50131.2020.9260674",
        "paper_author": "Hojjatinia S.",
        "affiliation_name": "Shahid Bahonar University of Kerman",
        "affiliation_city": "Kerman",
        "affiliation_country": "Iran",
        "affiliation_id": "60031268",
        "affiliation_state": "Kerman"
    },
    {
        "paper_title": "A<sup>2</sup>: Extracting cyclic switchings from DOB-nets for rejecting excessive disturbances: A<sup>2</sup>: Extracting cyclic switchings from DOB-nets for rejecting excessive disturbances",
        "publication": "Neurocomputing",
        "citied_by": "0",
        "cover_date": "2020-08-04",
        "Abstract": "Reinforcement Learning (RL) is limited in practice by its poor explainability, which is responsible for insufficient trustiness from users, unsatisfied interpretation for human intervention, inadequate analysis for future improvement, etc. This paper seeks to partially characterize the interplay between dynamical environments and a previously-proposed Disturbance OBserver net (DOB-net). The DOB-net is trained via RL and offers optimal control for a set of Partially Observable Markovian Decision Processes (POMDPs). The transition function of each POMDP is largely determined by the environments (excessive external disturbances). This paper proposes an Attention-based Abstraction (A2) approach to extract a finite-state automaton, referred to as a Key Moore Machine Network (KMMN), to capture the switching mechanisms exhibited by the DOB-net in dealing with multiple such POMDPs. A2 first quantizes the controlled platform by learning continuous-discrete interfaces. Then it extracts the KMMN by finding the key hidden states and transitions that attract sufficient attention from the DOB-net. Within the resultant KMMN, three patterns of cyclic switchings (between key hidden states) are found, and saturated controls are shown synchronized with unknown disturbances. Interestingly, the found switchings have previously appeared in the control design for often-saturated systems. They are interpreted via an analogy to the discrete-event subsystem of hybrid control.",
        "DOI": "10.1016/j.neucom.2020.03.014",
        "paper_author": "Lu W.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "A learning-based load, PV and energy storage system control for nearly zero energy building",
        "publication": "IEEE Power and Energy Society General Meeting",
        "citied_by": "5",
        "cover_date": "2020-08-02",
        "Abstract": "Large volumes of data are generated by advanced meters and sensors in modern buildings. A learning-based control method is proposed in this paper to benefit both power system operation and end-use facilities by utilizing these big data. Different from the other control methods, this paper aims to generate accurate control policies for building loads using deep learning instead of pre-setting by customers. Firstly, the learning models predict solar power supply, fixed loads (FLs), customers' comfort index requirement, controllable loads (CLs) and the daily driving cycles of EVs of a building based on the history data. Then, the information predicted using the learning models is applied to an optimization algorithm to minimize the deviation between the on-site PV generated energy and the actual building energy consumption by properly scheduling building loads, EVs charging cycles and Energy Storage System (ESS). The optimization algorithm aims to achieve nearly zero energy building (ZEB) and to find a highly efficient and economic management scheduling by considering customers' comfort demand. The proposed learning strategy is developed and compared by using four different machine learning methods based on the data from Pecan Street project of past three years. The non-linear optimization problem is solved by using CPLEX solver.",
        "DOI": "10.1109/PESGM41954.2020.9281924",
        "paper_author": "Gao Y.",
        "affiliation_name": "Department of Electrical and Computer Engineering",
        "affiliation_city": "Tuscaloosa",
        "affiliation_country": "United States",
        "affiliation_id": "60119595",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "Research on the multiagent joint proximal policy optimization algorithm controlling cooperative fixed-wing uav obstacle avoidance",
        "publication": "Sensors (Switzerland)",
        "citied_by": "28",
        "cover_date": "2020-08-02",
        "Abstract": "Multiple unmanned aerial vehicle (UAV) collaboration has great potential. To increase the intelligence and environmental adaptability of multi-UAV control, we study the application of deep reinforcement learning algorithms in the field of multi-UAV cooperative control. Aiming at the problem of a non-stationary environment caused by the change of learning agent strategy in reinforcement learning in a multi-agent environment, the paper presents an improved multiagent reinforcement learning algorithm—the multiagent joint proximal policy optimization (MAJPPO) algorithm with the centralized learning and decentralized execution. This algorithm uses the moving window averaging method to make each agent obtain a centralized state value function, so that the agents can achieve better collaboration. The improved algorithm enhances the collaboration and increases the sum of reward values obtained by the multiagent system. To evaluate the performance of the algorithm, we use the MAJPPO algorithm to complete the task of multi-UAV formation and the crossing of multiple-obstacle environments. To simplify the control complexity of the UAV, we use the six-degree of freedom and 12-state equations of the dynamics model of the UAV with an attitude control loop. The experimental results show that the MAJPPO algorithm has better performance and better environmental adaptability.",
        "DOI": "10.3390/s20164546",
        "paper_author": "Zhao W.",
        "affiliation_name": "Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60004828",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Using RBF Neural Network in Forecasting Urban Construction and Demolition Waste Generation",
        "publication": "Proceedings - 2020 International Conference on Big Data and Social Sciences, ICBDSS 2020",
        "citied_by": "2",
        "cover_date": "2020-08-01",
        "Abstract": "To achieve the effective construction and demolition waste (CDW) management, it is of great significance to predict CDW generation accurately to carry out the recycling treatment and formulate relevant policies for authorities. On the basis of the univariate time series of limited data samples, this paper puts forward a radial basis function neural network (RBFNN) to solve the CDW forecasting problem, which involves the algorithm of network training and prediction process. Three indicators are used to comprehensively evaluate the performance of the proposed method applicated in Shanghai and Hong Kong cases. Compared with other forecasting techniques, such as multiple linear regression (MLR), support vector regression (SVR), and back-propagation neural network (BPNN), this paper verifies that the RBFNN prediction model has strong accuracy in the analysis of CDW generation prediction.",
        "DOI": "10.1109/ICBDSS51270.2020.00051",
        "paper_author": "Xiaonan W.",
        "affiliation_name": "CETC Shanghai Microwave Communication Co., Ltd",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "114207550",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning a Behavioral Repertoire from Demonstrations",
        "publication": "IEEE Conference on Computatonal Intelligence and Games, CIG",
        "citied_by": "1",
        "cover_date": "2020-08-01",
        "Abstract": "Imitation Learning (IL) is a machine learning approach to learn a policy from a set of demonstrations. IL can be useful to kick-start learning before applying reinforcement learning (RL) but it can also be useful on its own, e.g. to learn to imitate human players in video games. Despite the success of systems that use IL and RL, how such systems can adapt in-between game rounds is a neglected area of study but an important aspect of many strategy games. In this paper, we present a new approach called Behavioral Repertoire Imitation Learning (BRIL) that learns a repertoire of behaviors from a set of demonstrations by augmenting the state-action pairs with behavioral descriptions. The outcome of this approach is a single neural network policy conditioned on a behavior description that can be precisely modulated. We apply this approach to train a policy on 7,777 human demonstrations for the build-order planning task in StarCraft II. Dimensionality reduction is applied to construct a low-dimensional behavioral space from a high-dimensional description of the army unit composition of each human replay. The results demonstrate that the learned policy can be effectively manipulated to express distinct behaviors. Additionally, by applying the UCB1 algorithm, the policy can adapt its behavior-in-between games-to reach a performance beyond that of the traditional IL baseline approach.",
        "DOI": "10.1109/CoG47356.2020.9231897",
        "paper_author": "Justesen N.",
        "affiliation_name": "IT-Universitetet i København",
        "affiliation_city": "Copenhagen",
        "affiliation_country": "Denmark",
        "affiliation_id": "60018567",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation",
        "publication": "29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020",
        "citied_by": "9",
        "cover_date": "2020-08-01",
        "Abstract": "Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",
        "DOI": "10.1109/RO-MAN47096.2020.9223558",
        "paper_author": "Yang P.C.",
        "affiliation_name": "Waseda University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60023462",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Phishing attacks detection using deep learning approach",
        "publication": "Proceedings of the 3rd International Conference on Smart Systems and Inventive Technology, ICSSIT 2020",
        "citied_by": "67",
        "cover_date": "2020-08-01",
        "Abstract": "In the COVID-19 pandemic, people are enforced to adopt 'work from home' policy. The Internet has become an effective channel for social interactions nowadays. Peoples' immense dependence on digital platform opens doors for fraud. Phishing is a type of cybercrime to steal users' credentials from online platforms such as online banking, online business, e-commerce, online classroom, digital marketplaces, etc. Phishers develop fake webpages alike the original one and send spam emails to hook the users. Phishers seize users' credentials when an online user visits the counterfeit webpages through the spams. Researchers have introduced enormous tools like blacklist, white-list, and antivirus software to detect phishing webpages. Attackers always devise creative ways to exploit human and network weakness to penetrate cyber defense. This paper presents a data-driven framework for detecting phishing webpages using deep learning approach. More precisely, a multilayer perceptron, which is also referred as a feed-forward neural network is used to predict the phishing webpages. The dataset was collected from Kaggle and contains information of ten thousand webpages. It consists of ten attributes. The proposed model has achieved 95% training accuracy and 93% test accuracy.",
        "DOI": "10.1109/ICSSIT48917.2020.9214132",
        "paper_author": "Saha I.",
        "affiliation_name": "University of Science and Technology Chittagong",
        "affiliation_city": "Chittagong",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60031570",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Information gain regulation in reinforcement learning with the digital twins' level of realism",
        "publication": "IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC",
        "citied_by": "4",
        "cover_date": "2020-08-01",
        "Abstract": "Digital Twin (DT) is widely used in various industrial sectors to optimize the operations and maintenance of physical assets, system and manufacturing processes. In this paper our goal is to introduce an architecture in which the radio access control happens automatically to minimize the utilized radio resources while still maximizing the production KPIs of the robot cell. To achieve this, we apply Reinforcement Learning (RL) in a simulated environment to explore the environment fast, while the DT ensures that the learned policy can be applied on the real world environment as well. We show that the application of Ultra Reliable Low Latency Communication (URLLC) connection can be reduced to approx. 30% of the total radio time while achieving real-world accurate robot control. The system in action can be seen on [1].",
        "DOI": "10.1109/PIMRC48278.2020.9217201",
        "paper_author": "Szabo G.",
        "affiliation_name": "Ericsson Hungary Ltd.",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary",
        "affiliation_id": "60080668",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Throughput maximization in C-RAN enabled virtualized wireless networks via multi-agent deep reinforcement learning",
        "publication": "IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC",
        "citied_by": "6",
        "cover_date": "2020-08-01",
        "Abstract": "With the excessive growth in mobile users' traffic, radio resource management (RRM) techniques should undergo revolutionary changes to be competent enough to meet the ever-increasing users' demands. Virtualized wireless network (VWN) has emerged as a satisfactory solution in the fifth-generation (5G) cellular networks ensuring the required quality-of-service (QoS) of distinct slices. Yet, it seems that tackling RRM problems in VWNs using conventional optimization is not practical for real-time applications. In this paper, driven by the advancements of machine learning, we consider the throughput maximization problem in a cloud radio access network (C-RAN) assisted softly virtualized wireless network supporting different types of services and solve it with a deep Q-learning (DQL) algorithm. The performance of the proposed policy is thoroughly evaluated via simulation results with respect to the isolation rate, penalty value as well as the discount factor. It is shown that our proposed policy achieves a higher sum rate compared to the existing baseline namely a greedy search-based power allocation strategy.",
        "DOI": "10.1109/PIMRC48278.2020.9217287",
        "paper_author": "Mohsenivatani M.",
        "affiliation_name": "K. N. Toosi University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60016248",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC 2020",
        "publication": "IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC",
        "citied_by": "0",
        "cover_date": "2020-08-01",
        "Abstract": "The proceedings contain 296 papers. The topics discussed include: low complexity joint user scheduling and hybrid beamforming for mmWave massive MIMO systems; good neighbor alternative to best response and machine learning based beamforming and power adaptation for MIMO ad hoc networks; multi-agent deep stochastic policy gradient for event based dynamic spectrum access; beam shape optimization method for low outage beamforming training with limited number of beams; virtual multiantenna array for estimating the DOA of a transmitter in UAV-assisted networks; modeling human body influence in UWB channels; low-complexity hybrid analog and digital precoding for mmWave MIMO systems; extreme values of trilateration localization error in wireless communication systems; and serial interference cancellation for improving uplink in LoRa-like networks.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning-based resource allocation in industrial IoT systems",
        "publication": "IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC",
        "citied_by": "2",
        "cover_date": "2020-08-01",
        "Abstract": "We consider an industrial internet-of-things (IIoT) system with multiple IoT devices, a user equipment (UE), together with a base station (BS) that receives the UE and IoT data. To circumvent the issue of numerous IoT-to-BS connections and to conserve IoT devices' energies, the UE serves as a relay to forward the IoT data to the BS. The UE employs frame-based uplink transmissions, wherein it shares few slots of every frame to relay the IoT data. The IIoT system experiences a transmission failure called outage when IoT data is not transmitted. The unsent UE data is stored in the UE's buffer and is discarded after the storage time exceeds the age threshold. As the UE and IoT devices share the transmission slots, trade-offs exist between system outages and aged UE data loss. To resolve system outage-data ageing challenge, we provide model-free reinforcement learning (RL)-based policies for slot-sharing between UE and IoT data. We compare the performance of the RL-based policies with low complexity heuristic-based slot-sharing schemes which either prioritise the UE data or account only for near-threshold aged UE data or are oblivious to the amount of UE data.",
        "DOI": "10.1109/PIMRC48278.2020.9217170",
        "paper_author": "Padakandla S.",
        "affiliation_name": "Indian Institute of Science",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60014097",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "An AI-Assisted Approach for Checking the Completeness of Privacy Policies against GDPR",
        "publication": "Proceedings of the IEEE International Conference on Requirements Engineering",
        "citied_by": "46",
        "cover_date": "2020-08-01",
        "Abstract": "Privacy policies are critical for helping individuals make informed decisions about their personal data. In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). If done entirely manually, checking whether a given privacy policy complies with GDPR is both time-consuming and error-prone. Automated support for this task is thus advantageous. At the moment, there is an evident lack of such support on the market. In this paper, we tackle an important dimension of GDPR compliance checking for privacy policies. Specifically, we provide automated support for checking whether the content of a given privacy policy is complete according to the provisions stipulated by GDPR. To do so, we present: (1) a conceptual model to characterize the information content envisaged by GDPR for privacy policies, (2) an AI-Assisted approach for classifying the information content in GDPR privacy policies and subsequently checking how well the classified content meets the completeness criteria of interest; and (3) an evaluation of our approach through a case study over 24 unseen privacy policies. For classification, we leverage a combination of Natural Language Processing and supervised Machine Learning. Our experimental material is comprised of 234 real privacy policies from the fund industry. Our empirical results indicate that our approach detected 45 of the total of 47 incompleteness issues in the 24 privacy policies it was applied to. Over these policies, the approach had eight false positives. The approach thus has a precision of 85% and recall of 96% over our case study.",
        "DOI": "10.1109/RE48521.2020.00025",
        "paper_author": "Torre D.",
        "affiliation_name": "University of Luxembourg",
        "affiliation_city": "Esch-sur-Alzette",
        "affiliation_country": "Luxembourg",
        "affiliation_id": "60072562",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning approaches in reliability and maintenance: Classifications of recent literature",
        "publication": "2020 Asia-Pacific International Symposium on Advanced Reliability and Maintenance Modeling, APARM 2020",
        "citied_by": "2",
        "cover_date": "2020-08-01",
        "Abstract": "Reliability and maintenance (RM) engineering is conventionally notorious for a lack of sufficient failure data to develop robust statistical models. The increasing miniaturization of data collection devices such as wireless sensors has provided a promising infrastructure for gathering information about parameters of the physical systems, which enable practitioners and researchers to apply machine learning (ML) algorithms to improve the efficiency of RM analysis. The number of published papers on ML in RM is enormous, this paper will therefore categorizes those papers that were published between 2017 to 16/May/2020, that are written in English, that have received a top 5% number of citations in the year published, and that use support vector methods, random forests, and cluster analysis.",
        "DOI": "10.1109/APARM49247.2020.9209392",
        "paper_author": "Wu S.",
        "affiliation_name": "Kent Business School",
        "affiliation_city": "Canterbury",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60162124",
        "affiliation_state": "Kent"
    },
    {
        "paper_title": "Smart e-Health Security and Safety Monitoring with Machine Learning Services",
        "publication": "Proceedings - International Conference on Computer Communications and Networks, ICCCN",
        "citied_by": "2",
        "cover_date": "2020-08-01",
        "Abstract": "This research provides security and safety extensions to a blockchain based solution whose target is e-health. The Advanced Blockchain platform is extended with intelligent monitoring for security and machine learning for detecting patient treatment medication safety issues. For the reasons of stringent HIPAA, HITECH, EU-GDPR and other regional regulations dictating security, safety and privacy requirements, the e-Health blockchains have to cover mandatory disclosure of violations or enforcements of policies during transaction flows involving healthcare. Our service solution further provides the benefits of resolving the abnormal flows of a medical treatment process, providing accountability of the service providers, enabling a trust health information environment for institutions to handle medication safely, giving patients a better safety guarantee, and enabling the authorities to supervise the security and safety of e-Health blockchains. The capabilities can be generalized to support a uniform smart solution across industry in a variety of blockchain applications.",
        "DOI": "10.1109/ICCCN49398.2020.9209679",
        "paper_author": "Liu W.",
        "affiliation_name": "School of Science and Technology Ggc",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125262400",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Advancement of weather-related crash prediction model using nonparametric machine learning algorithms",
        "publication": "SN Applied Sciences",
        "citied_by": "35",
        "cover_date": "2020-08-01",
        "Abstract": "This paper evaluates the machine learning-based weather-related crash prediction model in Connecticut. Crash severity prediction has always been the principal focus of safety professionals and emergency responders for appropriate policy making and resource management. Over the years, different statistical methodologies (e.g., random forest, support vector machine) have been explored in various research efforts to develop efficient crash severity prediction models. As technology is advancing and computing has started becoming more efficient, machine learning-based models for crash severity prediction are being brought into light for more accurate data-driven prediction. However, some machine learning methodologies provide increased efficiency and better performance compared to others from the same genre. To explore different machine learning methodologies for crash severity prediction, this study considered two machine learning applications—random forest (RF) and bayesian additive regression trees (BART) for performance comparison. RF model produced higher prediction probabilities for determining crash severity compare to BART. The results were evaluated using various prediction probability analyses obtained from these two machine learning models and showed the model capabilities to generate prediction consistent with the observed data. We found the performance of the RF model to be highly promising with a higher skill score (0.73) than BART (0.61). Overall, our findings demonstrate the robust performances of the RF algorithm in predicting weather-related crashes. The analysis of this study confirms that stakeholders can use weather-related RF model with confidence to obtain a better prediction of crash severity that enables them to facilitate appropriate emergency responses and support essential preemptive measures.",
        "DOI": "10.1007/s42452-020-03196-x",
        "paper_author": "Mondal A.R.",
        "affiliation_name": "UConn College of Engineering",
        "affiliation_city": "Storrs",
        "affiliation_country": "United States",
        "affiliation_id": "60151092",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Deep Reinforcement Learning in Immersive Virtual Reality Exergame for Agent Movement Guidance",
        "publication": "2020 IEEE 8th International Conference on Serious Games and Applications for Health, SeGAH 2020",
        "citied_by": "14",
        "cover_date": "2020-08-01",
        "Abstract": "Immersive Virtual Reality applied to exercise games has a unique potential to both guide and motivate users in performing physical exercise. Advances in modern machine learning open up new opportunities for more significant intelligence in such games. To this end, we investigate the following research question: What if we could train a virtual robot arm to guide us through physical exercises, compete with us, and test out various double-jointed movements? This paper presents a new game mechanic driven by artificial intelligence to visually assist users in their movements through the Unity Game Engine, Unity MI-Agents, and the HTC Vive Head-Mounted Display. We discuss how deep reinforcement learning through Proximal Policy Optimization and Generative Adversarial Imitation Learning can be applied to complete physical exercises from the same immersive virtual reality game. We examine our mechanics with four users through protecting a virtual butterfly with an agent that visually helps users as a cooperative 'ghost arm' and an independent competitor. Our results suggest that deep learning agents are effective at learning game exercises and may provide unique insights for users.",
        "DOI": "10.1109/SeGAH49190.2020.9201901",
        "paper_author": "Elor A.",
        "affiliation_name": "Baskin School of Engineering",
        "affiliation_city": "Santa Cruz",
        "affiliation_country": "United States",
        "affiliation_id": "60137794",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Deep reinforcement learning for greenhouse climate control",
        "publication": "Proceedings - 11th IEEE International Conference on Knowledge Graph, ICKG 2020",
        "citied_by": "19",
        "cover_date": "2020-08-01",
        "Abstract": "Worldwide, the area of greenhouse production is increasing with the rapid growth of global population and demands for fresh food. However, the greenhouse industry encounters challenges to find automatic control policy. Reinforcement Learning (RL) is a powerful tool in solving the autonomous decision making problems. In this paper, we propose a novel Deep Reinforcement Learning framework for cucumber climate control. Although some machine learning methods have been proposed to address the dynamic climate control problem, these methods have two major issues. First, they only consider the current reward (e.g., the fruit weight of the cucumber). Second, previous study only considers one control variable. However, the growth of crops are impacted by multiple factors synchronously (e.g., CO2 and Temperature).To solve these challenges, we propose a Deep Reinforcement learning based climate control method, which can model future reward explicitly. We further consider the fruit weight and the cost of the planting in order to improve the cumulative fruit weight and reduce the costs.Extensive experiments are conducted on the cucumber simulator environment have shown the superior performance of our methods.",
        "DOI": "10.1109/ICBK50248.2020.00073",
        "paper_author": "Wang L.",
        "affiliation_name": "East China Normal University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60021200",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Cache What You Need to Cache: Reducing Write Traffic in Cloud Cache via \"one-Time-Access-Exclusion\" Policy",
        "publication": "ACM Transactions on Storage",
        "citied_by": "7",
        "cover_date": "2020-08-01",
        "Abstract": "The SSD has been playing a significantly important role in caching systems due to its high performance-to-cost ratio. Since the cache space is typically much smaller than that of the backend storage by one order of magnitude or even more, write density (defined as writes per unit time and space) of the SSD cache is therefore much more intensive than that of HDD storage, which brings about tremendous challenges to the SSD's lifetime. Meanwhile, under social network workloads, quite a lot writes to the SSD cache are unnecessary. For example, our study on Tencent's photo caching shows that about 61% of total photos are accessed only once, whereas they are still swapped in and out of the cache. Therefore, if we can predict these kinds of photos proactively and prevent them from entering the cache, we can eliminate unnecessary SSD cache writes and improve cache space utilization. To cope with the challenge, we put forward a \"one-time-access criteria\"that is applied to the cache space and further propose a \"one-time-access-exclusion\"policy. Based on these two techniques, we design a prediction-based classifier to facilitate the policy. Unlike the state-of-the-art history-based predictions, our prediction is non-history oriented, which is challenging to achieve good prediction accuracy. To address this issue, we integrate a decision tree into the classifier, extract social-related information as classifying features, and apply cost-sensitive learning to improve classification precision. Due to these techniques, we attain a prediction accuracy greater than 80%. Experimental results show that the one-time-access-exclusion approach results in outstanding cache performance in most aspects. Take LRU, for instance: applying our approach improves the hit rate by 4.4%, decreases the cache writes by 56.8%, and cuts the average access latency by 5.5%.",
        "DOI": "10.1145/3397766",
        "paper_author": "Wang H.",
        "affiliation_name": "Wuhan National Laboratory for Optoelectronics",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60087294",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "DataOps for Societal Intelligence: A Data Pipeline for Labor Market Skills Extraction and Matching",
        "publication": "Proceedings - 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science, IRI 2020",
        "citied_by": "22",
        "cover_date": "2020-08-01",
        "Abstract": "Big Data analytics supported by AI algorithms enable skills localization and retrieval, in the context of a labor market intelligence problem. We formulate and solve this problem through specific DataOps models, blending data sources from administrative and technical partners in several countries into cooperation, creating shared knowledge to support policy and decision-making. We then focus on the critical task of skills extraction from resumes and vacancies featuring state-of-The-Art machine learning models. We showcase preliminary results with applied machine learning on real data from the employment agencies of the Netherlands and the Flemish region in Belgium. The final goal is to match these skills to standard ontologies of skills, jobs and occupations.",
        "DOI": "10.1109/IRI49571.2020.00063",
        "paper_author": "Tamburri D.A.",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60032882",
        "affiliation_state": "Noord-Brabant"
    },
    {
        "paper_title": "Global Land Temperature Forecasting Using Long Short-Term Memory Network",
        "publication": "Proceedings - 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science, IRI 2020",
        "citied_by": "5",
        "cover_date": "2020-08-01",
        "Abstract": "Based on NASA's 40 years of satellite data, earth has experienced drastic climatic changes in the form of sea-level rise, an increase in oceanic and atmospheric temperatures, depletion of the Ozone layer, and decrease in sea ice and snow cover. These observations point to the fact that the world is getting warmer, which significantly impacts humans and ecological systems. Forecasting global land temperature could help to identify the extent of devasting consequences on the natural habitat and shed light on the impact of policies, designed to mitigate them. Previous studies have attempted to forecast regional temperatures using traditional machine learning models. This paper uses a standard multi-layer perceptron, a simple Recurrent Neural Network, and a Long Short-Term Memory network to forecast next month's global land temperature. Our results show that deep learning outperforms traditional machine learning models, including decision tree, random forest, and ridge regression.",
        "DOI": "10.1109/IRI49571.2020.00038",
        "paper_author": "Maktala P.",
        "affiliation_name": "George Mason University",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States",
        "affiliation_id": "60018319",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Safe reinforcement learning using probabilistic shields",
        "publication": "Leibniz International Proceedings in Informatics, LIPIcs",
        "citied_by": "53",
        "cover_date": "2020-08-01",
        "Abstract": "This paper concerns the efficient construction of a safety shield for reinforcement learning. We specifically target scenarios that incorporate uncertainty and use Markov decision processes (MDPs) as the underlying model to capture such problems. Reinforcement learning (RL) is a machine learning technique that can determine near-optimal policies in MDPs that may be unknown before exploring the model. However, during exploration, RL is prone to induce behavior that is undesirable or not allowed in safety- or mission-critical contexts. We introduce the concept of a probabilistic shield that enables RL decision-making to adhere to safety constraints with high probability. We employ formal verification to efficiently compute the probabilities of critical decisions within a safety-relevant fragment of the MDP. These results help to realize a shield that, when applied to an RL algorithm, restricts the agent from taking unsafe actions, while optimizing the performance objective. We discuss tradeoffs between sufficient progress in the exploration of the environment and ensuring safety. In our experiments, we demonstrate on the arcade game PAC-MAN and on a case study involving service robots that the learning efficiency increases as the learning needs orders of magnitude fewer episodes.",
        "DOI": "10.4230/LIPIcs.CONCUR.2020.3",
        "paper_author": "Jansen N.",
        "affiliation_name": "Radboud Universiteit",
        "affiliation_city": "Nijmegen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60016529",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Exploring Influences of Built Environment on Car Ownership Based on a Machine Learning Method",
        "publication": "Jiaotong Yunshu Xitong Gongcheng Yu Xinxi/Journal of Transportation Systems Engineering and Information Technology",
        "citied_by": "8",
        "cover_date": "2020-08-01",
        "Abstract": "To analyze the car ownership behaviors, a gradient boosting decision tree (GBDT) method is employed to explore the effect sizes of residential and workplace built environments on car-ownership decisions. The empirical analysis is conducted based on the Changchun household travel survey data. The results show that the socio-economic factors contribute 58.95% to automobile ownership collectively and rank the first among the three categories of factors. The residential and workplace built environment variables are both associated with car ownership. And the residential built environment is more influential than the workplace built environment. Except for intersection density at residential locations, distance to the central business district(CBD), and bus stop density at workplace locations, all built environment variables have relative importance more than 5%. Therefore, it is of great importance for urban planners and policy makers to optimize the urban built environment to mitigate the increase of car ownership.",
        "DOI": "10.16097/j.cnki.1009-6744.2020.04.025",
        "paper_author": "Wang X.Q.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022381",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Impairing land registry: Social, demographic, and economic determinants of forest classification errors",
        "publication": "Remote Sensing",
        "citied_by": "8",
        "cover_date": "2020-08-01",
        "Abstract": "This paper investigates the social, demographic, and economic factors determining differences between forest identification based on remote sensing techniques and land registry. The Database of Topographic Objects and Sentinel-2 satellite imagery data from 2018 were used to train a forest detection supervised machine learning model. Results aggregated to communes (NUTS-5 units) were compared to data from land registry delivered in Local Data Bank by Statistics Poland. The differences identified between above mentioned sources were defined as errors of land registry. Then, geographically weighted regression was applied to explain spatially varying impact of investigated errors' determinants: Urbanization processes, civic society development, education, land ownership, and culture and quality of spatial planning. The research area covers the entirety of Poland. It was confirmed that in less developed areas, local development policy stimulating urbanization processes does not respect land use planning principles, including the accuracy of land registry. A high education level of the society leads to protective measures before the further increase of the investigated forest cover's overestimation of the land registry in substantially urbanized areas. Finally, higher coverage by valid local spatial development plans stimulate protection against forest classification errors in the land registry.",
        "DOI": "10.3390/RS12162628",
        "paper_author": "Adamiak M.",
        "affiliation_name": "SoftwareMill",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "124221070",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Sleeping Multi-Armed Bandit Learning for Fast Uplink Grant Allocation in Machine Type Communications",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "31",
        "cover_date": "2020-08-01",
        "Abstract": "Scheduling fast uplink grant transmissions for machine type communications (MTCs) is one of the main challenges of future wireless systems. In this paper, a novel fast uplink grant scheduling method based on the theory of multi-armed bandits (MABs) is proposed. First, a single quality-of-service metric is defined as a combination of the value of data packets, maximum tolerable access delay, and data rate. Since full knowledge of these metrics for all machine type devices (MTDs) cannot be known in advance at the base station (BS) and the set of active MTDs changes over time, the problem is modeled as a sleeping MAB with stochastic availability and a stochastic reward function. In particular, given that, at each time step, the knowledge on the set of active MTDs is probabilistic, a novel probabilistic sleeping MAB algorithm is proposed to maximize the defined metric. Analysis of the regret is presented and the effect of the prediction error of the source traffic prediction algorithm on the performance of the proposed sleeping MAB algorithm is investigated. Moreover, to enable fast uplink allocation for multiple MTDs at each time, a novel method is proposed based on the concept of best arms ordering in the MAB setting. Simulation results show that the proposed framework yields a three-fold reduction in latency compared to a maximum probability scheduling policy since it prioritizes the scheduling of MTDs that have stricter latency requirements. Moreover, by properly balancing the exploration versus exploitation tradeoff, the proposed algorithm selects the most important MTDs more often by exploitation. During exploration, the sub-optimal MTDs will be selected, which increases the fairness in the system, and, also provides a better estimate of the reward of the sub-optimal MTD.",
        "DOI": "10.1109/TCOMM.2020.2989338",
        "paper_author": "Ali S.",
        "affiliation_name": "Centre for Wireless Communications",
        "affiliation_city": "Oulu",
        "affiliation_country": "Finland",
        "affiliation_id": "60001738",
        "affiliation_state": "North Ostrobothnia"
    },
    {
        "paper_title": "Species ecological envelopes under climate change scenarios: A case study for the main two wood-production forest species in Portugal",
        "publication": "Forests",
        "citied_by": "8",
        "cover_date": "2020-08-01",
        "Abstract": "Species ecological envelope maps were obtained for the two main Portuguese wood-production species (Eucalyptus globulus Labill. and Pinus pinaster Aiton) and projected future climate change scenarios. A machine learning approach was used to understand the most influential environmental variables that may explain current species distribution and productivity. Background and Objectives: The aims of the study were: (1) to map species potential suitability areas using ecological envelopes in the present and to project them in the future under climate change scenarios; (2) to map species current distributions; (3) to map species current productivity; and (4) to explore the most influential environmental variables on species current distribution and productivity. Materials and Methods: Climate, elevation data, and soil data sets were used to obtain present and future species ecological envelopes under two climate change scenarios. The official land cover maps were used to map species distributions. Forest inventory data were used to map the species productivity by geostatistical techniques. A Bayesian machine learning approach, supported by species distributions and productivity data, was used to explore the most influential environmental variables on species distribution and productivity and to validate species ecological envelopes. Results: The species ecological envelope methodology was found to be robust. Species' ecological envelopes showed a high potential for both species' afforestation. In the future, a decrease in the country's area potentiality was forecasted for both species. The distribution of maritime pine was found to be mainly determined by precipitation-related variables, but the elevation and temperature-related variables were very important to differentiate species productivity. For eucalypts, species distribution was mainly explained by temperature-related variables, as well as the species productivity. Conclusions: These findings are key to support recommendations for future afforestation and will bring value to policy-makers and environmental authorities in policy formulation under climate change scenarios.",
        "DOI": "10.3390/F11080880",
        "paper_author": "Alegria C.",
        "affiliation_name": "Instituto Politécnico de Castelo Branco",
        "affiliation_city": "Castelo Branco",
        "affiliation_country": "Portugal",
        "affiliation_id": "60000302",
        "affiliation_state": "Castelo Branco"
    },
    {
        "paper_title": "Efficiently evaluating targeting policies: Improving on champion vs. Challenger experiments",
        "publication": "Management Science",
        "citied_by": "20",
        "cover_date": "2020-08-01",
        "Abstract": "Champion versus challenger field experiments are widely used to compare the performance of different targeting policies. These experiments randomly assign customers to receive marketing actions recommended by either the existing (champion) policy or the new (challenger) policy, and then compare the aggregate outcomes. We recommend an alternative experimental design and propose an alternative estimation approach to improve the evaluation of targeting policies. The recommended experimental design randomly assigns customers to marketing actions. This allows evaluation of any targeting policy without requiring an additional experiment, including policies designed after the experiment is implemented. The proposed estimation approach identifies customers for whom different policies recommend the same action and recognizes that for these customers there is no difference in performance. This allows for a more precise comparison of the policies. We illustrate the advantages of the experimental design and estimation approach using data from an actual field experiment. We also demonstrate that the grouping of customers, which is the foundation of our estimation approach, can help to improve the training of new targeting policies.",
        "DOI": "10.1287/mnsc.2019.3379",
        "paper_author": "Simester D.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Assessing public opinion on crispr-cas9: Combining crowdsourcing and deep learning",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "17",
        "cover_date": "2020-08-01",
        "Abstract": "Background: The discovery of the CRISPR-Cas9-based gene editing method has opened unprecedented new potential for biological and medical engineering, sparking a growing public debate on both the potential and dangers of CRISPR applications. Given the speed of technology development and the almost instantaneous global spread of news, it is important to follow evolving debates without much delay and in sufficient detail, as certain events may have a major long-term impact on public opinion and later influence policy decisions. Objective: Social media networks such as Twitter have shown to be major drivers of news dissemination and public discourse. They provide a vast amount of semistructured data in almost real-time and give direct access to the content of the conversations. We can now mine and analyze such data quickly because of recent developments in machine learning and natural language processing. Methods: Here, we used Bidirectional Encoder Representations from Transformers (BERT), an attention-based transformer model, in combination with statistical methods to analyze the entirety of all tweets ever published on CRISPR since the publication of the first gene editing application in 2013. Results: We show that the mean sentiment of tweets was initially very positive, but began to decrease over time, and that this decline was driven by rare peaks of strong negative sentiments. Due to the high temporal resolution of the data, we were able to associate these peaks with specific events and to observe how trending topics changed over time. Conclusions: Overall, this type of analysis can provide valuable and complementary insights into ongoing public debates, extending the traditional empirical bioethics toolset.",
        "DOI": "10.2196/17830",
        "paper_author": "Müller M.",
        "affiliation_name": "École Polytechnique Fédérale de Lausanne",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60028186",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning-based detection for cyber security attacks on connected and autonomous vehicles",
        "publication": "Mathematics",
        "citied_by": "59",
        "cover_date": "2020-08-01",
        "Abstract": "Connected and Autonomous Vehicle (CAV)-related initiatives have become some of the fastest expanding in recent years, and have started to affect the daily lives of people. More and more companies and research organizations have announced their initiatives, and some have started CAV road trials. Governments around the world have also introduced policies to support and accelerate the deployments of CAVs. Along these, issues such as CAV cyber security have become predominant, forming an essential part of the complications of CAV deployment. There is, however, no universally agreed upon or recognized framework for CAV cyber security. In this paper, following the UK CAV cyber security principles, we propose a UML (Unified Modeling Language)-based CAV cyber security framework, and based on which we classify the potential vulnerabilities of CAV systems. With this framework, a new CAV communication cyber-attack data set (named CAV-KDD) is generated based on the widely tested benchmark data set KDD99. This data set focuses on the communication-based CAV cyber-attacks. Two classification models are developed, using two machine learning algorithms, namely Decision Tree and Naive Bayes, based on the CAV-KDD training data set. The accuracy, precision and runtime of these two models when identifying each type of communication-based attacks are compared and analysed. It is found that the Decision Tree model requires a shorter runtime, and is more appropriate for CAV communication attack detection.",
        "DOI": "10.3390/MATH8081311",
        "paper_author": "He Q.",
        "affiliation_name": "University of Nottingham",
        "affiliation_city": "Nottingham",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015138",
        "affiliation_state": "Nottinghamshire"
    },
    {
        "paper_title": "Managing illicit online pharmacies: Web analytics and predictive models study",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "11",
        "cover_date": "2020-08-01",
        "Abstract": "Background: Online pharmacies have grown significantly in recent years, from US $29.35 billion in 2014 to an expected US $128 billion in 2023 worldwide. Although legitimate online pharmacies (LOPs) provide a channel of convenience and potentially lower costs for patients, illicit online pharmacies (IOPs) open the doors to unfettered access to prescription drugs, controlled substances (eg, opioids), and potentially counterfeits, posing a dramatic risk to the drug supply chain and the health of the patient. Unfortunately, we know little about IOPs, and even identifying and monitoring IOPs is challenging because of the large number of online pharmacies (at least 30,000-35,000) and the dynamic nature of the online channel (online pharmacies open and shut down easily). Objective: This study aims to increase our understanding of IOPs through web data traffic analysis and propose a novel framework using referral links to predict and identify IOPs, the first step in fighting IOPs. Methods: We first collected web traffic and engagement data to study and compare how consumers access and engage with LOPs and IOPs. We then proposed a simple but novel framework for predicting the status of online pharmacies (legitimate or illicit) through the referral links between websites. Under this framework, we developed 2 prediction models, the reference rating prediction method (RRPM) and the reference-based K-nearest neighbor. Results: We found that direct (typing URL), search, and referral are the 3 major traffic sources, representing more than 95% traffic to both LOPs and IOPs. It is alarming to see that direct represents the second-highest traffic source (34.32%) to IOPs. When tested on a data set with 763 online pharmacies, both RRPM and R2NN performed well, achieving an accuracy above 95% in their predictions of the status for the online pharmacies. R2NN outperformed RRPM in full performance metrics (accuracy, kappa, specificity, and sensitivity). On implementing the 2 models on Google search results for popular drugs (Xanax [alprazolam], OxyContin, and opioids), they produced an error rate of only 7.96% (R2NN) and 6.20% (RRPM). Conclusions: Our prediction models use what we know (referral links) to tackle the many unknown aspects of IOPs. They have many potential applications for patients, search engines, social media, payment companies, policy makers or government agencies, and drug manufacturers to help fight IOPs. With scarce work in this area, we hope to help address the current opioid crisis from this perspective and inspire future research in the critical area of drug safety.",
        "DOI": "10.2196/17239",
        "paper_author": "Zhao H.",
        "affiliation_name": "Penn State Smeal College of Business",
        "affiliation_city": "University Park",
        "affiliation_country": "United States",
        "affiliation_id": "60116247",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Predictive insights for improving the resilience of global food security using artificial intelligence",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "26",
        "cover_date": "2020-08-01",
        "Abstract": "Unabated pressures on food systems affect food security on a global scale. A human-centric artificial intelligence-based probabilistic approach is used in this paper to perform a unified analysis of data from the Global Food Security Index (GFSI). The significance of this intuitive probabilistic reasoning approach for predictive forecasting lies in its simplicity and user-friendliness to people who may not be trained in classical computer science or in software programming. In this approach, predictive modeling using a counterfactual probabilistic reasoning analysis of the GFSI dataset can be utilized to reveal the interplay and tensions between the variables that underlie food affordability, food availability, food quality and safety, and the resilience of natural resources. Exemplars are provided in this paper to illustrate how computational simulations can be used to produce forecasts of good and bad conditions in food security using multi-variant optimizations. The forecast of these future scenarios is useful for informing policy makers and stakeholders across domain verticals, so they can make decisions that are favorable to global food security.",
        "DOI": "10.3390/SU12156272",
        "paper_author": "How M.L.",
        "affiliation_name": "National Institute of Education",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60010940",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Bootstrap Aggregation and Cross-Validation Methods to Reduce Overfitting in Reservoir Control Policy Search",
        "publication": "Water Resources Research",
        "citied_by": "31",
        "cover_date": "2020-08-01",
        "Abstract": "Policy search methods provide a heuristic mapping between observations and decisions and have been widely used in reservoir control studies. However, recent studies have observed a tendency for policy search methods to overfit to the hydrologic data used in training, particularly the sequence of flood and drought events. This technical note develops an extension of bootstrap aggregation (bagging) and cross-validation techniques, inspired by the machine learning literature, to improve reservoir control policy performance on out-of-sample hydrological sequences. We explore these methods using a case study of Folsom Reservoir, California, using control policies structured as binary trees, and streamflow resampling based on the paleo-inflow record. Results show that calibration-validation strategies for policy selection coupled with certain ensemble aggregation methods can improve out-of-sample performance in water supply and flood risk objectives over baseline performance given fixed computational costs. Our findings highlight the potential to improve policy search methodologies by leveraging these well-established model training strategies from machine learning.",
        "DOI": "10.1029/2020WR027184",
        "paper_author": "Brodeur Z.P.",
        "affiliation_name": "Department of Biological and Environmental Engineering",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60144812",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Ethics in Health Informatics",
        "publication": "Yearbook of medical informatics",
        "citied_by": "19",
        "cover_date": "2020-08-01",
        "Abstract": "Contemporary bioethics was fledged and is sustained by challenges posed by new technologies. These technologies have affected many lives. Yet health informatics affects more lives than any of them. The challenges include the development and the appropriate uses and users of machine learning software, the balancing of privacy rights against the needs of public health and clinical practice in a time of Big Data analytics, whether and how to use this technology, and the role of ethics and standards in health policy. Historical antecedents in statistics and evidence-based practice foreshadow some of the difficulties now faced, but the scope and scale of these challenges requires that ethics, too, be brought to scale in parallel, especially given the size of contemporary data sets and the processing power of new computers. Fortunately, applied ethics affords a variety of tools to help identify and rank applicable values, support best practices, and contribute to standards. The bioethics community can in partnership with the informatics community arrive at policies that promote the health sciences while reaffirming the many and varied rights that patients expect will be honored.",
        "DOI": "10.1055/s-0040-1701966",
        "paper_author": "Goodman K.W.",
        "affiliation_name": "University of Miami Leonard M. Miller School of Medicine",
        "affiliation_city": "Miami",
        "affiliation_country": "United States",
        "affiliation_id": "60021519",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Characteristics of twitter use by state medicaid programs in the United States: Machine learning approach",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "5",
        "cover_date": "2020-08-01",
        "Abstract": "Background: Twitter is a potentially valuable tool for public health officials and state Medicaid programs in the United States, which provide public health insurance to 72 million Americans. Objective: We aim to characterize how Medicaid agencies and managed care organization (MCO) health plans are using Twitter to communicate with the public. Methods: Using Twitter's public application programming interface, we collected 158,714 public posts (\"tweets\") from active Twitter profiles of state Medicaid agencies and MCOs, spanning March 2014 through June 2019. Manual content analyses identified 5 broad categories of content, and these coded tweets were used to train supervised machine learning algorithms to classify all collected posts. Results: We identified 15 state Medicaid agencies and 81 Medicaid MCOs on Twitter. The mean number of followers was 1784, the mean number of those followed was 542, and the mean number of posts was 2476. Approximately 39% of tweets came from just 10 accounts. Of all posts, 39.8% (63,168/158,714) were classified as general public health education and outreach; 23.5% (n=37,298) were about specific Medicaid policies, programs, services, or events; 18.4% (n=29,203) were organizational promotion of staff and activities; and 11.6% (n=18,411) contained general news and news links. Only 4.5% (n=7142) of posts were responses to specific questions, concerns, or complaints from the public. Conclusions: Twitter has the potential to enhance community building, beneficiary engagement, and public health outreach, but appears to be underutilized by the Medicaid program.",
        "DOI": "10.2196/18401",
        "paper_author": "Zhu J.M.",
        "affiliation_name": "Oregon Health &amp; Science University",
        "affiliation_city": "Portland",
        "affiliation_country": "United States",
        "affiliation_id": "60016733",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Predicting car availability in free floating car sharing systems: Leveraging machine learning in challenging contexts",
        "publication": "Electronics (Switzerland)",
        "citied_by": "10",
        "cover_date": "2020-08-01",
        "Abstract": "Free-Floating Car Sharing (FFCS) services are currently available in tens of cities and countries spread all over the worlds. Depending on citizens’ habits, service policies, and road conditions, car usage profiles are rather variable and often hardly predictable. Even within the same city, different usage trends emerge in different districts and in various time slots and weekdays. Therefore, modeling car availability in FFCS systems is particularly challenging. For these reasons, the research community has started to investigate the applicability of Machine Learning models to analyze FFCS usage data. This paper addresses the problem of predicting the short-term level of availability of the FFCS service in the short term. Specifically, it investigates the applicability of Machine Learning models to forecast the number of available car within a restricted urban area. It seeks the spatial and temporal contexts in which nonlinear ML models, trained on past usage data, are necessary to accurately predict car availability. Leveraging ML has shown to be particularly effective while considering highly dynamic urban contexts, where FFCS service usage is likely to suddenly and unexpectedly change. To tailor predictive models to the real FFCS data, we study also the influence of ML algorithm, prediction horizon, and characteristics of the neighborhood of the target area. The empirical outcomes allow us to provide system managers with practical guidelines to setup and tune ML models.",
        "DOI": "10.3390/electronics9081322",
        "paper_author": "Daraio E.",
        "affiliation_name": "Politecnico di Torino",
        "affiliation_city": "Turin",
        "affiliation_country": "Italy",
        "affiliation_id": "60012162",
        "affiliation_state": "TO"
    },
    {
        "paper_title": "Communication behavior changes between patients with diabetes and healthcare providers over 9 years: Retrospective cohort study",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "12",
        "cover_date": "2020-08-01",
        "Abstract": "Background: Health organizations and patients interact over different communication channels and are harnessing digital communications for this purpose. Assisting health organizations to improve, adapt, and introduce new patient-health care practitioner communication channels (such as patient portals, mobile apps, and text messaging) enhances health care services access. Objective: This retrospective data study aims to assist health care administrators and policy makers to improve and personalize communication between patients and health care professionals by expanding the capabilities of current communication channels and introducing new ones. Our main hypothesis is that patient follow-up and clinical outcomes are influenced by their preferred communication channels with the health care organization. Methods: This study analyzes data stored in electronic medical records and logs documenting access to various communication channels between patients and a health organization (Clalit Health Services, Israel). Data were collected between 2008 and 2016 from records of 311,168 patients diagnosed with diabetes, aged 21 years and over, members of Clalit at least since 2007, and still alive in 2016. The analysis consisted of characterizing the use profiles of communication channels over time and used clustering for discretization purposes and patient profile building and then a hierarchical clustering and heatmaps to visualize the different communication profiles. Results: A total of 13 profiles of patients were identified and characterized. We have shown how the communication channels provided by the health organization influence the communication behavior of patients. We observed how different patients respond differently to technological means of communication and change or don't change their communication patterns with the health care organization based on the communication channels available to them. Conclusions: Identifying the channels of communication within the health organization and which are preferred by each patient creates an opportunity to convey messages adapted to the patient in the most appropriate way. The greater the likelihood that the therapeutic message is received by the patient, the greater the patient's response and proactiveness to the treatment will be.",
        "DOI": "10.2196/17186",
        "paper_author": "Benis A.",
        "affiliation_name": "Holon Institute of Technology",
        "affiliation_city": "Holon",
        "affiliation_country": "Israel",
        "affiliation_id": "60016941",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Remote monitoring of agricultural systems using NDVI time series and machine learning methods: a tool for an adaptive agricultural policy",
        "publication": "Arabian Journal of Geosciences",
        "citied_by": "21",
        "cover_date": "2020-08-01",
        "Abstract": "This study aims to provide accurate information about changes in agricultural systems (AS) using phenological metrics derived from the NDVI time series. Use of such information could help land managers optimize land use choices and monitor the status of agricultural lands, under a variety of environmental and socioeconomic conditions. For this purpose, the Moderate Resolution Imaging Spectroradiometer (MODIS) NDVI data were used to derive phenological metrics over the Oum Er-Rbia basin (central Morocco). Random forest (RF), support vector machine (SVM), and K-nearest neighbor (KNN) classifiers were explored and compared on their ability to classify AS classes over the study area. Four main AS classes have been considered: (1) irrigated annual crop (IAC), (2) irrigated perennial crop (IPC), (3) rainfed area (RA), and (4) fallow (FA). By comparing the accuracy of the three classifiers, the RF method showed the best performance with an overall accuracy of 0.97 and kappa coefficient of 0.96. The RF method was then chosen to examine time variations in AS over a 16-year period (2000–2016). The AS main variations were detected and evaluated for the four AS classes. These variations have been found to be linked well with other indicators of local agricultural land management, as well as the historical agricultural drought changes over the study area. Overall, the results present a tool for decision makers to improve agricultural management and provide a different perspective in understanding the spatiotemporal dynamics of agricultural systems.",
        "DOI": "10.1007/s12517-020-05789-7",
        "paper_author": "Lebrini Y.",
        "affiliation_name": "Faculté des Sciences et Techniques",
        "affiliation_city": "Beni Mellal",
        "affiliation_country": "Morocco",
        "affiliation_id": "60026301",
        "affiliation_state": "Béni Mellal-Khénifra"
    },
    {
        "paper_title": "Approaches Based on artificial intelligence and the internet of intelligent things to prevent the spread of COVID-19: Scoping review",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "120",
        "cover_date": "2020-08-01",
        "Abstract": "Background: Artificial intelligence (AI) and the Internet of Intelligent Things (IIoT) are promising technologies to prevent the concerningly rapid spread of coronavirus disease (COVID-19) and to maximize safety during the pandemic. With the exponential increase in the number of COVID-19 patients, it is highly possible that physicians and health care workers will not be able to treat all cases. Thus, computer scientists can contribute to the fight against COVID-19 by introducing more intelligent solutions to achieve rapid control of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes the disease. Objective: The objectives of this review were to analyze the current literature, discuss the applicability of reported ideas for using AI to prevent and control COVID-19, and build a comprehensive view of how current systems may be useful in particular areas. This may be of great help to many health care administrators, computer scientists, and policy makers worldwide. Methods: We conducted an electronic search of articles in the MEDLINE, Google Scholar, Embase, and Web of Knowledge databases to formulate a comprehensive review that summarizes different categories of the most recently reported AI-based approaches to prevent and control the spread of COVID-19. Results: Our search identified the 10 most recent AI approaches that were suggested to provide the best solutions for maximizing safety and preventing the spread of COVID-19. These approaches included detection of suspected cases, large-scale screening, monitoring, interactions with experimental therapies, pneumonia screening, use of the IIoT for data and information gathering and integration, resource allocation, predictions, modeling and simulation, and robotics for medical quarantine. Conclusions: We found few or almost no studies regarding the use of AI to examine COVID-19 interactions with experimental therapies, the use of AI for resource allocation to COVID-19 patients, or the use of AI and the IIoT for COVID-19 data and information gathering/integration. Moreover, the adoption of other approaches, including use of AI for COVID-19 prediction, use of AI for COVID-19 modeling and simulation, and use of AI robotics for medical quarantine, should be further emphasized by researchers because these important approaches lack sufficient numbers of studies. Therefore, we recommend that computer scientists focus on these approaches, which are still not being adequately addressed.",
        "DOI": "10.2196/19104",
        "paper_author": "Adly A.S.",
        "affiliation_name": "Faculty of Computers and Artificial Intelligence",
        "affiliation_city": "Helwan",
        "affiliation_country": "Egypt",
        "affiliation_id": "60273091",
        "affiliation_state": "Cairo"
    },
    {
        "paper_title": "Identifying vulnerable households using machine-learning",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "19",
        "cover_date": "2020-08-01",
        "Abstract": "Many Afghanistan households face food insecurity (FI), and this threatens sustainable development. Policymakers and international donors are trying to alleviate FI using food aid, development assistance, and outreach. This study identified household characteristics that discriminate between food-insecure and food-secure households, facilitating accurate assistance targeting in Afghanistan. We used machine-learning classification models (classification decision tree and random forest model) and applied to a household survey. This was done using equal priors and 1.5:1 misclassification penalties. The resulting model is able to correctly identify 80% of food-insecure households. Characteristics in six major categories are found important. Unsurprisingly traditional key variables, such as (1) income and expenditure items, (2) household size, (3) farm-related measures; (4) access to particular resources, and (5) short term shocks are important determinants of food security level. We also found the relevance of long-term household characteristics, such as dwelling wall composition, which are not generally addressed in the existing literature. We argue that these are reflective of accumulated household wealth and this supports the idea that some factors determining food security are persistent. We also found that commonly used demographic variables were not important.",
        "DOI": "10.3390/su12156002",
        "paper_author": "Gao C.",
        "affiliation_name": "Facebook, Inc.",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States",
        "affiliation_id": "60109024",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Measurement method for evaluating the lockdown policies during the COVID-19 pandemic",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "27",
        "cover_date": "2020-08-01",
        "Abstract": "Coronavirus Disease 2019 (COVID-19) has affected day to day life and slowed down the global economy. Most countries are enforcing strict quarantine to control the havoc of this highly contagious disease. Since the outbreak of COVID-19, many data analyses have been done to provide close support to decision-makers. We propose a method comprising data analytics and machine learning classification for evaluating the effectiveness of lockdown regulations. Lockdown regulations should be reviewed on a regular basis by governments, to enable reasonable control over the outbreak. The model aims to measure the efficiency of lockdown procedures for various countries. The model shows a direct correlation between lockdown procedures and the infection rate. Lockdown efficiency is measured by finding a correlation coefficient between lockdown attributes and the infection rate. The lockdown attributes include retail and recreation, grocery and pharmacy, parks, transit stations, workplaces, residential, and schools. Our results show that combining all the independent attributes in our study resulted in a higher correlation (0.68) to the dependent value Interquartile 3 (Q3). Mean Absolute Error (MAE) was found to be the least value when combining all attributes.",
        "DOI": "10.3390/ijerph17155574",
        "paper_author": "Zobbi M.A.",
        "affiliation_name": "Western Sydney University",
        "affiliation_city": "Penrith",
        "affiliation_country": "Australia",
        "affiliation_id": "60017803",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Increasing generality in machine learning through procedural content generation",
        "publication": "Nature Machine Intelligence",
        "citied_by": "72",
        "cover_date": "2020-08-01",
        "Abstract": "Procedural content generation (PCG) refers to the practice of generating game content, such as levels, quests or characters, algorithmically. Motivated by the need to make games replayable, as well as to reduce authoring burden and enable particular aesthetics, many PCG methods have been devised. At the same time that researchers are adapting methods from machine learning (ML) to PCG problems, the ML community has become more interested in PCG-inspired methods. One reason for this development is that ML algorithms often only work for a particular version of a particular task with particular initial parameters. In response, researchers have begun exploring randomization of problem parameters to counteract such overfitting and to allow trained policies to more easily transfer from one environment to another, such as from a simulated robot to a robot in the real world. Here we review existing work on PCG, its overlap with current efforts in ML, and promising new research directions such as procedurally generated learning environments. Although originating in games, we believe PCG algorithms are critical to creating more general machine intelligence.",
        "DOI": "10.1038/s42256-020-0208-z",
        "paper_author": "Risi S.",
        "affiliation_name": "modl.ai",
        "affiliation_city": "Copenhagen",
        "affiliation_country": "Denmark",
        "affiliation_id": "123279994",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mitigating insider threats using bio-inspired models",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "15",
        "cover_date": "2020-08-01",
        "Abstract": "Insider threats have become a considerable information security issue that governments and organizations must face. The implementation of security policies and procedures may not be enough to protect organizational assets. Even with the evolution of information and network security technology, the threat from insiders is increasing. Many researchers are approaching this issue with various methods in order to develop a model that will help organizations to reduce their exposure to the threat and prevent damage to their assets. In this paper, we approach the insider threat problem and attempt to mitigate it by developing a machine learning model based on Bio-inspired computing. The model was developed by using an existing unsupervised learning algorithm for anomaly detection and we fitted the model to a synthetic dataset to detect outliers. We explore swarm intelligence algorithms and their performance on feature selection optimization for improving the performance of the machine learning model. The results show that swarm intelligence algorithms perform well on feature selection optimization and the generated, near-optimal, subset of features has a similar performance to the original one.",
        "DOI": "10.3390/app10155046",
        "paper_author": "Nicolaou A.",
        "affiliation_name": "Open University of Cyprus",
        "affiliation_city": "Nicosia",
        "affiliation_country": "Cyprus",
        "affiliation_id": "60108559",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of artificial neural network for optimal operation of a multi-purpose multi-reservoir system, II: optimal solution and performance evaluation",
        "publication": "Sustainable Water Resources Management",
        "citied_by": "4",
        "cover_date": "2020-08-01",
        "Abstract": "This papers forms the second part of series on application of artificial neural network (ANN) for optimal operation of a multi-purpose multi-reservoir system. Optimal operating policies of a reservoir system are derived using Discrete differential dynamic programming (DDDP)-based ANN model. In ANN model development a feed-forward network with delta learning rule and back propagation algorithm is used. Neural networks have been trained using supervised learning approach. Water supply for irrigation, municipal and industrial use have been selected as objective of operation and other purposes are treated as binding constraints. Minimization of the sum of square of penalties incurred due to deviation of release from the target, is selected as the objective function. Damodar Valley (DV), a multi-purpose four reservoir system in India is used for this study. With different combination of input data, five types of ANN models are developed. Simulation has been done with 5 years (out of 1000 years) generated monthly inflow sequence as well as three types of observed historical monthly inflow sequences: maximum annual inflow year, 75% dependable inflow year and minimum annual inflow year. For simulation, total 360 monthly networks are trained and stored. ANN model: in which initial storage, current period’s inflow and previous period’s inflow are considered as input and optimal final state as output, yields lowest objective function value. Performances of the said model is computed based on modern reliability parameters, i.e., reliability, resiliency and vulnerability.",
        "DOI": "10.1007/s40899-020-00423-6",
        "paper_author": "Shaikh S.A.",
        "affiliation_name": "Aliah University",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India",
        "affiliation_id": "60275530",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Howard’s algorithm for high-order approximations of American options under jump-diffusion models",
        "publication": "International Journal of Data Science and Analytics",
        "citied_by": "2",
        "cover_date": "2020-08-01",
        "Abstract": "Data-driven approaches to price computations of financial options are gaining in importance relative to methods based on numerical solutions of the pricing equations. Comparisons between artificial neural networks and the Black–Scholes pricing model have shown that the machine learning technique compares well in terms of performance with the parametric model. A Bayesian neural network model has recently been employed for predicting the price of options under jump-diffusion models since jump processes have a better capability of fitting market options data. The potential applicability of data-driven models for generating price approximations under jump processes is high, but due to the need of ensuring that computed prices are arbitrage-free, validation by the often employed partial differential equations approach is important. This work proposes a new algorithm that can be used for comparing prices obtained by a learning algorithm for diffusion models with jumps. Two directions are chosen in order to develop a competitive algorithm. The first is employing a higher-order discretisation of the pricing partial integro-differential equation and second using a more efficient numerical procedure for the solution of the resulting linear complementarity problem. Howard’s algorithm or policy iteration is one such procedure for the second phase, but application of this method requires that the coefficient matrix is monotone. The combination of high-order approximations for the derivative and integral terms with policy iteration yields an accurate and efficient computational technique, and these properties are illustrated using an extensive set of numerical examples.",
        "DOI": "10.1007/s41060-018-00173-x",
        "paper_author": "Thakoor N.",
        "affiliation_name": "University of Mauritius",
        "affiliation_city": "Reduit",
        "affiliation_country": "Mauritius",
        "affiliation_id": "60072656",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Accelerating nonlinear model predictive control through machine learning",
        "publication": "Journal of Process Control",
        "citied_by": "33",
        "cover_date": "2020-08-01",
        "Abstract": "The high computational requirements of nonlinear model predictive control (NMPC) are a long-standing issue and, among other methods, learning the control policy with machine learning (ML) methods has been proposed in order to improve computational tractability. However, these methods typically do not explicitly consider constraint satisfaction. We propose two methods based on learning the optimal control policy by an artificial neural network (ANN) and using this for initialization to accelerate computations while meeting constraints and achieving good objective function value. In the first, the ANN prediction serves as the initial guess for the solution of the optimal control problem (OCP) solved in NMPC. In the second, the ANN prediction is improved by solving a single quadratic program (QP). We compare the performance of the two proposed strategies against two benchmarks representing the extreme cases of (i) solving the NMPC problem to convergence using the shift-initialization strategy and (ii) implementing the controls predicted by the ANN prediction without further correction to reduce the computational delay. We find that the proposed ANN initialization strategy mostly results in the same control policy as the shift-initialization strategy. The computational times are on average ∼45% longer but the maximum time is ∼42% smaller and the distribution is tighter, thus more predictable. The proposed QP-based method yields a good compromise between finding the optimal control policy and solution time. Closed-loop infeasibilities are negligible and the objective function is typically greatly improved as compared to benchmark (ii). The computational time required for the necessary second-order sensitivity integration is typically an order of magnitude smaller than for solving the NMPC problem to convergence.",
        "DOI": "10.1016/j.jprocont.2020.06.012",
        "paper_author": "Vaupel Y.",
        "affiliation_name": "Rheinisch-Westfälische Technische Hochschule Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany",
        "affiliation_id": "60016653",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Efficient proactive vehicle relocation for on-demand mobility service with recurrent neural networks",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "32",
        "cover_date": "2020-08-01",
        "Abstract": "One major challenge for on-demand mobility service (OMS) providers is to seamlessly match empty vehicles with trip requests so that the total vacant mileage is minimized. In this study, we develop an innovative data-driven approach for devising efficient vehicle relocation policy for OMS that (1) proactively relocates vehicles before the demand is observed and (2) reduces the inequality among drivers’ income so that the proactive relocation policy is fair and is likely to be followed by drivers. Our approach represents the fusion of optimization and machine learning methods, which comprises three steps: First, we formulate the optimal proactive relocation as an optimal/stable matching problems and solve for global optimal solutions based on historical data. Second, the optimal solutions are then grouped and fed to train the deep learning models which consist of fully connected layers and long short-term memory networks. Low rank approximation is introduced to reduce the model complexity and improve the training performances. Finally, we use the trained model to predict the relocation policy which can be implemented in real time. We conduct comprehensive numerical experiments and sensitivity analyses to demonstrate the performances of the proposed method using New York City taxi data. The results suggest that our method will reduce empty mileage per trip by 54–70% under the optimal matching strategy, and a 25–32% reduction can also be achieved by following the stable matching strategy. We also validate that the predicted relocation policies are robust in the presence of uncertain passenger demand level and passenger trip-requesting behavior.",
        "DOI": "10.1016/j.trc.2020.102678",
        "paper_author": "Lei Z.",
        "affiliation_name": "Lyles School of Civil and Construction Engineering",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60032781",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Performance evaluation of MLE, RF and SVM classification algorithms for watershed scale land use/land cover mapping using sentinel 2 bands",
        "publication": "Remote Sensing Applications: Society and Environment",
        "citied_by": "98",
        "cover_date": "2020-08-01",
        "Abstract": "The land use and land cover map plays a significant role in agricultural, water resources planning, management, and monitoring programs at regional and national levels and is an input to various hydrological models. Land use and land cover maps prepared using satellite remote sensing techniques in conjunction with landform-soil-vegetation relationships and ground truth are popular for locating suitable sites for the construction of water harvesting structures, soil and water conservation measures, runoff computations, irrigation planning and agricultural management, analyzing socio-ecological concerns, flood controlling, and overall watershed management. Here we use a novel approach to analyze Sentinel–2 multispectral satellite data using traditional and principal component analysis based approaches to evaluate the effectiveness of maximum likelihood estimation, random forest tree, and support vector machine classifiers to improve land use and land cover categorization for Soil Conservation Service Curve Number model. Additionally, we use stratified random sampling to evaluate the accuracies of resulted land use and land cover maps in terms of kappa coefficient, overall accuracy, producer's accuracy, and user's accuracy. The classifiers were used for classifying the data into seven major land use and land cover classes namely water, built-up, mixed forest, cultivated land, barren land, fallow land with vertisols dominance, and fallow land with inceptisols dominance for the Vishwamitri watershed. We find that principal component analysis with support vector machine is able to produce highly accurate land use and land cover classified maps. Principal component analysis extracts the useful spectral information by compressing redundant data embedded in each spectral channel. The study highlights the use of principal component analysis with support vector machine classifier to improve land use and land cover classification from which policymakers can make better decisions and extract basic information for policy amendments.",
        "DOI": "10.1016/j.rsase.2020.100351",
        "paper_author": "Rana V.K.",
        "affiliation_name": "The Maharaja Sayajirao University of Baroda",
        "affiliation_city": "Vadodara",
        "affiliation_country": "India",
        "affiliation_id": "60002112",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Safe, efficient, and comfortable velocity control based on reinforcement learning for autonomous driving",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "298",
        "cover_date": "2020-08-01",
        "Abstract": "A model used for velocity control during car following is proposed based on reinforcement learning (RL). To optimize driving performance, a reward function is developed by referencing human driving data and combining driving features related to safety, efficiency, and comfort. With the developed reward function, the RL agent learns to control vehicle speed in a fashion that maximizes cumulative rewards, through trials and errors in the simulation environment. To avoid potential unsafe actions, the proposed RL model is incorporated with a collision avoidance strategy for safety checks. The safety check strategy is used during both model training and testing phases, which results in faster convergence and zero collisions. A total of 1,341 car-following events extracted from the Next Generation Simulation (NGSIM) dataset are used to train and test the proposed model. The performance of the proposed model is evaluated by the comparison with empirical NGSIM data and with adaptive cruise control (ACC) algorithm implemented through model predictive control (MPC). The experimental results show that the proposed model demonstrates the capability of safe, efficient, and comfortable velocity control and outperforms human drivers in that it 1) has larger TTC values than those of human drivers, 2) can maintain efficient and safe headways around 1.2s, and 3) can follow the lead vehicle comfortably with smooth acceleration (jerk value is only a third of that of human drivers). Compared with the MPC-based ACC algorithm, the proposed model has better performance in terms of safety, comfort, and especially running speed during testing (more than 200 times faster). The results indicate that the proposed approach could contribute to the development of better autonomous driving systems. Source code of this paper can be found at https://github.com/MeixinZhu/Velocity_control.",
        "DOI": "10.1016/j.trc.2020.102662",
        "paper_author": "Zhu M.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data-driven Koopman operators for model-based shared control of human–machine systems",
        "publication": "International Journal of Robotics Research",
        "citied_by": "31",
        "cover_date": "2020-08-01",
        "Abstract": "We present a data-driven shared control algorithm that can be used to improve a human operator’s control of complex dynamic machines and achieve tasks that would otherwise be challenging, or impossible, for the user on their own. Our method assumes no a priori knowledge of the system dynamics. Instead, both the dynamics and information about the user’s interaction are learned from observation through the use of a Koopman operator. Using the learned model, we define an optimization problem to compute the autonomous partner’s control policy. Finally, we dynamically allocate control authority to each partner based on a comparison of the user input and the autonomously generated control. We refer to this idea as model-based shared control (MbSC). We evaluate the efficacy of our approach with two human subjects studies consisting of 32 total participants (16 subjects in each study). The first study imposes a linear constraint on the modeling and autonomous policy generation algorithms. The second study explores the more general, nonlinear variant. Overall, we find that MbSC significantly improves task and control metrics when compared with a natural learning, or user only, control paradigm. Our experiments suggest that models learned via the Koopman operator generalize across users, indicating that it is not necessary to collect data from each individual user before providing assistance with MbSC. We also demonstrate the data efficiency of MbSC and, consequently, its usefulness in online learning paradigms. Finally, we find that the nonlinear variant has a greater impact on a user’s ability to successfully achieve a defined task than the linear variant.",
        "DOI": "10.1177/0278364920921935",
        "paper_author": "Broad A.",
        "affiliation_name": "Boston Dynamics",
        "affiliation_city": "Waltham",
        "affiliation_country": "United States",
        "affiliation_id": "106748161",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Does the estimation of the propensity score by machine learning improve matching estimation? The case of Germany's programmes for long term unemployed",
        "publication": "Labour Economics",
        "citied_by": "11",
        "cover_date": "2020-08-01",
        "Abstract": "Matching-type estimators using the propensity score are the major workhorse in active labour market policy evaluation. This work investigates if machine learning algorithms for estimating the propensity score lead to more credible estimation of average treatment effects on the treated using a radius matching framework. Considering two popular methods, the results are ambiguous: We find that using LASSO based logit models to estimate the propensity score delivers more credible results than conventional methods in small and medium sized high dimensional datasets. However, the usage of Random Forests to estimate the propensity score may lead to a deterioration of the performance in situations with a low treatment share. The application reveals a positive effect of the training programme on days in employment for long-term unemployed. While the choice of the “first stage” is highly relevant for settings with low number of observations and few treated, machine learning and conventional estimation becomes more similar in larger samples and higher treatment shares.",
        "DOI": "10.1016/j.labeco.2020.101855",
        "paper_author": "Goller D.",
        "affiliation_name": "University of St. Gallen",
        "affiliation_city": "St Gallen",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60027786",
        "affiliation_state": "SG"
    },
    {
        "paper_title": "Constructing a meteorological indicator dataset for selected European NUTS 3 regions",
        "publication": "Data in Brief",
        "citied_by": "3",
        "cover_date": "2020-08-01",
        "Abstract": "The harmonization of data granularity in spatial and temporal terms is an important pre-step to any econometric and machine learning applications. Researchers, who wish to statistically test hypotheses on the relationship between agro-meteorological and European policy outcomes, often observe that agro-meteorological data is typically stored in gridded and temporally detailed form, while many relevant policy outcomes are only available on an aggregated level. This dataset intends to aid empirical investigations by providing a dataset with monthly meteorological indicators on a European Nomenclature of Territorial Units for Statistics level 3 (NUTS 3) regional level for 13 countries for the period from 1989 to 2018. The data we provide allows researchers to investigate hypothesis related to weather volatility and the probability of extreme weather events. We created this dataset from the daily data in grids of 25 km x 25 km provided by the Joint Research Centre of the European Commission. We matched the map with the raw data to a map with the administrative boundaries of European NUTS 3 regions. After appropriately weighting, we calculated the monthly, regional mean, variance and kurtosis of the following variables: maximum, minimum, average air temperature in degrees Centigrade, sum of precipitation in mm and snow depth in cm. We report the covariance between the average temperature and the precipitation as well.",
        "DOI": "10.1016/j.dib.2020.105786",
        "paper_author": "Angelova D.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",
        "publication": "International Orthopaedics",
        "citied_by": "31",
        "cover_date": "2020-08-01",
        "Abstract": "Purpose: Accurately forecasting the occurrence of future covid-19-related cases across relaxed (Sweden) and stringent (USA and Canada) policy contexts has a renewed sense of urgency. Moreover, there is a need for a multidimensional county-level approach to monitor the second wave of covid-19 in the USA. Method: We use an artificial intelligence framework based on timeline of policy interventions that triangulated results based on the three approaches—Bayesian susceptible-infected-recovered (SIR), Kalman filter, and machine learning. Results: Our findings suggest three important insights. First, the effective growth rate of covid-19 infections dropped in response to the approximate dates of key policy interventions. We find that the change points for spreading rates approximately coincide with the timelines of policy interventions across respective countries. Second, forecasted trend until mid-June in the USA was downward trending, stable, and linear. Sweden is likely to be heading in the other direction. That is, Sweden’s forecasted trend until mid-June appears to be non-linear and upward trending. Canada appears to fall somewhere in the middle—the trend for the same period is flat. Third, a Kalman filter based robustness check indicates that by mid-June the USA will likely have close to two million virus cases, while Sweden will likely have over 44,000 covid-19 cases. Conclusion: We show that drop in effective growth rate of covid-19 infections was sharper in the case of stringent policies (USA and Canada) but was more gradual in the case of relaxed policy (Sweden). Our study exhorts policy makers to take these results into account as they consider the implications of relaxing lockdown measures.",
        "DOI": "10.1007/s00264-020-04653-3",
        "paper_author": "Vaid S.",
        "affiliation_name": "DeGroote School of Business",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada",
        "affiliation_id": "60106384",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Clinical Application of Computational Methods in Precision Oncology: A Review",
        "publication": "JAMA Oncology",
        "citied_by": "16",
        "cover_date": "2020-08-01",
        "Abstract": "Importance: There is an enormous and growing amount of data available from individual cancer cases, which makes the work of clinical oncologists more demanding. This data challenge has attracted engineers to create software that aims to improve cancer diagnosis or treatment. However, the move to use computers in the oncology clinic for diagnosis or treatment has led to instances of premature or inappropriate use of computational predictive systems. Objective: To evaluate best practices for developing and assessing the clinical utility of predictive computational methods in oncology. Evidence Review: The National Cancer Policy Forum and the Board on Mathematical Sciences and Analytics at the National Academies of Sciences, Engineering, and Medicine hosted a workshop to examine the use of multidimensional data derived from patients with cancer and the computational methods used to analyze these data. The workshop convened diverse stakeholders and experts, including computer scientists, oncology clinicians, statisticians, patient advocates, industry leaders, ethicists, leaders of health systems (academic and community based), private and public health insurance carriers, federal agencies, and regulatory authorities. Key characteristics for successful computational oncology were considered in 3 thematic areas: (1) data quality, completeness, sharing, and privacy; (2) computational methods for analysis, interpretation, and use of oncology data; and (3) clinical infrastructure and expertise for best use of computational precision oncology. Findings: Quality control was found to be essential across all stages, from data collection to data processing, management, and use. Collecting a standardized parsimonious data set at every cancer diagnosis and restaging could enhance reliability and completeness of clinical data for precision oncology. Data completeness refers to key data elements such as information about cancer diagnosis, treatment, and outcomes, while data quality depends on whether appropriate variables have been measured in valid and reliable ways. Collecting data from diverse populations can reduce the risk of creating invalid and biased algorithms. Computational systems that aid clinicians should be classified as software as a medical device and thus regulated according to the potential risk posed. To facilitate appropriate use of computational methods that interpret high-dimensional data in oncology, treating physicians need access to multidisciplinary teams with broad expertise and deep training among a subset of clinical oncology fellows in clinical informatics. Conclusions and Relevance: Workshop discussions suggested best practices in demonstrating the clinical utility of predictive computational methods for diagnosing or treating cancer.",
        "DOI": "10.1001/jamaoncol.2020.1247",
        "paper_author": "Panagiotou O.A.",
        "affiliation_name": "United States Department of Health and Human Services",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60020555",
        "affiliation_state": "DC"
    },
    {
        "paper_title": "Predicting hospital admission for older emergency department patients: Insights from machine learning",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "25",
        "cover_date": "2020-08-01",
        "Abstract": "Background: Emergency departments (ED) are a portal of entry into the hospital and are uniquely positioned to influence the health care trajectories of older adults seeking medical attention. Older adults present to the ED with distinct needs and complex medical histories, which can make disposition planning more challenging. Machine learning (ML) approaches have been previously used to inform decision-making surrounding ED disposition in the general population. However, little is known about the performance and utility of ML methods in predicting hospital admission among older ED patients. We applied a series of ML algorithms to predict ED admission in older adults and discuss their clinical and policy implications. Materials and methods: We analyzed the Canadian data from the interRAI multinational ED study, the largest prospective cohort study of older ED patients to date. The data included 2274 ED patients 75 years of age and older from eight ED sites across Canada between November 2009 and April 2012. Data were extracted from the interRAI ED Contact Assessment, with predictors including a series of geriatric syndromes, functional assessments, and baseline care needs. We applied a total of five ML algorithms. Models were trained, assessed, and analyzed using 10-fold cross-validation. The performance of predictive models was measured using the area under the receiver operating characteristic curve (AUC). We also report the accuracy, sensitivity, and specificity of each model to supplement performance interpretation. Results: Gradient boosted trees was the most accurate model to predict older ED patients who would require hospitalization (AUC = 0.80). The five most informative features include home intravenous therapy, time of ED presentation, a requirement for formal support services, independence in walking, and the presence of an unstable medical condition. Conclusion: To the best of our knowledge, this is the first study to predict hospital admission in older ED patients using a series of geriatric syndromes and functional assessments. We were able to predict hospital admission in older ED patients with good accuracy using the items available in the interRAI ED Contact Assessment. This information can be used to inform decision-making about ED disposition and may expedite admission processes and proactive discharge planning.",
        "DOI": "10.1016/j.ijmedinf.2020.104163",
        "paper_author": "Mowbray F.",
        "affiliation_name": "McMaster University",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada",
        "affiliation_id": "60031828",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Deep Multi-Critic Network for accelerating Policy Learning in multi-agent environments",
        "publication": "Neural Networks",
        "citied_by": "5",
        "cover_date": "2020-08-01",
        "Abstract": "Humans live among other humans, not in isolation. Therefore, the ability to learn and behave in multi-agent environments is essential for any autonomous system that intends to interact with people. Due to the presence of multiple simultaneous learners in a multi-agent learning environment, the Markov assumption used for single-agent environments is not tenable, necessitating the development of new Policy Learning algorithms. Recent Actor–Critic algorithms proposed for multi-agent environments, such as Multi-Agent Deep Deterministic Policy Gradients and Counterfactual Multi-Agent Policy Gradients, find a way to use the same mathematical framework as single agent environments by augmenting the Critic with extra information. However, this extra information can slow down the learning process and afflict the Critic with Curse of Dimensionality. To combat this, we propose a novel Deep Neural Network configuration called Deep Multi-Critic Network. This architecture works by taking a weighted sum over the outputs of multiple critic networks of varying complexity and size. The configuration was tested on data collected from a real-world multi-agent environment. The results illustrate that by using Deep Multi-Critic Network, less data is needed to reach the same level of performance as when not using the configuration. This suggests that as the configuration learns faster from less data, then the Critic may be able to learn Q-values faster, accelerating Actor training as well.",
        "DOI": "10.1016/j.neunet.2020.04.023",
        "paper_author": "Hook J.",
        "affiliation_name": "Loughborough University London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60123703",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting Financial Health of Banks for Investor Guidance Using Machine Learning Algorithms",
        "publication": "Journal of Emerging Market Finance",
        "citied_by": "13",
        "cover_date": "2020-08-01",
        "Abstract": "While earlier studies have focused excessively on bankruptcy prediction of banks, this study classifies banks based on their financial strength from the perspective of retail depositors who currently do not have an authentic guiding framework that helps them identify banks with higher risk profiles. Using machine learning techniques, we classify 44 Indian banks into distinct categories of financial health based on 12-year data from 2005 to 2017. We first use unsupervised learning to identify a pattern leading to logical groups in terms of financial health and then move to supervised learning for prediction. Using linear discriminant analysis (LDA), Classification and Regression Tree (CART) and Random Forest methods, we predict the cluster membership with the associated explanatory power alongside. We also compare our classification with the credit ratings awarded by rating agencies and highlight certain discrepancies that exist between what is predicted by our models and the credit rating awards. JEL Codes: C53; M10",
        "DOI": "10.1177/0972652720913478",
        "paper_author": "Viswanathan P.K.",
        "affiliation_name": "Great Lakes Institute of Management, Chennai",
        "affiliation_city": "Manamai",
        "affiliation_country": "India",
        "affiliation_id": "60078466",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "A review on visual content-based and users’ tags-based image annotation: methods and techniques",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "13",
        "cover_date": "2020-08-01",
        "Abstract": "In the current era of digital communication, the use of images is growing exponentially since they are one of the best ways of expressing, sharing and memorizing knowledge. In fact, images can be used in various real-world applications, like biology, medical diagnosis, space research, remote sensing, etc. However, finding the most relevant images that meet the users’ needs is a challenging task, especially when the search is performed over gigantic amounts of images. This has led to the emergence of several image retrieval studies during the past two decades. Typically, research studies in this area were focused on the Content-based Image Retrieval (CBIR). However, extensive research have proved that there is a ‘semantic gap’ between the visual information captured by the imaging devices and the image semantics understandable by humans. As an alternative, researchers’ efforts have been oriented towards the Text-based Image Retrieval (TBIR). Indeed, TBIR is a typical method that helps bridge the issue of ‘semantic gap’ between the low-level image features and the high-level image semantics. Its policy consists in associating textual descriptions with the images, which constitute the focus of the research queries later on. In this paper, we analyze various image annotation methods, namely: Visual Content-based and Users’ Tags-based Image Annotation Methods. In particular, we focus on the visual content-based image annotation techniques since they are one of the dynamic research fields nowadays.",
        "DOI": "10.1007/s11042-020-08862-1",
        "paper_author": "Bouchakwa M.",
        "affiliation_name": "Multimedia, InfoRmation systems and Advanced Computing Laboratory",
        "affiliation_city": "Sfax",
        "affiliation_country": "Tunisia",
        "affiliation_id": "60091668",
        "affiliation_state": "Sfax"
    },
    {
        "paper_title": "RLProph: a dynamic programming based reinforcement learning approach for optimal routing in opportunistic IoT networks",
        "publication": "Wireless Networks",
        "citied_by": "31",
        "cover_date": "2020-08-01",
        "Abstract": "Routing in Opportunistic Internet of Things networks (OppIoTs) is a challenging task because of intermittent connectivity between devices and the lack of a fixed path between the source and destination of messages. Recently, machine learning (ML) and reinforcement learning (RL) have been used with great success to automate processes in a number of different problem domains. In this paper, we seek to fully automate the OppIoT routing process by using the Policy Iteration algorithm to maximize the possibility of message delivery. Moreover, we model the OppIoT environment as a Markov decision process (MDP) replete with states, actions, rewards, and transition probabilities. The proposed routing protocol, RLProph, is able to optimize the routing process via the optimal policy obtained by solving the MDP using Policy Iteration. Through extensive simulations, we show that RLProph outperforms a number of ML-based and context-aware routing protocols on a multitude of performance criteria.",
        "DOI": "10.1007/s11276-020-02331-1",
        "paper_author": "Sharma D.K.",
        "affiliation_name": "Netaji Subhas University of Technology",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60010633",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Use of Proximal Policy Optimization for the Joint Replenishment Problem",
        "publication": "Computers in Industry",
        "citied_by": "79",
        "cover_date": "2020-08-01",
        "Abstract": "Deep reinforcement learning has been coined as a promising research avenue to solve sequential decision-making problems, especially if few is known about the optimal policy structure. We apply the proximal policy optimization algorithm to the intractable joint replenishment problem. We demonstrate how the algorithm approaches the optimal policy structure and outperforms two other heuristics. Its deployment in supply chain control towers can orchestrate and facilitate collaborative shipping in the Physical Internet.",
        "DOI": "10.1016/j.compind.2020.103239",
        "paper_author": "Vanvuchelen N.",
        "affiliation_name": "KU Leuven",
        "affiliation_city": "Leuven",
        "affiliation_country": "Belgium",
        "affiliation_id": "60025063",
        "affiliation_state": "Vlaams-Brabant"
    },
    {
        "paper_title": "ThermoSim: Deep learning based framework for modeling and simulation of thermal-aware resource management for cloud computing environments",
        "publication": "Journal of Systems and Software",
        "citied_by": "47",
        "cover_date": "2020-08-01",
        "Abstract": "Current cloud computing frameworks host millions of physical servers that utilize cloud computing resources in the form of different virtual machines. Cloud Data Center (CDC) infrastructures require significant amounts of energy to deliver large scale computational services. Moreover, computing nodes generate large volumes of heat, requiring cooling units in turn to eliminate the effect of this heat. Thus, overall energy consumption of the CDC increases tremendously for servers as well as for cooling units. However, current workload allocation policies do not take into account effect on temperature and it is challenging to simulate the thermal behavior of CDCs. There is a need for a thermal-aware framework to simulate and model the behavior of nodes and measure the important performance parameters which can be affected by its temperature. In this paper, we propose a lightweight framework, ThermoSim, for modeling and simulation of thermal-aware resource management for cloud computing environments. This work presents a Recurrent Neural Network based deep learning temperature predictor for CDCs which is utilized by ThermoSim for lightweight resource management in constrained cloud environments. ThermoSim extends the CloudSim toolkit helping to analyze the performance of various key parameters such as energy consumption, service level agreement violation rate, number of virtual machine migrations and temperature during the management of cloud resources for execution of workloads. Further, different energy-aware and thermal-aware resource management techniques are tested using the proposed ThermoSim framework in order to validate it against the existing framework (Thas). The experimental results demonstrate the proposed framework is capable of modeling and simulating the thermal behavior of a CDC and ThermoSim framework is better than Thas in terms of energy consumption, cost, time, memory usage and prediction accuracy.",
        "DOI": "10.1016/j.jss.2020.110596",
        "paper_author": "Gill S.S.",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022109",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Sport and exercise genomics: The FIMS 2019 consensus statement update",
        "publication": "British Journal of Sports Medicine",
        "citied_by": "49",
        "cover_date": "2020-08-01",
        "Abstract": "Rapid advances in technologies in the field of genomics such as high throughput DNA sequencing, big data processing by machine learning algorithms and gene-editing techniques are expected to make precision medicine and gene-therapy a greater reality. However, this development will raise many important new issues, including ethical, moral, social and privacy issues. The field of exercise genomics has also advanced by incorporating these innovative technologies. There is therefore an urgent need for guiding references for sport and exercise genomics to allow the necessary advancements in this field of sport and exercise medicine, while protecting athletes from any invasion of privacy and misuse of their genomic information. Here, we update a previous consensus and develop a guiding reference for sport and exercise genomics based on a SWOT (Strengths, Weaknesses, Opportunities and Threats) analysis. This SWOT analysis and the developed guiding reference highlight the need for scientists/clinicians to be well-versed in ethics and data protection policy to advance sport and exercise genomics without compromising the privacy of athletes and the efforts of international sports federations. Conducting research based on the present guiding reference will mitigate to a great extent the risks brought about by inappropriate use of genomic information and allow further development of sport and exercise genomics in accordance with best ethical standards and international data protection principles and policies. This guiding reference should regularly be updated on the basis of new information emerging from the area of sport and exercise medicine as well as from the developments and challenges in genomics of health and disease in general in order to best protect the athletes, patients and all other relevant stakeholders.",
        "DOI": "10.1136/bjsports-2019-101532",
        "paper_author": "Tanisawa K.",
        "affiliation_name": "Waseda University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60023462",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep reinforcement learning for imbalanced classification",
        "publication": "Applied Intelligence",
        "citied_by": "147",
        "cover_date": "2020-08-01",
        "Abstract": "Data in real-world application often exhibit skewed class distribution which poses an intense challenge for machine learning. Conventional classification algorithms are not effective in case of imbalanced data distribution, and may fail when the data distribution is highly imbalanced. To address this issue, we propose a general imbalanced classification model based on deep reinforcement learning, in which we formulate the classification problem as a sequential decision-making process and solve it by a deep Q-learning network. In our model, the agent performs a classification action on one sample in each time step, and the environment evaluates the classification action and returns a reward to the agent. The reward from the minority class sample is larger, so the agent is more sensitive to the minority class. The agent finally finds an optimal classification policy in imbalanced data under the guidance of the specific reward function and beneficial simulated environment. Experiments have shown that our proposed model outperforms other imbalanced classification algorithms, and identifies more minority samples with better classification performance.",
        "DOI": "10.1007/s10489-020-01637-z",
        "paper_author": "Lin E.",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60024542",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "A supervised learning approach for heading detection",
        "publication": "Expert Systems",
        "citied_by": "7",
        "cover_date": "2020-08-01",
        "Abstract": "As the popularity of the portable document format (PDF) file format increases, research that facilitates PDF text analysis or extraction is necessary. Heading detection is a crucial component of PDF-based text classification processes. This research involves training a supervised learning model to detect headings by systematically testing and selecting classifier features using recursive feature elimination. Results indicate that decision tree is the best classifier with an accuracy of 95.83%, sensitivity of 0.981, and a specificity of 0.946. This research into heading detection contributes to the field of PDF-based text extraction and can be applied to the automation of large scale PDF text analysis in a variety of professional and policy-based contexts.",
        "DOI": "10.1111/exsy.12520",
        "paper_author": "Budhiraja S.S.",
        "affiliation_name": "Lakehead University",
        "affiliation_city": "Thunder Bay",
        "affiliation_country": "Canada",
        "affiliation_id": "60025949",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "An evidential integrated method for maintaining case base and vocabulary containers within CBR systems",
        "publication": "Information Sciences",
        "citied_by": "6",
        "cover_date": "2020-08-01",
        "Abstract": "Cases and vocabulary maintenance presents a crucial task to preserve high competent Case-Based Reasoning (CBR) systems, since the accuracy of their offered solutions are strongly dependent on stored cases and their describing attributes quality. The maintenance aims generally at eliminating two types of undesirable knowledge which are noisy and redundant data. However, inexpedient Case Base Maintenance (CBM) or vocabulary maintenance may not only greatly decrease CBR competence in solving new problems, but also reduce its performance in term of retrieval time. Besides, to provide a high maintenance quality, it is necessary to manage uncertainty within knowledge since “real-world data are never perfect” and stored cases within a CBR system's Case Base (CB) describe real-world experiences. Hence, we propose, in this paper, a new integrated method that maintains both of the CB and the vocabulary knowledge containers of CBR systems by offering a new alternating technique to properly detect noisiness and redundancy whether in cases or features. During the learning steps of our new integrated maintenance policy, which drives the decision making about cases and attributes selection, we manage uncertainty using one among the most powerful tools called the Belief Function Theory.",
        "DOI": "10.1016/j.ins.2019.11.009",
        "paper_author": "Ben Ayed S.",
        "affiliation_name": "Laboratoire de Recherche Opérationnelle, de Décision et de Contrôle de processus",
        "affiliation_city": "Le Bardo",
        "affiliation_country": "Tunisia",
        "affiliation_id": "60070639",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Multi-robot Target Encirclement Control with Collision Avoidance via Deep Reinforcement Learning",
        "publication": "Journal of Intelligent and Robotic Systems: Theory and Applications",
        "citied_by": "52",
        "cover_date": "2020-08-01",
        "Abstract": "The target encirclement control of multi-robot systems via deep reinforcement learning has been investigated in this paper. Inspired by the encirclement behavior of dolphins to entrap the fishes, the encirclement control is mainly to enforce the robots to achieve a capturing formation pattern around a target, and can be widely applied in many areas such as coverage, patrolling, escorting, etc. Different from traditional methods, we propose a deep reinforcement learning framework for multi-robot target encirclement formation control, combining the advantages of the deep neural network and deterministic policy gradient algorithm, which is free from the complicated work of building the control model and designing the control law. Our method provides a distributed control architecture for each robot in continuous action space, relying only on local teammate information. Besides, the behavioral output at each time step is determined by its own independent network. In addition, both the robots and the moving target can be trained simultaneously. In that way, both cooperation and competition can be contained, and the results validate the effectiveness of the proposed algorithm.",
        "DOI": "10.1007/s10846-019-01106-x",
        "paper_author": "Ma J.",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60024350",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Fair Classification with Counterfactual Learning",
        "publication": "SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citied_by": "5",
        "cover_date": "2020-07-25",
        "Abstract": "Recent advances in machine learning have led to emerging new approaches to deal with different kinds of biases that exist in the data. On the one hand, counterfactual learning copes with biases in the policy used for sampling (or logging) the data in order to evaluate and learn new policies. On the other hand, fairness-aware learning aims at learning fair models to avoid discrimination against certain individuals or groups. In this paper, we design a counterfactual framework to model fairness-aware learning which benefits from counterfactual reasoning to achieve more fair decision support systems. We utilize a definition of fairness to determine the bandit feedback in the counterfactual setting that learns a classification strategy from the offline data, and balances classification performance versus fairness measure. In the experiments, we demonstrate that a counterfactual setting can be perfectly exerted to learn fair models with competitive results compared to a well-known baseline system.",
        "DOI": "10.1145/3397271.3401291",
        "paper_author": "Tavakol M.",
        "affiliation_name": "Technische Universität Dortmund",
        "affiliation_city": "Dortmund",
        "affiliation_country": "Germany",
        "affiliation_id": "60032991",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "APS: An Active PubMed Search System for Technology Assisted Reviews",
        "publication": "SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citied_by": "6",
        "cover_date": "2020-07-25",
        "Abstract": "Systematic reviews constitute the cornerstone of Evidence-based Medicine. They can provide guidance to medical policy-making by synthesizing all available studies regarding a certain topic. However, conducting systematic reviews has become a laborious and time-consuming task due to the large amount and rapid growth of published literature. The TAR approaches aim to accelerate the screening stage of systematic reviews by combining machine learning algorithms and human relevance feedback. In this work, we built an online active search system for systematic reviews, named APS, by applying an state-of-the-art TAR approach-Continuous Active Learning. The system is built on the top of the PubMed collection, which is a widely used database of biomedical literature. It allows users to conduct the abstract screening for systematic reviews. We demonstrate the effectiveness and robustness of the APS in detecting relevant literature and reducing workload for systematic reviews using the CLEF TAR 2017 benchmark.",
        "DOI": "10.1145/3397271.3401401",
        "paper_author": "Li D.",
        "affiliation_name": "Universiteit van Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60002483",
        "affiliation_state": "Noord-Holland"
    },
    {
        "paper_title": "Influence Function for Unbiased Recommendation",
        "publication": "SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citied_by": "22",
        "cover_date": "2020-07-25",
        "Abstract": "Recommender system is one of the most successful machine learning technologies for commerce. However, it can reinforce the closed feedback loop problem, where the recommender system generates items to users, then the further recommendation model is trained with the data that users' feedback to the items. Such self-reinforcing pattern can cause data bias problems. There are several debiasing methods, inverse-propensity-scoring (IPS) is a practical one for industry product. Since it is relatively easy to reweight training samples, and ameliorate the distribution shift problem. However,because of deterministic policy problem and confoundings in real-world data, it is hard to predict propensity score accurately. Inspired by the sample reweight work for robust deep learning, we propose a novel influence function based method for recommendation modeling, and analyze how the influence function corrects the bias. In the experiments, our proposed method achieves better performance against the state-of-the-art approaches.",
        "DOI": "10.1145/3397271.3401321",
        "paper_author": "Yu J.",
        "affiliation_name": "University of Melbourne",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60026553",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "XCS with opponent modelling for concurrent reinforcement learners",
        "publication": "Neurocomputing",
        "citied_by": "6",
        "cover_date": "2020-07-25",
        "Abstract": "Reinforcement learning (RL) of optimal policies against an opponent agent also with learning capability is still challenging in Markov games. A variety of algorithms have been proposed for solving this problem such as the traditional Q-learning-based RL (QbRL) algorithms as well as the state-of-the-art neural-network-based RL (NNbRL) algorithms. However, the QbRL approaches have poor generalization capability for complex problems with non-stationary opponents, while the learned policies by NNbRL algorithms are lack of explainability and transparency. In this paper, we propose an algorithm X-OMQ(λ) that integrates eXtended Classifier System (XCS) with opponent modelling for concurrent reinforcement learners in zero-sum Markov Games. The algorithm can learn general, accurate, and interpretable action selection rules and allow policy optimization using the genetic algorithm (GA). Besides, the X-OMQ(λ) agent optimizes the established opponent's model while simultaneously learning to select actions in a goal-directed manner. In addition, we use the eligibility trace mechanism to further speed up the learning process. In the reinforcement component, not only the classifiers in the action set are updated, but other relevant classifiers are also updated in a certain proportion. We demonstrate the performance of the proposed algorithm in the hunter prey problem and two adversarial soccer scenarios where the opponent is allowed to learn with several benchmark QbRL and NNbRL algorithms. The results show that our method has similar learning performance with the NNbRL algorithms while our method requires no prior knowledge of the opponent or the environment. Moreover, the learned action selection rules are also interpretable while having generalization capability.",
        "DOI": "10.1016/j.neucom.2020.02.118",
        "paper_author": "Chen H.",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60024350",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Encyclopedia of Information Science and Technology, Fifth Edition",
        "publication": "Encyclopedia of Information Science and Technology, Fifth Edition",
        "citied_by": "3",
        "cover_date": "2020-07-24",
        "Abstract": "The rise of intelligence and computation within technology has created an eruption of potential applications in numerous professional industries. Techniques such as data analysis, cloud computing, machine learning, and others have altered the traditional processes of various disciplines including healthcare, economics, transportation, and politics. Information technology in today's world is beginning to uncover opportunities for experts in these fields that they are not yet aware of. The exposure of specific instances in which these devices are being implemented will assist other specialists in how to successfully utilize these transformative tools with the appropriate amount of discretion, safety, and awareness. Considering the level of diverse uses and practices throughout the globe, the fifth edition of the Encyclopedia of Information Science and Technology series continues the enduring legacy set forth by its predecessors as a premier reference that contributes the most cutting-edge concepts and methodologies to the research community. The Encyclopedia of Information Science and Technology, Fifth Edition is a three-volume set that includes 136 original and previously unpublished research chapters that present multidisciplinary research and expert insights into new methods and processes for understanding modern technological tools and their applications as well as emerging theories and ethical controversies surrounding the field of information science. Highlighting a wide range of topics such as natural language processing, decision support systems, and electronic government, this book offers strategies for implementing smart devices and analytics into various professional disciplines. The techniques discussed in this publication are ideal for IT professionals, developers, computer scientists, practitioners, managers, policymakers, engineers, data analysts, and programmers seeking to understand the latest developments within this field and who are looking to apply new tools and policies in their practice. Additionally, academicians, researchers, and students in fields that include but are not limited to software engineering, cybersecurity, information technology, media and communications, urban planning, computer science, healthcare, economics, environmental science, data management, and political science will benefit from the extensive knowledge compiled within this publication.",
        "DOI": "10.4018/978-1-7998-3479-3",
        "paper_author": "Khosrow-Pour M.",
        "affiliation_name": "Information Resources Management Association",
        "affiliation_city": null,
        "affiliation_country": "United States",
        "affiliation_id": "101950254",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "AutoPath: Image-Specific Inference for 3D Segmentation",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "5",
        "cover_date": "2020-07-24",
        "Abstract": "In recent years, deep convolutional neural networks (CNNs) has made great achievements in the field of medical image segmentation, among which residual structure plays a significant role in the rapid development of CNN-based segmentation. However, the 3D residual networks inevitably bring a huge computational burden to machines for network inference, thus limiting their usages for many real clinical applications. To tackle this issue, we propose AutoPath, an image-specific inference approach for more efficient 3D segmentations. The proposed AutoPath dynamically selects enabled residual blocks regarding different input images during inference, thus effectively reducing total computation without degrading segmentation performance. To achieve this, a policy network is trained using reinforcement learning, by employing the rewards of using a minimal set of residual blocks and meanwhile maintaining accurate segmentation. Experimental results on liver CT dataset show that our approach not only provides efficient inference procedure but also attains satisfactory segmentation performance.",
        "DOI": "10.3389/fnbot.2020.00049",
        "paper_author": "Sun D.",
        "affiliation_name": "Shenzhen University Health Science Center",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60133174",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Wrong but useful — What covid-19 epidemiologic models can and cannot tell us",
        "publication": "New England Journal of Medicine",
        "citied_by": "289",
        "cover_date": "2020-07-23",
        "Abstract": "NA",
        "DOI": "10.1056/NEJMp2016822",
        "paper_author": "Holmdahl I.S.M.",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60032499",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Role of artificial intelligence in operations environment: a review and bibliometric analysis",
        "publication": "TQM Journal",
        "citied_by": "229",
        "cover_date": "2020-07-21",
        "Abstract": "Purpose: “Technological intelligence” is the capacity to appreciate and adapt technological advancements, and “artificial intelligence” is the key to achieve persuasive operational transformations in majority of contemporary organizational set-ups. Implicitly, artificial intelligence (the philosophies of machines to think, behave and perform either same or similar to humans) has knocked the doors of business organizations as an imperative activity. Artificial intelligence, as a discipline, initiated by scientist John McCarthy and formally publicized at Dartmouth Conference in 1956, now occupies a central stage for many organizations. Implementation of artificial intelligence provides competitive edge to an organization with a definite augmentation in its social and corporate status. Mere application of a concept will not furnish real output until and unless its performance is reviewed systematically. Technological changes are dynamic and advancing at a rapid rate. Subsequently, it becomes highly crucial to understand that where have the people reached with respect to artificial intelligence research. The present article aims to review significant work by eminent researchers towards artificial intelligence in the form of top contributing universities, authors, keywords, funding sources, journals and citation statistics. Design/methodology/approach: As rightly remarked by past researchers that reviewing is learning from experience, research team has reviewed (by applying systematic literature review through bibliometric analysis) the concept of artificial intelligence in this article. A sum of 1,854 articles extracted from Scopus database for the year 2018–2019 (31st of May) with selected keywords (artificial intelligence, genetic algorithms, agent-based systems, expert systems, big data analytics and operations management) along with certain filters (subject–business, management and accounting; language-English; document–article, article in press, review articles and source-journals). Findings: Results obtained from cluster analysis focus on predominant themes for present as well as future researchers in the area of artificial intelligence. Emerged clusters include Cluster 1: Artificial Intelligence and Optimization; Cluster 2: Industrial Engineering/Research and Automation; Cluster 3: Operational Performance and Machine Learning; Cluster 4: Sustainable Supply Chains and Sustainable Development; Cluster 5: Technology Adoption and Green Supply Chain Management and Cluster 6: Internet of Things and Reverse Logistics. Originality/value: The result of review of selected studies is in itself a unique contribution and a food for thought for operations managers and policy makers.",
        "DOI": "10.1108/TQM-10-2019-0243",
        "paper_author": "Dhamija P.",
        "affiliation_name": "University of Johannesburg",
        "affiliation_city": "Johannesburg",
        "affiliation_country": "South Africa",
        "affiliation_id": "60000717",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "Spatiotemporal evolution of tropical forest degradation and its impact on ecological sensitivity: A case study in Jinghong, Xishuangbanna, China",
        "publication": "Science of the Total Environment",
        "citied_by": "50",
        "cover_date": "2020-07-20",
        "Abstract": "Due to rapid urbanization and a growing population, the tropical forest in southwestern China has experienced a dramatic shrinkage, which threatens its biodiversity and imposes limitations to sustainable development. Spatiotemporal change analysis and ecological sensitivity assessment are the important prerequisites for investigating the relationship between eco-environmental quality and human activities. In this study, the tropical forest and other land cover types in Jinghong, China were firstly classified by a machine learning classification algorithm (support vector machine, SVM) with 7 pairs of remote sensing (RS) data (from 1989 to 2018). Then the spatiotemporal change patterns were analyzed. The ecological sensitivity was evaluated based on an index system method (ISM) in which a weighted combination of eleven indicators were produced using an analytic hierarchy process (AHP) method and GIS. Meanwhile four individual sensitivity indicators, including biodiversity sensitivity (BS), water resources sensitivity (WRS), geological hazard sensitivity (GHS) and soil erosion sensitivity (SES) were assessed respectively to create a multi-perspective understanding of the entire ecological sensitivity. The results suggest that the tropical forest experienced a continual decrease from 5631.78 km2 in 1999 to 4216.23 km2 in 2018 with an average change rate of −1.49%. The decreased area was mainly encroached on by human settlements and agriculture, particularly in the south of Jinghong. Furthermore, it could be seen that urbanization is the key driver for the changes to ecological sensitivity with both positive and negative impacts. In Jinghong, the region covered by a tropical forest has a relatively higher comprehensive ecological sensitivity (CES) than that of an urban area. This work shows RS and GIS to be powerful tools providing profound insights to researchers with regard to the spatiotemporal evolution of tropical forests and ecological sensitivity. The results are significant for improving policies in order to keep a sustainable balance in regional ecosystem management.",
        "DOI": "10.1016/j.scitotenv.2020.138678",
        "paper_author": "Yu J.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mix-zero-sum differential games for linear systems with unknown dynamics based on off-policy IRL",
        "publication": "Neurocomputing",
        "citied_by": "16",
        "cover_date": "2020-07-20",
        "Abstract": "This paper discusses a multi-player mixed-zero-sum (MZS) differential games with completely unknown dynamics. Based on off-policy integral reinforcement learning (IRL), a novel algorithm is proposed to obtain the optimal control. First, a policy iteration algorithm is put forward to obtain the optimal solution for deterministic system. Next, the case that the system dynamics is completely unknown is considered. And an IRL-based off-policy algorithm is presented. Meanwhile, the convergence of the presented algorithms is proved in this paper. At the end, the effectiveness of the proposed algorithm is shown by a simulation.",
        "DOI": "10.1016/j.neucom.2020.02.078",
        "paper_author": "Song R.",
        "affiliation_name": "University of Science and Technology Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60018273",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Country-Wise Forecast Model for the Effective Reproduction Number R<inf>t</inf> of Coronavirus Disease",
        "publication": "Frontiers in Physics",
        "citied_by": "10",
        "cover_date": "2020-07-17",
        "Abstract": "Due to the particularities of SARS-CoV-2, public health policies have played a crucial role in the control of the COVID-19 pandemic. Epidemiological parameters for assessing the stage of the outbreak, such as the Effective Reproduction Number (Rt), are not always straightforward to calculate, raising barriers between the scientific community and non-scientific decision-making actors. The combination of estimators of Rt with elaborated Machine Learning-based forecasting techniques provides a way to support decision-making when assessing governmental plans of action. In this work, we develop forecast models applying logistic growth strategies and auto-regression techniques based on Auto-Regressive Integrated Moving Average (ARIMA) models for each country that records information about the COVID-19 outbreak. Using the forecast for the main variables of the outbreak, namely the number of infected (I), recovered (R), and dead (D) individuals, we provide a real-time estimation of Rt and its temporal evolution within a timeframe. With such models, we evaluate Rt trends at the continental and country levels, providing a clear picture of the effect governmental actions have had on the spread. We expect this methodology of combining forecast models for raw data to calculate Rt to serve as valuable input to support decision-making related to controlling the spread of SARS-CoV-2.",
        "DOI": "10.3389/fphy.2020.00304",
        "paper_author": "Medina-Ortiz D.",
        "affiliation_name": "Universidad de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile",
        "affiliation_id": "60012464",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Identifying Reliable Predictors of Educational Outcomes Through Machine-Learning Predictive Modeling",
        "publication": "Frontiers in Education",
        "citied_by": "21",
        "cover_date": "2020-07-16",
        "Abstract": "Results-based financing has guided the development of policies with measurable results improving learning outcomes at micro/macro levels. However, it is then necessary to identify factors which predict early and accurately favorable or challenging conditions for learning. Learning outcomes depend on complex interactions between multiple variables, many of which are not fully understood. The objective was to develop valid and accurate models predicting low and high levels of math performance and Vietnamese language, using machine-learning algorithms, as part of an international large-scale project in primary education in Vietnam. The models achieved very high accuracy (95–100%). A strong common pattern has been found for both Math and Vietnamese language, for the low and high levels of performance: the individual cognitive characteristics, physical factors and daily routines/ activities of the child are very important predictive factors of academic performance, as measured by student performance in the final Grade 5 test in math and Vietnamese, respectively. Parental expectations, pre-school attendance and school trajectory of students have added relative importance in the classification. In order to accurately identify an expected low or high academic performance outcome, it is the full pattern of variables contained in the vector of information from each case that should be considered. Because, although each variable in a particular vector has a small contribution to the total predictive weight, it is the overall pattern containing the interactions between these variables that carries the necessary information for the accurate predictions. In addition, the identification of specific patterns for extreme groups of performance provides the necessary guidance for more focused educational interventions/investment and sound educational policies.",
        "DOI": "10.3389/feduc.2020.00104",
        "paper_author": "Musso M.F.",
        "affiliation_name": "Centro Interdisciplinario de Investigaciones en Psicología Matemática y Experimental",
        "affiliation_city": "Buenos Aires",
        "affiliation_country": "Argentina",
        "affiliation_id": "60283015",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Use AI to mine literature for policymaking",
        "publication": "Nature",
        "citied_by": "4",
        "cover_date": "2020-07-16",
        "Abstract": "NA",
        "DOI": "10.1038/d41586-020-02086-x",
        "paper_author": "Gokhberg L.",
        "affiliation_name": "HSE University",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60020513",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A novel ensemble computational intelligence approach for the spatial prediction of land subsidence susceptibility",
        "publication": "Science of the Total Environment",
        "citied_by": "83",
        "cover_date": "2020-07-15",
        "Abstract": "Land subsidence (LS) is a significant problem that can cause loss of life, damage property, and disrupt local economies. The Semnan Plain is an important part of Iran, where LS is a major problem for sustainable development and management. The plain represents the changes occurring in 40% of the country. We introduce a novel-ensemble intelligence approach (called ANN-bagging) that uses bagging as a meta- or ensemble-classifier of an artificial neural network (ANN) to predict LS spatially on the Semnan Plain in Semnan Province, Iran. The ensemble model's goodness-of-fit (to training data) and prediction accuracy (of the validation data) are compared to benchmarks set by ANN-bagging. A total of 96 locations of LS and 12 LS conditioning factors (LSCFs) were collected. Each feature in the LS inventory map (LSIM) was randomly assigned to one of four groups or folds, each comprising 25% of cases. The novel ensemble model was trained using 75% (3 folds) and validated with the remaining 25% (1 fold) in a four-fold cross-validation (CV) system, which is used to control for the effects of the random selection of the training and validation datasets. LSCFs for LS prediction were selected using the information-gain ratio and multi-collinearity test methods. Factor significance was evaluated using a random forest (RF) model. Groundwater drawdown, land use and land cover, elevation, and lithology were the most important LSCFs. Using the k-fold CV approaches, twelve LS susceptibility maps (LSSMs) were prepared as each fold employed all three models (ANN-bagging, ANN, and bagging). The LS susceptibility mapping showed that between 5.7% and 12.6% of the plain had very high LS susceptibility. All three models produced LS susceptibility maps with acceptable prediction accuracies and goodness-of-fits, but the best maps were produced by the ANN-bagging ensemble method. Overall, LS risk was highest in agricultural areas with high groundwater drawdown in the flat lowlands on quaternary sediments (Qcf). Groundwater extraction rates should be monitored and potentially limited in regions of severe or high LS susceptibility. This investigation details a novel methodology that can help environmental planners and policy makers to mitigate LS to help achieve sustainability.",
        "DOI": "10.1016/j.scitotenv.2020.138595",
        "paper_author": "Arabameri A.",
        "affiliation_name": "Tarbiat Modares University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60032053",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Data-driven adaptive optimal control for stochastic systems with unmeasurable state",
        "publication": "Neurocomputing",
        "citied_by": "7",
        "cover_date": "2020-07-15",
        "Abstract": "This paper proposes a computational data-driven adaptive optimal control strategy for a class of linear stochastic systems with unmeasurable state. First, a data-driven optimal observer is designed to obtain the optimal state estimation policy. On this basis, an off-policy data-driven ADP algorithm is further proposed, yielding the stochastic optimal control in the absence of system model. An application example of the learning mechanism of central nervous system in arm movement control is given to illustrate the effectiveness and practicality of the strategy.",
        "DOI": "10.1016/j.neucom.2019.12.001",
        "paper_author": "Zhang M.",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016835",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting mortality from 57 economic, behavioral, social, and psychological factors",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "65",
        "cover_date": "2020-07-14",
        "Abstract": "Behavioral and social scientists have identified many nonbiological predictors of mortality. An important limitation of much of this research, however, is that risk factors are not studied in comparison with one another or from across different fields of research. It therefore remains unclear which factors should be prioritized for interventions and policy to reduce mortality risk. In the current investigation, we compare 57 factors within a multidisciplinary framework. These include (i) adverse socioeconomic and psychosocial experiences during childhood and (ii) socioeconomic conditions, (iii) health behaviors, (iv) social connections, (v) psychological characteristics, and (vi) adverse experiences during adulthood. The current prospective cohort investigation with 13,611 adults from 52 to 104 y of age (mean age 69.3 y) from the nationally representative Health and Retirement Study used weighted traditional (i.e., multivariate Cox regressions) and machine-learning (i.e., lasso, random forest analysis) statistical approaches to identify the leading predictors of mortality over 6 y of follow-up time. We demonstrate that, in addition to the well-established behavioral risk factors of smoking, alcohol abuse, and lack of physical activity, economic (e.g., recent financial difficulties, unemployment history), social (e.g., childhood adversity, divorce history), and psychological (e.g., negative affectivity) factors were also among the strongest predictors of mortality among older American adults. The strength of these predictors should be used to guide future transdisciplinary investigations and intervention studies across the fields of epidemiology, psychology, sociology, economics, and medicine to understand how changes in these factors alter individual mortality risk.",
        "DOI": "10.1073/pnas.1918455117",
        "paper_author": "Puterman E.",
        "affiliation_name": "The University of British Columbia",
        "affiliation_city": "Vancouver",
        "affiliation_country": "Canada",
        "affiliation_id": "60010365",
        "affiliation_state": "BC"
    },
    {
        "paper_title": "Understanding targeted video-ads in children's content",
        "publication": "Proceedings of the 31st ACM Conference on Hypertext and Social Media, HT 2020",
        "citied_by": "3",
        "cover_date": "2020-07-13",
        "Abstract": "As the volume of online video entertainment via streaming increases, ever so more are users targeted by online advertisement algorithms. Nevertheless, this rise in targeting and revenue does not come without any concerns. That is, even though the online advertising business model has is very successful, nowadays, rising societal concerns regarding the ethics and extent to which such algorithms agree with the laws of different countries are also present. Motivated by the dichotomy above, we here explore how targeted video-ads meet the regulatory policies regarding children advertising in Brazil and Canada. To perform our study, we create synthetic user personas that watch YouTube videos daily. Our personas are tailored to stream children's content while controlling for several variables (e.g., gender, country, and type of content streamed). With the data gathered, our analyses reveal statistical evidence of algorithmic targeting in videos geared towards children. Also, some of the advertised products (e.g., alcoholic beverages and fast-food) go directly against the regulations of the studied countries. With advertisements being matched to users by machine learning algorithms, it is impossible to state whether regulations are not followed on purpose (e.g., advertisers gaming the system). Nevertheless, our findings and discussion do raise a flag that regulations may not be sufficient, and content providers may still need to audit systems to meet the regulations.",
        "DOI": "10.1145/3372923.3404787",
        "paper_author": "Figueiredo F.",
        "affiliation_name": "Universidade Federal de Minas Gerais",
        "affiliation_city": "Belo Horizonte",
        "affiliation_country": "Brazil",
        "affiliation_id": "60030074",
        "affiliation_state": "MG"
    },
    {
        "paper_title": "Matching Algorithms for Blood Donation",
        "publication": "EC 2020 - Proceedings of the 21st ACM Conference on Economics and Computation",
        "citied_by": "11",
        "cover_date": "2020-07-13",
        "Abstract": "Managing perishable inventory, such as blood stock awaiting use by patients in need, has been a topic of research for decades. This has been investigated across several disciplines: medical and social scientists have investigated who donates blood, how frequently, and why; management science researchers have long studied the blood supply chain from a logistical perspective. Yet global demand for blood still far exceeds supply, and unmet need is greatest in low- and middle-income countries. Both academics and policy experts suggest that large-scale coordination is necessary to alleviate demand for donor blood. Using the recently-deployed Facebook Blood Donation tool, we conduct the first large-scale algorithmic matching of blood donors with donation opportunities. In both simulations and real experiments we match potential donors with opportunities, guided by a machine learning model trained on prior observations of donor behavior. While measuring actual donation rates remains a challenge, we measure donor action (i.e., calling a blood bank or making an appointment) as a proxy for actual donation. Simulations suggest that even a simple matching strategy can increase donor action rate by 10-15%; a pilot experiment with real donors finds a slightly smaller increase of roughly 5%. While overall action rates remain low, even this modest increase among donors in a global network corresponds to many thousands of more potential donors taking action toward donation. Further, observing donor action on a social network can shed light onto donor behavior and response to incentives. Our initial findings align with several observations made in the medical and social science literature regarding donor behavior.",
        "DOI": "10.1145/3391403.3399458",
        "paper_author": "McElfresh D.C.",
        "affiliation_name": "University of Maryland, College Park",
        "affiliation_city": "College Park",
        "affiliation_country": "United States",
        "affiliation_id": "60020304",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Generating Adversarial Examples for Static PE Malware Detector Based on Deep Reinforcement Learning",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "9",
        "cover_date": "2020-07-13",
        "Abstract": "Machine learning technology has been applied in filed of malware detection; it can improve efficiency of malware detection to deal with more and more increasing malware variants. However, malware detection model based on machine learning also has weakness which can be cheated by adversarial examples. Researching on method of generating adversarial examples could be benefit to exposing vulnerability of malware detection model and designing better malware detector. In this paper, we propose a reinforcement learning environment named gym-malware-mini based on gym-malware through which we generate adversarial examples using DQN and A2C deep reinforcement learning algorithm. As a result, DQN agent learned better policy of generating adversarial examples in gym-malware-mini, Success rate is increased by 18% compared with gym-malware. Success rate of DQN agent and A2C agent is increased by 20% and 15% compared with random agent in gym-malware-mini environment.",
        "DOI": "10.1088/1742-6596/1575/1/012011",
        "paper_author": "Chen J.",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60024350",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "How to build a more open justice system",
        "publication": "Science",
        "citied_by": "16",
        "cover_date": "2020-07-10",
        "Abstract": "NA",
        "DOI": "10.1126/science.aba6914",
        "paper_author": "Pah A.R.",
        "affiliation_name": "Kellogg School of Management Northwestern University",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States",
        "affiliation_id": "60138820",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Restructured society and environment: A review on potential technological strategies to control the COVID-19 pandemic",
        "publication": "Science of the Total Environment",
        "citied_by": "218",
        "cover_date": "2020-07-10",
        "Abstract": "The emergence of Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) in China at December 2019 had led to a global outbreak of coronavirus disease 2019 (COVID-19) and the disease started to spread all over the world and became an international public health issue. The entire humanity has to fight in this war against the unexpected and each and every individual role is important. Healthcare system is doing exceptional work and the government is taking various measures that help the society to control the spread. Public, on the other hand, coordinates with the policies and act accordingly in most state of affairs. But the role of technologies in assisting different social bodies to fight against the pandemic remains hidden. The intention of our study is to uncover the hidden roles of technologies that ultimately help for controlling the pandemic. On investigating, it is found that the strategies utilizing potential technologies would yield better benefits and these technological strategies can be framed either to control the pandemic or to support the confinement of the society during pandemic which in turn aids in controlling the spreading of infection. This study enlightens the various implemented technologies that assists the healthcare systems, government and public in diverse aspects for fighting against COVID-19. Furthermore, the technological swift that happened during the pandemic and their influence in the environment and society is discussed. Besides the implemented technologies, this work also deals with untapped potential technologies that have prospective applications in controlling the pandemic circumstances. Alongside the various discussion, our suggested solution for certain situational issues is also presented.",
        "DOI": "10.1016/j.scitotenv.2020.138858",
        "paper_author": "Madurai Elavarasan R.",
        "affiliation_name": "Sri Venkateswara College of Engineering, Sriperumbudur",
        "affiliation_city": "Sriperumbudur",
        "affiliation_country": "India",
        "affiliation_id": "60069599",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "An efficient actor-critic reinforcement learning for device-to-device communication underlaying sectored cellular network",
        "publication": "International Journal of Communication Systems",
        "citied_by": "4",
        "cover_date": "2020-07-10",
        "Abstract": "In this paper, a novel reinforcement learning (RL) approach with cell sectoring is proposed to solve the channel and power allocation issue for a device-to-device (D2D)-enabled cellular network when the prior traffic information is not known to the base station (BS). Further, this paper explores an optimal policy for resource and power allocation between users intending to maximize the sum-rate of the overall system. Since the behavior of wireless channel and traffic request of users in the system is stochastic in nature, the dynamic property of the environment allows us to employ an actor-critic RL technique to learn the best policy through continuous interaction with the surrounding. The proposed work comprises of four phases: cell splitting, clustering, queuing model, and channel allocation and power allocation simultaneously using an actor-critic RL. The implementation of cell splitting with novel clustering technique increases the network coverage, reduces co-channel cell interference, and minimizes the transmission power of nodes, whereas the queuing model solves the issue of waiting time for users in a priority-based data transmission. With the help of continuous state-action space, the actor-critic RL algorithm based on policy gradient improves the overall system sum-rate as well as the D2D throughput. The actor adopts a parameter-based stochastic policy for giving continuous action while the critic estimates the policy and criticizes the actor for the action. This reduces the high variance of the policy gradient. Through numerical simulations, the benefit of our resource sharing scheme over other existing traditional scheme is verified.",
        "DOI": "10.1002/dac.4315",
        "paper_author": "Khuntia P.",
        "affiliation_name": "National Institute of Technology Silchar",
        "affiliation_city": "Silchar",
        "affiliation_country": "India",
        "affiliation_id": "60097223",
        "affiliation_state": "AS"
    },
    {
        "paper_title": "BACS: Integrating behavioral sequences to ACS2",
        "publication": "GECCO 2020 Companion - Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion",
        "citied_by": "1",
        "cover_date": "2020-07-08",
        "Abstract": "In many real-world environments, only partial observations are provided, thus presenting challenges for Anticipatory Learning Classifier Systems (ALCS). The perceptual aliasing issue occurs when systems cannot differentiate situations that are truly distinct. To tackle the perceptual aliasing issue, ALCS classifiers can be chained in order to build Behavioral Sequences. Those sequences permit ALCS to deal with this issue, but they have never been implemented within ACS2 (Anticipatory Classifier System 2), although this is one of the most advanced ALCS. This paper introduces a novel learning classifier system, BACS, that integrates Behavioral sequences to ACS2. This integration required the adaptation of the action selection policy, the integration of an aliasing detection algorithm that let the system build behavioral classifiers, and the adaptation of the anticipatory learning process. The results obtained over a maze environment benchmark show that behavioral sequences are a promising approach to address the perceptual aliasing issue.",
        "DOI": "10.1145/3377929.3390002",
        "paper_author": "Orhand R.",
        "affiliation_name": "Laboratoire des Sciences de l'Ingénieur, de l'Informatique et de l'Imagerie",
        "affiliation_city": "Illkirch-Graffenstaden",
        "affiliation_country": "France",
        "affiliation_id": "60208831",
        "affiliation_state": "Grand Est"
    },
    {
        "paper_title": "DUGMO: Tool for the detection of unknown genetically modified organisms with high-throughput sequencing data for pure bacterial samples",
        "publication": "BMC Bioinformatics",
        "citied_by": "2",
        "cover_date": "2020-07-06",
        "Abstract": "Background: The European Community has adopted very restrictive policies regarding the dissemination and use of genetically modified organisms (GMOs). In fact, a maximum threshold of 0.9% of contaminating GMOs is tolerated for a \"GMO-free\"label. In recent years, imports of undescribed GMOs have been detected. Their sequences are not described and therefore not detectable by conventional approaches, such as PCR. Results: We developed DUGMO, a bioinformatics pipeline for the detection of genetically modified (GM) bacteria, including unknown GM bacteria, based on Illumina paired-end sequencing data. The method is currently focused on the detection of GM bacteria with - possibly partial - transgenes in pure bacterial samples. In the preliminary steps, coding sequences (CDSs) are aligned through two successive BLASTN against the host pangenome with relevant tuned parameters to discriminate CDSs belonging to the wild type genome (wgCDS) from potential GM coding sequences (pgmCDSs). Then, Bray-Curtis distances are calculated between the wgCDS and each pgmCDS, based on the difference of genomic vocabulary. Finally, two machine learning methods, namely the Random Forest and Generalized Linear Model, are carried out to target true GM CDS(s), based on six variables including Bray-Curtis distances and GC content. Tests carried out on a GM Bacillus subtilis showed 25 positive CDSs corresponding to the chloramphenicol resistance gene and CDSs of the inserted plasmids. On a wild type B. subtilis, no false positive sequences were detected. Conclusion: DUGMO detects exogenous CDS, truncated, fused or highly mutated wild CDSs in high-throughput sequencing data, and was shown to be efficient at detecting GM sequences, but it might also be employed for the identification of recent horizontal gene transfers.",
        "DOI": "10.1186/s12859-020-03611-5",
        "paper_author": "Hurel J.",
        "affiliation_name": "ANSES - French Agency for Food, Environmental and Occupational Health &amp; Safety",
        "affiliation_city": "Maisons-Alfort",
        "affiliation_country": "France",
        "affiliation_id": "60104932",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "A data-efficient deep learning approach for deployable multimodal social robots",
        "publication": "Neurocomputing",
        "citied_by": "14",
        "cover_date": "2020-07-05",
        "Abstract": "The deep supervised and reinforcement learning paradigms (among others) have the potential to endow interactive multimodal social robots with the ability of acquiring skills autonomously. But it is still not very clear yet how they can be best deployed in real world applications. As a step in this direction, we propose a deep learning-based approach for efficiently training a humanoid robot to play multimodal games—and use the game of ‘Noughts and Crosses’ with two variants as a case study. Its minimum requirements for learning to perceive and interact are based on a few hundred example images, a few example multimodal dialogues and physical demonstrations of robot manipulation, and automatic simulations. In addition, we propose novel algorithms for robust visual game tracking and for competitive policy learning with high winning rates, which substantially outperform DQN-based baselines. While an automatic evaluation shows evidence that the proposed approach can be easily extended to new games with competitive robot behaviours, a human evaluation with 130 humans playing with the Pepper robot confirms that highly accurate visual perception is required for successful game play.",
        "DOI": "10.1016/j.neucom.2018.09.104",
        "paper_author": "Cuayáhuitl H.",
        "affiliation_name": "University of Lincoln",
        "affiliation_city": "Lincoln",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026830",
        "affiliation_state": "Lincolnshire"
    },
    {
        "paper_title": "Data-Driven Optimal Assistance Control of a Lower Limb Exoskeleton for Hemiplegic Patients",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "15",
        "cover_date": "2020-07-03",
        "Abstract": "More recently, lower limb exoskeletons (LLE) have gained considerable interests in strength augmentation, rehabilitation, and walking assistance scenarios. For walking assistance, the LLE is expected to control the affected leg to track the unaffected leg's motion naturally. A critical issue in this scenario is that the exoskeleton system needs to deal with unpredictable disturbance from the patient, and the controller has the ability to adapt to different wearers. To this end, a novel data-driven optimal control (DDOC) strategy is proposed to adapt different hemiplegic patients with unpredictable disturbances. The interaction relation between two lower limbs of LLE and the leg of patient's unaffected side are modeled in the context of leader-follower framework. Then, the walking assistance control problem is transformed into an optimal control problem. A policy iteration (PI) algorithm is utilized to obtain the optimal controller. To improve the online adaptation to different patients, an actor-critic neural network (AC/NN) structure of the reinforcement learning (RL) is employed to learn the optimal controller on the basis of PI algorithm. Finally, experiments both on a simulation environment and a real LLE system are conducted to verify the effectiveness of the proposed walking assistance control method.",
        "DOI": "10.3389/fnbot.2020.00037",
        "paper_author": "Peng Z.",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60005465",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Perpetual growth, the labor share, and robots",
        "publication": "Economics of Innovation and New Technology",
        "citied_by": "8",
        "cover_date": "2020-07-03",
        "Abstract": "The recent literature on the economic effects of machine learning, robotization and artificial intelligence suggests that there may be an upcoming wave of substitution of human labor by machines. We argue that these new technologies may lead to so-called perpetual growth, i.e. growth of per capita income with a non-progressing state of technology. We specify an exact parameter threshold beyond which perpetual growth emerges, and argue that ongoing technological change may bring the threshold in reach. We also show that in a state of perpetual growth, factor-eliminating technological progress reduces the role of labor in the production process and that this leads to a rising wage rate but ever-declining share of wage income. We present simulation experiments on several policy options to combat this inequality, including a universal basic income as well as an option in which workers become owners of ‘robots’.",
        "DOI": "10.1080/10438599.2019.1643557",
        "paper_author": "Nomaler Ö.",
        "affiliation_name": "United Nations University – Maastricht Economic and Social Research Institute on Innovation and Technology",
        "affiliation_city": "Maastricht",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60024967",
        "affiliation_state": "Limburg"
    },
    {
        "paper_title": "Investigation of the impact of land-use distribution on pm<inf>2.5</inf> in weifang: Seasonal variations",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "25",
        "cover_date": "2020-07-02",
        "Abstract": "As air pollution becomes highly focused in China, the accurate identification of its influencing factors is critical for achieving effective control and targeted environmental governance. Land-use distribution is one of the key factors affecting air quality, and research on the impact of land-use distribution on air pollution has drawn wide attention. However, considerable studies have mostly used linear regression models, which fail to capture the nonlinear effects of land-use distribution on PM2.5 (fine particulate matter with a diameter less than or equal to 2.5 microns) and to show how impacts on PM2.5 vary with land-use magnitudes. In addition, related studies have generally focused on annual analyses, ignoring the seasonal variability of the impact of land-use distribution on PM2.5, thus leading to possible estimation biases for PM2.5 . This study was designed to address these issues and assess the impacts of land-use distribution on PM2.5 in Weifang, China. A machine learning statistical model, the boosted regression tree (BRT), was applied to measure nonlinear effects of land-use distribution on PM2.5, capture how land-use magnitude impacts PM2.5 across different seasons, and explore the policy implications for urban planning. The main conclusions are that the air quality will significantly improve with an increase in grassland and forest area, especially below 8% and 20%, respectively. When the distribution of construction land is greater than around 10%, the PM2.5 pollution can be seriously substantially increased with the increment of their areas. The impact of gardens and farmland presents seasonal characteristics. It is noted that as the weather becomes colder, the inhibitory effect of vegetation distribution on the PM2.5 concentration gradually decreases, while the positive impacts of artificial surface distributions, such as construction land and roads, are aggravated because leaves drop off in autumn (September–November) and winter (December–February). According to the findings of this study, it is recommended that Weifang should strengthen pollution control in winter, for instance, expand the coverage areas of evergreen vegetation like Pinus bungeana Zucc. and Euonymus japonicus Thunb, and increase the width and numbers of branches connecting different main roads. The findings also provide quantitative and optimal land-use planning and strategies to minimize PM2.5 pollution, referring to the status of regional urbanization and greening construction.",
        "DOI": "10.3390/ijerph17145135",
        "paper_author": "Li C.",
        "affiliation_name": "Chinese Academy of Surveying and Mapping",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60073462",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Time series analysis and forecasting with automated machine learning on a national ICD-10 database",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "20",
        "cover_date": "2020-07-02",
        "Abstract": "The application of machine learning (ML) for use in generating insights and making predictions on new records continues to expand within the medical community. Despite this progress to date, the application of time series analysis has remained underexplored due to complexity of the underlying techniques. In this study, we have deployed a novel ML, called automated time series (AutoTS) machine learning, to automate data processing and the application of a multitude of models to assess which best forecasts future values. This rapid experimentation allows for and enables the selection of the most accurate model in order to perform time series predictions. By using the nation-wide ICD-10 (International Classification of Diseases, Tenth Revision) dataset of hospitalized patients of Romania, we have generated time series datasets over the period of 2008–2018 and performed highly accurate AutoTS predictions for the ten deadliest diseases. Forecast results for the years 2019 and 2020 were generated on a NUTS 2 (Nomenclature of Territorial Units for Statistics) regional level. This is the first study to our knowledge to perform time series forecasting of multiple diseases at a regional level using automated time series machine learning on a national ICD-10 dataset. The deployment of AutoTS technology can help decision makers in implementing targeted national health policies more efficiently.",
        "DOI": "10.3390/ijerph17144979",
        "paper_author": "Olsavszky V.",
        "affiliation_name": "Universitätsklinikum Mannheim",
        "affiliation_city": "Mannheim",
        "affiliation_country": "Germany",
        "affiliation_id": "60001972",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Understanding power positions in a new digital landscape: perceptions of Syrian refugees and data experts on relocation algorithm",
        "publication": "Information Communication and Society",
        "citied_by": "19",
        "cover_date": "2020-07-02",
        "Abstract": "This study explores the differences and similarities between the perceptions of data experts and refugees as data subjects, in the context of a refugee relocation algorithm. The study conducted in-depth interviews with data experts and Syrian refugees in Estonia and Turkey. The results indicate that both refugees and data experts acknowledge the algorithms’ potential power for structuring the everyday life experiences of people. Whereas refugees mainly focused on cultural and social concerns, the data experts underlined the importance of refugees’ agency and the potential drawbacks of algorithms in terms of transparency and accountability. While both groups of interviewees thought the relocation algorithm could be useful especially in economic terms, the study demonstrates that algorithms create complex power relations and place extra pressure on both refugees and data experts. The new digital landscapes produced by algorithms entail a ‘triple agency’–an agency of experts developing and using these datafied solutions, an agency of data subjects being targets of those calculations, and an agency of algorithms. For solving the issue of ‘false authority’, where the modelling of spatial choice cannot grasp the socio-cultural reality, it is necessary to consider the socio-cultural context of the calculative devices. A paradigm shift in machine learning is necessary from learning machines as autonomous subjects to machines learning from social contexts and individuals’ experiences. Rather than experimenting with algorithmic solutions to speed up decisions about human lives, migration policies and relevant datafied solutions should consider the diversity of human experiences expressed in individuals’ everyday life.",
        "DOI": "10.1080/1369118X.2020.1739731",
        "paper_author": "Masso A.",
        "affiliation_name": "Majandusteaduskond",
        "affiliation_city": "Tallinn",
        "affiliation_country": "Estonia",
        "affiliation_id": "60199642",
        "affiliation_state": "Harjumaa"
    },
    {
        "paper_title": "Holding back from theory: limits and methodological alternatives of randomized field experiments in development economics",
        "publication": "Journal of Economic Methodology",
        "citied_by": "6",
        "cover_date": "2020-07-02",
        "Abstract": "In this paper, we critically and constructively examine the methodology of evidence-based development economics, which deploys randomized field experiments (RFEs) as its main tool. We describe the context in which this movement started, and illustrate in detail how RFEs are designed and implemented in practice, drawing on a series of experiments by Pascaline Dupas and her colleagues on the use of bednets, saving and governance in Kenya. We show that this line of experiments have evolved to address the limitation of obtaining policy-relevant insights from RFEs alone, characterized as their lack of external validity in the literature. After examining the two prominent responses by leading figures of evidence-based development economics, namely machine learning and structured speculation, we propose an alternative methodological strategy that incorporates two sub-fields, namely experimental economics and behavioral economics, to complement RFEs in investigating the data-generating process underlying the treatment effects of RFEs. This strategy highlights promising methodological developments in RFEs neither captured by the two proposals nor recognized by methodologists, and also guides how to combine different sub-fields of economics.",
        "DOI": "10.1080/1350178X.2020.1717585",
        "paper_author": "Favereau J.",
        "affiliation_name": "Université Lumière Lyon 2",
        "affiliation_city": "Lyon",
        "affiliation_country": "France",
        "affiliation_id": "60002142",
        "affiliation_state": "Auvergne-Rhone-Alpes"
    },
    {
        "paper_title": "Target Population Statistical Inference With Data Integration Across Multiple Sources—An Approach to Mitigate Information Shortage in Rare Disease Clinical Trials",
        "publication": "Statistics in Biopharmaceutical Research",
        "citied_by": "9",
        "cover_date": "2020-07-02",
        "Abstract": "A major challenge for rare disease clinical trials is the limited amount of available information for making robust statistical inference. While external data present information integration opportunities to enhance statistical inference, conventional data combining methods, for example, meta-analysis, usually do not adequately address study population differences. Matching methods, on the other hand, directly account for population characteristics but often lead to inefficient use of data by underutilizing unmatched data points. Aiming at a better bias-variance tradeoff, we propose an intuitive integrated inference framework to borrow information from all relevant data sources and make inference on the response of interest over a target population precisely characterized by the joint distribution of baseline covariates. The method is easily implemented and can be complemented by modern statistical learning or machine learning tools. Statistical inference is facilitated by the bootstrap. We argue that the integrated inference framework not only provides an intuitive and coherent perspective for a variety of clinical trial inference problems but also has broad application areas in clinical trial settings and beyond, as a quantitative data integration tool for making robust inference in a target population precise manner for policy and decision makers.",
        "DOI": "10.1080/19466315.2019.1654913",
        "paper_author": "Li X.",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60032499",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Health Data Analytics with an Opportunistic Big Data Algorithm",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-07-01",
        "Abstract": "In data-driven society, health data can lead to profound impacts on public safety policies, epidemic modeling, and advancement of health science and medicine. This paper presents an approach to automatically elucidating useful information from \"Big\" health data. In particular, we analyze manufactured cosmetic products containing chemicals that are known or suspected to cause cancer, birth defects, or developmental and reproductive harm. Our analysis is based on the Apriori algorithm, the heart of the popular Association Rule Mining to discover associations among sets of influencing factors. However, with rapid growth of huge amount of data, including ours, existing data analytics algorithms designed for in-memory data are not adequate. Most Big data analytics algorithms are implemented on MapReduce framework for execution in parallel and distributed environments. Unlike traditional implementation, our approach employs an opportunistic MapReduce-based Apriori algorithm to fully exploit parallelism. The paper describes the algorithm and presents our findings, from 113, 179 data instances, both in terms of the execution times and the discovered associations among product profiles. For a support threshold of 10% (5%,), 20 (53) association rules are obtained with an improved execution time over that of the traditional MapReduce-based algorithm by 14.6% (40.3%) on the average over three machines.",
        "DOI": "10.1145/3406601.3406628",
        "paper_author": "Chalumporn G.",
        "affiliation_name": "Edward E. Whitacre Jr. College of Engineering",
        "affiliation_city": "Lubbock",
        "affiliation_country": "United States",
        "affiliation_id": "60149446",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Privacy preservation of data-driven models in smart grids using homomorphic encryption",
        "publication": "Information (Switzerland)",
        "citied_by": "20",
        "cover_date": "2020-07-01",
        "Abstract": "Deep learning models have been applied for varied electrical applications in smart grids with a high degree of reliability and accuracy. The development of deep learning models requires the historical data collected from several electric utilities during the training of the models. The lack of historical data for training and testing of developed models, considering security and privacy policy restrictions, is considered one of the greatest challenges to machine learning-based techniques. The paper proposes the use of homomorphic encryption, which enables the possibility of training the deep learning and classical machine learning models whilst preserving the privacy and security of the data. The proposed methodology is tested for applications of fault identification and localization, and load forecasting in smart grids. The results for fault localization show that the classification accuracy of the proposed privacy-preserving deep learning model while using homomorphic encryption is 97–98%, which is close to 98–99% classification accuracy of the model on plain data. Additionally, for load forecasting application, the results show that RMSE using the homomorphic encryption model is 0.0352 MWh while RMSE without application of encryption in modeling is around 0.0248 MWh.",
        "DOI": "10.3390/info11070357",
        "paper_author": "Syed D.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60148980",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Early stage machine learning–based prediction of US county vulnerability to the COVID-19 pandemic: Machine learning approach",
        "publication": "JMIR Public Health and Surveillance",
        "citied_by": "33",
        "cover_date": "2020-07-01",
        "Abstract": "Background: The rapid spread of COVID-19 means that government and health services providers have little time to plan and design effective response policies. It is therefore important to quickly provide accurate predictions of how vulnerable geographic regions such as counties are to the spread of this virus. Objective: The aim of this study is to develop county-level prediction around near future disease movement for COVID-19 occurrences using publicly available data. Methods: We estimated county-level COVID-19 occurrences for the period March 14 to 31, 2020, based on data fused from multiple publicly available sources inclusive of health statistics, demographics, and geographical features. We developed a three-stage model using XGBoost, a machine learning algorithm, to quantify the probability of COVID-19 occurrence and estimate the number of potential occurrences for unaffected counties. Finally, these results were combined to predict the county-level risk. This risk was then used as an estimated after-five-day-vulnerability of the county. Results: The model predictions showed a sensitivity over 71% and specificity over 94% for models built using data from March 14 to 31, 2020. We found that population, population density, percentage of people aged >70 years, and prevalence of comorbidities play an important role in predicting COVID-19 occurrences. We observed a positive association at the county level between urbanicity and vulnerability to COVID-19. Conclusions: The developed model can be used for identification of vulnerable counties and potential data discrepancies. Limited testing facilities and delayed results introduce significant variation in reported cases, which produces a bias in the model.",
        "DOI": "10.2196/19446",
        "paper_author": "Mehta M.",
        "affiliation_name": "Pennsylvania State University",
        "affiliation_city": "University Park",
        "affiliation_country": "United States",
        "affiliation_id": "60001439",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "A multiview model for detecting the inappropriate use of prescription medication: Machine learning approach",
        "publication": "JMIR Medical Informatics",
        "citied_by": "4",
        "cover_date": "2020-07-01",
        "Abstract": "Background: The inappropriate use of prescription medication has recently garnered worldwide attention, but most national policies do not effectively provide for early detection or timely intervention. Objective: This study aimed to develop and assess the validity of a model that can detect the inappropriate use of prescription medication. This effort combines a multiview and topic matching method. The study also assessed the validity of this approach. Methods: A multiview extension of the latent Dirichlet allocation algorithm for topic modeling was chosen to generate diagnosis-medication topics, with data obtained from the Chinese Monitoring Network for Rational Use of Drugs (CMNRUD) database. Topic mapping allowed for calculating the degree to which diagnoses and medications were similarly distributed and, by setting a threshold, for identifying prescription misuse. The Beijing Regional Prescription Review Database (BRPRD) database was used as the gold standard to assess the model's validity. We also conducted a sensitivity analysis using random samples of validated prescriptions and evaluated the model's performance. Results: A total of 44 million prescriptions were used to generate topics using the diagnoses and medications from the CMNRUD database. A random sample (15,000 prescriptions) from the BRPRD was used for validation, and it was found that the model had a sensitivity of 81.8%, specificity of 47.4%, positive-predictive value of 14.5%, and negative-predictive value of 96.0%. The model showed superior stability under different sampling proportions. Conclusions: A method that combines multiview topic modeling and topic matching can detect the inappropriate use of prescription medication. This model, which has mediocre specificity and moderate sensitivity, can be used as a primary screening tool and will likely complement and improve the process of manually reviewing prescriptions.",
        "DOI": "10.2196/16312",
        "paper_author": "Zhuo L.",
        "affiliation_name": "Peking University Third Hospital",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60121975",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Control or Autism - Classification using Convolutional Neural Networks on Functional MRI",
        "publication": "2020 11th International Conference on Computing, Communication and Networking Technologies, ICCCNT 2020",
        "citied_by": "11",
        "cover_date": "2020-07-01",
        "Abstract": "Autism spectrum disorders (ASDs) because of it's permanent nature, high prevalence, substantial heterogeneity, and complexity contributes to a redoubtable challenge to the field of neuroscience and psychiatry. Thus in order to minimize the requirement of Large-scale multidisciplinary efforts, there is a dire need for the development of a reliable and efficient model that gives results at par with the ones offered by the doctors based on symptomatology. Many significant works have been propagated for classification of ASD, carried out over the Resting-State functional MRI (RS-fMRI) data. A novel convolutional neural network architecture has been developed for substantially analyzing the similarity in brain neural connectivities of the two classes, i.e. autism and control that outperforms existing Machine Learning/Deep Learning methods and produces state-of-the-art (SOTA) results. We have been able to attain an accuracy of 0.76 ± 0.039, precision of 0.7863 ± 0.037, and specificity of 0.8169 ± 0.047 using ten-fold Cross-validation policy on the pre-processed version of RS-fMRI data from the ABIDE-I database.",
        "DOI": "10.1109/ICCCNT49239.2020.9225506",
        "paper_author": "Shrivastava S.",
        "affiliation_name": "National Institute of Technology Raipur",
        "affiliation_city": "Raipur",
        "affiliation_country": "India",
        "affiliation_id": "60104578",
        "affiliation_state": "CG"
    },
    {
        "paper_title": "Social media emerging as a third eye !! decoding users' sentiment on government policy: A case study of GST",
        "publication": "Proceedings of the World Conference on Smart Trends in Systems, Security and Sustainability, WS4 2020",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "Micro blogging sites and other social networking platforms have become the primary means of communication and knowledge sharing with progressing technological trends. People across the globe express their views on products services, predict share price and present feedback on the policies of the regimes. Everything that is shared on social networks may not be authentic or denote the truth. However, it definitely forms a basis to investigate and comprehend the public sentiments. Public sentiments are capable of affecting the economic landscape via foreign investments and stock markets among having other financial and social impacts. In this paper, we have analyzed public sentiments on the Goods and Services tax, popularly known as GST in India. GST subsumes eight central and nine state taxes thereby integrating the absolute indirect tax framework in the country which paves the way for varied opinions reactions imperative to analyze a collective sentiment. We used a hybrid approach to do the sentiment analysis which uses a combination of lexicon-based method and supervised machine learning approach to determine public sentiments. We accumulated 163,373 tweets over a span of three weeks from July 4th to 25th, 2017 after GST was implemented in India w.e.f. July 1st, 2017. A spatio-temporal analysis was performed on the collected tweets. In this research, we annotated 22,000 unique tweets with the help of a lexicon-based method and thenceforth applied supervised machine learning techniques with a set of six distinct algorithms to train and predict the polarity on the complete data set. K-fold cross validation technique, for K in range of 3-10, was used to assess the model for an independent data set. Subsequently, it was found that accuracy, precision, recall and F1 score of all the models provided the best results when K approached 10. Resultantly, we observed that SVM and Logistic Regression could predict the polarity of new incoming tweets with an accuracy of 77.6% and 79.31% respectively.",
        "DOI": "10.1109/WorldS450073.2020.9210400",
        "paper_author": "Uniyal D.",
        "affiliation_name": "Graphic Era Deemed to be University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India",
        "affiliation_id": "60103785",
        "affiliation_state": "UK"
    },
    {
        "paper_title": "Double reinforcement learning for efficient off-policy evaluation in markov decision processes",
        "publication": "Journal of Machine Learning Research",
        "citied_by": "89",
        "cover_date": "2020-07-01",
        "Abstract": "Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate novel decision policies without needing to conduct exploration, which is often costly or otherwise infeasible. We consider for the first time the semiparametric efficiency limits of OPE in Markov decision processes (MDPs), where actions, rewards, and states are memoryless. We show existing OPE estimators may fail to be efficient in this setting. We develop a new estimator based on cross-fold estimation of q-functions and marginalized density ratios, which we term double reinforcement learning (DRL). We show that DRL is efficient when both components are estimated at fourth-root rates and is also doubly robust when only one component is consistent. We investigate these properties empirically and demonstrate the performance benefits due to harnessing memorylessness.",
        "DOI": "NA",
        "paper_author": "Kallus N.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Reliability of supervised machine learning using synthetic data in health care: Model to preserve privacy for data sharing",
        "publication": "JMIR Medical Informatics",
        "citied_by": "103",
        "cover_date": "2020-07-01",
        "Abstract": "Background: The exploitation of synthetic data in health care is at an early stage. Synthetic data could unlock the potential within health care datasets that are too sensitive for release. Several synthetic data generators have been developed to date; however, studies evaluating their efficacy and generalizability are scarce. Objective: This work sets out to understand the difference in performance of supervised machine learning models trained on synthetic data compared with those trained on real data. Methods: A total of 19 open health datasets were selected for experimental work. Synthetic data were generated using three synthetic data generators that apply classification and regression trees, parametric, and Bayesian network approaches. Real and synthetic data were used (separately) to train five supervised machine learning models: stochastic gradient descent, decision tree, k-nearest neighbors, random forest, and support vector machine. Models were tested only on real data to determine whether a model developed by training on synthetic data can used to accurately classify new, real examples. The impact of statistical disclosure control on model performance was also assessed. Results: A total of 92% of models trained on synthetic data have lower accuracy than those trained on real data. Tree-based models trained on synthetic data have deviations in accuracy from models trained on real data of 0.177 (18%) to 0.193 (19%), while other models have lower deviations of 0.058 (6%) to 0.072 (7%). The winning classifier when trained and tested on real data versus models trained on synthetic data and tested on real data is the same in 26% (5/19) of cases for classification and regression tree and parametric synthetic data and in 21% (4/19) of cases for Bayesian network-generated synthetic data. Tree-based models perform best with real data and are the winning classifier in 95% (18/19) of cases. This is not the case for models trained on synthetic data. When tree-based models are not considered, the winning classifier for real and synthetic data is matched in 74% (14/19), 53% (10/19), and 68% (13/19) of cases for classification and regression tree, parametric, and Bayesian network synthetic data, respectively. Statistical disclosure control methods did not have a notable impact on data utility. Conclusions: The results of this study are promising with small decreases in accuracy observed in models trained with synthetic data compared with models trained with real data, where both are tested on real data. Such deviations are expected and manageable. Tree-based classifiers have some sensitivity to synthetic data, and the underlying cause requires further investigation. This study highlights the potential of synthetic data and the need for further evaluation of their robustness. Synthetic data must ensure individual privacy and data utility are preserved in order to instill confidence in health care departments when using such data to inform policy decision-making.",
        "DOI": "10.2196/18910",
        "paper_author": "Rankin D.",
        "affiliation_name": "Ulster University",
        "affiliation_city": "Coleraine",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60020730",
        "affiliation_state": "Londonderry, Northern Ireland"
    },
    {
        "paper_title": "Control strategy of hydraulic cylinder based on Deep Reinforcement Learning",
        "publication": "15th International Conference Mechatronic Systems and Materials, MSM 2020",
        "citied_by": "11",
        "cover_date": "2020-07-01",
        "Abstract": "Authors developed a novel control strategy of hydraulic cylinder based on deep reinforcement learning. The control parameters of hydraulic cylinder are difficult to regulate for practical applications, and problems of force and oil pressure disturbance occur during the operation process. A class of reinforcement learning agents developed for hydraulic systems is designed based on the deep deterministic policy gradient and proximal policy optimization algorithms. The agents are trained by a significant number of system data. After learning completion, they can automatically control the hydraulic system online and consequently the system can always maintain a good control performance. Experiments are conducted to verify the proposed control strategy. Results show that the proposed method can achieve better performance that conventional proportional-integral-derivative regulator and effectively overcome the effects of disturbance.",
        "DOI": "10.1109/MSM49833.2020.9202351",
        "paper_author": "Wyrwal D.",
        "affiliation_name": "Politechnika Poznanska",
        "affiliation_city": "Poznan",
        "affiliation_country": "Poland",
        "affiliation_id": "60008555",
        "affiliation_state": "WP"
    },
    {
        "paper_title": "Autonomous warehouse-scale computers",
        "publication": "Proceedings - Design Automation Conference",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "Modern Warehouse-Scale Computers (WSCs), composed of many generations of servers and a myriad of domain specific accelerators, are becoming increasingly heterogeneous. Meanwhile, WSC workloads are also becoming incredibly diverse with different communication patterns, latency requirements, and service level objectives (SLOs). Insufficient understanding of the interactions between workload characteristics and the underlying machine architecture leads to resource over-provisioning, thereby significantly impacting the utilization of WSCs.We present Autonomous Warehouse-Scale Computers, a new WSC design that leverages machine learning techniques and automation to improve job scheduling, resource management, and hardware-software co-optimization to address the increasing heterogeneity in WSC hardware and workloads. Our new design introduces two new layers in the WSC stack, namely: (a) a Software-Defined Server (SDS) Abstraction Layer which redefines the hardware-software boundary and provides greater control of the hardware to higher layers of the software stack through stable abstractions; and (b) a WSC Efficiency Layer which regularly monitors the resource usage of workloads on different hardware types, autonomously quantifies the performance sensitivity of workloads to key system configurations, and continuously improves scheduling decisions and hardware resource QoS policies to maximize cluster level performance. Our new WSC design has been successfully deployed across all WSCs at Google for several years now. The new WSC design improves throughput of workloads (by 7-10%, on average), increases utilization of hardware resources (up to 2x), and reduces performance variance for critical workloads (up to 25%).",
        "DOI": "10.1109/DAC18072.2020.9218509",
        "paper_author": "Dev S.",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States",
        "affiliation_id": "60006191",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Grid Voltage Control Method Based on Generator Reactive Power Regulation Using Reinforcement Learning",
        "publication": "2020 IEEE/IAS Industrial and Commercial Power System Asia, I and CPS Asia 2020",
        "citied_by": "9",
        "cover_date": "2020-07-01",
        "Abstract": "Too high or too low grid voltage will greatly affect the operation safety of the power system. This paper proposes a voltage regulation method based on generator reactive power regulation using reinforcement learning. First, the members of the agent are selected based on the reactive power of the generator, and then the Q tables are trained corresponding to the agent. According to the voltage amplitude state of the point to be adjusted, the regulation action is given. In order to solve the problem of complex combination of action sets and difficult convergence of Q table in a single agent, multi-agents are selected to decompose complex regulation actions into a series of continuous simple actions. At the same time, in order to improve the effectiveness of agent actions, the 'progress' reward mechanism is proposed. The method based on reinforcement learning proposed in this paper can effectively regulate the reactive voltage of the system.",
        "DOI": "10.1109/ICPSAsia48933.2020.9208556",
        "paper_author": "Wang Y.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Solar Power Forecasting Based on Ensemble Learning Methods",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "11",
        "cover_date": "2020-07-01",
        "Abstract": "Alternative energy sources are becoming more and more common around the world. In order to reduce environmental pollution and CO2 emissions, in addition to being an ideal solution to overcome the energy crisis. In this context, power energy stands out, as it is the most abundant and most widely available natural resource on the entire planet. Due to the high level of uncertainty of the factors that directly interfere in the generation of solar power, such as temperature and solar radiation, make predictions of solar power with high precision is a challenge. Thus, the objective of this article is to develop a forecasting model, through time series, that makes it possible to predict the production of power energy, using a database collected in a photovoltaic plant in Uruguay. For the development of the proposal, models (base-learners), pre-processing techniques and models (meta-learners) used in the Stacking-Ensemble Learnig (STACK) method were used, which were compared using the measurements of performance Relative Root Mean Square Error (RRMSE), Symmetric Mean Absolute Percentage Error (sMAPE) and Determination Coefficient (R2 ) in addition to statistical tests. In the end, it can be concluded that the combination Correlation Matrix (CORR) and Language Model (LM), from Layer-0 obtained the best results, in the three performance measures and the combination of models (base-learners) and pre-processing techniques (Layer-0) presented the best results when compared to Layer-1, obtaining satisfactory values in all performance measures.",
        "DOI": "10.1109/IJCNN48605.2020.9206777",
        "paper_author": "Fraccanabbia N.",
        "affiliation_name": "Pontifícia Universidade Católica do Paraná",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil",
        "affiliation_id": "60020004",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "On the (Un)Reliability of Privacy Policies in Android Apps",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "27",
        "cover_date": "2020-07-01",
        "Abstract": "The access to privacy-sensitive information on Android is a growing concern in the mobile community. Albeit Google Play recently introduced some privacy guidelines, it is still an open problem to soundly verify whether apps actually comply with such rules. To this aim, in this paper, we discuss a novel methodology based on a fruitful combination of static analysis, dynamic analysis, and machine learning techniques, which allows assessing such compliance. More in detail, our methodology checks whether each app i) contains a privacy policy that complies with the Google Play privacy guidelines, and ii) accesses privacy-sensitive information only upon the acceptance of the policy by the user. Furthermore, the methodology also allows checking the compliance of third-party libraries embedded in the apps w.r.t. the same privacy guidelines.We implemented our methodology in a tool, 3PDroid, and we carried out an assessment on a set of recent and most-downloaded Android apps in the Google Play Store. Experimental results suggest that more than 95% of apps access user's privacy-sensitive information, but just a negligible subset of them (≈ 1%) fully complies with the Google Play privacy guidelines.",
        "DOI": "10.1109/IJCNN48605.2020.9206660",
        "paper_author": "Verderame L.",
        "affiliation_name": "Università degli Studi di Genova",
        "affiliation_city": "Genoa",
        "affiliation_country": "Italy",
        "affiliation_id": "60025153",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "PsychFM: Predicting your next gamble",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "1",
        "cover_date": "2020-07-01",
        "Abstract": "There is a sudden surge to model human behavior due to its vast and diverse applications which includes modeling public policies, economic behavior and consumer behavior. Most of the human behavior itself can be modeled into a choice prediction problem. Prospect theory is a theoretical model that tries to explain the anomalies in choice prediction. These theories perform well in terms of explaining the anomalies but they lack precision. Since the behavior is person dependent, there is a need to build a model that predicts choices on a per-person basis. Looking on at the average persons choice may not necessarily throw light on a particular person's choice. Modeling the gambling problem on a per person basis will help in recommendation systems and related areas. A novel hybrid model namely psychological factorisation machine ( PsychFM ) has been proposed that involves concepts from machine learning as well as psychological theories. It outperforms the popular existing models namely random forest and factorisation machines for the benchmark dataset CPC-18. Finally, the efficacy of the proposed hybrid model has been verified by comparing with the existing models.",
        "DOI": "10.1109/IJCNN48605.2020.9207591",
        "paper_author": "Rajan P.",
        "affiliation_name": "Indian Institute of Technology Gandhinagar",
        "affiliation_city": "Gandhinagar",
        "affiliation_country": "India",
        "affiliation_id": "60104341",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Reinforcement-based Program Induction in a Neural Virtual Machine",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "We present a neural virtual machine that can be trained to perform algorithmic tasks. Rather than combining a neural controller with non-neural memory storage as has been done in the past, this architecture is purely neural and emulates tape-based memory via fast associative weights (one-step learning). Here we formally define the architecture, and then extend the system to learn programs using recurrent policy gradient reinforcement learning based on examples of program inputs labeled with corresponding output targets, which are compared against actual output to generate a sparse reward signal. We describe the policy gradient training procedure used, and report its empirical performance on a number of small-scale list processing tasks, such as finding the maximum list element, filtering out certain elements, and reversing the order of the elements. These results show that program induction via reinforcement learning is possible using sparse rewards and solely neural computations.",
        "DOI": "10.1109/IJCNN48605.2020.9207671",
        "paper_author": "Katz G.E.",
        "affiliation_name": "Syracuse University",
        "affiliation_city": "Syracuse",
        "affiliation_country": "United States",
        "affiliation_id": "60030551",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Instance-Based Ensemble Selection Using Deep Reinforcement Learning",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "2",
        "cover_date": "2020-07-01",
        "Abstract": "Ensemble selection is a very active research topic in machine learning area. It aims to achieve a better performance by selecting a proper subset of the original ensemble, which is essentially a searching problem in large combinatorial spaces. In this paper, we propose an instance-based reinforcement learning (IBRL) model, that selects distinct subsets for different instances. Specifically, we use deep Q-network to approximate the optimal policy. Rather than considering the overall performance of each classifier, the network learns from the feedback of classifiers on individual instance, so that it generates non-static subsets for different instances. Experiments are conducted to compare our model against state-of-the-art approaches for both selection and combination. The proposed method generates promising results and it shows exceptional advantage in large scale distributed environment. Due to the environment-free characteristic of reinforcement learning, our model is adaptable to various real world tasks with minimal changes.",
        "DOI": "10.1109/IJCNN48605.2020.9207215",
        "paper_author": "Liu Z.",
        "affiliation_name": "School of Computing and Information Systems",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118847",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Stochastic Curiosity Maximizing Exploration",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "Deep reinforcement learning (RL) is known as an emerging research trend in machine learning for autonomous systems. In real-world scenarios, the extrinsic rewards, acquired from the environment for learning an agent, are usually missing or extremely sparse. Such an issue of sparse reward constrains the learning capability of agent because the agent only updates the policy when the goal state is successfully attained. It is always challenging to implement an efficient exploration in RL algorithms. To tackle the sparse reward and inefficient exploration, the agent needs other helpful information to update its policy even when there is no interaction with the environment. This paper proposes the stochastic curiosity maximizing exploration (SCME), a learning strategy explored to allow the agent to act as human. We cope with the sparse reward problem by encouraging the agent to explore future diversity. To do so, a latent dynamic system is developed to acquire the latent states and latent actions to predict the variations in future conditions. The mutual information and the prediction error in the predicted states and actions are calculated as the intrinsic rewards. The agent based on SCME is therefore learned by maximizing these rewards to improve sample efficiency for exploration. The experiments on PyDial and Super Mario Bros show the benefits of the proposed SCME in dialogue system and computer game, respectively.",
        "DOI": "10.1109/IJCNN48605.2020.9207295",
        "paper_author": "Chien J.T.",
        "affiliation_name": "National Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60012370",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Multi-level Visual Fusion Networks for Image Captioning",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "1",
        "cover_date": "2020-07-01",
        "Abstract": "Image captioning is a multi-modal complex task in machine learning. Traditional methods focus only on entities in visual strategy networks, and can't reason about the relationship between entities and attributes. There are problems of exposure bias and error accumulation in language strategy networks. To this end, this paper proposes a multi-level visual fusion network model based on reinforcement learning. In the visual strategy network, multi-level neural network modules are used to transform visual features into feature sets of visual knowledge. The fusion network generates function words that make the description more fluent, and is used for the interaction between the visual strategy network and the language strategy network. The self-criticism strategy gradient algorithm based on reinforcement learning in language strategy networks is used to achieve end-to-end optimization of visual fusion networks. We evaluated our model on the Flickr 30K and MS-COCO datasets, and verified the accuracy of the model and the diversity of model learning subtitles through experiments. Our model achieves better performance over state-of-the-art methods.",
        "DOI": "10.1109/IJCNN48605.2020.9206932",
        "paper_author": "Zhou D.",
        "affiliation_name": "Guangxi Normal University",
        "affiliation_city": "Guilin",
        "affiliation_country": "China",
        "affiliation_id": "60020464",
        "affiliation_state": "Guangxi"
    },
    {
        "paper_title": "Beating the Stock Market with a Deep Reinforcement Learning Day Trading System",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "19",
        "cover_date": "2020-07-01",
        "Abstract": "In this study we investigate the potential of using Deep Reinforcement Learning (DRL) to day trade stocks, taking into account the constraints imposed by the stock market, such as liquidity, latency, slippage and transaction costs. More specifically, we use a Deep Deterministic Policy Gradient (DDPG) algorithm to solve a series of asset allocation problems in order to define the percentage of capital that must be invested in each asset at each period, executing exclusively day trade operations. DDPG is a model-free, off-policy actor-critic method that can learn policies in high-dimensional and continuous action and state spaces, like the ones normally found in financial market environments. The proposed day trading system was tested in B3 - Brazil Stock Exchange, an important and understudied market, especially considering the application of DRL techniques to alpha generation. A series of experiments were performed from the beginning of 2017 until the end of 2019 and compared with ten benchmarks, including Ibovespa, the most important Brazilian market index, and the stock portfolios suggested by the main Brazilian banks and brokers during these years. The results were evaluated considering return and risk metrics and showed that the proposed method outperformed the benchmarks by a huge margin. The best results obtained by the algorithm had a cumulative percentage return of 311% in three years, with an annual average maximum drawdown around 19%.",
        "DOI": "10.1109/IJCNN48605.2020.9206938",
        "paper_author": "Conegundes L.",
        "affiliation_name": "Universidade Federal de Minas Gerais",
        "affiliation_city": "Belo Horizonte",
        "affiliation_country": "Brazil",
        "affiliation_id": "60030074",
        "affiliation_state": "MG"
    },
    {
        "paper_title": "FasTrCaps: An Integrated Framework for Fast yet Accurate Training of Capsule Networks",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "9",
        "cover_date": "2020-07-01",
        "Abstract": "Recently, Capsule Networks (CapsNets) have shown improved performance compared to the traditional Convolutional Neural Networks (CNNs), by encoding and preserving spatial relationships between the detected features in a better way. This is achieved through the so-called Capsules (i.e., groups of neurons) that encode both the instantiation probability and the spatial information. However, one of the major hurdles in the wide adoption of CapsNets is their gigantic training time, which is primarily due to the relatively higher complexity of their new constituting elements that are different from CNNs.In this paper, we implement different optimizations in the training loop of the CapsNets, and investigate how these optimizations affect their training speed and the accuracy. Towards this, we propose a novel framework FasTrCaps that integrates multiple lightweight optimizations and a novel learning rate policy called WarmAdaBatch (that jointly performs warm restarts and adaptive batch size), and steers them in an appropriate way to provide high training-loop speedup at minimal accuracy loss. We also propose weight sharing for capsule layers. The goal is to reduce the hardware requirements of CapsNets by removing unused/redundant connections and capsules, while keeping high accuracy through tests of different learning rate policies and batch sizes. We demonstrate that one of the solutions generated by the FasTrCaps framework can achieve 58.6% reduction in the training time, while preserving the accuracy (even 0.12% accuracy improvement for the MNIST dataset), compared to the CapsNet by Google Brain [25]. Moreover, the Pareto-optimal solutions generated by FasTrCaps can be leveraged to realize trade-offs between training time and achieved accuracy. We have open-sourced our framework on GitHub1.",
        "DOI": "10.1109/IJCNN48605.2020.9207533",
        "paper_author": "Marchisio A.",
        "affiliation_name": "Technische Universität Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria",
        "affiliation_id": "60018163",
        "affiliation_state": "Vienna"
    },
    {
        "paper_title": "Enhancing the Detection of Criminal Organizations in Mexico using ML and NLP",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "17",
        "cover_date": "2020-07-01",
        "Abstract": "This paper relies on Machine Learning (ML) and supervised Natural Language Processing (NLP) to generate a geo-referenced database on the violent presence of Mexican Criminal Organizations (MCOs) between 2000-2018. This application responds to the need for high-quality data on criminal groups to inform academic and policy analysis in a context of intense violence such as Mexico. Powered by ML and NLP tools, this computational social science application processes a vast collection of news stories written in Spanish to track MCOs' violent presence. The unprecedented granularity of the data allows disaggregating daily-municipal information for 10 main MCOs comprising more than 200 specific criminal cells.",
        "DOI": "10.1109/IJCNN48605.2020.9207039",
        "paper_author": "Osorio J.",
        "affiliation_name": "The University of Arizona",
        "affiliation_city": "Tucson",
        "affiliation_country": "United States",
        "affiliation_id": "60010065",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "HAMLET - A Learning Curve-Enabled Multi-Armed Bandit for Algorithm Selection",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "Automated algorithm selection and hyperparameter tuning facilitates the application of machine learning. Traditional multi-armed bandit strategies look to the history of observed rewards to identify the most promising arms for optimizing expected total reward in the long run. When considering limited time budgets and computational resources, this backward view of rewards is inappropriate as the bandit should look into the future for anticipating the highest final reward at the end of a specified time budget. This work addresses that insight by introducing HAMLET, which extends the bandit approach with learning curve extrapolation and computation time-awareness for selecting among a set of machine learning algorithms. Results show that the HAMLET Variants 1-3 exhibit equal or better performance than other bandit-based algorithm selection strategies in experiments with recorded hyperparameter tuning traces for the majority of considered time budgets. The best performing HAMLET Variant 3 combines learning curve extrapolation with the well-known upper confidence bound exploration bonus. That variant performs better than all non-HAMLET policies with statistical significance at the 95% level for 1,485 runs.",
        "DOI": "10.1109/IJCNN48605.2020.9207233",
        "paper_author": "Schmidt M.",
        "affiliation_name": "NEC Laboratories Europe GmbH",
        "affiliation_city": "Heidelberg",
        "affiliation_country": "Germany",
        "affiliation_id": "60078342",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Transformer Decoder Based Reinforcement Learning Approach for Conversational Response Generation",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "2",
        "cover_date": "2020-07-01",
        "Abstract": "Developing a machine that can hold an engaging conversation with a human is one of the main challenges in designing a dialogue system in the field of natural language processing. Responses generated by neural conversational models with log-likelihood training methods tend to lack informativeness and diversity. We address the limitation of log-likelihood training in dialogue generation models, and we present the Reinforce Transformer decoder model, our new approach for training the Transformer decoder based conversational model, which incorporates proximal policy optimization techniques from re-inforcement learning with the Transformer decoder architecture. We specifically examine the use of our proposed model for multi-turn dialogue response generation in a real word human to a human dataset. To verify the effectiveness of our proposed framework, we evaluate our model on the Reddit dialogues data, which is a real word human to a human dataset. Experiments show that our proposed response generating model in a dialogue achieves significant improvement over recurrent sequence-to-sequence models and also the state of the art Transformer based dialogue generation models based on diversity and relevance evaluation metrics.",
        "DOI": "10.1109/IJCNN48605.2020.9207289",
        "paper_author": "Faal F.",
        "affiliation_name": "Concordia Institute for Information Systems Engineering",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60116756",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Reinforcement Learning based Droplet Routing Algorithm for Digital Microfluidic Biochips",
        "publication": "2020 24th International Symposium on VLSI Design and Test, VDAT 2020",
        "citied_by": "5",
        "cover_date": "2020-07-01",
        "Abstract": "Digital Microfluidic Biochips (DMFBs) are part of lab-on-a-chip (LOC) devices and comes under the category of micro-electro-mechanical systems (MEMS). DMFBs are designed to be an alternative for traditional biochemical laboratories. DMFBs achieve miniaturization, automation, and programmability. DMFBs use electro-wetting-on-dielectric (EWOD) property to manipulate droplets on-chip discretely. Several computer-aided design (CAD) techniques have been designed for synthesizing DMFBs to reduce design complexity. Finding the concurrent routes between all source-target pairs of a bioassay is a challenging problem and NP-Complete. We proposed a reinforcement learning based droplet routing algorithm for DMFBs. Q-learning technique is used to determine a certain predefined number of optimal paths between a source-target pair. Q-learning is an off-policy reinforcement learning algorithm. After the paths for all the source-target pairs are determined, routes will be checked for constraint violations and collisions. If any collisions or violations are found, route compaction is done using stalling and detouring. Experimental results show that our proposed droplet routing algorithm outperformed compared algorithms.",
        "DOI": "10.1109/VDAT50263.2020.9190306",
        "paper_author": "Rajesh K.",
        "affiliation_name": "National Institute of Technology Rourkela",
        "affiliation_city": "Rourkela",
        "affiliation_country": "India",
        "affiliation_id": "60000934",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Classifier with Deep Deviation Detection in PoE-IoT Devices",
        "publication": "Proceedings of CONECCT 2020 - 6th IEEE International Conference on Electronics, Computing and Communication Technologies",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "With the rapid growth in diversity of PoE-IoT devices and concept of \"Edge intelligence\", PoE-IoT security and behavior analysis is the major concern. These PoE-IoT devices lack visibility when the entire network infrastructure is taken into account. The IoT devices are prone to have design faults in their security capabilities. The entire network may be put to risk by attacks on vulnerable IoT devices or malware might get introduced into IoT devices even by routine operations such as firmware upgrade. There have been various approaches based on machine learning(ML) to classify PoE-IoT devices based on network traffic characteristics such as Deep Packet Inspection(DPI). In this paper, we propose a novel method for PoE-IoT classification where ML algorithm, Decision Tree is used. In addition to classification, this method provides useful insights to the network deployment, based on the deviations detected. These insights can further be used for shaping policies, troubleshooting and behavior analysis of PoE-IoT devices.",
        "DOI": "10.1109/CONECCT50063.2020.9198605",
        "paper_author": "Bhat P.",
        "affiliation_name": "Hewlett Packard Enterprise",
        "affiliation_city": "Palo Alto",
        "affiliation_country": "United States",
        "affiliation_id": "60107956",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Freeware Solution for Preventing Data Leakage by Insider for Windows Framework",
        "publication": "2020 International Conference on Computational Performance Evaluation, ComPE 2020",
        "citied_by": "7",
        "cover_date": "2020-07-01",
        "Abstract": "Every organisation has some crucial data that holds the reason for its competitive advantage over others. This data includes intellectual property, trade secrets, salary details etc. Non-ethical disclosure of such data can have fatal impacts. Recent incidents of data leaks cannot be overlooked, therefore every organisation should preferably use Data Loss Prevention(DLP) system to avoid the risk of data leakage. The aim of this work is to develop a freeware DLP that will help small and medium scale organizations to protect their covert data. There are numerous channels of data exfiltration such as Bluetooth, E-mail, Universal Serial Bus(USB) etc. The USB channel being portable and fast to use, it is favoured for data transfer. This DLP system is developed to work on windows framework. It targets to block transfer of confidential files through a USB port, according to the policies set by an administrator. This solution uses emerging technologies and integrates kernel space modules and machine learning approach to deliver a novel solution. It intercepts file transfer actions through a USB port and checks the contents of the file. In case, contents of the file are found to be confidential, the copy action will be blocked. This solution is implemented in a way that makes it effective and simplistic to use. It will definitely help the organizations to protect their data. There is a plethora of research going on in this area to secure sensitive information from being leaked. Incorporating Machine learning to accurately detect leaks is a new challenge in this field.",
        "DOI": "10.1109/ComPE49325.2020.9200160",
        "paper_author": "Thombre S.",
        "affiliation_name": "MKSSS’s Cummins College of Engineering for Women",
        "affiliation_city": "Pune",
        "affiliation_country": "India",
        "affiliation_id": "60108738",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Identifying artificially drained pasture soils using machine learning and Earth observation imagery",
        "publication": "Journal of Applied Remote Sensing",
        "citied_by": "5",
        "cover_date": "2020-07-01",
        "Abstract": "In many areas of the globe, the installation of artificial drains on naturally poorly drained soils is a necessary part of farm management. Identifying the location of artificially drained areas is an important step in achieving environmentally sustainable agricultural production. However, in many regions, data on the presence or the distribution of artificial drainage systems are rare. We outline an approach to identify artificially drained soils using Earth observation (EO) satellite imagery and digital elevation data. The method exploits the contrasting phenology of grass during a peak growth stage to identify artificially drained and undrained soils. Two machine-learning techniques, support vector machine and random forest, were tested. Classification accuracy up to 91% was achieved using photointerpreted accuracy points using higher resolution satellite imagery. Additional investigations would be required to establish whether the drained conditions identified were a result of artificial drainage or from naturally well-drained soils occurring within larger soil units. Herein, the Republic of Ireland is used as a test case. Based on our findings, the area of artificially drained grassland within the study area could be revised upward, with 44% (or 1/4345, 000 ha) of pasture currently classed as \"poorly drained\"identified as \"artificially drained.\"At one location, a change in the modeled drainage condition at field level was demonstrated following drain installation. The presented method demonstrates the ability of EO satellites to quickly and accurately map field drainage status at farm management scales over a wide area. This has the potential to improve management decisions at local scales, but also has implications in terms of national policy development and regulation in areas such as water quality and climate change mitigation.",
        "DOI": "10.1117/1.JRS.14.034508",
        "paper_author": "O'Hara R.",
        "affiliation_name": "Ashtown Food Research Centre",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland",
        "affiliation_id": "60006903",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Can we improve information freshness with predictions in mobile crowd-learning?",
        "publication": "IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2020",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "The rapid growth of mobile devices has spurred the development of crowd-learning applications, which rely on users to collect, report and share real-time information. A critical factor of crowd-learning is information freshness, which can be measured by a metric called age-of-information (AoI). Moreover, recent advances in machine learning and abundance of historical data have enabled crowd-learning service providers to make precise predictions on user arrivals, data trends and other predictable information. These developments lead to a fundamental question: Can we improve information freshness with predictions in mobile crowd-learning? In this paper, we show that the answer is affirmative. Specifically, motivated by the age-optimal Round-Robin policy, we propose the so-called 'periodic equal spreading' (PES) policy. Under the PES policy, we first reveal a counter-intuitive insight that the frequency of prediction should not be too often in terms of AoI improvement. Further, we analyze the AoI performances of the proposed PES policy and derive upper bounds for the average age under i.i.d. and Markovian arrivals, respectively. In order to evaluate the AoI performance gain of the PES policy, we also derive two closed form expressions for the average age under uncontrolled i.i.d. and Markovian arrivals, which could be of independent interest. Our results in this paper serve as a first building block towards understanding the role of predictions in mobile crowd-learning.",
        "DOI": "10.1109/INFOCOMWKSHPS50562.2020.9162913",
        "paper_author": "Yuan Z.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Ames",
        "affiliation_country": "United States",
        "affiliation_id": "60145790",
        "affiliation_state": "IA"
    },
    {
        "paper_title": "A Trial for Detection of Change in AS Operation Policies by Use of Machine Learning",
        "publication": "ITC-CSCC 2020 - 35th International Technical Conference on Circuits/Systems, Computers and Communications",
        "citied_by": "0",
        "cover_date": "2020-07-01",
        "Abstract": "The full route obtained by Border Gateway Protocol operation does not only indicate routes to all Internet hosts, but also has global information of the Internet structure. These are stored as information about AS operation policy in a condensed form in various attributes that the origin ISP or transit ISP gives to the prefix. This information is included statistically as well as analytically. Our preliminary research has shown that the network topology can be reproduced from the learning data on full root information obtained by a small-scale network model. Now, for the 100AS model created according to the Internet model configured using CAIDA data to collect and analyze the actual full route, the policy of AS including the topology can be restored. We also discuss whether such information can be reproduced by analyzing actual Internet data.",
        "DOI": "NA",
        "paper_author": "Ishida A.",
        "affiliation_name": "Gifu University",
        "affiliation_city": "Gifu",
        "affiliation_country": "Japan",
        "affiliation_id": "60018429",
        "affiliation_state": "Gifu"
    },
    {
        "paper_title": "Derivation of Optimal Parameters According to Path Curvature by Policy Gradient Reinforcement Learning",
        "publication": "ITC-CSCC 2020 - 35th International Technical Conference on Circuits/Systems, Computers and Communications",
        "citied_by": "0",
        "cover_date": "2020-07-01",
        "Abstract": "Machine learning technology has become important in many fields. In robotics, for example, the robot learns the parameters autonomously according to the environment and runs. In the case of a robot that moves autonomously on wheels, the travel path and parameters such as speed and amount of turning must be adjusted. In this paper, we propose to find parameters that allow fast and smooth running along each path and switch between them according to the curvature. To find the optimal running parameters, we define the running state of the robot and propose a learning method that applies policy gradient reinforcement learning. We implement and verify the effectiveness of the proposed method on a real robot.",
        "DOI": "NA",
        "paper_author": "Nakashima K.",
        "affiliation_name": "Kyushu Sangyo University",
        "affiliation_city": "Fukuoka",
        "affiliation_country": "Japan",
        "affiliation_id": "60023307",
        "affiliation_state": "Fukuoka"
    },
    {
        "paper_title": "Inter-center cross-validation and finetuning without patient data sharing for predicting transcatheter aortic valve implantation outcome",
        "publication": "Proceedings - IEEE Symposium on Computer-Based Medical Systems",
        "citied_by": "2",
        "cover_date": "2020-07-01",
        "Abstract": "Transcatheter aortic valve implantation (TAVI) is the routine treatment worldwide for aortic valve stenosis in low-to high-risk patients. Assessing patient risk is essential to identify the most suitable candidates that could benefit from the procedure. Despite the broad use of statistical predictors in patient selection, current machine learning predictors have only been validated on retrospective data collected in single centers. Further, external validation is needed to assess the improvement in accuracy, which is offered by machine learning and deep learning techniques. In this study, we propose a finetuning approach for deep learning models by performing an inter-center cross-validation and finetuning technique, in order to improve the cross-validation accuracy results. We aimed to overcome data exchange and policy-related issues of two medical centers with a dedicated protocol, exploiting the exchange of deep learning models, data processing and validation steps which does not require any patient data sharing. The finetuning is based on the other center's data for further training of the initial model. After finetuning the model, we obtain an average AUC improvement of 13% and 7% with respect to the initial models. This research demonstrates that the predicting capabilities of deep learning models can be extended to and cross-validated with other centers, independent of limitations in data-sharing policies. Moreover, the study shows that finetuning can be exploited to considerably improve the accuracy of the prediction models.",
        "DOI": "10.1109/CBMS49503.2020.00117",
        "paper_author": "Lopes R.R.",
        "affiliation_name": "Universiteit van Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60002483",
        "affiliation_state": "Noord-Holland"
    },
    {
        "paper_title": "Covariant Cluster Transfer for Kernel Reinforcement Learning in Brain-Machine Interface",
        "publication": "Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",
        "citied_by": "1",
        "cover_date": "2020-07-01",
        "Abstract": "Brain-Machine Interface (BMI) provides a promising way to help disabled people restore their motor functions. The patients are able to control the external devices directly from their neural signals by the decoder. Due to various reasons such as mental fatigue and distraction, the distribution of the neural signals might change, which might lead to poor performance for the decoder. In this case, we need to calibrate the parameters before each session, which needs the professionals to label the data and is not convenient for the patient's usage at home. In this paper, we propose a covariant cluster transfer mechanism for the kernel reinforcement learning (RL) algorithm to speed up the adaptation across sessions. The parameters of the decoder will adaptively change according to a reward signal, which could be easily set by the patient. More importantly, we cluster the neural patterns in previous sessions. The cluster represents the conditional distribution from neural patterns to actions. When a distinct neural pattern appears in the new session, the nearest cluster will be transferred. In this way, the knowledge from the old session could be utilized to accelerate the learning in the new session. Our proposed algorithm is tested on the simulated neural data where the neural signal's distribution differs across sessions. Compared with the training from random initialization and a weight transfer policy, our proposed cluster transfer mechanism maintains a significantly higher success rate and a faster adaptation when the conditional distribution from neural signals to actions remains similar.",
        "DOI": "10.1109/EMBC44109.2020.9175985",
        "paper_author": "Zhang X.",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008592",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Similarity Caching: Theory and Algorithms",
        "publication": "Proceedings - IEEE INFOCOM",
        "citied_by": "20",
        "cover_date": "2020-07-01",
        "Abstract": "This paper focuses on similarity caching systems, in which a user request for an object o that is not in the cache can be (partially) satisfied by a similar stored object o′, at the cost of a loss of user utility. Similarity caching systems can be effectively employed in several application areas, like multimedia retrieval, recommender systems, genome study, and machine learning training/serving. However, despite their relevance, the behavior of such systems is far from being well understood. In this paper, we provide a first comprehensive analysis of similarity caching in the offline, adversarial, and stochastic settings. We show that similarity caching raises significant new challenges, for which we propose the first dynamic policies with some optimality guarantees. We evaluate the performance of our schemes under both synthetic and real request traces.",
        "DOI": "10.1109/INFOCOM41043.2020.9155221",
        "paper_author": "Garetto M.",
        "affiliation_name": "Università degli Studi di Torino",
        "affiliation_city": "Turin",
        "affiliation_country": "Italy",
        "affiliation_id": "60012259",
        "affiliation_state": "TO"
    },
    {
        "paper_title": "Hybrid Gaussian Process Inference Model for Construction Management Decision Making",
        "publication": "International Journal of Information Technology and Decision Making",
        "citied_by": "4",
        "cover_date": "2020-07-01",
        "Abstract": "Construction decision-making often involves several indefinite factors, and wrong decisions usually lead to many losses and may even cause the construction to fail. Correct policy making is very important. Construction decision making used to depend on managerial staff' experience and subjective recognition, but this approach is likely to bring about wrong decisions because of an excessive number of factors involved or biased subjective recognition. To prevent such a situation, this study establishes a Hybrid Gaussian Process Inference Model (HGPIM), which uses a Gaussian process (GP) to sort out the mapping relationship between data input and output. It also uses Bayesian inference together with particle swarm optimization (PSO) to optimize the hyper-parameters of the covariance function in GP to obtain the best inference predictive ability. By predicting with the model and giving the events that need to be decided an expected value and a variance, we can establish the data's confidence interval as a reference for making decisions. This study collects data from three construction projects to conduct the experiment and uses HGPIM to train, predict and retest these cases to prove HGPIMs predictive ability. It also shows that the model can be applied to various cases and data and thus can be applied to construction engineering.",
        "DOI": "10.1142/S0219622020500212",
        "paper_author": "Cheng M.Y.",
        "affiliation_name": "National Taiwan University of Science and Technology",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60027709",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Dynamic Pricing and Placement for Distributed Machine Learning Jobs",
        "publication": "Proceedings - 2020 6th International Conference on Big Data Computing and Communications, BigCom 2020",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "Nowadays distributed machine learning (ML) jobs usually adopt a parameter server (PS) framework to train models over large-scale datasets. Such ML job deploys hundreds of concurrent workers, and model parameter updates are exchanged frequently between workers and PSs. Current practice is that workers and PSs may be placed on different physical servers, bringing uncertainty in jobs' runtime. Also, existing cloud pricing policy often charges a fixed price according to the job's runtime. Although this pricing strategy is simple to implement, such pricing mechanism is not suitable for distributed ML jobs whose runtime is stochastic and can only be estimated according to its placement after job admission. To supplement existing cloud pricing schemes, we design a dynamic pricing and placement algorithm, DPS, for distributed ML jobs. DPS aims to maximize cloud provider's profit, which dynamically calculates unit resource price upon a job's arrival, and determines job's placement to minimize its runtime if offered price is accepted to users. Our design exploits the multi-armed bandit (MAB) technique to learn unknown information based on past sales. DPS balances the exploration and exploitation stage, and selects the best price based on the reward which is related to job runtime. Our learning-based algorithm increases the provider's profit, and achieves a sub-linear regret with both the time horizon and the total job number, compared to benchmark pricing schemes. Extensive evaluations also validates the efficacy of DPS.",
        "DOI": "10.1109/BigCom51056.2020.00029",
        "paper_author": "Zhang X.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60029306",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "A deep learning approach to urban street functionality prediction based on centrality measures and stacked denoising autoencoder",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "5",
        "cover_date": "2020-07-01",
        "Abstract": "In urban planning and transportation management, the centrality characteristics of urban streets are vital measures to consider. Centrality can help in understanding the structural properties of dense traffic networks that affect both human life and activity in cities. Many cities classify urban streets to provide stakeholders with a group of street guidelines for possible new rehabilitation such as sidewalks, curbs, and setbacks. Transportation research always considers street networks as a connection between different urban areas. The street functionality classification defines the role of each element of the urban street network (USN). Some potential factors such as land use mix, accessible service, design goal, and administrators' policies can affect the movement pattern of urban travelers. In this study, nine centrality measures are used to classify the urban roads in four cities evaluating the structural importance of street segments. In our work, a Stacked Denoising Autoencoder (SDAE) predicts a street's functionality, then logistic regression is used as a classifier. Our proposed classifier can differentiate between four different classes adopted from the U.S. Department of Transportation (USDT): principal arterial road, minor arterial road, collector road, and local road. The SDAE-based model showed that regular grid configurations with repeated patterns are more influential in forming the functionality of road networks compared to those with less regularity in their spatial structure.",
        "DOI": "10.3390/ijgi9070456",
        "paper_author": "Noori F.",
        "affiliation_name": "Shahid Rajaee Teacher Training University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60001784",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Continuous shared control in prosthetic hand grasp tasks by Deep Deterministic Policy Gradient with Hindsight Experience Replay",
        "publication": "International Journal of Advanced Robotic Systems",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "Grasp using a prosthetic hand in real life can be a difficult task. The amputee users are often capable of planning the reaching trajectory and hand grasp location selection, however, failed in precise finger movements, such as adapting the fingers to the surface of the object without excessive force. It is much efficient to leave that part to the machine autonomy. In order to combine the intention and planning ability of users with robotic control, the shared control is introduced in which users’ inputs and robot control methods are combined to achieve a goal. The shared control problem can be formulated as a Partially Observable Markov Decision Process. To find the optimal control policy, we adopt an adaptive dynamic programming and reinforcement learning-based control algorithm-Deep Deterministic Policy Gradient combined with Hindsight Experience Replay. We proposed the algorithm with a prediction layer using the reparameterization technique. The system was tested in a modified simulation environment for the ability to follow the user’s intention and keep the contact force in boundary for safety.",
        "DOI": "10.1177/1729881420936851",
        "paper_author": "Gao Z.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Simultaneously Evolving Deep Reinforcement Learning Models using Multifactorial optimization",
        "publication": "2020 IEEE Congress on Evolutionary Computation, CEC 2020 - Conference Proceedings",
        "citied_by": "11",
        "cover_date": "2020-07-01",
        "Abstract": "In recent years, Multifactorial optimization (MFO) has gained a notable momentum in the research community. MFO is known for its inherent capability to efficiently address multiple optimization tasks at the same time, while transferring information among such tasks to improve their convergence speed. On the other hand, the quantum leap made by Deep Q Learning (DQL) in the Machine Learning field has allowed facing Reinforcement Learning (RL) problems of unprecedented complexity. Unfortunately, complex DQL models usually find it difficult to converge to optimal policies due to the lack of exploration or sparse rewards. In order to overcome these drawbacks, pre-trained models are widely harnessed via Transfer Learning, extrapolating knowledge acquired in a source task to the target task. Besides, meta-heuristic optimization has been shown to reduce the lack of exploration of DQL models. This work proposes a MFO framework capable of simultaneously evolving several DQL models towards solving interrelated RL tasks. Specifically, our proposed framework blends together the benefits of meta-heuristic optimization, Transfer Learning and DQL to automate the process of knowledge transfer and policy learning of distributed RL agents. A thorough experimentation is presented and discussed so as to assess the performance of the framework, its comparison to the traditional methodology for Transfer Learning in terms of convergence, speed and policy quality, and the intertask relationships found and exploited over the search process.",
        "DOI": "10.1109/CEC48606.2020.9185667",
        "paper_author": "Martinez A.D.",
        "affiliation_name": "Basque Research and Technology Alliance (BRTA)",
        "affiliation_city": "Mendaro",
        "affiliation_country": "Spain",
        "affiliation_id": "60122752",
        "affiliation_state": "Guipuzcoa"
    },
    {
        "paper_title": "Safe and Computational Efficient Imitation Learning for Autonomous Vehicle Driving",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "10",
        "cover_date": "2020-07-01",
        "Abstract": "Autonomous vehicle driving systems face the challenge of providing safe, feasible and human-like driving policy quickly and efficiently. The traditional approach usually involves a search or optimization-based planning followed by a model-based controller. This may prove to be inadequate in some driving scenarios due to disturbance, uncertainties and limited computation time. The more recent end-to-end approaches aim at overcoming these issues by learning a policy to map from sensor data to controls using machine learning techniques. Although being attractive for its simplicity, they also show some drawbacks such as sample inefficiency and difficulties in validation and interpretability. This work presents an approach that attempts to exploit both worlds, combining machine learning-based and model-based control into an imitation learning framework that mimic expert driving behavior while obtaining safe and smooth driving. The dataset is generated from high-fidelity simulations of vehicle dynamics and model predictive control (MPC). A smooth spline-based motion planning represents the policy provided by a constrained neural network exploiting the convex hull property of B-splines. The policy network is trained with few dataset aggregations coming from its induced distribution of states. The learned policy is used as guidance for model-based feedback control and tested on a 15DOF high fidelity vehicle model.",
        "DOI": "10.23919/ACC45564.2020.9147256",
        "paper_author": "Acerbo F.S.",
        "affiliation_name": "Siemens Digital Industries Software",
        "affiliation_city": "Plano",
        "affiliation_country": "United States",
        "affiliation_id": "60107481",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Learning to Control Neurons using Aggregated Measurements",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "5",
        "cover_date": "2020-07-01",
        "Abstract": "Controlling a population of neurons with one or a few control signals is challenging due to the severely underactuated nature of the control system and the inherent nonlinear dynamics of the neurons that are typically unknown. Control strategies that incorporate deep neural networks and machine learning techniques directly use data to learn a sequence of control actions for targeted manipulation of a population of neurons. However, these learning strategies inherently assume that perfect feedback data from each neuron at every sampling instant are available, and do not scale gracefully as the number of neurons in the population increases. As a result, the learning models need to be retrained whenever such a change occurs. In this work, we propose a learning strategy to design a control sequence by using population-level aggregated measurements and incorporate reinforcement learning techniques to find a (bounded, piecewise constant) control policy that fulfills the given control task. We demonstrate the feasibility of the proposed approach using numerical experiments on a finite population of nonlinear dynamical systems and canonical phase models that are widely used in neuroscience.",
        "DOI": "10.23919/ACC45564.2020.9147426",
        "paper_author": "Yu Y.C.",
        "affiliation_name": "McKelvey School of Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60105336",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Dynamic Economic Optimization of a Continuously Stirred Tank Reactor Using Reinforcement Learning",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "12",
        "cover_date": "2020-07-01",
        "Abstract": "Reinforcement learning (RL) algorithms are a set of goal-oriented machine learning algorithms that can perform control and optimization in a system. Most RL algorithms do not require any information about the underlying dynamics of the system, they only require input and output information. RL algorithms can therefore be applied to a wide range of systems. This paper explores the use of a custom environment to optimize a problem pertinent to process engineers. In this study the custom environment is a continuously stirred tank reactor (CSTR). The purpose of using a custom environment is to illustrate that any number of systems can readily become RL environments. Three RL algorithms are investigated: deep deterministic policy gradient (DDPG), twin-delayed DDPG (TD3), and proximal policy optimization. They are evaluated based on how they converge to a stable solution and how well they dynamically optimize the economics of the CSTR. All three algorithms perform 98% as well as a first principles model, coupled with a non-linear solver, but only TD3 demonstrates convergence to a stable solution. While itself limited in scope, this paper seeks to further open the door to a coupling between powerful RL algorithms and process systems engineering.",
        "DOI": "10.23919/ACC45564.2020.9147706",
        "paper_author": "MacHalek D.",
        "affiliation_name": "John and Marcia Price College of Engineering",
        "affiliation_city": "Salt Lake City",
        "affiliation_country": "United States",
        "affiliation_id": "60150772",
        "affiliation_state": "UT"
    },
    {
        "paper_title": "Learning to flock through reinforcement",
        "publication": "Physical Review E",
        "citied_by": "38",
        "cover_date": "2020-07-01",
        "Abstract": "Flocks of birds, schools of fish, and insect swarms are examples of the coordinated motion of a group that arises spontaneously from the action of many individuals. Here, we study flocking behavior from the viewpoint of multiagent reinforcement learning. In this setting, a learning agent tries to keep contact with the group using as sensory input the velocity of its neighbors. This goal is pursued by each learning individual by exerting a limited control on its own direction of motion. By means of standard reinforcement learning algorithms we show that (i) a learning agent exposed to a group of teachers, i.e., hard-wired flocking agents, learns to follow them, and (ii) in the absence of teachers, a group of independently learning agents evolves towards a state where each agent knows how to flock. In both scenarios, the emergent policy (or navigation strategy) corresponds to the polar velocity alignment mechanism of the well-known Vicsek model. These results (a) show that such a velocity alignment may have naturally evolved as an adaptive behavior that aims at minimizing the rate of neighbor loss, and (b) prove that this alignment does not only favor (local) polar order, but it corresponds to the best policy or strategy to keep group cohesion when the sensory input is limited to the velocity of neighboring agents. In short, to stay together, steer together.",
        "DOI": "10.1103/PhysRevE.102.012601",
        "paper_author": "Durve M.",
        "affiliation_name": "Università degli Studi di Trieste",
        "affiliation_city": "Trieste",
        "affiliation_country": "Italy",
        "affiliation_id": "60018363",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Optimal Control of Wheeled Mobile Robots: From Simulation to Real World",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "13",
        "cover_date": "2020-07-01",
        "Abstract": "We study the problem of taking simulations to the real world (RW) for autonomous robotic systems with dynamic uncertainties and unknown disturbances while maintaining the optimal performance and stability of the designed controller designed in simulation. In general, an optimal and robust controller that is designed through simulation often does not perform similarly when deployed in the RW. We focus on using simulations to generate an optimal control policy utilizing the Memetic algorithm (MA) iteratively. The simulation-to-RW performance and stability are realized by using an adaptive fuzzy system to learn the uncertain part of the dynamic model, disturbance and noises. We demonstrate experimentally that this method permits the development of optimal control design in simulations and integrates adaptive learning rules to enable precise and repetitive trajectory tracking for the wheeled mobile robot (WMR) with disturbances and uncertainties.",
        "DOI": "10.23919/ACC45564.2020.9147898",
        "paper_author": "Arab A.",
        "affiliation_name": "Department of Mechanical and Aerospace Engineering",
        "affiliation_city": "Piscataway",
        "affiliation_country": "United States",
        "affiliation_id": "60120628",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "How do media, political and regulatory agendas influence one another in high risk policy issues?",
        "publication": "Policy and Politics",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "This article shows how an emerging risk is covered by the media and how this interacts with political attention and policy implementation. Gas drilling has resulted in earthquakes in the Netherlands over the past 25 years. We show that an increase in the frequency and magnitude has not stimulated greater media attention. Media and political attention increased only after the media had interpreted the risk as a safety issue. Once this had happened, newspapers and political debates tended to focus on the emotionally loaded aspects. This is in contrast with the regulatory agenda, which followed its own course by focusing on factual information. By using a new method-supervised-machine learning-we analyse a large, longitudinal data set to explore patterns over time. Our findings shed new light on risk-and agenda-setting theory, confirming that media and politics agendas reinforce each other, but the regulatory agenda is not strongly influenced by them.",
        "DOI": "10.1332/030557319X15734252420020",
        "paper_author": "Opperhuizen A.E.",
        "affiliation_name": "Erasmus Universiteit Rotterdam",
        "affiliation_city": "Rotterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60022265",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Towards declarative self-adapting buffer management",
        "publication": "Computer Communication Review",
        "citied_by": "5",
        "cover_date": "2020-07-01",
        "Abstract": "Buffering architectures and policies for their efficient management are one of the core ingredients of network architecture. However, despite strong incentives to experiment with and deploy new policies, opportunities for changing or automatically choosing anything beyond a few parameters in a predefined set of behaviors still remain very limited. We introduce a novel buffer management framework based on machine learning approaches which automatically adapts to traffic conditions changing over time and requires only limited knowledge from network operators about the dynamics and optimality of desired behaviors. We validate and compare various design options with a comprehensive evaluation study.",
        "DOI": "10.1145/3411740.3411745",
        "paper_author": "Chuprikov P.",
        "affiliation_name": "Università della Svizzera italiana",
        "affiliation_city": "Lugano",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60006824",
        "affiliation_state": "TI"
    },
    {
        "paper_title": "EvolveDTree: Analyzing Student Dropout in Universities",
        "publication": "International Conference on Systems, Signals, and Image Processing",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "Brazilian society suffers constant financial losses when higher education students disassociate from universities without completing the degree program in which they were enrolled. This is especially true when the institutions are funded through public resources. In order to minimize evasion losses, socioeconomic policies and programs were created to assist and support actions seeking to maximize the number of students that graduate in a suitable program time. This work presents a methodology that aims to predict evasion by using machine learning. Our approach was able to classify student abandonment with an average f-score and accuracy results above 95%. Our approach combines a decision tree alongside a genetic algorithm and cluster stratified sampling. The results obtained show that students with a Grade Point Average (GPA) below 5.79 and that have been enrolled for more than a year require careful monitoring because they tend to exceed the program duration time or abandon it. Furthermore, approximately one-third of all identified dropouts students occurred in the first year.",
        "DOI": "10.1109/IWSSIP48289.2020.9145203",
        "paper_author": "Santos G.A.S.",
        "affiliation_name": "Centro Federal De Educacão Tecnológica Celso Suckow Da Fonseca",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil",
        "affiliation_id": "60042765",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Artificial intelligence in health care: Bibliometric analysis",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "254",
        "cover_date": "2020-07-01",
        "Abstract": "Background: As a critical driving power to promote health care, the health care-related artificial intelligence (AI) literature is growing rapidly. Objective: The purpose of this analysis is to provide a dynamic and longitudinal bibliometric analysis of health care-related AI publications. Methods: The Web of Science (Clarivate PLC) was searched to retrieve all existing and highly cited AI-related health care research papers published in English up to December 2019. Based on bibliometric indicators, a search strategy was developed to screen the title for eligibility, using the abstract and full text where needed. The growth rate of publications, characteristics of research activities, publication patterns, and research hotspot tendencies were computed using the HistCite software. Results: The search identified 5235 hits, of which 1473 publications were included in the analyses. Publication output increased an average of 17.02% per year since 1995, but the growth rate of research papers significantly increased to 45.15% from 2014 to 2019. The major health problems studied in AI research are cancer, depression, Alzheimer disease, heart failure, and diabetes. Artificial neural networks, support vector machines, and convolutional neural networks have the highest impact on health care. Nucleosides, convolutional neural networks, and tumor markers have remained research hotspots through 2019. Conclusions: This analysis provides a comprehensive overview of the AI-related research conducted in the field of health care, which helps researchers, policy makers, and practitioners better understand the development of health care-related AI research and possible practice implications. Future AI research should be dedicated to filling in the gaps between AI health care research and clinical applications.",
        "DOI": "10.2196/18228",
        "paper_author": "Guo Y.",
        "affiliation_name": "The University of North Carolina at Charlotte",
        "affiliation_city": "Charlotte",
        "affiliation_country": "United States",
        "affiliation_id": "60006951",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Sentinel-2 data for land cover/use mapping: A review",
        "publication": "Remote Sensing",
        "citied_by": "485",
        "cover_date": "2020-07-01",
        "Abstract": "The advancement in satellite remote sensing technology has revolutionised the approaches to monitoring the Earth's surface. The development of the Copernicus Programme by the European Space Agency (ESA) and the European Union (EU) has contributed to the effective monitoring of the Earth's surface by producing the Sentinel-2 multispectral products. Sentinel-2 satellites are the second constellation of the ESA Sentinel missions and carry onboard multispectral scanners. The primary objective of the Sentinel-2mission is to provide high resolution satellite data for land cover/usemonitoring, climate change and disaster monitoring, as well as complementing the other satellite missions such as Landsat. Since the launch of Sentinel-2 multispectral instruments in 2015, there have been many studies on land cover/use classification which use Sentinel-2 images. However, no review studies have been dedicated to the application of ESA Sentinel-2 land cover/use monitoring. Therefore, this review focuses on two aspects: (1) assessing the contribution of ESA Sentinel-2 to land cover/use classification, and (2) exploring the performance of Sentinel-2 data in different applications (e.g., forest, urban area and natural hazard monitoring). The present review shows that Sentinel-2 has a positive impact on land cover/use monitoring, specifically in monitoring of crop, forests, urban areas, and water resources. The contemporary high adoption and application of Sentinel-2 can be attributed to the higher spatial resolution (10 m) than other medium spatial resolution images, the high temporal resolution of 5 days and the availability of the red-edge bands with multiple applications. The ability to integrate Sentinel-2 data with other remotely sensed data, as part of data analysis, improves the overall accuracy (OA) when working with Sentinel-2 images. The free access policy drives the increasing use of Sentinel-2 data, especially in developing countries where financial resources for the acquisition of remotely sensed data are limited. The literature also shows that the use of Sentinel-2 data produces high accuracies (>80%) with machine-learning classifiers such as support vector machine (SVM) and Random forest (RF). However, other classifiers such as maximum likelihood analysis are also common. Although Sentinel-2 offers many opportunities for land cover/use classification, there are challenges which include mismatching with Landsat OLI-8 data, a lack of thermal bands, and the differences in spatial resolution among the bands of Sentinel-2. Sentinel-2 data show promise and have the potential to contribute significantly towards land cover/use monitoring.",
        "DOI": "10.3390/rs12142291",
        "paper_author": "Phiri D.",
        "affiliation_name": "Copperbelt University",
        "affiliation_city": "Kitwe",
        "affiliation_country": "Zambia",
        "affiliation_id": "60072810",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Dr. Agent: Clinical predictive model via mimicked second opinions",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "12",
        "cover_date": "2020-07-01",
        "Abstract": "Objective: Prediction of disease phenotypes and their outcomes is a difficult task. In practice, patients routinely seek second opinions from multiple clinical experts for complex disease diagnosis. Our objective is to mimic such a practice of seeking second opinions by training 2 agents with different focuses: the primary agent studies the most recent visit of the patient to learn the current health status, and then the second-opinion agent considers the entire patient history to obtain a more global view. Materials and Methods: Our approach Dr. Agent augments recurrent neural networks with 2 policy gradient agents. Moreover, Dr. Agent is customized with various patient demographics information and learns a dynamic skip connection to focus on the relevant information over time. We trained Dr. Agent to perform 4 clinical prediction tasks on the publicly available MIMIC-III (Medical Information Mart for Intensive Care) database: (1) in-hospital mortality prediction, (2) acute care phenotype classification, (3) physiologic decompensation prediction, and (4) forecasting length of stay. We compared the performance of Dr. Agent against 4 baseline clinical predictive models. Results: Dr. Agent outperforms baseline clinical prediction models across all 4 tasks in terms of all metrics. Compared with the best baseline model, Dr. Agent achieves up to 15% higher area under the precision-recall curve on different tasks. Conclusions: Dr. Agent can comprehensively model the long-term dependencies of patients' health status while considering patients' demographics using 2 agents, and therefore achieves better prediction performance on different clinical prediction tasks.",
        "DOI": "10.1093/jamia/ocaa074",
        "paper_author": "Gao J.",
        "affiliation_name": "IQVIA Inc.",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60112142",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Near-optimal insulin treatment for diabetes patients: A machine learning approach",
        "publication": "Artificial Intelligence in Medicine",
        "citied_by": "19",
        "cover_date": "2020-07-01",
        "Abstract": "Blood glycemic control is crucial for minimizing severe side effects in diabetes mellitus. Currently, two opposing treatment approaches exist: in formulaic methods, insulin care is calculated by parameter-based computation (i.e., correction factor, insulin-to-carb ratio, and absorption duration), which are fixed by the medical team based on the history of a tested patient blood glucose levels (BGLs). Alternatively, closed-loop methods test glycemic level via sensors and provide insulin boluses based on sensor data thus ignoring other medical information. Unlike the body, both these systems are reactive – chasing insulin dosage based on fluctuating BGL – resulting in significant fluctuations of glucose values, rather than the relatively flat profile normal to the body's glycemic control. Extended periods of these fluctuations – particularly high BGLs (hyperglycemia) result in vascular and organ epithelial damage, which increases comorbidities and is ultimately life-threatening. We propose an individualized treatment scheme based on machine learning artificial intelligence, which combines the best of both approaches and is tailored to the individual. We model patient reaction to insulin treatment as Markov decision process (MDP) thus allowing the system to find a unique, individualized and dynamically updating insulin care policy that would lead to flat blood glucose profiles in target areas. We incorporate an individualized “health reward function”, preferably from the medical team, describing a grading scheme of BGL tailored to the patient for even more precise glycemic control. The solution to MDP is found via reinforcement learning, which yields an individualized, optimal insulin care policy. This policy can prevent hypoglycemia, minimize high glucose duration and glycemic fluctuations. It can be further updated as the patient undergoes environmental changes. Significantly, our method provides the care team a constantly updated patient model, allowing them to better understand and support the patient.",
        "DOI": "10.1016/j.artmed.2020.101917",
        "paper_author": "Shifrin M.",
        "affiliation_name": "University of Massachusetts Amherst",
        "affiliation_city": "Amherst",
        "affiliation_country": "United States",
        "affiliation_id": "60014313",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Deep Reinforcement Learning for Sequence-to-Sequence Models",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "142",
        "cover_date": "2020-07-01",
        "Abstract": "In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder-decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training time.",
        "DOI": "10.1109/TNNLS.2019.2929141",
        "paper_author": "Keneshloo Y.",
        "affiliation_name": "Virginia Tech College of Engineering",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States",
        "affiliation_id": "60157272",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Susceptibility mapping of soil water erosion using machine learning models",
        "publication": "Water (Switzerland)",
        "citied_by": "117",
        "cover_date": "2020-07-01",
        "Abstract": "Soil erosion is a serious threat to sustainable agriculture, food production, and environmental security. The advancement of accurate models for soil erosion susceptibility and hazard assessment is of utmost importance for enhancing mitigation policies and laws. This paper proposes novel machine learning (ML) models for the susceptibility mapping of the water erosion of soil. The weighted subspace random forest (WSRF), Gaussian process with a radial basis function kernel (Gaussprradial), and naive Bayes (NB) ML methods were used in the prediction of the soil erosion susceptibility. Data included 227 samples of erosion and non-erosion locations through field surveys to advance models of the spatial distribution using predictive factors. In this study, 19 effective factors of soil erosion were considered. The critical factors were selected using simulated annealing feature selection (SAFS). The critical factors included aspect, curvature, slope length, flow accumulation, rainfall erosivity factor, distance from the stream, drainage density, fault density, normalized difference vegetation index (NDVI), hydrologic soil group, soil texture, and lithology. The dataset cells of samples (70% for training and 30% for testing) were randomly prepared to assess the robustness of the different models. The functional relevance between soil erosion and effective factors was computed using the ML models. The ML models were evaluated using different metrics, including accuracy, the kappa coefficient, and the probability of detection (POD). The accuracies of the WSRF, Gaussprradial, and NB methods were 0.91, 0.88, and 0.85, respectively, for the testing data; 0.82, 0.76, and 0.71, respectively, for the kappa coefficient; and 0.94, 0.94, and 0.94, respectively, for POD. However, the ML models, especially the WSRF, had an acceptable performance regarding producing soil erosion susceptibility maps. Maps produced with the most robust models can be a useful tool for sustainable management, watershed conservation, and the reduction of soil and water loss.",
        "DOI": "10.3390/w12071995",
        "paper_author": "Mosavi A.",
        "affiliation_name": "Ton-Duc-Thang University",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60078563",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Does good ESG lead to better financial performances by firms? Machine learning and logistic regression models of public enterprises in Europe",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "119",
        "cover_date": "2020-07-01",
        "Abstract": "The increasing awareness of climate change and human capital issues is shifting companies towards aspects other than traditional financial earnings. In particular, the changing behaviors towards sustainability issues of the global community and the availability of environmental, social and governance (ESG) indicators are attracting investors to socially responsible investment decisions. Furthermore, whereas the strategic importance of ESG metrics has been particularly studied for private enterprises, little attention have received public companies. To address this gap, the present work has three aims-1. To predict the accuracy of main financial indicators such as the expected Return of Equity (ROE) and Return of Assets (ROA) of public enterprises in Europe based on ESG indicators and other economic metrics; 2. To identify whether ESG initiatives affect the financial performance of public European enterprises; and 3. To discuss how ESG factors, based on the findings of aims #1 and #2, can contribute to the advancements of the current debate on Corporate Social Responsibility (CSR) policies and practices in public enterprises in Europe. To fulfil the above aims, we use a combined approach of machine learning (ML) techniques and inferential (i.e., ordered logistic regression) model. The former predicts the accuracy of ROE and ROA on several ESG and other economic metrics and fulfils aim #1. The latter is used to test whether any causal relationships between ESG investment decisions and ROA and ROE exist and, whether these relationships exist, to assess their magnitude. The inferential analysis fulfils aim #2. Main findings suggest that ML accurately predicts ROA and ROE and indicate, through the ordered logistic regression model, the existence of a positive relationship between ESG practices and the financial indicators. In addition, the existing relationship appears more evident when companies invest in environmental innovation, employment productivity and diversity and equal opportunity policies. As a result, to fulfil aim #3 useful policy insights are advised on these issues to strengthen CSR strategies and sustainable development practices in European public enterprises.",
        "DOI": "10.3390/su12135317",
        "paper_author": "De Lucia C.",
        "affiliation_name": "Università degli Studi di Foggia",
        "affiliation_city": "Foggia",
        "affiliation_country": "Italy",
        "affiliation_id": "60022956",
        "affiliation_state": "FG"
    },
    {
        "paper_title": "Reinforcement learning for combined production-maintenance and quality control of a manufacturing system with deterioration failures",
        "publication": "Journal of Manufacturing Systems",
        "citied_by": "82",
        "cover_date": "2020-07-01",
        "Abstract": "This paper describes and examines thoroughly a stochastic production/inventory system that produces a single type of products. During the production process, the system is affected by several deterioration failures. It is restored to its initial and previous deterioration state by repair and maintenance activities. Both maintenance and repair duration are assumed as exponential random variables. Moreover, the quality of the manufactured products is assumed to be affected by the current deterioration level of the system. The aim of this paper is to find the optimal trade-off between conflicting performance metrics for the optimization of the total expected profit of the system. To tackle such optimization problems, researchers frequently employ Dynamic Programming. This method, though, is not appropriate for the addressed problem due to complexity reasons. To this end, a Reinforcement Learning-based approach is proposed in order to obtain the optimal joint production, maintenance and product quality control policies. To the authors’ knowledge, the proposed approach is novel and there are few examples of such implementation in the academic literature.",
        "DOI": "10.1016/j.jmsy.2020.07.004",
        "paper_author": "Paraschos P.D.",
        "affiliation_name": "Democritus University of Thrace",
        "affiliation_city": "Komotini",
        "affiliation_country": "Greece",
        "affiliation_id": "60030988",
        "affiliation_state": "Eastern Macedonia and Thrace"
    },
    {
        "paper_title": "A Reinforcement Learning Approach to Robust Scheduling of Semiconductor Manufacturing Facilities",
        "publication": "IEEE Transactions on Automation Science and Engineering",
        "citied_by": "150",
        "cover_date": "2020-07-01",
        "Abstract": "As semiconductor manufacturers, recently, have focused on producing multichip products (MCPs), scheduling semiconductor manufacturing operations become complicated due to the constraints related to reentrant production flows, sequence-dependent setups, and alternative machines. At the same time, the scheduling problems need to be solved frequently to effectively manage the variabilities in production requirements, available machines, and initial setup status. To minimize the makespan for an MCP scheduling problem, we propose a setup change scheduling method using reinforcement learning (RL) in which each agent determines setup decisions in a decentralized manner and learns a centralized policy by sharing a neural network among the agents to deal with the changes in the number of machines. Furthermore, novel definitions of state, action, and reward are proposed to address the variabilities in production requirements and initial setup status. Numerical experiments demonstrate that the proposed approach outperforms the rule-based, metaheuristic, and other RL methods in terms of the makespan while incurring shorter computation time than the metaheuristics considered. Note to Practitioners-This article studies a scheduling problem for die attach and wire bonding stages of a semiconductor packaging line. Due to the variabilities in production requirements, the number of available machines, and initial setup status, it is challenging for a scheduler to produce high-quality schedules within a specific time limit using existing approaches. In this article, a new scheduling method using reinforcement learning is proposed to enhance the robustness against the variabilities while achieving performance improvements. To verify the robustness of the proposed method, neural networks (NNs) trained on small-scale scheduling problems are used to solve large-scale scheduling problems. Experimental results show that the proposed method outperforms the existing approaches while requiring a short computation time. Furthermore, the trained NN performs well in solving unseen real-world scale problems even under stochastic processing time, suggesting the viability of the proposed method for real-world semiconductor packaging lines.",
        "DOI": "10.1109/TASE.2019.2956762",
        "paper_author": "Park I.B.",
        "affiliation_name": "Seoul National University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60013682",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Digital advertising to children",
        "publication": "Pediatrics",
        "citied_by": "97",
        "cover_date": "2020-07-01",
        "Abstract": "Advertising to children and teenagers is a multibillion-dollar industry. This policy statement reviews the forms of advertising that children and teenagers encounter, including newer forms of digital marketing, such as sponsored content, influencers, data collection, persuasive design, and personalized behavioral marketing driven by machine learning. Parents and pediatric health care providers need to be aware of the ways different marketing messages reach children and teenagers, including Internet sites, social media, and mobile apps. Evidence suggests that exposure to advertising is associated with unhealthy behaviors, such as intake of high-calorie, low-nutrient food and beverages; use of tobacco products and electronic cigarettes; use of alcohol and marijuana; and indoor tanning. Children are uniquely vulnerable to the persuasive effects of advertising because of immature critical thinking skills and impulse inhibition. School-aged children and teenagers may be able to recognize advertising but often are not able to resist it when it is embedded within trusted social networks, encouraged by celebrity influencers, or delivered next to personalized content. This policy statement expresses concern about the practice of tracking and using children's digital behavior to inform targeted marketing campaigns, which may contribute to health disparities among vulnerable children or populations. Pediatricians should guide parents and children to develop digital literacy skills to prevent or mitigate negative outcomes, but it is equally important that policy makers and technology companies embrace digital design, data collection, and marketing practices within today's broad digital environment that support healthier decision-making and outcomes.",
        "DOI": "10.1542/peds.2020-1681",
        "paper_author": "Radesky J.",
        "affiliation_name": "University of Michigan Medical School",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60033182",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Forecasting network throughput of remote data access in computing grids",
        "publication": "Journal of Computational Science",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "Computing grids are key enablers of computational science. Researchers from many fields (High Energy Physics, Bioinformatics, Climatology, etc.) employ grids for execution of distributed computational jobs. These computing workloads are typically data-intensive. The current state of the art approach for data access in grids is data placement: a job is scheduled to run at a specific data center, and its execution commences only once the complete input data has been transferred there. An alternative approach is remote data access: a job may stream the input data directly from arbitrary storage elements. Remote data access brings two innovative benefits: (1) the jobs can be executed asynchronously with respect to the data transfer; (2) when combined with data placement on the policy level, it can aid in the optimization of the network load, since these two data access methodologies partially exhibit nonoverlapping bottlenecks. However, in order to employ this technique systematically, the properties of its network throughput need to be studied carefully. This paper presents experimentally identified parameters of remote data access throughput, statistically tested formalization of these parameters and a derived throughput forecasting model. The model is applicable to large computing workloads, robust with respect to arbitrary dynamic changes in the grid infrastructure and exhibits a long-term prediction horizon. Its purpose is to assist various stakeholders of the grid in decision-making related to data access patterns. This work is based on measurements taken on the Worldwide LHC Computing Grid at CERN.",
        "DOI": "10.1016/j.jocs.2020.101158",
        "paper_author": "Begy V.",
        "affiliation_name": "Organisation Européenne pour la Recherche Nucléaire",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60019778",
        "affiliation_state": "GE"
    },
    {
        "paper_title": "Four-dimensional trajectory generation for uavs based on multi-agent Q learning",
        "publication": "Journal of Navigation",
        "citied_by": "12",
        "cover_date": "2020-07-01",
        "Abstract": "A distributed four-dimensional (4D) trajectory generation method based on multi-agent Q learning is presented for multiple unmanned aerial vehicles (UAVs). Based on this method, each vehicle can intelligently generate collision-free 4D trajectories for time-constrained cooperative flight tasks. For a single UAV, the 4D trajectory is generated by the bionic improved tau gravity guidance strategy, which can synchronously guide the position and velocity to the desired values at the arrival time. Furthermore, to optimise trajectory parameters, the continuous state and action wire fitting neural network Q (WFNNQ) learning method is applied. For multi-UAV applications, the learning is organised by the win or learn fast-policy hill climbing (WoLF-PHC) algorithm. Dynamic simulation results show that the proposed method can efficiently provide 4D trajectories for the multi-UAV system in challenging simultaneous arrival tasks, and the fully trained method can be used in similar trajectory generation scenarios.",
        "DOI": "10.1017/S0373463320000016",
        "paper_author": "Zhao W.",
        "affiliation_name": "School of Aeronautics and Astronautics, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117832",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Did the ACA Medicaid expansion save lives?",
        "publication": "Journal of Health Economics",
        "citied_by": "48",
        "cover_date": "2020-07-01",
        "Abstract": "We estimate the effect of the Affordable Care Act Medicaid expansion on county-level mortality in the first four years following expansion using restricted-access microdata covering all deaths in the United States. To adjust for pre-expansion differences in mortality rates between treatment and control, we use a propensity-score weighting model together with techniques from machine learning to match counties in expansion and non-expansion states. We find a reduction in all-cause mortality in ages 20 to 64 equaling 11.36 deaths per 100,000 individuals, a 3.6 percent decrease. This estimate is largely driven by reductions in mortality in counties with higher pre-expansion uninsured rates and for causes of death likely to be influenced by access to healthcare. A cost-benefit analysis shows that the improvement in welfare due to mortality responses may offset the entire net-of-transfers expenditure associated with the expansion.",
        "DOI": "10.1016/j.jhealeco.2020.102333",
        "paper_author": "Borgschulte M.",
        "affiliation_name": "IZA",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "120182530",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Whose data is it anyway? Patient experience and service improvement",
        "publication": "Journal of Health Services Research and Policy",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "NA",
        "DOI": "10.1177/1355819620921423",
        "paper_author": "Robert G.",
        "affiliation_name": "King's College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60011520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Epidemiology and Socioeconomic Trends in Adult Spinal Deformity Care",
        "publication": "Neurosurgery",
        "citied_by": "77",
        "cover_date": "2020-07-01",
        "Abstract": "Adult spinal deformity (ASD) has gained significant attention over the past decade with improvements in diagnostic tools, classification schemes, and surgical technique. The demographics of the aging population in the United States are undergoing a fundamental shift as medical care advances and life expectancy increases. The \"baby boomers\" represent the fastest growing demographic in the United States and by 2050, the number of individuals 65 yr and older is projected to reach 89 million, more than double its current size. Based on current prevalence estimates there are approximately 27.5 million elderly individuals with some form of spinal deformity, which will place a significant burden on our health care systems. Rates of surgery for ASD and case complexity are both increasing, with concomitant increase in the cost of deformity care. At the same time, patients are more medically complex with increasing number of comorbidities that result in increased surgical risk and complication profiles. This review aims to highlight recent trends in the epidemiology and socioeconomic patterns in surgery for ASD.",
        "DOI": "10.1093/neuros/nyz454",
        "paper_author": "Safaee M.M.",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States",
        "affiliation_id": "60031970",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Smart cities and a data-driven response to COVID-19",
        "publication": "Dialogues in Human Geography",
        "citied_by": "55",
        "cover_date": "2020-07-01",
        "Abstract": "This commentary describes the rapid development of a COVID-19 data dashboard utilising existing Urban Observatory Internet of Things (IoT) data and analytics infrastructure. Existing data capture systems were rapidly repurposed to provide real-time insights into the impacts of lockdown policy on urban governance.",
        "DOI": "10.1177/2043820620934211",
        "paper_author": "James P.",
        "affiliation_name": "Newcastle University",
        "affiliation_city": "Newcastle",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60006222",
        "affiliation_state": "Tyne and Wear"
    },
    {
        "paper_title": "Nutrition in times of Covid-19, how to trust the deluge of scientific information",
        "publication": "Current Opinion in Clinical Nutrition and Metabolic Care",
        "citied_by": "10",
        "cover_date": "2020-07-01",
        "Abstract": "Purpose of reviewThe Covid-19 pandemic has daunted the world with its enormous impact on healthcare, economic recession, and psychological distress. Nutrition is an integral part of every person life care, and should also be mandatorily integrated to patient care under the Covid-19 pandemic. It is crucial to understand how the Covid-19 does develop and which risk factors are associated with negative outcomes and death. Therefore, it is of utmost importance to have studies that respect the basic tenets of the scientific method in order to be trusted. The goal of this review is to discuss the deluge of scientific data and how it might influence clinical reasoning and practice.Recent findingsA large number of scientific manuscripts are daily published worldwide, and the Covid-19 makes no exception. Up to now, data on Covid-19 have come from countries initially affected by the disease and mostly pertain either epidemiological observations or opinion papers. Many of them do not fulfil the essential principles characterizing the adequate scientific method.SummaryIt is crucial to be able to critical appraise the scientific literature, in order to provide adequate nutrition therapy to patients, and in particular, to Covid-19 infected individuals.",
        "DOI": "10.1097/MCO.0000000000000666",
        "paper_author": "Correia M.I.T.D.",
        "affiliation_name": "Universidade Federal de Minas Gerais",
        "affiliation_city": "Belo Horizonte",
        "affiliation_country": "Brazil",
        "affiliation_id": "60030074",
        "affiliation_state": "MG"
    },
    {
        "paper_title": "Geographic and Longitudinal Trends in Media Framing of Obesity in the United States",
        "publication": "Obesity",
        "citied_by": "8",
        "cover_date": "2020-07-01",
        "Abstract": "Objective: The media’s framing of public health issues is closely linked to public opinion on these issues and support for interventions to address them. This study characterized geographic and temporal variation in the US media’s framing of obesity across states from 2006 to 2015. Methods: Newspaper articles that mentioned the term obesity were drawn from Access World News (NewsBank, Inc., Naples, Florida), a comprehensive online database (N = 364,288). This study employed automated content analysis, a machine learning technique, to categorize articles as (1) attributing obesity to individual-level causes (e.g., lifestyle behaviors), (2) attributing obesity to environmental/systemic causes (e.g., neighborhood walkability), (3) attributing obesity to both individual-level causes and environmental/systemic causes, or (4) articles without any such attribution framework. Results: Nationwide across all years, a higher proportion of articles focused on individual-level attribution of obesity than environmental-level attribution or both. Missouri and Idaho had the highest proportions of articles with an individual framework, and Nevada, Arkansas, and Wisconsin had the highest proportions of articles with an environmental framework. Conclusions: This analysis demonstrates that US media sources heavily focus on an individual framing of obesity, which may be informing public perceptions of obesity. By highlighting differences in obesity media portrayal, this study could inform research to understand why particular states represent outliers and how this may affect obesity policy making.",
        "DOI": "10.1002/oby.22845",
        "paper_author": "Chiang J.",
        "affiliation_name": "Stanford University School of Medicine",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60032838",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Proxy Experience Replay: Federated Distillation for Distributed Reinforcement Learning",
        "publication": "IEEE Intelligent Systems",
        "citied_by": "21",
        "cover_date": "2020-07-01",
        "Abstract": "Traditional distributed deep reinforcement learning (RL) commonly relies on exchanging the experience replay memory (RM) of each agent. Since the RM contains all state observations and action policy history, it may incur huge communication overhead while violating the privacy of each agent. Alternatively, this article presents a communication-efficient and privacy-preserving distributed RL framework, coined federated reinforcement distillation (FRD). In FRD, each agent exchanges its proxy experience RM (ProxRM), in which policies are locally averaged with respect to proxy states clustering actual states. To provide FRD design insights, we present ablation studies on the impact of ProxRM structures, neural network architectures, and communication intervals. Furthermore, we propose an improved version of FRD, coined mixup augmented FRD (MixFRD), in which ProxRM is interpolated using the mixup data augmentation algorithm. Simulations in a Cartpole environment validate the effectiveness of MixFRD in reducing the variance of mission completion time and communication cost, compared to the benchmark schemes, vanilla FRD, federated RL (FRL), and policy distillation.",
        "DOI": "10.1109/MIS.2020.2994942",
        "paper_author": "Cha H.",
        "affiliation_name": "Yonsei University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60016912",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modeling merging acceleration and deceleration behavior based on gradient-boosting decision tree",
        "publication": "Journal of Transportation Engineering Part A: Systems",
        "citied_by": "29",
        "cover_date": "2020-07-01",
        "Abstract": "This paper aims to model the behavior of merging acceleration/deceleration when cars are running in a congested weaving section on a freeway during the merging implementation period by using a data-driven method called gradient-boosting decision tree (GBDT). Different from other black-box machine learning techniques, GBDT can provide abundant information about the nonlinear effects for independent variables by drawing the partial effects. Noise-filtered vehicle trajectory data collected on US Highway 101 are investigated in this study. The partial dependence plots show that the influence of independent variables on merging acceleration/deceleration is nonlinear and complicated and thus is different from the car-following behavior, which indicates that the adoption of traditional car-following models to merging execution behavior cannot reflect the distinctive behavior of merging vehicles. Evaluation of the performances in comparison with other state-of-the-art methods indicates that the proposed method can obtain more accurate results and thus is practical for simulating the merging execution behavior.",
        "DOI": "10.1061/JTEPBS.0000386",
        "paper_author": "Li G.",
        "affiliation_name": "Nanjing Forestry University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60025665",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "An end-to-end model for rice yield prediction using deep learning fusion",
        "publication": "Computers and Electronics in Agriculture",
        "citied_by": "101",
        "cover_date": "2020-07-01",
        "Abstract": "Rice yield is essential for more than half of the world's population, and thus, accurate predictions of rice yield are of great importance for trade, development policies, humanitarian assistance, decision-makers, etc. However, traditional mechanistic models and statistical machine learning models need to identify features, making the research on and application of these models laborious and time-consuming. In this paper, a novel end-to-end prediction model that fuses two back-propagation neural networks (BPNNs) with an independently recurrent neural network (IndRNN), named BBI-model, is proposed to address these challenges. In stage one, BBI-model preprocesses the original area and meteorology data. In stage two, one BPNN and the IndRNN are used to learn deep spatial and temporal features in parallel. In stage three, another BPNN combines two kinds of deep features and learns the relationships between these deep features and rice yields to make predictions for summer and winter rice yields. The experimental results indicate that BBI-model achieved the lowest mean absolute error (MAE) and root mean square error (RMSE) for the summer rice prediction (0.0044 and 0.0057, respectively) and corresponding values of 0.0074 and 0.0192 for the winter rice prediction when the number of layers in the network was set to six. Moreover, the errors of the model using the combination of deep spatial-temporal features were significantly lower than when simply using deep temporal features. Furthermore, the model converged quickly with 100 iterations and then remained stable. These findings confirm that the model can make accurate predictions for summer and winter rice yields of 81 counties in the Guangxi Zhuang Autonomous Region, China.",
        "DOI": "10.1016/j.compag.2020.105471",
        "paper_author": "Chu Z.",
        "affiliation_name": "Xinjiang University",
        "affiliation_city": "Urumqi",
        "affiliation_country": "China",
        "affiliation_id": "60015780",
        "affiliation_state": "Xinjiang"
    },
    {
        "paper_title": "The Need for a National Strategy on Artificial Intelligence in Canadian Dermatology",
        "publication": "Journal of Cutaneous Medicine and Surgery",
        "citied_by": "6",
        "cover_date": "2020-07-01",
        "Abstract": "NA",
        "DOI": "10.1177/1203475420923648",
        "paper_author": "Lewinson R.T.",
        "affiliation_name": "University of Calgary",
        "affiliation_city": "Calgary",
        "affiliation_country": "Canada",
        "affiliation_id": "60002306",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "The big picture of cities: Analysing Flickr photos of 222 cities worldwide",
        "publication": "Cities",
        "citied_by": "25",
        "cover_date": "2020-07-01",
        "Abstract": "The purpose of the current research is to introduce a new method involving machine learning that can identify and analyse the city image dimensions (CIDs) of cities worldwide. Unlike traditional methods, this new method can rapidly identify city image dimensions from large sets of user-generated photos in an efficient and scalable manner, which could help city managers more effectively plan city branding strategies and city development policies. Label detection with Google Cloud Vision and dimension identification (or topic extraction) with latent Dirichlet allocation (LDA) modelling were used to analyse 222,000 photos of 222 cities worldwide from Flickr.com. Theoretically, this study reinforces the existing literature using Big Data, presents alternative ways to identify CIDs, and illustrates diversity within the image dimensions.",
        "DOI": "10.1016/j.cities.2020.102741",
        "paper_author": "Taecharungroj V.",
        "affiliation_name": "Mahidol University",
        "affiliation_city": "Nakhon Pathom",
        "affiliation_country": "Thailand",
        "affiliation_id": "60012718",
        "affiliation_state": "Nakhon Pathom"
    },
    {
        "paper_title": "Role of energy use in the prediction of CO<inf>2</inf> emissions and economic growth in India: evidence from artificial neural networks (ANN)",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "36",
        "cover_date": "2020-07-01",
        "Abstract": "The correspondence among energy use, carbon dioxide emissions, and growth is a matter of discussion among policymakers, economists, and researchers. It is not possible to deny that the concept of sustainable development inspires their enquiry into this arena. The primary aspiration of this work is to use machine learning techniques in the prediction of carbon dioxide emissions and growth by taking energy use as the input variable. Our findings suggest that the prediction accuracy of the relation between CO2 emission and growth can improve by using machine learning techniques. In this case, prediction using Adam optimization is better than stochastic gradient descent (SGD) in the context of carbon dioxide emissions and growth. Furthermore, the result highlights that the change from fossil fuel use to renewable energy use is a possible way to reduce carbon dioxide emissions without sacrificing economic growth. Hence, the policy has to be articulated in such way as to reduce fossil fuel use or increase energy efficiency, and at the same time, new investment has to be initiated in the renewable energy sector to promote economic growth in India.",
        "DOI": "10.1007/s11356-020-08675-7",
        "paper_author": "Ashin A.N.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India",
        "affiliation_id": "60004750",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "What influences sales market of new energy vehicles in China? Empirical study based on survey of consumers’ purchase reasons",
        "publication": "Energy Policy",
        "citied_by": "65",
        "cover_date": "2020-07-01",
        "Abstract": "In recent years, new energy vehicles (NEVs), which are considered to be one of the most important ways of solving global warming and energy crisis, have seen rapid development. Owing to the far-reaching policy implemented by Chinese government, the sales volume (SV) of NEVs has seen an exponential growth, and China has become the world's largest consumer of NEVs. The objective of this study was to determine the focus of Chinese consumers with regard to NEVs and to understand how their interests influence the SV. We used data mining combined with deep-learning technologies to investigate a large number of purchase reasons and found that the primary motivating factors were the vehicle, demographic characteristics, and national policy. Additionally, to determine how these factors affect the market, we used correlation analysis to examine the relationship between the SV and the factors. The results indicated that national policies, infrastructure, demographic factors, and safety awareness are closely related to the SV. The findings of this study suggest valuable strategies for government departments, allowing them to publish relevant policies, and manufacturers, allowing them to target specific consumer groups. This approach addresses the environmental concerns by promoting the utilization of NEVs rather than traditional fuel vehicles.",
        "DOI": "10.1016/j.enpol.2020.111484",
        "paper_author": "Wang L.",
        "affiliation_name": "Tianjin University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60019533",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The human side of health data",
        "publication": "Nature Medicine",
        "citied_by": "5",
        "cover_date": "2020-07-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41591-020-0838-z",
        "paper_author": "Banner N.F.",
        "affiliation_name": "Wellcome Trust",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022106",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The State of Data Science in Genomic Nursing",
        "publication": "Biological Research for Nursing",
        "citied_by": "11",
        "cover_date": "2020-07-01",
        "Abstract": "Nurse scientists are generating, acquiring, distributing, processing, storing, and analyzing greater volumes of complex omics data than ever before. To take full advantage of big omics data, to address core biological questions, and to enhance patient care, however, genomic nurse scientists must embrace data science. Intended for readership with limited but expanding data science knowledge and skills, this article aims to provide a brief overview of the state of data science in genomic nursing. Our goal is to introduce key data science concepts to genomic nurses who participate at any stage of the data science lifecycle, from research patient recruitment to data wrangling, preprocessing, and analysis to implementation in clinical practice to policy creation. We address three major components in this review: (1) fundamental terminology for the field of genomic nursing data science, (2) current genomic nursing data science research exemplars, and (3) the spectrum of genomic nursing data science roles as well as education pathways and training opportunities. Links to helpful resources are included throughout the article.",
        "DOI": "10.1177/1099800420915991",
        "paper_author": "Dreisbach C.",
        "affiliation_name": "University of Virginia",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States",
        "affiliation_id": "60021918",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Employing statistical learning to derive species-level genetic diversity for mammalian species",
        "publication": "Mammal Review",
        "citied_by": "14",
        "cover_date": "2020-07-01",
        "Abstract": "The patterns of genetic diversity in several genomic regions have been used in mammalian systematics for decades. For instance, when studying closely related species, it is generally assumed that the mitochondrial cytochrome b gene (cytb) exhibits significant information that can be used for differentiation between intraspecies and interspecies variation in mammals. Because of sampling limitations, early analyses of this proposition were conducted mainly on rodents and bats. Currently, more than 57000 cytb sequences are available covering all major lineages of mammals, and sequencing of several individuals per species is common practice in molecular systematics. We were thus prompted to carry out a large-scale analysis of the utility of cytb genetic variation as a predictor of whether a pair of sequences came from within-species or between-species comparisons. Using predetermined species-level assignments, we employed standard methods from statistical learning to calculate the cut-off values able to classify genetic distances in either intraspecies or interspecies categories; we then measured the performance of such statistical classifiers to predict the species-level taxonomic rank as defined by experts. Depending on the classifier, our results showed that when adopting cytb distance cut-off values of 7.3% and 5.5% for small mammals (Metatheria, Rodentia, Chiroptera, and Eulipotyphla) and 4.3% and 3% for medium-sized to large mammals (Primates, Carnivora, and Artiodactyla), the frequency of incorrect assignment of within-species divergences to the between-species category (type I error) varied from 7 to 11%. In order to avoid over-splitting by future researchers, we calculated cut-off values using a more conservative evaluation and provided a list of mammalian species that are likely to consist of complexes of cryptic species. We show that our supervised method can provide practical guidelines to improve the performance of unsupervised algorithms for species delimitation. Finally, we discuss limitations of large-scale approaches (e.g. effects of misclassification in databases and the need for case-by-case evaluation of cryptic species complexes) and their consequences for conservation policies.",
        "DOI": "10.1111/mam.12192",
        "paper_author": "Schrago C.G.",
        "affiliation_name": "Universidade Federal do Rio de Janeiro",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil",
        "affiliation_id": "60000036",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Using machine learning algorithms to map the groundwater recharge potential zones",
        "publication": "Journal of Environmental Management",
        "citied_by": "63",
        "cover_date": "2020-07-01",
        "Abstract": "Groundwater recharge is indispensable for the sustainable management of freshwater resources, especially in the arid regions. Here we address some of the important aspects of groundwater recharge through machine learning algorithms (MLAs). Three MLAs including, SVM, MARS, and RF were validated for higher prediction accuracies in generating groundwater recharge potential maps (GRPMs). Accordingly, soil permeability samples were prepared and are arbitrarily grouped into training (70%) and validation (30%) samples. The GRPMs are generated using sixteen effective factors, such as elevation (denoted using a digital elevation model; DEM), aspect, slope angle, TWI (topographic wetness index), fault density, MRVBF (multiresolution index of valley bottom flatness), rainfall, lithology, land use, drainage density, distance from rivers, distance from faults, annual ETP (evapo-transpiration), minimum temperature, maximum temperature, and rainfall 24-hr. Subsequently, the VI (variables importance) is assessed based on the LASSO algorithm. The GRPMs of three MLAs were validated using the ROC-AUC (receiver operating characteristic-area under curve) and various techniques including true positive rate (TPR), false positive rate (FPR), F-measures, fallout, sensitivity, specificity, true skill statistics (TSS), and corrected classified instances (CCI). Based on the validation, the RF algorithm performed better (AUC = 0.987) than the SVM (AUC = 0.963) and the MARS algorithm (AUC = 0.962). Furthermore, the accuracy of these MLAs are included in excellent class, based on the ROC curve threshold. Our case study shows that the GRPMs are potential guidelines for decision-makers in drafting policies related to the sustainable management of the groundwater resources.",
        "DOI": "10.1016/j.jenvman.2020.110525",
        "paper_author": "Pourghasemi H.R.",
        "affiliation_name": "Shiraz University",
        "affiliation_city": "Shiraz",
        "affiliation_country": "Iran",
        "affiliation_id": "60026914",
        "affiliation_state": "Fars"
    },
    {
        "paper_title": "Regret Lower Bounds for Unbiased Adaptive Control of Linear Quadratic Regulators",
        "publication": "IEEE Control Systems Letters",
        "citied_by": "3",
        "cover_date": "2020-07-01",
        "Abstract": "We present lower bounds for the regret of adaptive control of the linear quadratic regulator. These are given in terms of problem specific expected regret lower bounds valid for unbiased policies linear in the state. Our approach is based on the insight that the adaptive control problem can, given our assumptions, be reduced to a sequential estimation problem. This enables the use of the Cramér-Rao information inequality which yields a scaling limit lower bound of logarithmic order. The bound features both information-theoretic and control-theoretic quantities. By leveraging existing results, we are able to show that the bound is tight in a special case.",
        "DOI": "10.1109/LCSYS.2020.2982455",
        "paper_author": "Ziemann I.",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60002014",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "Predicting solutions of large-scale optimization problems via machine learning: A case study in blood supply chain management",
        "publication": "Computers and Operations Research",
        "citied_by": "91",
        "cover_date": "2020-07-01",
        "Abstract": "Practical constrained optimization models are often large, and solving them in a reasonable time is a challenge in many applications. Further, many industries have limited access to professional commercial optimization solvers or computational power for use in their day-to-day operational decisions. In this paper, we propose a novel approach to deal with the issue of solving large operational stochastic optimization problems (SOPs) by using machine learning models. We assume that decision makers have access to facilities to optimally solve their large-scale optimization model for some initial and limited period and for some test instances. This might be through a collaborative project with research institutes or through short-term use of high-performance computing facilities. We propose that longer term support can be provided by utilizing the solutions (i.e., the optimal value of the actionable decision variables) of the stochastic optimization model from this initial period to train a machine learning model to learn optimal operational decisions in the future. In this study, the proposed approach is employed to make decisions on transshipment of blood units in a network of hospitals. We compare the decisions learned by several machine learning models with the optimal results obtained if the hospitals had access to commercial optimization solvers and computational power, and with the hospital network's current empirical heuristic policy. The results show that using a trained neural network model reduces the average daily cost by about 29% compared with current policy, while the exact optimal policy reduces the average daily cost by 37%. Although optimization models cannot be fully replaced by machine learning, our proposed approach while not guaranteed to be optimal can improve operational decisions when optimization models are computationally expensive and infeasible for daily operational decisions in organizations such as not-for-profit and small and medium-sized enterprises.",
        "DOI": "10.1016/j.cor.2020.104941",
        "paper_author": "Abbasi B.",
        "affiliation_name": "RMIT University",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60011362",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Q-learning based dynamic task scheduling for energy-efficient cloud computing",
        "publication": "Future Generation Computer Systems",
        "citied_by": "169",
        "cover_date": "2020-07-01",
        "Abstract": "High energy consumption has become a growing concern in the operation of complex cloud data centers due to the ever-expanding size of cloud computing facilities and the ever-increasing number of users. It is critical to find viable solutions to cloud task scheduling so that cloud resources can be utilized in an energy-efficient way while still meeting diverse user requirements in real time. In this research we propose a Q-learning based task scheduling framework for energy-efficient cloud computing (QEEC). QEEC has two phases. In the first phase a centralized task dispatcher is used to implement the M/M/S queueing model, by which the arriving user requests are assigned to each server in a cloud. In the second phase a Q-learning based scheduler on each server first prioritizes all the requests by task laxity and task life time, then uses a continuously-updating policy to assign tasks to virtual machines, applying incentives to reward the assignments that can minimize task response time and maximize each server's CPU utilization. We have conducted simulation experiments, which have confirmed that implementing a M/M/S queueing system in a cloud can help to reduce the average task response time. The experiments have also demonstrated that the QEEC approach is the most energy-efficient as compared to other task scheduling policies, which can be largely credited to the M/M/S queueing model and the Q-learning strategy implemented in QEEC.",
        "DOI": "10.1016/j.future.2020.02.018",
        "paper_author": "Ding D.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022381",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Class expression induction as concept space exploration: From DL-FOIL to DL-FOCL",
        "publication": "Future Generation Computer Systems",
        "citied_by": "19",
        "cover_date": "2020-07-01",
        "Abstract": "The Web of Data is one of the perspectives of the Semantic Web. In this context, concept learning services, supported by multirelational machine learning, have been integrated in various tools for knowledge engineers to carry out several tasks related to the construction, completion and maintenance of the knowledge bases: essentially they are used to elicit new candidate concept definitions (i.e. axioms regarding classes) to be incorporated in the knowledge bases possibly also as replacements for previous ones. Sundry reference approaches rely on a covering strategy to generalize input examples that can be regarded as a form of hill-climbing search that explores a huge discrete conceptual space. Methods adopting this strategy are known to be affected by an inherent problem of myopia. In particular, our DL-FOIL has been shown to suffer from this problem as its algorithm is based on a stochastic yet informed exploration of the concept space, by means of a refinement operator, to generate partial descriptions iteratively. To tackle this problem and enhance the performance of our system we have introduced a series of extensions of the original DL-FOIL algorithm, that have led to various releases of its spin-off DL-FOCL. Essentially they aim at reducing the aforementioned problem through specific strategies grounded on either the integration of meta-heuristics, such as repeated hill-climbing and tabu search, or the employment of some form of lookahead. In this work, we present consolidated and extended releases of both DL-FOIL and DL-FOCL along various dimensions: better heuristics and stop conditions, more complex refinement operators with the possibility to perform the specialization adopting iterative deepening or lookahead strategies, improved versions of the algorithm based on the repeated hill-climbing strategy with new quality criteria and of the tabu search with a different policy for managing the local memory. All the implementations of these approaches have been extensively evaluated in three experimental sessions, involving various publicly available knowledge bases and fragments extracted from the Linked Data cloud, showing interesting results and indicating some lessons to be learned: our approaches outperformed a popular reference system from the DL-LEARNER framework on learning problems when the open-world semantics is explicitly considered. They also exhibited an analogous performance on a benchmark of datasets from contexts with an intended underlying closed-world semantics.",
        "DOI": "10.1016/j.future.2020.02.071",
        "paper_author": "Rizzo G.",
        "affiliation_name": "Università degli studi di Bari Aldo Moro",
        "affiliation_city": "Bari",
        "affiliation_country": "Italy",
        "affiliation_id": "60022778",
        "affiliation_state": "BA"
    },
    {
        "paper_title": "Time, space, money, and social interaction: Using machine learning to classify people's mobility strategies through four key dimensions",
        "publication": "Travel Behaviour and Society",
        "citied_by": "21",
        "cover_date": "2020-07-01",
        "Abstract": "Previous activity-based studies have shown that behavioural outcomes are the result of complex and multidimensional processes. In this context, identifying and characterizing discrete mobility profiles through the classification of people's behavior is particularly attractive. By facilitating the interpretation of complex, multidimensional processes, such an exercise could help to efficiently target transport policy decisions. The purpose of this paper is to identify mobility strategy profiles considering four key dimensions: time, space, money, and social interaction. Data from a seven-day activity, travel, expenditure, and social interaction diary applied to a sample of residents from the city of Concepción, Chile, is used. A two-step approach based on machine learning techniques is adopted. First, we use a Self-Organizing Map algorithm to identify seven distinct mobility strategies, each characterized by distinctive behaviors. These profiles are identified through 18 weekday and weekend daily behavior variables measuring the four key dimensions mentioned above, with an explicit focus on transport mode use. In the second step, we use a Decision Tree algorithm to profile the mobility strategies by means of personal and household sociodemographic variables. The results show interesting links among the dimensions of analysis within these profiles, such as connections between monetary expenditure on leisure and daily social interaction, and that profiles with higher private vehicle modal split tend to present higher levels of social interaction with people in their social network than public transit users.",
        "DOI": "10.1016/j.tbs.2020.02.004",
        "paper_author": "Victoriano R.",
        "affiliation_name": "Universidad de Concepcion",
        "affiliation_city": "Concepcion",
        "affiliation_country": "Chile",
        "affiliation_id": "60001282",
        "affiliation_state": "BI"
    },
    {
        "paper_title": "Integrated learning pathways in higher education: A framework enhanced with machine learning and semantics",
        "publication": "Education and Information Technologies",
        "citied_by": "26",
        "cover_date": "2020-07-01",
        "Abstract": "The present research work proposes the development of an integrated framework for the personalization and parameterization of learning pathways, aiming at optimizing the quality of the offered services by the Higher Educational Institutions (HEI). In order to achieve this goal, in addition to the educational part, the EDUC8 framework encloses the set of parameters that cover both the technical and the financial dimensions of a learning pathway, thus providing a complete tool for the optimization and calculation of the offered services by the HEIs in combination with the minimization of respective costs. Moreover, the proposed framework incorporates simulation modeling along with machine learning for the purpose of designing learning pathways and evaluating quality assurance indicators and the return on investment of implementation. The study presents a case study in relation to tertiary education in Greece, with a particular focus on Computer Science programs. Data clustering is specifically applied to learn potential insights pertaining to student characteristics, education factors and outcomes. Generally, the framework is conceived to provide a systematic approach for developing tertiary policies that help optimize the quality and cost of education.",
        "DOI": "10.1007/s10639-020-10105-7",
        "paper_author": "Iatrellis O.",
        "affiliation_name": "University of Thessaly",
        "affiliation_city": "Volos",
        "affiliation_country": "Greece",
        "affiliation_id": "60025812",
        "affiliation_state": "Thessaly"
    },
    {
        "paper_title": "The nexus of financial development and economic growth across major Asian economies: Evidence from bootstrap ARDL testing and machine learning approach",
        "publication": "Journal of Computational and Applied Mathematics",
        "citied_by": "60",
        "cover_date": "2020-07-01",
        "Abstract": "The growth trajectory of China, Japan, and India shows their highly influential position in the economy in Asia and the world. A recently developed bootstrap autoregressive-distributed lag (ARDL) test with structural breaks is used to test for cointegration and causality across major Asian economies to investigate the relationship between financial development and economic growth during the period 1960–2016. Although a long-run cointegrating relationship between the time series of real GDP and private credit is insufficient to be detected by a more rigorous test and comprehensive inference, the results show the contingency of causality in the short term. For China, a bidirectional causality with positive supply lead and negative demand following. Positive feedback exists in Japan and India, respectively. In machine learning approach, iterative classifier optimizer with adaboost as iterative classifier performs better than other classifiers in prediction of economic status. The results support the government in Japan and India to keep its steps to regard financial development as an instrument to foster economic growth, and economic growth is considered as an engine to promote financial development for sustainability. The government of China may set proper regulations in the financial market. Additionally, the government may monitor the credit performance to state-owned enterprises and investigate the process of financial resource from input to output, in order to improve financial efficiency and thereby, robustly contribute to economic growth. The empirical analysis provides several policy and managerial implications for decision-makers at the macroeconomic and microeconomic levels.",
        "DOI": "10.1016/j.cam.2019.112660",
        "paper_author": "Wu C.F.",
        "affiliation_name": "Wuchang University of Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60261354",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Coupling data science with community crowdsourcing for urban renewal policy analysis: An evaluation of Atlanta’s Anti-Displacement Tax Fund",
        "publication": "Environment and Planning B: Urban Analytics and City Science",
        "citied_by": "13",
        "cover_date": "2020-07-01",
        "Abstract": "We estimate the cost and impact of a proposed anti-displacement program in the Westside of Atlanta (GA) with data science and machine learning techniques. This program intends to fully subsidize property tax increases for eligible residents of neighborhoods where there are two major urban renewal projects underway, a stadium and a multi-use trail. We first estimate household-level income eligibility for the program with data science and machine learning approaches applied to publicly available household-level data. We then forecast future property appreciation due to urban renewal projects using random forests with historic tax assessment data. Combining these projections with household-level eligibility, we estimate the costs of the program for different eligibility scenarios. We find that our household-level data and machine learning techniques result in fewer eligible homeowners but significantly larger program costs, due to higher property appreciation rates than the original analysis, which was based on census and city-level data. Our methods have limitations, namely incomplete data sets, the accuracy of representative income samples, the availability of characteristic training set data for the property tax appreciation model, and challenges in validating the model results. The eligibility estimates and property appreciation forecasts we generated were also incorporated into an interactive tool for residents to determine program eligibility and view their expected increases in home values. Community residents have been involved with this work and provided greater transparency, accountability, and impact of the proposed program. Data collected from residents can also correct and update the information, which would increase the accuracy of the program estimates and validate the modeling, leading to a novel application of community-driven data science.",
        "DOI": "10.1177/2399808318819847",
        "paper_author": "Auerbach J.",
        "affiliation_name": "Colorado State University",
        "affiliation_city": "Fort Collins",
        "affiliation_country": "United States",
        "affiliation_id": "60009226",
        "affiliation_state": "CO"
    },
    {
        "paper_title": "Modelling world agriculture as a learning machine? From mainstream models to Agribiom 1.0",
        "publication": "Land Use Policy",
        "citied_by": "10",
        "cover_date": "2020-07-01",
        "Abstract": "Models of world agriculture and food systems are used widely to predict future scenarios of land and resource uses. Starting with a brief history of world agriculture models since the 1960s, which shows their hybrid character as well as their limitations in representing real world diversity and options, this article then presents an alternative modelling experience. We argue that models are tools of evidence, hence “truth machines”, but also tools of government, with a multi-faceted political dimension. For instance, the virtual realities that conventional models build incorporate value judgements about the future that remain invisible and difficult to challenge. For ease of computation and comparison, they standardise functional forms and parameters, eliding observable diversity and blacklisting sociotechnical policy options such as those based on agroecology and biological synergies. They are designed for prediction and prescription rather than for supporting public debate, which is also a (comfortable) political stance. In contrast, the Agrimonde experience – a foresight initiative based on the Agribiom model – shows that a model of world agriculture can be constructed as a “learning machine” that leaves room for a variety of scientific and stakeholder knowledge as well as public debate. This model and its partners unveiled some virtual realities, processes and actors that were invisible in mainstream models, and asserted a vision of sustainable agri-food systems by 2050. Agribiom and Agrimonde improved knowledge, policy-making and democracy. Overall, they highlighted the need for epistemic plurality and for engaging seriously in the production of models as learning machines.",
        "DOI": "10.1016/j.landusepol.2018.09.028",
        "paper_author": "Dorin B.",
        "affiliation_name": "Centre de Sciences Humaines",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60271839",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Scaling up behavioral science interventions in online education",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "115",
        "cover_date": "2020-06-30",
        "Abstract": "Online education is rapidly expanding in response to rising demand for higher and continuing education, but many online students struggle to achieve their educational goals. Several behavioral science interventions have shown promise in raising student persistence and completion rates in a handful of courses, but evidence of their effectiveness across diverse educational contexts is limited. In this study, we test a set of established interventions over 2.5 y, with one-quarter million students, from nearly every country, across 247 online courses offered by Harvard, the Massachusetts Institute of Technology, and Stanford. We hypothesized that the interventions would produce medium-to-large effects as in prior studies, but this is not supported by our results. Instead, using an iterative scientific process of cyclically preregistering new hypotheses in between waves of data collection, we identified individual, contextual, and temporal conditions under which the interventions benefit students. Self-regulation interventions raised student engagement in the first few weeks but not final completion rates. Value-relevance interventions raised completion rates in developing countries to close the global achievement gap, but only in courses with a global gap. We found minimal evidence that state-of-the-art machine learning methods can forecast the occurrence of a global gap or learn effective individualized intervention policies. Scaling behavioral science interventions across various online learning contexts can reduce their average effectiveness by an order-of-magnitude. However, iterative scientific investigations can uncover what works where for whom.",
        "DOI": "10.1073/pnas.1921417117",
        "paper_author": "Kizilcec R.F.",
        "affiliation_name": "Cornell University Department of Information Science",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60028072",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "7th International Conference on Control, Decision and Information Technologies, CoDIT 2020",
        "publication": "7th International Conference on Control, Decision and Information Technologies, CoDIT 2020",
        "citied_by": "0",
        "cover_date": "2020-06-29",
        "Abstract": "The proceedings contain 212 papers. The topics discussed include: implementation of the algorithm for improving the frontier in DEA models; a decision model and method for the bi-objective parallel machine ScheLoc problem; deep imitation learning for broom-manipulation tasks using small-sized training data; performance and usage frequency based policy for products recovery and remanufacturing; voltage oriented control of indirect matrix converter applied to wind energy conversion system using PMSM generator; optimal trajectories synthesis of a mobile robots group using Cartesian genetic programming; minimization of an aircraft's energy; a multi-objective and multi-decision maker approach for the balancing market in distribution grids in presence of aggregators; actor-critic algorithm for optimal synchronization of Kuramoto oscillator; and estimation of the distance to moving vehicles in a traffic stream.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Research on Forecasting of China's Monetary Policy Based on Random Forest Algorithm",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "3",
        "cover_date": "2020-06-29",
        "Abstract": "This paper uses the random forest algorithm model to quantify and predict the monetary policy of the People's Bank of China under the input of 16 macroeconomic indicators. It is compared with three other machine learning algorithms (CART decision tree, support vector machine and neural network algorithm), discrete selection model and combined prediction model. The results show that the random forest algorithm shows better prediction accuracy in predicting the direction of the central bank's monetary policy.",
        "DOI": "10.1088/1742-6596/1549/3/032078",
        "paper_author": "Qiu C.",
        "affiliation_name": "Shenzhen University",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60000937",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Potential for Early Forecast of Moroccan Wheat Yields Based on Climatic Drivers",
        "publication": "Geophysical Research Letters",
        "citied_by": "21",
        "cover_date": "2020-06-28",
        "Abstract": "Wheat production plays an important role in Morocco. Current wheat forecast systems use weather and vegetation data during the crop growing phase, thus limiting the earliest possible release date to early spring. However, Morocco's wheat production is mostly rainfed and thus strongly tied to fluctuations in rainfall, which in turn depend on slowly evolving climate dynamics. This offers a source of predictability at longer time scales. Using physically guided causal discovery algorithms, we extract climate precursors for wheat yield variability from gridded fields of geopotential height and sea surface temperatures which show potential for accurate yield forecasts already in December, with around 50% explained variance in an out-of-sample cross validation. The detected interactions are physically meaningful and consistent with documented ocean-atmosphere feedbacks. Reliable yield forecasts at such long lead times could provide farmers and policy makers with necessary information for early action and strategic adaptation measurements to support food security.",
        "DOI": "10.1029/2020GL087516",
        "paper_author": "Lehmann J.",
        "affiliation_name": "Leibniz-Gemeinschaft",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60008523",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Explaining\" machine learning reveals policy challenges the need to make objectives explicit may expose policy trade-offs that had previously been implicit and obscured",
        "publication": "Science",
        "citied_by": "56",
        "cover_date": "2020-06-26",
        "Abstract": "NA",
        "DOI": "10.1126/science.aba9647",
        "paper_author": "Coyle D.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Scheduling Policies for Federated Learning in Wireless Networks: An Overview",
        "publication": "ZTE Communications",
        "citied_by": "5",
        "cover_date": "2020-06-25",
        "Abstract": "Due to the increasing need for massive data analysis and machine learning model training at the network edge, as well as the rising concerns about data privacy, a new distrib⁃ uted training framework called federated learning (FL) has emerged and attracted much at⁃ tention from both academia and industry. In FL, participating devices iteratively update the local models based on their own data and contribute to the global training by uploading mod⁃ el updates until the training converges. Therefore, the computation capabilities of mobile de⁃ vices can be utilized and the data privacy can be preserved. However, deploying FL in re⁃ source-constrained wireless networks encounters several challenges, including the limited energy of mobile devices, weak onboard computing capability, and scarce wireless band⁃ width. To address these challenges, recent solutions have been proposed to maximize the convergence rate or minimize the energy consumption under heterogeneous constraints. In this overview, we first introduce the backgrounds and fundamentals of FL. Then, the key challenges in deploying FL in wireless networks are discussed, and several existing solu⁃ tions are reviewed. Finally, we highlight the open issues and future research directions in FL scheduling.",
        "DOI": "10.12142/ZTECOM.202002003",
        "paper_author": "Shi W.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Using Machine Learning for Intent-based provisioning in High-Speed Science Networks",
        "publication": "SNTA 2020 - Proceedings of the 3rd International Workshop on Systems and Network Telemetry and Analytics",
        "citied_by": "24",
        "cover_date": "2020-06-23",
        "Abstract": "Smart and rapid provisioning of network resources that are easy to configure, monitor, and maintain is essential for high-speed network infrastructures. There is a need to allow users to interface directly with networks to easily navigate their use-cases, while not compromising network policies. This paper introduces EVIAN, a system designed to bridge the gap between user and network requirements. EVIAN is an intent rendering platform, that uses natural language processing to interact with users, gathers network requirements in an easy-to-talk English conversation, and translates these to network API calls.",
        "DOI": "10.1145/3391812.3396269",
        "paper_author": "Mahtout H.",
        "affiliation_name": "Bordeaux Graduate School of Engineering",
        "affiliation_city": "Bordeaux",
        "affiliation_country": "France",
        "affiliation_id": "113035950",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "WIP: Ethical responsibility formation of students in a nuclear engineering course through inquiry learning",
        "publication": "ASEE Annual Conference and Exposition, Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2020-06-22",
        "Abstract": "Engineering ethics - both in the nature of engineering practice and the impact of engineering work - intersects ethics of many dimensions including the philosophical, technical, business, professional, environmental, legal, and bioethics [1], [2]. The impact of engineering work, including energy systems, extends well beyond the immediate use of technology into the social institutions, distribution of resources, culture, health, and environment. The breadth of desired engineer competencies reveal the social, cultural, and political dimensions of an engineer's professional practice, despite the predominant perception of engineers as technical experts meeting business needs [3]-[5]. Even as the need increases for collaboration across disciplines, no longer can the technology experts be 'disconnected from the civil society' [6]. The critical theory perspective and systems paradigm challenge us to examine what it means to 'teach engineering ethics.' We acknowledge and accept that it cannot be expected that individual engineers will carry the entire responsibility for ethical and equitable decision making in engineering. The organizational culture and structure, the contractual arrangements within the industry, engineering teams, and policy instruments can either enhance or constrain responsibility in engineering decisions. In working towards presenting a solution to a problem, or the implementation of a new technology, engineers will need to acknowledge competing interests and act as a mediator to negotiate for a practical solution. In some aspects, engineers will have to reassert themselves as the stewards of public safety, and as co-decision makers, instead of being treated as commoditized instruments [7] of the business machinery. Simultaneously, we pay attention to the engineers' privileged position - e.g. as experts and high-income earners, with greater proximity to large-scale project decisions - and its role in the unequal influence relations engineers have with other knowledge disciplines and/or community stakeholders. Engineers can be important mediators or gatekeepers for the input of diverse stakeholders on the technology development (e.g. machine learning bias). Therefore, our working vision for engineering ethics education is two-fold: (1) to empower students as moral agents who effectively negotiate for social and ethical responsibility in the technology industry; and (2) to motivate and equip students to actively include and respond to the perspectives, concerns, experiences of the stakeholders whom, otherwise, are made invisible in the decisions regarding engineering projects.",
        "DOI": "NA",
        "paper_author": "Ha M.R.",
        "affiliation_name": "Lassonde School of Engineering",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60191762",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Wheat Area Mapping in Afghanistan Based on Optical and SAR Time-Series Images in Google Earth Engine Cloud Environment",
        "publication": "Frontiers in Environmental Science",
        "citied_by": "26",
        "cover_date": "2020-06-19",
        "Abstract": "Wheat is cultivated on more than 2.7 million hectares in Afghanistan annually, yet the country is dependent on imports to meet domestic demand. The timely estimation of domestic wheat production is highly critical to address any potential food security issues and has been identified as a priority by the Ministry of Agriculture Irrigation and Livestock (MAIL). In this study, we developed a system for in-season mapping of wheat crop area based on both optical (Sentinel-2) and synthetic aperture radar (SAR, Sentinel-1) data to support estimation of wheat cultivated area for management and food security planning. Utilizing a 2010 Food and Agriculture Organization (FAO) cropland mask, wheat sown area for 2017 was mapped integrating decision trees and machine learning algorithms in the Google Earth Engine cloud platform. Information from provincial crop calendars in addition to training and validation data from field-based surveys, and high-resolution Digitalglobe and Airbus Pleiades images were used for classification and validation. The total irrigated and rainfed wheat area were estimated as 912,525 and 562,611 ha, respectively for 2017. Province-wise accuracy assessments show the maximum accuracy of irrigated (IR) and rainfed (RF) wheat across provinces was 98.76 and 99%, respectively, whereas the minimum accuracy was found to be 48% (IR) and 73% (RF). The lower accuracy is attributed to the unavailability of reference data, cloud cover in the satellite images and overlap of spectral reflectance of wheat with other crops, especially in the opium poppy growing provinces. While the method is designed to provide estimation at different stages of the growing season, the best accuracy is achieved at the end of harvest using time-series satellite data for the whole season. The approach followed in the study can be used to generate wheat area maps for other years to aid in food security planning and policy decisions.",
        "DOI": "10.3389/fenvs.2020.00077",
        "paper_author": "Tiwari V.",
        "affiliation_name": "International Centre for Integrated Mountain Development Nepal",
        "affiliation_city": "Kathmandu",
        "affiliation_country": "Nepal",
        "affiliation_id": "60071806",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An unstructured big data approach for country logistics performance assessment in global supply chains",
        "publication": "International Journal of Operations and Production Management",
        "citied_by": "42",
        "cover_date": "2020-06-19",
        "Abstract": "Purpose: The purpose of this study is to explore the potential for the development of a country logistics performance assessment approach based upon textual big data analytics. Design/methodology/approach: The study employs design science principles. Data were collected using the Global Perspectives text corpus that describes the logistics systems of 20 countries from 2006–2014. The extracted texts were processed and analysed using text analytic techniques, and domain experts were employed for training and developing the approach. Findings: The developed approach is able to generate results in the form of logistics performance assessments. It contributes towards the development of more informed weights of the different country logistics performance categories. That said, a larger text corpus and iterative classifier training is required to produce a more robust approach for benchmarking and ranking. Practical implications: When successfully developed and implemented, the developed approach can be used by managers and government bodies, such as the World Bank and its stakeholders, to complement the Logistics Performance Index (LPI). Originality/value: A new and unconventional approach for logistics system performance assessment is explored. A new potential for textual big data analytic applications in supply chain management is demonstrated. A contribution to performance management in operations and supply chain management is made by demonstrating how domain-specific text corpora can be transformed into an important source of performance information.",
        "DOI": "10.1108/IJOPM-07-2019-0544",
        "paper_author": "Kinra A.",
        "affiliation_name": "Universität Bremen",
        "affiliation_city": "Bremen",
        "affiliation_country": "Germany",
        "affiliation_id": "60008293",
        "affiliation_state": "Bremen"
    },
    {
        "paper_title": "A cost-effectiveness analysis of the number of samples to collect and test from a sexual assault",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "10",
        "cover_date": "2020-06-16",
        "Abstract": "Although the backlog of untested sexual assault kits in the United States is starting to be addressed, many municipalities are opting for selective testing of samples within a kit, where only the most probative samples are tested. We use data from the San Francisco Police Department Criminalistics Laboratory, which tests all samples but also collects information on the samples flagged by sexual assault forensic examiners as most probative, to build a standard machine learning model that predicts (based on covariates gleaned from sexual assault kit questionnaires) which samples are most probative. This model is embedded within an optimization framework that selects which samples to test from each kit to maximize the Combined DNA Index System (CODIS) yield (i.e., the number of kits that generate at least one DNA profile for the criminal DNA database) subject to a budget constraint. Our analysis predicts that, relative to a policy that tests only the samples deemed probative by the sexual assault forensic examiners, the proposed policy increases the CODIS yield by 45.4% without increasing the cost. Full testing of all samples has a slightly lower cost-effectiveness than the selective policy based on forensic examiners, but more than doubles the yield. In over half of the sexual assaults, a sample was not collected during the forensic medical exam from the body location deemed most probative by the machine learning model. Our results suggest that electronic forensic records coupled with machine learning and optimization models could enhance the effectiveness of criminal investigations of sexual assaults.",
        "DOI": "10.1073/pnas.2001103117",
        "paper_author": "Wang Z.",
        "affiliation_name": "Stanford Graduate School of Business",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60020928",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Can crowdsourcing create the missing crash data?",
        "publication": "COMPASS 2020 - Proceedings of the 2020 3rd ACM SIGCAS Conference on Computing and Sustainable Societies",
        "citied_by": "4",
        "cover_date": "2020-06-15",
        "Abstract": "UPDATED - -June 1, 2020. Road traffic crashes (RTCs) are the primary cause of death among children and young adults. Yet data on RTCs is incomplete, hindering effective road safety policymaking in many developing countries where mortality is purportedly highest. We web-scrape 850,000 tweets to create crash data and develop a machine learning algorithm to geolocate RTCs. Our algorithm is nearly twice as precise as a standard geoparsing algorithm in identifying the set of locations that include the crash location. Above and beyond, it identifies the unique location of a crash from the set of possible locations in a majority of cases. We dispatch a set of motorcycle drivers to the site of the presumed crash in real time to verify the validity of the crowdsourced data and document the performance of the algorithm. The study can be used as a proof of concept for countries interested to improve RTC data at low cost through a machine learning approach and substantially increase the data available to analyze RTCs and prioritize road safety policies.",
        "DOI": "10.1145/3378393.3402264",
        "paper_author": "Milusheva S.",
        "affiliation_name": "The World Bank, USA",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60112834",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Targeting Development Aid with Machine Learning and Mobile Phone Data: Evidence from an Anti-Poverty Intervention in Afghanistan",
        "publication": "COMPASS 2020 - Proceedings of the 2020 3rd ACM SIGCAS Conference on Computing and Sustainable Societies",
        "citied_by": "8",
        "cover_date": "2020-06-15",
        "Abstract": "Recent papers demonstrate that non-traditional data, from mobile phones and other digital sensors, can be used to roughly estimate the wealth of individual subscribers. This paper asks a question more directly relevant to development policy: Can non-traditional data be used to more efficiently target development aid? By combining rich survey data from a \"big push\" anti-poverty program in Afghanistan with detailed mobile phone logs from program beneficiaries, we study the extent to which machine learning methods can accurately differentiate ultra-poor households eligible for program benefits from other households deemed ineligible. We show that supervised learning methods leveraging mobile phone data can identify ultra-poor households as accurately as standard survey-based measures of poverty, including consumption and wealth; and that combining survey-based measures with mobile phone data produces classifications more accurate than those based on a single data source. We discuss the implications and limitations of these methods for targeting extreme poverty in marginalized populations.",
        "DOI": "10.1145/3378393.3402274",
        "paper_author": "Aiken E.L.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Prediction of Consumer Price Index based on Long Short-Term Memory Model",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "1",
        "cover_date": "2020-06-15",
        "Abstract": "Consumer Price Index(CPI) is the main standard to identify inflation or deflation. Accurate prediction of CPI will help the government to implement macro-control and formulate price stabilization policies, so as to achieve the goal of building a moderately prosperous society. CPI is a non-stationary and non-linear time series, and has relevance in time dimension. In order to fully mine the correlation of CPI sequence in long and short time span, a method of predicting CPI using Long Short-Term Memory(LSTM) model is proposed. Taking historical CPI data of Anhui Province as the empirical analysis object, modeling and predicting are carried out. The prediction effect of LSTM is compared with classic time series model-Autoregressive Integrated Moving Average(ARIMA). According to the predicted results, LSTM model has significantly improvement in RMSE and MAE indicators compared with ARIMA model, indicating the LSTM model has higher prediction accuracy. The SDAE indicator of LSTM model is smaller than ARIMA model, indicating the LSTM model has better prediction stability.",
        "DOI": "10.1088/1742-6596/1550/3/032068",
        "paper_author": "Ao X.",
        "affiliation_name": "Anhui Xinhua University",
        "affiliation_city": "Hefei",
        "affiliation_country": "China",
        "affiliation_id": "60268359",
        "affiliation_state": "Anhui"
    },
    {
        "paper_title": "Evaluation Model of the Regional Economic Vitality",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2020-06-15",
        "Abstract": "Regional economic vitality is an important part of regional comprehensive competitiveness. Accurate assessment of regional economic vitality can reflect the state of economic development among different regions and provide reference to the developing policies of regional economic. To measure the regional economic vitality of main Chinese cities, in this paper, we first establish a mathematical index system based on five aspects (i.e., industrial vitality, capital vitality, innovation vitality, talent vitality and humanistic vitality). Then, the evaluation model of regional economic vitality is constructed using entropy method. The result shows that among 19 main cities of China, Guangzhou and Hangzhou have the highest economic vitality in the first-tier and second-tier cities, respectively. Besides, the change of the comprehensive evaluation of economic vitality among the first-tier cities is more obvious than that between second-tier cities. The evaluation results reflect regional differences in Chinese economic development and can provide valuable reference for exploring benign sustainable policies for regional economic development.",
        "DOI": "10.1088/1742-6596/1550/3/032013",
        "paper_author": "Hu J.",
        "affiliation_name": "Shandong Normal University",
        "affiliation_city": "Jinan",
        "affiliation_country": "China",
        "affiliation_id": "60002210",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Machine learning in agricultural and applied economics",
        "publication": "European Review of Agricultural Economics",
        "citied_by": "125",
        "cover_date": "2020-06-15",
        "Abstract": "This review presents machine learning (ML) approaches from an applied economist's perspective. We first introduce the key ML methods drawing connections to econometric practice. We then identify current limitations of the econometric and simulation model toolbox in applied economics and explore potential solutions afforded by ML. We dive into cases such as inflexible functional forms, unstructured data sources and large numbers of explanatory variables in both prediction and causal analysis, and highlight the challenges of complex simulation models. Finally, we argue that economists have a vital role in addressing the shortcomings of ML when used for quantitative economic analysis.",
        "DOI": "10.1093/erae/jbz033",
        "paper_author": "Storm H.",
        "affiliation_name": "Universität Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany",
        "affiliation_id": "60007493",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Developing machine learning models to automate news classification",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "9",
        "cover_date": "2020-06-15",
        "Abstract": "Reading news articles is essential and critical for understanding the local, nation-wide, and global emerging and developing events, as well as understanding the citizens' demands and critics' opinions. However, with the explosion of social media as news channels, citizens and groups of professionals share news and opinions, which has been the territory of trained journalists, adding more news to process. News often comes with multimedia objects, and suffers from integrity issues, especially with the unreliable or false claims, so-called fake news or altered or alternative facts. These quantity, diversity, and integrity pose significant challenges in the information age, not only for the decision-makers, including policymakers, business leaders but also for individual citizens. This study focuses on how the machine learning classification algorithms could help the news classifications in different categories to easily access the needed category of news and to filter out the noisy and harmful news.",
        "DOI": "10.1145/3396956.3397001",
        "paper_author": "Singh R.",
        "affiliation_name": "Rutgers Institute for Data Science, Learning, and Applications",
        "affiliation_city": "Newark",
        "affiliation_country": "United States",
        "affiliation_id": "60119247",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Integration of Neural Network Algorithm in Adaptive Learning Management System",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "4",
        "cover_date": "2020-06-14",
        "Abstract": "The study aims to integrate neural network algorithm that predicts students' vulnerability of not having graduation on time to an adaptive learning management system. Neural network is one of the popular machine learning techniques because of its learning algorithm. The learning algorithm is focused on updating weights of the edges in order to produce minimal mean squared error between actual and predicted values. The integration of this platform could lead to much efficient learning management system as LMS is mainly driven to provide individualized and personalized learning tailored to specific requirements and learning preferences. The neural network algorithm is designed to classify students with learning difficulty so that administrators can formulate remediation and academic support policies.",
        "DOI": "10.1145/3402597.3402613",
        "paper_author": "Lagman A.C.",
        "affiliation_name": "FEU Institute of Technology",
        "affiliation_city": "Manila",
        "affiliation_country": "Philippines",
        "affiliation_id": "60110905",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "PartLy: Learning data partitioning for distributed data stream processing",
        "publication": "Proceedings of the 3rd International Workshop on Exploiting Artificial Intelligence Techniques for Data Management, aiDM 2020",
        "citied_by": "5",
        "cover_date": "2020-06-14",
        "Abstract": "Data partitioning plays a critical role in data stream processing. Current data partitioning techniques use simple, static heuristics that do not incorporate feedback about the quality of the partitioning decision (i.e., fire and forget strategy). Hence, the data partitioner often repeatedly chooses the same decision. In this paper, we argue that reinforcement learning techniques can be applied to address this problem. The use of artificial neural networks can facilitate learning of efficient partitioning policies. We identify the challenges that emerge when applying machine learning techniques to the data partitioning problem for distributed data stream processing. Furthermore, we introduce PartLy, a proof-of-concept data partitioner, and present preliminary results that indicate PartLy's potential to match the performance of state-of-the-art techniques in terms of partitioning quality, while minimizing storage and processing overheads.",
        "DOI": "10.1145/3401071.3401660",
        "paper_author": "Abdelhamid A.S.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60148675",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Learning fast and precise numerical analysis",
        "publication": "Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)",
        "citied_by": "19",
        "cover_date": "2020-06-11",
        "Abstract": "Numerical abstract domains are a key component of modern static analyzers. Despite recent advances, precise analysis with highly expressive domains remains too costly for many real-world programs. To address this challenge, we introduce a new data-driven method, called LAIT, that produces a faster and more scalable numerical analysis without significant loss of precision. Our approach is based on the key insight that sequences of abstract elements produced by the analyzer contain redundancy which can be exploited to increase performance without compromising precision significantly. Concretely, we present an iterative learning algorithm that learns a neural policy that identifies and removes redundant constraints at various points in the sequence. We believe that our method is generic and can be applied to various numerical domains. We instantiate LAIT for the widely used Polyhedra and Octagon domains. Our evaluation of LAIT on a range of real-world applications with both domains shows that while the approach is designed to be generic, it is orders of magnitude faster on the most costly benchmarks than a state-of-the-art numerical library while maintaining close-to-original analysis precision. Further, LAIT outperforms hand-crafted heuristics and a domain-specific learning approach in terms of both precision and speed.",
        "DOI": "10.1145/3385412.3386016",
        "paper_author": "He J.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Machine Learning for Fast Short-Term Energy Load Forecasting",
        "publication": "Proceedings - 2020 IEEE Conference on Industrial Cyberphysical Systems, ICPS 2020",
        "citied_by": "6",
        "cover_date": "2020-06-10",
        "Abstract": "Improved energy usage data from smart meters offers a unique opportunity to apply advanced analytics that can dramatically improve load forecasting. Utility companies, policy makers, and consumers benefit with better integration of renewables and overall energy management in the IoT digital age. Accurate short-term energy forecasting is essential to improving energy efficiency, reducing blackouts, and enabling smart grid control. In this work-in-progress (WIP) paper, we use individual residential load data to perform customer segmentation based on energy profiles, introduce a unique data segmentation and feature extraction technique based on inherent load signal periodicities, and use deep learning to perform fast and accurate short-term forecasting. Partnering with Prime Solutions Group, a veteran-owned company based in Arizona, we found that we could obtain up to a 12% improvement in hourly one-day forecasting using our custom data segmentation and feature extraction techniques with neural network methods.",
        "DOI": "10.1109/ICPS48405.2020.9274781",
        "paper_author": "Smith D.",
        "affiliation_name": "Sensor Signal and Information Processing (SenSIP) Center",
        "affiliation_city": "Tempe",
        "affiliation_country": "United States",
        "affiliation_id": "60093810",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Supporting robot application development using a distributed learning approach",
        "publication": "Proceedings - 2020 IEEE Conference on Industrial Cyberphysical Systems, ICPS 2020",
        "citied_by": "1",
        "cover_date": "2020-06-10",
        "Abstract": "Robot application developers program industrial robots during the commissioning or re-configuration of a production line. Not only do they require precise locations of work pieces and respective movements but also need to optimize program parameters manually. This often results in high engineering effort and stress. This paper introduces an approach to support robot application developers using distributed learning and machine learning to optimize robot application parameters in simulation. Contrary to end-to-end robot learning approaches which are often infeasible to adopt in practice, this approach leverages domain knowledge of application developers and their familiarity with writing robot programs. The developer is only additionally required to specify bounds for parameters to be optimized and an evaluation criterion. A central machine triggers as many worker machines as required to run simulations in parallel with different parameters to learn the best policy. Our approach works independent of the robot task and robot simulation software and can be configured with different algorithms. To validate the approach, it is applied to a robotic insertion task in an assembly scenario using a genetic algorithm and ABB RobotStudio.",
        "DOI": "10.1109/ICPS48405.2020.9274784",
        "paper_author": "Kotriwala A.",
        "affiliation_name": "ABB Corporate Research, Heidelberg",
        "affiliation_city": "Heidelberg",
        "affiliation_country": "Germany",
        "affiliation_id": "60072208",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Innovative use of data sources: A cross-sectional study of data linkage and artificial intelligence practices across European countries",
        "publication": "Archives of Public Health",
        "citied_by": "20",
        "cover_date": "2020-06-10",
        "Abstract": "Background: The availability of data generated from different sources is increasing with the possibility to link these data sources with each other. However, linked administrative data can be complex to use and may require advanced expertise and skills in statistical analysis. The main objectives of this study were to describe the current use of data linkage at the individual level and artificial intelligence (AI) in routine public health activities, to identify the related estimated health indicators (i.e., outcome and intervention indicators) and health determinants of non-communicable diseases and the obstacles to linking different data sources. Method: We performed a survey across European countries to explore the current practices applied by national institutes of public health, health information and statistics for innovative use of data sources (i.e., the use of data linkage and/or AI). Results: The use of data linkage and AI at national institutes of public health, health information and statistics in Europe varies. The majority of European countries use data linkage in routine by applying a deterministic method or a combination of two types of linkages (i.e., deterministic & probabilistic) for public health surveillance and research purposes. The use of AI to estimate health indicators is not frequent at national institutes of public health, health information and statistics. Using linked data, 46 health outcome indicators, 34 health determinants and 23 health intervention indicators were estimated in routine. The complex data regulation laws, lack of human resources, skills and problems with data governance, were reported by European countries as obstacles to routine data linkage for public health surveillance and research. Conclusions: Our results highlight that the majority of European countries have integrated data linkage in their routine public health activities but only a few use AI. A sustainable national health information system and a robust data governance framework allowing to link different data sources are essential to support evidence-informed health policy development. Building analytical capacity and raising awareness of the added value of data linkage in national institutes is necessary for improving the use of linked data in order to improve the quality of public health surveillance and monitoring activities.",
        "DOI": "10.1186/s13690-020-00436-9",
        "paper_author": "Haneef R.",
        "affiliation_name": "Santé Publique France",
        "affiliation_city": "Saint-Maurice",
        "affiliation_country": "France",
        "affiliation_id": "60139055",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Non-linear Interactions Driving Food Security of Smallholder Farm Households in the Western Highlands of Guatemala",
        "publication": "Frontiers in Sustainable Food Systems",
        "citied_by": "5",
        "cover_date": "2020-06-10",
        "Abstract": "In the western highlands of Guatemala, the indigenous population is one of the most marginalized communities. The food security of subsistence and infrasubsistence smallholders within this population still relies on domestic agricultural production as the principal livelihood activity and the main source of food. Smallholder production systems in the region are complex, with multiple interacting subsystems functioning at different integration levels and with different temporal dynamics. Previous results, based on a data set of nearly 5,000 farm households using a robust food availability indicator (that quantifies agricultural production, consumption, transformation, and commercialization of produce), have shown large differences in food security between farmers in the western highlands of Guatemala. Another important finding was that more than half of the farm households do not have the means to produce enough energy for home consumption from their agricultural activities. Identifying the constraints, patterns, and underlying processes driving food security could give rise to a set of easy-to-measure variables that quickly and reliably assess household food security status; such a tool would be helpful for decision and policy makers trying to focus on actions more likely to succeed in improving food security in the region. In this study, we developed a predictive model of food security, through the application of machine learning techniques, to identify the most important factors, and their interactions, which account for variability in food security. The resulting “artificial neural network” model performed well, explaining nearly 85% of the variance in food security status. By applying different sensitivity analysis methods, we were able to detect highly non-linear interactions between the different factors driving food security. Land availability per person is detected as the main constraint for attaining food security. The median value of land availability per person in the region is 0.085 ha, explaining why 52% of the farm household population does not produce enough food energy from agriculture. Many other interactions were found between crop land allocation, diversity, yields, and food security, which can help to target interventions to improve the food security status in the region.",
        "DOI": "10.3389/fsufs.2020.00051",
        "paper_author": "Barba-Escoto L.",
        "affiliation_name": "Centro Internacional de Mejoramiento de Maiz y Trigo",
        "affiliation_city": "Texcoco",
        "affiliation_country": "Mexico",
        "affiliation_id": "60015079",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Declarative access control for aggregations of multiple ownership data",
        "publication": "Proceedings of ACM Symposium on Access Control Models and Technologies, SACMAT",
        "citied_by": "2",
        "cover_date": "2020-06-10",
        "Abstract": "Data aggregation operations are popular in domains like data analytics, machine learning and artificial intelligence. However, despite the availability of information, situations like fragmented ownership and legal frameworks hinder data processing, requiring companies to design complex human-driven processes in order to gather, aggregate, and process data in a compliant way. Our proposal addresses this lack of automation with an access control mechanism extending XACML, an access control standard with language and implementation, to regulate operations with multiple data policies.",
        "DOI": "10.1145/3381991.3395609",
        "paper_author": "Rosa M.",
        "affiliation_name": "Università degli Studi di Bergamo",
        "affiliation_city": "Bergamo",
        "affiliation_country": "Italy",
        "affiliation_id": "60005254",
        "affiliation_state": "BG"
    },
    {
        "paper_title": "ABAC-CC: Attribute-based access control and communication control for internet of things",
        "publication": "Proceedings of ACM Symposium on Access Control Models and Technologies, SACMAT",
        "citied_by": "42",
        "cover_date": "2020-06-10",
        "Abstract": "Internet of Things (IoT) is revolutionizing the capabilities of the Internet with billions of connected devices in the cyberspace. These devices are commonly referred to as smart things enabling smart environments, such as Smart Home, Smart Health, Smart Transportation, and overall Smart Communities, together with key enabling technologies like Cloud Computing, Artificial Intelligence (AI) and Machine Learning (ML). Security and privacy are major concerns for today's diverse autonomous IoT ecosystem. Autonomous things and a large amount of data associated with things have fueled significant research in IoT access control and privacy in both academia and industry. To enable futuristic IoT with sustainable growth, dynamic access and communication control framework that adequately addresses security and privacy issues in IoT is inevitable. In this paper, we analyze the access and communication control requirements in Cloud-Enabled IoT (CE-IoT) and propose an attribute-based framework for access control and communication control, known as ABAC-CC, to secure accesses and communications (data flow) between various entities in the IoT architecture. We also introduce a novel Attribute-Based Communication Control (ABCC) model, which focuses on securing communications and data flow in IoT and enables users to define privacy policies using attributes of various entities. Furthermore, we analyze the applicability of ABAC-CC in specific IoT application domains, and finally, we present future research directions in the context of Cloud and Edge computing enabled IoT platforms.",
        "DOI": "10.1145/3381991.3395618",
        "paper_author": "Bhatt S.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States",
        "affiliation_id": "60143652",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Antagonistic bias: developing a typology of agonistic talk on Twitter using gun control networks",
        "publication": "Online Information Review",
        "citied_by": "5",
        "cover_date": "2020-06-09",
        "Abstract": "Purpose: The purpose of this paper is to apply Connolly’s (2003) concept of agonistic respect to develop a typology of agonistic/antagonistic discourses on Twitter. To develop the typology, this study examines 2,236 Tweets containing the hashtag #guncontrol and uses NodeXL (Smith et al., 2010) to create a network map from which the 75 most influential accounts are derived. Using constant-comparative analysis (Glaser and Strauss, 1967), the authors identify seven categories of discourse style based on Connoly’s (2001) notion of ressentiment and “good faith presentations” of opposing arguments: furtive/secretive, cravenly opportunistic, willfully ignorant, irrational sentimental, misunderstanding/misguided, contingently wrong and reciprocal inquiry. The typology provides a useful and unique way to operationalize agonistic democratic theory and serves as the possible basis for training a machine learning classifier to detect antagonistic discourses on social media platforms. Design/methodology/approach: To determine the level of agonism on Twitter, the authors examine tweets that employed the hashtag #guncontrol on March 12, 2018, one month after the shooting at the Marjory Stoneman Douglass High School in Parkland, Florida on February 14. The authors used the NodeXL excel add-on to collect and map 2,236 tweets. Using grounded theory/constant-comparative analysis (Glaser and Strauss, 1967), the authors develop a typology of seven types of discourses ordered from most antagonistic to most agonistic using Connolly’s (1993) concept of agonistic respect. Findings: After examining the top 75 most shared tweets and using constant-comparative analysis to look for patterns of similarity and dissimilarity, the authors identified seven different ways in which individuals present their opponents’ value positions on Twitter on the issue of gun control. The authors were guided by agonistic theory in the authors’ inquiry. The authors looked at how Twitter users expressed their opponent’s faith/value positions, how pluralistic the discourse space was in the comment threads and how much the “talk” was likely to elicit ressentiment from adversaries. Research limitations/implications: Because the authors intended to engage in theory building, the authors limited the analysis to a selected number of tweets on one particularly salient topic, on one day. The intent of this was to allow for a close reading of the tweets in that specific network for the purposes of creating a useful typology that can be applied to a broader range of cases/issues/platforms. Practical implications: The authors hope that typology could serve as a potential starting point for Twitter to think about how it could design its algorithms toward agonistic talk. The typology could be used as a classification scheme to differentiate agonistic from antagonistic threads. An algorithm could be trained to spot threads overwhelmingly populated by antagonistic discourse and instructed to insert posts from other threads that represent agonistic responses like “contingently wrong” or “reciprocal inquiry.” While generous presentations or deeper, more nuanced presentations of the opponent’s value position are not a panacea, they could serve to change the orientation by which users engage with policy issues. Social implications: Social media platforms like Twitter have up to now been left alone to make markets and establish profitability off of public sphere conversations. The result has been a lack of attention to how discourse on these platforms affects users mental well-being, community health and democratic viability. Recently, Twitter’s CEO has indicated a need to rethink the ways in which it promotes “healthy discourse.” The utilitarian presumption that, left to our own devices, we will trial and error our way to the collective good does not account for the importance of others in refining one’s preferences, arguments and world views. Without an “other” to vet ideas and lead us toward becoming wiser, we are left with a Wyly antagonism that moves discourse further and further away from agonistic respect and toward antagonistic virtual struggle. Platforms that allow antagonistic talk that breeds ressentiment run the risk of irrevocably damaging democracy through poisoning its public sphere. Originality/value: This paper is unique in providing a typology/framework for thinking about the types of “political talk” that exists on Twitter. By using agonistic political theory as a framework, the authors are able to establish some guiding principles for “good political talk” that acknowledges the incommensurability of value positions on issues like gun control. The typology’s emphasis on agonistic respect, ressentiment and generosity in the presentation of alternative value positions provides a starting point from which to map and catalog discourse on Twitter more generally and offers a normative model for changing algorithmic design.",
        "DOI": "10.1108/OIR-11-2018-0338",
        "paper_author": "Marichal J.",
        "affiliation_name": "California Lutheran University",
        "affiliation_city": "Thousand Oaks",
        "affiliation_country": "United States",
        "affiliation_id": "60014209",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "The mental health status of asylum seekers in middle to high income countries and the potential application of artificial intelligence for diagnosis and management of glaucoma in adults",
        "publication": "British Medical Bulletin",
        "citied_by": "0",
        "cover_date": "2020-06-08",
        "Abstract": "NA",
        "DOI": "10.1093/bmb/ldaa016",
        "paper_author": "Vetter N.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Actor-critic sequence generation for relative difference captioning",
        "publication": "ICMR 2020 - Proceedings of the 2020 International Conference on Multimedia Retrieval",
        "citied_by": "8",
        "cover_date": "2020-06-08",
        "Abstract": "This paper investigates a new task named relative difference caption which aims to generate a sentence to tell the difference between the given image pair. Difference description is a crucial task for developing intelligent machines that can understand and handle changeable visual scenes and applications. Towards that end, we propose a reinforcement learning-based model, which utilizes a policy network and a value network in a decision procedure to collaboratively produce a difference caption. Specifically, the policy network works as an actor to estimate the probability of next word based on the current state and the value network serves as a critic to predict all possible extension values according to current action and state. To encourage generating correct and meaningful descriptions, we leverage a visual-linguistic similarity-based reward function as feedback. Empirical results on the recently released dataset demonstrate the effectiveness of our method in comparison with various baselines and model variants.",
        "DOI": "10.1145/3372278.3390679",
        "paper_author": "Fei Z.",
        "affiliation_name": "Institute of Computing Technology Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60030904",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Qualitative and quantitative approach to assess of the potential for automating administrative tasks in general practice",
        "publication": "BMJ open",
        "citied_by": "21",
        "cover_date": "2020-06-08",
        "Abstract": "OBJECTIVE: To identify the extent to which administrative tasks carried out by primary care staff in general practice could be automated. DESIGN: A mixed-method design including ethnographic case studies, focus groups, interviews and an online survey of automation experts. SETTING: Three urban and three rural general practice health centres in England selected for differences in list size and organisational characteristics. PARTICIPANTS: Observation and interviews with 65 primary care staff in the following job roles: administrator, manager, general practitioner, healthcare assistant, nurse practitioner, pharmacy technician, phlebotomist, practice nurse, pharmacist, prescription clerk, receptionist, scanning clerk, secretary and medical summariser; together with a survey of 156 experts in automation technologies. METHODS: 330 hours of ethnographic observation and documentation of administrative tasks carried out by staff in each of the above job roles, followed by coding and classification; semistructured interviews with 10 general practitioners and 6 staff focus groups. The online survey of machine learning, artificial intelligence and robotics experts was analysed using an ordinal Gaussian process prediction model to estimate the automatability of the observed tasks. RESULTS: The model predicted that roughly 44% of administrative tasks carried out by staff in general practice are 'mostly' or 'completely' automatable using currently available technology. Discussions with practice staff underlined the need for a cautious approach to implementation. CONCLUSIONS: There is considerable potential to extend the use of automation in primary care, but this will require careful implementation and ongoing evaluation.",
        "DOI": "10.1136/bmjopen-2019-032412",
        "paper_author": "Willis M.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175816",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Who performs better? AVMs vs hedonic models",
        "publication": "Journal of Property Investment and Finance",
        "citied_by": "52",
        "cover_date": "2020-06-08",
        "Abstract": "Purpose: In the literature there are numerous tests that compare the accuracy of automated valuation models (AVMs). These models first train themselves with price data and property characteristics, then they are tested by measuring their ability to predict prices. Most of them compare the effectiveness of traditional econometric models against the use of machine learning algorithms. Although the latter seem to offer better performance, there is not yet a complete survey of the literature to confirm the hypothesis. Design/methodology/approach: All tests comparing regression analysis and AVMs machine learning on the same data set have been identified. The scores obtained in terms of accuracy were then compared with each other. Findings: Machine learning models are more accurate than traditional regression analysis in their ability to predict value. Nevertheless, many authors point out as their limit their black box nature and their poor inferential abilities. Practical implications: AVMs machine learning offers a huge advantage for all real estate operators who know and can use them. Their use in public policy or litigation can be critical. Originality/value: According to the author, this is the first systematic review that collects all the articles produced on the subject done comparing the results obtained.",
        "DOI": "10.1108/JPIF-12-2019-0157",
        "paper_author": "Valier A.",
        "affiliation_name": "Università degli Studi di Padova",
        "affiliation_city": "Padua",
        "affiliation_country": "Italy",
        "affiliation_id": "60000481",
        "affiliation_state": "PD"
    },
    {
        "paper_title": "Deep deterministic policy gradient for portfolio management",
        "publication": "Colloquium in Information Science and Technology, CIST",
        "citied_by": "5",
        "cover_date": "2020-06-05",
        "Abstract": "Portfolio management is a financial problem that has been the subject of much research over the years. It is a planning task where an agent constantly redistributes resources across a set of assets in order to achieve investment objectives and thereby maximize return. However, it remains difficult to obtain an optimal strategy in an environment as complex and dynamic as the financial market. Our article focuses on solving this stochastic control problem in order to obtain an optimal strategy that would allow us to make profitable decisions by interacting directly with the environment. To do this, we explore the power of deep reinforcement learning which differs from traditional Machine Learning by combining the task of predicting stock behavior and analyzing the optimal course of action in a single unit, thus aligning the problem of Machine Learning with the investor's objectives. As a method, we propose to use the Deep Deterministic Policy Gradient which is an off-policy algorithm and is used for environments with continuous action spaces. The obtained results demonstrate that the model achieves a higher rate of return than the strategy of 'Uniform Buy and Hold' stocks and the strategy of 'Buy Best Stock in last month'.",
        "DOI": "10.1109/CiSt49399.2021.9357266",
        "paper_author": "Khemlichi F.",
        "affiliation_name": "Université Sidi Mohamed Ben Abdellah",
        "affiliation_city": "Fez",
        "affiliation_country": "Morocco",
        "affiliation_id": "60017021",
        "affiliation_state": "Fes-Meknes"
    },
    {
        "paper_title": "2020 5th International Conference on Intelligent Computing and Signal Processing, ICSP 2020",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2020-06-02",
        "Abstract": "The proceedings contain 202 papers. The topics discussed include: research on machine learning and its algorithms and development; seismic exploration device based on time-frequency space algorithm; the discussion on application of underground pipeline 3D information system in college's repair project; text analysis of cross-border e-commerce policy based on co-word clustering method: a case study of Gansu Province; autocorrelation and limited sampling algorithm with fixed packet length in period measurement; research on robot dynamic handling system based on machine vision and online tracking technology; three-dimensional reconstruction filtering algorithm based on single ray picture of pipe welds; least-squares method for the diffraction problem of strip gratings; evaluation of deep learning models for Urdu handwritten characters recognition; and orthodontic path planning method based on optimized artificial bee colony algorithm.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Object-based random forest classification for informal settlements identification in the Middle East: Jeddah a case study",
        "publication": "International Journal of Remote Sensing",
        "citied_by": "28",
        "cover_date": "2020-06-02",
        "Abstract": "The identification of informal settlements in urban areas is an important step in developing and implementing pro-poor urban policies. Understanding when, where and who lives inside informal settlements is critical in efforts to improve their resilience. This study aims to analyse the capability of machine-learning (ML) methods to map informal settlement areas in Jeddah, Saudi Arabia, using very-high-resolution (VHR) imagery and terrain data. Fourteen indicators of settlement characteristics were derived and mapped using an object-based ML approach and VHR imagery. These indicators were categorized according to three different spatial levels: environ, settlement and object. The most useful indicators for prediction were found to be density and texture measures, (with random forest (RF) relative importance measures of over 25% and 23% respectively). The success of this approach was evaluated using a small, fully independent validation dataset. Informal areas were mapped with an overall accuracy of 91%. Object-based ML as a processing chain approach performed better (8%) than object-based image analysis alone due to its ability to encompass all available geospatial levels.",
        "DOI": "10.1080/01431161.2020.1718237",
        "paper_author": "Fallatah A.",
        "affiliation_name": "King Abdulaziz University",
        "affiliation_city": "Jeddah",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60004582",
        "affiliation_state": "Makkah al Mukarramah"
    },
    {
        "paper_title": "Applied econometric analysis: Emerging research and opportunities",
        "publication": "Applied Econometric Analysis: Emerging Research and Opportunities",
        "citied_by": "1",
        "cover_date": "2020-06-01",
        "Abstract": "Professionals are constantly searching for competitive solutions to help determine current and future economic tendencies. Econometrics uses statistical methods and real-world data to predict and establish specific trends within business and finance. This analytical method sustains limitless potential, but the necessary research for professionals to understand and implement this approach is lacking. Applied Econometric Analysis: Emerging Research and Opportunities explores the theoretical and practical aspects of detailed econometric theories and applications within economics, political science, public policy, business, and finance. Featuring coverage on a broad range of topics such as cointegration, machine learning, and time series analysis, this book is ideally designed for economists, policymakers, financial analysts, marketers, researchers, academicians, and graduate students seeking research on the various techniques of econometric concepts.",
        "DOI": "10.4018/978-1-7998-1093-3",
        "paper_author": "Sloboda B.W.",
        "affiliation_name": "University of Phoenix",
        "affiliation_city": "Phoenix",
        "affiliation_country": "United States",
        "affiliation_id": "60027183",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "The Role of Higher Education in Developing Policy and Practice for the Development of the New Industrial Age",
        "publication": "Journal of Higher Education Policy and Leadership Studies",
        "citied_by": "2",
        "cover_date": "2020-06-01",
        "Abstract": "This article discusses a problem that education must address if it is to prepare people adequately for the new industrial age. Intelligent machines are rapidly taking over routine tasks both at home and work. New competencies are demanded now that we are becoming released from practices that have traditionally occupied time. This gives opportunity to communicate across disciplines to solve the challenging problems of today’s world, like climate change, inequality and rapid people movements. It is exciting times as we move into the third decade of 2020. However, we need a more holistic approach to education at all levels- realising that personal, transferable intelligence need as much attention as academic ones in formal learning. In Higher Education (HE), a Practitioner Doctorate now compliments traditional Research models – sponsored by the United States of America (USA) Carnegie Foundation in universities. This produces leaders able to investigate their own work contexts, with ability to change policy and practice to improve performances that are relevant to the local area.",
        "DOI": "10.29252/johepal.1.1.64",
        "paper_author": "Sage R.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Review of Model-Based Reinforcement Learning",
        "publication": "Journal of Frontiers of Computer Science and Technology",
        "citied_by": "8",
        "cover_date": "2020-06-01",
        "Abstract": "Deep reinforcement learning (DRL) as an important learning paradigm in the field of machine learning, has received increasing attentions after AlphaGo defeats the human. DRL interacts with the environment by trials and errors, and obtains the optimal policy by maximizing the cumulative reward. Reinforcement learning can be divided into two categories: model-free reinforcement learning and model-based reinforcement learning. The training process of model-free reinforcement learning needs a large number of samples. It is difficult for model-free reinforcement learning to get good performance when the sampling budget is limited, and a large number of samples cannot be collected. However, model-based reinforcement learning can reduce the real sample demand and improve the data efficiency through making full use of the environment model. This paper focuses on the field of model-based reinforcement learning, introduces its research status, investigates its classical algorithms, and discusses future development trend and application prospect.",
        "DOI": "10.3778/j.issn.1673-9418.1912040",
        "paper_author": "Zhao T.",
        "affiliation_name": "Tianjin University of Science &amp; Technology",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60092437",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The Law and Political Economy of Workplace Technological Change",
        "publication": "Harvard Civil Rights-Civil Liberties Law Review",
        "citied_by": "18",
        "cover_date": "2020-06-01",
        "Abstract": "This Article explores how labor and employment laws shape workplace technological change. It focuses on emerging data-driven technologies such as machine learning, the branch of artificial intelligence that has sparked widespread concern about the future of work. The Article argues that labor and employment laws shape employers’ technological choices in two ways. First, those laws help to facilitate technological development by granting employers broad rights to gather workplace data, to develop new technologies using that data, and to implement those technologies into the workplace, typically regardless of workers’ preferences. Second, those laws channel technological development in certain directions, in particular by encouraging companies to use technologies to exert power over workers and therefore cut labor costs. This analysis has policy implications. Among other things, it suggests that ensuring a decent future of work may require reforms to guarantee workers a voice in the development and deployment of workplace technologies. The Article also argues that automation, while a real and important phenomenon, is not the most important challenge facing workers now or in the foreseeable future.",
        "DOI": "NA",
        "paper_author": "Rogers B.",
        "affiliation_name": "Temple University",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60030398",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Powertrain Control for Hybrid-Electric Vehicles Using Supervised Machine Learning",
        "publication": "Vehicles",
        "citied_by": "19",
        "cover_date": "2020-06-01",
        "Abstract": "This paper presents a novel framework to enable automatic re-training of the supervisory powertrain control strategy for hybrid electric vehicles using supervised machine learning. The aim of re-training is to customize the control strategy to a user-specific driving behavior without human intervention. The framework is designed to update the control strategy at the end of a driving task. A combination of dynamic programming and supervised machine learning is used to train the control strategy. The trained control strategy denoted as SML is compared to an online-implementable strategy based on the combination of the optimal operation line and Pontryagin’s minimum principle denoted as OOL-PMP, on the basis of fuel consumption. SML consistently performed better than OOL-PMP, evaluated over five standard drive cycles. The EUDC performance was almost identical while on FTP75 the OOL-PMP consumed 14.7% more fuel than SML. Moreover, the deviation from the global benchmark obtained from dynamic programming was between 1.8% and 5.4% for SML and between 5.8% and 16.8% for OOL-PMP. Furthermore, a test-case was conducted to emulate a real-world driving scenario wherein a trained controller is exposed to a new drive cycle. It is found that the performance on the new drive cycle deviates significantly from the optimal policy; however, this performance gap is bridged with a single re-training episode for the respective test-case.",
        "DOI": "10.3390/vehicles2020015",
        "paper_author": "Harold C.K.D.",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60032882",
        "affiliation_state": "Noord-Brabant"
    },
    {
        "paper_title": "Efficient utilization of virtual instances by suspend resume strategy in cloud data center",
        "publication": "Journal of Scientific and Industrial Research",
        "citied_by": "1",
        "cover_date": "2020-06-01",
        "Abstract": "The effective utilization of virtual instances by suspend resume policy in virtualized data center is analyzed in this paper. Cloud computing is a term that describes the means of delivering all information technology from computing power to computing infrastructure, applications, business process and personal collaboration to end users as a service wherever and whenever they need it. Here Infrastructure as a Service is used for open source cloud implementation. Open Stack provides architecture for cloud to build the virtual instances. Thus Virtual Machine allocates a single job, by dividing them to the grid systems. Suspend resume policy is used to provide the jobs to the virtual instances based on the usage. It helps in examining the weight flanked by the virtual instances as job arrived.",
        "DOI": "NA",
        "paper_author": "Kumar A.N.",
        "affiliation_name": "CMR Institute of Technology, Hyderabad",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India",
        "affiliation_id": "60109987",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Predictive Maintenance for Edge-Based Sensor Networks: A Deep Reinforcement Learning Approach",
        "publication": "IEEE World Forum on Internet of Things, WF-IoT 2020 - Symposium Proceedings",
        "citied_by": "27",
        "cover_date": "2020-06-01",
        "Abstract": "Failure of mission-critical equipment interrupts production and results in monetary loss. The risk of unplanned equipment downtime can be minimized through Predictive Maintenance of revenue generating assets to ensure optimal performance and safe operation of equipment. However, the increased sensorization of the equipment generates a data deluge, and existing machine-learning based predictive model alone becomes inadequate for timely equipment condition predictions. In this paper, a model-free Deep Reinforcement Learning algorithm is proposed for predictive equipment maintenance from an equipment-based sensor network context. Within each equipment, a sensor device aggregates raw sensor data, and the equipment health status is analyzed for anomalous events. Unlike traditional black-box regression models, the proposed algorithm self-learns an optimal maintenance policy and provides actionable recommendation for each equipment. Our experimental results demonstrate the potential for broader range of equipment maintenance applications as an automatic learning framework.",
        "DOI": "10.1109/WF-IoT48130.2020.9221098",
        "paper_author": "Hoong Ong K.S.",
        "affiliation_name": "School of Computer Science and Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60078616",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Improving Sample Efficiency and Multi-Agent Communication in RL-based Train Rescheduling",
        "publication": "Proceedings - 2020 7th Swiss Conference on Data Science, SDS 2020",
        "citied_by": "4",
        "cover_date": "2020-06-01",
        "Abstract": "We present preliminary results from our sixth placed entry to the Flatland international competition for train rescheduling, including two improvements for optimized reinforcement learning (RL) training efficiency, and two hypotheses with respect to the prospect of deep RL for complex real-world control tasks: first, that current state of the art policy gradient methods seem inappropriate in the domain of high-consequence environments; second, that learning explicit communication actions (an emerging machine-to-machine language, so to speak) might offer a remedy. These hypotheses need to be confirmed by future work. If confirmed, they hold promises with respect to optimizing highly efficient logistics ecosystems like the Swiss Federal Railways railway network.",
        "DOI": "10.1109/SDS49233.2020.00024",
        "paper_author": "Roost D.",
        "affiliation_name": "ZHAW Zurich University of Applied Sciences",
        "affiliation_city": "Winterthur",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60015769",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Machine learning for rotating machines: Simulation, diagnosis and control",
        "publication": "Vibroengineering Procedia",
        "citied_by": "1",
        "cover_date": "2020-06-01",
        "Abstract": "The goal of this work is association of several machine learning methods in a study of rotating machines with fluid-film bearings. A fitting method is applied to fit a non-linear reaction force in a bearing and solve a rotor dynamics problem. The solution in the form of a simulation model of a rotor machine has become a part of a control system based on reinforcement learning and the policy gradient method. Experimental part of the paper deals with a pattern recognition and fault diagnosis problem. All the methods are effective and accurate enough.",
        "DOI": "10.21595/vp.2020.21549",
        "paper_author": "Kornaev A.",
        "affiliation_name": "Orel State University",
        "affiliation_city": "Orel",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60070544",
        "affiliation_state": "Oryol Oblast"
    },
    {
        "paper_title": "ICRITO 2020 - IEEE 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)",
        "publication": "ICRITO 2020 - IEEE 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)",
        "citied_by": "0",
        "cover_date": "2020-06-01",
        "Abstract": "The proceedings contain 270 papers. The topics discussed include: performance analysis of fuel cell using PI controller; performance analysis of machine learning algorithms in credit cards fraud detection; a comprehensive approach for DDoS attack detection in smart home network using shortest path algorithm; implementation of low cost real-time attendance management system: a comparative study; design and development of voice controllable wheelchair; application of machine learning to predict hospital churning; satellite constellation stationing effects on communication networks; leveraging latest developments for delivering patient-centric healthcare to diabetic patients; pricing and inventory policy for deteriorating item in a two-echelon supply chain: a Stackelberg duopoly game approach; designing of facial emotion recognition system based on machine learning; and software defect categorization based on maintenance effort and change impact using multinomial naïve bayes algorithm.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Survey on Fake Profile Detection on Social Sites by Using Machine Learning Algorithm",
        "publication": "ICRITO 2020 - IEEE 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)",
        "citied_by": "18",
        "cover_date": "2020-06-01",
        "Abstract": "To avoid the spam message, malicious and cyber bullies activities which are mostly done by the fake profile. These activities challenge the privacy policies of the social network communities. These fake profiles are responsible for spread false information on social communities. To identify the fake profile, duplicate, spam and bots account there is much research work done in this area. By using a machine-learning algorithm, most of the fake accounts detected successfully. This paper represents the review of Fake Profile Detection on Social Site by Using Machine Learning.",
        "DOI": "10.1109/ICRITO48877.2020.9197935",
        "paper_author": "Patel K.",
        "affiliation_name": "Madan Mohan Malaviya University of Technology",
        "affiliation_city": "Gorakhpur",
        "affiliation_country": "India",
        "affiliation_id": "60079433",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Development of a market trend evaluation system for policy making",
        "publication": "Journal of Competitiveness",
        "citied_by": "5",
        "cover_date": "2020-06-01",
        "Abstract": "The previous economic crisis has increased the attention of government to focus their activities more on economic stability. The development of government subsidies requires an analytically based analysis, one which would identify problematic areas of regional development more precisely. However, to monitor market changes in a highly dynamic market is time consuming and inefficient. Without proper market monitoring, the level of competitiveness within regions might decrease in the long run. Thus, the goal of the article is to establish the framework of a market trend monitoring system. To achieve this goal, the research methodology consists of a scientific literature analysis, an analysis of available data infrastructure for market trend analysis, and a statistical analysis together with a machine learning approach. The authors of the publication propose a market monitoring framework which would provide an infrastructure for evidence-based policy recommendations for government institutes and might provide guidelines of how to increase their competitiveness. A case study of real estate data and macroeconomic indicators of Lithuania was conducted, during which a clustering algorithm was applied to identify groups in Lithuania. The 60 municipalities of Lithuania were grouped into 4 clusters in terms of noteworthy relationships between industrial development and population size. In 3 of the clusters, the relationship of industrial growth and population was direct. In cluster 4, however, the relationship was opposite, a result which requires a further analysis of infrastructure and industrial sectors to provide more precise policy recommendations. The theoretical contribution and findings from the case study provides grounding to develop the market monitoring system.",
        "DOI": "10.7441/joc.2020.02.02",
        "paper_author": "Gruzauskas V.",
        "affiliation_name": "Kaunas University of Technology",
        "affiliation_city": "Kaunas",
        "affiliation_country": "Lithuania",
        "affiliation_id": "60042282",
        "affiliation_state": "Kaunas"
    },
    {
        "paper_title": "Research on Systematic Risk Early Warning System Based on Machine Learning Technology: A Case Study of Marine Economy",
        "publication": "Journal of Coastal Research",
        "citied_by": "3",
        "cover_date": "2020-06-01",
        "Abstract": "With the rapid development of information technology, the value contained in big data has attracted more and more attention. Conducting efficient analysis of big data has become an important topic. Machine learning is one of the commonly used methods for data analysis. The traditional machine learning algorithm is often designed as the way of offline batch training. However, this method is not suitable for data sets with massive scale and continuous growth in the big data environment. Transforming the traditional machine learning algorithm so that it can better apply to the big data environment has become a research hotspot. With the rapid development of economy and society and the continuous progress of science and technology, the public's understanding of ocean functions is gradually deepened, the demand for marine products and services is increasing every day, and the economic and social benefits of the ocean are continuously rising. In this context, great importance should be given to the examination of marine resources and environment, the development and utilization of work, the constant adjusting of the ocean economic development policy, and the variety of comprehensive marine management measures to ensure the sustainable development of implementation of marine programs. The current mainstream of machine learning technology based on the marine economy of systemic risk early warning system for research is proposed here.",
        "DOI": "10.2112/JCR-SI108-045.1",
        "paper_author": "Zhao J.",
        "affiliation_name": "Harbin Engineering University",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60003353",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Reinforcement learning for attack mitigation in SDN-enabled networks",
        "publication": "Proceedings of the 2020 IEEE Conference on Network Softwarization: Bridging the Gap Between AI and Network Softwarization, NetSoft 2020",
        "citied_by": "30",
        "cover_date": "2020-06-01",
        "Abstract": "With the recent progress in the development of low-budget sensors and machine-to-machine communication, the Internet-of-Things has attracted considerable attention. Unfortunately, many of today's smart devices are rushed to market with little consideration for basic security and privacy protection making them easy targets for various attacks. Unfortunately, organizations and network providers use mostly manual workflows to address malware-related incidents and therefore they are able to prevent neither attack damage nor potential attacks in the future. Thus, there is a need for a defense system that would not only detect an intrusion on time, but also would make the most optimal real-time crisis-action decision on how the network security policy should be modified in order to mitigate the threat. In this study, we are aiming to reach this goal relying on advanced technologies that have recently emerged in the area of cloud computing and network virtualization. We are proposing an intelligent defense system implemented as a reinforcement machine learning agent that processes current network state and takes a set of necessary actions in form of software-defined networking flows to redirect certain network traffic to virtual appliances. We also implement a proof-of-concept of the system and evaluate a couple of state-of-art reinforcement learning algorithms for mitigating three basic network attacks against a small realistic network environment.",
        "DOI": "10.1109/NetSoft48620.2020.9165383",
        "paper_author": "Zolotukhin M.",
        "affiliation_name": "University of Jyväskylä",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland",
        "affiliation_id": "60032398",
        "affiliation_state": "Central Finland"
    },
    {
        "paper_title": "Fault pattern recognition in power distribution integrated network with renewable energy source",
        "publication": "2020 5th International Conference on Renewable Energies for Developing Countries, REDEC 2020",
        "citied_by": "6",
        "cover_date": "2020-06-01",
        "Abstract": "The challenge with most developing countries is to maintain a reliable and sustainable electricity supply. This has a depleting effect on the economic development of most states. In order to reduce the impact of energy shortages, there has been an extensive attempt to use renewable energy sources to generate electricity. There are however technical challenges of integrating the existing power system grid with the renewable external sources. These challenges include adequate power system protection, energy security, and reliability of external sources. In this paper, we investigate the fault pattern recognition and detection in a power distribution grid integrated with the wind energy source. A reduced Eskom 22kV and wind power energy source integrated is modeled using MATLAB/Simulink. From the integrated model, various types of power systems faults are generated. We further investigated the use of local polynomial approximation (LPA) for signal decomposition and support vector machine (SVM) for fault classification and detection. We also tested the performance of the naive Bayes classifier. In this paper, a hybrid technique based on LPA and SVM is proposed for fault pattern recognition and detection in a power distribution integrated system with the wind energy source. The proposed method was further tested using machine learning platforms WEKA and Orange. The results of the classifiers gave the accuracy of between 98 and 99 %.",
        "DOI": "10.1109/REDEC49234.2020.9163596",
        "paper_author": "Moloi K.",
        "affiliation_name": "Tshwane University of Technology",
        "affiliation_city": "Pretoria",
        "affiliation_country": "South Africa",
        "affiliation_id": "60006393",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "Intent-based control loop for DASH video service assurance using ML-based edge QoE estimation",
        "publication": "Proceedings of the 2020 IEEE Conference on Network Softwarization: Bridging the Gap Between AI and Network Softwarization, NetSoft 2020",
        "citied_by": "23",
        "cover_date": "2020-06-01",
        "Abstract": "Intent-Based Networking (IBN) proposals are based on autonomous closed-loop orchestration architectures that monitor and tune network performance. To this end, IBN defines high-level policies and actions implemented by a closed-loop system. This work demonstrates a Closed Control Loop (CCL) architecture for video service assurance using Machine Learning (ML) based Quality of Experience (QoE) estimation at edge nodes. As part of the solution, network-level Quality of Service (QoS) metrics patterns (e.g., RTT, Throughput) collected through flow-level monitoring are used to build a QoS-to-QoE correlation model tailored to specific target network regions, user groups, and services, in our case DASH video streaming. The demo will showcase the CCL workflow triggering the Orchestrator to take appropriate network-level actions to overcome network QoS degradations and restore the QoE target based on the intent associated with the video service.",
        "DOI": "10.1109/NetSoft48620.2020.9165375",
        "paper_author": "Rothenberg C.E.",
        "affiliation_name": "Universidade Estadual de Campinas",
        "affiliation_city": "Campinas",
        "affiliation_country": "Brazil",
        "affiliation_id": "60029570",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "Semi-Supervised learning approach for optimizing condition-based-maintenance (CBM) decisions",
        "publication": "Proceedings of the Annual Conference of the Prognostics and Health Management Society, PHM",
        "citied_by": "3",
        "cover_date": "2020-06-01",
        "Abstract": "Recent heightened enthusiasm towards Industrial Artificial Intelligence (IAI) and Industrial Internet of Things (IIoT) coupled with developments in smart sensor technologies have resulted in simultaneous incorporation of several advanced Condition Monitoring (CM) technologies within manufacturing and industrial sectors. Efficient utilization of CM data leads to enhanced safety, reliability and availability of manufacturing systems. In this regard, the paper proposes an efficient and novel hybrid Maintenance Decision Support System (MDSS) for fault diagnostic and prognostic considering CM data along with event-triggered data. The proposed MDSS model is a hybrid Machine Learning (ML)-based solution coupled with statistical techniques. In order to find an optimal maintenance policy, we concentrate the attention on a time-dependent Proportional Hazards Model (PHM) augmented with a semi-supervised ML approach. The developed hybrid model is capable of inferring and fusing High-Dimensional and Multi-modal Streaming (HDMS) data sources in an adaptive and autonomous fashion to recommend optimal maintenance decisions without human intervention. To illustrate the complete structure of the proposed MDSS, experimental evaluations are designed based on a dataset provided by NASA containing run-to-failure and CM data associated with aircraft engines. The effectiveness of the proposed model is demonstrated through a comprehensive set of comparisons with different ML algorithms.",
        "DOI": "10.1109/ICPHM49022.2020.9187022",
        "paper_author": "Azar K.",
        "affiliation_name": "Concordia Institute for Information Systems Engineering",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60116756",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Hybrid intrusion detection system for detecting new attacks using machine learning",
        "publication": "Proceedings of the 5th International Conference on Communication and Electronics Systems, ICCES 2020",
        "citied_by": "6",
        "cover_date": "2020-06-01",
        "Abstract": "Traditional Intrusion Detection Systems are used to detect malicious activities, policy violations, and produce relevant alerts. But most of the commercially available Intrusion Detection Systems are not capable of detecting newer attacks. Also, these intrusion detection systems produce a lot of alerts for a single complex attack. In this paper, an attempt is done to build a real-time hybrid intrusion detection system, which could be helpful to detect newer attacks as well as group together alerts of a complex attack for better Incident Response. The newer attacks are identified from the model built from the KDD dataset using various supervised machine learning algorithms. The complex attacks are clusteredin the alert correlation module using DBScan density-based clustering algorithm. The model identifies a similar attack encountered in the future resulting in a greatly improved incident response.",
        "DOI": "10.1109/ICCES48766.2020.09137888",
        "paper_author": "Felix Enigo V.S.",
        "affiliation_name": "SSN College of Engineering, Kalavakkam",
        "affiliation_city": "Kanchipuram",
        "affiliation_country": "India",
        "affiliation_id": "60079728",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Proceedings of International Conference on Intelligent Engineering and Management, ICIEM 2020",
        "publication": "Proceedings of International Conference on Intelligent Engineering and Management, ICIEM 2020",
        "citied_by": "0",
        "cover_date": "2020-06-01",
        "Abstract": "The proceedings contain 98 papers. The topics discussed include: fuzzy elliptic curve cryptography based cipher text policy attribute based encryption for cloud security; nanotechnology and its impact on medical diagnosis; a machine vision system for manual assembly line monitoring; anomaly detection and fault prediction of breakdown to repair process using mining techniques; image processing mechanism for augmented reality based autonomous navigation; small area fingerprint verification using deep convolutional neural network; Bayesian estimation of global and local variances for improved perceptual quality of fused medical images; feature selection to identify the residence state of teachers for the real-time; review on performance of SDAE for historical usage data using deep learning; an analysis of data mining techniques to analyze the effect of weather on agriculture; Elman recurrent neural networks based direct inverse control for quadrotor attitude and altitude control; and swarm intelligence and its applications towards various computing: a systematic review.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Adaptive ciphertext policy attribute based encryption scheme for internet of things devices using decision tree",
        "publication": "Revue d'Intelligence Artificielle",
        "citied_by": "5",
        "cover_date": "2020-06-01",
        "Abstract": "The Internet of Things (IoT) has recently become a hot spot for researchers and its industrial importance is growing exponentially day after day. Statistics show that the number of IoT devices will reach fifty billion by 2020. IoT applications are backed through clouds where data is stored and processed by gigantic processing systems and accessed only by authorized users. In the present work, we outsource the encryption and decryption of ABE operations to proxy servers in order to reduce the computation overhead of encryption and decryption. However, in some cases performing full encryption is more worthy than partial encryption if IoT resources are fit to perform this encryption thus, our scheme allows to adaptively switch from partial encryption to full encryption based on the resources that available and the number of attributes in access tree. The decision maker component (manager) uses decision tree to select the appropriate scheme based on the context at encryption time. Finally, we evaluate the performance of our scheme with other scheme proposed for constrained devices.",
        "DOI": "10.18280/ria.340301",
        "paper_author": "Taha M.B.",
        "affiliation_name": "Telefonaktiebolaget LM Ericsson",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60004661",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "PASAPTO: Policy-aware Security and Performance Trade-off Analysis - Computation on Encrypted Data with Restricted Leakage",
        "publication": "Proceedings - IEEE Computer Security Foundations Symposium",
        "citied_by": "1",
        "cover_date": "2020-06-01",
        "Abstract": "This work considers the trade-off between security and performance when revealing partial information about encrypted data computed on. The focus of our work is on information revealed through control flow side-channels when executing programs on encrypted data. We use quantitative information flow to measure security, running time to measure performance and program transformation techniques to alter the trade-off between the two. Combined with information flow policies, we perform a policy-aware security and performance trade-off (PASAPTO) analysis. We formalize the problem of PASAPTO analysis as an optimization problem, prove the NPhardness of the corresponding decision problem and present two algorithms solving it heuristically.We implemented our algorithms and combined them with the Dataflow Authentication (DFAuth) approach for outsourcing sensitive computations. Our DFAuth Trade-off Analyzer (DFATA) takes Java Bytecode operating on plaintext data and an associated information flow policy as input. It outputs semantically equivalent program variants operating on encrypted data which are policy-compliant and approximately Pareto-optimal with respect to leakage and performance. We evaluated DFATA in a commercial cloud environment using Java programs, e.g., a decision tree program performing machine learning on medical data. The decision tree variant with the worst performance is 357% slower than the fastest variant. Leakage varies between 0% and 17% of the input.",
        "DOI": "10.1109/CSF49147.2020.00024",
        "paper_author": "Fischer A.",
        "affiliation_name": "SAP Security Research",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125089082",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Proceedings - 2020 IEEE 33rd Computer Security Foundations Symposium, CSF 2020",
        "publication": "Proceedings - IEEE Computer Security Foundations Symposium",
        "citied_by": "0",
        "cover_date": "2020-06-01",
        "Abstract": "The proceedings contain 28 papers. The topics discussed include: optimal obfuscation mechanisms via machine learning; anonymous lottery in the proof-of-stake setting; language-based web session integrity; a method for proving unlinkability of stateful protocols; authentication in key-exchange: definitions, relations and composition; exploiting attack–defense trees to find an optimal set of countermeasures; clockwork: tracking remote timing attacks; reconciling progress-insensitive noninterference and declassification; dispute resolution in voting; SoK: techniques for verifiable mix nets; PASAPTO: policy-aware security and performance trade-off analysis – computation on encrypted data with restricted leakage; and securing asynchronous exceptions.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Rényi Entropy Bounds on the Active Learning Cost-Performance Tradeoff",
        "publication": "IEEE International Symposium on Information Theory - Proceedings",
        "citied_by": "0",
        "cover_date": "2020-06-01",
        "Abstract": "Semi-supervised classification, one of the most prominent fields in machine learning, studies how to combine the statistical knowledge of the often abundant unlabeled data with the often limited labeled data in order to maximize overall classification accuracy. In this context, the process of actively choosing the data to be labeled is referred to as active learning. In this paper, we initiate the non-asymptotic analysis of the optimal policy for semi-supervised classification with actively obtained labeled data. Considering a general Bayesian classification model, we provide the first characterization of the jointly optimal active learning and semi-supervised classification policy, in terms of the cost-performance tradeoff driven by the label query budget (number of data items to be labeled) and overall classification accuracy. Leveraging recent results on the Rényi Entropy, we derive tight information-theoretic bounds on such active learning cost-performance tradeoff.",
        "DOI": "10.1109/ISIT44484.2020.9174162",
        "paper_author": "Jamali V.",
        "affiliation_name": "Friedrich-Alexander-Universität Erlangen-Nürnberg",
        "affiliation_city": "Erlangen",
        "affiliation_country": "Germany",
        "affiliation_id": "60000765",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Energy-efficient radio resource allocation for federated edge learning",
        "publication": "2020 IEEE International Conference on Communications Workshops, ICC Workshops 2020 - Proceedings",
        "citied_by": "192",
        "cover_date": "2020-06-01",
        "Abstract": "Edge machine learning involves the development of learning algorithms at the network edge to leverage massive distributed data and computation resources. Among others, the framework of federated edge learning (FEEL) is particularly promising for its data-privacy preservation. FEEL coordinates global model training at a server and local model training at edge devices over wireless links. In this work, we explore the new direction of energy-efficient radio resource management (RRM) for FEEL. To reduce devices' energy consumption, we propose energy-efficient strategies for bandwidth allocation and scheduling. They adapt to devices' channel states and computation capacities so as to reduce their sum energy consumption while warranting learning performance. In contrast with the traditional rate-maximization designs, the derived optimal policies allocate more bandwidth to those scheduled devices with weaker channels or poorer computation capacities, which are the bottlenecks of synchronized model updates in FEEL. On the other hand, the scheduling priority function derived in closed form gives preferences to devices with better channels and computation capacities. Substantial energy reduction contributed by the proposed strategies is demonstrated in learning experiments.",
        "DOI": "10.1109/ICCWorkshops49005.2020.9145118",
        "paper_author": "Zeng Q.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Federated convolutional auto-encoder for optimal deployment of UAVs with visible light communications",
        "publication": "2020 IEEE International Conference on Communications Workshops, ICC Workshops 2020 - Proceedings",
        "citied_by": "8",
        "cover_date": "2020-06-01",
        "Abstract": "In this paper, the problem of unmanned aerial vehicles (UAV) deployment is investigated for visible light communication (VLC)-enabled UAV networks. Here, UAVs can simul-taneously provide communications and illumination services to ground users. In this model, ambient illumination distribution of the service area must be considered since it can cause interference over the VLC link and affects the illumination requirements of users. This problem is formulated as an optimization problem, which jointly considers UAV deployment, user association, power efficiency, and predictions of the illumination distribution. To solve this problem, we first need to predict illumination distribution to proactively determine the UAV deployment and user association so as to minimize total transmission power of UAVs. To predict the illumination distribution of the entire service area, a federated learning framework based on the machine learning algorithm of convolutional auto-encoder (CAE) is proposed. Compared to the centralized machine learning algorithms that requires complete illumination data for centralized training, the proposed algorithm enables the UAVs to train their local CAE with partial illumination data and cooperatively build a global CAE model that can predict the entire illumination distribution. Using these predictions, the optimal UAV deployment and user association policy that minimizes the total transmission power of UAVs is determined. Simulation results demonstrate that the proposed approach reduces the transmission power of UAVs up to 14.8% and 25.1%, respectively, compared to the local CAE prediction models and the conventional optimal algorithm without illumination distribution predictions.",
        "DOI": "10.1109/ICCWorkshops49005.2020.9145090",
        "paper_author": "Wang Y.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Machine learning-based resource allocation for multi-UAV communications system",
        "publication": "2020 IEEE International Conference on Communications Workshops, ICC Workshops 2020 - Proceedings",
        "citied_by": "14",
        "cover_date": "2020-06-01",
        "Abstract": "The unmanned aerial vehicle (UAV)-based wireless communication system is prominent in its flexibility and low cost for providing ubiquitous connectivity. In this work, considering a multi-UAV communications system, we propose to utilize a machine learning-based approach to tackle the trajectory design and resource allocation problems. In particular, with the objective to maximize the system utility over all served ground users, a joint user association, power allocation and trajectory design problem is formulated. To solve the problem caused by high dimensionality in state space, the machine learning-based strategic resource allocation algorithm comprising of reinforcement learning and deep learning is presented to design the optimal policy of all the UAVs. Extensive simulation studies are conducted and illustrated to evaluate the advantages of the proposed scheme.",
        "DOI": "10.1109/ICCWorkshops49005.2020.9145458",
        "paper_author": "Chang Z.",
        "affiliation_name": "University of Jyväskylä",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland",
        "affiliation_id": "60032398",
        "affiliation_state": "Central Finland"
    },
    {
        "paper_title": "Closing the psychological treatment gap during the covid-19 pandemic with a supportive text messaging program: protocol for implementation and evaluation",
        "publication": "JMIR Research Protocols",
        "citied_by": "36",
        "cover_date": "2020-06-01",
        "Abstract": "Background: Coronavirus disease (COVID-19) has spread globally with far-reaching, significant, and unprecedented impacts on health and everyday life. Threats to mental health, psychological safety, and well-being are now emerging, increasing the impact of this virus on world health. Providing support for these challenges is difficult because of the high number of people requiring support in the context of a need to maintain physical distancing. This protocol describes the use of SMS text messaging (Text4Hope) as a convenient, cost-effective, and accessible population-level mental health intervention. This program is evidence-based, with prior research supporting good outcomes and high user satisfaction. Objective: The project goal is to implement a program of daily supportive SMS text messaging (Text4Hope) to reduce distress related to the COVID-19 crisis, initially among Canadians. The prevalence of stress, anxiety, and depressive symptoms; the demographic correlates of the same; and the outcomes of the Text4Hope intervention in mitigating distress will be evaluated. Methods: Self-administered anonymous online questionnaires will be used to assess stress (Perceived Stress Scale), anxiety (Generalized Anxiety Disorder-7 scale [GAD-7]), and depressive symptoms (Patient Health Questionnaire-9 [PHQ-9]). Data will be collected at baseline (onset of SMS text messaging), the program midpoint (6 weeks), and the program endpoint (12 weeks). Results: Data analysis will include parametric and nonparametric techniques, focusing on primary outcomes (ie, stress, anxiety, and depressive symptoms) and metrics of use, including the number of subscribers and user satisfaction. Given the large size of the data set, machine learning and data mining methods will also be used. Conclusions: This COVID-19 project will provide key information regarding prevalence rates of stress, anxiety, and depressive symptoms during the pandemic; demographic correlates of distress; and outcome data related to this scalable population-level intervention. Information from this study will be valuable for practitioners and useful for informing policy and decision making regarding psychological interventions during the pandemic.",
        "DOI": "10.2196/19292",
        "paper_author": "Agyapong V.I.O.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60030835",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Targeting prospective customers: Robustness of machine-learning methods to typical data challenges",
        "publication": "Management Science",
        "citied_by": "61",
        "cover_date": "2020-06-01",
        "Abstract": "We investigate how firms can use the results of field experiments to optimize the targeting of promotions when prospecting for new customers. We evaluate seven widely used machine-learning methods using a series of two large-scale field experiments. The first field experiment generates a common pool of training data for each of the seven methods. We then validate the seven optimized policies provided by each method together with uniform benchmark policies in a second field experiment. The findings not only compare the performance of the targeting methods, but also demonstrate how well the methods address common data challenges. Our results reveal that when the training data are ideal, model-driven methods perform better than distance-driven methods and classification methods. However, the performance advantage vanishes in the presence of challenges that affect the quality of the training data, including the extent to which the training data captures details of the implementation setting. The challenges we study are covariate shift, concept shift, information loss through aggregation, and imbalanced data. Intuitively, the model-driven methods make better use of the information available in the training data, but the performance of these methods is more sensitive to deterioration in the quality of this information. The classification methods we tested performed relatively poorly. We explain the poor performance of the classification methods in our setting and describe how the performance of these methods could be improved.",
        "DOI": "10.1287/mnsc.2019.3308",
        "paper_author": "Simester D.",
        "affiliation_name": "MIT Sloan School of Management",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60014228",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "A dynamic intelligent policies analysis mechanism for personal data processing in the iot ecosystem",
        "publication": "Big Data and Cognitive Computing",
        "citied_by": "8",
        "cover_date": "2020-06-01",
        "Abstract": "The evolution of the Internet of Things is significantly affected by legal restrictions imposed for personal data handling, such as the European General Data Protection Regulation (GDPR). The main purpose of this regulation is to provide people in the digital age greater control over their personal data, with their freely given, specific, informed and unambiguous consent to collect and process the data concerning them. ADVOCATE is an advanced framework that fully complies with the requirements of GDPR, which, with the extensive use of blockchain and artificial intelligence technologies, aims to provide an environment that will support users in maintaining control of their personal data in the IoT ecosystem. This paper proposes and presents the Intelligent Policies Analysis Mechanism (IPAM) of the ADVOCATE framework, which, in an intelligent and fully automated manner, can identify conflicting rules or consents of the user, which may lead to the collection of personal data that can be used for profiling. In order to clearly identify and implement IPAM, the problem of recording user data from smart entertainment devices using Fuzzy Cognitive Maps (FCMs) was simulated. FCMs are an intelligent decision-making system that simulates the processes of a complex system, modeling the correlation base, knowing the behavioral and balance specialists of the system. Respectively, identifying conflicting rules that can lead to a profile, training is done using Extreme Learning Machines (ELMs), which are highly efficient neural systems of small and flexible architecture that can work optimally in complex environments.",
        "DOI": "10.3390/bdcc4020009",
        "paper_author": "Demertzis K.",
        "affiliation_name": "International Hellenic University",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece",
        "affiliation_id": "60158100",
        "affiliation_state": "Central Macedonia"
    },
    {
        "paper_title": "Adaptive Access Control Policies for IoT Deployments",
        "publication": "2020 International Wireless Communications and Mobile Computing, IWCMC 2020",
        "citied_by": "7",
        "cover_date": "2020-06-01",
        "Abstract": "In the era of the Internet of Things (IoT), it has become possible for a set of smart devices to collaborate autonomously and communicate seamlessly to achieve complex tasks that require a high degree of intelligence. Unlike traditional internet devices, a compromised IoT device can cause real-world damages. The severity of these damages increases dangerously in sensitive contexts especially when these devices are controlled by system insiders. Detecting abnormal access behaviors in such environments is quite challenging, due to frequent changes in the access contexts under which the IoT device can be accessed. In this paper, we propose an adaptive access control policy framework that dynamically refines the system access policies in response to changes in the device-to-device access behavior. We apply supervised machine learning to model and classify the device access behavior based on a real-life data set. We provide a use case scenario of a door locking system to validate our work. Results show that our framework provides improved security, dynamic adaptability and sufficient scalability to the target application domain.",
        "DOI": "10.1109/IWCMC48107.2020.9148090",
        "paper_author": "Alkhresheh A.",
        "affiliation_name": "Queen’s University",
        "affiliation_city": "Kingston",
        "affiliation_country": "Canada",
        "affiliation_id": "60016005",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Balanced Map Coverage using Reinforcement Learning in Repeated Obstacle Environments",
        "publication": "IEEE International Symposium on Industrial Electronics",
        "citied_by": "3",
        "cover_date": "2020-06-01",
        "Abstract": "This paper demonstrates novel Complete Coverage Path Planning using reinforcement learning to enable a robot to complete map coverage at high speeds in complicated environments, like factories and airline cabins, with many repeated obstacles, such as furniture and walls. Our framework trains the robot in a simulated environment to move to uncovered areas and to avoid frequent collisions using rewards. Additionally, it encourages the robot to complete map coverage missions efficiently and quickly. We select the Machine-Learning Agent provided by Unity3D to build a fragment (sample cell) of an airline cabin environment in which to train the robot. We implement Proximal Policy Optimization as the main training network, and added curiosity functions (i.e., intrinsic rewards) to encourage the robot to explore uncovered areas during training. We use Generative Adversarial Imitation Learning to guide the training policy's convergence close to the expert data. Experimental results show that our optimal policy enables complete map coverage in complicated environments. We provide demonstrations comparing random motion methods to reinforcement learning networks to show differences in map coverage, trajectory length, and time-cost.",
        "DOI": "10.1109/ISIE45063.2020.9152263",
        "paper_author": "Xia X.",
        "affiliation_name": "Auburn University",
        "affiliation_city": "Auburn",
        "affiliation_country": "United States",
        "affiliation_id": "60011754",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "Fault Classification Driven by Maintenance Management for Smart Maintenance Applications",
        "publication": "2020 IEEE International Workshop on Metrology for Industry 4.0 and IoT, MetroInd 4.0 and IoT 2020 - Proceedings",
        "citied_by": "5",
        "cover_date": "2020-06-01",
        "Abstract": "The study focuses on health monitoring applications that enables companies to offer smart maintenance services in the general context of industry 4.0. To this aim, a common practice consists in acquiring technical data, mining them using machine learning algorithms, and then deciding by taking into account commercial policies too. This work aims to demonstrate that business information can be advantageously embedded in a modified machine learning workflow. The main idea is supported by a frequent fact: practical maintenance procedures are less than the possible fault types. This assumption allows a task redefinition, thus providing an output ready for taking a final decision with better overall performances. A case study is analyzed in order to show the performance of the proposed strategy in an industrial application of condition monitoring. A combination of hypotheses and classification algorithms commonly used for predictive maintenance has been tested in order to check the performance improvement. In particular, Decision Trees, Nearest Neighbors, Linear SVM, Random Forest, AdaBoost, Naive Bayes and XGBoost have been considered. In all cases having a statistical significance, an improvement has been observed. Moreover, for the case of decision trees the advantages are gained regardless the tree heights, that is really interesting when low-performance computing platforms are actually available, as it happens for the case of IoT nodes.",
        "DOI": "10.1109/MetroInd4.0IoT48571.2020.9138294",
        "paper_author": "Bodo R.",
        "affiliation_name": "Università degli Studi di Padova",
        "affiliation_city": "Padua",
        "affiliation_country": "Italy",
        "affiliation_id": "60000481",
        "affiliation_state": "PD"
    },
    {
        "paper_title": "Multi-agent cooperation q-learning algorithm based on constrained Markov game",
        "publication": "Computer Science and Information Systems",
        "citied_by": "8",
        "cover_date": "2020-06-01",
        "Abstract": "Multi-Agent system has broad application in real world, whose security performance, however, is barely considered. Reinforcement learning is one of the most important methods to resolve Multi-Agent problems. At present, certain progress has been made in applying Multi-Agent reinforcement learning to robot system, man-machine match, and automatic, etc. However, in the above area, an agent may fall into unsafe states where the agent may find it difficult to bypass obstacles, to receive information from other agents and so on. Ensuring the safety of Multi-Agent system is of great importance in the above areas where an agent may fall into dangerous states that are irreversible, causing great damage. To solve the safety problem, in this paper we introduce a Multi-Agent Cooperation Q-Learning Algorithm based on Constrained Markov Game. In this method, safety constraints are added to the set of actions, and each agent, when interacting with the environment to search for optimal values, should be restricted by the safety rules, so as to obtain an optimal policy that satisfies the security requirements. Since traditional Multi-Agent reinforcement learning algorithm is no more suitable for the proposed model in this paper, a new solution is introduced for calculating the global optimum state-action function that satisfies the safety constraints. We take advantage of the Lagrange multiplier method to determine the optimal action that can be performed in the current state based on the premise of linearizing constraint functions, under conditions that the state-action function and the constraint function are both differentiable, which not only improves the efficiency and accuracy of the algorithm, but also guarantees to obtain the global optimal solution. The experiments verify the effectiveness of the algorithm.",
        "DOI": "10.2298/CSIS191220009G",
        "paper_author": "Ge Y.",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China",
        "affiliation_id": "60010432",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "A conceptual model of the influence of resume components on personnel decisions: A policy-capturing study on resume screening",
        "publication": "Journal of Management Information and Decision Sciences",
        "citied_by": "2",
        "cover_date": "2020-06-01",
        "Abstract": "Based on a literature review of not only industrial and organizational psychology but also decision theory, we have developed a conceptual model of resume screening. It postulates that personnel decisions concerning assignment to particular categories result from a gradual process with an underlying initial assumption, and the decision-making process varies depending on specific conditions. Under different conditions, decision makers utilize different resume components (relevant, irrelevant and formal), whose impacts might interact with each other. We designed and conducted two policy-capturing experimental studies and employed a machine learning approach and a decision tree classification method to verify our conceptual model. The results indicate that it might be considered valid and might explain actual decisions regarding resumes. The data we have collected suggests that in a situation of certainty recruitment specialists make their decisions solely on the basis of information obtained from relevant resume components and apply straightforward, i.e., non-compensatory, rules. However, when making decisions in a situation of uncertainty, recruitment specialists make an attribution and are influenced by the combined interactive effect of relevant, non-relevant and formal components of resumes. These decisions, in turn, are compensatory in nature. For example, positive personnel decisions regarding the appraisal of a resume may be made if deficiencies in a relevant area are compensated for by an exceptional level of non-relevant or formal components.",
        "DOI": "NA",
        "paper_author": "Grobelny J.",
        "affiliation_name": "Uniwersytet im. Adama Mickiewicza w Poznaniu",
        "affiliation_city": "Poznan",
        "affiliation_country": "Poland",
        "affiliation_id": "60014168",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "COVID-19 public sentiment insights and machine learning for tweets classification",
        "publication": "Information (Switzerland)",
        "citied_by": "322",
        "cover_date": "2020-06-01",
        "Abstract": "Along with the Coronavirus pandemic, another crisis has manifested itself in the form of mass fear and panic phenomena, fueled by incomplete and often inaccurate information. There is therefore a tremendous need to address and better understand COVID-19's informational crisis and gauge public sentiment, so that appropriate messaging and policy decisions can be implemented. In this research article, we identify public sentiment associated with the pandemic using Coronavirus specific Tweets and R statistical software, along with its sentiment analysis packages. We demonstrate insights into the progress of fear-sentiment over time as COVID-19 approached peak levels in the United States, using descriptive textual analytics supported by necessary textual data visualizations. Furthermore, we provide a methodological overview of two essential machine learning (ML) classification methods, in the context of textual analytics, and compare their effectiveness in classifying Coronavirus Tweets of varying lengths. We observe a strong classification accuracy of 91% for short Tweets, with the Naive Bayes method. We also observe that the logistic regression classification method provides a reasonable accuracy of 74% with shorter Tweets, and both methods showed relatively weaker performance for longer Tweets. This research provides insights into Coronavirus fear sentiment progression, and outlines associated methods, implications, limitations and opportunities.",
        "DOI": "10.3390/info11060314",
        "paper_author": "Samuel J.",
        "affiliation_name": "University of Charleston",
        "affiliation_city": "Charleston",
        "affiliation_country": "United States",
        "affiliation_id": "60277830",
        "affiliation_state": "WV"
    },
    {
        "paper_title": "Advances in hydrologic forecasts and water resources management",
        "publication": "Water (Switzerland)",
        "citied_by": "28",
        "cover_date": "2020-06-01",
        "Abstract": "The impacts of climate change on water resources management as well as the increasing severe natural disasters over the last decades have caught global attention. Reliable and accurate hydrological forecasts are essential for efficient water resources management and the mitigation of natural disasters. While the notorious nonlinear hydrological processes make accurate forecasts a very challenging task, it requires advanced techniques to build accurate forecast models and reliable management systems. One of the newest techniques for modelling complex systems is artificial intelligence (AI). AI can replicate the way humans learn and has the great capability to efficiently extract crucial information from large amounts of data to solve complex problems. The fourteen research papers published in this Special Issue contribute significantly to the uncertainty assessment of operational hydrologic forecasting under changing environmental conditions and the promotion of water resources management by using the latest advanced techniques, such as AI techniques. The fourteen contributions across four major research areas: (1) machine learning approaches to hydrologic forecasting; (2) uncertainty analysis and assessment on hydrological modelling under changing environments; (3) AI techniques for optimizing multi-objective reservoir operation; and (4) adaption strategies of extreme hydrological events for hazard mitigation. The papers published in this issue can not only advance water sciences but can also support policy makers toward more sustainable and effective water resources management.",
        "DOI": "10.3390/w12061819",
        "paper_author": "Chang F.J.",
        "affiliation_name": "National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60005429",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Risk-informed prediction of dredging project duration using stochastic machine learning",
        "publication": "Water (Switzerland)",
        "citied_by": "5",
        "cover_date": "2020-06-01",
        "Abstract": "Dredging engineering projects are complex because they involve greater uncertainty from the natural environment, social needs, government policy and many stakeholders. Engineering companies submit tenders that draw on similar cases undertaken in recent years. However, weather, earthquakes, typhoons and other disasters often change landforms. Therefore, evaluating the duration of dredging projects with reference to only a few previous cases is inadequate, often leading to an unnecessarily long construction duration if the scope of the project is not clearly defined at the early phase. The goal of this investigation aimed to estimate project duration at the beginning of construction and the probability of risk. Evolutionary machine learning was used to build a deterministic model of dredging project duration. Monte Carlo simulation was then utilized to establish the probabilistic distribution of the project duration based on historical patterns. The analytical outputs are displayed through a graphical user interface that provides project coordinators with a means of assessing the uncertainty of project duration in the initial phase of the project. This study will provide a practical reference for contractors and theWater Resources Agency.",
        "DOI": "10.3390/w12061643",
        "paper_author": "Chou J.S.",
        "affiliation_name": "National Taiwan University of Science and Technology",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60027709",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Large scale flood risk mapping in data scarce environments: An application for Romania",
        "publication": "Water (Switzerland)",
        "citied_by": "28",
        "cover_date": "2020-06-01",
        "Abstract": "Large-scale flood risk assessment is essential in supporting national and global policies, emergency operations and land-use management. The present study proposes a cost-efficient method for the large-scale mapping of direct economic flood damage in data-scarce environments. The proposed framework consists of three main stages: (i) deriving a water depth map through a geomorphic method based on a supervised linear binary classification; (ii) generating an exposure land-use map developed from multi-spectral Landsat 8 satellite images using a machine-learning classification algorithm; and (iii) performing a flood damage assessment using a GIS tool, based on the vulnerability (depth-damage) curves method. The proposed integrated method was applied over the entire country of Romania (including minor order basins) for a 100-year return time at 30-m resolution. The results showed how the description of flood risk may especially benefit from the ability of the proposed cost-efficient model to carry out large-scale analyses in data-scarce environments. This approach may help in performing and updating risk assessments and management, taking into account the temporal and spatial changes in hazard, exposure, and vulnerability.",
        "DOI": "10.3390/w12061834",
        "paper_author": "Albano R.",
        "affiliation_name": "Università degli Studi della Basilicata",
        "affiliation_city": "Potenza",
        "affiliation_country": "Italy",
        "affiliation_id": "60020919",
        "affiliation_state": "PZ"
    },
    {
        "paper_title": "Performance evaluation of machine learning methods for forest fire modeling and prediction",
        "publication": "Symmetry",
        "citied_by": "179",
        "cover_date": "2020-06-01",
        "Abstract": "Predicting and mapping fire susceptibility is a top research priority in fire-prone forests worldwide. This study evaluates the abilities of the Bayes Network (BN), Naive Bayes (NB), Decision Tree (DT), and Multivariate Logistic Regression (MLP) machine learning methods for the prediction and mapping fire susceptibility across the Pu Mat National Park, Nghe An Province, Vietnam. The modeling methodology was formulated based on processing the information from the 57 historical fires and a set of nine spatially explicit explanatory variables, namely elevation, slope degree, aspect, average annual temperate, drought index, river density, land cover, and distance from roads and residential areas. Using the area under the receiver operating characteristic curve (AUC) and seven other performance metrics, the models were validated in terms of their abilities to elucidate the general fire behaviors in the Pu Mat National Park and to predict future fires. Despite a few differences between the AUC values, the BN model with an AUC value of 0.96 was dominant over the other models in predicting future fires. The second best was the DT model (AUC = 0.94), followed by the NB (AUC = 0.939), and MLR (AUC = 0.937) models. Our robust analysis demonstrated that these models are sufficiently robust in response to the training and validation datasets change. Further, the results revealed that moderate to high levels of fire susceptibilities are associated with ~19% of the Pu Mat National Park where human activities are numerous. This study and the resultant susceptibility maps provide a basis for developing more efficient fire-fighting strategies and reorganizing policies in favor of sustainable management of forest resources.",
        "DOI": "10.3390/SYM12061022",
        "paper_author": "Pham B.T.",
        "affiliation_name": "Đại học Công nghệ Giao thông vận tải",
        "affiliation_city": "Hanoi",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60272966",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Future runoff analysis in the mekong river basin under a climate change scenario using deep learning",
        "publication": "Water (Switzerland)",
        "citied_by": "32",
        "cover_date": "2020-06-01",
        "Abstract": "In establishing adequate climate change policies regarding water resource development and management, the most essential step is performing a rainfall-runoff analysis. To this end, although several physical models have been developed and tested in many studies, they require a complex grid-based parameterization that uses climate, topography, land-use, and geology data to simulate spatiotemporal runoff. Furthermore, physical rainfall-runoff models also suffer from uncertainty originating from insufficient data quality and quantity, unreliable parameters, and imperfect model structures. As an alternative, this study proposes a rainfall-runoff analysis system for the Kratie station on the Mekong River mainstream using the long short-term memory (LSTM) model, a data-based black-box method. Future runoff variations were simulated by applying a climate change scenario. To assess the applicability of the LSTM model, its result was compared with a runoff analysis using the Soil and Water Assessment Tool (SWAT) model. The following steps (dataset periods in parentheses) were carried out within the SWAT approach: parameter correction (2000-2005), verification (2006-2007), and prediction (2008-2100), while the LSTM model went through the process of training (1980-2005), verification (2006-2007), and prediction (2008-2100). Globally available data were fed into the algorithms, with the exception of the observed discharge and temperature data, which could not be acquired. The bias-corrected Representative Concentration Pathways (RCPs) 4.5 and 8.5 climate change scenarios were used to predict future runoff. When the reproducibility at the Kratie station for the verification period of the two models (2006-2007) was evaluated, the SWAT model showed a Nash-Sutcliffe efficiency (NSE) value of 0.84, while the LSTM model showed a higher accuracy, NSE = 0.99. The trend analysis result of the runoff prediction for the Kratie station over the 2008-2100 period did not show a statistically significant trend for neither scenario nor model. However, both models found that the annual mean flow rate in the RCP 8.5 scenario showed greater variability than in the RCP 4.5 scenario. These findings confirm that the LSTM runoff prediction presents a higher reproducibility than that of the SWAT model in simulating runoff variation according to time-series changes. Therefore, the LSTM model, which derives relatively accurate results with a small amount of data, is an effective approach to large-scale hydrologic modeling when only runoff time-series are available.",
        "DOI": "10.3390/W12061556",
        "paper_author": "Lee D.",
        "affiliation_name": "Kyungpook National University (KNU)",
        "affiliation_city": "Daegu",
        "affiliation_country": "South Korea",
        "affiliation_id": "60012704",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessing and comparing top accelerators in Brazil, India, and the USA: Through the lens of new ventures’ performance",
        "publication": "Entrepreneurial Business and Economics Review",
        "citied_by": "14",
        "cover_date": "2020-06-01",
        "Abstract": "Objective: The objective of this article is to assess and compare the factors influencing the performance of new ventures within top business accelerators across three countries using the Resource Based View (RBV) theory. Research Design & Methods: The key analysed parameters are funding dimensions, survivability, acquisition, and growth of 1286 new ventures that graduated from the top two accelerators in Brazil, India, and the USA, i.e. countries from developed and emerging economies. Methods we used were machine learning and two independ-ent sample t-tests. Findings: Input seed funding by accelerators played a dominant role and improved funding trajectories. The external ecosystem was an important differentiator and im-pacted new ventures’ survivability, growth, and funding outcomes. Capabilities and competencies of accelerators differentiated outcomes within the same ecosystem while external environment dampened accelerator outcomes in emerging economies. Implications & Recommendations: Accelerators from emerging ecosystems should strive to augment their human capital and network capabilities, including seed funding, while policy-makers should improve ecosystem index values mentioned in this study. Contribution & Value Added: This is the first of its kind study that extended the RBV theory to accelerators and disentangled the effect of the external environment and RBV on accelerators across three ecosystems with a comprehensive framework of measures. It provides value to practitioners in India and Brazil by highlighting lacunae in their accelerator programs and possible approaches to address them successfully.",
        "DOI": "10.15678/EBER.2020.080209",
        "paper_author": "Snehal S.",
        "affiliation_name": "Amrita TBI",
        "affiliation_city": "Kollam",
        "affiliation_country": "India",
        "affiliation_id": "124708648",
        "affiliation_state": "KL"
    },
    {
        "paper_title": "Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks",
        "publication": "IEEE Transactions on Robotics",
        "citied_by": "157",
        "cover_date": "2020-06-01",
        "Abstract": "Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. It is nontrivial to manually design a robot controller that combines these modalities, which have very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to train directly on real robots due to sample complexity. In this article, we use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. Evaluating our method on a peg insertion task, we show that it generalizes over varying geometries, configurations, and clearances, while being robust to external perturbations. We also systematically study different self-supervised learning objectives and representation learning architectures. Results are presented in simulation and on a physical robot.",
        "DOI": "10.1109/TRO.2019.2959445",
        "paper_author": "Lee M.A.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Reinforcement learning in blockchain-enabled IIoT networks: A survey of recent advances and open challenges",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "54",
        "cover_date": "2020-06-01",
        "Abstract": "Blockchain is emerging as a promising candidate for the uberization of Internet services. It is a decentralized, secure, and auditable solution for exchanging, and authenticating information via transactions, without the need of a trusted third party. Therefore, blockchain technology has recently been integrated with industrial Internet-of-things (IIoT) networks to help realize the fourth industrial revolution, Industry 4.0. Though blockchain-enabled IIoT networks may have the potential to support the services and demands of next-generation networks, the gap analysis presented in this work highlights some of the areas that need improvement. Based on these observations, the article then promotes the utility of reinforcement learning (RL) techniques to address some of the major issues of blockchain-enabled IIoT networks such as block time minimization and transaction throughput enhancement. This is followed by a comprehensive case study where a Q-learning technique is used for minimizing the occurrence of forking events by reducing the transmission delays for a miner. Extensive simulations have been performed and the results have been obtained for the average transmission delay which relates to the forking events. The obtained results demonstrate that the Q-learning approach outperforms the greedy policy while having a reasonable level of complexity. To further develop the blockchain-enabled IIoT networks, some future research directions are also documented. While this article highlights the applications of RL techniques in blockchain-enabled IIoT networks, the provided insights and results could pave the way for rapid adoption of blockchain technology.",
        "DOI": "10.3390/su12125161",
        "paper_author": "Jameel F.",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland",
        "affiliation_id": "60103653",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "COVID-19 diagnostics, tools, and prevention",
        "publication": "Diagnostics",
        "citied_by": "66",
        "cover_date": "2020-06-01",
        "Abstract": "The Coronavirus Disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2), outbreak from Wuhan City, Hubei province, China in 2019 has become an ongoing global health emergency. The emerging virus, SARS-CoV-2, causes coughing, fever, muscle ache, and shortness of breath or dyspnea in symptomatic patients. The pathogenic particles that are generated by coughing and sneezing remain suspended in the air or attach to a surface to facilitate transmission in an aerosol form. This review focuses on the recent trends in pandemic biology, diagnostics methods, prevention tools, and policies for COVID-19 management. To meet the growing demand for medical supplies during the COVID-19 era, a variety of personal protective equipment (PPE) and ventilators have been developed using do-it-yourself (DIY) manufacturing. COVID-19 diagnosis and the prediction of virus transmission are analyzed by machine learning algorithms, simulations, and digital monitoring. Until the discovery of a clinically approved vaccine for COVID-19, pandemics remain a public concern. Therefore, technological developments, biomedical research, and policy development are needed to decipher the coronavirus mechanism and epidemiological characteristics, prevent transmission, and develop therapeutic drugs.",
        "DOI": "10.3390/diagnostics10060409",
        "paper_author": "Allam M.",
        "affiliation_name": "Wallace H. Coulter Department of Biomedical Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60136860",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "RoPE: An Architecture for Adaptive Data-Driven Routing Prediction at the Edge",
        "publication": "IEEE Transactions on Network and Service Management",
        "citied_by": "26",
        "cover_date": "2020-06-01",
        "Abstract": "The demand of low latency applications has fostered interest in edge computing, a recent paradigm in which data is processed locally, at the edge of the network. The challenge of delivering services with low-latency and high bandwidth requirements has seen the flourishing of Software-Defined Networking (SDN) solutions that utilize ad-hoc data-driven statistical learning solutions to dynamically steer edge computing resources. In this paper, we propose RoPE, an architecture that adapts the routing strategy of the underlying edge network based on future available bandwidth. The bandwidth prediction method is a policy that we adjust dynamically based on the required time-to-solution and on the available data. An SDN controller keeps track of past link loads and takes a new route if the current path is predicted to be congested. We tested RoPE on different use case applications comparing different well-known prediction policies. Our evaluation results demonstrate that our adaptive solution outperforms other ad-hoc routing solutions and edge-based applications, in turn, benefit from adaptive routing, as long as the prediction is accurate and easy to obtain.",
        "DOI": "10.1109/TNSM.2020.2980899",
        "paper_author": "Sacco A.",
        "affiliation_name": "Politecnico di Torino",
        "affiliation_city": "Turin",
        "affiliation_country": "Italy",
        "affiliation_id": "60012162",
        "affiliation_state": "TO"
    },
    {
        "paper_title": "Development of a geogenic radon hazard index—concept, history, experiences",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "52",
        "cover_date": "2020-06-01",
        "Abstract": "Exposure to indoor radon at home and in workplaces constitutes a serious public health risk and is the second most prevalent cause of lung cancer after tobacco smoking. Indoor radon concentration is to a large extent controlled by so-called geogenic radon, which is radon generated in the ground. While indoor radon has been mapped in many parts of Europe, this is not the case for its geogenic control, which has been surveyed exhaustively in only a few countries or regions. Since geogenic radon is an important predictor of indoor radon, knowing the local potential of geogenic radon can assist radon mitigation policy in allocating resources and tuning regulations to focus on where it needs to be prioritized. The contribution of geogenic to indoor radon can be quantified in different ways: the geogenic radon potential (GRP) and the geogenic radon hazard index (GRHI). Both are constructed from geogenic quantities, with their differences tending to be, but not always, their type of geographical support and optimality as indoor radon predictors. An important feature of the GRHI is consistency across borders between regions with different data availability and Rn survey policies, which has so far impeded the creation of a European map of geogenic radon. The GRHI can be understood as a generalization or extension of the GRP. In this paper, the concepts of GRP and GRHI are discussed and a review of previous GRHI approaches is presented, including methods of GRHI estimation and some preliminary results. A methodology to create GRHI maps that cover most of Europe appears at hand and appropriate; however, further fine tuning and validation remains on the agenda.",
        "DOI": "10.3390/ijerph17114134",
        "paper_author": "Bossew P.",
        "affiliation_name": "Bundesamt für Strahlenschutz",
        "affiliation_city": "Salzgitter",
        "affiliation_country": "Germany",
        "affiliation_id": "60104187",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Optimising a microgrid system by deep reinforcement learning techniques",
        "publication": "Energies",
        "citied_by": "32",
        "cover_date": "2020-06-01",
        "Abstract": "The deployment of microgrids could be fostered by control systems that do not require very complex modelling, calibration, prediction and/or optimisation processes. This paper explores the application of Reinforcement Learning (RL) techniques for the operation of a microgrid. The implemented Deep Q-Network (DQN) can learn an optimal policy for the operation of the elements of an isolated microgrid, based on the interaction agent-environment when particular operation actions are taken in the microgrid components. In order to facilitate the scaling-up of this solution, the algorithm relies exclusively on historical data from past events, and therefore it does not require forecasts of the demand or the renewable generation. The objective is to minimise the cost of operating the microgrid, including the penalty of non-served power. This paper analyses the effect of considering different definitions for the state of the system by expanding the set of variables that define it. The obtained results are very satisfactory as it can be concluded by their comparison with the perfect-information optimal operation computed with a traditional optimisation model, and with a Naive model.",
        "DOI": "10.3390/en13112830",
        "paper_author": "Domínguez-Barbero D.",
        "affiliation_name": "Universidad Pontificia Comillas, Escuela Técnica Superior de Ingeniería, Instituto de Investigación Tecnológica",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain",
        "affiliation_id": "60110597",
        "affiliation_state": "Madrid"
    },
    {
        "paper_title": "Identifying corporate sustainability issues by analyzing shareholder resolutions: A machine-learning text analytics approach",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "19",
        "cover_date": "2020-06-01",
        "Abstract": "Corporations have embraced the idea of corporate environmental, social, and governance (ESG) under the general framework of sustainability. Studies have measured and analyzed the impact of internal sustainability efforts on the performance of individual companies, policies, and projects. This exploratory study attempts to extract useful insight from shareholder sustainability resolutions using machine learning-based text analytics. Prior research has studied corporate sustainability disclosures from public reports. By studying shareholder resolutions, we gain insight into the shareholders' perspectives and objectives. The primary source for this study is the Ceres sustainability shareholder resolution database, with 1737 records spanning 2009-2019. The study utilizes a combination of text analytic approaches (i.e., word cloud, co-occurrence, row-similarities, clustering, classification, etc.) to extract insights. These are novel methods of transforming textual data into useful knowledge about corporate sustainability endeavors. This study demonstrates that stakeholders, such as shareholders, can influence corporate sustainability via resolutions. The incorporation of text analytic techniques offers insight to researchers who study vast collections of unstructured bodies of text, improving the understanding of shareholder resolutions and reaching a wider audience.",
        "DOI": "10.3390/su12114753",
        "paper_author": "Raghupathi V.",
        "affiliation_name": "The City University of New York",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60007033",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Analyzing factors associated with fatal road crashes: A machine learning approach",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "49",
        "cover_date": "2020-06-01",
        "Abstract": "Road traffic injury accounts for a substantial human and economic burden globally. Understanding risk factors contributing to fatal injuries is of paramount importance. In this study, we proposed a model that adopts a hybrid ensemble machine learning classifier structured from sequential minimal optimization and decision trees to identify risk factors contributing to fatal road injuries. The model was constructed, trained, tested, and validated using the Lebanese Road Accidents Platform (LRAP) database of 8482 road crash incidents, with fatality occurrence as the outcome variable. A sensitivity analysis was conducted to examine the influence of multiple factors on fatality occurrence. Seven out of the nine selected independent variables were significantly associated with fatality occurrence, namely, crash type, injury severity, spatial cluster-ID, and crash time (hour). Evidence gained from the model data analysis will be adopted by policymakers and key stakeholders to gain insights into major contributing factors associated with fatal road crashes and to translate knowledge into safety programs and enhanced road policies.",
        "DOI": "10.3390/ijerph17114111",
        "paper_author": "Ghandour A.J.",
        "affiliation_name": "National Council for Scientific Research, Beirut",
        "affiliation_city": "Beirut",
        "affiliation_country": "Lebanon",
        "affiliation_id": "60069447",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "COVID-19: A comparison of time series methods to forecast percentage of active cases per population",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "126",
        "cover_date": "2020-06-01",
        "Abstract": "The ongoing COVID-19 pandemic has caused worldwide socioeconomic unrest, forcing governments to introduce extreme measures to reduce its spread. Being able to accurately forecast when the outbreak will hit its peak would significantly diminish the impact of the disease, as it would allow governments to alter their policy accordingly and plan ahead for the preventive steps needed such as public health messaging, raising awareness of citizens and increasing the capacity of the health system. This study investigated the accuracy of a variety of time series modeling approaches for coronavirus outbreak detection in ten different countries with the highest number of confirmed cases as of 4 May 2020. For each of these countries, six different time series approaches were developed and compared using two publicly available datasets regarding the progression of the virus in each country and the population of each country, respectively. The results demonstrate that, given data produced using actual testing for a small portion of the population, machine learning time series methods can learn and scale to accurately estimate the percentage of the total population that will become affected in the future.",
        "DOI": "10.3390/app10113880",
        "paper_author": "Papastefanopoulos V.",
        "affiliation_name": "University of Patras",
        "affiliation_city": "Rio",
        "affiliation_country": "Greece",
        "affiliation_id": "60031155",
        "affiliation_state": "Achaia"
    },
    {
        "paper_title": "Using machine learning models to predict the initiation of renal replacement therapy among chronic kidney disease patients",
        "publication": "PLoS ONE",
        "citied_by": "42",
        "cover_date": "2020-06-01",
        "Abstract": "Starting renal replacement therapy (RRT) for patients with chronic kidney disease (CKD) at an optimal time, either with hemodialysis or kidney transplantation, is crucial for patient’s well-being and for successful management of the condition. In this paper, we explore the possibilities of creating forecasting models to predict the onset of RRT 3, 6, and 12 months from the time of the patient’s first diagnosis with CKD, using only the comorbidities data from National Health Insurance from Taiwan. The goal of this study was to see whether a limited amount of data (including comorbidities but not considering laboratory values which are expensive to obtain in low- and medium-income countries) can provide a good basis for such predictive models. On the other hand, in developed countries, such models could allow policy-makers better planning and allocation of resources for treatment. Using data from 8,492 patients, we obtained the area under the receiver operating characteristic curve (AUC) of 0.773 for predicting RRT within 12 months from the time of CKD diagnosis. The results also show that there is no additional advantage in focusing only on patients with diabetes in terms of prediction performance. Although these results are not as such suitable for adoption into clinical practice, the study provides a strong basis and a variety of approaches for future studies of forecasting models in healthcare.",
        "DOI": "10.1371/journal.pone.0233976",
        "paper_author": "Dovgan E.",
        "affiliation_name": "Institut \"Jožef Stefan\"",
        "affiliation_city": "Ljubljana",
        "affiliation_country": "Slovenia",
        "affiliation_id": "60023955",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ensuring accurate resource identification",
        "publication": "Nature Protocols",
        "citied_by": "3",
        "cover_date": "2020-06-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41596-020-0334-4",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Advancing clinical trials for inherited retinal diseases: Recommendations from the second monaciano symposium",
        "publication": "Translational Vision Science and Technology",
        "citied_by": "74",
        "cover_date": "2020-06-01",
        "Abstract": "Major advances in the study of inherited retinal diseases (IRDs) have placed efforts to develop treatments for these blinding conditions at the forefront of the emerging field of precision medicine. As a result, the growth of clinical trials for IRDs has increased rapidly over the past decade and is expected to further accelerate as more therapeutic possibilities emerge and qualified participants are identified. Although guided by established principles, these specialized trials, requiring analysis of novel outcome measures and endpoints in small patient populations, present multiple challenges relative to study design and ethical considerations. This position paper reviews recent accomplishments and existing challenges in clinical trials for IRDs and presents a set of recommendations aimed at rapidly advancing future progress. The goal is to stimulate discussions among researchers, funding agencies, industry, and policy makers that will further the design, conduct, and analysis of clinical trials needed to accelerate the approval of effective treatments for IRDs, while promoting advocacy and ensuring patient safety.",
        "DOI": "10.1167/tvst.9.7.2",
        "paper_author": "Thompson D.A.",
        "affiliation_name": "University of Michigan W.K. Kellogg Eye Center",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60022590",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Investigating fertility intentions for a second child in contemporary china based on user-generated content",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "17",
        "cover_date": "2020-06-01",
        "Abstract": "China’s two-child policy, aimed at boosting the country’s total fertility rate, has failed to achieve the desired outcomes. Previous studies on low fertility rates mainly used data obtained from demographic censuses, questionnaires, or interviews. These data-gathering methods are costly, entailing time delays and yielding limited information. User-generated content (UGC) provides an alternative data source. We propose a machine–human hybrid approach using UGC obtained from social media to assess users’ intentions to have a second child. Our results showed that couples associate a second child with high economic costs mainly through negative impacts on the mothers’ careers, with no concomitant economic benefits. A key motivation for having two children relates to the mental benefit of the joy in having children. However, raising a second child also entails considerable mental costs such as exhaustion and pressure. Couples largely seek help within their extended families, that is, their parents are major sources of child-rearing support. Therefore, the government should devise ways of reducing the negative impacts of having a second child on a woman’s career and provide child-rearing support to help increase the fertility rate. Our proposed approach can also be used to elicit the reasons for low fertility rates in other countries.",
        "DOI": "10.3390/ijerph17113905",
        "paper_author": "Qian Y.",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60023813",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Combining Planning and Deep Reinforcement Learning in Tactical Decision Making for Autonomous Driving",
        "publication": "IEEE Transactions on Intelligent Vehicles",
        "citied_by": "185",
        "cover_date": "2020-06-01",
        "Abstract": "Tactical decision making for autonomous driving is challenging due to the diversity of environments, the uncertainty in the sensor information, and the complex interaction with other road users. This article introduces a general framework for tactical decision making, which combines the concepts of planning and learning, in the form of Monte Carlo tree search and deep reinforcement learning. The method is based on the AlphaGo Zero algorithm, which is extended to a domain with a continuous state space where self-play cannot be used. The framework is applied to two different highway driving cases in a simulated environment and it is shown to perform better than a commonly used baseline method. The strength of combining planning and learning is also illustrated by a comparison to using the Monte Carlo tree search or the neural network policy separately.",
        "DOI": "10.1109/TIV.2019.2955905",
        "paper_author": "Hoel C.J.",
        "affiliation_name": "Volvo Group",
        "affiliation_city": "Gothenburg",
        "affiliation_country": "Sweden",
        "affiliation_id": "60223189",
        "affiliation_state": "Vastra Gotaland"
    },
    {
        "paper_title": "Estimation of potato yield using satellite data at a municipal level: A machine learning approach",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "24",
        "cover_date": "2020-06-01",
        "Abstract": "Crop growth modeling and yield forecasting are essential to improve food security policies worldwide. To estimate potato (Solanum tubersum L.) yield over Mexico at a municipal level, we used meteorological data provided by the ERA5 (ECMWF Re-Analysis) dataset developed by the Copernicus Climate Change Service, satellite imagery from the TERRA platform, and field information. Five different machine learning algorithms were used to build the models: Random forest (rf), support vector machine linear (svmL), support vector machine polynomial (svmP), support vector machine radial (svmR), and general linear model (glm). The optimized models were tested using independent data (2017 and 2018) not used in the training and optimization phase (2004-2016). In terms of percent root mean squared error (%RMSE), the best results were obtained by the rf algorithm in the winter cycle using variables from the first three months of the cycle (R2 = 0.757 and %RMSE = 18.9). For the summer cycle, the best performing model was the svmP which used the first five months of the cycle as variables (R2 = 0.858 and %RMSE = 14.9). Our results indicated that adding predictor variables of the last two months before the harvest did not significantly improved model performances. These results demonstrate that our models can predict potato yield by analyzing the yield of the previous year, the general conditions of NDVI, meteorology, and information related to the irrigation system at a municipal level.",
        "DOI": "10.3390/ijgi9060343",
        "paper_author": "Salvador P.",
        "affiliation_name": "Universidad de Valladolid",
        "affiliation_city": "Valladolid",
        "affiliation_country": "Spain",
        "affiliation_id": "60024695",
        "affiliation_state": "Valladolid"
    },
    {
        "paper_title": "Adjustable and adaptive control for an unstable mobile robot using imitation learning with trajectory optimization",
        "publication": "Robotics",
        "citied_by": "2",
        "cover_date": "2020-06-01",
        "Abstract": "In this contribution, we develop a feedback controller in the form of a parametric function for a mobile inverted pendulum. The control both stabilizes the system and drives it to target positions with target orientations. A design of the controller based only on a cost function is difficult for this task, which is why we choose to train the controller using imitation learning on optimized trajectories. In contrast to popular approaches like policy gradient methods, this approach allows us to shape the behavior of the system by including equality constraints. When transferring the parametric controller from simulation to the real mobile inverted pendulum, the control performance is degraded due to the reality gap. A robust control design can reduce the degradation. However, for the framework of imitation learning on optimized trajectories, methods that explicitly consider robustness do not yet exist to the knowledge of the authors. We tackle this research gap by presenting a method to design a robust controller in the form of a recurrent neural network, to improve the transferability of the trained controller to the real system. As a last step, we make the behavior of the parametric controller adjustable to allow for the fine tuning of the behavior of the real system. We design the controller for our system and show in the application that the recurrent neural network has increased performance compared to a static neural network without robustness considerations.",
        "DOI": "10.3390/ROBOTICS9020029",
        "paper_author": "Dengler C.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Gubernatorial Policy Priorities and State Fiscal Outcomes",
        "publication": "Politics and Policy",
        "citied_by": "3",
        "cover_date": "2020-06-01",
        "Abstract": "This study tests the effect of gubernatorial policy agendas on state budgetary choices. Governors are commonly perceived as state policy leaders, but lack direct legislative authority and depend on the law makers to pass bills and present them for signature. The theory posits that governors nonetheless possess several formal and informal tools that are used to overcome this institutional disadvantage and successfully pursue their policy goals. Gubernatorial policy priorities in this study are extracted from public speeches using unsupervised machine learning. Their influence on state spending choices in different policy areas is tested through panel data analysis of all states from 2007 through 2015. Empirical findings reveal that the effect of executive agendas is more pronounced in the area of transportation infrastructure and public safety—potentially due to lower levels of conflict and concentrated benefits, which eases deal making with law makers. Governors are also more persistent with policy proposals that are more important for reelection. Related Articles: Adams, Brian E. 2016. “Assessing the Merits of Decentralization: A Framework for Identifying the Causal Mechanisms Influencing Policy Outcomes.” Politics & Policy 44 (5): 820-849. https://doi.org/10.1111/polp.12172. Heidbreder, Brianne. 2012. “Agenda Setting in the States: How Politics and Policy Needs Shape Gubernatorial Agendas.” Politics & Policy 40 (2): 296-319. https://doi.org/10.1111/j.1747-1346.2012.00345.x. Patrick, Barbara. 2012. “Fiscal Federalism, Performance Policies, and Education Reforms: Are States Using Performance Policies to Improve Workforce Quality?” Politics & Policy 40 (4): 593-628. https://doi.org/10.1111/j.1747-1346.2012.00370.x.",
        "DOI": "10.1111/polp.12353",
        "paper_author": "Ivonchyk M.",
        "affiliation_name": "State University of New York Albany",
        "affiliation_city": "Albany",
        "affiliation_country": "United States",
        "affiliation_id": "60011666",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "How Online Content Providers Moderate User-Generated Content to Prevent Harmful Online Communication: An Analysis of Policies and Their Implementation",
        "publication": "Policy and Internet",
        "citied_by": "28",
        "cover_date": "2020-06-01",
        "Abstract": "This article reports two studies conducted in the United States, Germany, South Korea, and China to examine how online content providers (OCPs) exercise their responsibility in dealing with harmful online communication (HOC) by moderating user-generated content. The first study employed content analysis of 547 HOC policy documents. In the second study, 41 representatives of OCPs were interviewed regarding the implementation of these policies. We show that HOC policies are most often communicated through user-unfriendly terms of service. Only Korean OCPs present their policies very vividly. Few organizations, mainly United States and German, encourage counter-speech. The most common organizational actions against HOC mentioned in the policies are deleting posts or blocking accounts. The interviews reveal, however, that organizations—apart from those from China—are cautious in implementing such reactive actions. They fear accusations of censorship and acknowledge the tension between free speech and their content moderation practice. What emerged as the “gold standard” for identifying HOC was manual inspection. However, organizations operating large platforms widely apply machine-learning technology or artificial intelligence. In sum, our research suggests that OCPs are not proactive enough in their communication for HOC prevention and often focus more on avoiding legal ramifications than on educating users when handling HOC.",
        "DOI": "10.1002/poi3.239",
        "paper_author": "Einwiller S.A.",
        "affiliation_name": "Universität Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria",
        "affiliation_id": "60025988",
        "affiliation_state": "Vienna"
    },
    {
        "paper_title": "A Deep Reinforcement Learning Approach for Global Routing",
        "publication": "Journal of Mechanical Design",
        "citied_by": "66",
        "cover_date": "2020-06-01",
        "Abstract": "Global routing has been a historically challenging problem in the electronic circuit design, where the challenge is to connect a large and arbitrary number of circuit components with wires without violating the design rules for the printed circuit boards or integrated circuits. Similar routing problems also exist in the design of complex hydraulic systems, pipe systems, and logistic networks. Existing solutions typically consist of greedy algorithms and hard-coded heuristics. As such, existing approaches suffer from a lack of model flexibility and usually fail to solve sub-problems conjointly. As an alternative approach, this work presents a deep reinforcement learning method for solving the global routing problem in a simulated environment. At the heart of the proposed method is deep reinforcement learning that enables an agent to produce a policy for routing based on the variety of problems, and it is presented with leveraging the conjoint optimization mechanism of deep reinforcement learning. Conjoint optimization mechanism is explained and demonstrated in detail; the best network structure and the parameters of the learned model are explored. Based on the fine-tuned model, routing solutions and rewards are presented and analyzed. The results indicate that the approach can outperform the benchmark method of a sequential A*method, suggesting a promising potential for deep reinforcement learning for global routing and other routing or path planning problems in general. Another major contribution of this work is the development of a global routing problem sets generator with the ability to generate parameterized global routing problem sets with different size and constraints, enabling evaluation of different routing algorithms and the generation of training datasets for future data-driven routing approaches.",
        "DOI": "10.1115/1.4045044",
        "paper_author": "Liao H.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60104842",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Accelerating the Discovery of New DP Steel Using Machine Learning-Based Multiscale Materials Simulations",
        "publication": "Metallurgical and Materials Transactions A: Physical Metallurgy and Materials Science",
        "citied_by": "7",
        "cover_date": "2020-06-01",
        "Abstract": "In recent years, the use of dual-phase (DP) steels by the automotive industry has been growing rapidly, motivated by government policies prompting the production of fuel-efficient vehicles. While it is of high interest for the transportation industry to design and discover different grades of DP steels exhibiting desirable mechanical properties, this requires exploring a large number of DP steel microstructure combinations. Expensive trial-and-error-based experimentations and multiscale materials simulations are two conventional approaches that have been widely adopted in the field of materials design and discovery. Yet, it is challenging to use such approaches for fast materials design and discovery when considering the computational and cost limitations, as it is computationally infeasible and intractable to use multiscale materials models to characterize the mechanical properties of millions of different microstructures. To address this major limitation in material design, a Gaussian process is developed to accelerate the discovery of the mechanical properties of different DP steels by evolving the microstructure parameters using a limited number of numerical simulations (using a multiscale materials model). A Gaussian process is a machine learning technique that is trained to find nontrivial correlations between a set of inputs (microstructure properties) to predict a desired output (mechanical property). The proposed Gaussian process not only accelerates the prediction of the desired mechanical properties of millions of multiscale materials simulations but also offers uncertainty quantification around its predictions. These merits make the Gaussian process a very reliable, robust, and practical solution for material design exploration. The proposed framework combining multiscale simulations and the Gaussian process is used to discover the microstructural design of DP steel with maximum tensile toughness. The results showed the effectiveness and robustness of the proposed method in comparison to benchmark methods.",
        "DOI": "10.1007/s11661-020-05764-7",
        "paper_author": "Chehade A.A.",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Dearborn",
        "affiliation_country": "United States",
        "affiliation_id": "60155312",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Finding the de-carbonization potentials in the transport sector: application of scenario analysis with a hybrid prediction model",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "17",
        "cover_date": "2020-06-01",
        "Abstract": "De-carbonization of the transport sector is an important pathway to climate-change mitigation and presents the potential for future lower emissions. To assess the potential quantitatively under different optimization measures, this paper presents a hybrid model combining an integrated machine learning model with the scenario analysis. We compare the training accuracy of the back-propagation neural networks (BPNN), Gaussian process regression (GPR), and support vector machine (SVM) fitting model with different training datasets. The results indicate that the performance of the SVM model is superior to other methods. And the particle swarm optimization (PSO) algorithm is then used to optimize hyper-parameters of the SVM model. Two scenarios including business as usual (BAU) and best case (BC) are set according to the current trends and target trends of driving factors identified by the extended stochastic impacts by regression on population, affluence, and technology (STIRPAT) model. Finally, to find the de-carbonization potentials in the transport sector, the PSO-SVM model is applied to predict transport emissions from 2015 to 2030 under two scenarios. Results show that transport emissions reduce by about 131.36 million tons during 2015–2020 and 372.86 million tons during 2021–2025 in the BC scenario. The findings can effectively track, test, and predict the achievement of policy goals and provide practical guidance for de-carbonization development.",
        "DOI": "10.1007/s11356-020-08627-1",
        "paper_author": "Wang L.",
        "affiliation_name": "Guangdong University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60007155",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Novel 2019 coronavirus: Genome structure, clinical trials, and outstanding questions",
        "publication": "Experimental Biology and Medicine",
        "citied_by": "25",
        "cover_date": "2020-06-01",
        "Abstract": "Novel 2019 coronavirus has created havoc across the globe since its emergence in December 2019 in Wuhan, China, and fast spreading potential. While we were able to identify the causative agent within a few days of the disease outbreak, several questions still remain unanswered. In this review, we discuss the extent of virus spread, current statistics, SARS-CoV-2 genome organization, comparison between the novel coronavirus and causative agents involved in previous outbreaks, ongoing clinical trials and myths associated with the virus. Lastly, we provide insights into the future perspectives which could prove useful for the scientific community as they work on finding the cure against the disease. Impact statement: Early availability of the sequence, the genetic material of SARS-CoV-2 (the virus that causes COVID-19), has prompted efforts towards identifying a safe and effective vaccine in the current public health emergency. To that end, understanding the pathophysiology of disease is crucial for scientists around the world. Since conventional vaccine development and manufacturing may take several years, it is important to think about alternative strategies that we could use to mitigate imminent catastrophe. We hope that this article will open up new avenues and provide insights that could potentially save hundreds of lives affected by COVID-19.",
        "DOI": "10.1177/1535370220920540",
        "paper_author": "Jogalekar M.P.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Decoding motor skills of artificial intelligence and human policies: A study on humanoid and human balance control",
        "publication": "IEEE Robotics and Automation Magazine",
        "citied_by": "8",
        "cover_date": "2020-06-01",
        "Abstract": "From the advancement in computers, computeraided design has emerged for mechanical and electronic engineering, architecture, and many other engineering fields. Foreseeing a similar development curve and technology wave, we forecast a new emerging discipline in the near future that uses learning-aided approaches to catalyze control development, alongside other similar applications such as medicine discovery. In this article, we propose a new paradigm for using machine learning to facilitate quicker, more efficient, and more effective control development, as an alternative way of leveraging the power of machine learning in addition to other options that intend to use learning directly in real-world applications.",
        "DOI": "10.1109/MRA.2020.2980547",
        "paper_author": "Yuan K.",
        "affiliation_name": "The University of Edinburgh",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60027272",
        "affiliation_state": "Scotland"
    },
    {
        "paper_title": "Local motion simulation using deep reinforcement learning",
        "publication": "Transactions in GIS",
        "citied_by": "14",
        "cover_date": "2020-06-01",
        "Abstract": "Traditional local motion simulation focuses largely on avoiding collisions in the next frame. However, due to its lack of forward looking, the global trajectory of agents usually seems unreasonable. As a method of optimizing the overall reward, deep reinforcement learning (DRL) can better correct the problems that exist in the traditional local motion simulation method. In this article, we propose a local motion simulation method integrating optimal reciprocal collision avoidance (ORCA) and DRL, referred to as ORCA-DRL. The main idea of ORCA-DRL is to perform local collision avoidance detection via ORCA and smooth the trajectory at the same time via DRL. We use a deep neural network (DNN) as the state-to-action mapping function, where the state information is detected by virtual visual sensors and the action space includes two continuous spaces: speed and direction. To improve data utilization and speed up the training process, we use the proximal policy optimization based on the actor–critic (AC) framework to update the DNN parameters. Three scenes (circle, hallway, and crossing) are designed to evaluate the performance of ORCA-DRL. The results reveal that, compared with the ORCA, our proposed ORCA-DRL method can: (a) reduce the total number of frames, leading to less time for agents to reach their destination; and (b) effectively avoid local optima, evidenced by smoothed global trajectories.",
        "DOI": "10.1111/tgis.12620",
        "paper_author": "Xu D.",
        "affiliation_name": "East China Normal University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60021200",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting of water level in multiple temperate lakes using machine learning models",
        "publication": "Journal of Hydrology",
        "citied_by": "123",
        "cover_date": "2020-06-01",
        "Abstract": "Due to global climate change and growing population, fresh water resources are becoming more vulnerable to pollution. Protecting fresh water resources, especially lakes and the associated environment, is one of the key challenges faced by policy makers and water managers. Lake water level is an important physical indicator of lakes, and its fluctuation may significantly impact lake ecosystems. Therefore, reliable forecasting of lake water level is vital for a proper assessment of the health of lake ecosystems and their management. In this study, two machine learning models, including feed forward neural network (FFNN) and Deep Learning (DL) technique, were used to predict monthly lake water level. The two models were employed for one month ahead forecasting of lake water level in 69 temperate lakes in Poland. The results show that both the FFNN and the DL models performed generally well for forecasting of lake water level of the 69 lakes, with only marginal differences. The results also indicate that the DL model did not show significant superiority over the traditional FFNN model; indeed, the FFNN model slightly outperformed the DL model for 33 of the 69 lakes. These results seem to suggest that traditional machine learning models may just be sufficient for forecasting of lake water level when they are properly trained. The outcomes of the present study have important implications for water level forecasting and water resources management of lakes, especially from the perspective of machine learning models and their complexities.",
        "DOI": "10.1016/j.jhydrol.2020.124819",
        "paper_author": "Zhu S.",
        "affiliation_name": "Nanjing Hydraulic Research Institute",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60021391",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Hybrid intrusion detection and signature generation using Deep Recurrent Neural Networks",
        "publication": "Neural Computing and Applications",
        "citied_by": "61",
        "cover_date": "2020-06-01",
        "Abstract": "Automated signature generation for Intrusion Detection Systems (IDSs) for proactive security of networks is a promising area of research. An IDS monitors a system or activities of a network for detecting any policy violations or malicious actions and produces reports to the management system. Numerous solutions have been proposed by various researchers so far for intrusion detection in networks. However, the need to efficiently identifying any intrusion in the network is on the rise as the network attacks are increasing exponentially. This research work proposes a deep learning-based system for hybrid intrusion detection and signature generation of unknown web attacks referred as D-Sign. D-Sign is capable of successfully detecting and generating attack signatures with high accuracy, sensitivity and specificity. It has been for attack detection and signature generation of web-based attacks. D-Sign has reported significantly low False Positives and False Negatives. The experimental results demonstrated that the proposed system identifies the attacks proactively than other state-of-the-art approaches and generates signatures effectively thereby causing minimum damage due to network attacks.",
        "DOI": "10.1007/s00521-019-04187-9",
        "paper_author": "Kaur S.",
        "affiliation_name": "Thapar Institute of Engineering &amp; Technology",
        "affiliation_city": "Patiala",
        "affiliation_country": "India",
        "affiliation_id": "60001166",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Dynamic scheduling for flexible job shop with new job insertions by deep reinforcement learning",
        "publication": "Applied Soft Computing Journal",
        "citied_by": "351",
        "cover_date": "2020-06-01",
        "Abstract": "In modern manufacturing industry, dynamic scheduling methods are urgently needed with the sharp increase of uncertainty and complexity in production process. To this end, this paper addresses the dynamic flexible job shop scheduling problem (DFJSP) under new job insertions aiming at minimizing the total tardiness. Without lose of generality, the DFJSP can be modeled as a Markov decision process (MDP) where an intelligent agent should successively determine which operation to process next and which machine to assign it on according to the production status of current decision point, making it particularly feasible to be solved by reinforcement learning (RL) methods. In order to cope with continuous production states and learn the most suitable action (i.e. dispatching rule) at each rescheduling point, a deep Q-network (DQN) is developed to address this problem. Six composite dispatching rules are proposed to simultaneously select an operation and assign it on a feasible machine every time an operation is completed or a new job arrives. Seven generic state features are extracted to represent the production status at a rescheduling point. By taking the continuous state features as input to the DQN, the state–action value (Q-value) of each dispatching rule can be obtained. The proposed DQN is trained using deep Q-learning (DQL) enhanced by two improvements namely double DQN and soft target weight update. Moreover, a “softmax” action selection policy is utilized in real implementation of the trained DQN so as to promote the rules with higher Q-values while maintaining the policy entropy. Numerical experiments are conducted on a large number of instances with different production configurations. The results have confirmed both the superiority and generality of DQN compared to each composite rule, other well-known dispatching rules as well as the stand Q-learning-based agent.",
        "DOI": "10.1016/j.asoc.2020.106208",
        "paper_author": "Luo S.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Estimating spatio-temporal air temperature in London (UK) using machine learning and earth observation satellite data",
        "publication": "International Journal of Applied Earth Observation and Geoinformation",
        "citied_by": "71",
        "cover_date": "2020-06-01",
        "Abstract": "Urbanisation generates greater population densities and an increase in anthropogenic heat generation. These factors elevate the urban–rural air temperature (Ta) difference, thus generating the Urban Heat Island (UHI) phenomenon. Ta is used in the fields of public health and epidemiology to quantify deaths attributable to heat in cities around the world: the presence of UHI can exacerbate exposure to high temperatures during summer periods, thereby increasing the risk of heat-related mortality. Measuring and monitoring the spatial patterns of Ta in urban contexts is challenging due to the lack of a good network of weather stations. This study aims to produce a parsimonious model to retrieve maximum Ta (Tmax) at high spatio-temporal resolution using Earth Observation (EO) satellite data. The novelty of this work is twofold: (i) it will produce daily estimations of Tmax for London at 1 km2 during the summertime between 2006 and 2017 using advanced statistical techniques and satellite-derived predictors, and (ii) it will investigate for the first time the predictive power of the gradient boosting algorithm to estimate Tmax for an urban area. In this work, 6 regression models were calibrated with 6 satellite products, 3 geospatial features, and 29 meteorological stations. Stepwise linear regression was applied to create 9 groups of predictors, which were trained and tested on each regression method. This study demonstrates the potential of machine learning algorithms to predict Tmax: the gradient boosting model with a group of five predictors (land surface temperature, Julian day, normalised difference vegetation index, digital elevation model, solar zenith angle) was the regression model with the best performance (R² = 0.68, MAE = 1.60 °C, and RMSE = 2.03 °C). This methodological approach is capable of being replicated in other UK cities, benefiting national heat-related mortality assessments since the data (provided by NASA and the UK Met Office) and programming languages (Python) sources are free and open. This study provides a framework to produce a high spatio-temporal resolution of Tmax, assisting public health researchers to improve the estimation of mortality attributable to high temperatures. In addition, the research contributes to practice and policy-making by enhancing the understanding of the locations where mortality rates may increase due to heat. Therefore, it enables a more informed decision-making process towards the prioritisation of actions to mitigate heat-related mortality amongst the vulnerable population.",
        "DOI": "10.1016/j.jag.2020.102066",
        "paper_author": "dos Santos R.S.",
        "affiliation_name": "London School of Hygiene &amp; Tropical Medicine",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031331",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Deep Reinforcement Learning Based Offloading Game in Edge Computing",
        "publication": "IEEE Transactions on Computers",
        "citied_by": "174",
        "cover_date": "2020-06-01",
        "Abstract": "Edge computing is a new paradigm to provide strong computing capability at the edge of pervasive radio access networks close to users. A critical research challenge of edge computing is to design an efficient offloading strategy to decide which tasks can be offloaded to edge servers with limited resources. Although many research efforts attempt to address this challenge, they need centralized control, which is not practical because users are rational individuals with interests to maximize their benefits. In this article, we study to design a decentralized algorithm for computation offloading, so that users can independently choose their offloading decisions. Game theory has been applied in the algorithm design. Different from existing work, we address the challenge that users may refuse to expose their information about network bandwidth and preference. Therefore, it requires that our solution should make the offloading decision without such knowledge. We formulate the problem as a partially observable Markov decision process (POMDP), which is solved by a policy gradient deep reinforcement learning (DRL) based approach. Extensive simulation results show that our proposal significantly outperforms existing solutions.",
        "DOI": "10.1109/TC.2020.2969148",
        "paper_author": "Zhan Y.",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008928",
        "affiliation_state": "Hong Kong"
    },
    {
        "paper_title": "Machine learning based modeling of households: A regionalized bottom-up approach to investigate consumption-induced environmental impacts",
        "publication": "Journal of Industrial Ecology",
        "citied_by": "35",
        "cover_date": "2020-06-01",
        "Abstract": "As major drivers of economy, households induce a large share of worldwide environmental impacts. The variability of local consumption patterns and associated environmental impacts needs to be quantified as an important starting point to devise targeted measures aimed at reducing household environmental footprints. The goal of this article is the development and appraisal of a comprehensive regionalized bottom-up model that assesses realistic environmental profiles for individual households in a specific region. For this purpose, a physically based building energy model, the results of an agent-based transport simulation, and a data-driven household consumption model were interlinked within a new probability-based classification framework and applied to the case of Switzerland. The resulting model predicts the demands in about 400 different consumption areas for each Swiss household by considering its particular circumstances and produces a realistic picture of variability in household environmental footprints. An analysis of the model results on a municipal level reveals per-capita income, population density, buildings' age, and household structure as possible drivers of municipal carbon footprints. While higher-emission municipalities are located in rural areas and tend to show higher shares of older buildings, lower-emission communities have larger proportions of families and can be found in highly populated regions by trend. However, the opposing effects of various variables observed in this analysis confirm the importance of a model that is able to capture regional distinctions. The overall model constitutes a comprehensive information base supporting policymakers in understanding consumption patterns in their region and deriving environmental strategies tailored to their specific population.",
        "DOI": "10.1111/jiec.12969",
        "paper_author": "Froemelt A.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Heterogeneous Hardware-based Network Intrusion Detection System with Multiple Approaches for SDN",
        "publication": "Mobile Networks and Applications",
        "citied_by": "15",
        "cover_date": "2020-06-01",
        "Abstract": "Software-Defined Networking has became one of the most efficient network architectures to deal with complexity, policy control improvement, and vendor dependencies removal. Besides, with the diversity of network attacks, the SDN architecture faces many security issues that need to be taken into account. In this work, we propose an architecture for SDN-based secured forwarding devices (switches) by extending our previous architecture - HPOFS with multiple security functions including lightweight DDoS mechanisms, signature-based and anomaly-based IDS. We implement our architecture on a heterogeneous system including host processors, GPU, and FPGA boards. To the best of our knowledge, this is the first forwarding device for SDN implemented on a heterogeneous system in the literature. Our system not only is enhanced security but also provides a high-speed switching capacity based on the OpenFlow standard. The implemented design on GTX Geforce 1080 G1 for training phase is 14× faster when compared to CPU Intel Core i7 – 4770, 3.4GHz, 16GB of RAM on the Ubuntu version 14.04. The switching function along with three lightweight DDoS detection/prevention mechanisms provide processing speed at 39.48 Gbps on a NetFPGA-10G board (with a Xilinx xc5vtx240t FPGA device). Especially, our neural network models on the NetFPGA-10G board outperform CPU in processing performance by reaching throughputs at 4.84 Gbps. Moreover, the implemented neural network model achieves 99.01% precision with only 0.02% false positive rate when processing a dataset.",
        "DOI": "10.1007/s11036-019-01437-x",
        "paper_author": "Ngo D.M.",
        "affiliation_name": "Ho Chi Minh City University of Technology - HUTECH",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60071399",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modeling of electricity demand forecast for power system",
        "publication": "Neural Computing and Applications",
        "citied_by": "30",
        "cover_date": "2020-06-01",
        "Abstract": "The emerging complex circumstances caused by economy, technology, and government policy and the requirement of low-carbon development of power grid lead to many challenges in the power system coordination and operation. However, the real-time scheduling of electricity generation needs accurate modeling of electricity demand forecasting for a range of lead times. In order to better capture the nonlinear and non-stationary characteristics and the seasonal cycles of future electricity demand data, a new concept of the integrated model is developed and successfully applied to research the forecast of electricity demand in this paper. The proposed model combines adaptive Fourier decomposition method, a new signal preprocessing technology, for extracting useful element from the original electricity demand series through filtering the noise factors. Considering the seasonal term existing in the decomposed series, it should be eliminated through the seasonal adjustment method, in which the seasonal indexes are calculated and should multiply the forecasts back to restore the final forecast. Besides, a newly proposed moth-flame optimization algorithm is used to ensure the suitable parameters of the least square support vector machine which can generate the forecasts. Finally, the case studies of Australia demonstrated the efficacy and feasibility of the proposed integrated model. Simultaneously, it can provide a better concept of modeling for electricity demand prediction over different forecasting horizons.",
        "DOI": "10.1007/s00521-019-04153-5",
        "paper_author": "Jiang P.",
        "affiliation_name": "Dongbei University of Finance and Economics",
        "affiliation_city": "Dalian",
        "affiliation_country": "China",
        "affiliation_id": "60016094",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Joint inference of reward machines and policies for reinforcement learning",
        "publication": "Proceedings International Conference on Automated Planning and Scheduling, ICAPS",
        "citied_by": "60",
        "cover_date": "2020-05-29",
        "Abstract": "Incorporating high-level knowledge is an effective way to expedite reinforcement learning (RL), especially for complex tasks with sparse rewards. We investigate an RL problem where the high-level knowledge is in the form of reward machines, a type of Mealy machines that encode non-Markovian reward functions. We focus on a setting in which this knowledge is a priori not available to the learning agent. We develop an iterative algorithm that performs joint inference of reward machines and policies for RL (more specifically, q-learning). In each iteration, the algorithm maintains a hypothesis reward machine and a sample of RL episodes. It uses a separate q-function defined for each state of the current hypothesis reward machine to determine the policy and performs RL to update the q-functions. While performing RL, the algorithm updates the sample by adding RL episodes along which the obtained rewards are inconsistent with the rewards based on the current hypothesis reward machine. In the next iteration, the algorithm infers a new hypothesis reward machine from the updated sample. Based on an equivalence relation between states of reward machines, we transfer the q-functions between the hypothesis reward machines in consecutive iterations. We prove that the proposed algorithm converges almost surely to an optimal policy in the limit. The experiments show that learning high-level knowledge in the form of reward machines leads to fast convergence to optimal policies in RL, while the baseline RL methods fail to converge to optimal policies after a substantial number of training steps.",
        "DOI": "10.1609/icaps.v30i1.6756",
        "paper_author": "Xu Z.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Digital Debt Collection and Ecologies of Consumer Overindebtedness",
        "publication": "Economic Geography",
        "citied_by": "20",
        "cover_date": "2020-05-26",
        "Abstract": "New digital financial technologies (fintech) are changing the contours of the consumer debt industry. The aim of this article is to address the challenges that these shifts pose for the operation and regulation of the debt collection industry and how they map onto existing spatial ecologies of consumer overindebtedness. Two ideal types of consumer debt ecosystems are developed: a mainstream ecology based on traditional modes of operating that include some practices that have existed for centuries; and a new digital ecology comprising new digital entrants that use artificial intelligence, machine learning, and data mining. A fourfold framework provides a lens through which the new fintech debt ecology is analyzed: debt repayment, debt reporting, debt accounting, and debt prevention. The challenges digital debt collection pose for financial exclusion, digital inequality, the digital divide, and the implications for policy makers and regulators are discussed.",
        "DOI": "10.1080/00130095.2020.1762486",
        "paper_author": "Burton D.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Characterizing Motor Control of Mastication With Soft Actor-Critic",
        "publication": "Frontiers in Human Neuroscience",
        "citied_by": "5",
        "cover_date": "2020-05-26",
        "Abstract": "The human masticatory system is a complex functional unit characterized by a multitude of skeletal components, muscles, soft tissues, and teeth. Muscle activation dynamics cannot be directly measured on live human subjects due to ethical, safety, and accessibility limitations. Therefore, estimation of muscle activations and their resultant forces is a longstanding and active area of research. Reinforcement learning (RL) is an adaptive learning strategy which is inspired by the behavioral psychology and enables an agent to learn the dynamics of an unknown system via policy-driven explorations. The RL framework is a well-formulated closed-loop system where high capacity neural networks are trained with the feedback mechanism of rewards to learn relatively complex actuation patterns. In this work, we are building on a deep RL algorithm, known as the Soft Actor-Critic, to learn the inverse dynamics of a simulated masticatory system, i.e., learn the activation patterns that drive the jaw to its desired location. The outcome of the proposed training procedure is a parametric neural model which acts as the brain of the biomechanical system. We demonstrate the model's ability to navigate the feasible three-dimensional (3D) envelope of motion with sub-millimeter accuracies. We also introduce a performance analysis platform consisting of a set of quantitative metrics to assess the functionalities of a given simulated masticatory system. This platform assesses the range of motion, metabolic efficiency, the agility of motion, the symmetry of activations, and the accuracy of reaching the desired target positions. We demonstrate how the model learns more metabolically efficient policies by integrating a force regularization term in the RL reward. We also demonstrate the inverse correlation between the metabolic efficiency of the models and their agility and range of motion. The presented masticatory model and the proposed RL training mechanism are valuable tools for the analysis of mastication and other biomechanical systems. We see this framework's potential in facilitating the functional analyses aspects of surgical treatment planning and predicting the rehabilitation performance in post-operative subjects.",
        "DOI": "10.3389/fnhum.2020.00188",
        "paper_author": "Abdi A.H.",
        "affiliation_name": "The University of British Columbia",
        "affiliation_city": "Vancouver",
        "affiliation_country": "Canada",
        "affiliation_id": "60010365",
        "affiliation_state": "BC"
    },
    {
        "paper_title": "Exploration of GPU sharing policies under GEMM workloads",
        "publication": "Proceedings of the 23rd International Workshop on Software and Compilers for Embedded Systems, SCOPES 2020",
        "citied_by": "1",
        "cover_date": "2020-05-25",
        "Abstract": "Lately, cloud computing has seen explosive growth, due to the flexibility and scalability it offers. The ever-increasing computational demands, especially from the machine learning domain, have forced cloud operators to enhance their infrastructure with acceleration devices, such as General-Purpose (GP)GPUs or FPGAs. Even though multi-tenancy has been widely examined for conventional CPUs, this is not the case for accelerators. Current solutions support \"one accelerator per user\" schemes, which can lead to both under-utilization and starvation of available resources. In this work, we analyze the potentials of GPU sharing inside data-center environments. We investigate how several architectural features affect the performance of GPUs under different multi-tenant stressing scenarios. We compare CUDA MPS with the native, default CUDA scheduler and also with Vinetalk, a research framework providing GPU sharing capabilities. Experimental results show that NVIDIA's MPS achieves the best performance in multi-application scenarios, specifically up to X4.5 and X11.2 compared to native CUDA scheduler and Vinetalk respectively.",
        "DOI": "10.1145/3378678.3391887",
        "paper_author": "Oroutzoglou I.",
        "affiliation_name": "National Technical University of Athens (NTUA)",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece",
        "affiliation_id": "60002947",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "Industrial internet of things and cyber-physical systems: Transforming the conventional to digital",
        "publication": "Industrial Internet of Things and Cyber-Physical Systems: Transforming the Conventional to Digital",
        "citied_by": "1",
        "cover_date": "2020-05-22",
        "Abstract": "With the help of artificial intelligence, machine learning, and big data analytics, the internet of things (IoT) is creating partnerships within industry where machines, processes, and humans communicate with one another. As this radically changes traditional industrial operations, this results in the rapid design, cheap manufacture, and effective customization of products. Answering the growing demand of customers and their preferences has become a challenge for such partnerships. Industrial Internet of Things and Cyber-Physical Systems: Transforming the Conventional to Digital is a collection of innovative research that discusses development, implementation, and business impacts of IoT technologies on sustainable societal development and improved life quality. Highlighting a wide range of topics such as green technologies, wireless networks, and IoT policy, this book is ideally designed for technology developers, entrepreneurs, industrialists, programmers, engineers, technicians, researchers, academicians, and students.",
        "DOI": "10.4018/978-1-7998-2803-7",
        "paper_author": "Kumar P.",
        "affiliation_name": "Quaid-e-Awam University of Engineering, Science &amp; Technology",
        "affiliation_city": "Nawabshah",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60274285",
        "affiliation_state": "Sindh"
    },
    {
        "paper_title": "A Mini-Review on High-Penetration Renewable Integration Into a Smarter Grid",
        "publication": "Frontiers in Energy Research",
        "citied_by": "20",
        "cover_date": "2020-05-21",
        "Abstract": "With the increasingly serious energy crisis and environmental pollution, the development and utilization of renewable energy resources have become an indispensable choice to ensure secure and sustainable energy supply. In recent years, the installed capacities of renewable generations such as wind power and photovoltaic are rapidly increasing, changing power generating sources of power systems from predominantly fossil power generation to high penetration of renewable generations. Unfortunately, the inherent uncertainty and variability of renewable energy sources will pose huge operational challenges in today's power systems. At the same time, new emerging techniques, such as smart inverters, advanced communication protocols, and machine learning, provide more regulatory means available for better integration of high-penetration renewables. This paper deals with a mini-review of several emerging technologies for high-penetration renewable integration (HPRI). The main aim of this paper is the introduction of the basic concepts, principles, as well as the presentation of the main applications of these technologies in smart grids. Additionally, the challenges faced and future prospects of these technologies are also discussed. In this paper, an attempt has been made to present a comprehensive review of the research on emerging technologies in the field of renewable integration in recent years.",
        "DOI": "10.3389/fenrg.2020.00084",
        "paper_author": "Li Y.",
        "affiliation_name": "Northeast Electric Power University",
        "affiliation_city": "Jilin",
        "affiliation_country": "China",
        "affiliation_id": "60073562",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Counting crowds using a scale-distribution-aware network and adaptive human-shaped kernel",
        "publication": "Neurocomputing",
        "citied_by": "18",
        "cover_date": "2020-05-21",
        "Abstract": "Intelligent bus system plays a key role in the modern smart city. The number of passengers in the buses or at the stations is necessary for making an optimal scheduling policy of public buses. We develop a crowd counting algorithm to provide the counting information for a bus dispatch system in a human–machine system. In consideration of the challenges (e.g., pedestrian occlusions, non-uniform crowd distributions, and scale variations) existed in hand-crafted features based crowd counting, a scale-distribution-aware multi-column convolutional neural network (SDA-MCNN) is presented to count crowds by summing up the output (denoted as the density map) of the SDA-MCNN. The SDA-MCNN is robust to scale variations by processing a crowd image with multiple convolutional neural network (CNN) columns and minimizing the per-scale loss. A weighted Euclidean loss is proposed to handle non-uniform crowd distributions. The loss can increase activations in dense regions and restrain activations in backgrounds. A new approach to estimate perspective maps of dense crowds is put forward to offer necessary information for generating density maps with human-shaped kernels. Evaluations on benchmarks are performed with other state-of-the-art counting approaches using deep neural networks. Comparative results verify the accuracy of our counting approach in challenging crowds. Evaluations on the real world BUS data reveal the accuracy of the proposed approach in counting passengers in spite of the complex environment.",
        "DOI": "10.1016/j.neucom.2019.02.071",
        "paper_author": "Yang B.",
        "affiliation_name": "Changzhou University",
        "affiliation_city": "Changzhou",
        "affiliation_country": "China",
        "affiliation_id": "60104429",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Variability in Action Selection Relates to Striatal Dopamine 2/3 Receptor Availability in Humans: A PET Neuroimaging Study Using Reinforcement Learning and Active Inference Models",
        "publication": "Cerebral Cortex",
        "citied_by": "19",
        "cover_date": "2020-05-18",
        "Abstract": "Choosing actions that result in advantageous outcomes is a fundamental function of nervous systems. All computational decision-making models contain a mechanism that controls the variability of (or confidence in) action selection, but its neural implementation is unclear-especially in humans. We investigated this mechanism using two influential decision-making frameworks: Active inference (AI) and reinforcement learning (RL). In AI, the precision (inverse variance) of beliefs about policies controls action selection variability-similar to decision 'noise' parameters in RL- A nd is thought to be encoded by striatal dopamine signaling. We tested this hypothesis by administering a 'go/no-go' task to 75 healthy participants, and measuring striatal dopamine 2/3 receptor (D2/3R) availability in a subset (n = 25) using [11C]-(+)-PHNO positron emission tomography. In behavioral model comparison, RL performed best across the whole group but AI performed best in participants performing above chance levels. Limbic striatal D2/3R availability had linear relationships with AI policy precision (P = 0.029) as well as with RL irreducible decision 'noise' (P = 0.020), and this relationship with D2/3R availability was confirmed with a 'decision stochasticity' factor that aggregated across both models (P = 0.0006). These findings are consistent with occupancy of inhibitory striatal D2/3Rs decreasing the variability of action selection in humans.",
        "DOI": "10.1093/cercor/bhz327",
        "paper_author": "Adams R.A.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence and the future of global health",
        "publication": "The Lancet",
        "citied_by": "389",
        "cover_date": "2020-05-16",
        "Abstract": "Concurrent advances in information technology infrastructure and mobile computing power in many low and middle-income countries (LMICs) have raised hopes that artificial intelligence (AI) might help to address challenges unique to the field of global health and accelerate achievement of the health-related sustainable development goals. A series of fundamental questions have been raised about AI-driven health interventions, and whether the tools, methods, and protections traditionally used to make ethical and evidence-based decisions about new technologies can be applied to AI. Deployment of AI has already begun for a broad range of health issues common to LMICs, with interventions focused primarily on communicable diseases, including tuberculosis and malaria. Types of AI vary, but most use some form of machine learning or signal processing. Several types of machine learning methods are frequently used together, as is machine learning with other approaches, most often signal processing. AI-driven health interventions fit into four categories relevant to global health researchers: (1) diagnosis, (2) patient morbidity or mortality risk assessment, (3) disease outbreak prediction and surveillance, and (4) health policy and planning. However, much of the AI-driven intervention research in global health does not describe ethical, regulatory, or practical considerations required for widespread use or deployment at scale. Despite the field remaining nascent, AI-driven health interventions could lead to improved health outcomes in LMICs. Although some challenges of developing and deploying these interventions might not be unique to these settings, the global health community will need to work quickly to establish guidelines for development, testing, and use, and develop a user-driven research agenda to facilitate equitable and ethical use.",
        "DOI": "10.1016/S0140-6736(20)30226-9",
        "paper_author": "Schwalbe N.",
        "affiliation_name": "Mailman School of Public Health",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60012769",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Temporal Convolutional Network for Pork Price Prediction",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "2",
        "cover_date": "2020-05-15",
        "Abstract": "With the continuous economic development, China's pork consumption and demand market are expanding. But in recent years, due to the rising cost of raising pigs and the environmental protection policies in animal husbandry, China's domestic pork production has been restricted. It is not difficult to see that the domestic pork price volatility has always existed and had a profound impact on household consumption. Therefore, a prediction model for pork prices is essential, which can be used by governments, enterprises or residents to grasp the information in the pork market. Therefore, a prediction model for pork prices is essential. In this paper, a pork price prediction model is proposed, which is based on the Temporal Convolution Network (TCN). The experimental data are from China's National Agricultural Product Price Database. We select the daily pork price of Yunyang Vegetable Wholesale Market in Jingyang County, Shaanxi Province from Feb.1st, 2017 to Jan.31st, 2020. Experimental results show that based on grasping a large amount of effective historical information, TCN model effectively improves the accuracy of short-Term prediction, and has better performance and practical significance in pork price prediction.",
        "DOI": "10.1145/3437075.3437077",
        "paper_author": "Yang Y.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Brain Morphological Dynamics of Procrastination: The Crucial Role of the Self-Control, Emotional, and Episodic Prospection Network",
        "publication": "Cerebral Cortex",
        "citied_by": "37",
        "cover_date": "2020-05-14",
        "Abstract": "Globally, about 17% individuals are suffering from the maladaptive procrastination until now, which impacts individual's financial status, mental health, and even public policy. However, the comprehensive understanding of neuroanatomical understructure of procrastination still remains gap. 688 participants including 3 independent samples were recruited for this study. Brain morphological dynamics referred to the idiosyncrasies of both brain size and brain shape. Multilinear regression analysis was utilized to delineate brain morphological dynamics of procrastination in Sample 1. In the Sample 2, cross-validation was yielded. Finally, prediction models of machine learning were conducted in Sample 3. Procrastination had a significantly positive correlation with the gray matter volume (GMV) in the left insula, anterior cingulate gyrus (ACC), and parahippocampal gyrus (PHC) but was negatively correlated with GMV of dorsolateral prefrontal cortex (dlPFC) and gray matter density of ACC. Furthermore, procrastination was positively correlated to the cortical thickness and cortical complexity of bilateral orbital frontal cortex (OFC). In Sample 2, all the results were cross-validated highly. Predication analysis demonstrated that these brain morphological dynamic can predict procrastination with high accuracy. This study ascertained the brain morphological dynamics involving in self-control, emotion, and episodic prospection brain network for procrastination, which advanced promising aspects of the biomarkers for it.",
        "DOI": "10.1093/cercor/bhz278",
        "paper_author": "Chen Z.",
        "affiliation_name": "Southwest University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China",
        "affiliation_id": "60122052",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ideas for how informaticians can get involved with COVID-19 research",
        "publication": "BioData Mining",
        "citied_by": "22",
        "cover_date": "2020-05-12",
        "Abstract": "The coronavirus disease 2019 (COVID-19) pandemic has had a significant impact on population health and wellbeing. Biomedical informatics is central to COVID-19 research efforts and for the delivery of healthcare for COVID-19 patients. Critical to this effort is the participation of informaticians who typically work on other basic science or clinical problems. The goal of this editorial is to highlight some examples of COVID-19 research areas that could benefit from informatics expertise. Each research idea summarizes the COVID-19 application area, followed by an informatics methodology, approach, or technology that could make a contribution. It is our hope that this piece will motivate and make it easy for some informaticians to adopt COVID-19 research projects.",
        "DOI": "10.1186/s13040-020-00213-y",
        "paper_author": "Moore J.H.",
        "affiliation_name": "University of Pennsylvania Perelman School of Medicine",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60003711",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Estimating geographic subjective well-being from Twitter: A comparison of dictionary and data-driven language methods",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "144",
        "cover_date": "2020-05-12",
        "Abstract": "Researchers and policy makers worldwide are interested in measuring the subjective well-being of populations. When users post on social media, they leave behind digital traces that reflect their thoughts and feelings. Aggregation of such digital traces may make it possible to monitor well-being at large scale. However, social media-based methods need to be robust to regional effects if they are to produce reliable estimates. Using a sample of 1.53 billion geotagged English tweets, we provide a systematic evaluation of word-level and data-driven methods for text analysis for generating well-being estimates for 1,208 US counties. We compared Twitter-based county-level estimates with well-being measurements provided by the Gallup-Sharecare Well-Being Index survey through 1.73 million phone surveys. We find that word-level methods (e.g., Linguistic Inquiry and Word Count [LIWC] 2015 and Language Assessment by Mechanical Turk [LabMT]) yielded inconsistent county-level well-being measurements due to regional, cultural, and socioeconomic differences in language use. However, removing as few as three of the most frequent words led to notable improvements in well-being prediction. Data-driven methods provided robust estimates, approximating the Gallup data at up to r = 0.64. We show that the findings generalized to county socioeconomic and health outcomes and were robust when poststratifying the samples to be more representative of the general US population. Regional well-being estimation from social media data seems to be robust when supervised data-driven methods are used.",
        "DOI": "10.1073/pnas.1906364117",
        "paper_author": "Jaidka K.",
        "affiliation_name": "National University of Singapore",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60017161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "On Consequentialism and Fairness",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "24",
        "cover_date": "2020-05-08",
        "Abstract": "Recent work on fairness in machine learning has primarily emphasized how to define, quantify, and encourage “fair” outcomes. Less attention has been paid, however, to the ethical foundations which underlie such efforts. Among the ethical perspectives that should be taken into consideration is consequentialism, the position that, roughly speaking, outcomes are all that matter. Although consequentialism is not free from difficulties, and although it does not necessarily provide a tractable way of choosing actions (because of the combined problems of uncertainty, subjectivity, and aggregation), it nevertheless provides a powerful foundation from which to critique the existing literature on machine learning fairness. Moreover, it brings to the fore some of the tradeoffs involved, including the problem of who counts, the pros and cons of using a policy, and the relative value of the distant future. In this paper we provide a consequentialist critique of common definitions of fairness within machine learning, as well as a machine learning perspective on consequentialism. We conclude with a broader discussion of the issues of learning and randomization, which have important implications for the ethics of automated decision making systems.",
        "DOI": "10.3389/frai.2020.00034",
        "paper_author": "Card D.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "China's digital transformation: The key role of artificial intelligence in the Chinese economy and society",
        "publication": "The Changing Global Environment in Asia and Human Resource Management Strategies",
        "citied_by": "1",
        "cover_date": "2020-05-07",
        "Abstract": "China's innovation policies have been based on incremental applications of existing technologies and protectionist policies, which favored profitable oligopolies. The scale of the Chinese market has also been a decisive factor. The rise of the internet and e-commerce have been linked to the widespread use of smartphones. Currently, the rapid development of computer power and the accumulation of data by Baidu, Alibaba and Tencent (BAT), the three dominant firms, has opened the way to the rise of artificial intelligence (AI), the next frontier for productivity in key sectors (transport, health, manufacturing, energy). It is also an efficient tool for social surveillance and governance of the stateparty system, and a technology that may determine geopolitical supremacy. The mix of cooperation and competition with the United States is especially relevant in AI, where China is catching up with the US in talent as well as in chip technology, both crucial for machine learning.",
        "DOI": "NA",
        "paper_author": "Fabre G.",
        "affiliation_name": "Université Paul-Valéry Montpellier III",
        "affiliation_city": "Montpellier",
        "affiliation_country": "France",
        "affiliation_id": "60009278",
        "affiliation_state": "Occitanie"
    },
    {
        "paper_title": "Determining optimal strategies for primary prevention of cardiovascular disease: Systematic review, cost-effectiveness review and network meta-analysis protocol",
        "publication": "Systematic Reviews",
        "citied_by": "7",
        "cover_date": "2020-05-07",
        "Abstract": "Background: Despite recent improvements in the burden of cardiovascular disease (CVD) in the UK, deaths from CVD are relatively high compared with other high-income countries. An estimated 7 million people in the UK are living with CVD, and the healthcare cost is approximately £11 billion annually. In more than 90% of cases, the risk of a first heart attack is thought to be related to modifiable risk factors including smoking, poor diet, lipidemia, high blood pressure, inactivity, obesity and excess alcohol consumption. The aim of the study is to synthesise evidence for the comparative effectiveness and cost-effectiveness of different interventions for the primary prevention of CVD. Methods: We will systematically search databases (for example, MEDLINE (Ovid), Embase (Ovid), Cochrane Library) and the reference lists of previous systematic reviews for randomised controlled trials that assess the effectiveness and cost-effectiveness of any form of intervention aimed at adult populations for the primary prevention of CVD, including but not limited to lipid lowering medications, blood pressure lowering medications, antiplatelet agents, nutritional supplements, dietary interventions, health promotion programmes, physical activity interventions or structural and policy interventions. Interventions may or may not be targeted at high-risk groups. Publications from any year will be considered for inclusion. The primary outcome will be all cause mortality. Secondary outcomes will be cardiovascular diseases related mortality, major cardiovascular events, coronary heart disease, incremental costs per quality-adjusted life years gained. If data permits, we will use network meta-analysis to compare and rank effectiveness of different interventions, and test effect modification of intervention effectiveness using subgroup analyses and meta-regression analyses. Discussion: The results will be important for policymakers when making decisions between multiple possible alternative strategies to prevent CVD. Compared to results from existing multiple separate pairwise meta-analyses, this overarching synthesis of all relevant work will enhance decision-making. The findings will be crucial to inform evidence-based priorities and guidelines for policies and planning prevention strategies of CVD. Systematic review registration: PROSPERO CRD42019123940.",
        "DOI": "10.1186/s13643-020-01366-x",
        "paper_author": "Uthman O.A.",
        "affiliation_name": "Warwick Medical School",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60000064",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "Respiratory diseases, malaria and leishmaniasis: Temporal and spatial association with fire occurrences from knowledge discovery and data mining",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "5",
        "cover_date": "2020-05-05",
        "Abstract": "The relationship between the fires occurrences and diseases is an essential issue for making public health policy and environment protecting strategy. Thanks to the Internet, today, we have a huge amount of health data and fire occurrence reports at our disposal. The challenge, therefore, is how to deal with 4 Vs (volume, variety, velocity and veracity) associated with these data. To overcome this problem, in this paper, we propose a method that combines techniques based on Data Mining and Knowledge Discovery from Databases (KDD) to discover spatial and temporal association between diseases and the fire occurrences. Here, the case study was addressed to Malaria, Leishmaniasis and respiratory diseases in Brazil. Instead of losing a lot of time verifying the consistency of the database, the proposed method uses Decision Tree, a machine learning-based supervised classification, to perform a fast management and extract only relevant and strategic information, with the knowledge of how reliable the database is. Namely, States, Biomes and period of the year (months) with the highest rate of fires could be identified with great success rates and in few seconds. Then, the K-means, an unsupervised learning algorithms that solves the well-known clustering problem, is employed to identify the groups of cities where the fire occurrences is more expressive. Finally, the steps associated with KDD is perfomed to extract useful information from mined data. In that case, Spearman’s rank correlation coefficient, a nonparametric measure of rank correlation, is computed to infer the statistical dependence between fire occurrences and those diseases. Moreover, maps are also generated to represent the distribution of the mined data. From the results, it was possible to identify that each region showed a susceptible behaviour to some disease as well as some degree of correlation with fire outbreak, mainly in the drought period.",
        "DOI": "10.3390/ijerph17103718",
        "paper_author": "Schroeder L.",
        "affiliation_name": "Universidade do Vale do Rio dos Sinos",
        "affiliation_city": "Sao Leopoldo",
        "affiliation_country": "Brazil",
        "affiliation_id": "60024559",
        "affiliation_state": "RS"
    },
    {
        "paper_title": "Increasing the detail of European land use/cover data by combining heterogeneous data sets",
        "publication": "International Journal of Digital Earth",
        "citied_by": "33",
        "cover_date": "2020-05-03",
        "Abstract": "Data on land use and land cover (LULC) are a vital input for policy-relevant research, such as modelling of the human population, socioeconomic activities, transportation, environment, and their interactions. In Europe, CORINE Land Cover has been the only data set covering the entire continent consistently, but with rather limited spatial detail. Other data sets have provided much better detail, but either have covered only a fraction of Europe (e.g. Urban Atlas) or have been thematically restricted (e.g. Copernicus High Resolution Layers). In this study, we processed and combined diverse LULC data to create a harmonised, ready-to-use map covering 41 countries. By doing so, we increased the spatial detail (from 25 to one hectare) and the thematic detail (by seven additional LULC classes) compared to the CORINE Land Cover. Importantly, we decomposed the class ‘Industrial and commercial units’ into ‘Production facilities’, ‘Commercial/service facilities’ and ‘Public facilities’ using machine learning to exploit a large database of points of interest. The overall accuracy of this thematic breakdown was 74%, despite the confusion between the production and commercial land uses, often attributable to noisy training data or mixed land uses. Lessons learnt from this exercise are discussed, and further research direction is proposed.",
        "DOI": "10.1080/17538947.2018.1550119",
        "paper_author": "Rosina K.",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "60103695",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Optimized forecasting method for weekly influenza confirmed cases",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "17",
        "cover_date": "2020-05-02",
        "Abstract": "Influenza epidemic is a serious threat to the entire world, which causes thousands of death every year and can be considered as a public health emergency that needs to be more addressed and investigated. Forecasting influenza incidences or confirmed cases is very important to do the necessary policies and plans for governments and health organizations. In this paper, we present an enhanced adaptive neuro-fuzzy inference system (ANFIS) to forecast the weekly confirmed influenza cases in China and the USA using official datasets. To overcome the limitations of the original ANFIS, we use two metaheuristics, called flower pollination algorithm (FPA) and sine cosine algorithm (SCA), to enhance the prediction of the ANFIS. The proposed FPASCA-ANFIS is evaluated using two datasets collected from the CDC and WHO websites. Furthermore, it was compared to some previous state-of-the-art approaches. Experimental results confirmed that the FPASCA-ANFIS outperformed the compared methods using variant measures, including RMSRE, MAPE, MAE, and R2.",
        "DOI": "10.3390/ijerph17103510",
        "paper_author": "Al-Qaness M.A.A.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60029306",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "A deep learning approach for the dynamic dispatching of unreliable machines in re-entrant production systems",
        "publication": "International Journal of Production Research",
        "citied_by": "29",
        "cover_date": "2020-05-02",
        "Abstract": "This research combines deep neural network (DNN) and Markov decision processes (MDP) for the dynamic dispatching of re-entrant production systems. In re-entrant production systems, jobs enter the same workstation multiple times and dynamic dispatching oftentimes aims to dynamically assign different priorities to various job groups to minimise weighted cycle time or maximise throughput. MDP is an effective tool for dynamic production control, but it suffers from two major challenges in dynamic control problems. First, the curse of dimensionality limits the computational performance of solving large MDP problems. Second, a different model should be built and solved after system configuration is changed. DNN is used to overcome both challenges by learning directly from optimal dispatching policies generated by MDP. Results suggest that a properly trained DNN model can instantly generate near-optimal dynamic control policies for large problems. The quality of the DNN solution is compared with the optimal dynamic control policies through the standard K-fold cross-validation test and discrete event simulation. On average, the performance of the DNN policy is within 2% of optimal in both tests. The proposed artificial intelligence algorithm illustrates the potential of machine learning methods in manufacturing applications.",
        "DOI": "10.1080/00207543.2020.1727041",
        "paper_author": "Wu C.H.",
        "affiliation_name": "National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60005429",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Automatic design of scheduling policies for dynamic flexible job shop scheduling via surrogate-assisted cooperative co-evolution genetic programming",
        "publication": "International Journal of Production Research",
        "citied_by": "73",
        "cover_date": "2020-05-02",
        "Abstract": "At present, a lot of references use discrete event simulation to evaluate the fitness of evolved rules, but which simulation configuration can achieve better evolutionary rules in a limited time has not been fully studied. This study proposes three types of hyper-heuristic methods for coevolution of the machine assignment rules (MAR) and job sequencing rules (JSR) to solve the DFJSP, including the cooperative coevolution genetic programming with two sub-populations (CCGP), the genetic programming with two sub-trees (TTGP) and the genetic expression programming with two sub-chromosomes (GEP). After careful parameter tuning, a surrogate simulation model is used to evaluate the fitness of evolved scheduling policies (SP). Computational simulations and comparisons demonstrate that the proposed surrogate-assisted CCGP method (CCGP-SM) shows competitive performance with other evolutionary approaches using the same computation time. Furthermore, the learning process of the proposed methods demonstrates that the surrogate-assisted GP methods help accelerating the evolutionary process and improving the quality of the evolved SPs without a signiﬁcant increase in the length of SP. In addition, the evolved SPs generated by the CCGP-SM show superior performance as compared with existing rules in the literature. These results demonstrate the effectiveness and robustness of the proposed method.",
        "DOI": "10.1080/00207543.2019.1620362",
        "paper_author": "Zhou Y.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013789",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "On the robustness of cooperative multi-agent reinforcement learning",
        "publication": "Proceedings - 2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",
        "citied_by": "44",
        "cover_date": "2020-05-01",
        "Abstract": "In cooperative multi-agent reinforcement learning (c-MARL), agents learn to cooperatively take actions as a team to maximize a total team reward. We analyze the robustness of c-MARL to adversaries capable of attacking one of the agents on a team. Through the ability to manipulate this agent's observations, the adversary seeks to decrease the total team reward. Attacking c-MARL is challenging for three reasons: first, it is difficult to estimate team rewards or how they are impacted by an agent mispredicting; second, models are non-differentiable; and third, the feature space is low-dimensional. Thus, we introduce a novel attack. The attacker first trains a policy network with reinforcement learning to find a wrong action it should encourage the victim agent to take. Then, the adversary uses targeted adversarial examples to force the victim to take this action. Our results on the StartCraft II multi-agent benchmark demonstrate that c-MARL teams are highly vulnerable to perturbations applied to one of their agent's observations. By attacking a single agent, our attack method has highly negative impact on the overall team reward, reducing it from 20 to 9.4. This results in the team's winning rate to go down from 98.9% to 0%.",
        "DOI": "10.1109/SPW50608.2020.00027",
        "paper_author": "Lin J.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "RTA3: A real time adversarial attack on recurrent neural networks",
        "publication": "Proceedings - 2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",
        "citied_by": "3",
        "cover_date": "2020-05-01",
        "Abstract": "Recurrent neural networks are widely used in machine learning systems that process time series data including health monitoring, object tracking in video, and automatic speech recognition (ASR). While much work has been done demonstrating the vulnerability of deep neural networks to socalled adversarial perturbations, the majority of this work has focused on convolutional neural networks that process non-sequential data for tasks like image recognition. We propose that the unique memory and parameter sharing properties of recurrent neural networks make them susceptible to periodic adversarial perturbations that can exploit these unique features. In this paper, we demonstrate a general application of deep reinforcement learning to the generation of periodic adversarial perturbations in a black-box approach to attack recurrent neural networks processing sequential data. We successfully learn an attack policy to generate adversarial perturbations against the DeepSpeech ASR system and further demonstrate that this attack policy generalizes to a set of unseen examples in real time.",
        "DOI": "10.1109/SPW50608.2020.00022",
        "paper_author": "Serrano C.R.",
        "affiliation_name": "HRL Laboratories",
        "affiliation_city": "Malibu",
        "affiliation_country": "United States",
        "affiliation_id": "60021939",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Transfer Learning Applied to Reinforcement Learning-Based HVAC Control",
        "publication": "SN Computer Science",
        "citied_by": "26",
        "cover_date": "2020-05-01",
        "Abstract": "Modern control solutions for HVAC have demonstrated excellent cost and energy savings through the utilisation of machine learning techniques. However, a challenging problem faced by most machine learning tasks is the amount of time and data required to train effective policies in the absence of prior knowledge. Considering that buildings from a specific geographical location share common environmental and structural features, this paper investigates the impact of spatial changes on performance accuracy through the use of transfer learning applied to reinforcement learning based HVAC control. We propose the development of an adapted RL (Q-learning) algorithm which can transfer HVAC control polices, adjusting themselves according to spatial changes. We examine the performance of our approach across multiple different locations. Moreover, an analysis of the user’s time out comfort has been made, comparing models with and without transfer learning. The results from different cases show that after applying transfer learning the learning time to train optimal or near-optimal control policies was reduced by more than a factor of 6 when comparing to experiments without it. Furthermore, the test case where the spatial variation was lower than 50% achieved a similar performance for both dynamic and static HVAC control, presenting an average time out comfort error of 2.55% and 3.83%, respectively. From the user’s perspective, it means they will not feel any additional discomfort, as the number of minutes out of the comfort zone for the static version is approximately the same for a 1-day interval. Finally, when examining the effect of transfer learning on geographical changes, the proposed method demonstrated higher performance in countries where the temperature variation is lower, reducing time out comfort by one-third. If an agent receives a policy from a place where the environmental conditions are very different the proposed method will still work and find the best policy, but not as fast as receiving it from a similar place.",
        "DOI": "10.1007/s42979-020-00146-7",
        "paper_author": "Lissa P.",
        "affiliation_name": "University of Galway",
        "affiliation_city": "Galway",
        "affiliation_country": "Ireland",
        "affiliation_id": "60008539",
        "affiliation_state": "Connacht"
    },
    {
        "paper_title": "Autonomous guidewire navigation in a two dimensional vascular phantom",
        "publication": "Current Directions in Biomedical Engineering",
        "citied_by": "34",
        "cover_date": "2020-05-01",
        "Abstract": "The treatment of cerebro- and cardiovascular diseases requires complex and challenging navigation of a catheter. Previous attempts to automate catheter navigation lack the ability to be generalizable. Methods of Deep Reinforcement Learning show promising results and may be the key to automate catheter navigation through the tortuous vascular tree. This work investigates Deep Reinforcement Learning for guidewire manipulation in a complex and rigid vascular model in 2D. The neural network trained by Deep Deterministic Policy Gradients with Hindsight Experience Replay performs well on the low-level control task, however the high-level control of the path planning must be improved further.",
        "DOI": "10.1515/cdbme-2020-0007",
        "paper_author": "Karstensen L.",
        "affiliation_name": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "affiliation_city": "Stuttgart",
        "affiliation_country": "Germany",
        "affiliation_id": "60025167",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Improving Generalisation in Learning Assistance by Demonstration for Smart Wheelchairs",
        "publication": "Proceedings - IEEE International Conference on Robotics and Automation",
        "citied_by": "2",
        "cover_date": "2020-05-01",
        "Abstract": "Learning Assistance by Demonstration (LAD) is concerned with using demonstrations of a human agent to teach a robot how to assist another human. The concept has previously been used with smart wheelchairs to provide customised assistance to individuals with driving difficulties. A basic premise of this technique is that the learned assistive policy should be able to generalise to environments different than the ones used for training; but this has not been tested before. In this work we evaluate the assistive power and the generalisation capability of LAD using our custom teleoperation and learning system for smart wheelchairs, while seeking to improve it by experimenting with different combinations of dimensionality reduction techniques and machine learning models. Using Autoencoders to reduce the dimension of laserscan data and a Gaussian Process as the learning model, we achieved a 23% improvement in prediction performance against the combination used by the latest work on the field. Using this model to assist a driver exposed to a simulated disability, we observed a 9.8% reduction in track completion times when compared to driving without assistance.",
        "DOI": "10.1109/ICRA40945.2020.9197490",
        "paper_author": "Schettino V.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Novel Intelligent Controller for Improved Transient Performance of SEIG-based Wave Energy Conversion System",
        "publication": "2nd IEEE Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability 2020, ECBIOS 2020",
        "citied_by": "0",
        "cover_date": "2020-05-01",
        "Abstract": "This study presented the devise of a novel intelligent controller (NIC) for the stability of self-excited induction generator (SEIG)-based wells turbine. The proposed NIC consisted of a recurrent wavelet based Elman neural network (RWENN) and modified ant colony optimization (MACO). A MACO method is used to regulate the learning rates and enhance the learning capability of RWENN. The intelligent control strategy is realized to preserve balance between generator output and grid power, to maintain the constant voltage of alternating current line, and DC-Link stable during variable load and speed. The innovative control strategy in this study improves the power regulation and dynamic capability of wave energy in a large range of working status.",
        "DOI": "10.1109/ECBIOS50299.2020.9203713",
        "paper_author": "Lu K.H.",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016835",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Problems of Poison: New Paradigms and \"agreed\" Competition in the Era of AI-Enabled Cyber Operations",
        "publication": "International Conference on Cyber Conflict, CYCON",
        "citied_by": "9",
        "cover_date": "2020-05-01",
        "Abstract": "Few developments seem as poised to alter the characteristics of security in the digital age as the advent of artificial intelligence (AI) technologies. For national defense establishments, the emergence of AI techniques is particularly worrisome, not least because prototype applications already exist. Cyber attacks augmented by AI portend the tailored manipulation of human vectors within the attack surface of important societal systems at great scale, as well as opportunities for calamity resulting from the secondment of technical skill from the hacker to the algorithm. Arguably most important, however, is the fact that AI-enabled cyber campaigns contain great potential for operational obfuscation and strategic misdirection. At the operational level, techniques for piggybacking onto routine activities and for adaptive evasion of security protocols add uncertainty, complicating the defensive mission particularly where adversarial learning tools are employed in offense. Strategically, AI-enabled cyber operations offer distinct attempts to persistently shape the spectrum of cyber contention may be able to pursue conflict outcomes beyond the expected scope of adversary operation. On the other, AI-augmented cyber defenses incorporated into national defense postures are likely to be vulnerable to \"poisoning\"attacks that predict, manipulate and subvert the functionality of defensive algorithms. This article takes on two primary tasks. First, it considers and categorizes the primary ways in which AI technologies are likely to augment offensive cyber operations, including the shape of cyber activities designed to target AI systems. Then, it frames a discussion of implications for deterrence in cyberspace by referring to the policy of persistent engagement, agreed competition and forward defense promulgated in 2018 by the United States. Here, it is argued that the centrality of cyberspace to the deployment and operation of soon-to-be-ubiquitous AI systems implies new motivations for operation within the domain, complicating numerous assumptions that underlie current approaches. In particular, AI cyber operations pose unique measurement issues for the policy regime.",
        "DOI": "10.23919/CyCon49761.2020.9131717",
        "paper_author": "Whyte C.",
        "affiliation_name": "Virginia Commonwealth University",
        "affiliation_city": "Richmond",
        "affiliation_country": "United States",
        "affiliation_id": "60002476",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Towards Classifying Devices on the Internet Using Artificial Intelligence",
        "publication": "International Conference on Cyber Conflict, CYCON",
        "citied_by": "5",
        "cover_date": "2020-05-01",
        "Abstract": "Hundreds of millions of devices are directly reachable by anyone on the Internet. Security researchers and malicious actors are highly interested in ICS, IoT, and building automation and networking devices that can be compromised to negatively affect either a specific person or organization or a whole country at once. The current approach for determining a class of individual device is to conduct a manual investigation or apply static rules to large sets of devices, which is timeconsuming and ineffective. We are proposing to utilize neural networks for automated classification.Many devices have a generic web interface supporting HTTP protocol. We have investigated which features of the HTTP responses from these devices are meaningful for training the neural network model and enabling classification of devices. We have trained neural network models and assessed their accuracy to be 87%. We are analysing the classified sets of the whole Internet scans consisting of tens of millions of devices and comparing them between the years 2018 and 2019 to identify the changes. This kind of all-encompassing view might reveal positive and negative trends that are happening to specific classes of devices, which might be correlated with real-world events, e.g. new policies issued by governments.",
        "DOI": "10.23919/CyCon49761.2020.9131713",
        "paper_author": "Lavrenovs A.",
        "affiliation_name": "NATO CCD COE",
        "affiliation_city": "Tallinn",
        "affiliation_country": "Estonia",
        "affiliation_id": "113363612",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Microservice Aging and Rejuvenation",
        "publication": "2020 World Conference on Computing and Communication Technologies, WCCCT 2020",
        "citied_by": "8",
        "cover_date": "2020-05-01",
        "Abstract": "Due to 'aging', not only the service rate of the software decreases with time but the software itself experiences occasional crash/hang failures. Software rejuvenation involves occasional stopping the executing software, 'cleaning' the 'internal state' and restarting. Moreover, container technology promotes the process of fair and efficient allocation of physical resources among virtual machines. However, the emergence of distributed cloud platform undoubtedly increase the flexibility and complexity of the system. In this paper, we propose a method of predicting microservice [1] aging by deep learning, and a rejuvenation policy by the CVA architecture. From the perspective of container, it can provide a technology of vertical expansion and contraction of container resources, improve the utilization of resources in the clustered environment, and improve the availability of microservice system.",
        "DOI": "10.1109/WCCCT49810.2020.9170005",
        "paper_author": "Yue J.",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60018308",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Optimizing high-performance computing systems for biomedical workloads",
        "publication": "Proceedings - 2020 IEEE 34th International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2020",
        "citied_by": "5",
        "cover_date": "2020-05-01",
        "Abstract": "The productivity of computational biologists is limited by the speed of their workflows and subsequent overall job throughput. Because most biomedical researchers are focused on better understanding scientific phenomena rather than developing and optimizing code, a computing and data system implemented in an adventitious and/or non-optimized manner can impede the progress of scientific discovery. In our experience, most computational, life-science applications do not generally leverage the full capabilities of high-performance computing, so tuning a system for these applications is especially critical. To optimize a system effectively, systems staff must understand the effects of the applications on the system. Effective stewardship of the system includes an analysis of the impact of the applications on the compute cores, file system, resource manager and queuing policies. The resulting improved system design, and enactment of a sustainability plan, help to enable a long-term resource for productive computational and data science. We present a case study of a typical biomedical computational workload at a leading academic medical center supporting over $100 million per year in computational biology research. Over the past eight years, our high-performance computing system has enabled over 900 biomedical publications in four major areas: genetics and population analysis, gene expression, machine learning, and structural and chemical biology. We have upgraded the system several times in response to trends, actual usage, and user feedback. Major components crucial to this evolution include scheduling structure and policies, memory size, compute type and speed, parallel file system capabilities, and deployment of cloud technologies. We evolved a 70 teraflop machine to a 1.4 petaflop machine in seven years and grew our user base nearly 10-fold. For long-term stability and sustainability, we established a chargeback fee structure. Our overarching guiding principle for each progression has been to increase scientific throughput and enable enhanced scientific fidelity with minimal impact to existing user workflows or code. This highly-constrained system optimization has presented unique challenges, leading us to adopt new approaches to provide constructive pathways forward. We share our practical strategies resulting from our ongoing growth and assessments.",
        "DOI": "10.1109/IPDPSW50202.2020.00040",
        "paper_author": "Kovatch P.",
        "affiliation_name": "Icahn School of Medicine at Mount Sinai",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60012981",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Automatically detecting bystanders in photos to reduce privacy risks",
        "publication": "Proceedings - IEEE Symposium on Security and Privacy",
        "citied_by": "38",
        "cover_date": "2020-05-01",
        "Abstract": "Photographs taken in public places often contain bystanders - people who are not the main subject of a photo. These photos, when shared online, can reach a large number of viewers and potentially undermine the bystanders' privacy. Furthermore, recent developments in computer vision and machine learning can be used by online platforms to identify and track individuals. To combat this problem, researchers have proposed technical solutions that require bystanders to be proactive and use specific devices or applications to broadcast their privacy policy and identifying information to locate them in an image.We explore the prospect of a different approach - identifying bystanders solely based on the visual information present in an image. Through an online user study, we catalog the rationale humans use to classify subjects and bystanders in an image, and systematically validate a set of intuitive concepts (such as intentionally posing for a photo) that can be used to automatically identify bystanders. Using image data, we infer those concepts and then use them to train several classifier models. We extensively evaluate the models and compare them with human raters. On our initial dataset, with a 10-fold cross validation, our best model achieves a mean detection accuracy of 93% for images when human raters have 100% agreement on the class label and 80% when the agreement is only 67%. We validate this model on a completely different dataset and achieve similar results, demonstrating that our model generalizes well.",
        "DOI": "10.1109/SP40000.2020.00097",
        "paper_author": "Hasan R.",
        "affiliation_name": "Indiana University Bloomington",
        "affiliation_city": "Bloomington",
        "affiliation_country": "United States",
        "affiliation_id": "60021121",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Improving the scalability of deep reinforcement learning-based routing with control on partial nodes",
        "publication": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
        "citied_by": "16",
        "cover_date": "2020-05-01",
        "Abstract": "Machine Learning (ML)-based routing optimization has been proposed to optimize the performance of flow routing for future networks, such as Software-Defined Networks (SDNs). However, existing studies are either hard to converge for large networks or vulnerable to topology changes. In this paper, we propose SINET, a scalable and intelligent network control framework for routing optimization. To improve the robustness and scalability, SINET selects several critical routing nodes to be directly controlled by a Deep Reinforcement Learning (DRL) agent, which dynamically generates routing policy to optimize network performance. Simulation results show that SINET can reduce the average flow completion time by at least 32% for a network with 82 nodes and exhibit better robustness against minor topology changes, compared to other DRL-based schemes.",
        "DOI": "10.1109/ICASSP40776.2020.9054483",
        "paper_author": "Sun P.",
        "affiliation_name": "National Digital Switching System Engineering &amp; Technological R&amp;D Center",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125133413",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Team Deep Mixture of Experts for Distributed Power Control",
        "publication": "IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC",
        "citied_by": "3",
        "cover_date": "2020-05-01",
        "Abstract": "In the context of wireless networking, it was recently shown that multiple DNNs can be jointly trained to offer a desired collaborative behaviour capable of coping with a broad range of sensing uncertainties. In particular, it was established that DNNs can be used to derive policies that are robust with respect to the information noise statistic affecting the local information (e.g. CSI in a wireless network) used by each agent (e.g.Transmitter) to make its decision. While promising, a major challenge in the implementation of such method is that information noise statistics may differ from agent to agent and, more importantly, that such statistics may not be available at the time of training or may evolve over time, making burdensome retraining necessary. This situation makes it desirable to devise a \"universal\" machine learning model, which can be trained once for all so as to allow for decentralized cooperation in any future feedback noise environment. With this goal in mind, we propose an architecture inspired from the well-known Mixture of Experts (MoE) model, which was previously used for non-linear regression and classification tasks in various contexts, such as computer vision and speech recognition. We consider the decentralized power control problem as an example to showcase the validity of the proposed model and to compare it against other power control algorithms. We show the ability of the so called Team-DMoE model to efficiently track time-varying statistical scenarios.",
        "DOI": "10.1109/SPAWC48557.2020.9154235",
        "paper_author": "Zecchin M.",
        "affiliation_name": "EURECOM Ecole d'Ingénieur et Centre de Recherche en Sciences du Numérique",
        "affiliation_city": "Sophia Antipolis",
        "affiliation_country": "France",
        "affiliation_id": "60029859",
        "affiliation_state": "Provence Alpes Côte d'Azur"
    },
    {
        "paper_title": "Proving Ground Test of a DDPG-based Vehicle Trajectory Planner",
        "publication": "European Control Conference 2020, ECC 2020",
        "citied_by": "6",
        "cover_date": "2020-05-01",
        "Abstract": "The paper presents real-world test cases of an optimal trajectory design solution that combines modern control techniques with machine learning. The first step of the current research is to train a reinforcement learning agent in a simulated environment, where the conditions and the applied vehicle are modeled. System dynamics is described by a nonlinear single-track vehicle with dynamic wheel model. The designed trajectory is evaluated by driving the vehicle using a control loop. The reward of the method is based on the sum of different measures considering safety and passenger comfort. The proposed method forms a special one-step reinforcement learning task handled by Deep Deterministic Policy Gradient (DDPG) learning agent. As a result, the learning process provides a real-time neural-network-based motion planner and a tracking algorithm. The evaluation of the algorithm under real conditions is made by using an experimental test vehicle. The test setup contains a high precision GPS module, an automotive inertial sensor, an industrial PC, and communication interface devices. The test cases were performed on the ZalaZone automotive proving ground.",
        "DOI": "NA",
        "paper_author": "Feher A.",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary",
        "affiliation_id": "60030035",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Analise de redes sociais como estrategia de apoio a vigilancia em saude durante a Covid-19",
        "publication": "Estudos Avancados",
        "citied_by": "14",
        "cover_date": "2020-05-01",
        "Abstract": "The large volume of data generated on social networks is used by companies to monitor public opinion about their products and services. These data may contain useful information for health surveillance, such as in assessing the impact of public policies or identifying fake news. This work presents results of studies that demonstrate how analysis of data from social networks may be applied to surveillance activities, using the covid-19 pandemic as a case study. An approach based on data science was used, with information extracted through machine learning algorithms. Results indicate that this approach can reveal useful information for surveillance activities, providing a real-time view of aspects related to the pandemic.",
        "DOI": "10.1590/S0103-4014.2020.3499.016",
        "paper_author": "Xavier F.",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil",
        "affiliation_id": "60008088",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "Efficient Decoupled Neural Architecture Search by Structure and Operation Sampling",
        "publication": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
        "citied_by": "5",
        "cover_date": "2020-05-01",
        "Abstract": "We propose a novel neural architecture search algorithm via reinforcement learning by decoupling structure and operation search. Our approach samples candidate models from the multinomial distribution over the policy vectors. The proposed technique improves the efficiency of architecture search significantly compared to the existing methods while achieving competitive classification accuracy and model compactness. Our policy vectors are easily interpretable throughout the training procedure, which allows analyzing the search progress and the identified architectures. Note that, on the contrary, the black-box characteristics of the conventional methods based on RNN controllers hamper understanding training progress in terms of policy parameter updates. Our experiments demonstrate the outstanding performance of our approach compared to the state-of-the-art techniques with a fraction of search cost.",
        "DOI": "10.1109/ICASSP40776.2020.9053197",
        "paper_author": "Lee H.C.",
        "affiliation_name": "Hana Institute of Technology",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "123780694",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Data-Driven Frequency Scaling Approach for Deadline-aware Energy Efficient Scheduling on Graphics Processing Units (GPUs)",
        "publication": "Proceedings - 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGRID 2020",
        "citied_by": "8",
        "cover_date": "2020-05-01",
        "Abstract": "Modern computing paradigms, such as cloud computing, are increasingly adopting GPUs to boost their computing capabilities primarily due to the heterogeneous nature of AI/ML/deep learning workloads. However, the energy consumption of GPUs is a critical problem. Dynamic Voltage Frequency Scaling (DVFS) is a widely used technique to reduce the dynamic power of GPUs. Yet, configuring the optimal clock frequency for essential performance requirements is a non-trivial task due to the complex nonlinear relationship between the application's runtime performance characteristics, energy, and execution time. It becomes more challenging when different applications behave distinctively with similar clock settings. Simple analytical solutions and standard GPU frequency scaling heuristics fail to capture these intricacies and scale the frequencies appropriately. In this regard, we propose a data-driven frequency scaling technique by predicting the power and execution time of a given application over different clock settings. We collect the data from application profiling and train the models to predict the outcome accurately. The proposed solution is generic and can be easily extended to different kinds of workloads and GPU architectures. Furthermore, using this frequency scaling by prediction models, we present a deadline-aware application scheduling algorithm to reduce energy consumption while simultaneously meeting their deadlines. We conduct real extensive experiments on NVIDIA GPUs using several benchmark applications. The experiment results have shown that our prediction models have high accuracy with the average RMSE values of 0.38 and 0.05 for energy and time prediction, respectively. Also, the scheduling algorithm consumes 15.07% less energy as compared to the baseline policies.",
        "DOI": "10.1109/CCGrid49817.2020.00-35",
        "paper_author": "Ilager S.",
        "affiliation_name": "School of Computing and Information Systems",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118847",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Resource Awareness in Unmanned Aerial Vehicle-Assisted Mobile-Edge Computing Systems",
        "publication": "IEEE Vehicular Technology Conference",
        "citied_by": "29",
        "cover_date": "2020-05-01",
        "Abstract": "This paper investigates an unmanned aerial vehicle (UAV)-assisted mobile-edge computing (MEC) system, in which the UAV provides complementary computation resource to the terrestrial MEC system. The UAV processes the received computation tasks from the mobile users (MUs) by creating the corresponding virtual machines. Due to finite shared I/O resource of the UAV in the MEC system, each MU competes to schedule local as well as remote task computations across the decision epochs, aiming to maximize the expected long-term computation performance. The non-cooperative interactions among the MUs are modeled as a stochastic game, in which the decision makings of a MU depend on the global state statistics and the task scheduling policies of all MUs are coupled. To approximate the Nash equilibrium solutions, we propose a proactive scheme based on the long short-term memory and deep reinforcement learning (DRL) techniques. A digital twin of the MEC system is established to train the proactive DRL scheme offline. Using the proposed scheme, each MU makes task scheduling decisions only with its own information. Numerical experiments show a significant performance gain from the scheme in terms of average utility per MU across the decision epochs.",
        "DOI": "10.1109/VTC2020-Spring48590.2020.9128981",
        "paper_author": "Chen X.",
        "affiliation_name": "Teknologian Tutkimuskeskus VTT",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland",
        "affiliation_id": "60033191",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "Continuous Control of a Soft Continuum Arm using Deep Reinforcement Learning",
        "publication": "2020 3rd IEEE International Conference on Soft Robotics, RoboSoft 2020",
        "citied_by": "59",
        "cover_date": "2020-05-01",
        "Abstract": "Soft Continuum Arms (SCAs) are challenging to control due to their highly nonlinear characteristics and sensitivity to external loading. Recent efforts to address the control problem using machine learning techniques are limited to simple SCA architectures. In this paper, we train a model-free reinforcement learning control policy based on Deep Deterministic Policy Gradient (DDPG) for end effector path tracking on a BR2 SCA. Unlike simple SCA architectures, the BR2 SCA has the functionality to bend and rotate spatially thus leading to enhanced workspace and ability to perform complex tasks. The control policy is first validated in simulations and then implemented on a prototype BR2 with state feedback. An average tracking error less than 3 cm (< diameter of the SCA) is reported using the proposed control policy. The efficacy of the control policy is validated for different loading conditions both in simulations and on the SCA prototype.",
        "DOI": "10.1109/RoboSoft48309.2020.9116003",
        "paper_author": "Satheeshbabu S.",
        "affiliation_name": "University of Illinois Urbana-Champaign",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States",
        "affiliation_id": "60000745",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Categorizing Driving Patterns based on Telematics Data Using Supervised and Unsupervised Learning",
        "publication": "Proceedings of the International Conference on Intelligent Computing and Control Systems, ICICCS 2020",
        "citied_by": "4",
        "cover_date": "2020-05-01",
        "Abstract": "Progressive motor insurance companies use telematics, a way to quantify the amount of risk involved directly on the usage of the vehicle. Telematics for motor vehicles is a device that records all driving data in real-time, including timestamp based acceleration, GPS location, etc. Current research deals with either only telematics data or insurance claim history to determine a suitable insurance policy. A combination of both the aforementioned data enabled us to create an adaptive method is proposed wherein the categorization of driving patterns would always cover the entire spectrum of driving quality, no matter how good or bad every one of the customers aggregately becomes. This ensures equal penalty and reward when aggregated on the entire customer base which amounts to a stable low-risk policy for insurers while being justifiably attractive to customers. Our technique involves using both supervised and unsupervised Machine Learning algorithms in a two-layer approach to calculate an adaptive driving score for each motor vehicle over some time. This score is nothing but a value indicative of how good a motor vehicle under consideration is driven. A comprehensive explanation is presented about our methodology backed by a detailed evaluation of our two-layered approach and discuss the combination of traditional policymaking and telematics on providing a new-age personalized motor insurance policy for insurers.",
        "DOI": "10.1109/ICICCS48265.2020.9120976",
        "paper_author": "Narwani B.",
        "affiliation_name": "Sardar Patel Institute of Technology, Mumbai",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60103994",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "CQUIC: Cross-Layer QUIC for Next Generation Mobile Networks",
        "publication": "IEEE Wireless Communications and Networking Conference, WCNC",
        "citied_by": "12",
        "cover_date": "2020-05-01",
        "Abstract": "Requirements for Next Generation Mobile Networks (NGMN) include low latency, higher throughput, scalability, and energy efficiency. As 5G millimeter wave (mmWave) band is short-range, the handover is inevitable. Google proposed QUIC (Quick UDP Internet Connection), which aims to address these challenges. However, Google QUIC (GQUIC), follows 'WiFi-First' policy causing frequent network switching, which can lead to a throughput reduction and fast battery degradation. In this paper, we propose Cross-layer QUIC (CQUIC) framework, that follows 'WiFi-if-best' policy to enhance the throughput and resilience by using a Cross-Layer approach. CQUIC proposes a novel migration scheme in QUIC which adapts to the dynamic network characteristics. GQUIC protocol with low bandwidth and high round-trip-time fail to migrate for seamless User Experience. CQUIC algorithm predicts Cross-Layer Score (CLS) which incorporates predicted Signal-to-Interference Noise Ratio (SINR), QUIC Bandwidth, round-triptime (RTT) stats from QUIC Session and models the handover decision pro-actively. Compared with state-of-the-art methods such as GQUIC and HTTP (using TCP) this paper reveals the significant benefits of the proposed method. A series of experimental results obtained in live air network over Samsung Galaxy S10 devices show CQUIC outperforms the GQUIC by 20%, TCP by 36% and MPTCP (Backup) by 17% in terms of throughput. Furthermore, CQUIC compared with MPTCP, reduces the data consumption over mobile network and operates green by reducing the power consumption by 25%.",
        "DOI": "10.1109/WCNC45663.2020.9120850",
        "paper_author": "Sinha G.",
        "affiliation_name": "Samsung R&amp;D Institute India-Bangalore",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60283810",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Machine Learning assisted Handover and Resource Management for Cellular Connected Drones",
        "publication": "IEEE Vehicular Technology Conference",
        "citied_by": "26",
        "cover_date": "2020-05-01",
        "Abstract": "Cellular connectivity for drones comes with a wide set of challenges as well as opportunities. Communication of cellular-connected drones is influenced by 3-dimensional mobility and line-of-sight channel characteristics which results in higher number of handovers with increasing altitude. Our cell planning simulations in coexistence of aerial and terrestrial users indicate that the severe interference from drones to base stations is a major challenge for uplink communications of terrestrial users. Here, we first present the major challenges in co-existence of terrestrial and drone communications by considering real geographical network data for Stockholm. Then, we derive analytical models for the key performance indicators (KPIs), including communications delay and interference over cellular networks, and formulate the handover and radio resource management (H-RRM) optimization problem. Afterwards, we transform this problem into a machine learning problem, and propose a deep reinforcement learning solution to solve HRRM problem. Finally, using simulation results, we present how the speed and altitude of drones, and the tolerable level of interference, shape the optimal H-RRM policy in the network. Especially, the heat-maps of handover decisions for different altitudes/speeds of drones have been presented, which promote a revision of the legacy handover schemes and boundaries of cells in the sky.",
        "DOI": "10.1109/VTC2020-Spring48590.2020.9129453",
        "paper_author": "Azari A.",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60002014",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "Age-Based Scheduling Policy for Federated Learning in Mobile Edge Networks",
        "publication": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
        "citied_by": "140",
        "cover_date": "2020-05-01",
        "Abstract": "Federated learning (FL) is a machine learning model that preserves data privacy in the training process. Specifically, FL brings the model directly to the user equipments (UEs) for local training, where an edge server periodically collects the trained parameters to produce an improved model and sends it back to the UEs. However, since communication usually occurs through a limited spectrum, only a portion of the UEs can update their parameters upon each global aggregation. As such, new scheduling algorithms have to be engineered to facilitate the full implementation of FL. In this paper, based on a metric termed the age of update (AoU), we propose a scheduling policy by jointly accounting for the staleness of the received parameters and the instantaneous channel qualities to improve the running efficiency of FL. The proposed algorithm has low complexity and its effectiveness is demonstrated by Monte Carlo simulations.",
        "DOI": "10.1109/ICASSP40776.2020.9053740",
        "paper_author": "Yang H.H.",
        "affiliation_name": "Singapore University of Technology and Design",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60104290",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "EXpectation Propagation LOgistic REgRession on permissioned blockCHAIN (ExplorerChain): Decentralized online healthcare/genomics predictive model learning",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "37",
        "cover_date": "2020-05-01",
        "Abstract": "Predicting patient outcomes using healthcare/genomics data is an increasingly popular/important area. However, some diseases are rare and require data from multiple institutions to construct generalizable models. To address institutional data protection policies, many distributed methods keep the data locally but rely on a central server for coordination, which introduces risks such as a single point of failure. We focus on providing an alternative based on a decentralized approach. We introduce the idea using blockchain technology for this purpose, with a brief description of its own potential advantages/disadvantages. Materials and Methods: We explain how our proposed EXpectation Propagation LOgistic REgRession on Permissioned blockCHAIN (ExplorerChain) can achieve the same results when compared to a distributed model that uses a central server on 3 healthcare/genomic datasets, and what trade-offs need to be considered when using centralized/decentralized methods. We explain how the use of blockchain technology can help decrease some of the problems encountered in decentralized methods. Results: We showed that the discrimination power of ExplorerChain can be statistically similar to its counterpart central server-based algorithm. While ExplorerChain inherited some benefits of blockchain, it had a small increased running time. Discussion: ExplorerChain has the same prerequisites as a distributed model with a centralized server for coordination. In a manner similar to secure multi-party computation strategies, it assumes that participating institutions are honest, but \"curious.\" Conclusion: When evaluated on relatively small datasets, results suggest that ExplorerChain, which combines artificial intelligence and blockchain technologies, performs as well as a central server-based method, and may avoid some risks at the cost of efficiency.",
        "DOI": "10.1093/jamia/ocaa023",
        "paper_author": "Kuo T.T.",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States",
        "affiliation_id": "60030612",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Learning stabilizing control policies for a tensegrity hopper with augmented random search",
        "publication": "Proceedings - 2020 International Conference on Industrial Engineering, Applications and Manufacturing, ICIEAM 2020",
        "citied_by": "1",
        "cover_date": "2020-05-01",
        "Abstract": "In this paper, the authors consider a tensegrity hopper - a novel tensegrity-based robot, capable of moving by hopping. The paper focuses on the design of the stabilizing control policies, which are obtained with the Augmented Random Search method. In particular, the authors search for control policies, which allow the hopper to maintain vertical stability after performing a single jump. It is demonstrated, that the hopper can maintain a vertical configuration, subject to the different initial conditions and with changing control frequency rates. In particular, lowering control frequency from 1000Hz in training to 500Hz in execution does not affect the success rate of the balancing task.",
        "DOI": "10.1109/ICIEAM48468.2020.9111973",
        "paper_author": "Kurenkov V.",
        "affiliation_name": "Innopolis University",
        "affiliation_city": "Innopolis",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60105869",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Open data and energy analytics",
        "publication": "Energies",
        "citied_by": "8",
        "cover_date": "2020-05-01",
        "Abstract": "This pioneering Special Issue aims at providing the state-of-the-art on open energy data analytics; its availability in the different contexts, i.e., country peculiarities; and at different scales, i.e., building, district, and regional for data-aware planning and policy-making. Ten high-quality papers were published after a demanding peer review process and are commented on in this Editorial.",
        "DOI": "10.3390/en13092334",
        "paper_author": "Nastasi B.",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60032350",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Forecasting of COVID-19: Transmission models and beyond",
        "publication": "Journal of Thoracic Disease",
        "citied_by": "1",
        "cover_date": "2020-05-01",
        "Abstract": "NA",
        "DOI": "10.21037/jtd-20-1692",
        "paper_author": "Zhao Y.",
        "affiliation_name": "Nanjing Medical University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60018310",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Development of a decision support model based on machine learning for applying greenhouse gas reduction technology",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "7",
        "cover_date": "2020-05-01",
        "Abstract": "Multiple nations have implemented policies for greenhouse gas (GHG) reduction since the 21st Conference of Parties (COP 21) at the United Nations Framework Convention on Climate Change (UNFCCC) in 2015. In this convention, participants voluntarily agreed to a new climate regime that aimed to decrease GHG emissions. Subsequently, a reduction in GHG emissions with specific reduction technologies (renewable energy) to decrease energy consumption has become a necessity and not a choice. With the launch of the Korean Emissions Trading Scheme (K-ETS) in 2015, Korea has certified and financed GHG reduction projects to decrease emissions. To help the user make informed decisions for economic and environmental benefits from the use of renewable energy, an assessment model was developed. This study establishes a simple assessment method (SAM), an assessment database (DB) of 1199 GHG reduction technologies implemented in Korea, and a machine learning-based GHG reduction technology assessment model (GRTM). Additionally, we make suggestions on how to evaluate economic benefits, which can be obtained in conjunction with the environmental benefits of GHG reduction technology. Finally, we validate the applicability of the assessment model on a public building in Korea.",
        "DOI": "10.3390/SU12093582",
        "paper_author": "Lee S.",
        "affiliation_name": "Hanyang University ERICA Campus",
        "affiliation_city": "Ansan",
        "affiliation_country": "South Korea",
        "affiliation_id": "60211585",
        "affiliation_state": "Gyeonggi-do"
    },
    {
        "paper_title": "Application of Deep Q-Network in Portfolio Management",
        "publication": "2020 5th IEEE International Conference on Big Data Analytics, ICBDA 2020",
        "citied_by": "34",
        "cover_date": "2020-05-01",
        "Abstract": "Machine Learning algorithms and Neural Networks are widely applied to many different areas such as stock market prediction, facial recognition and automatic machine translation. This paper introduces a novel strategy based on the classic Deep Reinforcement Learning algorithm, Deep QNetwork, for stock market portfolio management. It is a type of deep neural network which is optimized by Q Learning. To adapt the Deep Q-Network for stock market production, we first discretize the action space so that portfolio management becomes a problem that Deep Q-Network can solve. Following this, we combine the Convolutional Neural Network and dueling Q-Net to enhance the recognition ability of the algorithm. We choose five low-relevant American stocks to test our model. It is found that the Deep Q-Network based strategy outperforms the ten other traditional strategies. The profit of Deep Q-Network algorithm is 30% more than the profit of other strategies. Moreover, the Sharpe ratio and Max Drawdown demonstrates that the risk of policy associated with Deep Q-Network is the lowest.",
        "DOI": "10.1109/ICBDA49040.2020.9101333",
        "paper_author": "Gao Z.",
        "affiliation_name": "Xi'an Jiaotong-Liverpool University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China",
        "affiliation_id": "60102426",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Ethical applications of big data-driven ai on social systems: Literature analysis and example deployment use case",
        "publication": "Information (Switzerland)",
        "citied_by": "5",
        "cover_date": "2020-05-01",
        "Abstract": "The use of technological solutions to address the production of goods and offering of services is ubiquitous. Health and social issues, however, have only slowly been permeated by technological solutions. Whilst several advances have been made in health in recent years, the adoption of technology to combat social problems has lagged behind. In this paper, we explore Big Data-driven Artificial Intelligence (AI) applied to social systems; i.e., social computing, the concept of artificial intelligence as an enabler of novel social solutions. Through a critical analysis of the literature, we elaborate on the social and human interaction aspects of technology that must be in place to achieve such enabling and address the limitations of the current state of the art in this regard. We review cultural, political, and other societal impacts of social computing, impact on vulnerable groups, and ethically-aligned design of social computing systems. We show that this is not merely an engineering problem, but rather the intersection of engineering with health sciences, social sciences, psychology, policy, and law. We then illustrate the concept of ethically-designed social computing with a use case of our ongoing research, where social computing is used to support safety and security in home-sharing settings, in an attempt to simultaneously combat youth homelessness and address loneliness in seniors, identifying the risks and potential rewards of such a social computing application.",
        "DOI": "10.3390/INFO11050235",
        "paper_author": "Garcia P.",
        "affiliation_name": "Carleton University",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60017592",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "An empirical study of statutory interpretation in tax law",
        "publication": "New York University Law Review",
        "citied_by": "14",
        "cover_date": "2020-05-01",
        "Abstract": "A substantial academic literature considers how agencies should interpret statutes. But few studies have considered how agencies actually do interpret statutes, and none has empirically compared the methodologies of agencies and courts in prac-tice. This Article conducts such a comparison, using a newly created dataset of all Internal Revenue Service (IRS) publications ever released, along with an existing dataset of court decisions. It applies natural language processing, machine learning, and regression analysis to map methodological trends and to test whether particular authorities have developed unique cultures of statutory interpretation. It finds that, over time, the IRS has increasingly made rules on normative policy grounds (like fairness and efficiency) rather than merely producing rules based on the “best reading” of the relevant statute (under any interpretive theory, like purposivism or textualism). Moreover, when the IRS does focus on the statute, it has grown much more purposivist over time. In contrast, the Tax Court has not grown more normative and has followed the same trend toward textualism as most other courts. But although the Tax Court has become more broadly textualist, it prioritizes different interpretive tools than other courts, like Chevron deference and holistic-textual canons of interpretation. This suggests that each authority adopts its own flavor of textualism or purposivism. These findings complicate the literature on tax exceptionalism and the judicial nature of the Tax Court. They also inform ongoing debates about judicial deference and the future of doctrines like Chevron and Skidmore deference. Most broadly, they provide an empirical counterpoint to the existing theoretical literature on statutory interpretation by agencies.",
        "DOI": "NA",
        "paper_author": "Choi J.H.",
        "affiliation_name": "NYU Law",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60108324",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Adversarial Jamming Attacks on Deep Reinforcement Learning Based Dynamic Multichannel Access",
        "publication": "IEEE Wireless Communications and Networking Conference, WCNC",
        "citied_by": "23",
        "cover_date": "2020-05-01",
        "Abstract": "Adversarial attack strategies have been widely studied in machine learning applications, and now are increasingly attracting interest in wireless communications as the application of machine learning methods to wireless systems grows along with security concerns. In this paper, we propose two adversarial policies, one based on feed-forward neural networks (FNNs) and the other based on deep reinforcement learning (DRL) policies. Both attack strategies aim at minimizing the accuracy of a DRL-based dynamic channel access agent. We first present the two frameworks and the dynamic attack procedures of the two adversarial policies. Then we demonstrate and compare their performances. Finally, the advantages and disadvantages of the two frameworks are identified.",
        "DOI": "10.1109/WCNC45663.2020.9120770",
        "paper_author": "Zhong C.",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Syracuse",
        "affiliation_country": "United States",
        "affiliation_id": "60148874",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Crop monitoring using satellite/UAV data fusion and machine learning",
        "publication": "Remote Sensing",
        "citied_by": "208",
        "cover_date": "2020-05-01",
        "Abstract": "Non-destructive crop monitoring over large areas with high efficiency is of great significance in precision agriculture and plant phenotyping, as well as decision making with regards to grain policy and food security. The goal of this research was to assess the potential of combining canopy spectral information with canopy structure features for crop monitoring using satellite/unmanned aerial vehicle (UAV) data fusion and machine learning. Worldview-2/3 satellite data were tasked synchronized with high-resolution RGB image collection using an inexpensive unmanned aerial vehicle (UAV) at a heterogeneous soybean (Glycine max (L.) Merr.) field. Canopy spectral information (i.e., vegetation indices) was extracted fromWorldview-2/3 data, and canopy structure information (i.e., canopy height and canopy cover) was derived from UAV RGB imagery. Canopy spectral and structure information and their combination were used to predict soybean leaf area index (LAI), aboveground biomass (AGB), and leaf nitrogen concentration (N) using partial least squares regression (PLSR), random forest regression (RFR), support vector regression (SVR), and extreme learning regression (ELR) with a newly proposed activation function. The results revealed that: (1) UAV imagery-derived high-resolution and detailed canopy structure features, canopy height, and canopy coverage were significant indicators for crop growth monitoring, (2) integration of satellite imagery-based rich canopy spectral information with UAV-derived canopy structural features using machine learning improved soybean AGB, LAI, and leaf N estimation on using satellite or UAV data alone, (3) adding canopy structure information to spectral features reduced background soil effect and asymptotic saturation issue to some extent and led to better model performance, (4) the ELR model with the newly proposed activated function slightly outperformed PLSR, RFR, and SVR in the prediction of AGB and LAI, while RFR provided the best result for N estimation. This study introduced opportunities and limitations of satellite/UAV data fusion using machine learning in the context of crop monitoring.",
        "DOI": "10.3390/RS12091357",
        "paper_author": "Maimaitijiang M.",
        "affiliation_name": "Saint Louis University",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60028590",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Learning to Identify Footholds from Geometric Characteristics for a Six-legged Robot over Rugged Terrain",
        "publication": "Journal of Bionic Engineering",
        "citied_by": "3",
        "cover_date": "2020-05-01",
        "Abstract": "Foothold identification is a key ability for legged robots that allows generating terrain adaptive behaviors (e.g., gait and control parameters) and thereby improving mobility in complex environment. To this end, this paper addresses the issue of foothold characterization and identification over rugged terrain, from the terrain geometry point of view. For a terrain region that might be a potential foothold of a robotic leg, the characteristic features are extracted as two first-order partial derivatives and two curvature parameters of a quadric regression surface at this location. These features are able to give an intuitive and, more importantly, accurate characterization towards the specific geometry of the ground location. On this basis, a supervised learning technique, Support Vector Machine (SVM), is employed, seeking to learn a foothold identification policy from human expert demonstration. As a result, an SVM classifier is learnt using the extracted features and human-demonstrated labels, which is able to identify whether or not a certain ground location is suited as a safe foot support for a robotic leg. It is shown that over 90% identification rate can be achieved with the proposed approach. Finally, preliminary experiment is implemented with a six-legged robot to demonstrate the effectiveness of the proposed approach.",
        "DOI": "10.1007/s42235-020-0041-4",
        "paper_author": "Chen J.",
        "affiliation_name": "School of Mechanical Engineering and Automation, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60118695",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "On Sampled Reinforcement Learning in Wireless Networks: Exploitation of Policy Structures",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "8",
        "cover_date": "2020-05-01",
        "Abstract": "Reinforcement learning is a classical tool to solve network control or policy optimization problems in unknown environments. In order to learn the optimal policy correctly, the classical Q-learning algorithm requires sufficient visits to all state-action pairs, resulting in the need for a large number of observations in the presence of a large state-action space. Nevertheless, complexity reduction can be achieved by exploiting the particular structure of the optimal policy. A sampled reinforcement learning algorithm is proposed, where the optimal policy is estimated only for a subset of states; a machine learning technique, as well as a graph signal processing approach, are applied for policy interpolation for unvisited states. A policy refinement algorithm is further proposed to improve the performance of policy interpolation. Performance analysis and bounds are also provided for the proposed policy sampling and interpolation algorithms. Numerical experiments on a single link wireless network with a large state space show that the sample Q-learning algorithm with policy interpolation achieves a much faster runtime with negligible performance loss compared to classical Q-learning.",
        "DOI": "10.1109/TCOMM.2020.2974216",
        "paper_author": "Liu L.",
        "affiliation_name": "USC Viterbi School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60143535",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Intelligent User-Centric Networks: Learning-Based Downlink CoMP Region Breathing",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "6",
        "cover_date": "2020-05-01",
        "Abstract": "In the presence of irregular transmission/reception point (TRP) topologies and non-uniform user distribution, the user-to-node association optimization is a rather challenging process in real user-centric networks, especially for the joint transmission aided coordinated multipoint (CoMP) technique. The grade of challenge further escalates, when taking the dynamic user scheduling process into account in order to enhance the system capacity attained. To tackle the above-mentioned problem, we holistically optimize the system by conceiving joint user scheduling and user-to-node association. Then, for the sake of striking a significantly better balance between the network capacity and coverage quality, we propose a generalized reinforcement learning assisted framework intrinsically amalgamated both with neural-fitted Q-iteration as well as with ensemble learning and transfer learning techniques. Consequently, a powerful policy can be found for dynamically adjusting the set of TRPs participating in the joint transmission, thus allowing the CoMP-region to breathe, depending on both the temporal and geographical distribution of the tele-traffic load across the network. To facilitate the prompt learning of the global policy supporting flexible scalability, the overall network optimization process is decoupled into multiple local optimization phases associated with a number of TRP clusters relying on iterative information exchange among them. Our simulation results show that the proposed scheme is capable of producing a policy achieving a network-edge throughput gain of up to 140% and a network capacity gain of up to 190% under the challenging scenario of having a non-uniform geographical UE distribution and bursty traffic.",
        "DOI": "10.1109/TVT.2020.2982319",
        "paper_author": "Wang L.",
        "affiliation_name": "Huawei Technologies",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "101405650",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An improved machine learning-based approach for predicting travelers mode choice in Morocco",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "1",
        "cover_date": "2020-05-01",
        "Abstract": "Predicting the travel mode choice is an important task of transportation planning and policy making to understand inter-urban mobility. It enables the enhancement of the third step of the widely used four-step model. While advances in machine learning have led to numerous powerful predictive models, their usefulness for modeling travel mode choice remains none widely explored. The aim of this paper is to fill in this gap by proposing an advanced machine learning approach tailored to this problem. That is, using extensive Moroccan travel diary data in the year 2016, enriched with numerous individual and household features, our contribution consists of investigating the importance of applying the feature selection approach while using support vector machines (SVM) as a predictive model. The experimental results show that the adopted approach outperforms both native SVM and the artificial neural network, which are the most common data-driven techniques of dealing with such a problem.",
        "DOI": "NA",
        "paper_author": "Hadraoui M.E.L.",
        "affiliation_name": "Ecole Mohammadia d'Ingenieurs, Mohammed V University in Rabat",
        "affiliation_city": "Rabat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60011371",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "This physicist-turned-economist is modelling the pandemic's financial fallout",
        "publication": "Nature",
        "citied_by": "1",
        "cover_date": "2020-05-01",
        "Abstract": "NA",
        "DOI": "10.1038/d41586-020-01338-0",
        "paper_author": "Gibney E.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Basic reinforcement learning techniques to control the intensity of a seeded free-electron laser",
        "publication": "Electronics (Switzerland)",
        "citied_by": "32",
        "cover_date": "2020-05-01",
        "Abstract": "Optimal tuning of particle accelerators is a challenging task. Many different approaches have been proposed in the past to solve two main problems—attainment of an optimal working point and performance recovery after machine drifts. The most classical model-free techniques (e.g., Gradient Ascent or Extremum Seeking algorithms) have some intrinsic limitations. To overcome those limitations, Machine Learning tools, in particular Reinforcement Learning (RL), are attracting more and more attention in the particle accelerator community. We investigate the feasibility of RL model-free approaches to align the seed laser, as well as other service lasers, at FERMI, the free-electron laser facility at Elettra Sincrotrone Trieste. We apply two different techniques—the first, based on the episodic Q-learning with linear function approximation, for performance optimization; the second, based on the continuous Natural Policy Gradient REINFORCE algorithm, for performance recovery. Despite the simplicity of these approaches, we report satisfactory preliminary results, that represent the first step toward a new fully automatic procedure for the alignment of the seed laser to the electron beam. Such an alignment is, at present, performed manually.",
        "DOI": "10.3390/electronics9050781",
        "paper_author": "Bruchon N.",
        "affiliation_name": "Università degli Studi di Trieste",
        "affiliation_city": "Trieste",
        "affiliation_country": "Italy",
        "affiliation_id": "60018363",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Planning under uncertainty applications in power plants using factored markov decision processes",
        "publication": "Energies",
        "citied_by": "5",
        "cover_date": "2020-05-01",
        "Abstract": "Due to its ability to deal with non-determinism and partial observability, represent goals as an immediate reward function and find optimal solutions, planning under uncertainty using factored Markov Decision Processes (FMDPs) has increased its importance and usage in power plants and power systems. In this paper, three different applications using this approach are described: (i) optimal dam management in hydroelectric power plants, (ii) inspection and surveillance in electric substations, and (iii) optimization of steam generation in a combined cycle power plant. For each case, the technique has demonstrated to find optimal action policies in uncertain settings, present good response and compilation times, deal with stochastic variables and be a good alternative to traditional control systems. The main contributions of this work are as follows, a methodology to approximate a decision model using machine learning techniques, and examples of how to specify and solve problems in the electric power domain in terms of a FMDP.",
        "DOI": "10.3390/en13092302",
        "paper_author": "Reyes A.",
        "affiliation_name": "Instituto Nacional de Electricidad y Energías Limpias",
        "affiliation_city": "Cuernavaca",
        "affiliation_country": "Mexico",
        "affiliation_id": "117400585",
        "affiliation_state": "MOR"
    },
    {
        "paper_title": "Financial econometrics, mathematics, statistics, and financial technology: an overall view",
        "publication": "Review of Quantitative Finance and Accounting",
        "citied_by": "10",
        "cover_date": "2020-05-01",
        "Abstract": "Based upon my experience in research, teaching, writing textbooks, and editing handbooks and journals, this review paper discusses how financial econometrics, mathematics, statistics, and financial technology can be used in research and teaching for students majoring in quantitative finance. A major portion of this paper discusses essential content of Lee and Lee (Handbook of financial econometrics, mathematics, statistics, and machine learning, World Scientific, Singapore, 2020). Then Lee (From east to west: memoirs of a finance professor on academia, practice, and policy, World Scientific, Singapore, 2017), Lee et al. (Financial econometrics, mathematics and statistics, Springer, New York, 2019a; Machine learning for predicting default of credit card holders and success of kickstarters. Working paper, 2019b), and Lee and Lee (Handbook of financial econometrics and statistics, Springer, New York, 2015) are used to enhance the content of this paper. In addition, important and relevant papers, which have been published in different journals are also used to support the issues discussed in this paper. I have found the applications of financial econometrics, mathematics, statistics, and technology have improved drastically over the last five decades. Therefore, both practitioners and academicians need to update their skills in this area to compete in both financial market and academic research.",
        "DOI": "10.1007/s11156-020-00883-z",
        "paper_author": "Lee C.F.",
        "affiliation_name": "Rutgers University–New Brunswick",
        "affiliation_city": "New Brunswick",
        "affiliation_country": "United States",
        "affiliation_id": "60119141",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "A Hybrid Method for Electric Spring Control Based on Data and Knowledge Integration",
        "publication": "IEEE Transactions on Smart Grid",
        "citied_by": "15",
        "cover_date": "2020-05-01",
        "Abstract": "Electric spring (ES) is a relatively new power electronics device for voltage regulation in a distribution system. Some existing ES control methods are system-independent; however, their performances generally can be significantly improved when accurate system models are properly utilized. Unfortunately, accurate model of the concerned distribution system is not always available in practice. This paper proposes a hybrid method for ES control, based on the integration of data-driven and analytical models. The inaccurate analytical model provides a basic policy to generate system data. Three data-driven models based on the extreme learning machine (ELM) are built using these data to replace the power flow, active power, and reactive power models respectively. An ELM-based control model is proposed to generate the final control strategies. The hybrid method is tested using a 15-node distribution network. Simulation results show that the data-driven model is more accurate than the analytical model in predicting system states, while the proposed control method outperforms the original analytical method.",
        "DOI": "10.1109/TSG.2019.2951585",
        "paper_author": "Zhao H.",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60108865",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Decumbent development: Urban sprawl in the Guwahati Metropolitan Area, India",
        "publication": "Singapore Journal of Tropical Geography",
        "citied_by": "20",
        "cover_date": "2020-05-01",
        "Abstract": "Urban sprawl has become a global phenomenon as an outcome of growing population and rapid urbanization. Previous studies have addressed the rising incidence of uncontrollable urban development, particularly in peri-urban areas of cities, leading to chronic urban sprawl. The city of Guwahati, a million city in north east India, has expanded significantly in recent years. In this article, the links between population and growth of built-up areas were examined using geo-spatial techniques and remotely sensed datasets. The results indicate that the sprawl has accentuated in recent years. The intensity of land use remained uneven due to marked variations in the distribution of built-up areas, plausibly an outcome of unplanned urban growth. If current trends are anything to go by, future urban sprawl could pose serious threats to the vulnerable eco-sensitive and peri-urban areas of Guwahati. Secondary cities have unfortunately received scant attention in urban policy research, and Guwahati, epitomizes urban woes in a developing country.",
        "DOI": "10.1111/sjtg.12317",
        "paper_author": "Pawe C.K.",
        "affiliation_name": "Gauhati University",
        "affiliation_city": "Guwahati",
        "affiliation_country": "India",
        "affiliation_id": "60016850",
        "affiliation_state": "AS"
    },
    {
        "paper_title": "A 2020 perspective on “How to derive causal insights for digital commerce in China? A research commentary on computational social science methods”",
        "publication": "Electronic Commerce Research and Applications",
        "citied_by": "1",
        "cover_date": "2020-05-01",
        "Abstract": "Cyber-physical data from wearable and other data-sensing devices have been rapidly changing the landscape of opportunity for the conduct of computational social science (CSS) studies. We now have the opportunity to include in our research wearable healthcare data sensors, global positioning system (GPS) data, as well as a range of other digital data via mobile phones and other kinds of easily deployed sensors. The result is a dramatic new set of measurement opportunities for management scientists, marketing research staff, and policy analysts, who can now apply a range of approaches to such data capture and analysis, including machine learning of patterns, and causal inference methods for relevant policy analytics conclusions.",
        "DOI": "10.1016/j.elerap.2020.100975",
        "paper_author": "Phang D.C.W.",
        "affiliation_name": "University of Nottingham Ningbo China",
        "affiliation_city": "Ningbo",
        "affiliation_country": "China",
        "affiliation_id": "60104720",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Is real options analysis fit for purpose in supporting climate adaptation planning and decision-making?",
        "publication": "Wiley Interdisciplinary Reviews: Climate Change",
        "citied_by": "15",
        "cover_date": "2020-05-01",
        "Abstract": "Even though real options analysis (ROA) is often thought as the best tool available for evaluating flexible strategies, there are profound problems with the assumptions underpinning ROA rendering it unsuitable for use in supporting planning and decision-making on climate adaptation. In the face of dynamic and deep uncertainty about the future, flexible strategies which can be adapted in response to how the uncertainty is resolving are attractive. Traditional cost-benefit analysis cannot account for the value created through optionality. ROA sets out to amend this. There are however several profound problems with how ROA tries to do this. It is typically not clear what is the baseline plan, without options, against which value is to be estimated. Different baselines significantly change option value. Even if option value can unequivocally be established for a given scenario, ROA relies on expected values over a set of scenarios. First, this requires assigning weights, or probabilities, to scenarios. Given the long-time horizon involved in climate adaptation, these probabilities are meaningless. Second, the expected value over a set of scenarios need not obtain in any single scenario and is thus not a meaningful summary of option value. This article is categorized under: Climate Economics > Iterative Risk-Management Policy Portfolios.",
        "DOI": "10.1002/wcc.638",
        "paper_author": "Kwakkel J.H.",
        "affiliation_name": "Faculteit Techniek, Bestuur en Management, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60117886",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Multi-layer security scheme for implantable medical devices",
        "publication": "Neural Computing and Applications",
        "citied_by": "20",
        "cover_date": "2020-05-01",
        "Abstract": "Internet of Medical Things (IoMTs) is fast emerging, thereby fostering rapid advances in the areas of sensing, actuation and connectivity to significantly improve the quality and accessibility of health care for everyone. Implantable medical device (IMD) is an example of such an IoMT-enabled device. IMDs treat the patient’s health and give a mechanism to provide regular remote monitoring to the healthcare providers. However, the current wireless communication channels can curb the security and privacy of these devices by allowing an attacker to interfere with both the data and communication. The privacy and security breaches in IMDs have thereby alarmed both the health providers and government agencies. Ensuring security of these small devices is a vital task to prevent severe health consequences to the bearer. The attacks can range from system to infrastructure levels where both the software and hardware of the IMD are compromised. In the recent years, biometric and cryptographic approaches to authentication, machine learning approaches to anomaly detection and external wearable devices for wireless communication protection have been proposed. However, the existing solutions for wireless medical devices are either heavy for memory constrained devices or require additional devices to be worn. To treat the present situation, there is a requirement to facilitate effective and secure data communication by introducing policies that will incentivize the development of security techniques. This paper proposes a novel electrocardiogram authentication scheme which uses Legendre approximation coupled with multi-layer perceptron model for providing three levels of security for data, network and application levels. The proposed model can reach up to 99.99% testing accuracy in identifying the authorized personnel even with 5 coefficients.",
        "DOI": "10.1007/s00521-018-3819-0",
        "paper_author": "Rathore H.",
        "affiliation_name": "Hiller Measuremnts",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "124042128",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Bayesian Automatic Model Compression",
        "publication": "IEEE Journal on Selected Topics in Signal Processing",
        "citied_by": "11",
        "cover_date": "2020-05-01",
        "Abstract": "Model compression has drawn great attention in deep learning community. A core problem in model compression is to determine the layer-wise optimal compression policy, e.g., the layer-wise bit-width in network quantization. Conventional hand-crafted heuristics rely on human experts and are usually sub-optimal, while recent reinforcement learning based approaches can be inefficient during the exploration of the policy space. In this article, we propose Bayesian automatic model compression (BAMC), which leverages non-parametric Bayesian methods to learn the optimal quantization bit-width for each layer of the network. BAMC is trained in a one-shot manner, avoiding the back and forth (re)-training in reinforcement learning based approaches. Experimental results on various datasets validate that our proposed methods can find reasonable quantization policies efficiently with little accuracy drop for the quantized network.",
        "DOI": "10.1109/JSTSP.2020.2977090",
        "paper_author": "Wang J.",
        "affiliation_name": "Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60019499",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Comparing machine and human reviewers to evaluate the risk of bias in randomized controlled trials",
        "publication": "Research Synthesis Methods",
        "citied_by": "15",
        "cover_date": "2020-05-01",
        "Abstract": "Background: Evidence from new health technologies is growing, along with demands for evidence to inform policy decisions, creating challenges in completing health technology assessments (HTAs)/systematic reviews (SRs) in a timely manner. Software can decrease the time and burden by automating the process, but evidence validating such software is limited. We tested the accuracy of RobotReviewer, a semi-autonomous risk of bias (RoB) assessment tool, and its agreement with human reviewers. Methods: Two reviewers independently conducted RoB assessments on a sample of randomized controlled trials (RCTs), and their consensus ratings were compared with those generated by RobotReviewer. Agreement with the human reviewers was assessed using percent agreement and weighted kappa (κ). The accuracy of RobotReviewer was also assessed by calculating the sensitivity, specificity, and area under the curve in comparison to the consensus agreement of the human reviewers. Results: The study included 372 RCTs. Inter-rater reliability ranged from κ = −0.06 (no agreement) for blinding of participants and personnel to κ = 0.62 (good agreement) for random sequence generation (excluding overall RoB). RobotReviewer was found to use a high percentage of “irrelevant supporting quotations” to complement RoB assessments for blinding of participants and personnel (72.6%), blinding of outcome assessment (70.4%), and allocation concealment (54.3%). Conclusion: RobotReviewer can help with risk of bias assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers.",
        "DOI": "10.1002/jrsm.1398",
        "paper_author": "Armijo-Olivo S.",
        "affiliation_name": "Institute of Health Economics",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60000855",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Quantifying the impact of urban road networks on the efficiency of local trips",
        "publication": "Transportation Research Part A: Policy and Practice",
        "citied_by": "26",
        "cover_date": "2020-05-01",
        "Abstract": "City-level circuity factors have been introduced to quantify and compare the directness of vehicular travel across different cities. While these city-level factors help to improve the quality of distance approximation functions for city-wide vehicle movements, more granular factors are needed to obtain accurate shortest path distance approximations for last-mile transportation systems that are typically characterized by local trips. More importantly, local circuity factors encode valuable information about the efficiency and complexity of the urban road network, which can be leveraged to inform policy and practice. In this paper, we quantify and analyze local network circuity leveraging contemporary traffic datasets. Using the city of São Paulo as our primary case study and a combination of supervised and un-supervised machine learning methods, we observe significant heterogeneities in local network circuity, explained by dimensional and topological properties of the road network. Locally, real trip distances are about twice as long as distances predicted by the L1 norm. Results from São Paulo are compared to seven additional urban areas in Latin America and the United States. At a coarse-grained level of analysis, we observe similar correlations between road network properties and local circuity across these cities.",
        "DOI": "10.1016/j.tra.2020.02.015",
        "paper_author": "Merchán D.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Joint optimization of customer location clustering and drone-based routing for last-mile deliveries",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "160",
        "cover_date": "2020-05-01",
        "Abstract": "With growing consumer demand and expectations, companies are attempting to achieve cost-efficient and faster delivery operations. The integration of autonomous vehicles, such as drones, in the last-mile network design can curtail many operational challenges and provide a competitive advantage. This paper deals with the problem of delivering orders to a set of customer locations using multiple drones that operate in conjunction with a single truck. To take advantage of the drone fleet, the delivery tasks are parallelized by concurrently dispatching the drones from a truck parked at a focal point (ideal drone launch location) to the nearby customer locations. Hence, the key decisions to be optimized are the partitioning of delivery locations into small clusters, identifying a focal point per cluster, and routing the truck through all focal points such that the customer orders in each cluster are fulfilled either by a drone or truck. In contrast to prior studies that tackle this problem using multi-phase sequential procedures, this paper presents mathematical programming models to jointly optimize all the decisions involved. We also consider two polices for choosing a cluster focal point - (i) restricting it to one of the customer locations, and (ii) allowing it to be anywhere in the delivery area (i.e., a customer or non-customer location). Since the models considering unrestricted focal points are computationally expensive, an unsupervised machine learning-based heuristic algorithm is proposed to accelerate the solution time. Initially, we treat the problem as a single objective by independently minimizing either the total cost or delivery completion time. Subsequently, the two conflicting objectives are considered together for obtaining the set of best trade-off solutions. An extensive computational study is conducted to investigate the impacts of restricting the focal points, and the influence of adopting a joint optimization method instead of a sequential approach. Finally, several key insights are obtained to aid the logistics practitioners in decision making.",
        "DOI": "10.1016/j.trc.2020.01.019",
        "paper_author": "Salama M.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Columbia",
        "affiliation_country": "United States",
        "affiliation_id": "60152000",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Analyzing driving factors of land values in urban scale based on big data and non-linear machine learning techniques",
        "publication": "Land Use Policy",
        "citied_by": "93",
        "cover_date": "2020-05-01",
        "Abstract": "Land value plays a vital role in the real estate market. It is a critical reference for urban planners to reallocate land resources and introduce valid policies. Studying the influential factors on land value can help better understand the spatial-temporal variation of land values and design effective control policies. This attracted a number of scholars to study the spatial and temporal relationships between land value and its possible influential factors from the perspective of macro and micro. However, the majority of the existing studies have the problems of linear assumption and multicollinearity in research models. Limited features and the lack of feature selection procedure are another two commonly seen limitations. To overcome the gaps, this paper adopts non-linear machine learning (ML) methods to investigate the influential factors on land values per square foot based on “big data” in New York City. More than one thousand potential factors are considered, covering from the land attribute, point of interest, demographics, housing, to economic, education, and social. They are further selected using a feature extraction model named Recursive Feature Elimination (RFE). Six ML algorithms, including Random Forest (RF), Gradient Boosting Decision Tree (GBDT), Multi Linear Regression (MLR), Linear Support Vector Regression (SVR), Multilayer Perceptron (MLP) Regression, and K-Nearest Neighbor (KNN) Regression are evaluated and compared. The optimal one with an R-square value of 0.933 is used to calculate the feature importance further. Several important impact features are disclosed, including the number of newsstands, and the vacant housing percentage.",
        "DOI": "10.1016/j.landusepol.2020.104537",
        "paper_author": "Ma J.",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008592",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A multi-view similarity measure framework for trouble ticket mining",
        "publication": "Data and Knowledge Engineering",
        "citied_by": "11",
        "cover_date": "2020-05-01",
        "Abstract": "Text similarity measures play a very important role in several text mining applications. Although there is an extensive literature on measuring the similarity between long texts, there is less work related to the measurement of similarity between short texts. And most of these works on short text similarity are based on adaptations of long-text similarity methods. Unfortunately, the description of a trouble ticket is just a kind of short texts. Thus, ticket mining applications such as ticket classification, ticket clustering, and ticket resolution recommendation often suffer from poor performance because of tickets’ particular characteristics of unstructured, short free-text with large vocabulary size, large volume, non-English dictionary words, and so on. Therefore, the ability to accurately measure the similarity between two tickets is critical to the performance of ticket mining. To address this performance issue, this paper proposes a multi-view similarity measure framework that easily integrates several kinds of existing similarity measures including surface matching based measures, semantic similarity measures and syntax based measures. Further, in order to make full use of the strengths of different similarity measures, our framework adopts four different policies to combine them. In particular, we consider a machine learning based policy that can be applied to integrate various similarity measures in a more general way, which makes our framework flexible and extensible. To demonstrate the effectiveness of measures generated from our framework, we empirically validate them on a publicly available short text data set and apply them to a real-world ticket data set from a large enterprise IT infrastructure. Some important findings obtained via the result analysis will be helpful to further improve performance.",
        "DOI": "10.1016/j.datak.2020.101800",
        "paper_author": "Xu J.",
        "affiliation_name": "Nanjing University of Science and Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60010080",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Machine Learning Cyberattack and Defense Strategies",
        "publication": "Computers and Security",
        "citied_by": "48",
        "cover_date": "2020-05-01",
        "Abstract": "Cybersecurity is an increasingly important challenge for computer systems. In this work, cyberattacks were modeled using an extension of the well-known Petri net formalism. That formalism, designated Petri nets with players, strategies, and costs, models the states of the cyberattack and events during the attack as markings and transition firings in the net respectively. The formalism models the attacker and defender as competing players who may observe the marking of a subset of the net and based on the observed marking act by changing the stochastic firing rates of a subset of the transitions in order to achieve their competing goals. Rate changes by the players incur a cost. Using the formalism, nets were constructed to model specific cyberattack patterns (cross-site scripting and spear phishing) documented in the Common Attack Pattern Enumeration and Classification database. The models were validated by a panel of cybersecurity experts in a structured face validation process. Given those validated nets, a reinforcement learning algorithm using an -Greedy policy was implemented and set to the task of learning which actions to take, i.e., which transition rates to change for the different observable markings, so as to accomplish the goals of the attacker or defender. Experiments were conducted with a dynamic (learning) attacker against a static (fixed) defender, a static attacker against a dynamic defender, and a dynamic attacker against a dynamic defender. In all cases, the reinforcement learning algorithm was able to improve its performance, in terms of achieving the player's objective and reducing the cost of doing so, over time. These results demonstrate the potential of formally modeling cyberattacks and of applying reinforcement learning to improving cybersecurity.",
        "DOI": "10.1016/j.cose.2020.101738",
        "paper_author": "Bland J.A.",
        "affiliation_name": "The University of Alabama in Huntsville",
        "affiliation_city": "Huntsville",
        "affiliation_country": "United States",
        "affiliation_id": "60020583",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "An off-policy approach for model-free stabilization of linear systems subject to input energy constraint and its application to spacecraft rendezvous",
        "publication": "Optimal Control Applications and Methods",
        "citied_by": "2",
        "cover_date": "2020-05-01",
        "Abstract": "This note is concerned with the problem of stabilizing a class of linear continuous-time systems with completely unknown system dynamics subject to input energy constraint. To deal with this problem, a model-based low gain feedback law is designed firstly by establishing a special algebraic Riccati equation. Such a low gain feedback law can semiglobally stabilize the linear systems subject to input energy constraint with the exact system model. In order to relax the assumption that the system model is exactly known, an off-policy reinforcement learning approach is designed to solve the same problem without requiring the completely knowledge of the system dynamics. Finally, in order to verify the effectiveness of the proposed model-free approach, simulation result on the spacecraft rendezvous problem is introduced.",
        "DOI": "10.1002/oca.2579",
        "paper_author": "Gu J.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Some manifold learning considerations toward explicit model predictive control",
        "publication": "AIChE Journal",
        "citied_by": "8",
        "cover_date": "2020-05-01",
        "Abstract": "Model predictive control (MPC) is a de facto standard control algorithm across the process industries. There remain, however, applications where MPC is impractical because an optimization problem is solved at each time step. We present a link between explicit MPC formulations and manifold learning to enable facilitated prediction of the MPC policy. Our method uses a similarity measure informed by control policies and system state variables, to “learn” an intrinsic parametrization of the MPC controller using a diffusion maps algorithm, which will also discover a low-dimensional control law when it exists as a smooth, nonlinear combination of the state variables. We use function approximation algorithms to project points from state space to the intrinsic space, and from the intrinsic space to policy space. The approach is illustrated first by “learning” the intrinsic variables for MPC control of constrained linear systems, and then by designing controllers for an unstable nonlinear reactor.",
        "DOI": "10.1002/aic.16881",
        "paper_author": "Lovelett R.J.",
        "affiliation_name": "Whiting School of Engineering",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60145911",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Implementing Artificial Intelligence and Digital Health in Resource-Limited Settings? Top 10 Lessons We Learned in Congenital Heart Defects and Cardiology",
        "publication": "OMICS A Journal of Integrative Biology",
        "citied_by": "25",
        "cover_date": "2020-05-01",
        "Abstract": "Artificial intelligence (AI) is one of the key drivers of digital health. Digital health and AI applications in medicine and biology are emerging worldwide, not only in resource-rich but also resource-limited regions. AI predates to the mid-20th century, but the current wave of AI builds in part on machine learning (ML), big data, and algorithms that can learn from massive amounts of online user data from patients or healthy persons. There are lessons to be learned from AI applications in different medical specialties and across developed and resource-limited contexts. A case in point is congenital heart defects (CHDs) that continue to plague sub-Saharan Africa, which calls for innovative approaches to improve risk prediction and performance of the available diagnostics. Beyond CHDs, AI in cardiology is a promising context as well. The current suite of digital health applications in CHD and cardiology include complementary technologies such as neural networks, ML, natural language processing and deep learning, not to mention embedded digital sensors. Algorithms that build on these advances are beginning to complement traditional medical expertise while inviting us to redefine the concepts and definitions of expertise in molecular diagnostics and precision medicine. We examine and share here the lessons learned in current attempts to implement AI and digital health in CHD for precision risk prediction and diagnosis in resource-limited settings. These top 10 lessons on AI and digital health summarized in this expert review are relevant broadly beyond CHD in cardiology and medical innovations. As with AI itself that calls for systems approaches to data capture, analysis, and interpretation, both developed and developing countries can usefully learn from their respective experiences as digital health continues to evolve worldwide.",
        "DOI": "10.1089/omi.2019.0142",
        "paper_author": "Thomford N.E.",
        "affiliation_name": "University of Cape Town",
        "affiliation_city": "Cape Town",
        "affiliation_country": "South Africa",
        "affiliation_id": "60000356",
        "affiliation_state": "Western Cape"
    },
    {
        "paper_title": "A hybrid model considering spatial heterogeneity for landslide susceptibility mapping in Zhejiang Province, China",
        "publication": "Catena",
        "citied_by": "144",
        "cover_date": "2020-05-01",
        "Abstract": "Landslides are a type of serious geologic disaster causing great damage to the human environment. Landslide susceptibility mapping is an effective means to reduce landslide risk. However, previous studies have not considered spatial heterogeneity. In this study, a hybrid model considering spatial heterogeneity is designed by integrating GeoSOM and Stacking ensemble methods and is applied to map the landslide susceptibility of Zhejiang Province, China. The GeoSOM method was used to cluster the study area into several homogeneous regions to solve the heterogeneity problem, and each region was assigned a cluster attribute as one of the landslide model inputs. The Stacking ensemble technique was utilized to design a high-performance landslide model by combining three traditional machine learning methods (support vector machine (SVM), artificial neural network (ANN), and gradient-boosting decision tree (GBDT)). We collected 1051 landslide samples and fourteen affecting factors after feature selection. For landslide modelling, the landslides were randomly split into two subsets: 70% samples for training and the rest for validation. Landslide models were assessed by the receiver operating characteristic (ROC) curve and statistical measures. The results indicated that the hybrid model was 0.11–0.135 higher than those of traditional machine learning methods in term of the area under the ROC curve (AUC). In general, this hybrid model can generate high-quality landslide susceptibility maps and help to develop policies that reduce the burden of landslides.",
        "DOI": "10.1016/j.catena.2019.104425",
        "paper_author": "Wang Y.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60029306",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Robust Experimental Study of Data-driven Optimal Control for an Underactuated Rotary Flexible Joint",
        "publication": "International Journal of Control, Automation and Systems",
        "citied_by": "11",
        "cover_date": "2020-05-01",
        "Abstract": "As an important component of industrial robot, the motion control of rotary flexible joint (RFJ) system is of great significance, especially when the system has unmodeled dynamics or is seriously disturbed. This paper presents an experimental robustness study on a kind data-driven optimal control approach based on an underactuated rotary flexible joint system. The data-driven approach combines the off-policy optimal control algorithm and the popular integral reinforcement learning technique. Through literature review, we find that the key step of the control design lies in that it learns the optimal value function and control policy simultaneously from the input and output (I/O) data. However, the I/O data are often disturbed by the system uncertainty or environmental noise, and then it will indirectly affect the optimal control performance. To investigate the robustness of the data-driven optimal control approach, we artificially set different experimental scenarios and take numerous control experiments on a RFJ experimental setup. The experimental results show that the data-driven optimal control method is quite robust against the system uncertainties in terms of maintaining the stability and delivering satisfactory tracking performance, even when the uncertainty is not a small quantity. In addition, the disturbance originating from environmental noise has certain impact on the controlling of RFJ system, but as long as the noise power is not too large, the control algorithm can converge to a satisfactory result. Finally, we find that the probing signal up has strong influence to this control algorithm, which reminds us to be cautious when selecting the probing signal.",
        "DOI": "10.1007/s12555-019-0402-0",
        "paper_author": "Xin Y.",
        "affiliation_name": "Tianjin University of Technology",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60026990",
        "affiliation_state": "Tianjin"
    },
    {
        "paper_title": "Hop.Skip.Jump.Games: The effect of “principled” exergameplay on children's locomotor skill acquisition",
        "publication": "British Journal of Educational Technology",
        "citied_by": "18",
        "cover_date": "2020-05-01",
        "Abstract": "Sedentary past-times such as video gameplay are cited as having a negative effect on children's Fundamental Motor Skills (FMS) acquisition. Conversely, “exergames” utilise 3D sensor control systems (eg, Kinect®) to offer full body interactive user experiences in which FMS outputs are often part of the game “play” experience. This study evaluated the impact that participation in (1) commercial exergames and, (2) purpose-built exergames had on user locomotor skill outcomes (run, hop, skip, jump and slide) when both sets of games were deployed with a “principled” human-in-the-loop personalisation process. Typically developing children aged between 5 and 6 years were divided into two groups; a control group (n = 20; 45% girls) exposed to commercial exergames and, an experimental group (n = 20; 50% girls) exposed to purpose-built exergames. Gameplay was delivered daily, in the classroom, over a period of 8 weeks. The Test of Gross Motor Development-2 was utilised to assess children's locomotor skills at three time points (pre, interim and posttest). A mixed analysis of variance with repeated measures on time was conducted to evaluate results of the experimental group in comparison to the control group. A significant interaction effect was observed relating to Time × Group. Pairwise comparisons with a Bonferroni adjustment demonstrated that the experimental group made significant improvements for each locomotor skill (run, hop, skip, jump and slide) from pretest to posttest while the control group made significant improvements in only one locomotor skill (the slide) over the same timeframe. Results indicate that principled design and deployment of purpose-built exergames support high quality locomotor outputs and, improved outcomes over time. Practitioner Notes What is already known about this topic A majority of modern children do not possess proficient locomotor skills and cannot hop, skip or even run properly Teachers typically target motor skills in the Physical Education setting but these skills require regular personalised practice to improve performance 3D sensor controlled exergames provide a potential platform to target locomotor skill acquisition in the classroom, but currently lack the necessary design principles to improve user locomotor skill outcomes What this paper adds A suite of “principled” exergames with adaptable features to target locomotor skills in the classroom A human-in-the-loop deployment process that empowers the teacher to be a crucial component of the learning experience Empirical evidence to support the effectiveness of purpose-built exergames for locomotor skill acquisition purposes in the classroom Implications for practice and/or policy Educators can work with a gaming system to effectively deploy “short bouts” of 3D sensor exergameplay in the classroom and facilitate significantly improved locomotor skills in children. Design and development of educational technology could consider the teacher as a valuable “human intelligent system” capable of making decisions about the user and user experience that the system cannot. This could potentially transform effectiveness of educational technologies from both the teacher and learner perspective.",
        "DOI": "10.1111/bjet.12886",
        "paper_author": "McGann J.",
        "affiliation_name": "Dublin City University",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland",
        "affiliation_id": "60025059",
        "affiliation_state": "Leinster"
    },
    {
        "paper_title": "Sentiment classification using harmony random forest and harmony gradient boosting machine",
        "publication": "Soft Computing",
        "citied_by": "14",
        "cover_date": "2020-05-01",
        "Abstract": "The building of a system for exploring the opinions of users that are made in the blog posts, tweets, reviews or comments regarding a particular topic, policy or a product is known as sentiment analysis. The primary aim of this is the determination of the user attitude regarding a certain topic. The harmony search algorithm has proved to be extremely useful in a varied range of problems in optimization. This shows better performance compared to the other techniques of optimization. Another very powerful technique that is applied to machine learning which is now getting extremely popular is gradient boosting. There are several tree parameters which have been optimized for the random forest and the gradient boosting machine that make use of the harmony search algorithm.",
        "DOI": "10.1007/s00500-019-04370-z",
        "paper_author": "Sridharan K.",
        "affiliation_name": "Anna University",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60021176",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Big Data in sleep apnoea: Opportunities and challenges",
        "publication": "Respirology",
        "citied_by": "41",
        "cover_date": "2020-05-01",
        "Abstract": "Sleep apnoea is now regarded as a highly prevalent systemic, multimorbid, chronic disease requiring a combination of long-term home-based treatments. Optimization of personalized treatment strategies requires accurate patient phenotyping. Data to describe the broad variety of phenotypes can come from electronic health records, health insurance claims, socio-economic administrative databases, environmental monitoring, social media, etc. Connected devices in and outside homes collect vast amount of data amassed in databases. All this contributes to ‘Big Data’ that, if used appropriately, has great potential for the benefit of health, well-being and therapeutics. Sleep apnoea is particularly well placed with regards to Big Data because the primary treatment is positive airway pressure (PAP). PAP devices, used every night over long periods by millions of patients across the world, generate an enormous amount of data. In this review, we discuss how different types of Big Data have, and could be, used to improve our understanding of sleep-disordered breathing, to identify undiagnosed sleep apnoea, to personalize treatment and to adapt health policies and better allocate resources. We discuss some of the challenges of Big Data including the need for appropriate data management, compilation and analysis techniques employing innovative statistical approaches alongside machine learning/artificial intelligence; closer collaboration between data scientists and physicians; and respect of the ethical and regulatory constraints of collecting and using Big Data. Lastly, we consider how Big Data can be used to overcome the limitations of randomized clinical trials and advance real-life evidence-based medicine for sleep apnoea.",
        "DOI": "10.1111/resp.13669",
        "paper_author": "Pépin J.L.",
        "affiliation_name": "Université Grenoble Alpes",
        "affiliation_city": "Saint Martin d'Heres",
        "affiliation_country": "France",
        "affiliation_id": "60104653",
        "affiliation_state": "Auvergne-Rhone-Alpes"
    },
    {
        "paper_title": "The forecasting power of the multi-language narrative of sell-side research: A machine learning evaluation",
        "publication": "Finance Research Letters",
        "citied_by": "0",
        "cover_date": "2020-05-01",
        "Abstract": "This is probably the first ever analysis of sell-side daily economic research to use Natural Language Processing, and it shows that the narrative of such reports can be used to predict economic time series. The NLP indexes are based on Polish and English language reports released at the same time and exhibit predictive power for different sets of economic variables. VAR models with the NLP indexes generate smaller forecast errors than ARIMA. The wordscores scaling model uses Monetary Policy Council statements to generate scores and allows NLP indexes to be created with better forecasting power than the sentiment-based ones.",
        "DOI": "10.1016/j.frl.2019.08.009",
        "paper_author": "Rybinski K.",
        "affiliation_name": "Vistula University",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60105805",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Automatic Extraction of Access Control Policies from Natural Language Documents",
        "publication": "IEEE Transactions on Dependable and Secure Computing",
        "citied_by": "28",
        "cover_date": "2020-05-01",
        "Abstract": "A fundamental management responsibility is securing information systems. Almost all applications that deal with safety, privacy, or defense include some form of access control. There are a plethora of access control models in the information security realm such as role-based access control and attribute-based access control. However, the initial development of access control policies (ACPs) can be very challenging. Most organizations have high-level requirement specifications that include a set of ACPs, which describe allowable operations of the system. It is time consuming and error-prone to manually sift through these documents and extract ACPs. In this paper, we propose a new framework towards extracting ACPs from unrestricted natural language documents using semantic role labeling (SRL). We were able to correctly identify ACP elements with an average F_1F1 score of 75 percent, which bested the previous work by 15 percent. Furthermore, as SRL tools are often trained on publicly available corpora such as Wall Street Journal, we investigated the idea of improving SRL performance using domain-related knowledge. We utilized domain adaptation and semi-supervised learning techniques and were able to improve the SRL performance by 2 percent using only a small amount of access control data.",
        "DOI": "10.1109/TDSC.2018.2818708",
        "paper_author": "Narouei M.",
        "affiliation_name": "University of North Texas",
        "affiliation_city": "Denton",
        "affiliation_country": "United States",
        "affiliation_id": "60024438",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "State of the Art and Perspective of Agricultural Land Use Remote Sensing Information Extraction",
        "publication": "Journal of Geo-Information Science",
        "citied_by": "30",
        "cover_date": "2020-04-25",
        "Abstract": "Agricultural lands account for nearly half of the global land area, and changes in agricultural land use directly affect food security, water security, ecological security, and climate change. Remote sensing is the main means for acquiring agricultural land use information. In recent years, the free opening of medium-resolution remote sensing data such as Landsat, Sentinel, and China's GaoFen satellites has opened unprecedented opportunities for extraction of agricultural land use information. A series of promising research progress has been made. This review paper analyzes the state of the art of agricultural land use information extraction from four aspects:cropland, crop type, agricultural planting system, and agricultural land management. We found that: (1) The products of cropland mapping have been improved from the past coarse resolution (500~1000 m) to a higher spatial resolution of 10~30 m in the past decade. The global and regional cropland layers have been well established; but there is a need to track historical cropland changes, especially to identify the key turning points, by making full use of the existing remote sensing data (data fusion and satellite constellation approaches). (2) Existing crop type mapping efforts have been mostly carried out by combining ground survey data with satellite remote sensing (mainly Landsat and Sentinel-2). It has been operationalized in North America and Europe, but the ability to monitor crop planting areas needs to be strengthened in other countries including China. Also, the early season monitoring capacity of crop type mapping needs to be improved; (3) Existing studies on tracking agricultural planting systems are mainly concentrated in Eastern Europe (e.g., the abandonment after the breakup of the Soviet Union). In China, cropland abandonment, rotation, and fallow are also common in the recent decade, due to economic and policy factors; however, existing studies are lacking on this issue. (4) in terms of the agricultural land management, encouraging progress has been made on the regional products of irrigation, but the reliability and accuracy of the products need to be improved. New technologies, including the emerging multiple sources of remote sensing data so-called remote sensing big data, deep learning algorithms, and cloud computing platforms (e.g., Google Earth Engineand Amazon Web Services) provide unprecedented opportunities for future agricultural land use information extraction, which will rely on (1) the fusion of multi-source data to form remote sensing big data with higher spatial, spectral, and temporal resolutions, (2) coupling of intelligent methods such as machine learning and deep learning algorithms with expert knowledge-based methods considering geographical and phenological information, and (3) the application of cutting-edge technologies such as remote sensing cloud computing platforms.",
        "DOI": "10.12082/dqxxkx.2020.200192",
        "paper_author": "Dong J.",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60031150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Obtaining accurate estimated action values in categorical distributional reinforcement learning",
        "publication": "Knowledge-Based Systems",
        "citied_by": "2",
        "cover_date": "2020-04-22",
        "Abstract": "Categorical Distributional Reinforcement Learning (CDRL) uses a categorical distribution with evenly spaced outcomes to model the entire distribution of returns and produces state-of-the-art empirical performance. However, using inappropriate bounds with CDRL may generate inaccurate estimated action values, which affect the policy update step and the final performance. In CDRL, the bounds of the distribution indicate the range of the action values that the agent can obtain in one task, without considering the policy's performance and state–action pairs. The action values that the agent obtains are often far from the bounds, and this reduces the accuracy of the estimated action values. This paper describes a method of obtaining more accurate estimated action values for CDRL using adaptive bounds. This approach enables the bounds of the distribution to be adjusted automatically based on the policy and state–action pairs. To achieve this, we save the weights of the critic network over a fixed number of time steps, and then apply a bootstrapping method. In this way, we can obtain confidence intervals for the upper and lower bound, and then use the upper and lower bound of these intervals as the new bounds of the distribution. The new bounds are more appropriate for the agent and provide a more accurate estimated action value. To further correct the estimated action values, a distributional target policy is proposed as a smoothing method. Experiments show that our method outperforms many state-of-the-art methods on the OpenAI gym tasks.",
        "DOI": "10.1016/j.knosys.2020.105511",
        "paper_author": "Zhao Y.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Generalize Robot Learning From Demonstration to Variant Scenarios With Evolutionary Policy Gradient",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "5",
        "cover_date": "2020-04-21",
        "Abstract": "There has been substantial growth in research on the robot automation, which aims to make robots capable of directly interacting with the world or human. Robot learning for automation from human demonstration is central to such situation. However, the dependence of demonstration restricts robot to a fixed scenario, without the ability to explore in variant situations to accomplish the same task as in demonstration. Deep reinforcement learning methods may be a good method to make robot learning beyond human demonstration and fulfilling the task in unknown situations. The exploration is the core of such generalization to different environments. While the exploration in reinforcement learning may be ineffective and suffer from the problem of low sample efficiency. In this paper, we present Evolutionary Policy Gradient (EPG) to make robot learn from demonstration and perform goal oriented exploration efficiently. Through goal oriented exploration, our method can generalize robot learned skill to environments with different parameters. Our Evolutionary Policy Gradient combines parameter perturbation with policy gradient method in the framework of Evolutionary Algorithms (EAs) and can fuse the benefits of both, achieving effective and efficient exploration. With demonstration guiding the evolutionary process, robot can accelerate the goal oriented exploration to generalize its capability to variant scenarios. The experiments, carried out in robot control tasks in OpenAI Gym with dense and sparse rewards, show that our EPG is able to provide competitive performance over the original policy gradient methods and EAs. In the manipulator task, our robot can learn to open the door with vision in environments which are different from where the demonstrations are provided.",
        "DOI": "10.3389/fnbot.2020.00021",
        "paper_author": "Cao J.",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60003970",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Spatially and Temporally Explicit Life Cycle Environmental Impacts of Soybean Production in the U.S. Midwest",
        "publication": "Environmental science &amp; technology",
        "citied_by": "35",
        "cover_date": "2020-04-21",
        "Abstract": "Understanding spatially and temporally explicit life cycle environmental impacts is critical for designing sustainable supply chains for biofuel and animal sectors. However, annual life cycle environmental impacts of crop production at county scale across mutiple years are lacking. To address this knowledge gap, this study used a combination of Environmental Policy Integrated Climate and process-based life cycle assessment models to quantify life cycle global warming (GWP), eutrophication (EU) and acidification (AD) impacts of soybean production in nearly 1000 Midwest counties yr-1 over 9 years. Sequentially, a machine learning approach was applied to identify the top influential factors among soil, climate, and farming practices, which drive the spatial and temporal heterogeneity of life cycle environmental impacts. The results indicated that significant variations existed in life cycle GWP, EU, and AD among counties and across years. Life cycle GWP impacts ranged from -11.4 to 22.0 kg CO2-eq kg soybean-1, whereas life cycle EU and AD impacts varied by factors of 302 and 44, respectively. Nitrogen application rates, temperature in March and soil texture were the top influencing factors for life cycle GWP impacts. In contrast, soil organic content and nitrogen application rate were the top influencing factors for life cycle EU and AD impacts.",
        "DOI": "10.1021/acs.est.9b06874",
        "paper_author": "Romeiko X.X.",
        "affiliation_name": "State University of New York Albany",
        "affiliation_city": "Albany",
        "affiliation_country": "United States",
        "affiliation_id": "60011666",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "FIMS: Identifying, Predicting and Visualising Food Insecurity",
        "publication": "The Web Conference 2020 - Companion of the World Wide Web Conference, WWW 2020",
        "citied_by": "2",
        "cover_date": "2020-04-20",
        "Abstract": "Food insecurity is a persistent and pernicious problem in the UK. Due to logistical challenges, national food insecurity statistics are unmeasured by government bodies - and this lack of data leads to any local estimates that do exist being routinely questioned by policymakers. We demonstrate a data-driven approach to address this issue, deriving national estimates of food insecurity via combination of supervised machine learning with network analysis of user behaviour, extracted from the world's most popular peer-to-peer food sharing application (OLIO). Despite long-standing theoretical links between social graph topologies and physical neighbourhoods, prior research has not considered dimensions of geography, network interactions and behaviours in the digital/analogue space simultaneously. In addressing this oversight, we produce a browser-based, interactive and rapidly updateable visualisation, which can be used to analyse the spatial distribution of food insecurity across the UK, and provide new perspective for policy research.",
        "DOI": "10.1145/3366424.3383538",
        "paper_author": "Nica-Avram G.",
        "affiliation_name": "University of Nottingham",
        "affiliation_city": "Nottingham",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015138",
        "affiliation_state": "Nottinghamshire"
    },
    {
        "paper_title": "Finding a Choice in a Haystack: Automatic Extraction of Opt-Out Statements from Privacy Policy Text",
        "publication": "The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020",
        "citied_by": "60",
        "cover_date": "2020-04-20",
        "Abstract": "Website privacy policies sometimes provide users the option to opt-out of certain collections and uses of their personal data. Unfortunately, many privacy policies bury these instructions deep in their text, and few web users have the time or skill necessary to discover them. We describe a method for the automated detection of opt-out choices in privacy policy text and their presentation to users through a web browser extension. We describe the creation of two corpora of opt-out choices, which enable the training of classifiers to identify opt-outs in privacy policies. Our overall approach for extracting and classifying opt-out choices combines heuristics to identify commonly found opt-out hyperlinks with supervised machine learning to automatically identify less conspicuous instances. Our approach achieves a precision of 0.93 and a recall of 0.9. We introduce Opt-Out Easy, a web browser extension designed to present available opt-out choices to users as they browse the web. We evaluate the usability of our browser extension with a user study. We also present results of a large-scale analysis of opt-outs found in the text of thousands of the most popular websites.",
        "DOI": "10.1145/3366423.3380262",
        "paper_author": "Bannihatti Kumar V.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60027950",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Reputation Agent: Prompting Fair Reviews in Gig Markets",
        "publication": "The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020",
        "citied_by": "14",
        "cover_date": "2020-04-20",
        "Abstract": "Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker's control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker's control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers' performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.",
        "DOI": "10.1145/3366423.3380199",
        "paper_author": "Toxtli C.",
        "affiliation_name": "West Virginia University",
        "affiliation_city": "Morgantown",
        "affiliation_country": "United States",
        "affiliation_id": "60021143",
        "affiliation_state": "WV"
    },
    {
        "paper_title": "Throughput prediction of asynchronous SGD in tensorflow",
        "publication": "ICPE 2020 - Proceedings of the ACM/SPEC International Conference on Performance Engineering",
        "citied_by": "5",
        "cover_date": "2020-04-20",
        "Abstract": "Modern machine learning frameworks can train neural networks using multiple nodes in parallel, each computing parameter updates with stochastic gradient descent (SGD) and sharing them asynchronously through a central parameter server. Due to communication overhead and bottlenecks, the total throughput of SGD updates in a cluster scales sublinearly, saturating as the number of nodes increases. In this paper, we present a solution to predicting training throughput from profiling traces collected from a single-node configuration. Our approach is able to model the interaction of multiple nodes and the scheduling of concurrent transmissions between the parameter server and each node. By accounting for the dependencies between received parts and pending computations, we predict overlaps between computation and communication and generate synthetic execution traces for configurations with multiple nodes. We validate our approach on TensorFlow training jobs for popular image classification neural networks, on AWS and on our in-house cluster, using nodes equipped with GPUs or only with CPUs. We also investigate the effects of data transmission policies used in TensorFlow and the accuracy of our approach when combined with optimizations of the transmission schedule.",
        "DOI": "10.1145/3358960.3379141",
        "paper_author": "Li Z.",
        "affiliation_name": "University of Southern California",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60029311",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "An analysis of warrant for rights in records for refugees",
        "publication": "International Journal of Human Rights",
        "citied_by": "6",
        "cover_date": "2020-04-20",
        "Abstract": "This paper argues that personal actualisation of human and personal rights articulated in key internationally recognised policy instruments is significantly impeded without similar recognition of individual rights ‘in and to records’. It reports on a study in which archival literary warrant analysis was applied top-down on 19 such instruments and on professional international guidelines for archiving records relevant to human rights. Warrant was also derived bottom-up from media and personal accounts of documentation and recordkeeping challenges faced by refugees. Based on the results of these analyses, a platform of proposed refugee rights in and to records was derived. These rights are presented together with the warrants from which they were derived, and also juxtaposed with other frameworks emanating out of peace research as well as information, data and machine learning communities in order to demonstrate where there is overlap and divergence in recommendations. Further research is necessary to test whether such a framework addressing refugees’ needs is sufficiently inclusive to encompass any context in which documentation and recordkeeping play key roles in enabling and actualising human rights, and whether rights in and to records should themselves be recognised as fundamental human rights.",
        "DOI": "10.1080/13642987.2019.1651295",
        "paper_author": "Gilliland A.J.",
        "affiliation_name": "University of California, Los Angeles",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60027550",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "On the economic consequences of automation and robotics",
        "publication": "Journal of Economic and Administrative Sciences",
        "citied_by": "8",
        "cover_date": "2020-04-17",
        "Abstract": "Purpose: The academic literature is currently placing significant attention on the study of the socio-economic consequences of the observable fast automation of all sectors of economic activity. The purpose of this paper is to systematize meaningful ideas on the economic impact of the rise of the robots. Design/methodology/approach: With the goal of evaluating the channels through which the current wave of fast technological change affects the organization and performance of the economy and the behavior of agents, the paper is structured into two parts. The first part assesses the state of knowledge regarding the potential revolutionary role of robot use in production. The second part designs a model aimed at exposing the interplay between the most prominent features associated with the new economic reality. Findings: The current wave of innovation has implications that escape conventional economic thinking. The evaluation and prediction of what the new phenomena brings is fundamental to design policies that prevent income inequality to widen and growth to slow down. Research limitations/implications: The full macroeconomic impact of the fast, pervasive and irreversible automation of production is far from being completely assimilated. At this level, no benchmark model should be interpreted as a definitive framework of analysis, and economic thought should evolve alongside with empirically observed evidence. Originality/value: We are facing an automation convulsion that replaces humans by machines at an unprecedented fast rate. This paper systematizes ideas about this process and offers a novel conceptual model to better understand what really is at stake.",
        "DOI": "10.1108/JEAS-04-2018-0049",
        "paper_author": "Gomes O.",
        "affiliation_name": "Instituto Superior de Contabilidade e Administração de Lisboa",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal",
        "affiliation_id": "60285972",
        "affiliation_state": "Lisboa"
    },
    {
        "paper_title": "A reinforcement learning method to scheduling problem of steel production process",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "6",
        "cover_date": "2020-04-17",
        "Abstract": "In this paper, a reinforcement learning method is utilized to solve the steel production scheduling problem. Based on characteristics of steel production processing, the model of hybrid flow-shop scheduling problem is constructed. Then the model is attributed to a Markov Decision Process, and corresponding states, actions, reward function are put forward. When trading off the exploration and exploitation, an improved ϵ -greedy policy is designed. Finally, this hybrid flow-shop scheduling model based on reinforcement learning is applied to the scheduling example of steel production processing. Compared to genetic algorithm, the reinforcement learning method gets the better result.",
        "DOI": "10.1088/1742-6596/1486/7/072035",
        "paper_author": "Guo F.",
        "affiliation_name": "Naval Aviation University",
        "affiliation_city": "Yantai",
        "affiliation_country": "China",
        "affiliation_id": "108659623",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Methodology for the preparation of rescue plans – a Polish case study",
        "publication": "Disaster Prevention and Management: An International Journal",
        "citied_by": "2",
        "cover_date": "2020-04-16",
        "Abstract": "Purpose: The purpose of this paper is to present a proposal for the methodology of developing rescue plans and the concepts of applying recommended response schedules in the context of the State Fire Service’s planning responsibilities (preparation) and public administration (reconciliation and approval), according to the legal order in force in Poland. In the proposed concept, recommended schedules are built on the basis of the matches and successes identified according to the criteria, i.e. the best carried out rescue actions from the register of reports. Design/methodology/approach: The paper is based on the analysis of existing legal status and policy in Poland as well as the selected relevant academic literature. Findings: The result is the formulation of a methodology for drawing up the rescue plans to the extent required by law and proposing a concept for the method of developing and applying recommended response schedules, supporting operational planning and conducting rescue operations. Practical implications: The proposed methodology is to support the procedure of drawing up rescue plans by implying and implementing them into IT solutions. The suggested recommended response schedules, based on observations and conclusions from the analysis of the past rescue operations, may present circumstances and sequences of the use of forces and measures that have had beneficial effects in the past. An in-depth analysis of historical data from the conducted rescue operations may also be used to determine time indicators for the response phase. Originality/value: The proposed solutions complement the methods currently used by public administration in Poland. The concept can also be inspiring for the State Fire Service (PSP) which has its own analytical tools in the form of a decision support system and registers of rescue operations carried out. The PSP may undertake the practical verification of the presented methodology for preparing rescue plans and recommended response schedules.",
        "DOI": "10.1108/DPM-02-2019-0062",
        "paper_author": "Kunikowski G.",
        "affiliation_name": "Politechnika Warszawska",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60003675",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Crytojacking Classification based on Machine Learning Algorithm",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "2",
        "cover_date": "2020-04-15",
        "Abstract": "The rise of cryptocurrency has resulted in a number of concerns. A new threat known as cryptojacking\" has entered the picture where cryptojacking malware is the trend for future cyber criminals, who infect computers, install cryptocurrency miners, and use stolen information from victim databases to set up wallets for illicit funds transfers. Worst by 2020, researchers estimate there will be 30 billion of IoT devices in the world. Majority of the devices are highly vulnerable to simple attacks based on weak passwords and unpatched vulnerabilities and poorly monitored. Thus it is the best projection that IoT become a perfect target for cryptojacking malwares. There are lacks of study that provide in depth analysis on cryptojacking malware especially in the classification model. As IoT devices requires small processing capability, a lightweight model are required for the cryptojacking malware detection algorithm to maintain its accuracy without sacrificing the performance of other process. As a solution, we propose a new lightweight cryptojacking classifier model based on instruction simplification and machine learning technique that can detect the cryptojacking classification algorithm. This research aims to study the features of existing cryptojacking classification algorithm, to enhanced existing algorithm and to evaluate the enhanced algorithm for cryptojacking malware classification. The output of this research will be significant used in detecting cryptojacking malware attacks that benefits multiple industries including cyber security contractors, oil and gas, water, power and energy industries which align with the National Cyber Security Policy (NCSP) which address the risks to the Critical National Information Infrastructure (CNII).",
        "DOI": "10.1145/3390525.3390537",
        "paper_author": "Mansor W.N.A.B.W.",
        "affiliation_name": "Universiti Sains Islam Malaysia",
        "affiliation_city": "Nilai",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090706",
        "affiliation_state": "Negeri Sembilan"
    },
    {
        "paper_title": "Prediction and optimization of oscillating wave surge converter using machine learning techniques",
        "publication": "Energy Conversion and Management",
        "citied_by": "47",
        "cover_date": "2020-04-15",
        "Abstract": "With the increase in global environmental problems and the energy crisis, the oscillating wave surge converter has been extensively studied in the past decades owing to its simple geometry and direct energy capture mechanism. However, systematic optimization of this converter is yet to be achieved. Consequently, in this study, a scaled oscillating wave surge converter under regular waves is numerically investigated using the smoothed particle hydrodynamics method, which is validated against experimental data. With the random changes in nine typical design parameters (i.e., the wave period, wave height, water depth, width of bottom border of the flap, width of top border, flap height, hinge height, flap density, and damping of the power take-off system), a total of 379 cases are generated and simulated. Subsequently, the capture factors corresponding to each case are calculated to quantitatively describe the energy conversion efficiency. With the design parameter combinations as input and the capture factors as output, a radial basis function neural network is trained as the prediction model of capture factors of the converters, which performs satisfactorily. Finally, this prediction model is used with the genetic algorithm to optimize the converters corresponding to different wave periods, wave heights, and water depths. By interpolating the open-source optimization results, a converter with high performance can be easily designed. The optimization method used in this study includes a radial basis function neural network based prediction model and genetic algorithm based optimization model, which can not only optimize oscillating wave surge converters but also has the potential to solve other scientific and technical optimization problems.",
        "DOI": "10.1016/j.enconman.2020.112677",
        "paper_author": "Liu Z.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Spatial heterogeneities of current and future hurricane flood risk along the U.S. Atlantic and Gulf coasts",
        "publication": "Science of the Total Environment",
        "citied_by": "42",
        "cover_date": "2020-04-15",
        "Abstract": "We evaluate the spatial heterogeneities of hurricane flood risk along the United States (U.S.) Atlantic and Gulf coasts under two different climate scenarios (current and future). The flood hazard is presented as the hurricane surge flood level with 1% annual exceedance probability (100-year flood) under the two scenarios, where the future scenario considers the effect of hurricane climatology change and sea level rise towards late-21st-century under a high emission scenario (RCP8.5). This hazard information is combined with estimated vulnerability and disaster resilience of coastal communities to map the relative current and future risk employing different risk definitions. Several geographical techniques and spatial distributional models (e.g., spatial autocorrelation, spatial hotspot analysis, and spatial multivariate clustering analysis) are applied to systematically analyze the risk and identify statistically significant hotspots of the highest risk. Most of the high-risk hotspots are found in the Gulf coast region, particularly along the west coast of Florida. However, two out of three risk evaluation approaches also indicate New York City as a risk hotspot under the future climate—showing that the resultant risk is sensitive to the consideration of evaluation factors (i.e., hazard, vulnerability, and resilience). Additionally, we apply a machine-learning algorithm-based spatial multivariate approach to map the spatially distinct groups based on the values of risk, hazard, vulnerability, and resilience. The results show that the counties in the highest risk group (value >3rd quartile, 15% of total counties, including New York City) in the future lack specifically in the community capital and the social components of community resilience. This assessment of coastal risk to hurricane flood has important policy-relevant implications to provide a focus-for-action for risk reduction and resilience enhancement for the U.S., where 6.5 million households live in the hurricane flood-prone areas.",
        "DOI": "10.1016/j.scitotenv.2020.136704",
        "paper_author": "Sajjad M.",
        "affiliation_name": "City University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60013983",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Satellite-based soybean yield forecast: Integrating machine learning and weather data for improving crop yield prediction in southern Brazil",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "274",
        "cover_date": "2020-04-15",
        "Abstract": "Soybean yield predictions in Brazil are of great interest for market behavior, to drive governmental policies and to increase global food security. In Brazil soybean yield data generally demand various revisions through the following months after harvest suggesting that there is space for improving the accuracy and the time of yield predictions. This study presents a novel model to perform in-season (“near real-time”) soybean yield forecasts in southern Brazil using Long-Short Term Memory (LSTM), Neural Networks, satellite imagery and weather data. The objectives of this study were to: (i) compare the performance of three different algorithms (multivariate OLS linear regression, random forest and LSTM neural networks) for forecasting soybean yield using NDVI, EVI, land surface temperature and precipitation as independent variables, and (ii) evaluate how early (during the soybean growing season) this method is able to forecast yield with reasonable accuracy. Satellite and weather data were masked using a non-crop-specific layer with field boundaries obtained from the Rural Environment Registry that is mandatory for all farmers in Brazil. Main outcomes from this study were: (i) soybean yield forecasts at municipality-scale with a mean absolute error (MAE) of 0.24 Mg ha−1 at DOY 64 (march 5) (ii) a superior performance of the LSTM neural networks relative to the other algorithms for all the forecast dates except DOY 16 where multivariate OLS linear regression provided the best performance, and (iii) model performance (e.g., MAE) for yield forecast decreased when predictions were performed earlier in the season, with MAE increasing from 0.24 Mg ha−1 to 0.42 Mg ha−1 (last values from OLS regression) when forecast timing changed from DOY 64 (March 5) to DOY 16 (January 6). This research portrays the benefits of integrating statistical techniques, remote sensing, weather to field survey data in order to perform more reliable in-season soybean yield forecasts.",
        "DOI": "10.1016/j.agrformet.2019.107886",
        "paper_author": "Schwalbert R.A.",
        "affiliation_name": "Universidade Federal de Santa Maria",
        "affiliation_city": "Santa Maria",
        "affiliation_country": "Brazil",
        "affiliation_id": "60033356",
        "affiliation_state": "RS"
    },
    {
        "paper_title": "Lane Keeping Assist for an Autonomous Vehicle Based on Deep Reinforcement Learning",
        "publication": "SAE Technical Papers",
        "citied_by": "8",
        "cover_date": "2020-04-14",
        "Abstract": "Lane keeping assist (LKA) is an autonomous driving technique that enables vehicles to travel along a desired line of lanes by adjusting the front steering angle. Reinforcement learning (RL) is one kind of machine learning. Agents or machines are not told how to act but instead learn from interaction with the environment. It also frees us from coding complex policies manually. But it has not yet been successfully applied to autonomous driving. Two control strategies using different deep reinforcement learning (DRL) algorithms have been proposed and used in the lane keeping assist scenario in this paper. Deep Q-network (DQN) algorithm with discrete action space and deep deterministic policy gradient (DDPG) algorithm with continuous action space have been implemented, respectively. Based on MATLAB/Simulink, deep neural networks representing the control policy are designed. The environment as well as the vehicle dynamics are also modelled in Simulink. By integrating the proposed control method and a vehicle dynamics model, the lane keeping assist simulation is performed. Experimental results demonstrate that the vehicle travel along the centerline of the path and the controller reaches a steady state after a short time, validating the effectiveness of the proposed control method.",
        "DOI": "10.4271/2020-01-0728",
        "paper_author": "Wang Q.",
        "affiliation_name": "Nanjing University of Science and Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60010080",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Safety Assurance Concepts for Automated Driving Systems",
        "publication": "SAE Technical Papers",
        "citied_by": "2",
        "cover_date": "2020-04-14",
        "Abstract": "Automated driving systems (ADSs) for road vehicles are being developed that can perform the entire dynamic driving task without a human driver in the loop. However, current regulatory frameworks for assuring vehicle safety may restrict the deployment of ADSs that can use machine learning to modify their functionality while in service. A review was undertaken to identify and assess key initiatives and research relevant to the safety assurance of adaptive safety-critical systems that use machine learning, and to highlight assurance concepts that could benefit from further research. The primary objective was to produce findings and recommendations that can inform policy and regulatory reform relating to ADS safety assurance. Due to the almost infinite number and combination of scenarios that an ADS could encounter, the review found much support for concepts that involve the use of simulation data as virtual evidence of safety compliance, with suggestions of a need to assure simulation tools and models. Real-world behavioural competency testing was also commonly proposed, although noting this concept has its limitations. The concept of whole-of-life assurance was identified, supported by various versions of dynamic runtime monitoring, verification and validation. Concerns regarding Artificial Intelligence (AI) robustness were raised, particularly regarding adversarial inputs and unmodelled scenarios that are essentially unknown unknowns. Further, the concept of explainable AI was highlighted as having potential to provide evidence from an ADS that could support safety assurance and regulatory compliance. While each of the identified assurance concepts should be considered when developing ADS safety assurance framework options, it is recommended that further research on each concept should be progressed.",
        "DOI": "10.4271/2020-01-0727",
        "paper_author": "Ballingall S.",
        "affiliation_name": "University of Melbourne",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60026553",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Using Reinforcement Learning and Simulation to Develop Autonomous Vehicle Control Strategies",
        "publication": "SAE Technical Papers",
        "citied_by": "0",
        "cover_date": "2020-04-14",
        "Abstract": "While machine learning in autonomous vehicles development has increased significantly in the past few years, the use of reinforcement learning (RL) methods has only recently been applied. Convolutional Neural Networks (CNNs) became common for their powerful object detection and identification and even provided end-to-end control of an autonomous vehicle. However, one of the requirements of a CNN is a large amount of labeled data to inform and train the neural network. While data is becoming more accessible, these networks are still sensitive to the format and collection environment which makes the use of others' data more difficult. In contrast, RL develops solutions in a simulation environment through trial and error without labeled data. Our research expands upon previous research in RL and Proximal Policy Optimization (PPO) and the application of these algorithms to 1/18th scale cars by expanding the application of this control strategy to a full-sized passenger vehicle. By using this method of unsupervised learning, our research demonstrates the ability to learn new control strategies while in a simulated environment without the need for large amounts of real-world data. The use of simulation environments for RL is important as the unsupervised learning methodology requires many trials to learn appropriate desired behavior. Running this in the real-world would be expensive and impractical, however the simulation enables the solutions to be developed at low cost and time as the process can be accelerated beyond real-time. The simulation environment has high-fidelity to model vehicle dynamics as well as rendering capability for domain adaptation, and guarantees successful simulation-to-real world transfer. Traditional control algorithms are used on the strategies developed to ensure a proper mapping to the physical vehicle it is being applied to. This approach results in a low cost, low data solution that enables control of a full-sized, self-driving passenger vehicle.",
        "DOI": "10.4271/2020-01-0737",
        "paper_author": "Navarro A.",
        "affiliation_name": "PolySync Technologies",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "124323313",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modeling arsenic content in Brazilian soils: What is relevant?",
        "publication": "Science of the Total Environment",
        "citied_by": "33",
        "cover_date": "2020-04-10",
        "Abstract": "Arsenic accumulation in the environment poses ecological and human health risks. A greater knowledge about soil total As content variability and its main drivers is strategic for maintaining soil security, helping public policies and environmental surveys. Considering the poor history of As studies in Brazil at the country's geographical scale, this work aimed to generate predictive models of topsoil As content using machine learning (ML) algorithms based on several environmental covariables representing soil forming factors, ranking their importance as explanatory covariables and for feeding group analysis. An unprecedented databank based on laboratory analyses (including rare earth elements), proximal and remote sensing, geographical information system operations, and pedological information were surveyed. The median soil As content ranged from 0.14 to 41.1 mg kg−1 in reference soils, and 0.28 to 58.3 mg kg−1 in agricultural soils. Recursive Feature Elimination Random Forest outperformed other ML algorithms, ranking as most important environmental covariables: temperature, soil organic carbon (SOC), clay, sand, and TiO2. Four natural groups were statistically suggested (As content ± standard error in mg kg−1): G1) with coarser texture, lower SOC, higher temperatures, and the lowest TiO2 contents, has the lowest As content (2.24 ± 0.50), accomplishing different environmental conditions; G2) organic soils located in floodplains, medium TiO2 and temperature, whose As content (3.78 ± 2.05) is slightly higher than G1, but lower than G3 and G4; G3) medium contents of As (7.14 ± 1.30), texture, SOC, TiO2, and temperature, representing the largest number of points widespread throughout Brazil; G4) the largest contents of As (11.97 ± 1.62), SOC, and TiO2, and the lowest sand content, with points located mainly across Southeastern Brazil with milder temperature. In the absence of soil As content, a common scenario in Brazil and in many Latin American countries, such natural groups could work as environmental indicators.",
        "DOI": "10.1016/j.scitotenv.2020.136511",
        "paper_author": "de Menezes M.",
        "affiliation_name": "Universidade Federal de Lavras",
        "affiliation_city": "Lavras",
        "affiliation_country": "Brazil",
        "affiliation_id": "60017841",
        "affiliation_state": "MG"
    },
    {
        "paper_title": "The potential of integrating blockchain technology into smart sustainable city development",
        "publication": "IOP Conference Series: Earth and Environmental Science",
        "citied_by": "13",
        "cover_date": "2020-04-06",
        "Abstract": "The rise of global urbanisation has led to massive pressures on resources such as food, water, infrastructure, and energy demand to support growing populations. It brings adverse impacts on the liveable condition and economic growth of a country if this problem remains unsolved. Smart city is a potential solution to address the challenges of urbanisation by leveraging the technological breakthrough such as internet of things (IoT), Artificial Intelligence (AI), machine learning, big data, and cloud computing to facilitate scarce resources planning and management. With numerous connected devices and vast communication networks, it poses a challenges of security threat which cannot be addressed by the conventional cybersecurity solutions. Blockchain offers a solution in securing the huge numbers of connected devices in smart city network. The application of blockchain technology is leading in the banking and financial industry. However, the uses and implementations in smart city have emerged in recent years. The combination of blockchain technology and smart city has offered a great potential for sustainable development. Thus, it is imperative to discuss the potential of these two elements in making the city safer and sustainable. This paper explores how the blockchain technology application can help in managing smart city and achieve sustainability. The findings revealed that there are five key areas of blockchain application in smart city which are smart governance, smart mobility, smart asset, smart utility and smart logistic. A framework for smart sustainable city with blockchain technology is presented as an outcome of this study. It gives a clear overview for the policy makers and regulators of how blockchain supports within smart city framework. It facilitates the transition towards smart and sustainable cities through the use of blockchain.",
        "DOI": "10.1088/1755-1315/463/1/012020",
        "paper_author": "Wong P.F.",
        "affiliation_name": "Universiti Tunku Abdul Rahman",
        "affiliation_city": "Kajang",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090708",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Additional planning with multiple objectives for reinforcement learning",
        "publication": "Knowledge-Based Systems",
        "citied_by": "16",
        "cover_date": "2020-04-06",
        "Abstract": "Most control tasks have multiple objectives that need to be achieved simultaneously, while the reward definition is the weighted combination of all objects to determine one optimal policy. This configuration has a limitation in exploration flexibility and presents difficulty in reaching a satisfied terminate condition. Although some multi-objective reinforcement learning (MORL) methods have been presented recently, they concentrate on obtaining a set of compromising options rather than one best-performed strategy. On the other hand, the existing policy-improve methods have rarely emphasized on solving multiple objectives circumstances. Inspired by the enhanced policy search methods, an additional planning technique with multiple objectives for reinforcement learning is proposed in this paper, which is denoted as RLAP-MOP. This method provides opportunities to evaluate parallel requirements at the same time and suggests several optimal feasible actions to improve long-term performance further. Meanwhile, the short-term planning adopted in this paper has advantages in maintaining safe trajectories and building more accurate approximate models, which contributes to accelerating the training program. For comparison, an RLAP with single-objective optimization is also introduced in theoretical and experimental studies. The proposed techniques are investigated on a multi-objective cartpole environment and a soft robotic palpation task. The superiorities in the improved return values and learning stability prove that the multiple objectives based additional planning is a promising assistant to improve reinforcement learning.",
        "DOI": "10.1016/j.knosys.2019.105392",
        "paper_author": "Pan A.",
        "affiliation_name": "Donghua University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60010953",
        "affiliation_state": "Shanghai"
    },
    {
        "paper_title": "Introduction: From cognitive radio to modern spectrum sharing",
        "publication": "Spectrum Sharing: The Next Frontier in Wireless Networks",
        "citied_by": "0",
        "cover_date": "2020-04-03",
        "Abstract": "This book, titled Spectrum Sharing: The Next Frontier in Wireless Networks, provides a comprehensive treatment of the principles and architectures for spectrum sharing by expert authors from leading academia, industry and regulation authorities. The book starts with the historic form of cognitive radio, goes into current standardized forms of spectrum sharing, reviews the major technical ingredients that are currently foreseeable in spectrum sharing approaches, and finishes with implementation, policy and business aspects, and a future outlook.",
        "DOI": "10.1002/9781119551539.ch1",
        "paper_author": "Papadias C.B.",
        "affiliation_name": "The American College of Greece",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece",
        "affiliation_id": "60031663",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "Distress, Impairment, and Racial/Ethnic Differences in Perceived Need for Mental Health Treatment in a Nationally Representative Sample",
        "publication": "Psychiatry (New York)",
        "citied_by": "5",
        "cover_date": "2020-04-02",
        "Abstract": "Objective: To advance our understanding of racial/ethnic differences in help seeking for mental health conditions, this article tests whether differences in serious psychological distress or functional impairment account for racial/ethnic differences in perceived need for treatment. Method: Data from the 2009–2014 National Survey of Drug Use and Health, a survey of a nationally representative sample of the U.S. population, were analyzed. Logistic regression models were used to test whether differences in psychological distress, assessed with the Kessler-6, or functional impairment, assessed with the WHO Disability Assessment Scale, account for racial/ethnic differences in perceived need for mental health treatment. Results: Perceived need, psychological distress, and functional impairment all vary significantly across racial/ethnic groups; psychological distress is highest among Hispanics interviewed in English and lowest among Hispanics interviewed in Spanish, while functional impairment is highest among Non-Hispanic Whites and lowest among Hispanics interviewed in Spanish. Associations with perceived need vary across racial/ethnic groups for distress (X2(5) = 22.14, p = .001), but not for impairment (X2(5) = 8.73, p = .121). Associations between distress and perceived need are significantly weaker among Hispanics interviewed in Spanish than among Non-Hispanic Whites (OR = 1.13 vs. 1.08, p = .001). Differences across racial/ethnic groups in perceived need are sustained after adjustment for distress and impairment. Conclusions: Differences in perceived need across racial/ethnic groups are not attributable to differences in distress and impairment. Heterogeneity in the relationships of psychological distress and functional impairment with perceived need for mental health treatment is related to language, a strong indicator of country of birth.",
        "DOI": "10.1080/00332747.2020.1762394",
        "paper_author": "Breslau J.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning in the analysis of mental disease",
        "publication": "ACMSE 2020 - Proceedings of the 2020 ACM Southeast Conference",
        "citied_by": "1",
        "cover_date": "2020-04-02",
        "Abstract": "Mental Health issues affect millions of people every year and deter the ability of an individual to live a fulfilling life. 1 in 5 U.S. adults experience some type of mental illness every year. Even though in the U.S. there are progressive policies and initiatives to help those with mental illnesses, there are still many people suffering and not receiving the help they need. There are different factors and reasons behind why some individuals are hesitant to receive care. Location, stigma, and the fear of treatment are some of the reasons, but with the help of technology like machine learning there can be a access to help everywhere. This work provides general overview on the mental disease particularly to review the machine learning application in the mental disease analysis to provide the best overview of this emerging direction.",
        "DOI": "10.1145/3374135.3385299",
        "paper_author": "Kim L.",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States",
        "affiliation_id": "60019740",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "A pre-trained fuzzy reinforcement learning method for the pursuing satellite in a one-to-one game in space",
        "publication": "Sensors (Switzerland)",
        "citied_by": "7",
        "cover_date": "2020-04-02",
        "Abstract": "In order to help the pursuer find its advantaged control policy in a one-to-one game in space, this paper proposes an innovative pre-trained fuzzy reinforcement learning algorithm, which is conducted in the x, y, and z channels separately. Compared with the previous algorithms applied in ground games, this is the first time reinforcement learning has been introduced to help the pursuer in space optimize its control policy. The known part of the environment is utilized to help the pursuer pre-train its consequent set before learning. An actor-critic framework is built in each moving channel of the pursuer. The consequent set of the pursuer is updated through the gradient descent method in fuzzy inference systems. The numerical experimental results validate the effectiveness of the proposed algorithm in improving the game ability of the pursuer.",
        "DOI": "10.3390/s20082253",
        "paper_author": "Wang X.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013789",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "“Sorry I Didn’t Hear You.” The Ethics of Voice Computing and AI in High Risk Mental Health Populations",
        "publication": "AJOB Neuroscience",
        "citied_by": "5",
        "cover_date": "2020-04-02",
        "Abstract": "This article examines the ethical and policy implications of using voice computing and artificial intelligence to screen for mental health conditions in low income and minority populations. Mental health is unequally distributed among these groups, which is further exacerbated by increased barriers to psychiatric care. Advancements in voice computing and artificial intelligence promise increased screening and more sensitive diagnostic assessments. Machine learning algorithms have the capacity to identify vocal features that can screen those with depression. However, in order to screen for mental health pathology, computer algorithms must first be able to account for the fundamental differences in vocal characteristics between low income minorities and those who are not. While researchers have envisioned this technology as a beneficent tool, this technology could be repurposed to scale up discrimination or exploitation. Studies on the use of big data and predictive analytics demonstrate that low income minority populations already face significant discrimination. This article urges researchers developing AI tools for vulnerable populations to consider the full ethical, legal, and social impact of their work. Without a national, coherent framework of legal regulations and ethical guidelines to protect vulnerable populations, it will be difficult to limit AI applications to solely beneficial uses. Without such protections, vulnerable populations will rightfully be wary of participating in such studies which also will negatively impact the robustness of such tools. Thus, for research involving AI tools like voice computing, it is in the research community’s interest to demand more guidance and regulatory oversight from the federal government.",
        "DOI": "10.1080/21507740.2020.1740355",
        "paper_author": "Villongco C.",
        "affiliation_name": "Morehouse School of Medicine",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60024321",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Visa trial of international trade: evidence from support vector machines and neural networks",
        "publication": "Journal of Management Analytics",
        "citied_by": "22",
        "cover_date": "2020-04-02",
        "Abstract": "International trade depends on networking, interaction and in-person meetings which stimulate cross-border travels. The countries are seeking policies to encourage inbound mobility to support bilateral trade, tourism, and foreign direct investments. Some nations have been implementing liberal visa regimes as an important part of facilitating policies in view of security concerns. Turkey has been among the nations introducing liberal visa policies to support trade in the last decade and recorded significant increases in the volumes of exports. In this paper, we employed machine learning methodologies, Support vector machines (SVM) and Neural networks (NN), to investigate the facilitating impact of liberal visa policies on bilateral trade, using the export data from Turkey for the period of 2000–2014. The research disentangled the variables that have the strongest impact on trade utilizing SVM and NN models and exhibited that visa policies have significant impacts on the bilateral trade. More relaxed visa policies are recommended for the countries in the pursuit of increasing exports.",
        "DOI": "10.1080/23270012.2020.1731719",
        "paper_author": "Akman E.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Applying deep learning to the newsvendor problem",
        "publication": "IISE Transactions",
        "citied_by": "78",
        "cover_date": "2020-04-02",
        "Abstract": "The newsvendor problem is one of the most basic and widely applied inventory models. If the probability distribution of the demand is known, the problem can be solved analytically. However, approximating the probability distribution is not easy and is prone to error; therefore, the resulting solution to the newsvendor problem may not be optimal. To address this issue, we propose an algorithm based on deep learning that optimizes the order quantities for all products based on features of the demand data. Our algorithm integrates the forecasting and inventory-optimization steps, rather than solving them separately, as is typically done, and does not require knowledge of the probability distributions of the demand. One can view the optimal order quantities as the labels in the deep neural network. However, unlike most deep learning applications, our model does not know the true labels (order quantities), but rather learns them during the training. Numerical experiments on real-world data suggest that our algorithm outperforms other approaches, including data-driven and machine learning approaches, especially for demands with high volatility. Finally, in order to show how this approach can be used for other inventory optimization problems, we provide an extension for (r, Q) policies.",
        "DOI": "10.1080/24725854.2019.1632502",
        "paper_author": "Oroojlooyjadid A.",
        "affiliation_name": "P.C. Rossin College of Engineering &amp; Applied Science",
        "affiliation_city": "Bethlehem",
        "affiliation_country": "United States",
        "affiliation_id": "60146240",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Identifying social media user demographics and topic diversity with computational social science: a case study of a major international policy forum",
        "publication": "Journal of Computational Social Science",
        "citied_by": "18",
        "cover_date": "2020-04-01",
        "Abstract": "When the world’s countries agreed on the 2030 Agenda for Sustainable Development, they recognized that equity and inclusion should be at the center of implementing the 17 Sustainable Development Goals (SDGs). SDG 15, which calls for protecting, restoring, and promoting the sustainable use of terrestrial ecosystems, has spurred commitments to restore 350 million hectares of land by 2030. These commitments, primarily made in a top-down manner at the international scale, must be implemented by actively engaging individual landholders and local communities. Ensuring that diverse and marginalized audiences are engaged in the land restoration movement is critical to equitably distributing the economic benefits of restoration. This publication uses social network analysis and machine learning to understand how important the voices of Africans, women, and young people are in governing restoration in Africa. We analyze location- and machine learning-identified demographics from Twitter data collected during the Global Landscapes Forum (GLF), which is the world’s largest platform for promoting sustainable land use practices. Our results suggest that convening the GLF in Nairobi, Kenya elevated the voices of African leaders in comparison to the previous GLF in Bonn, Germany. We also found significant demographic differences in topic-level engagement between different ages, races, and genders. The primary contributions of this paper are a novel methodology for quantifying demographic differences in social media engagement and the application of social media and social network analysis to provide critical insights into the inclusivity of a large political conference aimed at engaging youth and African voices.",
        "DOI": "10.1007/s42001-019-00061-9",
        "paper_author": "Brandt J.",
        "affiliation_name": "World Resources Institute",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60014872",
        "affiliation_state": "DC"
    },
    {
        "paper_title": "Autoencoder-Based Three-Factor Model for the Yield Curve of Japanese Government Bonds and a Trading Strategy",
        "publication": "Journal of Risk and Financial Management",
        "citied_by": "9",
        "cover_date": "2020-04-01",
        "Abstract": "Interest rates are representative indicators that reflect the degree of economic activity. The yield curve, which combines government bond interest rates by maturity, fluctuates to reflect various macroeconomic factors. Central bank monetary policy is one of the significant factors influencing interest rate markets. Generally, when the economy slows down, the central bank tries to stimulate the economy by lowering the policy rate to establish an environment in which companies and individuals can easily raise funds. In Japan, the shape of the yield curve has changed significantly in recent years following major changes in monetary policy. Therefore, an increasing need exists for a model that can flexibly respond to the various shapes of yield curves. In this research, we construct a three-factor model to represent the Japanese yield curve using the machine learning approach of an autoencoder. In addition, we focus on the model parameters of the intermediate layer of the neural network that constitute the autoencoder and confirm that the three automatically generated factors represent the “Level,” “Curvature,” and “Slope” of the yield curve. Furthermore, we develop a long–short strategy for Japanese government bonds by setting their valuation with the autoencoder, and we confirm good performance compared with the trend-follow investment strategy.",
        "DOI": "10.3390/jrfm13040082",
        "paper_author": "Suimon Y.",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60025272",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "AI for humanitarian action: Human rights and ethics",
        "publication": "International Review of the Red Cross",
        "citied_by": "34",
        "cover_date": "2020-04-01",
        "Abstract": "Artificial intelligence (AI)-supported systems have transformative applications in the humanitarian sector but they also pose unique risks for human rights, even when used with the best intentions. Drawing from research and expert consultations conducted across the globe in recent years, this paper identifies key points of consensus on how humanitarian practitioners can ensure that AI augments - rather than undermines - human interests while being rights-respecting. Specifically, these consultations emphasized the necessity of an anchoring framework based on international human rights law as an essential baseline for ensuring that human interests are embedded in AI systems. Ethics, in addition, can play a complementary role in filling gaps and elevating standards above the minimum requirements of international human rights law. This paper summarizes the advantages of this framework, while also identifying specific tools and best practices that either already exist and can be adapted to the AI context, or that need to be created, in order to operationalize this human rights framework. As the COVID crisis has laid bare, AI will increasingly shape the global response to the world's toughest problems, especially in the development and humanitarian sector. To ensure that AI tools enable human progress and contribute to achieving the Sustainable Development Goals, humanitarian actors need to be proactive and inclusive in developing tools, policies and accountability mechanisms that protect human rights.",
        "DOI": "10.1017/S1816383121000011",
        "paper_author": "Pizzi M.",
        "affiliation_name": "Jain Family Institute",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125937479",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "No place like home: Cross-national data analysis of the efficacy of social distancing during the COVID-19 pandemic",
        "publication": "JMIR Public Health and Surveillance",
        "citied_by": "59",
        "cover_date": "2020-04-01",
        "Abstract": "Background: In the absence of a cure in the time of a pandemic, social distancing measures seem to be the most effective intervention to slow the spread of disease. Various simulation-based studies have been conducted to investigate the effectiveness of these measures. While those studies unanimously confirm the mitigating effect of social distancing on disease spread, the reported effectiveness varies from 10% to more than 90% reduction in the number of infections. This level of uncertainty is mostly due to the complex dynamics of epidemics and their time-variant parameters. However, real transactional data can reduce uncertainty and provide a less noisy picture of the effectiveness of social distancing. Objective: The aim of this paper was to integrate multiple transactional data sets (GPS mobility data from Google and Apple as well as disease statistics from the European Centre for Disease Prevention and Control) to study the role of social distancing policies in 26 countries and analyze the transmission rate of the coronavirus disease (COVID-19) pandemic over the course of 5 weeks. Methods: Relying on the susceptible-infected-recovered (SIR) model and official COVID-19 reports, we first calculated the weekly transmission rate (β) of COVID-19 in 26 countries for 5 consecutive weeks. Then, we integrated these data with the Google and Apple mobility data sets for the same time frame and used a machine learning approach to investigate the relationship between the mobility factors and β values. Results: Gradient boosted trees regression analysis showed that changes in mobility patterns resulting from social distancing policies explain approximately 47% of the variation in the disease transmission rates. Conclusions: Consistent with simulation-based studies, real cross-national transactional data confirms the effectiveness of social distancing interventions in slowing the spread of COVID-19. In addition to providing less noisy and more generalizable support for the idea of social distancing, we provide specific insights for public health policy makers regarding locations that should be given higher priority for enforcing social distancing measures.",
        "DOI": "10.2196/19862",
        "paper_author": "Delen D.",
        "affiliation_name": "Spears School of Business at Oklahoma State University",
        "affiliation_city": "Stillwater",
        "affiliation_country": "United States",
        "affiliation_id": "60159673",
        "affiliation_state": "OK"
    },
    {
        "paper_title": "Remodeling the knowledge economy growth concept using machine learning analysis",
        "publication": "International Journal of Pharmaceutical Research",
        "citied_by": "0",
        "cover_date": "2020-04-01",
        "Abstract": "Traditional econometric models are now considered to be weak in measuring economic activities in line with new economic realities. The consequence is inaccurate forecasts and growing concerns for predicting impact and timely macroeconomic policy interventions. The purpose of this study was to identify features that expedite knowledge economy driven growth and create a machine learning model that addresses the methodological weaknesses of econometric models in assisting lagging economies drive a knowledge economy-based transition. A naïve bayes model was designed and implemented based on a small dataset from the Organisation of Economic Development and Corporation (OECD) members’ Science and Technology Indicators (STIs) and World Bank Gross National Income (GNI) per capita growth rates from 44 countries (OECD and non-OECD countries). The initial dataset had observations over 4 years (2015-2018). The formulated model had an F1 score of 85% at its peak which was satisfactory based on the size of the dataset. The results from the study indicate that economies targeting sustainable high growth are continuously going to rely on the capacitation of business research. Transitioned economies in the last two decades have experienced negative growth rates in basic research with more focus being made towards applied and experimental research. In addition, there is need for the business sector to collaborate with government, with the former conducting much of the gross research in an economy.",
        "DOI": "10.31838/ijpr/2020.12.02.255",
        "paper_author": "Kuppusamy M.",
        "affiliation_name": "University of Cyberjaya",
        "affiliation_city": "Cyberjaya",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090602",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "A Proposal for an Explainable Fuzzy-based Deep Learning System for Skin Cancer Prediction",
        "publication": "2020 7th International Conference on eDemocracy and eGovernment, ICEDEG 2020",
        "citied_by": "13",
        "cover_date": "2020-04-01",
        "Abstract": "Explainable deep learning (XDL) is a research field that aims to make deep learning predictions or classifications more understandable for humans. Literature shows that deep learning (DL) algorithms are more precise in terms of their prediction than traditional machine learning (ML) algorithms. Nevertheless, they lack the interpretability and explainability that less complex algorithms are more fitted. Nowadays, one of the main goals of XDL research is to make these algorithms highly precise and explainable. There exist different systems and techniques, but only limited research on explaining deep neural networks using soft computing approaches. The purpose of this research is to propose the theoretical fundamentals of an explainable fuzzy-based deep learning (EFBDL) system that is both precise and explainable. The system comprises two main parts. First, the deep network part composed of a convolutional neural network (CNN) based on Inception V4 for image classification, a transfer learning mechanism, and a feature extraction algorithm based on neuron perturbation. Second, a soft computing part comprised of a fuzzy rule-based system (FRBS), a hierarchical network for natural language generation named granular linguistic model of a phenomenon (GLMP), and a human-machine integration methodology for linguistic rules named highly interpretable linguistic knowledge (HILK). The output of the overall system is an explanation of the neural network decision using natural language. This system focuses on preventing skin cancer rather than healing it. Thus, governments could use this kind of system for implementing policies focused on prevention and save in overall treatment costs of the disease.",
        "DOI": "10.1109/ICEDEG48599.2020.9096799",
        "paper_author": "Lima S.",
        "affiliation_name": "University of Fribourg",
        "affiliation_city": "Fribourg",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60024631",
        "affiliation_state": "FR"
    },
    {
        "paper_title": "Research and implementation of the prediction methods of the vehicle insurance renewal rate based on model fusion",
        "publication": "Proceedings - 2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering, AEMCSE 2020",
        "citied_by": "0",
        "cover_date": "2020-04-01",
        "Abstract": "This essay is based on an insurance company policy data and as the original data to make training test via Spss, Matlab, Python and three algorithms of XGBoost, LightGBM and BI-LSTM combining the big data, neural web and other relevant knowledge and technologies. And then, we can speculate the various customers of renewal insurance rate via the relatively and robust mathematical models which are made F1 value as the reference to adjust the weight and linear fusion. Simultaneously, we obtained the accuracy is about 0.88 under many data test verifications stably. And this satisfied simulation result can indicate this way is appropriate.",
        "DOI": "10.1109/AEMCSE50948.2020.00051",
        "paper_author": "Sun Z.",
        "affiliation_name": "Neimenggu Agricultural University",
        "affiliation_city": "Hohhot",
        "affiliation_country": "China",
        "affiliation_id": "60028205",
        "affiliation_state": "Nei Mongol"
    },
    {
        "paper_title": "Causal tree with instrumental variable: an extension of the causal tree framework to irregular assignment mechanisms",
        "publication": "International Journal of Data Science and Analytics",
        "citied_by": "11",
        "cover_date": "2020-04-01",
        "Abstract": "This paper provides a link between causal inference and machine learning techniques—specifically, Classification and Regression Trees—in observational studies where the receipt of the treatment is not randomized, but the assignment to the treatment can be assumed to be randomized (irregular assignment mechanism). The paper contributes to the growing applied machine learning literature on causal inference, by proposing a modified version of the Causal Tree (CT) algorithm to draw causal inference from an irregular assignment mechanism. The proposed method is developed by merging the CT approach with the instrumental variable framework to causal inference, hence the name Causal Tree with Instrumental Variable (CT-IV). An improved version, named Honest Causal Tree with Instrumental Variable (HCT-IV), able to estimate more reliably the heterogeneous causal effects, is also proposed. As compared to CT, the main strength of CT-IV and HCT-IV is that they can deal more efficiently with the heterogeneity of causal effects, as demonstrated by a series of numerical results obtained on synthetic data. Then, the proposed algorithms are used to evaluate a public policy implemented by the Tuscan Regional Administration (Italy), which aimed at easing the access to credit for small firms. In this context, HCT-IV breaks fresh ground for target-based policies, identifying interesting heterogeneous causal effects.",
        "DOI": "10.1007/s41060-019-00187-z",
        "paper_author": "Bargagli Stoffi F.J.",
        "affiliation_name": "Scuola IMT Alti Studi Lucca",
        "affiliation_city": "Lucca",
        "affiliation_country": "Italy",
        "affiliation_id": "60102060",
        "affiliation_state": "LU"
    },
    {
        "paper_title": "Energy-Efficient UAV Communications with Interference Management: Deep Learning Framework",
        "publication": "2020 IEEE Wireless Communications and Networking Conference Workshops, WCNCW 2020 - Proceedings",
        "citied_by": "8",
        "cover_date": "2020-04-01",
        "Abstract": "In this paper, an interference-aware energy- efficient scheme for a network of coexisting aerial-terrestrial cellular users is proposed. In particular, each aerial user aims at achieving a trade-off between maximizing energy efficiency and spectral efficiency while minimizing the incurred interference on the terrestrial users along its path. To provide a solution, we first formulate the energy efficiency problem for UAVs as an optimization problem by considering different key performance indicators (KPIs) for the network, coexisting terrestrial users, and UAVs as aerial users. Then, leveraging tools from deep learning, we transform this problem into a deep queue learning problem and present a learning-powered solution that incorporates the KPIs of interest in the design of the reward function to solve energy efficiency maximization for aerial users while minimizing interference to terrestrial users. A broad set of simulations have been conducted in order to investigate how the altitude of UAVs, and the tolerable level of interference, shape the optimal energy-efficient policy in the network. Simulation results show that the proposed scheme achieves better energy and spectral efficiency for UAV and less interference to terrestrial users incurred from aerial users. The obtained results further provide insights on the benefits of leveraging intelligent energy-efficient scheme. For example, a significant increase in the energy efficiency of aerial users with respect to increases in their spectral efficiency, while a considerable decrease in incurred interference to the terrestrial users is achieved in comparison to the non-learning scheme.",
        "DOI": "10.1109/WCNCW48565.2020.9124759",
        "paper_author": "Ghavimi F.",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland",
        "affiliation_id": "60103653",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "ONAP Based Pro-Active Access Discovery and Selection for 5G Networks",
        "publication": "2020 IEEE Wireless Communications and Networking Conference Workshops, WCNCW 2020 - Proceedings",
        "citied_by": "5",
        "cover_date": "2020-04-01",
        "Abstract": "This paper enhances the functionality of analytics and policy framework of ONAP to solve the problem of access discovery and selection of radio access networks, which is currently manually configured by the operators. We propose to automate the policy creation and handle it dynamically, based on current and historic data collected from various network nodes based on three main services (open to accomodate new services) of 5G i.e. Enhanced mobile broadband (eMBB), Ultra-reliable Low Latency communication (URLLC) and Massive Machine type communication (mMTC). Learning, analysis and prediction of the real and non-real time data can help to form dynamic access discovery and selection policies on the go with help of ONAP's DCAE (Data Collection, Analytics, and Events) and policy framework. To verify the effectiveness of our proposal we created a test bed with different access points and blended SOC with ONAP. Based on three different use cases we collected real time and non-real time traffic traces for our SOC to form dynamic policies with the help of DCAE and policy framework for selection of best available gNBs or eNBs. We compare our proposal with legacy networks and existing research works in the literature.",
        "DOI": "10.1109/WCNCW48565.2020.9124724",
        "paper_author": "Banerji R.",
        "affiliation_name": "Samsung R&amp;D Institute India-Bangalore",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60283810",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Machine Learning Based Approaches to Predict Customer Churn for an Insurance Company",
        "publication": "2020 Systems and Information Engineering Design Symposium, SIEDS 2020",
        "citied_by": "16",
        "cover_date": "2020-04-01",
        "Abstract": "Customer churn prediction plays an important role in business success for insurance companies like Markel Corporation. Each year Markel loses premium because some of their customers choose not to renew their policies. Based on the fact that the cost of attracting new customers is much greater than that of retaining existing customers, it is important for Markel to take early action to engage their customers before a policy expires. The goal in this work is to apply various machine learning methods and obtain an optimal model to predict customer churn rate. The dataset includes customer demographics features, customer behavior features, and macro environmental features. Exploratory analysis is conducted on critical features including policy length and types of coverage to draw insight about the impact of these features on the target variable - customers renew or do not renew their policies. With a large dataset, one of the main challenges is conducting feature dimension reduction and extracting important features to be used with a set of potential ML models. It turns out that the ML model with the best performance on the Area Under the Curve (AUC) metric is Extremely Randomized Trees Classifier and Gradient Boosting Model. Some suggestions on additional features to be incorporated are provided in the final comments. These features will improve predictive performance for the ML model of customer churn for Markel Corporation.",
        "DOI": "10.1109/SIEDS49339.2020.9106691",
        "paper_author": "He Y.",
        "affiliation_name": "University of Virginia",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States",
        "affiliation_id": "60021918",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "A Hybrid Game Theory and Reinforcement Learning Approach for Cyber-Physical Systems Security",
        "publication": "Proceedings of IEEE/IFIP Network Operations and Management Symposium 2020: Management in the Age of Softwarization and Artificial Intelligence, NOMS 2020",
        "citied_by": "15",
        "cover_date": "2020-04-01",
        "Abstract": "Cyber-Physical Systems (CPS) are monitored and controlled by Supervisory Control and Data Acquisition (SCADA) systems that use advanced computing, sensors, control systems, and communication networks. At first, CPS and SCADA systems were protected and secured by isolation. However, with recent industrial technology advances, the increased connectivity of CPSs and SCADA systems to enterprise networks has uncovered them to new cybersecurity threats and made them a primary target for cyber-attacks with the potential of causing catastrophic economic, social, and environmental damage. Recent research focuses on new methodologies for risk modeling and assessment using game theory and reinforcement learning.This paperwork proposes to frame CPS security on two different levels, strategic and battlefield, by meeting ideas from game theory and Multi-Agent Reinforcement Learning (MARL). The strategic level is modeled as imperfect information, extensive form game. Here, the human administrator and the malware author decide on the strategies of defense and attack, respectively. At the battlefield level, strategies are implemented by machine learning agents that derive optimal policies for run-time decisions. The outcomes of these policies manifest as the utility at a higher level, where we aim to reach a Nash Equilibrium (NE) in favor of the defender. We simulate the scenario of a virus spreading in the context of a CPS network. We present experiments using the MiniCPS simulator and the OpenAI Gym toolkit and discuss the results.",
        "DOI": "10.1109/NOMS47738.2020.9110453",
        "paper_author": "Khoury J.",
        "affiliation_name": "American University of Beirut",
        "affiliation_city": "Beirut",
        "affiliation_country": "Lebanon",
        "affiliation_id": "60068761",
        "affiliation_state": "Beirut Governorate"
    },
    {
        "paper_title": "Environment Modeling and Abstraction of Network States for Cognitive Functions",
        "publication": "Proceedings of IEEE/IFIP Network Operations and Management Symposium 2020: Management in the Age of Softwarization and Artificial Intelligence, NOMS 2020",
        "citied_by": "3",
        "cover_date": "2020-04-01",
        "Abstract": "Cognitive Autonomous Networks (CANs) promise to overcome the shortcomings of current Self-Organizing Network (SON) implementations, i.e., the limited flexibility and adaptability to changing environments, by applying cognition. In CAN, intelligent network automation functions, herein called Cognitive Functions (CFs), apply machine learning techniques to learn context-specific behavioral policies with which to automate network operations. For proper operation, the CAN system needs to learn the environment in which the functions are operating and to abstract the environment and performance observations into states to which the CFs must respond. This paper proposes a design and implementation of an Environmental-state Modeling and Abstraction (EMA) engine that could be tasked to learn the required abstract states in a consistent way across multiple CFs.",
        "DOI": "10.1109/NOMS47738.2020.9110333",
        "paper_author": "Mwanje S.S.",
        "affiliation_name": "Nokia Bell Labs",
        "affiliation_city": "Murray",
        "affiliation_country": "United States",
        "affiliation_id": "60021378",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "IoT or NoT: Identifying IoT Devices in a Short Time Scale",
        "publication": "Proceedings of IEEE/IFIP Network Operations and Management Symposium 2020: Management in the Age of Softwarization and Artificial Intelligence, NOMS 2020",
        "citied_by": "27",
        "cover_date": "2020-04-01",
        "Abstract": "In recent years the number of IoT devices in home networks has increased dramatically. Whenever a new device connects to the network, it must be quickly managed and secured using the relevant security mechanism or QoS policy. Thus a key challenge is to distinguish between IoT and NoT devices in a matter of minutes. Unfortunately, there is no clear indication of whether a device in a network is an IoT. In this paper, we propose different classifiers that identify a device as IoT or non-IoT, in a short time scale, and with high accuracy.Our classifiers were constructed using machine learning techniques on a seen (training) dataset and were tested on an unseen (test) dataset. They successfully classified devices that were not in the seen dataset with accuracy above 95%. The first classifier is a logistic regression classifier based on traffic features. The second classifier is based on features we retrieve from DHCP packets. Finally, we present a unified classifier that leverages the advantages of the other two classifiers.",
        "DOI": "10.1109/NOMS47738.2020.9110451",
        "paper_author": "Bremler-Barr A.",
        "affiliation_name": "Reichman University",
        "affiliation_city": "Herzliya",
        "affiliation_country": "Israel",
        "affiliation_id": "60012513",
        "affiliation_state": "Tel Aviv"
    },
    {
        "paper_title": "Learning context-aware policies from multiple smart homes via federated multi-task learning",
        "publication": "Proceedings - 5th ACM/IEEE Conference on Internet of Things Design and Implementation, IoTDI 2020",
        "citied_by": "70",
        "cover_date": "2020-04-01",
        "Abstract": "Internet-of-Things (IoT) devices deployed in smart homes expose users to cyber threats that can cause privacy leakage (e.g., smart TV eavesdropping) or physical hazards (e.g., smart stove causing fire). Prior work has argued that to effectively detect and prevent such threats, contextual policies are needed to decide if an access to an IoT device should be allowed. Today, however, such contextual access control policies need to be manually generated by IoT developers or users via preinstallation or runtime prompts. Both approaches suffer from potential misconfigurations and often fail to provide coverage over the space of policies. In this paper, our goal is to build a machine learning framework to automatically learn the contextual access control policies from the observed behavioral patterns of users in smart homes. Designing such a learning framework is challenging on two fronts. First, the accuracy is constrained by insufficient data in some smart homes and the diversity of IoT access patterns across different smart homes. Second, since we rely on usage patterns of IoT devices, users will have privacy concerns. We address these challenges in designing LoFTI, a federated multi-task learning framework that learns customized context-aware policies from multiple smart homes in a privacy-preserving manner. Based on prior user studies, we identify six general types of features to capture contextual access patterns. We build a simple machine learning model with temporal structure to achieve a good trade-off between accuracy and communication/computation cost. We design a custom data augmentation mechanism to address the issue of unbalanced data in learning (i.e., few negative vs. normal samples). We show that LoFTI can achieve low false positives/false negatives, reducing the false negative rate by 24.2% and false positive rate by 49.5%, comparing with the state-of-the-art single-home learning and all-home learning mechanism.",
        "DOI": "10.1109/IoTDI49375.2020.00017",
        "paper_author": "Yu T.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60027950",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Humanoid robot kick in motion ability for playing robotic soccer",
        "publication": "2020 IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2020",
        "citied_by": "15",
        "cover_date": "2020-04-01",
        "Abstract": "This work seeks to design and implement a humanoid robotic kick for situations where the robot is moving for the RoboCup simulation 3D robotic soccer league. It employs Reinforcement Learning (RL) techniques, namely the Proximal Policy Optimization (PPO) algorithm to create fast and reliable skills. The kick was divided into 6 cases according to initial conditions and separately trained for each of the cases. A series of kicks, both static and in motion, using two different gaits were developed. The kicks obtained show very high reliability and, when compared to state of the art kicks, displayed a very high time performance improvement. This opens the door to more dynamic games with faster kicks in the RoboCup simulation 3D league.",
        "DOI": "10.1109/ICARSC49921.2020.9096073",
        "paper_author": "Teixeira H.",
        "affiliation_name": "Universidade do Porto",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60007249",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "Fela: Incorporating flexible parallelism and elastic tuning to accelerate large-scale DML",
        "publication": "Proceedings - International Conference on Data Engineering",
        "citied_by": "6",
        "cover_date": "2020-04-01",
        "Abstract": "Distributed machine learning (DML) has become the common practice in industry, because of the explosive volume of training data and the growing complexity of training model. Traditional DML follows data parallelism but causes significant communication cost, due to the huge amount of parameter transmission. The recently emerging model-parallel solutions can reduce the communication workload, but leads to load imbalance and serious straggler problems. More importantly, the existing solutions, either data-parallel or model-parallel, ignore the nature of flexible parallelism for most DML tasks, thus failing to fully exploit the GPU computation power. Targeting at these existing drawbacks, we propose Fela, which incorporates both flexible parallelism and elastic tuning mechanism to accelerate DML. In order to fully leverage GPU power and reduce communication cost, Fela adopts hybrid parallelism and uses flexible parallel degrees to train different parts of the model. Meanwhile, Fela designs token-based scheduling policy to elastically tune the workload among different workers, thus mitigating the straggler effect and achieve better load balance. Our comparative experiments show that Fela can significantly improve the training throughput and outperforms the three main baselines (i.e. dataparallel, model-parallel, and hybrid-parallel) by up to 3.23×, 12.22×, and 1.85× respectively.",
        "DOI": "10.1109/ICDE48307.2020.00124",
        "paper_author": "Geng J.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Remote sensing of boreal wetlands 2: Methods for evaluating boreal wetland ecosystem state and drivers of change",
        "publication": "Remote Sensing",
        "citied_by": "45",
        "cover_date": "2020-04-01",
        "Abstract": "The following review is the second part of a two part series on the use of remotely sensed data for quantifying wetland extent and inferring or measuring condition for monitoring drivers of change on wetland environments. In the first part, we introduce policy makers and non-users of remotely sensed data with an effective feasibility guide on how data can be used. In the current review, we explore the more technical aspects of remotely sensed data processing and analysis using case studies within the literature. Here we describe: (a) current technologies used for wetland assessment and monitoring; (b) the latest algorithmic developments for wetland assessment; (c) new technologies; and (d) a framework for wetland sampling in support of remotely sensed data collection. Results illustrate that high or fine spatial resolution pixels (10 m) are critical for identifying wetland boundaries and extent, and wetland class, form and type, but are not required for all wetland sizes. Average accuracies can be up to 11% better (on average) than medium resolution (11-30 m) data pixels when compared with field validation. Wetland size is also a critical factor such that large wetlands may be almost as accurately classified using medium-resolution data (average = 76% accuracy, stdev = 21%). Decision-tree and machine learning algorithms provide the most accurate wetland classification methods currently available, however, these also require sampling of all permutations of variability. Hydroperiod accuracy, which is dependent on instantaneous water extent for single time period datasets does not vary greatly with pixel resolution when compared with field data (average = 87%, 86%) for high and medium resolution pixels, respectively. The results of this review provide users with a guideline for optimal use of remotely sensed data and suggested field methods for boreal and global wetland studies.",
        "DOI": "10.3390/RS12081321",
        "paper_author": "Chasmer L.",
        "affiliation_name": "University of Lethbridge",
        "affiliation_city": "Lethbridge",
        "affiliation_country": "Canada",
        "affiliation_id": "60024776",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Aerosol optical properties and contribution to differentiate haze and haze-freeweather in Wuhan city",
        "publication": "Atmosphere",
        "citied_by": "6",
        "cover_date": "2020-04-01",
        "Abstract": "Haze is an atmospheric phenomenon in which different types of particulates obscure the sky, and hence affect almost all human activities. Over a couple of recent decades, China has witnessed increasingly worse air quality as well as atmospheric haziness in its cities. There are various haze contributing factors including the rapid industrialization, excessive biomass burning, and an increase in the number of vehicles. This study proposes a methodology based on the aerosols scattering and absorption properties, to predict the likelihood of an episode of hazy days. This case study employs the aerosol optical properties data from integrated nephelometer and aethalometer sensors from December 2009 to September 2014 over Wuhan. The role and contribution of each aerosol optical parameter (e.g., aerosol scattering and absorption coefficients, single scattering albedo, scattering, and absorption Angstrom exponents, backscatter ratio, and asymmetry factor) in distinguishing haze and haze-free conditions has been quantitatively determined based on a machine learning approach. Each aerosol optical parameter was classified independently by the support vector machine (SVM) algorithm, and the aerosol scattering (85.37%) and absorption (74.53%) coefficients were found to be primary potential indicators. Through the Kolmogorov-Smirnov test and traditional statistical analysis, the aerosol scattering and absorption coefficients were then verified as important indicators in distinguishing haze and haze-free days. Finally, through a probability density diagram and frequency histogram, we propose a simple quantitative standard to distinguish between haze and haze-free conditions based on the aerosol scattering coefficient and absorption coefficient in Wuhan City. The accuracy of the standard was determined to be 81.49% after testing, which indicates an accurate result. An error in aerosol optical properties may lead to an error in the calculation of aerosol radiative forcing, the earth's energy budget, and climate prediction. Therefore, understanding of the aerosol properties during haze-free and haze-days will help policymakers to make new policies to control urban pollution and their effects on human health.",
        "DOI": "10.3390/atmos11040322",
        "paper_author": "Zhang M.",
        "affiliation_name": "Nanyang Normal University",
        "affiliation_city": "Nanyang",
        "affiliation_country": "China",
        "affiliation_id": "60082202",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "The Dynamics of Political Incivility on Twitter",
        "publication": "SAGE Open",
        "citied_by": "94",
        "cover_date": "2020-04-01",
        "Abstract": "Online incivility and harassment in political communication have become an important topic of concern among politicians, journalists, and academics. This study provides a descriptive account of uncivil interactions between citizens and politicians on Twitter. We develop a conceptual framework for understanding the dynamics of incivility at three distinct levels: macro (temporal), meso (contextual), and micro (individual). Using longitudinal data from the Twitter communication mentioning Members of Congress in the United States across a time span of over a year and relying on supervised machine learning methods and topic models, we offer new insights about the prevalence and dynamics of incivility toward legislators. We find that uncivil tweets represent consistently around 18% of all tweets mentioning legislators, but with spikes that correspond to controversial policy debates and political events. Although we find evidence of coordinated attacks, our analysis reveals that the use of uncivil language is common to a large number of users.",
        "DOI": "10.1177/2158244020919447",
        "paper_author": "Theocharis Y.",
        "affiliation_name": "Universität Bremen",
        "affiliation_city": "Bremen",
        "affiliation_country": "Germany",
        "affiliation_id": "60008293",
        "affiliation_state": "Bremen"
    },
    {
        "paper_title": "Reinforcement learning-based detection method for malware behavior in industrial control systems",
        "publication": "Gongcheng Kexue Xuebao/Chinese Journal of Engineering",
        "citied_by": "5",
        "cover_date": "2020-04-01",
        "Abstract": "Due to the popularity of intelligent mobile devices, malwares in the internet have seriously threatened the security of industrial control systems. Increasing number of malware attacks has become a major concern in the information security community. Currently, with the increase of malware variants in a wide range of application fields, some technical challenges must be addressed to detect malwares and achieve security protection in industrial control systems. Although many traditional solutions have been developed to provide effective ways of detecting malwares, some current approaches have their limitations in intelligently detecting and recognizing malwares, as more complex malwares exist. Given the success of machine learning methods and techniques in data analysis applications, some advanced algorithms can also be applied in the detection and analysis of complex malwares. To detect malwares and consider the advantages of machine learning algorithms, we developed a detection framework for malwares that threatens the network security of industrial control systems through the combination of an advanced machine learning algorithm, i.e., reinforcement learning. During the implementation process, according to the actual needs of malware behavior detection, key modules including feature extraction, policy, and classification networks were designed on the basis of the intelligent features of reinforcement learning algorithms in relation to sequence decision and dynamic feedback learning. Moreover, the training algorithms for the above key modules were presented while providing the detailed functional analysis and implementation framework. In the application experiments, after preprocessing the actual dataset of malwares, the developed method was tested and the satisfactory classification performance for malware was achieved that verified the efficiency and effectiveness of the reinforcement learning-based method. This method can provide an intelligent decision aid for general malware behavior detection.",
        "DOI": "10.13374/j.issn2095-9389.2019.09.16.005",
        "paper_author": "Gao Y.",
        "affiliation_name": "China Information Technology Security Evaluation Center",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "108160971",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Integrating landsat-8 and sentinel-2 time series data for yield prediction of sugarcane crops at the block level",
        "publication": "Remote Sensing",
        "citied_by": "47",
        "cover_date": "2020-04-01",
        "Abstract": "Early prediction of sugarcane crop yield at the commercial block level (unit area of a single crop of the same variety, ratoon or planting date) offers significant benefit to growers, consultants, millers, policy makers, crop insurance companies and researchers. This current study explored a remote sensing based approach for predicting sugarcane yield at the block level by further developing a regionally specific Landsat time series model and including individual crop sowing (or previous seasons' harvest) date. For the Bundaberg growing region of Australia this extends over a five months period, from July to November. For this analysis, the sugarcane blocks were clustered into 10 groups based on their specific planting or ratoon commencement date within the specified five months period. These clustered or groups of blocks were named 'bins'. Cloud free (<20%) satellite data from the polar-orbiting Landsat-8 (launched 2013), Sentinel-2A (launched 2015) and Sentinel-2B (launched 2017) sensors were acquired over the cane growing region in Bundaberg (area of 32,983 ha), from the growing season starting in July 2014, with the average green normalised difference vegetation index (GNDVI) derived for each block. The number of images acquired for each season was defined by the number of cloud free acquisitions. Using the Simple Linear Machine Learning (ML) algorithm, the extracted Landsat derived GNDVI values for each of the blocks were converted to Sentinel GNDVI. The average GNDVI of each 'bin' was plotted and a quadratic model was fitted through the time series to identify the peak growth stage defined as the maximum GNDVI value. The model derived maximum GNDVI values for each of the bins were then regressed against the average actual yield (t·ha-1) achieved for the respective bin over the five growing years, producing strong correlations (R2 = 0.92 to 0.99). The quadratic curves developed for the different bins were shifted according to the specific planting or ratoon date of an individual block allowing for the peak GNDVI value of the block to be calculated, regressed against the actual block yield (t·ha-1) and the prediction of yield to be made. To validate the accuracies of the 10 time series algorithms representing each of the 10 bins, 592 individual blocks were selected from the Bundaberg region during the 2019 harvest season. The crops were clustered into the appropriate bins with the respective algorithm applied. From a Sentinel image acquired on the 5 May 2019, the prediction accuracies were encouraging (R2 = 0.87 and RMSE = 11.33 (t·ha-1)) when compared to actual harvested yield, as reported by the mill. The results presented in this paper demonstrate significant progress in the accurate prediction of sugarcane yield at the individual sugarcane block level using a remote sensing, time-series based approach.",
        "DOI": "10.3390/RS12081313",
        "paper_author": "Rahman M.M.",
        "affiliation_name": "University of New England Australia",
        "affiliation_city": "Armidale",
        "affiliation_country": "Australia",
        "affiliation_id": "60017837",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "An Artificial Intelligence Enabled F-RAN Testbed",
        "publication": "IEEE Wireless Communications",
        "citied_by": "9",
        "cover_date": "2020-04-01",
        "Abstract": "F-RAN is regarded as a promising paradigm for mobile networks to alleviate the unprecedented traffic pressures and meet quality of service requirements of various 5G services with great flexibility. To make F-RAN work in a reliable, efficient, and smart way, AI-enabled F-RAN could be innovative in a number of directions: computing task offloading, resource management, dynamic beam selection, cross-layer design, energy saving and harvesting, mobility enhancement, and so on. In this article, an AI-enabled F-RAN testbed has been designed and implemented in a portable way based on OpenAirInterface, where an AI module is integrated into the F-RAN architecture. The AI module encapsulates the underlying operators of various machine learning frameworks to help a network make policies for different applications. Based on the proposed testbed, the F-RAN research community can easily analyze and evaluate their novel methods and quickly develop intelligent algorithms in a lab environment.",
        "DOI": "10.1109/MWC.001.1900386",
        "paper_author": "Lu Z.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Application of time series models in forecasting automobile sectors volatility for selected period",
        "publication": "International Journal of Management",
        "citied_by": "0",
        "cover_date": "2020-04-01",
        "Abstract": "The Bombay Stock Exchange is extensive and fully regulated trading system in India. Exploration and forecasting of stock market time series data have developed considerable interest from the researchers over the last decade. Time Series modelling techniques perform pivotal role in prediction of data for future demands. Volatility forecasting has become crucial for investors, policy holders, retailers since bringing preciseness in estimating the future is very difficult. Automotive sector has gone through severe crash in their operations in last decade mostly due to policy changes, policy paralysis and confusion among retailers about several new changes to be brought by the authority. This paper suggested a review on some of the most crucial works gives a meticulous view of recent machine learning (ML) techniques in the quantitative share price prediction showing that these are the methods transcend some traditional approaches. This paper using time series analysis found out the volatility forecasting using machine learning and by applying volatility forecasting model ARIMA. The present study focuses on analyzing the suitability of ARIMA model for forecasting share prices of four major companies of automobile sectors Hero Motor Corp, Ashok Leyland, TVS Motors, Eicher Motors. The data collection was done on monthly basis for the period 11th August, 2014 to 16th August,2019 from the website of Bombay stock exchange.",
        "DOI": "10.34218/IJM.11.4.2020.002",
        "paper_author": "Ghangare A.S.",
        "affiliation_name": "Shri Ramdeobaba College of Engineering and Management, Nagpur",
        "affiliation_city": "Nagpur",
        "affiliation_country": "India",
        "affiliation_id": "60056514",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Challenges in estimating tropical forest canopy height from planet dove imagery",
        "publication": "Remote Sensing",
        "citied_by": "25",
        "cover_date": "2020-04-01",
        "Abstract": "Monitoring tropical forests using spaceborne and airborne remote sensing capabilities is important for informing environmental policies and conservation actions. Developing large-scale machine learning estimation models of forest structure is instrumental in bridging the gap between retrospective analysis and near-real-time monitoring. However, most approaches use moderate spatial resolution satellite data with limited capabilities of frequent updating. Here, we take advantage of the high spatial and temporal resolutions of Planet Dove images and aim to automatically estimate top-of-canopy height (TCH) for the biologically diverse country of Peru from satellite imagery at 1 ha spatial resolution by building a model that associates Planet Dove textural features with airborne light detection and ranging (LiDAR) measurements of TCH.We use and modify features derived from Fourier textural ordination (FOTO) of Planet Dove images using spectral projection and train a gradient boosted regression for TCH estimation. We discuss the technical and scientific challenges involved in the generation of reliable mechanisms for estimating TCH from Planet Dove satellite image spectral and textural features. Our developed software toolchain is a robust and generalizable regression model that provides a root mean square error (RMSE) of 4.36 m for Peru. This represents a helpful advancement towards better monitoring of tropical forests and improves efforts in reducing emissions from deforestation and forest degradation (REDD+), an important climate change mitigation approach.",
        "DOI": "10.3390/rs12071160",
        "paper_author": "Csillik O.",
        "affiliation_name": "Arizona State University",
        "affiliation_city": "Tempe",
        "affiliation_country": "United States",
        "affiliation_id": "60003892",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Machine Learning and Water Economy: a New Approach to Predicting Dams Water Sales Revenue",
        "publication": "Water Resources Management",
        "citied_by": "7",
        "cover_date": "2020-04-01",
        "Abstract": "The proper prediction of water sales revenue allows for pricing policies with a specified trend for the optimized use of water resources. The present work focuses on the prediction of the economic status of water sales revenue in a semi-arid environment. To meet this objective, evaporation data (E), dam input water volume (I), and dam output water volume (O) are used as independent factors to estimate water revenue (R) in the case study of Jiroft Dam, Iran. Different machine learning models are used, including classification and regression tree (CART), Chi-squared automatic interaction detector (CHAID), multi-layer perceptron neural network (MLP), and radial basis function neural network (RBF). The data are obtained daily from 20 March 2012 to 20 March 2015 and defined in six input combinations to the models using multicollinearity analyses. To compare these models, the Nash-Sutcliffe efficiency coefficient (NSEC), the root mean square error (RMSE), and the coefficient of correlation (CC) criteria are employed. All the models act better when records of water sales revenue are incorporated as additional input factors to the machine learning models. The MLP neural-based model indicates the best predicted values for daily water sales revenue (RMSE = 638.3 $ and CC = 0.798) followed by the RBF neural model (RMSE = 655.1 $ and CC = 0.786).",
        "DOI": "10.1007/s11269-020-02529-0",
        "paper_author": "Zounemat-Kermani M.",
        "affiliation_name": "Shahid Bahonar University of Kerman",
        "affiliation_city": "Kerman",
        "affiliation_country": "Iran",
        "affiliation_id": "60031268",
        "affiliation_state": "Kerman"
    },
    {
        "paper_title": "Deep reinforcement learning for the control of microbial co-cultures in bioreactors",
        "publication": "PLoS Computational Biology",
        "citied_by": "70",
        "cover_date": "2020-04-01",
        "Abstract": "Multi-species microbial communities are widespread in natural ecosystems. When employed for biomanufacturing, engineered synthetic communities have shown increased productivity in comparison with monocultures and allow for the reduction of metabolic load by compartmentalising bioprocesses between multiple sub-populations. Despite these benefits, co-cultures are rarely used in practice because control over the constituent species of an assembled community has proven challenging. Here we demonstrate, in silico, the efficacy of an approach from artificial intelligence—reinforcement learning—for the control of co-cultures within continuous bioreactors. We confirm that feedback via a trained reinforcement learning agent can be used to maintain populations at target levels, and that model-free performance with bang-bang control can outperform a traditional proportional integral controller with continuous control, when faced with infrequent sampling. Further, we demonstrate that a satisfactory control policy can be learned in one twenty-four hour experiment by running five bioreactors in parallel. Finally, we show that reinforcement learning can directly optimise the output of a co-culture bioprocess. Overall, reinforcement learning is a promising technique for the control of microbial communities.",
        "DOI": "10.1371/journal.pcbi.1007783",
        "paper_author": "Treloar N.J.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Guest Editorial: Robust resource-constrained systems for machine learning",
        "publication": "IEEE Design and Test",
        "citied_by": "5",
        "cover_date": "2020-04-01",
        "Abstract": "Machine learning (ML) is nowadays embedded in several computing devices, consumer electronics, and cyber-physical systems. Smart sensors are deployed everywhere, in applications such as wearables and perceptual computing devices, and intelligent algorithms power our connected world. These devices collect and aggregate volumes of data, and in doing so, they augment our society in multiple ways; from healthcare, to social networks, to consumer electronics, and many more. To process these immense volumes of data, ML is emerging as the de facto analysis tool that powers several aspects of our Big Data society. Applications spanning from infrastructure (smart cities, intelligent transportation systems, smart grids, and to name a few), to social networks and content delivery, to e-commerce and smart factories, and emerging concepts such as self-driving cars and autonomous robots, are powered by ML technologies. These emerging systems require real-time inference and decision support; such scenarios, therefore, may use customized hardware accelerators, are typically bound by limited resources, and are restricted to limited connectivity and bandwidth. Thus, near-sensor computation and near-sensor intelligence have started emerging as necessities to continue supporting the paradigm shift of our connected world. The need for real-time intelligent data analytics (especially in the era of Big Data) for decision support near the data acquisition points emphasizes the need for revolutionizing the way we design, build, test, and verify processors, accelerators, and systems that facilitate ML (and deep learning, in particular) implemented in resource-constrained environments for use at the edge and the fog. As such, traditional von Neumann architectures are no longer sufficient and suitable, primarily because of limitations in both performance and energy efficiency caused especially by large amounts of data movement. Furthermore, due to the connected nature of such systems, security and reliability are also critically important. Robustness, therefore, in the form of reliability and operational capability in the presence of faults, whether malicious or accidental, is a critical need for such systems. Moreover, the operating nature of these systems relies on input data that is characterized by the four 'V's': velocity (speed of data generation), variability (variable forms and types), veracity (unreliable and unpredictable), and volume (i.e., large amounts of data). Thus, the robustness of such systems needs to consider this issue as well. Furthermore, robustness in terms of security, and in terms of reliability to hardware and software faults, in particular, besides their importance when it comes to safety-critical applications, is also a positive factor in building trustworthiness toward these disrupting technologies from our society. To achieve this envisioned robustness, we need to refocus on problems such as design, verification, architecture, scheduling and allocation policies, optimization, and many more, for determining the most efficient, secure, and reliable way of implementing these novel applications within a robust, resource-constrained system, which may or may not be connected. This special issue, therefore, addresses a key aspect of fog and edge-based ML algorithms; robustness (as defined above) under resource-constraint scenarios. The special issue presents emerging works in how we design robust systems, both in terms of reliability as well as fault tolerance and security, while operating with a limited number of resources, and possibly in the presence of harsh environments that may eliminate connectivity and pollute the input data.",
        "DOI": "10.1109/MDAT.2020.2971201",
        "paper_author": "Theocharides T.",
        "affiliation_name": "University of Cyprus",
        "affiliation_city": "Nicosia",
        "affiliation_country": "Cyprus",
        "affiliation_id": "60071343",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting disease risk areas through co-production of spatial models: The example of kyasanur forest disease in india’s forest landscapes",
        "publication": "PLoS Neglected Tropical Diseases",
        "citied_by": "36",
        "cover_date": "2020-04-01",
        "Abstract": "Zoonotic diseases affect resource-poor tropical communities disproportionately, and are linked to human use and modification of ecosystems. Disentangling the socio-ecological mechanisms by which ecosystem change precipitates impacts of pathogens is critical for predicting disease risk and designing effective intervention strategies. Despite the global “One Health” initiative, predictive models for tropical zoonotic diseases often focus on nar-row ranges of risk factors and are rarely scaled to intervention programs and ecosystem use. This study uses a participatory, co-production approach to address this disconnect between science, policy and implementation, by developing more informative disease models for a fatal tick-borne viral haemorrhagic disease, Kyasanur Forest Disease (KFD), that is spreading across degraded forest ecosystems in India. We integrated knowledge across disciplines to identify key risk factors and needs with actors and beneficiaries across the relevant policy sectors, to understand disease patterns and develop decision support tools. Human case locations (2014–2018) and spatial machine learning quantified the relative role of risk factors, including forest cover and loss, host densities and public health access, in driving landscape-scale disease patterns in a long-affected district (Shivamogga, Karnataka State). Models combining forest metrics, livestock densities and elevation accurately predicted spatial patterns in human KFD cases (2014–2018). Consistent with suggestions that KFD is an “ecotonal” disease, landscapes at higher risk for human KFD contained diverse forest-plantation mosaics with high coverage of moist evergreen forest and plantation, high indigenous cattle density, and low coverage of dry deciduous forest. Models predicted new hotspots of outbreaks in 2019, indicating their value for spatial targeting of intervention. Co-production was vital for: gathering outbreak data that reflected locations of exposure in the landscape; better understanding contextual socio-ecological risk factors; and tailoring the spatial grain and outputs to the scale of forest use, and public health interventions. We argue this inter-disciplinary approach to risk prediction is applicable across zoonotic diseases in tropical settings.",
        "DOI": "10.1371/journal.pntd.0008179",
        "paper_author": "Purseid B.V.",
        "affiliation_name": "UK Centre for Ecology &amp; Hydrology",
        "affiliation_city": "Wallingford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60004708",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Top concerns of tweeters during the COVID-19 pandemic: A surveillance study",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "582",
        "cover_date": "2020-04-01",
        "Abstract": "Background: The recent coronavirus disease (COVID-19) pandemic is taking a toll on the world's health care infrastructure as well as the social, economic, and psychological well-being of humanity. Individuals, organizations, and governments are using social media to communicate with each other on a number of issues relating to the COVID-19 pandemic. Not much is known about the topics being shared on social media platforms relating to COVID-19. Analyzing such information can help policy makers and health care organizations assess the needs of their stakeholders and address them appropriately. Objective: This study aims to identify the main topics posted by Twitter users related to the COVID-19 pandemic. Methods: Leveraging a set of tools (Twitter's search application programming interface (API), Tweepy Python library, and PostgreSQL database) and using a set of predefined search terms (\"corona,\" \"2019-nCov,\" and \"COVID-19\"), we extracted the text and metadata (number of likes and retweets, and user profile information including the number of followers) of public English language tweets from February 2, 2020, to March 15, 2020. We analyzed the collected tweets using word frequencies of single (unigrams) and double words (bigrams). We leveraged latent Dirichlet allocation for topic modeling to identify topics discussed in the tweets. We also performed sentiment analysis and extracted the mean number of retweets, likes, and followers for each topic and calculated the interaction rate per topic. Results: Out of approximately 2.8 million tweets included, 167,073 unique tweets from 160,829 unique users met the inclusion criteria. Our analysis identified 12 topics, which were grouped into four main themes: origin of the virus; its sources; its impact on people, countries, and the economy; and ways of mitigating the risk of infection. The mean sentiment was positive for 10 topics and negative for 2 topics (deaths caused by COVID-19 and increased racism). The mean for tweet topics of account followers ranged from 2722 (increased racism) to 13,413 (economic losses). The highest mean of likes for the tweets was 15.4 (economic loss), while the lowest was 3.94 (travel bans and warnings). Conclusions: Public health crisis response activities on the ground and online are becoming increasingly simultaneous and intertwined. Social media provides an opportunity to directly communicate health information to the public. Health systems should work on building national and international disease detection and surveillance systems through monitoring social media. There is also a need for a more proactive and agile public health presence on social media to combat the spread of fake news.",
        "DOI": "10.2196/19016",
        "paper_author": "Abd-Alrazaq A.",
        "affiliation_name": "Hamad Bin Khalifa University, College of Science and Engineering",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar",
        "affiliation_id": "60113885",
        "affiliation_state": "Ad-Dawhah"
    },
    {
        "paper_title": "Mode Selection and Resource Allocation in Sliced Fog Radio Access Networks: A Reinforcement Learning Approach",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "54",
        "cover_date": "2020-04-01",
        "Abstract": "The mode selection and resource allocation in fog radio access networks (F-RANs) have been advocated as key techniques to improve spectral and energy efficiency. In this paper, we investigate the joint optimization of mode selection and resource allocation in uplink F-RANs, where both of the traditional user equipments (UEs) and fog UEs are served by constructed network slice instances. The concerned optimization is formulated as a mixed-integer programming problem, and both the orthogonal and multiplexed subchannel allocation strategies are proposed to guarantee the slice isolation. Motivated by the development of machine learning, two reinforcement learning based algorithms are developed to solve the original high complexity problem under traditional and fog UEs' specific performance requirements. The basic idea of the proposals is to generate a good mode selection policy according to the immediate reward fed back by an environment. Simulation results validate the benefits of our proposed algorithms and show that a tradeoff between system power consumption and queue delay can be achieved.",
        "DOI": "10.1109/TVT.2020.2972999",
        "paper_author": "Xiang H.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Resource Allocation With Edge Computing in IoT Networks via Machine Learning",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "130",
        "cover_date": "2020-04-01",
        "Abstract": "In this article, we investigate resource allocation with edge computing in Internet-of-Things (IoT) networks via machine learning approaches. Edge computing is playing a promising role in IoT networks by providing computing capabilities close to users. However, the massive number of users in IoT networks requires sufficient spectrum resource to transmit their computation tasks to an edge server, while the IoT users were developed to have more powerful computation ability recently, which makes it possible for them to execute some tasks locally. Then, the design of computation task offloading policies for such IoT edge computing systems remains challenging. In this article, centralized user clustering is explored to group the IoT users into different clusters according to users' priorities. The cluster with the highest priority is assigned to offload computation tasks and executed at the edge server, while the lowest priority cluster executes computation tasks locally. For the other clusters, the design of distributed task offloading policies for the IoT users is modeled by a Markov decision process, where each IoT user is considered as an agent which makes a series of decisions on task offloading by minimizing the system cost based on the environment dynamics. To deal with the curse of high dimensionality, we use a deep 'Q' -network to learn the optimal policy in which deep neural network is used to approximate the 'Q' -function in 'Q' -learning. Simulations show that users are grouped into clusters with optimal number of clusters. Moreover, our proposed computation offloading algorithm outperforms the other baseline schemes under the same system costs.",
        "DOI": "10.1109/JIOT.2020.2970110",
        "paper_author": "Liu X.",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022109",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial neural networks to estimate the influence of vehicular emission variables on morbidity and mortality in the largest metropolis in South America",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "37",
        "cover_date": "2020-04-01",
        "Abstract": "The emission of pollutants from vehicles is presented as a prime factor deteriorating air quality. Thus, seeking public policies encouraging the use and the development of more sustainable vehicles is paramount to preserve populations' health. To better understand the health risks caused by air pollution and exclusively by mobile sources urges the question of which input variables should be considered. Therefore, this research aims to estimate the impacts on populations' health related to road transport variables for Sao Paulo, Brazil, the largest metropolis in South America. We used three Artificial Neural Networks (ANN) (Multilayer Perceptron-MLP, Extreme Learning Machines-ELM, and Echo State Neural Networks-ESN) to estimate the impacts of carbon monoxide, nitrogen oxides, ozone, sulfur dioxide, and particulate matter on outcomes for respiratory diseases (morbidity-hospital admissions and mortality). We also used unusual inputs, such as road vehicles fleet, distributed and sold fuels amount, and vehicle average mileage. We also used deseasonalization and the Variable Selection Methods (VSM) (Mutual Information Filter and Wrapper). The results showed that the VSM excluded some variables, but the best performances were reached considering all of them. The ELM achieved the best overall results to morbidity, and the ESN to mortality, both using deseasonalization. Our study makes an important contribution to the following United Nations Sustainable Development Goals: 3-good health and well-being, 7-affordable and clean energy, and 11-sustainable cities and communities. These research findings will guide government about future legislations, public policies aiming to warranty and improve the health system.",
        "DOI": "10.3390/su12072621",
        "paper_author": "Kachba Y.",
        "affiliation_name": "Universidade Tecnológica Federal do Paraná",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil",
        "affiliation_id": "60027294",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "LoadaBoost: Loss-based AdaBoost federated machine learning with reduced computational complexity on IID and non-IID intensive care data",
        "publication": "PLoS ONE",
        "citied_by": "107",
        "cover_date": "2020-04-01",
        "Abstract": "Intensive care data are valuable for improvement of health care, policy making and many other purposes. Vast amount of such data are stored in different locations, on many different devices and in different data silos. Sharing data among different sources is a big challenge due to regulatory, operational and security reasons. One potential solution is federated machine learning, which is a method that sends machine learning algorithms simultaneously to all data sources, trains models in each source and aggregates the learned models. This strategy allows utilization of valuable data without moving them. One challenge in applying federated machine learning is the possibly different distributions of data from diverse sources. To tackle this problem, we proposed an adaptive boosting method named LoAdaBoost that increases the efficiency of federated machine learning. Using intensive care unit data from hospitals, we investigated the performance of learning in IID and non-IID data distribution scenarios, and showed that the proposed LoAdaBoost method achieved higher predictive accuracy with lower computational complexity than the baseline method.",
        "DOI": "10.1371/journal.pone.0230706",
        "paper_author": "Huang L.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Nursing in the age of artificial intelligence: Protocol for a scoping review",
        "publication": "JMIR Research Protocols",
        "citied_by": "21",
        "cover_date": "2020-04-01",
        "Abstract": "Background: It is predicted that digital health technologies that incorporate artificial intelligence will transform health care delivery in the next decade. Little research has explored how emerging trends in artificial intelligence-driven digital health technologies may influence the relationship between nurses and patients. Objective: The purpose of this scoping review is to summarize the findings from 4 research questions regarding emerging trends in artificial intelligence-driven digital health technologies and their influence on nursing practice across the 5 domains outlined by the Canadian Nurses Association framework: administration, clinical care, education, policy, and research. Specifically, this scoping review will examine how emerging trends will transform the roles and functions of nurses over the next 10 years and beyond. Methods: Using an established scoping review methodology, MEDLINE, Cumulative Index to Nursing and Allied Health Literature, Embase, PsycINFO, Cochrane Database of Systematic Reviews, Cochrane Central, Education Resources Information Centre, Scopus, Web of Science, and Proquest databases were searched. In addition to the electronic database searches, a targeted website search will be performed to access relevant grey literature. Abstracts and full-text studies will be independently screened by 2 reviewers using prespecified inclusion and exclusion criteria. Included literature will focus on nursing and digital health technologies that incorporate artificial intelligence. Data will be charted using a structured form and narratively summarized. Results: Electronic database searches have retrieved 10,318 results. The scoping review and subsequent briefing paper will be completed by the fall of 2020. Conclusions: A symposium will be held to share insights gained from this scoping review with key thought leaders and a cross section of stakeholders from administration, clinical care, education, policy, and research as well as patient advocates. The symposium will provide a forum to explore opportunities for action to advance the future of nursing in a technological world and, more specifically, nurses' delivery of compassionate care in the age of artificial intelligence. Results from the symposium will be summarized in the form of a briefing paper and widely disseminated to relevant stakeholders.",
        "DOI": "10.2196/17490",
        "paper_author": "Buchanan C.",
        "affiliation_name": "Registered Nurses' Association of Ontario",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "106948301",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "The physician-scientist, 75 years after Vannevar Bush–rethinking the ‘bench’ and ‘bedside’ dichotomy",
        "publication": "Nature Medicine",
        "citied_by": "4",
        "cover_date": "2020-04-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41591-020-0828-1",
        "paper_author": "Sarma G.P.",
        "affiliation_name": "Broad Institute",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60001001",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Adaptive human-machine evaluation framework using stochastic gradient descent-based reinforcement learning for dynamic competing network",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "7",
        "cover_date": "2020-04-01",
        "Abstract": "Complex problems require considerable work, extensive computation, and the development of effective solution methods. Recently, physical hardware- and software-based technologies have been utilized to support problem solving with computers. However, problem solving often involves human expertise and guidance. In these cases, accurate human evaluations and diagnoses must be communicated to the system, which should be done using a series of real numbers. In previous studies, only binary numbers have been used for this purpose. Hence, to achieve this objective, this paper proposes a new method of learning complex network topologies that coexist and compete in the same environment and interfere with the learning objectives of the others. Considering the special problem of reinforcement learning in an environment in which multiple network topologies coexist, we propose a policy that properly computes and updates the rewards derived from quantitative human evaluation and computes together with the rewards of the system. The rewards derived from the quantitative human evaluation are designed to be updated quickly and easily in an adaptive manner. Our new framework was applied to a basketball game for validation and demonstrated greater effectiveness than the existing methods.",
        "DOI": "10.3390/app10072558",
        "paper_author": "Kim J.",
        "affiliation_name": "Kumoh National Institute of Technology",
        "affiliation_city": "Gumi",
        "affiliation_country": "South Korea",
        "affiliation_id": "60019209",
        "affiliation_state": "Gyeongsangbuk-do"
    },
    {
        "paper_title": "Digital twin and CyberGIS for improving connectivity and measuring the impact of infrastructure construction planning in smart cities",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "123",
        "cover_date": "2020-04-01",
        "Abstract": "Smart technologies are advancing, and smart cities can be made smarter by increasing the connectivity and interactions of humans, the environment, and smart devices. This paper discusses selective technologies that can potentially contribute to developing an intelligent environment and smarter cities. While the connectivity and efficiency of smart cities is important, the analysis of the impact of construction development and large projects in the city is crucial to decision and policy makers, before the project is approved. This raises the question of assessing the impact of a new infrastructure project on the community prior to its commencement-what type of technologies can potentially be used for creating a virtual representation of the city? How can a smart city be improved by utilizing these technologies? There are a wide range of technologies and applications available but understanding their function, interoperability, and compatibility with the community requires more discussion around system designs and architecture. These questions can be the basis of developing an agenda for further investigations. In particular, the need for advanced tools such as mobile scanners, Geospatial Artificial Intelligence, Unmanned Aerial Vehicles, Geospatial Augmented Reality apps, Light Detection, and Ranging in smart cities is discussed. In line with smart city technology development, this Special Issue includes eight accepted articles covering trending topics, which are briefly reviewed.",
        "DOI": "10.3390/ijgi9040240",
        "paper_author": "Shirowzhan S.",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60028333",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Missing data imputation for geolocation-based price prediction using KNN-MCF method",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "40",
        "cover_date": "2020-04-01",
        "Abstract": "Accurate house price forecasts are very important for formulating national economic policies. In this paper, we offer an effective method to predict houses' sale prices. Our algorithm includes one-hot encoding to convert text data into numeric data, feature correlation to select only the most correlated variables, and a technique to overcome the missing data. Our approach is an effective way to handle missing data in large datasets with the K-nearest neighbor algorithm based on the most correlated features (KNN-MCF). As far as we are concerned, there has been no previous research that has focused on important features dealing with missing observations. Compared to the typical machine learning prediction algorithms, the prediction accuracy of the proposed method is 92.01% with the random forest algorithm, which is more efficient than the other methods.",
        "DOI": "10.3390/ijgi9040227",
        "paper_author": "Sanjar K.",
        "affiliation_name": "Kyungpook National University (KNU)",
        "affiliation_city": "Daegu",
        "affiliation_country": "South Korea",
        "affiliation_id": "60012704",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A guide for the food industry to meet the future skills requirements emerging with industry 4.0",
        "publication": "Foods",
        "citied_by": "97",
        "cover_date": "2020-04-01",
        "Abstract": "The food industry has recently faced rapid and constant changes due to the current industrial revolution, Industry 4.0, which has also profoundly altered the dynamics of the industry overall. Due to the emerging digitalisation, manufacturing models are changing through the use of smart technologies, such as robotics, Artificial Intelligence (AI), Internet of Things (IoT), machine learning, etc. They are experiencing a new phase of automation that enables innovative and more efficient processes, products and services. The introduction of these novel business models demands new professional skills requirements in the workforce of the food industry. In this work, we introduce an industry-driven proactive strategy to achieve a successful digital transformation in the food sector. For that purpose, we focus on defining the current and near-future key skills and competencies demanded by each of the professional profiles related to the food industry. To achieve this, we generated an automated database of current and future professions and competencies and skills. This database can be used as a fundamental roadmap guiding the sector through future changes caused by Industry 4.0. The interest shown by the local sectorial cluster and related entities reinforce the idea. This research will be a key tool for both academics and policy-makers to provide well-developed and better-oriented continuous training programs in order to reduce the skill mismatch between the workforce and the jobs.",
        "DOI": "10.3390/foods9040492",
        "paper_author": "Akyazi T.",
        "affiliation_name": "Universidad de Deusto",
        "affiliation_city": "Bilbao",
        "affiliation_country": "Spain",
        "affiliation_id": "60006565",
        "affiliation_state": "Biscay"
    },
    {
        "paper_title": "Four equity considerations for the use of artificial intelligence in public health",
        "publication": "Bulletin of the World Health Organization",
        "citied_by": "25",
        "cover_date": "2020-04-01",
        "Abstract": "NA",
        "DOI": "10.2471/BLT.19.237503",
        "paper_author": "Smith M.J.",
        "affiliation_name": "Western University",
        "affiliation_city": "London",
        "affiliation_country": "Canada",
        "affiliation_id": "60010884",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Automated Geometric Shape Deviation Modeling for Additive Manufacturing Systems via Bayesian Neural Networks",
        "publication": "IEEE Transactions on Automation Science and Engineering",
        "citied_by": "55",
        "cover_date": "2020-04-01",
        "Abstract": "A significant challenge in comprehensive geometric accuracy control of an additive manufacturing (AM) system is the specification of shape deviation models for different computer-aided design products manufactured on its constituent AM processes. Current deviation modeling techniques do not satisfactorily address this challenge because they can require substantial user inputs and efforts to implement. We present a new model building methodology based on a class of Bayesian neural networks (NNs) that directly addresses this challenge with much less effort. Our method enables automated deviation modeling of different shapes and AM processes and yields models with higher predictive accuracies compared to the existing modeling methods on the same samples of manufactured products. A fundamental innovation in our methodology is the design of new and connectable NN structures that facilitate the leveraging of previously specified deviation models for adaptive model building of new shapes and AM processes. The power and broad scope of our method are demonstrated with several case studies on both in-plane and out-of-plane deviations for a wide variety of shapes manufactured under different stereolithography processes. Our Bayesian methodology for automated and comprehensive deviation modeling can ultimately help to advance flexible, efficient, and high-quality manufacturing in an AM system. Note to Practitioners - Additive manufacturing (AM) systems possess an intrinsic capability for one-of-a-kind manufacturing of a vast variety of shapes across a wide spectrum of constituent processes. Learning how to control geometric shape accuracy in a comprehensive manner for an AM system is vital to its operation. This task is challenging due to constraints on the number of test shapes that can be manufactured and user efforts that can be devoted for learning and predicting geometric errors of different sets of shapes and AM processes. This article presents an automated machine learning methodology for comprehensive learning and prediction of geometric errors in an AM system based on a limited number of test shapes manufactured under different processes. Several case studies serve to validate the potential of our methodology to learn effective geometric accuracy control policies for general AM systems in practice.",
        "DOI": "10.1109/TASE.2019.2936821",
        "paper_author": "Ferreira R.D.S.B.",
        "affiliation_name": "Intel Corporation",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States",
        "affiliation_id": "60033010",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Towards a global strategy on digital health",
        "publication": "Bulletin of the World Health Organization",
        "citied_by": "18",
        "cover_date": "2020-04-01",
        "Abstract": "NA",
        "DOI": "10.2471/BLT.20.253955",
        "paper_author": "Mariano B.",
        "affiliation_name": "Organisation Mondiale de la Santé",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60027142",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ethical barriers to artificial intelligence in the national health service, United Kingdom of Great Britain and Northern Ireland",
        "publication": "Bulletin of the World Health Organization",
        "citied_by": "11",
        "cover_date": "2020-04-01",
        "Abstract": "NA",
        "DOI": "10.2471/BLT.19.237230",
        "paper_author": "Thompson C.L.",
        "affiliation_name": "University of Aberdeen School of Medicine, Medical Sciences and Nutrition",
        "affiliation_city": "Aberdeen",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60011032",
        "affiliation_state": "Scotland"
    },
    {
        "paper_title": "Identification of ancestry informative marker (AIM) panels to assess hybridisation between feral and domestic sheep",
        "publication": "Animals",
        "citied_by": "15",
        "cover_date": "2020-04-01",
        "Abstract": "Hybridisation of wild populations with their domestic counterparts can lead to the loss of wildtype genetic integrity, outbreeding depression, and loss of adaptive features. The Mediterranean island of Sardinia hosts one of the last extant autochthonous European mouflon (Ovis aries musimon) populations. Although conservation policies, including reintroduction plans, have been enforced to preserve Sardinian mouflon, crossbreeding with domestic sheep has been documented. We identified panels of single nucleotide polymorphisms (SNPs) that could act as ancestry informative markers able to assess admixture in feral x domestic sheep hybrids. The medium-density SNP array genotyping data of Sardinian mouflon and domestic sheep (O. aries aries) showing pure ancestry were used as references. We applied a two-step selection algorithm to this data consisting of preselection via Principal Component Analysis followed by a supervised machine learning classification method based on random forest to develop SNP panels of various sizes. We generated ancestry informative marker (AIM) panels and tested their ability to assess admixture in mouflon x domestic sheep hybrids both in simulated and real populations of known ancestry proportions. All the AIM panels recorded high correlations with the ancestry proportion computed using the full medium-density SNP array. The AIM panels proposed here may be used by conservation practitioners as diagnostic tools to exclude hybrids from reintroduction plans and improve conservation strategies for mouflon populations.",
        "DOI": "10.3390/ani10040582",
        "paper_author": "Somenzi E.",
        "affiliation_name": "Università Cattolica del Sacro Cuore, Campus di Piacenza e Cremona",
        "affiliation_city": "Piacenza",
        "affiliation_country": "Italy",
        "affiliation_id": "60005563",
        "affiliation_state": "Emilia-Romagna"
    },
    {
        "paper_title": "Partial Policy-Based Reinforcement Learning for Anatomical Landmark Localization in 3D Medical Images",
        "publication": "IEEE Transactions on Medical Imaging",
        "citied_by": "45",
        "cover_date": "2020-04-01",
        "Abstract": "Utilizing the idea of long-term cumulative return, reinforcement learning (RL) has shown remarkable performance in various fields. We follow the formulation of landmark localization in 3D medical images as an RL problem. Whereas value-based methods have been widely used to solve RL-based localization problems, we adopt an actor-critic based direct policy search method framed in a temporal difference learning approach. In RL problems with large state and/or action spaces, learning the optimal behavior is challenging and requires many trials. To improve the learning, we introduce a partial policy-based reinforcement learning to enable solving the large problem of localization by learning the optimal policy on smaller partial domains. Independent actors efficiently learn the corresponding partial policies, each utilizing their own independent critic. The proposed policy reconstruction from the partial policies ensures a robust and efficient localization, where the sub-agents uniformly contribute to the state-transitions based on their simple partial policies mapping to binary actions. Experiments with three different localization problems in 3D CT and MR images showed that the proposed reinforcement learning requires a significantly smaller number of trials to learn the optimal behavior compared to the original behavior learning scheme in RL. It also ensures a satisfactory performance when trained on fewer images.",
        "DOI": "10.1109/TMI.2019.2946345",
        "paper_author": "Abdullah Al W.",
        "affiliation_name": "Hankuk University of Foreign Studies",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60007830",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning Automata Based Competition Scheme to Train Deep Neural Networks",
        "publication": "IEEE Transactions on Emerging Topics in Computational Intelligence",
        "citied_by": "10",
        "cover_date": "2020-04-01",
        "Abstract": "Deep neural network has been one of the most powerful models in the field of machine learning, which has acquired state-of-the-art results in many tasks including image classification, object detection, text recognition, and so on. There have been many tricks to improve the training and generalization performance of deep neural network, such as dropout, ReLU, batch normalization, etc. In this paper, we proposed a new basic element to form deep neural networks, called learning automata competition unit (LCU). The LCU includes a group of general neural units and learning automata. The adopted learning automata are reinforcement learning methods, which can learn the optimal action through continuously interacting with a stochastic environment. Since the learning automata has powerful policy-making ability for both stochastic and non-stationary environment, the proposed LCU can facilitate competition in a group of neural units and gradually select the better trained neural units during training. The selected neural units through competition can make the training process more efficient, which can simultaneously get better training and generalization performance. The experiments on MNIST, CIFAR-10, and the Reuters newswire topic classification dataset show the performance of our method for both deep fully connected neural network and convolutional neural network.",
        "DOI": "10.1109/TETCI.2018.2868474",
        "paper_author": "Guo H.",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60025084",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep reinforcement learning approach with multiple experience pools for UAV’s autonomous motion planning in complex unknown environments",
        "publication": "Sensors (Switzerland)",
        "citied_by": "35",
        "cover_date": "2020-04-01",
        "Abstract": "Autonomous motion planning (AMP) of unmanned aerial vehicles (UAVs) is aimed at enabling a UAV to safely fly to the target without human intervention. Recently, several emerging deep reinforcement learning (DRL) methods have been employed to address the AMP problem in some simplified environments, and these methods have yielded good results. This paper proposes a multiple experience pools (MEPs) framework leveraging human expert experiences for DRL to speed up the learning process. Based on the deep deterministic policy gradient (DDPG) algorithm, a MEP–DDPG algorithm was designed using model predictive control and simulated annealing to generate expert experiences. On applying this algorithm to a complex unknown simulation environment constructed based on the parameters of the real UAV, the training experiment results showed that the novel DRL algorithm resulted in a performance improvement exceeding 20% as compared with the state-of-the-art DDPG. The results of the experimental testing indicate that UAVs trained using MEP–DDPG can stably complete a variety of tasks in complex, unknown environments.",
        "DOI": "10.3390/s20071890",
        "paper_author": "Hu Z.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Sepsis 2019: What surgeons need to know",
        "publication": "Surgical Infections",
        "citied_by": "21",
        "cover_date": "2020-04-01",
        "Abstract": "The definition of sepsis continues to be as dynamic as the management strategies used to treat this. Sepsis-3 has replaced the earlier systemic inflammatory response syndrome (SIRS)-based diagnoses with the rapid Sequential Organ Failure Assessment (SOFA) score assisting in predicting overall prognosis with regards to mortality. Surgeons have an important role in ensuring adequate source control while recognizing the threat of carbapenem-resistance in gram-negative organisms. Rapid diagnostic tests are being used increasingly for the early identification of multi-drug-resistant organisms (MDROs), with a key emphasis on the multidisciplinary alert of results. Novel, higher generation antibiotic agents have been developed for resistance in ESKCAPE (Enterococcus faecium, Staphylococcus aureus, Klebsiella pneumoniae, Acinetobacter baumannii, Pseudomonas aeruginosa, and Enterobacter species) organisms while surgeons have an important role in the prevention of spread. The Study to Optimize Peritoneal Infection Therapy (STOP-IT) trial has challenged the previous paradigm of length of antibiotic treatment whereas biomarkers such as procalcitonin are playing a prominent role in individualizing therapy. Several novel therapies for refractory septic shock, while still investigational, are gaining prominence rapidly (such as vitamin C) whereas others await further clinical trials. Management strategies presented as care bundles continue to be updated by the Surviving Sepsis Campaign, yet still remain controversial in its global adoption. We have broadened our temporal and epidemiologic perspective of sepsis by understanding it both as an acute, time-sensitive, life-threatening illness to a chronic condition that increases the risk of mortality up to five years post-discharge. Artificial intelligence, machine learning, and bedside scoring systems can assist the clinician in predicting post-operative sepsis. The public health role of the surgeon is key. This includes collaboration and multi-disciplinary antibiotic stewardship at a hospital level. It also requires controlling pharmaceutical sales and the unregulated dispensing of antibiotic agents globally through policy initiatives to control emerging resistance through prevention.",
        "DOI": "10.1089/sur.2019.126",
        "paper_author": "Ho V.P.",
        "affiliation_name": "MetroHealth Medical Center Cleveland",
        "affiliation_city": "Cleveland",
        "affiliation_country": "United States",
        "affiliation_id": "60027486",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Can we learn individual-level treatment policies from clinical data?",
        "publication": "Biostatistics (Oxford, England)",
        "citied_by": "16",
        "cover_date": "2020-04-01",
        "Abstract": "NA",
        "DOI": "10.1093/biostatistics/kxz043",
        "paper_author": "Shalit U.",
        "affiliation_name": "Technion - Israel Institute of Technology",
        "affiliation_city": "Haifa",
        "affiliation_country": "Israel",
        "affiliation_id": "60022403",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The rise and fall of the model for end-stage liver disease score and the need for an optimized machine learning approach for liver allocation",
        "publication": "Current Opinion in Organ Transplantation",
        "citied_by": "12",
        "cover_date": "2020-04-01",
        "Abstract": "Purpose of reviewThe Model for End-Stage Liver Disease (MELD) has been used to rank liver transplant candidates since 2002, and at the time bringing much needed objectivity to the liver allocation process. However, and despite numerous revisions to the MELD score, current liver allocation still does not allow for equitable access to all waitlisted liver candidates.Recent findingsAn optimized prediction of mortality (OPOM) was developed utilizing novel machine-learning optimal classification tree models trained to predict a liver candidate's 3-month waitlist mortality or removal. When compared to MELD and MELD-Na, OPOM more accurately and objectively prioritized candidates for liver transplantation based on disease severity. In simulation analysis, OPOM allowed for more equitable allocation of livers with a resultant significant number of additional lives saved every year when compared with MELD-based allocation.SummaryMachine learning technology holds the potential to help guide transplant clinical practice, and thus potentially guide national organ allocation policy.",
        "DOI": "10.1097/MOT.0000000000000734",
        "paper_author": "Vagefi P.A.",
        "affiliation_name": "UT Southwestern Medical Center",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States",
        "affiliation_id": "60026695",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "The Challenge of Pairing Big Datasets: Probabilistic Record Linkage Methods and Diagnosis of Their Empirical Viability",
        "publication": "Journal of Business Cycle Research",
        "citied_by": "0",
        "cover_date": "2020-04-01",
        "Abstract": "In this paper, we evaluated the predictive performance of probabilistic record linkage algorithms, discussing the implications of different configurations of blocking keys, string similarity functions and phonetic code on the prediction’s overall performance and computational complexity. Furthermore, we carried out a bibliographical survey of the main deterministic and probabilistic record linkage methods, as well as of recent advances combining machine learning techniques and main packages and implementations available in open-source R language. The results can provide heuristics for problems of administrative records integration at the national level and have potential value for the formulation and evaluation of public policies.",
        "DOI": "10.1007/s41549-020-00043-1",
        "paper_author": "Peng Y.",
        "affiliation_name": "Brazilian Secretariat for Economic Policy",
        "affiliation_city": "Brasilia",
        "affiliation_country": "Brazil",
        "affiliation_id": "124082409",
        "affiliation_state": "DF"
    },
    {
        "paper_title": "Learning to Walk a Tripod Mobile Robot Using Nonlinear Soft Vibration Actuators with Entropy Adaptive Reinforcement Learning",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "23",
        "cover_date": "2020-04-01",
        "Abstract": "Soft mobile robots have shown great potential in unstructured and confined environments by taking advantage of their excellent adaptability and high dexterity. However, there are several issues to be addressed, such as actuating speeds and controllability, in soft robots. In this letter, a new vibration actuator is proposed using the nonlinear stiffness characteristic of a hyperelastic material, which creates continuous vibration of the actuator. By integrating three proposed actuators, we also present an advanced soft mobile robot with high degrees of freedom of movement. However, since the dynamic model of the soft mobile robot is generally hard to obtain(intractable), it is difficult to design a controller for the robot. In this regard, we present a method to train a controller, using a novel reinforcement learning (RL) algorithm called adaptive soft actor-critic (ASAC). ASAC gradually reduces a parameter called an entropy temperature, which regulates the entropy of the control policy. In this way, the proposed method can narrow down the search space during training, and reduce the duration of demanding data collection processes in real-world experiments. For the verification of the robustness and the controllability of our robot and the RL algorithm, experiments for zig-zagging path tracking and obstacle avoidance were conducted, and the robot successfully finished the missions with only an hour of training time.",
        "DOI": "10.1109/LRA.2020.2970945",
        "paper_author": "Kim J.I.",
        "affiliation_name": "Institute of Advanced Machines and Design",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60120123",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Rigid-soft interactive learning for robust grasping",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "17",
        "cover_date": "2020-04-01",
        "Abstract": "Robot learning is widely accepted by academia and industry with its potentials to transform autonomous robot control through machine learning. Inspired by widely used soft fingers on grasping, we propose a method of rigid-soft interactive learning, aiming at reducing the time of data collection. In this letter, we classify the interaction categories into Rigid-Rigid, Rigid-Soft, Soft-Rigid according to the interaction surface between grippers and target objects. We find experimental evidence that the interaction types between grippers and target objects play an essential role in the learning methods. We use soft, stuffed toys for training, instead of everyday objects, to reduce the integration complexity and computational burden. Although the stuffed toys are limited in reflecting the physics of finger-object interaction in real-life scenarios, we exploit such rigid-soft interaction by changing the gripper fingers to the soft ones when dealing with rigid, daily-life items such as the Yale-CMU-Berkeley (YCB) objects. With a small data collection of 5 K picking attempts in total, our results suggest that such Rigid-Soft and Soft-Rigid interactions are transferable. Moreover, the combination of such interactions shows better performance on the grasping test. We also explore the effect of the grasp type on the learning method by changing the gripper configurations. We achieve the best grasping performance at 97.5% for easy YCB objects and 81.3% for difficult YCB objects while using a precise grasp with a two-soft-finger gripper to collect training data and power grasp with a four-soft-finger gripper to test the grasp policy.",
        "DOI": "10.1109/LRA.2020.2969932",
        "paper_author": "Yang L.",
        "affiliation_name": "Southern University of Science and Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60105683",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Big data and data processing in rheumatology: bioethical perspectives",
        "publication": "Clinical Rheumatology",
        "citied_by": "24",
        "cover_date": "2020-04-01",
        "Abstract": "Big data analytics and processing through artificial intelligence (AI) are increasingly being used in the health sector. This includes both clinical and research settings, and newly in specialties like rheumatology. It is, however, important to consider how these new methodologies are used, and particularly the sensitivities associated with personal information. Based on current applications in rheumatology, this article provides a narrative review of the bioethical perspectives of big data. It presents examples of databases, data analytic methods, and AI in this specialty to address four main ethical issues: privacy and confidentiality, informed consent, the impact on the medical profession, and justice. The use of big data and AI processing in healthcare has great potential to improve the quality of clinical care, including through better diagnosis, treatment, and prognosis. They may also increase patient and societal participation and engagement in healthcare and research. Developing these methodologies and using the information generated from them in line with ethical standards could positively affect the design of global health policies and introduce a new phase in the democratization of health.Key Points• Current applications of big data, data analytics, and AI in rheumatology—including registries, machine learning algorithms, and consumer-facing platforms—raise issues in four main bioethical areas: privacy and confidentiality, informed consent, the impact on the medical profession, and justice.• Bioethical concerns about rheumatology registries require careful consideration of privacy provisions, set within the context of local, national, and regional law.• Machine learning and big data aid diagnosis, treatment, and prognosis, but the final decision about the use of information from algorithms should be left to rheumatology specialists to maintain the promise of fiduciary obligations in the physician–patient relationship.• International collaboration in big data projects and increased patient engagement could be ways to counteract health inequalities in the practice of rheumatology, even on a global scale.",
        "DOI": "10.1007/s10067-020-04969-w",
        "paper_author": "Manrique de Lara A.",
        "affiliation_name": "Universidad Nacional Autónoma de México",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico",
        "affiliation_id": "60032442",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Online Convex Optimization for Caching Networks",
        "publication": "IEEE/ACM Transactions on Networking",
        "citied_by": "25",
        "cover_date": "2020-04-01",
        "Abstract": "We study the problem of wireless edge caching when file popularity is unknown and possibly non-stationary. A bank of $J$ caches receives file requests and a utility is accrued for each request depending on the serving cache. The network decides dynamically which files to store at each cache and how to route them, in order to maximize total utility. The request sequence is assumed to be drawn from an arbitrary distribution, capturing time-variance, temporal and spatial locality of requests. For this challenging setting, we propose the Bipartite Supergradient Caching Algorithm (BSCA) which provably exhibits no regret ( $R_{T}/T \\to 0$ ). That is, as the time horizon $T$ increases, BSCA achieves (at least) the same utility with the cache configuration that we would have chosen knowing all future requests. The learning rate of the algorithm is characterized by its regret expression $R_{T}\\!=\\!O(\\sqrt {JT})$ , which is independent of the file library size. For the single-cache case, we prove that this is the lowest attainable bound. BSCA requires at each step $J$ projections on intersections of boxes and simplices, for which we propose a tailored algorithm. Our model is the first that draws a connection between the network caching problem and Online Convex Optimization, and we demonstrate its generality by discussing various practical extensions and presenting a trace-driven comparison with state-of-the-art competitors.",
        "DOI": "10.1109/TNET.2020.2968424",
        "paper_author": "Paschos G.S.",
        "affiliation_name": "Amazon.com, Inc.",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States",
        "affiliation_id": "60076757",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "A Probabilistic Model-Based Online Learning Optimal Control Algorithm for Soft Pneumatic Actuators",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "24",
        "cover_date": "2020-04-01",
        "Abstract": "Soft robots are increasingly being employed in different fields and various designs are created to satisfy relevant requirements. The wide ranges of design bring challenges to soft robotic control in that a unified control framework is difficult to derive. Traditional model-driven approaches for soft robots are usually design-specific which highly depend on specific design structures. Our approach to such challenges involves a probabilistic model that learns a mapping from the soft actuator states and controls to the next states. Then an optimal control policy is derived by minimizing a cost function based on the probabilistic model. We demonstrate the efficiency of our approach through simulations with parameter analysis and real-robot experiments involving three different designs of soft pneumatic actuators. Comparisons with previous model-based controllers are also provided to show advantages of the proposed method. Overall, this work provides a promising design-independent control approach for the soft robotics community.",
        "DOI": "10.1109/LRA.2020.2967293",
        "paper_author": "Tang Z.Q.",
        "affiliation_name": "Chinese University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60002798",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Technological advances in field studies of pollinator ecology and the future of e-ecology",
        "publication": "Current Opinion in Insect Science",
        "citied_by": "36",
        "cover_date": "2020-04-01",
        "Abstract": "Our review looks at recent advances in technologies applied to studying pollinators in the field. These include RFID, radar and lidar for detecting and tracking pollinators; wireless sensor networks (e.g. ‘smart’ hives); automated visual and audio monitoring systems including vision motion software for monitoring fine-scale pollinator behaviours over extended periods; and automated species identification systems based on machine learning that can vastly reduce the bottleneck in (big) data analysis. An improved e-ecology platform that leverages these tools is needed for ecologists to acquire and understand large spatiotemporal datasets, and thus inform knowledge gaps in environmental policy-making. Developing the next generation of e-ecology tools will require synergistic partnerships between academia and industry and significant investment in a cross-disciplinary scientific consortia.",
        "DOI": "10.1016/j.cois.2020.01.008",
        "paper_author": "Barlow S.E.",
        "affiliation_name": "The University of Utah",
        "affiliation_city": "Salt Lake City",
        "affiliation_country": "United States",
        "affiliation_id": "60025488",
        "affiliation_state": "UT"
    },
    {
        "paper_title": "A review on renewable energy and electricity requirement forecasting models for smart grid and buildings",
        "publication": "Sustainable Cities and Society",
        "citied_by": "354",
        "cover_date": "2020-04-01",
        "Abstract": "The benefits of renewable energy are that it is sustainable and is low in environmental pollution. Growing load requirement, global warming, and energy crisis need energy-intensive management to give sincere attempts to promote high accuracy energy monitoring techniques in order to enhance energy system efficiency and performance. The energy consumption data of domestic, commercial and industrial are becoming accessible to estimate the notable share of various sectors in the energy market. Energy forecasting algorithms play a vital role in energy sector development and policy formulation. Energy prediction and power supply management are the key roots of energy planning. A large number of prediction models have been used in the recent past. The selection of a prediction model usually based on available data, the objectives of the model network mechanism and energy planning operation. In this review, we conduct a critical and systematic review of renewable energy and electricity prediction models applied as an energy planning tool. The forecasting intervals is divided into three sections including: i) short-term; ii) medium-term; iii) and long-term. Three renewable energy resources, i.e. wind, solar, and geothermal energy, and electricity load demand requirement are considered for review forecasting analysis. Three major states-of-art forecasting classifications: i) machine learning algorithms; ii) ensemble-based approaches; iii) and artificial neural networks are analyzed. These approaches are investigated for prediction applicability; accuracy for spatial and temporal forecasting; and relevance to policy and planning objectives. The machine learning models can handle large amount of data with accurate forecasting analysis. Applying ensemble techniques enables us to obtain higher forecasting accuracy by combining different models. Artificial neural networks if used in the right way can contribute a robust choice, given that it is capible to extract and model unseen relationships and features. Furthermore, unlike these conventional techniques, artificial neural networks do not force any limitation on residual and input distributions. Findings from this review would help professionals and researchers in obtaining recognition of the prediction approaches and allow them to choose the relevant methods to satisfy their desired tasks and forecasting requirements.",
        "DOI": "10.1016/j.scs.2020.102052",
        "paper_author": "Ahmad T.",
        "affiliation_name": "State Key Laboratory of Internet of Things for Smart City",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao",
        "affiliation_id": "60202520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A novel policy gradient algorithm with PSO-based parameter exploration for continuous control",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "13",
        "cover_date": "2020-04-01",
        "Abstract": "Continuous control has attracted enormous attention due to its essential role in real-world applications. However, it is considerably difficult to be addressed through explicitly modeling in practice. As promising approaches, model-free policy gradient (PG) based methods in reinforcement learning (RL), however, suffer from slow convergence and complex computation owing to the high variance of gradient estimating and sophisticated backpropagation. Therefore, in this paper, a gradient-free policy gradient algorithm with PSO-based parameter exploration (PG-PSOPE) is proposed for continuous control tasks. To reduce variance and improve convergence rate, the PSO is combined with PG to provide a novel way for training policy network in RL. Experimental results of simulated physical control tasks verify the effectiveness of the proposed algorithm. Besides, the PG-PSOPE is superior in both convergence speed and final performance to the typical on-policy PG and the off-policy deep RL method. Furthermore, the PG-PSOPE exhibits the simplicity and high effectiveness by comparison of training time under different tasks, and its running time is reduced by 58 times compared with other gradient-based methods for the best case.",
        "DOI": "10.1016/j.engappai.2020.103525",
        "paper_author": "Liu T.",
        "affiliation_name": "Xiamen University",
        "affiliation_city": "Xiamen",
        "affiliation_country": "China",
        "affiliation_id": "60018205",
        "affiliation_state": "Fujian"
    },
    {
        "paper_title": "Constrained-Space Optimization and Reinforcement Learning for Complex Tasks",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "12",
        "cover_date": "2020-04-01",
        "Abstract": "Learning from demonstration is increasingly used for transferring operator manipulation skills to robots. In practice, it is important to cater for limited data and imperfect human demonstrations, as well as underlying safety constraints. This article presents a constrained-space optimization and reinforcement learning scheme for managing complex tasks. Through interactions within the constrained space, the reinforcement learning agent is trained to optimize the manipulation skills according to a defined reward function. After learning, the optimal policy is derived from the well-trained reinforcement learning agent, which is then implemented to guide the robot to conduct tasks that are similar to the experts' demonstrations. The effectiveness of the proposed method is verified with a robotic suturing task, demonstrating that the learned policy outperformed the experts' demonstrations in terms of the smoothness of the joint motion and end-effector trajectories, as well as the overall task completion time.",
        "DOI": "10.1109/LRA.2020.2965392",
        "paper_author": "Tsai Y.Y.",
        "affiliation_name": "Hamlyn Centre for Robotic Surgery",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "112455423",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Advising reinforcement learning toward scaling agents in continuous control environments with sparse rewards",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "6",
        "cover_date": "2020-04-01",
        "Abstract": "This paper adapts the success of the teacher–student framework for reinforcement learning to a continuous control environment with sparse rewards. Furthermore, the proposed advising framework is designed for the scaling agents problem, wherein the student policy is trained to control multiple agents while the teacher policy is well trained for a single agent. Existing research on teacher–student frameworks have been focused on discrete control domain. Moreover, they rely on similar target and source environments and as such they do not allow for scaling the agents. On the other hand, in this work the agents face a scaling agents problem where the value functions of the source and target task converge at different rates. Existing concepts from the teacher–student framework are adapted to meet new challenges including early advising, importance of advising, and mistake correction, but a modified heuristic was used to decide on when to teach. The performance of the proposed algorithm was evaluated using the case study of pushing, and picking and placing objects with a dual arm manipulation system. The teacher policy was trained using a simulated scenario consisting of a single arm. The student policy was trained to handle the dual arm manipulation system in simulation under the advice of the teacher agent. The trained student policy was then validated using two Quanser Mico arms for experimental demonstration. The effects of varying parameters on the student performance in the advising framework was also analyzed and discussed. The results showed that the proposed advising framework expedited the training process and achieved the desired scaling within a limited advising budget.",
        "DOI": "10.1016/j.engappai.2020.103515",
        "paper_author": "Ren H.",
        "affiliation_name": "Virginia Tech College of Engineering",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States",
        "affiliation_id": "60157272",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Reinforcement learning for angle-only intercept guidance of maneuvering targets",
        "publication": "Aerospace Science and Technology",
        "citied_by": "120",
        "cover_date": "2020-04-01",
        "Abstract": "We present a novel guidance law that uses observations consisting solely of seeker line-of-sight angle measurements and their rate of change. The policy is optimized using reinforcement meta-learning and demonstrated in a simulated terminal phase of a mid-course exo-atmospheric interception. Importantly, the guidance law does not require range estimation, making it particularly suitable for passive seekers. The optimized policy maps stabilized seeker line-of-sight angles and their rate of change directly to commanded thrust for the missile's divert thrusters. Optimization with reinforcement meta-learning allows the optimized policy to adapt to target acceleration, and we demonstrate that the policy performs better than augmented zero-effort miss guidance with perfect target acceleration knowledge. The optimized policy is computationally efficient and requires minimal memory, and should be compatible with today's flight processors.",
        "DOI": "10.1016/j.ast.2020.105746",
        "paper_author": "Gaudet B.",
        "affiliation_name": "The University of Arizona College of Engineering",
        "affiliation_city": "Tucson",
        "affiliation_country": "United States",
        "affiliation_id": "60149993",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Deep reinforcement learning for six degree-of-freedom planetary landing",
        "publication": "Advances in Space Research",
        "citied_by": "157",
        "cover_date": "2020-04-01",
        "Abstract": "This work develops a deep reinforcement learning based approach for Six Degree-of-Freedom (DOF) planetary powered descent and landing. Future Mars missions will require advanced guidance, navigation, and control algorithms for the powered descent phase to target specific surface locations and achieve pinpoint accuracy (landing error ellipse <5 m radius). This requires both a navigation system capable of estimating the lander's state in real-time and a guidance and control system that can map the estimated lander state to a commanded thrust for each lander engine. In this paper, we present a novel integrated guidance and control algorithm designed by applying the principles of reinforcement learning theory. The latter is used to learn a policy mapping the lander's estimated state directly to a commanded thrust for each engine, resulting in accurate and almost fuel-optimal trajectories over a realistic deployment ellipse. Specifically, we use proximal policy optimization, a policy gradient method, to learn the policy. Another contribution of this paper is the use of different discount rates for terminal and shaping rewards, which significantly enhances optimization performance. We present simulation results demonstrating the guidance and control system's performance in a 6-DOF simulation environment and demonstrate robustness to noise and system parameter uncertainty.",
        "DOI": "10.1016/j.asr.2019.12.030",
        "paper_author": "Gaudet B.",
        "affiliation_name": "The University of Arizona College of Engineering",
        "affiliation_city": "Tucson",
        "affiliation_country": "United States",
        "affiliation_id": "60149993",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Machine learning solutions to challenges in finance: An application to the pricing of financial products",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "64",
        "cover_date": "2020-04-01",
        "Abstract": "The recent fast development of machine learning provides new tools to solve challenges in many areas. In finance, average options are popular financial products among corporations, institutional investors, and individual investors for risk management and investment because average options have the advantages of cheap prices and their payoffs are not very sensitive to the changes of the underlying asset prices at the maturity date, avoiding the manipulation of asset prices and option prices. The challenge is that pricing arithmetic average options requires traditional numerical methods with the drawbacks of expensive repetitive computations and non-realistic model assumptions. This paper proposes a machine-learning method to price arithmetic and geometric average options accurately and in particular quickly. The method is model-free and it is verified by empirical applications as well as numerical experiments.",
        "DOI": "10.1016/j.techfore.2020.119928",
        "paper_author": "Gan L.",
        "affiliation_name": "Southern University of Science and Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60105683",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Artificial intelligence in the AEC industry: Scientometric analysis and visualization of research activities",
        "publication": "Automation in Construction",
        "citied_by": "391",
        "cover_date": "2020-04-01",
        "Abstract": "The Architecture, Engineering and Construction (AEC) industry is fraught with complex and difficult problems. Artificial intelligence (AI) represents a powerful tool to assist in addressing these problems. Therefore, over the years, researchers have been conducting research on AI in the AEC industry (AI-in-the-AECI). In this paper, the first comprehensive scientometric study appraising the state-of-the-art of research on AI-in-the-AECI is presented. The science mapping method was used to systematically and quantitatively analyze 41,827 related bibliographic records retrieved from Scopus. The results indicated that genetic algorithms, neural networks, fuzzy logic, fuzzy sets, and machine learning have been the most widely used AI methods in AEC. Optimization, simulation, uncertainty, project management, and bridges have been the most commonly addressed topics/issues using AI methods/concepts. The primary value and uniqueness of this study lies in it being the first in providing an up-to-date inclusive, big picture of the literature on AI-in-the-AECI. This study adds value to the AEC literature through visualizing and understanding trends and patterns, identifying main research interests, journals, institutions, and countries, and how these are linked within now-available studies on AI-in-the-AECI. The findings bring to light the deficiencies in the current research and provide paths for future research, where they indicated that future research opportunities lie in applying robotic automation and convolutional neural networks to AEC problems. For the world of practice, the study offers a readily-available point of reference for practitioners, policy makers, and research and development (R&D) bodies. This study therefore raises the level of awareness of AI and facilitates building the intellectual wealth of the AI area in the AEC industry.",
        "DOI": "10.1016/j.autcon.2020.103081",
        "paper_author": "Darko A.",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008928",
        "affiliation_state": "Hong Kong"
    },
    {
        "paper_title": "Energy-aware resource management for uplink non-orthogonal multiple access: Multi-agent deep reinforcement learning",
        "publication": "Future Generation Computer Systems",
        "citied_by": "5",
        "cover_date": "2020-04-01",
        "Abstract": "Non-orthogonal multiple access (NOMA) is one of the promising technologies to meet the huge access demand and the high data rate requirements of the next generation networks. In this paper, we investigate the joint subchannel assignment and power allocation problem in an uplink multi-user NOMA system to maximize the energy efficiency (EE) while ensuring the quality-of-service (QoS) of all users. Different from conventional model-based resource allocation methods, we propose two deep reinforcement learning (DRL) based frameworks to solve this non-convex and dynamic optimization problem, referred to as discrete DRL based resource allocation (DDRA) framework and continuous DRL based resource allocation (CDRA) framework. Specifically, for the DDRA framework, we use a deep Q network (DQN) to output the optimum subchannel assignment policy, and design a distributed and discretized multi-DQN based network to allocate the corresponding transmit power of all users. For the CDRA framework, we design a joint DQN and deep deterministic policy gradient (DDPG) based network to generate the optimal subchannel assignment and power allocation policy. The entire resource allocation policies of these two frameworks are adjusted by updating the weights of their neural networks according to feedback of the system. Numerical results show that the proposed DRL-based resource allocation frameworks can significantly improve the EE of the whole NOMA system compared with other approaches. The proposed DRL based frameworks can provide good performance in various moving speed scenarios through adjusting learning parameters.",
        "DOI": "10.1016/j.future.2019.12.047",
        "paper_author": "Li Y.",
        "affiliation_name": "Honghe University",
        "affiliation_city": "Mengzi",
        "affiliation_country": "China",
        "affiliation_id": "60087292",
        "affiliation_state": "Yunnan"
    },
    {
        "paper_title": "Increment-averaged kriging: a comparison with depth-harmonized mapping of soil exchangeable sodium percentage in a cropping region of eastern Australia",
        "publication": "Geoderma",
        "citied_by": "5",
        "cover_date": "2020-04-01",
        "Abstract": "Soil sodicity, generally measured through the exchangeable sodium percentage (ESP), is the most prevalent edaphic stress in Australia, particularly in the northern grains-growing region (NGR) of Australia. Farmers, scientists and policy-makers need accurate maps of sodicity for environmental modelling, and to make rational decisions for management. A common approach to mapping soil properties for multiple target depths is to first harmonize soil profile data to the target depth intervals, usually through equal-area spline functions, then undertake a two-dimensional spatial analysis (often regression kriging) for each interval; we refer to this as a ‘spline-then-krige’ (STK) approach. An alternative is to calibrate a single three-dimensional model that describes soil variation both horizontally and vertically, as is done in the increment-averaged kriging (IAK) approach. This study compares IAK and STK for mapping ESP in the NGR. A machine-learning algorithm was used to model trends based on environmental covariates in both approaches. Both IAK and STK captured the ESP variation reasonably well (concordance correlation coefficient values for IAK around 0.5 for all depths), with IAK giving slightly better predictive accuracies for all depths, most evidently in the topsoil. IAK allows the natural use of all available data, explicitly accounts for the sample support of the soil data and the horizontal and vertical auto-correlation between and within soil profiles, and enables the propagation of uncertainty from the original data through to the final predictions and prediction uncertainties. We conclude that IAK can provide a competitive alternative to STK approaches for mapping soil properties in three dimensions.",
        "DOI": "10.1016/j.geoderma.2019.114151",
        "paper_author": "Lai Y.R.",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60031004",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Can donor narratives yield insights? A natural language processing proof of concept to facilitate kidney allocation",
        "publication": "American Journal of Transplantation",
        "citied_by": "9",
        "cover_date": "2020-04-01",
        "Abstract": "Although expedited placement could ameliorate stagnant kidney utilization, precisely identifying difficult-to-place organs is crucial to mitigate potential harms associated with this policy. Existing algorithms have only leveraged structured data from the Organ Procurement and Transplantation Network (OPTN); however, detailed, free text case information about a donor exists. No known research exists about the utility of these data. We developed a model to predict the probability of delay or discard for adult deceased kidney donors between 2010 and 2018, leveraging donor free text data. The resultant model had a c-statistic of 0.75 compared to 0.80 (Reduced Probability of Delay or Discard [model], r-PODD) and 0.77 (Kidney Donor Profile Index, KDPI) on the test dataset. Analysis of the top predictive words suggest both known and potentially novel clinical factors (ie, a known factor such as hypertension vs a novel factor such as stents), and nuanced social factors (intravenous drug use) could negatively affect kidney utilization. These findings suggest that donor narratives have utility; the natural language processing (NLP) model is only moderately correlated with existing indices and provides directional evidence about additional cardiovascular risk factors that may affect kidney utilization. More research is needed to understand the potential to enhance existing indices of kidney utilization to better enable and mitigate the effects of policy interventions such as expedited placement.",
        "DOI": "10.1111/ajt.15705",
        "paper_author": "Placona A.M.",
        "affiliation_name": "United Network for Organ Sharing",
        "affiliation_city": "Richmond",
        "affiliation_country": "United States",
        "affiliation_id": "60026342",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Flash-flood hazard assessment using ensembles and Bayesian-based machine learning models: Application of the simulated annealing feature selection method",
        "publication": "Science of the Total Environment",
        "citied_by": "259",
        "cover_date": "2020-04-01",
        "Abstract": "Flash-floods are increasingly recognized as a frequent natural hazard worldwide. Iran has been among the most devastated regions affected by the major floods. While the temporal flash-flood forecasting models are mainly developed for warning systems, the models for assessing hazardous areas can greatly contribute to adaptation and mitigation policy-making and disaster risk reduction. Former researches in the flash-flood hazard mapping have heightened the urge for the advancement of more accurate models. Thus, the current research proposes the state-of-the-art ensemble models of boosted generalized linear model (GLMBoost) and random forest (RF), and Bayesian generalized linear model (BayesGLM) methods for higher performance modeling. Furthermore, a pre-processing method, namely simulated annealing (SA), is used to eliminate redundant variables from the modeling process. Results of the modeling based on the hit and miss analysis indicates high performance for both models (accuracy = 90–92%, Kappa = 79–84%, Success ratio = 94–96%, Threat score = 80–84%, and Heidke skill score = 79–84%). The variables of distance from the stream, vegetation, drainage density, land use, and elevation have shown more contribution among others for modeling the flash-flood. The results of this study can significantly facilitate mapping the hazardous areas and further assist watershed managers to control and remediate induced damages of flood in the data-scarce regions.",
        "DOI": "10.1016/j.scitotenv.2019.135161",
        "paper_author": "Hosseini F.S.",
        "affiliation_name": "University of Tehran",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60022927",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Small-scale moving target detection in aerial image by deep inverse reinforcement learning",
        "publication": "Soft Computing",
        "citied_by": "15",
        "cover_date": "2020-04-01",
        "Abstract": "It proposes a deep inverse reinforcement learning method for slow and weak moving targets detection in aerial video. Differential gray images of adjacent frames are used as the network model input, and the feature network layer extracts the candidate moving target regions through the multi-layer convolution. The candidate target information is used as the initial layer of the policy network. The expert trajectory is used to adjust and optimize the feature convolution network model and the policy fully connected network model to realize the training the reward return function and the expert policy. In the stage of autonomous improvement policy, the policy model is re-optimized by unmarked aerial video, and deep inverse reinforcement learning and nonlinear policy network are used to make decision on moving target position and size information. The target size of the multi-group aerial video test set is 10 * 10 pixels. Experimental results show that the proposed algorithm has the advantage of the nonlinear policy of the neural network compared with the traditional moving target detection algorithm, and the detection result is more accurate. At the same time, compared with the traditional marginal programming (MMP) method and the structured classification based (SCIRL) method, the proposed algorithm shows obvious advantages in the accuracy of aerial video moving target detection.",
        "DOI": "10.1007/s00500-019-04404-6",
        "paper_author": "Sun W.",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60025578",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Reward-driven U-Net training for obstacle avoidance drone",
        "publication": "Expert Systems with Applications",
        "citied_by": "33",
        "cover_date": "2020-04-01",
        "Abstract": "Along with the fast progress in deep learning, an autonomous drone with obstacle avoidance capability has been studied mainly by two machine learning paradigms, i.e. supervised learning, and reinforcement learning. The former has some advantages since the trained network is light and fast, but it needs a large amount of data that requires laborious manual labeling. With the latter, such a drawback can be overcome as an agent learns by itself in a simulated environment, although the gap between the real and simulated one has to be minimized in the end. This study proposes a new framework where a supervised segmentation network is trained with labels made by an actor-critic network in a reward-driven manner, wherein this U-Net based network infers the next moving direction from the sequence of input images. For the actor-critic part, several recent policy gradient algorithms have been tested for controlling the drone with the continuous action space. After training in the Airsim simulation environment, the model is transferred to a Bebop drone flying in the real environment, built as a reconfigurable maze using panels and a hoop. The result suggests that our network enables the drone to navigate through the obstacles using only monocular RGB input in the trained environment as well as in the reconfigured ones without retraining.",
        "DOI": "10.1016/j.eswa.2019.113064",
        "paper_author": "Shin S.Y.",
        "affiliation_name": "Sejong University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60027884",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement learning based on movement primitives for contact tasks",
        "publication": "Robotics and Computer-Integrated Manufacturing",
        "citied_by": "41",
        "cover_date": "2020-04-01",
        "Abstract": "Recently, robot learning through deep reinforcement learning has incorporated various robot tasks through deep neural networks, without using specific control or recognition algorithms. However, this learning method is difficult to apply to the contact tasks of a robot, due to the exertion of excessive force from the random search process of reinforcement learning. Therefore, when applying reinforcement learning to contact tasks, solving the contact problem using an existing force controller is necessary. A neural-network-based movement primitive (NNMP) that generates a continuous trajectory which can be transmitted to the force controller and learned through a deep deterministic policy gradient (DDPG) algorithm is proposed for this study. In addition, an imitation learning algorithm suitable for NNMP is proposed such that the trajectories similar to the demonstration trajectory are stably generated. The performance of the proposed algorithms was verified using a square peg-in-hole assembly task with a tolerance of 0.1 mm. The results confirm that the complicated assembly trajectory can be learned stably through NNMP by the proposed imitation learning algorithm, and that the assembly trajectory is improved by learning the proposed NNMP through the DDPG algorithm.",
        "DOI": "10.1016/j.rcim.2019.101863",
        "paper_author": "Kim Y.L.",
        "affiliation_name": "Korea University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60005273",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data-driven historical preservation: a case study in Shanghai",
        "publication": "Neural Computing and Applications",
        "citied_by": "3",
        "cover_date": "2020-04-01",
        "Abstract": "Historical preservation is becoming ever important in globalizing Shanghai city. However, traditional survey-based ways of policy making are not efficient. This work introduces the data-driven technique with machine learning algorithm to find the relationship between the features of the historical sites and the popularity, which relates to the economy such as tourism and the associated GDP contribution. The method is automatic, which relieves the work load from statistical surveys and other inefficient traditional approaches. Moreover, while the surveys can only reflect the current conditions, the machine learning approach has the ability of predicting the possible outcomes based on existing data, which is helpful when decisions on protection and development are to be made. We collect data from selected historical sites in Shanghai to illustrate the procedure of the proposed data-driven approach. The case study demonstrates the capability of prediction and shows its promising future in guiding policy making, resource allocation and scientific research.",
        "DOI": "10.1007/s00521-018-3710-z",
        "paper_author": "Wei Z.",
        "affiliation_name": "Shanghai University of Engineering Science",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60032504",
        "affiliation_state": "Shanghai"
    },
    {
        "paper_title": "Big data analytics: Computational intelligence techniques and application areas",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "171",
        "cover_date": "2020-04-01",
        "Abstract": "Big Data has significant impact in developing functional smart cities and supporting modern societies. In this paper, we investigate the importance of Big Data in modern life and economy, and discuss challenges arising from Big Data utilization. Different computational intelligence techniques have been considered as tools for Big Data analytics. We also explore the powerful combination of Big Data and Computational Intelligence (CI) and identify a number of areas, where novel applications in real world smart city problems can be developed by utilizing these powerful tools and techniques. We present a case study for intelligent transportation in the context of a smart city, and a novel data modelling methodology based on a biologically inspired universal generative modelling approach called Hierarchical Spatial-Temporal State Machine (HSTSM). We further discuss various implications of policy, protection, valuation and commercialization related to Big Data, its applications and deployment.",
        "DOI": "10.1016/j.techfore.2018.03.024",
        "paper_author": "Iqbal R.",
        "affiliation_name": "Coventry University",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60017326",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "A Dynamic and Failure-Aware Task Scheduling Framework for Hadoop",
        "publication": "IEEE Transactions on Cloud Computing",
        "citied_by": "34",
        "cover_date": "2020-04-01",
        "Abstract": "Hadoop has become a popular framework for processing data-intensive applications in cloud environments. A core constituent of Hadoop is the scheduler, which is responsible for scheduling and monitoring the jobs and tasks, and rescheduling them in case of failures. Although fault-tolerance mechanisms have been proposed for Hadoop, the performance of Hadoop can be significantly impacted by unforeseen events in the cloud environment. In this paper, we introduce a dynamic and failure-aware framework that can be integrated within Hadoop scheduler and adjust the scheduling decisions based on collected information about the cloud environment. Our framework relies on predictions made by machine learning algorithms and scheduling policies generated by a Markovian Decision Process (MDP), to adjust its scheduling decisions on the fly. Instead of the fixed heartbeat-based failure detection commonly used in Hadoop to track active TaskTrackers (i.e., nodes that process the scheduled tasks), our proposed framework implements an adaptive algorithm that can dynamically detect the failures of the TaskTracker. To deploy our proposed framework, we have built, ATLAS+, an AdapTive Failure-Aware Scheduler for Hadoop. To assess the performance of ATLAS+, we conduct a large empirical study on a 100-node Hadoop cluster deployed on Amazon Elastic MapReduce (EMR), comparing the performance of ATLAS+ with those of three Hadoop schedulers (FIFO, Fair, and Capacity). Results show that ATLAS+ outperforms FIFO, Fair, and Capacity schedulers. ATLAS+ can reduce the number of failed jobs by up to 43 percent and the number of failed tasks by up to 59 percent. On average, ATLAS+ could reduce the total execution time of jobs by 10 minutes, which represents 40 percent of the job execution times, and by up to 3 minutes for tasks, which represents 47 percent of the task execution time. ATLAS+ also reduced CPU and memory usage by 22 and 20 percent, respectively.",
        "DOI": "10.1109/TCC.2018.2805812",
        "paper_author": "Soualhia M.",
        "affiliation_name": "Concordia University",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60033154",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Household wealth proxies for socio-economic inequality policy studies in China",
        "publication": "Data and Policy",
        "citied_by": "3",
        "cover_date": "2020-03-30",
        "Abstract": "In China, one percent of the richest population holds more than one-third of the wealth, while the poorest 25% shares no more than two percent of the total. The country's rapid economic development has resulted in increasing socio-economic disparities, and a rapidly deteriorating environment. This puts the Chinese citizens, especially the most vulnerable and deprived socio-economic status (SES) groups, at high risks of environmental inequality (EI). In most SES-based EI studies conducted in China, household wealth has often been overlooked, though it potentially serves a good economic indicator to capture the socio-economic effect of environmental change in China. Nevertheless, existing SES databases in China are of low spatial resolution and are insufficient to support fine-grained EI studies at the intra-city level in China. The core research challenge is to develop a representative household wealth proxy in high-spatial resolution for China. This study highlights the research gaps and proposes a new household wealth proxy, which integrates both fine-grained data/features such as daytime satellite imagery and easily accessible wealth indicators such as house prices. We also capitalize on everyday economic activity data retrieved from personal mobile phones and online transaction/social platforms in the composition of our wealth proxy to achieve a higher accuracy in estimating household wealth at fine-grained resolution via machine learning. Finally, we summarize the challenges in improving both the quality and the availability of Chinese socio-economic datasets, while protecting personal privacy and information security during the data collection process for household wealth proxy development in China.",
        "DOI": "10.1017/dap.2020.4",
        "paper_author": "Lam J.C.K.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Using task descriptions in lifelong machine learning for improved performance and zero-shot transfer",
        "publication": "Journal of Artificial Intelligence Research",
        "citied_by": "25",
        "cover_date": "2020-03-29",
        "Abstract": "Knowledge transfer between tasks can improve the performance of learned models, but requires an accurate estimate of inter-task relationships to identify the relevant knowledge to transfer. These inter-task relationships are typically estimated based on training data for each task, which is inefficient in lifelong learning settings where the goal is to learn each consecutive task rapidly from as little data as possible. To reduce this burden, we develop a lifelong learning method based on coupled dictionary learning that utilizes high-level task descriptions to model inter-task relationships. We show that using task descriptors improves the performance of the learned task policies, providing both theoretical justification for the benefit and empirical demonstration of the improvement across a variety of learning problems. Given only the descriptor for a new task, the lifelong learner is also able to accurately predict a model for the new task through zero-shot learning using the coupled dictionary, eliminating the need to gather training data before addressing the task.",
        "DOI": "10.1613/JAIR.1.11304",
        "paper_author": "Rostami M.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60006297",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Deep Reinforcement Learning for Visual Navigation of Wheeled Mobile Robots",
        "publication": "Conference Proceedings - IEEE SOUTHEASTCON",
        "citied_by": "6",
        "cover_date": "2020-03-28",
        "Abstract": "A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic (A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",
        "DOI": "10.1109/SoutheastCon44009.2020.9249654",
        "paper_author": "Nwaonumah E.",
        "affiliation_name": "Georgia Southern University",
        "affiliation_city": "Statesboro",
        "affiliation_country": "United States",
        "affiliation_id": "60020059",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Computational modelling as a tool to reduce PM pollution",
        "publication": "Advances in Environmental Research. Volume 71",
        "citied_by": "0",
        "cover_date": "2020-03-27",
        "Abstract": "Air pollution has become a major issue in recent years. One of the most relevant air pollutants is the particulate matter (PM) with an aerodynamic diameter smaller than 2.5 μm (PM is associated with adverse effects on human health, which include fatal cardiovascular and respiratory diseases, and with environmental concerns such as visibility impairment (haze) and damage in ecosystems. PMinf2.5/inf presence in the atmosphere depends on its variety of anthropogenic and natural sources (e.g., traffic emissions, industrial processes, residential combustion, and biogenic emissions), related factors (e.g., climate, meteorology, and urbanization level) and other episodes like dust transport and deposition. This study aimed to understand the current panorama of PMinf2.5/inf pollution and how the application of computer modelling can contribute to its monitoring and control. To implement policies and carry out targeted and effective measures to improve air quality and mitigate PM presence and its effects, the behaviours of PMinf2.5/inf concentrations in different environmental conditions should be characterised. With the emergence of computer science, there was an exponential increase in the application of air pollution models. Air pollution modelling is used to describe relationships between factors like emissions, meteorology, climatology, transport and deposition. Based on inputs of meteorological data and source information, mathematical models can be an interesting tool to study the complex interactions that are difficult to analyse by observation or monitoring. Based on the machine learning concept, Artificial Neural Network models have been strongly applied in the study field of air pollution, presenting good performances when predicting PM concentrations.",
        "DOI": "NA",
        "paper_author": "Adães J.",
        "affiliation_name": "Universidade do Porto",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60007249",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "Machine Learning and Complex Event Processing A Review of Real-time Data Analytics for the Industrial Internet of Things",
        "publication": "Enterprise Modelling and Information Systems Architectures",
        "citied_by": "13",
        "cover_date": "2020-03-23",
        "Abstract": "In the Industrial Internet of Things, cyber-physical systems bridge the gap between the physical and digital world by connecting advanced manufacturing systems with digital services in so-called smart factories. This interplay generates a large amount of data. By analyzing the data, manufacturers can reap many benefits and optimize their operations. Here, the value of information is at its highest with low latency to its emergence and its value decreases over time. Complex Event Processing (CEP) is a technology, which enables real-time analysis of complex events (i.e., combined data values from different sources). In this way, CEP assists in the identification and localization of anomalous process sequences in smart factories. However, CEP comes with limitations that reduce its effectiveness. Setting up CEP requires in-depth domain knowledge and is primarily declarative as well as reactive by nature. Combining CEP with machine learning is a possible extension to circumvent these technological limitations. However, there is no up-to-date overview on the integration of both paradigms in research and no review of their transferability for application in smart factories. In this article, we provide (1) a synthesis of research on the integration of CEP and machine learning identifying supervised learning as the predominant approach, and (2) a transfer of potentials for the use in smart factories. Here, reactive and proactive policies are used in equal frequency.",
        "DOI": "10.18417/emisa.15.1",
        "paper_author": "Wanner J.",
        "affiliation_name": "Julius-Maximilians-Universität Würzburg",
        "affiliation_city": "Wurzburg",
        "affiliation_country": "Germany",
        "affiliation_id": "60012689",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Core Topics Discovery in Sustainable Supply Chain Literature: An Automatic Approach",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "1",
        "cover_date": "2020-03-23",
        "Abstract": "The study of Sustainable Supply Chain (SSC) has evolved and expanded over the last two decades. This study uses text mining and machine learning methods for automatically identify and classify the topics that permeate a collection of documents. The topics of SSC research were identified, using the Latent Dirichlet Allocation model, from 684 articles published between 2001 and 2017 in 13 top journals. Then, we explored trends by examining changes in the classification of topics in different periods and by identifying the hot and cold topics of SSC research. The relationships of these topics with the journals were also determined. Finally, applying the Competitive Neural Network learning model, the topics were classified according to the Elkington's Triple Bottom Line precepts. The findings of this study are expected to provide clues for researchers and policymakers in the field of SSC.",
        "DOI": "10.1088/1742-6596/1454/1/012009",
        "paper_author": "Montenegro C.",
        "affiliation_name": "Escuela Politécnica Nacional",
        "affiliation_city": "Quito",
        "affiliation_country": "Ecuador",
        "affiliation_id": "60072054",
        "affiliation_state": "Pichincha"
    },
    {
        "paper_title": "Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness",
        "publication": "The BMJ",
        "citied_by": "293",
        "cover_date": "2020-03-20",
        "Abstract": "Machine learning, artificial intelligence, and other modern statistical methods are providing new opportunities to operationalise previously untapped and rapidly growing sources of data for patient benefit. Despite much promising research currently being undertaken, particularly in imaging, the literature as a whole lacks transparency, clear reporting to facilitate replicability, exploration for potential ethical concerns, and clear demonstrations of effectiveness. Among the many reasons why these problems exist, one of the most important (for which we provide a preliminary solution here) is the current lack of best practice guidance specific to machine learning and artificial intelligence. However, we believe that interdisciplinary groups pursuing research and impact projects involving machine learning and artificial intelligence for health would benefit from explicitly addressing a series of questions concerning transparency, reproducibility, ethics, and effectiveness (TREE). The 20 critical questions proposed here provide a framework for research groups to inform the design, conduct, and reporting; for editors and peer reviewers to evaluate contributions to the literature; and for patients, clinicians and policy makers to critically appraise where new findings may deliver patient benefit.",
        "DOI": "10.1136/bmj.l6927",
        "paper_author": "Vollmer S.",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60111768",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Minimizing Risk and Maximizing Spatial Transferability: Challenges in Constructing a Useful Model of Potential Suitability for an Invasive Insect",
        "publication": "Annals of the Entomological Society of America",
        "citied_by": "10",
        "cover_date": "2020-03-18",
        "Abstract": "Forecasting the spread and potential impacts of invasive, alien species is vital to relevant management and policy decisions. Models that estimate areas of potential suitability are useful to guide early detection and eradication, inform effective budget allocations, and justify quarantine regulations. Machine-learning is a rapidly emerging technology with myriad applications, including the analysis of factors that govern species' distributions. However, forecasts for invasive species often require extrapolation into novel spaces, which may severely Erode model reliability. Using the popular machine-learning platform, MaxEnt, we integrate numerous tools and recommendations to demonstrate a method of rigorous model development that emphasizes assessment of model transferability. Our models use Lymantria dispar dispar (L.) (Lepidoptera: Erebidae), an insect brought to the United States in the late 1860s from Europe and subsequently well monitored in spread. Recent genetic analyses provide evidence that the eastern North American population originated in Germany, France, and northern Italy. We demonstrate that models built and assessed using typical methodology for invasive species (e.g., using records from the full native geographic range) showed the smallest extent of extrapolation, but the worst transferability when validated with independent data. Conversely, models based on the purported genetic source of the eastern North American populations (i.e., a subset of the native range) showed the greatest transferability, but the largest extent of extrapolation. Overall, the model that yielded high transferability to North America and low extrapolation was built following current recommendations of spatial thinning and parameter optimization with records from both the genetic source in Europe and early North American invasion.",
        "DOI": "10.1093/aesa/saz049",
        "paper_author": "Morey A.C.",
        "affiliation_name": "University of Minnesota Twin Cities",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States",
        "affiliation_id": "60029445",
        "affiliation_state": "MN"
    },
    {
        "paper_title": "A hybrid model for predicting human physical activity status from lifelogging data",
        "publication": "European Journal of Operational Research",
        "citied_by": "18",
        "cover_date": "2020-03-16",
        "Abstract": "One trend in the recent healthcare transformations is people are encouraged to monitor and manage their health based on their daily diets and physical activity habits. However, much attention of the use of operational research and analytical models in healthcare has been paid to the systematic level such as country or regional policy making or organisational issues. This paper proposes a model concerned with healthcare analytics at the individual level, which can predict human physical activity status from sequential lifelogging data collected from wearable sensors. The model has a two-stage hybrid structure (in short, MOGP-HMM) – a multi-objective genetic programming (MOGP) algorithm in the first stage to reduce the dimensions of lifelogging data and a hidden Markov model (HMM) in the second stage for activity status prediction over time. It can be used as a decision support tool to provide real-time monitoring, statistical analysis and personalized advice to individuals, encouraging positive attitudes towards healthy lifestyles. We validate the model with the real data collected from a group of participants in the UK, and compare it with other popular two-stage hybrid models. Our experimental results show that the MOGP-HMM can achieve comparable performance. To the best of our knowledge, this is the very first study that uses the MOGP in the hybrid two-stage structure for individuals’ activity status prediction. It fits seamlessly with the current trend in the UK healthcare transformation of patient empowerment as well as contributing to a strategic development for more efficient and cost-effective provision of healthcare.",
        "DOI": "10.1016/j.ejor.2019.05.035",
        "paper_author": "Ni J.",
        "affiliation_name": "University of Lincoln",
        "affiliation_city": "Lincoln",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026830",
        "affiliation_state": "Lincolnshire"
    },
    {
        "paper_title": "Applications of Artificial Intelligence and Machine learning in smart cities",
        "publication": "Computer Communications",
        "citied_by": "500",
        "cover_date": "2020-03-15",
        "Abstract": "Smart cities are aimed to efficiently manage growing urbanization, energy consumption, maintain a green environment, improve the economic and living standards of their citizens, and raise the people's capabilities to efficiently use and adopt the modern information and communication technology (ICT). In the smart cities concept, ICT is playing a vital role in policy design, decision, implementation, and ultimate productive services. The primary objective of this review is to explore the role of artificial intelligence (AI), machine learning (ML), and deep reinforcement learning (DRL) in the evolution of smart cities. The preceding techniques are efficiently used to design optimal policy regarding various smart city-oriented complex problems. In this survey, we present in-depth details of the applications of the prior techniques in intelligent transportation systems (ITSs), cyber-security, energy-efficient utilization of smart grids (SGs), effective use of unmanned aerial vehicles (UAVs) to assure the best services of 5G and beyond 5G (B5G) communications, and smart health care system in a smart city. Finally, we present various research challenges and future research directions where the aforementioned techniques can play an outstanding role to realize the concept of a smart city.",
        "DOI": "10.1016/j.comcom.2020.02.069",
        "paper_author": "Ullah Z.",
        "affiliation_name": "Università degli Studi di Camerino",
        "affiliation_city": "Camerino",
        "affiliation_country": "Italy",
        "affiliation_id": "60026298",
        "affiliation_state": "MC"
    },
    {
        "paper_title": "Big data mining for the estimation of hourly rooftop photovoltaic potential and its uncertainty",
        "publication": "Applied Energy",
        "citied_by": "127",
        "cover_date": "2020-03-15",
        "Abstract": "The large-scale deployment of photovoltaics (PV) on building rooftops can play a significant role in the transition to a low-carbon energy system. To date, the lack of high-resolution building and environmental data and the large uncertainties related to existing processing methods impede the accurate estimation of large-scale rooftop PV potentials. To address this gap, we developed a methodology that combines Machine Learning algorithms, Geographic Information Systems and physical models to estimate the technical PV potential for individual roof surfaces at hourly temporal resolution. We further estimate the uncertainties related to each step of the potential assessment and combine them to quantify the uncertainty on the final PV potential. The methodology is applied to 9.6 million rooftops in Switzerland and can be transferred to any large region or country with sufficient available data. Our results suggest that 55% of the total Swiss roof surface is available for the installation of PV panels, yielding an annual technical rooftop PV potential of 24±9TWh. This could meet more than 40% of Switzerland's current annual electricity demand. The presented method for an hourly rooftop PV potential and uncertainty estimation can be applied to the large-scale assessment of future energy systems with decentralised electricity grids. The results can be used to propose effective policies for the integration of rooftop photovoltaics in the built environment.",
        "DOI": "10.1016/j.apenergy.2019.114404",
        "paper_author": "Walch A.",
        "affiliation_name": "École Polytechnique Fédérale de Lausanne",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60028186",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A reinforcement neural architecture search method for rolling bearing fault diagnosis",
        "publication": "Measurement: Journal of the International Measurement Confederation",
        "citied_by": "76",
        "cover_date": "2020-03-15",
        "Abstract": "The fault diagnosis of rolling bearing has always been a research hotspot, and it is an urgent task to develop the effective method for rolling bearing fault identification. Most traditional methods cannot automatically build appropriately models for different datasets. In this paper, a neural network architecture automatic search method based on reinforcement learning is proposed for fault diagnosis of rolling bearings. The framework of proposed method contains of two components: a controller model and child models. The controller is recurrent neural network (RNN) and generates a series of actions, each action specifies a design choice to construct the child models for fault diagnosis. Then, the controller parameters are updated using the policy gradient method of reinforcement learning by maximizing the accuracy of the child models. The results confirm that the proposed method can realize the automatic design of neural network architecture and overcome the limitation of traditional methods.",
        "DOI": "10.1016/j.measurement.2019.107417",
        "paper_author": "Wang R.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "A novel optimal bipartite consensus control scheme for unknown multi-agent systems via model-free reinforcement learning",
        "publication": "Applied Mathematics and Computation",
        "citied_by": "108",
        "cover_date": "2020-03-15",
        "Abstract": "In this paper, the optimal bipartite consensus control (OBCC) problem is investigated for unknown multi-agent systems (MASs) with coopetition networks. A novel distributed OBCC scheme is proposed based on model-free reinforcement learning method to achieve OBCC, where the agent's dynamics are no longer required. First, The coopetition networks are applied to establish the cooperative and competitive interactions among agents, and then the OBCC problem is formulated by introducing local neighbor bipartite consensus errors and performance index functions (PIFs) for each agent. Second, in order to obtain the OBCC laws, a policy iteration algorithm (PIA) is employed to learn the solutions to discrete-time (DT) Hamilton-Jacobi-Bellman (HJB) equations. Third, to implement the proposed methods, we adopt a data-driven actor-critic-based neural networks (NNs) framework to approximate the control laws and the PIFs, respectively, in an online learning manner. Finally, some simulation results are given to demonstrate the effectiveness of the developed approaches.",
        "DOI": "10.1016/j.amc.2019.124821",
        "paper_author": "Peng Z.",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60005465",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Carbon trading volume and price forecasting in China using multiple machine learning models",
        "publication": "Journal of Cleaner Production",
        "citied_by": "197",
        "cover_date": "2020-03-10",
        "Abstract": "Motivated by reducing carbon emissions, carbon trading market have been opened to promote environmental protection. Accurate carbon trading volume and price forecasts have far-reaching implications for environmental and energy policy formulation. As the country with the most massive carbon emissions in the world, China's carbon price trends, carbon trading volume trends, and policy orientation are of great significance. As matters stand, there are few studies on carbon price and trading volume forecasts, and no research paper has covered carbon price and trading volume forecasts for all carbon trading markets in China. In order to provide a relatively complete reference for the carbon price and trading volume in China, this paper uses six machine learning models to predict the daily carbon price and trading volume of eight carbon markets in China, including Beijing, Shenzhen, Guangdong, Hubei, Shanghai, Fujian, Tianjin, Chongqing. The prediction models include extreme gradient boosting, random forest, kernel-based nonlinear extension of the Arps decline model optimized by grey wolf optimizer (GWO-KNEA), support vector machine optimized by particle swarm optimizer, support vector machine optimized by fruit fly optimizer and simulated annealing algorithm, and radial basis function neural network (RBFNN). Moreover, an advanced data denoising method, i.e., complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN), is used in the models to smooth the raw data. Because the eight carbon trading markets have different carbon price and trading volume distribution characteristics in time series, by comparing the prediction results, more suitable models for the specific carbon market can be obtained. The prediction results show that CEEMDAN-GWO-KNEA and CEEMDAN-RBFNN are more competitive in predicting carbon prices and trading volume in China because of their best performance in many datasets. The average accuracy of CEEMDAN-RBFNN and CEMDAN-GWO-KNEA in carbon price prediction is 98.40% and 97.89%, respectively. The predictive stability of each model in different application scenarios is also discussed. The results show that high prediction accuracy does not mean better prediction stability, but CEEMDAN-RBFNN and CEMDAN-GWO-KNEA can still guarantee high stability in most datasets.",
        "DOI": "10.1016/j.jclepro.2019.119386",
        "paper_author": "Lu H.",
        "affiliation_name": "Southwest Petroleum University China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60017244",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Optimizing zinc electrowinning processes with current switching via Deep Deterministic Policy Gradient learning",
        "publication": "Neurocomputing",
        "citied_by": "31",
        "cover_date": "2020-03-07",
        "Abstract": "This paper proposes a model-free Deep Deterministic Policy Gradient (DDPG) learning controller for zinc electrowinning processes (ZEP) to save energy consumption during the current switching periods. To overcome the problems such as inaccurate modeling and various time delays, the proposed DDPG controller utilizes various control periods and parameters for different working conditions. Strategies such as action boundary setting, reward function definition, state normalization are applied to ensure its learning performance. Simulations and experiments show that the DDPG learning controller can significantly decrease energy consumption during the ZEP current switching periods. The optimal control policy will be learnt for different working conditions with only one group hyperparameters. Furthermore, the smoother control actions of the DDPG controller will improve the stability and reduce more energy consumption by comparing with traditional proportional-integral (PI) controller, model predictive control (MPC) and artificial experiences. The artificial intelligence-based optimal control framework brings both energy saving and intelligence to zinc manufacturing plants.",
        "DOI": "10.1016/j.neucom.2019.11.022",
        "paper_author": "Shi X.",
        "affiliation_name": "Central South University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60017060",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Dynamic colocation policies with reinforcement learning",
        "publication": "ACM Transactions on Architecture and Code Optimization",
        "citied_by": "12",
        "cover_date": "2020-03-04",
        "Abstract": "We draw on reinforcement learning frameworks to design and implement an adaptive controller for managing resource contention. During runtime, the controller observes the dynamic system conditions and optimizes control policies that satisfy latency targets yet improve server utilization. We evaluate a physical prototype that guarantees 95th percentile latencies for a search engine and improves server utilization by up to 70%, compared to exclusively reserving servers for interactive services, for varied batch workloads in machine learning.",
        "DOI": "10.1145/3375714",
        "paper_author": "Li Y.",
        "affiliation_name": "Duke University",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60008724",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Mapping the public debate on ethical concerns: algorithms in mainstream media",
        "publication": "Journal of Information, Communication and Ethics in Society",
        "citied_by": "17",
        "cover_date": "2020-03-03",
        "Abstract": "Purpose: Algorithms are in the mainstream media news on an almost daily basis. Their context is invariably artificial intelligence (AI) and machine learning decision-making. In media articles, algorithms are described as powerful, autonomous actors that have a capability of producing actions that have consequences. Despite a tendency for deification, the prevailing critique of algorithms focuses on ethical concerns raised by decisions resulting from algorithmic processing. However, the purpose of this paper is to propose that the ethical concerns discussed are limited in scope and suggest that it is not clear what concerns dominate the debate. Design/methodology/approach: The paper uses a systematic mapping study approach to review articles appearing in leading UK national papers from the perspective of the ethical concerns over a period of one year. The articles are categorised using a widely cited framework detailing a taxonomy of ethical concerns. The UK context is important because of UK public policy initiatives around AI. Findings: The research presented in this paper contributes the first systematic mapping study of articles appearing in leading UK national papers from the perspective of widely accepted ethical concerns such as inscrutable evidence, misguided evidence, unfair outcomes and transformative effects. Originality/value: The research presented in this paper contributes the first systematic mapping study of articles appearing in leading UK national papers from the perspective of the ethical concerns. The UK context is important because of UK public policy initiatives around AI. To review the media content from the perspective of ethical concerns, this paper uses the synthesised conceptual map of ethical concerns developed by Mittelstad et al. Given the dominance of that framework, this paper’s contribution is also an important instantiation and experimental validation of using that conceptual map.",
        "DOI": "10.1108/JICES-04-2019-0039",
        "paper_author": "Barn B.S.",
        "affiliation_name": "Middlesex University",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60014105",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Recent trends and future direction of dental research in the digital era",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "82",
        "cover_date": "2020-03-02",
        "Abstract": "The digital transformation in dental medicine, based on electronic health data information, is recognized as one of the major game-changers of the 21st century to tackle present and upcoming challenges in dental and oral healthcare. This opinion letter focuses on the estimated top five trends and innovations of this new digital era, with potential to decisively influence the direction of dental research: (1) rapid prototyping (RP), (2) augmented and virtual reality (AR/VR), (3) artificial intelligence (AI) and machine learning (ML), (4) personalized (dental) medicine, and (5) tele-healthcare. Digital dentistry requires managing expectations pragmatically and ensuring transparency for all stakeholders: patients, healthcare providers, university and research institutions, the medtech industry, insurance, public media, and state policy. It should not be claimed or implied that digital smart data technologies will replace humans providing dental expertise and the capacity for patient empathy. The dental team that controls digital applications remains the key and will continue to play the central role in treating patients. In this context, the latest trend word is created: augmented intelligence, e.g., the meaningful combination of digital applications paired with human qualities and abilities in order to achieve improved dental and oral healthcare, ensuring quality of life.",
        "DOI": "10.3390/IJERPH17061987",
        "paper_author": "Joda T.",
        "affiliation_name": "Universität Basel",
        "affiliation_city": "Basel",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60023588",
        "affiliation_state": "BS"
    },
    {
        "paper_title": "The impact of covid-19 epidemic declaration on psychological consequences: A study on active weibo users",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "1254",
        "cover_date": "2020-03-02",
        "Abstract": "COVID-19 (Corona Virus Disease 2019) has significantly resulted in a large number of psychological consequences. The aim of this study is to explore the impacts of COVID-19 on people’s mental health, to assist policy makers to develop actionable policies, and help clinical practitioners (e.g., social workers, psychiatrists, and psychologists) provide timely services to affected populations. We sample and analyze the Weibo posts from 17,865 active Weibo users using the approach of Online Ecological Recognition (OER) based on several machine-learning predictive models. We calculated word frequency, scores of emotional indicators (e.g., anxiety, depression, indignation, and Oxford happiness) and cognitive indicators (e.g., social risk judgment and life satisfaction) from the collected data. The sentiment analysis and the paired sample t-test were performed to examine the differences in the same group before and after the declaration of COVID-19 on 20 January, 2020. The results showed that negative emotions (e.g., anxiety, depression and indignation) and sensitivity to social risks increased, while the scores of positive emotions (e.g., Oxford happiness) and life satisfaction decreased. People were concerned more about their health and family, while less about leisure and friends. The results contribute to the knowledge gaps of short-term individual changes in psychological conditions after the outbreak. It may provide references for policy makers to plan and fight against COVID-19 effectively by improving stability of popular feelings and urgently prepare clinical practitioners to deliver corresponding therapy foundations for the risk groups and affected people.",
        "DOI": "10.3390/ijerph17062032",
        "paper_author": "Li S.",
        "affiliation_name": "Institute of Psychology Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60018614",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A comprehensive wind power forecasting system integrating artificial intelligence and numerical weather prediction",
        "publication": "Energies",
        "citied_by": "56",
        "cover_date": "2020-03-02",
        "Abstract": "The National Center for Atmospheric Research (NCAR) recently updated the comprehensive wind power forecasting system in collaboration with Xcel Energy addressing users' needs and requirements by enhancing and expanding integration between numerical weather prediction and machine-learning methods. While the original system was designed with the primary focus on day-ahead power prediction in support of power trading, the enhanced system provides short-term forecasting for unit commitment and economic dispatch, uncertainty quantification in wind speed prediction with probabilistic forecasting, and prediction of extreme events such as icing. Furthermore, the empirical power conversion machine-learning algorithms now use a quantile approach to data quality control that has improved the accuracy of the methods. Forecast uncertainty is quantified using an analog ensemble approach. Two methods of providing short-range ramp forecasts are blended: the variational doppler radar analysis system and an observation-based expert system. Extreme events, specifically changes in wind power due to high winds and icing, are now forecasted by combining numerical weather prediction and a fuzzy logic artificial intelligence system. These systems and their recent advances are described and assessed.",
        "DOI": "10.3390/en13061372",
        "paper_author": "Kosovic B.",
        "affiliation_name": "National Center for Atmospheric Research",
        "affiliation_city": "Boulder",
        "affiliation_country": "United States",
        "affiliation_id": "60021243",
        "affiliation_state": "CO"
    },
    {
        "paper_title": "Optimal torque distribution control of multi-axle electric vehicles with in-wheel motors based on DDPG algorithm",
        "publication": "Energies",
        "citied_by": "20",
        "cover_date": "2020-03-02",
        "Abstract": "In order to effectively reduce the energy consumption of the vehicle, an optimal torque distribution control for multi-axle electric vehicles (EVs) with in-wheel motors is proposed. By analyzing the steering dynamics, the formulas of additional steering resistance are given. Aiming at the multidimensional continuous system that cannot be solved by traditional optimization methods, the deep deterministic policy gradient (DDPG) algorithm for deep reinforcement learning is adopted. Each wheel speed and deflection angle are selected as the state, the distribution ratio of drive torque is the optimized action and the state of charge (SOC) is the reward. After completing a large number of training for vehicle model, the algorithm is verified under conventional steering and extreme steering conditions. The maximum SOC decline of the vehicle can be reduced by about 5% under conventional steering conditions based on the motor efficiency mapused. The combination of artificial intelligence technology and actual situation provides an innovative solution to the optimization problem of the multidimensional state input and the continuous action output related to vehicles or similar complex systems.",
        "DOI": "10.3390/en13061331",
        "paper_author": "Jin L.",
        "affiliation_name": "Jilin University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60007711",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Re-imagining the future of education in the era of the fourth industrial revolution",
        "publication": "Worldwide Hospitality and Tourism Themes",
        "citied_by": "30",
        "cover_date": "2020-03-02",
        "Abstract": "Purpose: Globally, higher education has been, over the years, a source of innovation, policy, new knowledge and a national asset. However, the advent of the Fourth Industrial Revolution (4IR) is having an impact on the principles of learning from primary to tertiary levels. The purpose of this paper is to consider how the 4IR has and will continue to impact education at the various levels of learning. Design/methodology/approach: The paper aims to bridge the perceived information gap and provide insights into the kinds of educational preparation and the skills and qualifications that 4IR jobs require. In response, the following are considered: the need to tweak the curriculum, adopt the right technology for in class and online delivery and the projection of other learning techniques and skills that are often not considered pertinent. Data gathering for the report was by discussion with experts and consultation of relevant articles and write-ups from related websites. Findings: The advent of smart communication systems involving artificial intelligence, internet, robotics, virtual reality and digital textbooks has opened a new vista in relation to how and what is learnt in schools. Just as technologies brought about smart communication systems, the 4IR model of higher education is rapidly evolving and as such, curriculum development and review must be dynamic, and it must keep pace with the technological advances and skills required in the twenty first century. Research limitations/implications: More purposeful research needs to be conducted in universities and industries with the intention of accelerating internal and external innovations so that markets can be expanded. Furthermore, efforts to reduce the cost and time of generating innovations will need to be intensified. Practical implications: The value and emphasis that are placed on the acquisition of degrees and paper qualifications are changing rapidly. Although it is traditional for students to compete for admission to the face-to-face classroom model, it is no longer unusual for a student to take courses online from any part of the world and still be accepted into positions usually reserved for traditional classroom education. Social implications: As at today, examples of 4IR services include Uber, Airbnb, Cloud services, Artificial intelligence, Cyber-security, three-dimensional printers, driverless cars and robotics. Machine learning and drone technology are also of growing significance. As yet, subjects dealing with such inventions and innovations are not part of the curriculum of many institutions and this is a cause for concern. Originality/value: The 4IR era will bring great changes to how students are taught and what students must learn as the tools for transformational learning are already overwhelming. Jobs will be scarce for those without the requisite skills, whereas those with the right skills will have to keep up with the pace of technological development, otherwise they too will be left behind. Schools will increasingly become centres for the generation of innovation and its incubation and in all this, quality learning, teaching and knowledge impartation can easily be carried out online.",
        "DOI": "10.1108/WHATT-10-2019-0066",
        "paper_author": "Ilori M.O.",
        "affiliation_name": "University of Lagos",
        "affiliation_city": "Lagos",
        "affiliation_country": "Nigeria",
        "affiliation_id": "60006448",
        "affiliation_state": "Lagos"
    },
    {
        "paper_title": "Multi-class approach for user behavior prediction using deep learning framework on twitter election dataset",
        "publication": "Journal of Data, Information and Management",
        "citied_by": "21",
        "cover_date": "2020-03-01",
        "Abstract": "Among the broad assortment of Machine Learning approaches, deep learning has recently attracted attention particularly in the domain of user behavior analysis. The notion to study user behavior from the unstructured tweets shared on social media is an interesting yet challenging task. A social platform such as Twitter yield access to the unprompted views of the wide-ranging users on particular events like election. These views cater government and corporates to remold strategies, assess the areas where better measures need to be put forward and monitor common opinion. With the advent of the general election in India (largest democracy) people tend to articulate their views or issues. Tweets related to general elections 2019 of India is used as data corpus for the study. Multi-class classification fabricated with novel deep learning approach is implemented to analyses the user opinion. Here, we have used nine different classes, which is representing larger issues in the nation for election agenda. Moreover, comparative analysis between tradition approaches such as Naïve Bayes, SVM, decision tree, logistic regression and employed approach with deep learning method is presented. Experimental results revels that the proposed model can reach up to 98.70% accuracy on multiclass based prediction in machine learning. The results assist the government and businesses to know about grave issue offering a shot to revise strategic policy and make welfare scheme program.",
        "DOI": "10.1007/s42488-019-00013-y",
        "paper_author": "Mohbey K.K.",
        "affiliation_name": "Central University of Rajasthan",
        "affiliation_city": "Ajmer",
        "affiliation_country": "India",
        "affiliation_id": "60107394",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "The impact of increasing returns on knowledge and big data: From adam smith and allyn young to the age of machine learning and digital platforms",
        "publication": "Prometheus: Critical Studies in Innovation",
        "citied_by": "6",
        "cover_date": "2020-03-01",
        "Abstract": "Allyn Young’s concept of increasing returns (not to be confused with static, equilibrium constructs of economies of scale and increasing returns to scale) is applied to analyse how and why increasing returns arise in the production (generation) and use (application) of knowledge and big data, thereby driving economic growth and progress. Knowledge is chosen as our focus because it is said to be our most powerful engine of production, and big data are included to make the analysis more complete and recent. We analyse four mechanisms or sources of increasing returns in the production of knowledge, and four in the use of knowledge. Turning to big data, we analyse increasing returns in the functioning of digital platforms and increasing returns in machine learning from gigantic amounts of training data. Concluding remarks concern some key differences between big data and knowledge, some policy implications, and some of the social negative impacts from the ways in which big data are being used.",
        "DOI": "10.13169/prometheus.36.1.0010",
        "paper_author": "Hu Y.S.",
        "affiliation_name": "Hong Kong Shue Yan University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "China",
        "affiliation_id": "60081158",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Applying the Deep Learning Method for Simulating Outcomes of Educational Interventions",
        "publication": "SN Computer Science",
        "citied_by": "6",
        "cover_date": "2020-03-01",
        "Abstract": "Predicting outcomes of educational interventions before investing in large-scale implementation efforts in school settings is essential for educational policy-making. However, due to time and resource limitations, conducting longitudinal, large-scale experiments testing outcomes of interventions in authentic settings is difficult. Here, we introduce the deep learning method as a way to address this issue and illustrate the use of the deep learning method for the prediction of intervention outcomes through a MATLAB implementation. The presented deep learning method extracts predictable patterns from an empirical dataset to simulate large-scale intervention outcomes. Findings from our simulations suggest that the deep learning applied simulation model can predict intervention outcomes significantly more accurately compared to the traditional regression analysis methods.",
        "DOI": "10.1007/s42979-020-0075-z",
        "paper_author": "Han H.",
        "affiliation_name": "The University of Alabama",
        "affiliation_city": "Tuscaloosa",
        "affiliation_country": "United States",
        "affiliation_id": "60025371",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "Characterizing Radar Network Traffic: A first step towards spoofing attack detection",
        "publication": "IEEE Aerospace Conference Proceedings",
        "citied_by": "5",
        "cover_date": "2020-03-01",
        "Abstract": "An Air Traffic Management (ATM) Surveillance System is used to provide services to perform Air Traffic Control (ATC) (e.g., horizontal separation between aircraft). This sytem carries messages containing aircraft's position from a collection of radars of an Air Navigation Service Provider (ANSP) through its network. Then Radar traffic is one of the most important sources of information for this system. The format of the radar messages is defined by a specific application-layer protocol entitled ASTERIX. The evolution of the security policy and technologies used makes existing radar systems, once considered safe, now potentially open to attack. Both safety and security of ATM system could be impacted by any kind of attack into the network traffic, who could maliciously modified information about aicrafts, in particular thanks to Spoofing Attack. To counter this risk, there is need to detect intrusion and then to have anomaly detection modules for this safety-critical network traffic, that can be deployed in a security appliance. In order to design this module, we did a statistical analysis to have an overview of the traffic to better know what we need to protect. Specifically, we studied radar network traffic in order to extract high level statistic characteristics of normal radar traffic. This allowed us to identify a trend in the evolution of this traffic. We were then able to inject a spoofing attack (when a malicious party impersonates another device or network user for the purpose of altering the data) into this traffic to modify the nominal traffic. Thereafter, we were able to detect this attack using our method, which consists of the use of a machine learning detection method, using a Long-Short Term Memory (LSTM) mechanism. This is the subject of our paper, an overview of radar traffic and a method to detect spoofing attack in this traffic. This would help to develop an ATM IDS especially as this type of attack could remain invisible for air traffic controller.",
        "DOI": "10.1109/AERO47225.2020.9172292",
        "paper_author": "De Riberolles T.",
        "affiliation_name": "Activus Group",
        "affiliation_city": "Toulouse",
        "affiliation_country": "France",
        "affiliation_id": "121073141",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Recent Land Use and Land Cover Change Dynamics in the Gran Chaco Americano",
        "publication": "2020 IEEE Latin American GRSS and ISPRS Remote Sensing Conference, LAGIRS 2020 - Proceedings",
        "citied_by": "4",
        "cover_date": "2020-03-01",
        "Abstract": "Land transformation is one of the most significant human changes on the Earth's surface processes. Therefore, land use land cover time series are a key input for environmental monitoring, natural resources management, territorial planning enforcement at national scale. We here capitalize from the MapBiomas initiative to characterize land use land cover (LULC) change in the Gran Chaco between 2010 and 2017. Specifically we sought to a) quantify annual changes in the main LULC classes; b) identify the main LULC transitions and c) relate these transitions to current land use policies. Within the MapBiomas project, Landsat based annual maps depicting natural woody vegetation, natural herbaceous vegetation, dispersed natural vegetation, cropland, pastures, bare areas and water. We used Random Forest machine learning algorithms trained by samples produced by visual interpretation of high resolution images. Annual overall accuracy ranged from 0,73 to 0,74. Our results showed that, between 2010 and 2017, agriculture and pasture lands increased ca. 3.7 Mha while natural forestry decreased by 2.3 Mha. Transitions from forests to agriculture accounted for 1.14% of the overall deforestation while 86% was associated to pastures and natural herbaceous vegetation. In Argentina, forest loss occurred primarily (39%) on areas non considered by the territorial planning Law, followed by medium (33%), high (19%) and low (9%) conservation priority classes. These results illustrate the potential contribution of remote sensing to characterize complex human environmental interactions occurring over extended areas and time frames.",
        "DOI": "10.1109/LAGIRS48042.2020.9165579",
        "paper_author": "Banchero S.",
        "affiliation_name": "Instituto Nacional de Tecnología Agropecuaria Buenos Aires",
        "affiliation_city": "Buenos Aires",
        "affiliation_country": "Argentina",
        "affiliation_id": "60009264",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Variation-Aware Heterogeneous Voltage Regulation for Multi-Core Systems-on-A-Chip with On-Chip Machine Learning",
        "publication": "Proceedings - International Symposium on Quality Electronic Design, ISQED",
        "citied_by": "1",
        "cover_date": "2020-03-01",
        "Abstract": "Large-scale systems-on-A-chips (SoCs) have stringent power requirements to ensure adequate supply of power to on-die devices and prevent catastrophic timing violations. Heterogeneous voltage regulation (HVR) leveraging a combination of on-chip and off-chip voltage regulators has been advocated for ensuring power integrity with maximum efficiency. However, unavoidable process and temperature variations have not been considered in prior HVR work. In this paper, we present an in-depth evaluation of the impacts of process and temperature variations on HVR. Furthermore, we propose a systemic solution to incorporate variation awareness into the HVR system control policy to add a further improvement of up to 4.28% in system power efficiency with minimal hardware overhead.",
        "DOI": "10.1109/ISQED48828.2020.9136985",
        "paper_author": "Riad J.",
        "affiliation_name": "Texas AM University",
        "affiliation_city": "Temple",
        "affiliation_country": "United States",
        "affiliation_id": "115044240",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Emergent Control of MPSoC Operation by a Hierarchical Supervisor / Reinforcement Learning Approach",
        "publication": "Proceedings of the 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020",
        "citied_by": "10",
        "cover_date": "2020-03-01",
        "Abstract": "MPSoCs increasingly depend on adaptive resource management strategies at runtime for efficient utilization of resources when executing complex application workloads. In particular, conflicting demands for adequate computation performance and power-/energy-efficiency constraints make desired application goals hard to achieve. We present a hierarchical, cross-layer hardware/software resource manager capable of adapting to changing workloads and system dynamics with zero initial knowledge. The manager uses rule-based reinforcement learning classifier tables (LCTs) with an archive-based backup policy as leaf controllers. The LCTs directly manipulate and enforce MPSoC building block operation parameters in order to explore and optimize potentially conflicting system requirements (e.g., meeting a performance target while staying within the power constraint). A supervisor translates system requirements and application goals into per-LCT objective functions (e.g., core instructions-per-second (IPS). Thus, the supervisor manages the possibly emergent behavior of the low-level LCT controllers in response to 1) switching between operation strategies (e.g., maximize performance vs. minimize power; and 2) changing application requirements. This hierarchical manager leverages the dual benefits of a software supervisor (enabling flexibility), together with hardware learners (allowing quick and efficient optimization). Experiments on an FPGA prototype confirmed the ability of our approach to identify optimized MPSoC operation parameters at runtime while strictly obeying given power constraints.",
        "DOI": "10.23919/DATE48585.2020.9116574",
        "paper_author": "Maurer F.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "A Reinforcement Learning Approach to Directed Test Generation for Shared Memory Verification",
        "publication": "Proceedings of the 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020",
        "citied_by": "10",
        "cover_date": "2020-03-01",
        "Abstract": "Multicore chips are expected to rely on coherent shared memory. Albeit the coherence hardware can scale gracefully, the protocol state space grows exponentially with core count. That is why design verification requires directed test generation (DTG) for dynamic coverage control under the tight time constraints resulting from slow simulation and short verification budgets. Next generation EDA tools are expected to exploit Machine Learning for reaching high coverage in less time. We propose a technique that addresses DTG as a decision process and tries to find a decision-making policy for maximizing the cumulative coverage, as a result of successive actions taken by an agent. Instead of simply relying on learning, our technique builds upon the legacy from constrained random test generation (RTG). It casts DTG as coverage-driven RTG, and it explores distinct RTG engines subject to progressively tighter constraints. We compared three Reinforcement Learning generators with a state-of-the-art generator based on Genetic Programming. The experimental results show that the proper enforcement of constraints is more efficient for guiding learning towards higher coverage than simply letting the generator learn how to select the most promising memory events for increasing coverage. For a 3-level MESI 32-core design, the proposed approach led to the highest observed coverage (95.81%), and it was 2.4 times faster than the baseline generator to reach the latter's maximal coverage.",
        "DOI": "10.23919/DATE48585.2020.9116198",
        "paper_author": "Pfeifer N.",
        "affiliation_name": "Universidade Federal de Santa Catarina",
        "affiliation_city": "Florianopolis",
        "affiliation_country": "Brazil",
        "affiliation_id": "60017609",
        "affiliation_state": "SC"
    },
    {
        "paper_title": "A Machine Learning Based Write Policy for SSD Cache in Cloud Block Storage",
        "publication": "Proceedings of the 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020",
        "citied_by": "12",
        "cover_date": "2020-03-01",
        "Abstract": "Nowadays, SSD cache plays an important role in cloud storage systems. The associated write policy, which enforces an admission control policy regarding filling data into the cache, has a significant impact on the performance of the cache system and the amount of write traffic to SSD caches. Based on our analysis on a typical cloud block storage system, approximately 47.09% writes are write-only, i.e., writes to the blocks which have not been read during a certain time window. Naively writing the write-only data to the SSD cache unnecessarily introduces a large number of harmful writes to the SSD cache without any contribution to cache performance. On the other hand, it is a challenging task to identify and filter out those write-only data in a real-time manner, especially in a cloud environment running changing and diverse workloads.In this paper, to alleviate the above cache problem, we propose an ML-WP, Machine Learning Based Write Policy, which reduces write traffic to SSDs by avoiding writing write-only data. The main challenge in this approach is to identify write-only data in a real-time manner. To realize ML-WP and achieve accurate write-only data identification, we use machine learning methods to classify data into two groups (i.e., write-only and normal data). Based on this classification, the write-only data is directly written to backend storage without being cached. Experimental results show that, compared with the industry widely deployed write-back policy, ML-WP decreases write traffic to SSD cache by 41.52%, while improving the hit ratio by 2.61% and reducing the average read latency by 37.52%.",
        "DOI": "10.23919/DATE48585.2020.9116539",
        "paper_author": "Zhang Y.",
        "affiliation_name": "Wuhan National Laboratory for Optoelectronics",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60087294",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Benchmarking Q-learning methods for intelligent network orchestration in the edge",
        "publication": "2nd 6G Wireless Summit 2020: Gain Edge for the 6G Era, 6G SUMMIT 2020",
        "citied_by": "2",
        "cover_date": "2020-03-01",
        "Abstract": "We benchmark Q-learning methods, with various action selection strategies, in intelligent orchestration of the network edge. Q-learning is a reinforcement learning technique that aims to find optimal action policies by taking advantage of the experiences in the past without utilizing a model that describes the dynamics of the environment. With experiences, we refer to the observed causality between the action and the corresponding impact to the environment. In this paper, the environment for Q-learning is composed of virtualized networking resources along with their dynamics that are monitored with Spindump, an in-network latency measurement tool with support for QUIC and TCP. We optimize the orchestration of these networking resources by introducing Q-learning as part of the machine learning driven, intelligent orchestration that is applicable in the edge. Based on the benchmarking results, we identify which action selection strategies support network orchestration that provides low latency and packet loss by considering network resource allocation in the edge.",
        "DOI": "10.1109/6GSUMMIT49458.2020.9083745",
        "paper_author": "Reijonen J.",
        "affiliation_name": "Oy LM Ericsson Ab",
        "affiliation_city": "Jorvas",
        "affiliation_country": "Finland",
        "affiliation_id": "60102007",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "DDPG-based radio resource management for user interactive mobile edge networks",
        "publication": "2nd 6G Wireless Summit 2020: Gain Edge for the 6G Era, 6G SUMMIT 2020",
        "citied_by": "7",
        "cover_date": "2020-03-01",
        "Abstract": "The development of the fifth-generation (5G) system on capability and flexibility enables emerging applications with stringent requirements, such as ultra-high-resolution video streaming and online interactive virtual reality (VR) gaming. Hence, the resource management problem becomes more complicated than in the past, and machine learning can be a powerful tool to provide solutions. In this article, the Deep Deterministic Policy Gradient (DDPG) is used to schedule resources in an edge network environment. We integrate a 3D radio resource structure with componentized Markov decision process (MDP) actions to work on user interactivity-based groups. From the simulation results, we can see that more users are satisfied with DDPG-based radio resource management, especially in bandwidth and latency demanding situations.",
        "DOI": "10.1109/6GSUMMIT49458.2020.9083926",
        "paper_author": "Chen P.C.",
        "affiliation_name": "National Central University",
        "affiliation_city": "Taoyuan",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60024666",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Optimal Stopping Approach for Iterative Training in Federated Learning",
        "publication": "2020 54th Annual Conference on Information Sciences and Systems, CISS 2020",
        "citied_by": "8",
        "cover_date": "2020-03-01",
        "Abstract": "This paper studies the problem of iterative training in Federated Learning. We consider a system with a single parameter server (PS) and M client devices for training a predictive learning model with distributed data sets on the client devices. The clients communicate with the parameter server using a common wireless channel, so each time only one device can transmit. The training is an iterative process consisting of multiple rounds. At beginning of each round (also called an iteration), each client trains the model, broadcast by the parameter server at the beginning of the round, with its own data. After finishing training, the device transmits the update to the parameter server when the wireless channel is available. The server aggregates updates to obtain a new model and broadcasts it to all clients to start a new round. We consider adaptive training where the parameter server decides when to stop/restart a new round, and formulate the problem as an optimal stopping problem. While this optimal stopping problem is difficult to solve, we propose a modified optimal stopping problem. We first develop a low complexity algorithm to solve the modified problem, which also works for the original problem. Experiments on a real data set shows significant improvements compared with policies collecting a fixed number of updates in each round.",
        "DOI": "10.1109/CISS48834.2020.1570616094",
        "paper_author": "Jiang P.",
        "affiliation_name": "Arizona State University",
        "affiliation_city": "Tempe",
        "affiliation_country": "United States",
        "affiliation_id": "60003892",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Deep Learning Model for Forecasting Institutional Building Energy Consumption",
        "publication": "2020 Conference on Information Communications Technology and Society, ICTAS 2020 - Proceedings",
        "citied_by": "6",
        "cover_date": "2020-03-01",
        "Abstract": "South Africa is currently facing an on-going energy crisis that seems to persist every year. Load shedding has become one of the country's biggest challenge. This is because of energy consumption being at an all-time high and inconsistent in terms of supply. In this paper, we propose a deep learning framework (called Dense Neural Network) for the prediction of energy consumption for University buildings. The deep learning model is evaluated on an energy dataset (collected from the University of KwaZulu-Natal), to forecast the energy consumption of the buildings in the University of KwaZulu-Natal. Furthermore, we compared the performance of the proposed model with two classical algorithms (Support Vector Machine and Multiple Regression), and the deep learning model outperformed the classical algorithms. The forecasted energy consumption can be used by various University managements to assess where most of the energy is being consumed. It can provide an opportunity to devise strategies for optimal utilization of energy in Universities.",
        "DOI": "10.1109/ICTAS47918.2020.234004",
        "paper_author": "Mlangeni S.",
        "affiliation_name": "University of KwaZulu-Natal",
        "affiliation_city": "Durban",
        "affiliation_country": "South Africa",
        "affiliation_id": "60010499",
        "affiliation_state": "KwaZulu-Natal"
    },
    {
        "paper_title": "2020 Conference on Information Communications Technology and Society, ICTAS 2020 - Proceedings",
        "publication": "2020 Conference on Information Communications Technology and Society, ICTAS 2020 - Proceedings",
        "citied_by": "0",
        "cover_date": "2020-03-01",
        "Abstract": "The proceedings contain 33 papers. The topics discussed include: analysis of limit states and tolerance field of polarization multiplexing; evidence quality estimation using selected machine learning approaches; challenges faced by employers when using social media for recruitment and selection purposes; eModeration adoption requirements for secondary school education: a critical literature review; on the efficiency of heterogeneous system architecture for image processing; students' attitude towards using a mobile learning management system: a large, undergraduate information systems class; mobile information security awareness among students in higher education: an exploratory study; and examining the challenges of integration and interoperability of a security and privacy policy framework for e-government services: the case of South Africa.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Predictive Model for Students' Performance and Risk Level Indicators Using Machine Learning",
        "publication": "2020 International Conference in Mathematics, Computer Engineering and Computer Science, ICMCECS 2020",
        "citied_by": "11",
        "cover_date": "2020-03-01",
        "Abstract": "Educational data mining has been a veritable tool for predictive analytics which aids informed decision making and policy formulation tasks in the education industry. This study identifies relevant attributes from academic data of graduate teachers at a College of Education in Nigeria and develops a model that forecasts academic performance of teachers-in-training by assigning risk levels to their academic standing dataset. The model analyses success indicators from the list of attributes and assigned risk levels is a veritable tool for monitoring and evaluation of teachers-in-training by school administrators for an improved performance before graduation. The result shows that core courses offered in the first and second semesters of the second year of studentship have a healthy level of significance in forecasting teachers-in-training overall academic performance. Any deficient in such courses, therefore increases the risk level. A noteworthy discovery is the less significance of the teaching practice program, which assigns teachers-in-training to schools for six months, in determining their final academic standing on graduation.",
        "DOI": "10.1109/ICMCECS47690.2020.240897",
        "paper_author": "Olaleye T.O.",
        "affiliation_name": "Federal University of Agriculture, Abeokuta",
        "affiliation_city": "Abeokuta",
        "affiliation_country": "Nigeria",
        "affiliation_id": "60008386",
        "affiliation_state": "Ogun"
    },
    {
        "paper_title": "Opinion Mining on Food Services using Topic Modeling and Machine Learning Algorithms",
        "publication": "2020 6th International Conference on Advanced Computing and Communication Systems, ICACCS 2020",
        "citied_by": "9",
        "cover_date": "2020-03-01",
        "Abstract": "The development in technologies and the use of social media on a wide scale, has created opportunities for growth in analytics in obtaining useful insights from data with no proper schema. The use of opinion mining in the field of big data is used for categorizing the opinions of people or customers into different sentiments and to evaluate the mood of the customers. Opinion mining has gained significant importance over time due to the steep increase in amount of opinions available online. People share their opinions on products, services, movies, restaurants, schools, hospitals, holiday destinations etc. Social media has made it simple for users to share their opinion and make it available for any person on the Internet. The companies improve their strategy, products, marketing and services in order to detect latest trends and opportunities or to gauge how effective their marketing is. Several research attempts are being made at sentiment analysis to detect sentiment polarity and to perform predictive analytic. It is a research field which uses computer science and psychology. Natural Language Processing studies how machines can be used to comprehend a language and make it do meaningful things. The process of collecting public opinion and analyzing huge amount of social data has drawn great importance because of its real time behavior. A real time McDonald's dataset has been used for this work to determine the positive, negative and neutral reviews about the policies followed or violated by the restaurant. The people have posted their reviews as feedback of the service provided at McDonalds. McDonald's gets an enormous amount of customer comments on their website daily. Their employees don't have time to read every single comment, but they do want to read a subset of comments that they are most interested in. In particular, the media has recently portrayed their employees as being rude, and so they want to review comments about rude service. The objective of this workis to analyze every review of the user and classify if it is positive, negative or neutral in nature, which is called as opinion mining, using Machine Learning algorithms. Furthermore, topic modeling is done on the customer's reviews on the McDonald's services using LDA to find the frequently mentioned topics in their reviews. The classification of the emotions in the reviews are happy, sad, angry etc.",
        "DOI": "10.1109/ICACCS48705.2020.9074428",
        "paper_author": "Akila R.",
        "affiliation_name": "B.S.Abdur Rahman University",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60014273",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "A Review on Deep Learning Method for Intrusion Detection in Network Security",
        "publication": "2nd International Conference on Innovative Mechanisms for Industry Applications, ICIMIA 2020 - Conference Proceedings",
        "citied_by": "9",
        "cover_date": "2020-03-01",
        "Abstract": "In recent past, the evolution of enormous communication and many internet applications are run on the top of internet by considering cyber security as the important parameter. Gradually intruders determine new attack types and therefore to stop attacks are remaining as a main and major concern. Intrusion detection system (IDS) can either be a device or software helps to detect and monitor the network, system or device. This helps to detect malicious, suspicious activity or policy violation and send an alert to admin. Recently, deep learning, a subset of machine learning is related with algorithms that are based on the structure and function of brain is called artificial neural networks. The development in such learning algorithms may improve the functionality of intrusion detection (ID) in the network security. The proposed method implements an effective and enhanced ID for network security by using deep learning method with KDD dataset.",
        "DOI": "10.1109/ICIMIA48430.2020.9074975",
        "paper_author": "Shende S.",
        "affiliation_name": "Government College of Engineering, Amravati",
        "affiliation_city": "Amravati",
        "affiliation_country": "India",
        "affiliation_id": "60104095",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Uncovering hidden signals for sustainable investing using big data: Artificial intelligence, machine learning and natural language processing",
        "publication": "Journal of Risk Management in Financial Institutions",
        "citied_by": "18",
        "cover_date": "2020-03-01",
        "Abstract": "Risk managers and investors have increasingly been seeking high-quality environment, social and governance (ESG) data in order to assess nonfinancial risks as well as allocate capital towards companies that manage themselves in a ‘socially responsible’ way and adhere to their contract with society. The problem is that due to the lack of agreed-upon standards for companies to use for reporting on sustainability issues, there is a paucity of high-quality firm-level data to serve as key inputs in assessing a company’s risks and adherence to ESG criteria. Big Data, developed through cutting-edge statistical models, artificial intelligence (AI) and natural language processing (NLP) covering dozens of languages, provides the solution for ESG rankings and ratings and can help combat self-reported bias and ‘greenwashing’ and provide high-quality data. The ŉext generation’ measures of firms ‘doing good’ are the UN sustainable development goals (SDGs), which are this decade’s benchmarks against which millennials and many investors are beginning to assess companies. The SDGs go beyond the more narrowly focused set of sustainability issues embedded in ESGs, and quality data to measure performance against the SDGs are even more sparse. Using Big Data, Global AI Corporation uncovers data measuring companies’ and counties’ performance on all 17 SDGs, which can enable the integration of SDG factors into investment, risk management and national policy decision-making processes. Big Data is providing statistical indicators and performance metrics data to national governments and the United Nations to benchmark progress towards achieving the SDGs. It is also producing the SDG footprint of the private sector at the regional and global levels for policy purposes as shown in the United Nations Conference on Trade and Development’s (UNCTAD) SDG Pulse publication. Using Big Data, Global AI Corporation eliminates self-reporting biases and uncovers hidden data, which results in negative as well as positive ESG/SDG scores, while the self-reporting data only produces positive scores.",
        "DOI": "10.69554/cikj7477",
        "paper_author": "Antoncic M.",
        "affiliation_name": "Global AI Corporation",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "124357617",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "The impact of intelligent cyber-physical systems on the decarbonization of energy",
        "publication": "Energy and Environmental Science",
        "citied_by": "125",
        "cover_date": "2020-03-01",
        "Abstract": "The decarbonisation of energy provision is key to managing global greenhouse gas emissions and hence mitigating climate change. Digital technologies such as big data, machine learning, and the Internet of Things are receiving more and more attention as they can aid the decarbonisation process while requiring limited investments. The orchestration of these novel technologies, so-called cyber-physical systems (CPS), provides further, synergetic effects that increase efficiency of energy provision and industrial production, thereby optimising economic feasibility and environmental impact. This comprehensive review article assesses the current as well as the potential impact of digital technologies within CPS on the decarbonisation of energy systems. Ad hoc calculation for selected applications of CPS and its subsystems estimates not only the economic impact but also the emission reduction potential. This assessment clearly shows that digitalisation of energy systems using CPS completely alters the marginal abatement cost curve (MACC) and creates novel pathways for the transition to a low-carbon energy system. Moreover, the assessment concludes that when CPS are combined with artificial intelligence (AI), decarbonisation could potentially progress at an unforeseeable pace while introducing unpredictable and potentially existential risks. Therefore, the impact of intelligent CPS on systemic resilience and energy security is discussed and policy recommendations are deducted. The assessment shows that the potential benefits clearly outweigh the latent risks as long as these are managed by policy makers.",
        "DOI": "10.1039/c9ee01919g",
        "paper_author": "Inderwildi O.",
        "affiliation_name": "Akademie der Naturwissenschaften Schweiz",
        "affiliation_city": "Bern",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60005426",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modified SEIR and AI prediction of the epidemics trend of COVID-19 in China under public health interventions",
        "publication": "Journal of Thoracic Disease",
        "citied_by": "1114",
        "cover_date": "2020-03-01",
        "Abstract": "Background: The coronavirus disease 2019 (COVID-19) outbreak originating in Wuhan, Hubei province, China, coincided with chunyun, the period of mass migration for the annual Spring Festival. To contain its spread, China adopted unprecedented nationwide interventions on January 23 2020. These policies included large-scale quarantine, strict controls on travel and extensive monitoring of suspected cases. However, it is unknown whether these policies have had an impact on the epidemic. We sought to show how these control measures impacted the containment of the epidemic. Methods: We integrated population migration data before and after January 23 and most updated COVID-19 epidemiological data into the Susceptible-Exposed-Infectious-Removed (SEIR) model to derive the epidemic curve. We also used an artificial intelligence (AI) approach, trained on the 2003 SARS data, to predict the epidemic. Results: We found that the epidemic of China should peak by late February, showing gradual decline by end of April. A five-day delay in implementation would have increased epidemic size in mainland China three-fold. Lifting the Hubei quarantine would lead to a second epidemic peak in Hubei province in mid-March and extend the epidemic to late April, a result corroborated by the machine learning prediction. Conclusions: Our dynamic SEIR model was effective in predicting the COVID-19 epidemic peaks and sizes. The implementation of control measures on January 23 2020 was indispensable in reducing the eventual COVID-19 epidemic size.",
        "DOI": "10.21037/jtd.2020.02.64",
        "paper_author": "Yang Z.",
        "affiliation_name": "Guangzhou Medical University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60013156",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Analysis of risk factors and symptoms of burnout syndrome in colombian school teachers under statutes 2277 and 1278 using machine",
        "publication": "Social Sciences",
        "citied_by": "9",
        "cover_date": "2020-03-01",
        "Abstract": "In 2002, the Colombian ministry of education released statute 1278, for teaching professionalization, superseding statute 2277 of 1977. Although statute 1278 was intended to increase the quality of the education service and teachers' remuneration, there is evidence that the abundant evaluations and hindered promotion system introduced by statute 1278 resulted in an impairment of the quality of life of the teachers, and a higher incidence of burnout syndrome. We used two techniques for machine learning interpretability, SHapley Additive exPlanation summary plots and predictor importance, to interpret support vector machine and decision tree machine learning models, respectively, to better understand the differences on risk factors and symptoms of burnout syndrome in school teachers under statutes 2277 and 1278. We have surveyed 54 school teachers between August and October 2018, 17 under statute 2277, and 37 under statute 1278. Among the risk factors and symptoms of burnout syndrome considered in this study, we found that the satisfaction with earnt income was the most relevant risk factor, followed by the overtime work and the perceived severity of the sanctions on lower performance. The most relevant symptoms of burnout were fatigue at the end of the day, and frequent headaches. This methodology can be potentially used in other contexts and social groups, allowing institutional authorities and policy makers to allocate resources to specific issues affecting a particular group of workers.",
        "DOI": "10.3390/socsci9030030",
        "paper_author": "Posada-Quintero H.F.",
        "affiliation_name": "University of Connecticut",
        "affiliation_city": "Storrs",
        "affiliation_country": "United States",
        "affiliation_id": "60022659",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Mapping Maize Fields by Using Multi-Temporal Sentinel-1A and Sentinel-2A Images in Makarfi, Northern Nigeria, Africa",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "36",
        "cover_date": "2020-03-01",
        "Abstract": "A timely and accurate crop type mapping is very significant, and a prerequisite for agricultural regions and ensuring global food security. The combination of remotely sensed optical and radar datasets presents an opportunity for acquiring crop information at relative spatial resolution and temporal resolution adequately to capture the growth profiles of various crop species. In this paper, we employed Sentinel-1A (S-1) and Sentinel-2A (S-2) data acquired between the end of June and early September 2016, on a semi-arid area in northern Nigeria. A different set of (VV and VH) SAR and optical (SI and SB) images, illustrating crop phenological development stage, were employed as inputs to the two machines learning Random Forest (RF) and Support Vector Machine (SVM) algorithms to automatically map maize fields. Significant increases in overall classification were shown when the multi-temporal spectral indices (SI) and spectral band (SB) datasets were added with the different integration of SAR datasets (i.e., VV and VH). The best overall accuracy (OA) for maize (96.93%) was derived by using RF classification algorithms with SI-SB-SAR datasets, although the SI datasets for RF and SB datasets for SVM also produced high overall maize classification accuracies, of 97.04% and 97.44%. The outcomes indicate the robustness of the RF or SVM methods to produce high-resolution maps of maize for subsequent application from agronomists, policy planners, and the government, because such information is lacking in our study area.",
        "DOI": "10.3390/su12062539",
        "paper_author": "Abubakar G.A.",
        "affiliation_name": "College of Environmental and Resource Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117779",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Decision-making techniques for credit resource management using machine learning and optimization",
        "publication": "Information (Switzerland)",
        "citied_by": "20",
        "cover_date": "2020-03-01",
        "Abstract": "Credit operations are fundamental in the banks' activities and provide a significant share of their income. Under an increased demand for credit resources, credit risks are growth. It keeps the importance of the problem of an increase in the efficiency of lending management processes in financial institutions. The aim of the work is the justification and development of new technology and models for the management of bank lending that reduce credit risks and increases lending efficiency. The research materials are statistical data from the Bank of Russia and Rosstat. The methods of system analysis, methods of control theory, methods of statistics, optimization methods and machine learning are used. The positive results of the implementation of the proposed technology and credit management models are of practical importance to ensure the profitability growth of credit organization and contribute to its competitiveness.",
        "DOI": "10.3390/info11030144",
        "paper_author": "Orlova E.V.",
        "affiliation_name": "Ufa University of Science and Technology",
        "affiliation_city": "Ufa",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60277054",
        "affiliation_state": "Bashkortostan Republic"
    },
    {
        "paper_title": "Reinforcement learning for suppression of collective activity in oscillatory ensembles",
        "publication": "Chaos",
        "citied_by": "24",
        "cover_date": "2020-03-01",
        "Abstract": "We present the use of modern machine learning approaches to suppress self-sustained collective oscillations typically signaled by ensembles of degenerative neurons in the brain. The proposed hybrid model relies on two major components: an environment of oscillators and a policy-based reinforcement learning block. We report a model-agnostic synchrony control based on proximal policy optimization and two artificial neural networks in an Actor-Critic configuration. A class of physically meaningful reward functions enabling the suppression of collective oscillatory mode is proposed. The synchrony suppression is demonstrated for two models of neuronal populations-for the ensembles of globally coupled limit-cycle Bonhoeffer-van der Pol oscillators and for the bursting Hindmarsh-Rose neurons using rectangular and charge-balanced stimuli.",
        "DOI": "10.1063/1.5128909",
        "paper_author": "Krylov D.",
        "affiliation_name": "Skolkovo Institute of Science and Technology",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60107405",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Cognitive Action Laws: The Case of Visual Features",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "10",
        "cover_date": "2020-03-01",
        "Abstract": "This paper proposes a theory for understanding perceptual learning processes within the general framework of laws of nature. Artificial neural networks are regarded as systems whose connections are Lagrangian variables, namely, functions depending on time. They are used to minimize the cognitive action, an appropriate functional index that measures the agent interactions with the environment. The cognitive action contains a potential and a kinetic term that nicely resemble the classic formulation of regularization in machine learning. A special choice of the functional index, which leads to the fourth-order differential equations - Cognitive Action Laws (CAL) - exhibits a structure that mirrors classic formulation of machine learning. In particular, unlike the action of mechanics, the stationarity condition corresponds with the global minimum. Moreover, it is proven that typical asymptotic learning conditions on the weights can coexist with the initialization provided that the system dynamics is driven under a policy referred to as information overloading control. Finally, the theory is experimented for the problem of feature extraction in computer vision.",
        "DOI": "10.1109/TNNLS.2019.2911174",
        "paper_author": "Betti A.",
        "affiliation_name": "Università degli Studi di Firenze",
        "affiliation_city": "Florence",
        "affiliation_country": "Italy",
        "affiliation_id": "60021859",
        "affiliation_state": "FI"
    },
    {
        "paper_title": "Retraction notice to “Uncalibrated dynamic visual servoing via multivariate adaptive regression splines and improved incremental extreme learning machine” [ISA Transactions 92 (2019) 298–314] (ISA Transactions (2019) 92 (298–314), (S0019057819301089), (10.1016/j.isatra.2019.02.029))",
        "publication": "ISA Transactions",
        "citied_by": "0",
        "cover_date": "2020-03-01",
        "Abstract": "This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the authors and with the Editor-in-Chief's approval due to errors in Figures 9–10 under Section 6. The authors apologise for the inconvenience caused to readers.",
        "DOI": "10.1016/j.isatra.2020.02.021",
        "paper_author": "Zhou Z.",
        "affiliation_name": "Zhejiang Sci-Tech University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60103821",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "A novel load scheduling mechanism using artificial neural network based customer profiles in smart grid",
        "publication": "Energies",
        "citied_by": "18",
        "cover_date": "2020-03-01",
        "Abstract": "In most demand response (DR) based residential load management systems, shifting a considerable amount of load in low price intervals reduces end user cost, however, it may create rebound peaks and user dissatisfaction. To overcome these problems, this work presents a novel approach to optimizing load demand and storage management in response to dynamic pricing using machine learning and optimization algorithms. Unlike traditional load scheduling mechanisms, the proposed algorithm is based on finding suggested low tariff area using artificial neural network (ANN). Where the historical load demand individualized power consumption profiles of all users and real time pricing (RTP) signal are used as input parameters for a forecasting module for training and validating the network. In a response, the ANN module provides a suggested low tariff area to all users such that the electricity tariff below the low tariff area is market based. While the users are charged high prices on the basis of a proposed load based pricing policy (LBPP) if they violate low tariff area, which is based on RTP and inclining block rate (IBR). However, we first developed the mathematical models of load, pricing and energy storage systems (ESS), which are an integral part of the optimization problem. Then, based on suggested low tariff area, the problem is formulated as a linear programming (LP) optimization problem and is solved by using both deterministic and heuristic algorithms. The proposed mechanism is validated via extensive simulations and results show the effectiveness in terms of minimizing the electricity bill as well as intercepting the creation of minimal-price peaks. Therefore, the proposed energy management scheme is beneficial to both end user and utility company.",
        "DOI": "10.3390/en13051062",
        "paper_author": "Khalid Z.",
        "affiliation_name": "University of Lahore",
        "affiliation_city": "Lahore",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60070610",
        "affiliation_state": "Punjab"
    },
    {
        "paper_title": "Toward Distributed Energy Services: Decentralizing Optimal Power Flow with Machine Learning",
        "publication": "IEEE Transactions on Smart Grid",
        "citied_by": "70",
        "cover_date": "2020-03-01",
        "Abstract": "The implementation of optimal power flow (OPF) methods to perform voltage and power flow regulation in electric networks is generally believed to require extensive communication. We consider distribution systems with multiple controllable Distributed Energy Resources (DERs) and present a data-driven approach to learn control policies for each DER to reconstruct and mimic the solution to a centralized OPF problem from solely locally available information. Collectively, all local controllers closely match the centralized OPF solution, providing near-optimal performance and satisfaction of system constraints. A rate distortion framework enables the analysis of how well the resulting fully decentralized control policies are able to reconstruct the OPF solution. The methodology provides a natural extension to decide what nodes a DER should communicate with to improve the reconstruction of its individual policy. The method is applied on both single- and three-phase test feeder networks using data from real loads and distributed generators, focusing on DERs that do not exhibit intertemporal dependencies. It provides a framework for Distribution System Operators to efficiently plan and operate the contributions of DERs to achieve Distributed Energy Services in distribution networks.",
        "DOI": "10.1109/TSG.2019.2935711",
        "paper_author": "Dobbe R.",
        "affiliation_name": "New York University",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60021784",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Who Voted in 2016? Using Fuzzy Forests to Understand Voter Turnout",
        "publication": "Social Science Quarterly",
        "citied_by": "5",
        "cover_date": "2020-03-01",
        "Abstract": "Objective: What can machine learning tell us about who voted in 2016? There are numerous competing voter turnout theories, and a large number of covariates are required to assess which theory best explains turnout. This article is a proof of concept that machine learning can help overcome this curse of dimensionality and reveal important insights in studies of political phenomena. Methods: We use fuzzy forests, an extension of random forests, to screen variables for a parsimonious but accurate prediction. Fuzzy forests achieve accurate variable importance measures in the face of high-dimensional and highly correlated data. The data that we use are from the 2016 Cooperative Congressional Election Study. Results: Fuzzy forests chose only a small number of covariates as major correlates of 2016 turnout and still boasted high predictive performance. Conclusion: Our analysis provides three important conclusions about turnout in 2016: registration and voting procedures were important, political issues were important (especially Obamacare, climate change, and fiscal policy), but few demographic variables other than age were strongly associated with turnout. We conclude that fuzzy forests is an important methodology for studying overdetermined questions in social sciences.",
        "DOI": "10.1111/ssqu.12777",
        "paper_author": "Kim S.y.S.",
        "affiliation_name": "California Institute of Technology",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States",
        "affiliation_id": "60031581",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A Machine Learning Approach to 5G Infrastructure Market Optimization",
        "publication": "IEEE Transactions on Mobile Computing",
        "citied_by": "88",
        "cover_date": "2020-03-01",
        "Abstract": "It is now commonly agreed that future 5G Networks will build upon the network slicing concept. The ability to provide virtual, logically independent 'slices' of the network will also have an impact on the models that will sustain the business ecosystem. Network slicing will open the door to new players: the infrastructure provider, which is the owner of the infrastructure, and the tenants, which may acquire a network slice from the infrastructure provider to deliver a specific service to their customers. In this new context, how to correctly handle resource allocation among tenants and how to maximize the monetization of the infrastructure become fundamental problems that need to be solved. In this paper, we address this issue by designing a network slice admission control algorithm that (ii) autonomously learns the best acceptance policy while (iiii) it ensures that the service guarantees provided to tenants are always satisfied. The contributions of this paper include: (ii) an analytical model for the admissibility region of a network slicing-capable 5G Network, (iiii) the analysis of the system (modeled as a Semi-Markov Decision Process) and the optimization of the infrastructure providers revenue, and (iiiiii) the design of a machine learning algorithm that can be deployed in practical settings and achieves close to optimal performance.",
        "DOI": "10.1109/TMC.2019.2896950",
        "paper_author": "Bega D.",
        "affiliation_name": "IMDEA Networks Institute",
        "affiliation_city": "Leganes",
        "affiliation_country": "Spain",
        "affiliation_id": "60108460",
        "affiliation_state": "Madrid"
    },
    {
        "paper_title": "Impressions of digital soil maps: The good, the not so good, and making them ever better",
        "publication": "Geoderma Regional",
        "citied_by": "98",
        "cover_date": "2020-03-01",
        "Abstract": "Since the turn of the millennium, digital soil mapping (DSM) has revolutionized the production of fine resolution gridded soil data with associated uncertainty. However, the link to conventional soil maps has not been sufficiently explained nor are the approaches complementary and synergistic. Further training on the digital soil mapping approaches, and associated strengths and weaknesses is required. The user community requires training in, and experience with, the new digital soil map products, especially about the use of uncertainties for risk modelling and policy development. Standards are required for public and private sector digital soil map products to prevent the production of poor-quality information which will become misleading and counter-productive. Machine-learning methods are to be used with caution with respect to their interpretability and parsimony. The use of DSM products for improved pedological understanding and soil survey interpretations requires urgent investigation.",
        "DOI": "10.1016/j.geodrs.2020.e00255",
        "paper_author": "Arrouays D.",
        "affiliation_name": "Unité Info&amp;Sols",
        "affiliation_city": "Orleans",
        "affiliation_country": "France",
        "affiliation_id": "60280688",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Identification of risk factors for early psychiatric rehospitalization",
        "publication": "Psychiatry Research",
        "citied_by": "8",
        "cover_date": "2020-03-01",
        "Abstract": "Identifying risk factors for early psychiatric rehospitalization (EPR, rehospitalization within 90 days) can inform strategies to reduce rehospitalization rates. Random forest (RF), a tree-based classification algorithm, can be useful for identifying potential risk factors for EPR from a large number of patient factors. Patient characteristics were collected from 519 psychiatric inpatients at eight New York City hospitals. RF was used to identify potential risk factors for EPR. Multiple logistic regression was performed to assess the association between the identified risk factors and rehospitalization. Top risk factors identified by RF were previous psychiatric hospitalizations, number of post-discharge needs, social isolation, and sense of belonging in one's community. Follow-up analyses confirmed the significant association between EPR and number of previous psychiatric hospitalizations, number of endorsed post-discharge needs, and social isolation after adjusting for demographic variables. Understanding the contributors to EPR can better inform mental health service planning, policies, and programs that promote recovery.",
        "DOI": "10.1016/j.psychres.2020.112803",
        "paper_author": "Zhao Y.",
        "affiliation_name": "NYC Department of Health and Mental Hygiene",
        "affiliation_city": "Long Island City",
        "affiliation_country": "United States",
        "affiliation_id": "120958574",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Adaptive cache pre-forwarding policy for distributed deep learning",
        "publication": "Computers and Electrical Engineering",
        "citied_by": "2",
        "cover_date": "2020-03-01",
        "Abstract": "With the rapid growth of deep learning algorithms, several high-accuracy models have been developed and applied to many real-world domains. Deep learning is parallel and suitable for distributed computing, which can significantly improve the system throughput. However, there is a bottleneck for cross-machine training, that is, network latency. Nodes frequently need to wait for synchronization, and the content of each synchronization may range from several megabytes to hundred megabytes. Thus, network communication takes considerable time in the training process, which reduces system performance. Therefore, many computing architectures have been proposed. This paper proposes a type of distributed computing system for deep learning. Our design aims to reduce synchronization times and network blocking times by using a new cache mechanism, called cache pre-forwarding. The design concept of cache pre-forwarding aims to exploit reinforcement learning to train a pre-forwarding policy to increase the cache hit rate. Because of the features of reinforcement learning, our policy is adaptive and applicable to different computing environments. Finally, we experimentally demonstrate that our system is feasible.",
        "DOI": "10.1016/j.compeleceng.2020.106558",
        "paper_author": "Cheng S.T.",
        "affiliation_name": "National Cheng Kung University",
        "affiliation_city": "Tainan",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60014982",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Big data, traditional data and the tradeoffs between prediction and causality in highway-safety analysis",
        "publication": "Analytic Methods in Accident Research",
        "citied_by": "261",
        "cover_date": "2020-03-01",
        "Abstract": "The analysis of highway accident data is largely dominated by traditional statistical methods (standard regression-based approaches), advanced statistical methods (such as models that account for unobserved heterogeneity), and data-driven methods (artificial intelligence, neural networks, machine learning, and so on). These methods have been applied mostly using data from observed crashes, but this can create a problem in uncovering causality since individuals that are inherently riskier than the population as a whole may be over-represented in the data. In addition, when and where individuals choose to drive could affect data analyses that use real-time data since the population of observed drivers could change over time. This issue, the nature of the data, and the implementation target of the analysis imply that analysts must often tradeoff the predictive capability of the resulting analysis and its ability to uncover the underlying causal nature of crash-contributing factors. The selection of the data-analysis method is often made without full consideration of this tradeoff, even though there are potentially important implications for the development of safety countermeasures and policies. This paper provides a discussion of the issues involved in this tradeoff with regard to specific methodological alternatives and presents researchers with a better understanding of the trade-offs often being inherently made in their analysis.",
        "DOI": "10.1016/j.amar.2020.100113",
        "paper_author": "Mannering F.",
        "affiliation_name": "University of South Florida, Tampa",
        "affiliation_city": "Tampa",
        "affiliation_country": "United States",
        "affiliation_id": "60007740",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Autonomous power management with double-q reinforcement learning method",
        "publication": "IEEE Transactions on Industrial Informatics",
        "citied_by": "44",
        "cover_date": "2020-03-01",
        "Abstract": "Energy efficiency and autonomous power management are extremely important for mobile-edge computing. Reducing energy consumption of a number of applications running concurrently in mobile devices while maintaining performance poses a challenge to energy optimization due to the limited capacity of the embedded battery. To extend battery life and offer a long-lasting working energy, dynamic voltage and frequency scaling (DVFS) has been widely used in mobile devices for energy consumption minimization. However, most conventional DVFS techniques scale operating frequency based on static policies, and thus, they are difficult to be adapted to systems of varied conditions. In order to improve adaptivity, in this article, we proposed a Double-Q power management approach to scale operating frequency based on learning. The Double-Q method stores two Q tables and two corresponding update functions. In each decision point, either of Q tables is randomly chosen and updated, while the other is used for the measurement. This mechanism reduces the overestimation in Q values, consequently enhancing the accurateness of frequency predictions. To evaluate the effectiveness of our proposed approach, a Double-Q governor is implemented in the Linux kernel. Our approach is computationally light, and experimental results indicate that it achieves at least 5-18\\% total energy saving compared to ondemand and conservative governors, as well as Q learning-based method.",
        "DOI": "10.1109/TII.2019.2953932",
        "paper_author": "Huang H.",
        "affiliation_name": "St. Francis Xavier University",
        "affiliation_city": "Antigonish",
        "affiliation_country": "Canada",
        "affiliation_id": "60032048",
        "affiliation_state": "NS"
    },
    {
        "paper_title": "Deep Reinforcement Learning-Based Edge Caching in Wireless Networks",
        "publication": "IEEE Transactions on Cognitive Communications and Networking",
        "citied_by": "133",
        "cover_date": "2020-03-01",
        "Abstract": "With the purpose to offload data traffic in wireless networks, content caching techniques have recently been studied intensively. Using these techniques and caching a portion of the popular files at the local content servers, the users can be served with less delay. Most of the content replacement policies are based on the content popularity, that depends on the users' preferences. In practice, such information varies over time. Therefore, an approach to determine the file popularity patterns must be incorporated into caching policies. In this context, we study content caching at the wireless network edge using a deep reinforcement learning framework with Wolpertinger architecture. In particular, we propose deep actor-critic reinforcement learning based policies for both centralized and decentralized content caching. For centralized edge caching, we aim at maximizing the cache hit rate. In decentralized edge caching, we consider both the cache hit rate and transmission delay as performance metrics. The proposed frameworks are assumed to neither have any prior information on the file popularities nor know the potential variations in such information. Via simulation results, the superiority of the proposed frameworks is verified by comparing them with other policies, including least frequently used (LFU), least recently used (LRU), and first-in-first-out (FIFO) policies.",
        "DOI": "10.1109/TCCN.2020.2968326",
        "paper_author": "Zhong C.",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Syracuse",
        "affiliation_country": "United States",
        "affiliation_id": "60148874",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Using Artificial Neural Network techniques to improve the description and prediction of household financial ratios",
        "publication": "Journal of Behavioral and Experimental Finance",
        "citied_by": "25",
        "cover_date": "2020-03-01",
        "Abstract": "The purpose of the study described in this paper was to shed light on the need for alternative methods to improve descriptions and predictions of household financial ratios. Using data from the 2013, 2015, and 2017 Panel Study of Income Dynamics (PSID), this study examined the descriptive and predictive power of an Artificial Neural Network (ANN) model and an Ordinary Least Squares (OLS) model when evaluating household savings-to-income ratios and debt-to-asset ratios cross-sectionally and across time. Results suggest that ANN models provide a better overall model fit when describing and forecasting financial ratios. Findings confirm that machine learning procedures can provide a robust, efficient, and effective analytic method when an educator, researcher, financial service professional, lender, or policy maker needs to describe and/or predict a household's future financial situation. Suggestions for the implementation of ANN modeling procedures by household finance researchers, practitioners, and policy makers are provided.",
        "DOI": "10.1016/j.jbef.2020.100273",
        "paper_author": "Heo W.",
        "affiliation_name": "South Dakota State University",
        "affiliation_city": "Brookings",
        "affiliation_country": "United States",
        "affiliation_id": "60014826",
        "affiliation_state": "SD"
    },
    {
        "paper_title": "Reinforcement learning in dual-arm trajectory planning for a free-floating space robot",
        "publication": "Aerospace Science and Technology",
        "citied_by": "122",
        "cover_date": "2020-03-01",
        "Abstract": "A free-floating space robot exhibits strong dynamic coupling between the arm and the base, and the resulting position of the end of the arm depends not only on the joint angles but also on the state of the base. Dynamic modeling is complicated for multiple degree of freedom (DOF) manipulators, especially for a space robot with two arms. Therefore, the trajectories are typically planned offline and tracked online. However, this approach is not suitable if the target has relative motion with respect to the servicing space robot. To handle this issue, a model-free reinforcement learning strategy is proposed for training a policy for online trajectory planning without establishing the dynamic and kinematic models of the space robot. The model-free learning algorithm learns a policy that maps states to actions via trial and error in a simulation environment. With the learned policy, which is represented by a feedforward neural network with 2 hidden layers, the space robot can schedule and perform actions quickly and can be implemented for real-time applications. The feasibility of the trained policy is demonstrated for both fixed and moving targets.",
        "DOI": "10.1016/j.ast.2019.105657",
        "paper_author": "Wu Y.H.",
        "affiliation_name": "Nanjing University of Aeronautics and Astronautics",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60021666",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Stochastic dispatch of energy storage in microgrids: An augmented reinforcement learning approach",
        "publication": "Applied Energy",
        "citied_by": "76",
        "cover_date": "2020-03-01",
        "Abstract": "The dynamic dispatch (DD) of battery energy storage systems (BESSs) in microgrids integrated with volatile energy resources is essentially a multiperiod stochastic optimization problem (MSOP). Because the life span of a BESS is significantly affected by its charging and discharging behaviors, its lifecycle degradation costs should be incorporated into the DD model of BESSs, which makes it non-convex. In general, this MSOP is intractable. To solve this problem, we propose a reinforcement learning (RL) solution augmented with Monte-Carlo tree search (MCTS) and domain knowledge expressed as dispatching rules. In this solution, the Q-learning with function approximation is employed as the basic learning architecture that allows multistep bootstrapping and continuous policy learning. To improve the computation efficiency of randomized multistep simulations, we employed the MCTS to estimate the expected maximum action values. Moreover, we embedded a few dispatching rules in RL as probabilistic logics to reduce infeasible action explorations, which can improve the quality of the data-driven solution. Numerical test results show the proposed algorithm outperforms other baseline RL algorithms in all cases tested.",
        "DOI": "10.1016/j.apenergy.2019.114423",
        "paper_author": "Shang Y.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data Analytics in Asset Management: Cost-Effective Prediction of the Pavement Condition Index",
        "publication": "Journal of Infrastructure Systems",
        "citied_by": "205",
        "cover_date": "2020-03-01",
        "Abstract": "Understanding the deterioration of roads is an important part of road asset management. In this study, the long-term pavement performance (LTPP) data and machine learning algorithms were used to predict the deterioration in the pavement condition index (PCI) over 2, 3, 5, and 6 years. In selecting the attributes for conducting the analysis, we targeted ones that are freely available. This approach can help smaller municipalities, which could be short on money or required expertise. For larger ones and transportation agencies, this can save the increasingly significant costs for collecting field data and any associated safety or traffic implications. In addition, we used this category of attributes to better examine the role of data analytics in asset management. Without considering a causal model, can trends in data help assess deterioration in the PCI? Several models using combinations of 15 attributes were learned and tested. The algorithms used in this study were two types of decision trees and their boosted models based on gradient boosted trees. The accuracy of the ensemble of boosted classifiers was considerably higher than their base learners, with some reaching over 80% in predicting unseen data. We also found that dividing data into different climatic zones can change the relative importance of attributes and the overall accuracy of the models. Increasing the prediction span reduces accuracy, while reducing the number of prediction classes (levels of deterioration) increases the accuracy. In addition to automating the calculation and prediction of PCI, this study presented informative or important attributes for prediction. Such analyses could help municipalities and departments of transportations with forming a more effective policy for data collection and management.",
        "DOI": "10.1061/(ASCE)IS.1943-555X.0000512",
        "paper_author": "Piryonesi S.M.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "The implications of a fundamental contradiction in advocating randomized trials for policy",
        "publication": "World Development",
        "citied_by": "8",
        "cover_date": "2020-03-01",
        "Abstract": "Ethical concerns aside, there is nothing inherently wrong with using randomized control trials for intellectual inquiry in development economics. A fundamental problem arises, however, in claiming that results from experimental and quasi-experimental methods are more credible than other sources of evidence for policy. Specifically, there is a contradiction between rejecting econometric assumptions required for identifying causal relationships using non-experimental data, and accepting assumptions required for extrapolating experimental results for policy. I explain this tension and its implications, then discuss recent efforts – including the use of replication and machine learning methods – to circumvent it. Such attempts remain inadequate, and assertions in the 2019 Nobel Award are therefore either premature or misplaced. Use of pluralistic approaches negates these sharp contradictions, but requires abandoning any special status for experimental methods.",
        "DOI": "10.1016/j.worlddev.2019.104831",
        "paper_author": "Muller S.",
        "affiliation_name": "University of Johannesburg",
        "affiliation_city": "Johannesburg",
        "affiliation_country": "South Africa",
        "affiliation_id": "60000717",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "A review on machine learning forecasting growth trends and their real-time applications in different energy systems",
        "publication": "Sustainable Cities and Society",
        "citied_by": "133",
        "cover_date": "2020-03-01",
        "Abstract": "Energy forecasting and planning play an important role in energy sector development and policy formulation. The forecasting model selection mostly based on the availability of the data, and the principal objective is the planning exercise and tool in different modern energy systems. Existing literature explicate that the supervised based machine learning algorithms are intelligent for predictions such as future load demand, wind, solar and geothermal energy forecasting, etc., across the wide range of applications. In this study, a comprehensive review is conducted on supervised based machine learning algorithms by using three well-known forecasting engines. This review aims to suggest suitable methods for forecasting analysis and several other prediciton tasks. A particular objective is to investigate and analyzed the methods used to forecast energy, real time use in multiple applications and to identify the research review with useful techniques that are approachable in the current literature. This review contains a critical comparison and study among various modeling techniques to choose a better forecasting model for performing the desired task in multiple applications. The forecasting accuracy is compared and analyzed through comprehensive literature review and with the real-time energy consumption and climate data used for modeling analysis. The Bayesian regularization backpropagation neural networks (BRBNNs) and the Levenberg Marquardt backpropagation neural networks (LMBNNs) render higher forecasting accuracy and performance with the coefficient of correlation 0.972 and 0.971 respectively. The supervised learning is useful for real-time applications because of optimal scenario of a specific model will allow for the model to precisely predict the label's class for unseen data instances. Additionally, the supervised learning can reduce the noise and control imbalanced data in the network formulation.",
        "DOI": "10.1016/j.scs.2019.102010",
        "paper_author": "Ahmad T.",
        "affiliation_name": "State Key Laboratory of Internet of Things for Smart City",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao",
        "affiliation_id": "60202520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Linking human-building interactions in shared offices with personality traits",
        "publication": "Building and Environment",
        "citied_by": "31",
        "cover_date": "2020-03-01",
        "Abstract": "Occupant behavior influences office building energy performance. The level of human-building interactions (HBIs) in shared offices strongly influences building energy use and occupant well-being. This study explored the link between occupant personality types and their behaviors of sharing energy and environment control systems and interactions with their colleagues. Inspired by the Five-Factor Model (FFM), we classified HBI behaviors into four dimensions: willingness to share control, knowledge of control, group decision behavior, and adaptive strategies. These four variables can be mapped to the four personality traits proposed by the FFM: agreeableness, openness, extraversion, and conscientiousness. Our cluster analysis identified six behavioral patterns: average (17.7%), reserved (15.3%), environmentally friendly (16.6%), role model (24.2%), self-centered (17.2%), and mechanist (9.0%). We further applied association rules, a widely utilized machine learning technique, to discover how demographics, building-related contextual factors, and perception-attitudinal factors influence HBI behaviors. Country, control feature accessibility, and group dynamics were found to be the three most influential factors that determine occupants’ HBI behaviors. The study provides insights about building design and operation, as well as policy to promote socially and environmentally desirable HBI behaviors in a shared office environment.",
        "DOI": "10.1016/j.buildenv.2019.106602",
        "paper_author": "Hong T.",
        "affiliation_name": "Lawrence Berkeley National Laboratory",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60007174",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Dealing with the game-changing technologies of Agriculture 4.0: How do we manage diversity and responsibility in food system transition pathways?",
        "publication": "Global Food Security",
        "citied_by": "377",
        "cover_date": "2020-03-01",
        "Abstract": "Agriculture 4.0 is comprised of different already operational or developing technologies such as robotics, nanotechnology, synthetic protein, cellular agriculture, gene editing technology, artificial intelligence, blockchain, and machine learning, which may have pervasive effects on future agriculture and food systems and major transformative potential. These technologies underpin con­cepts such as ver­ti­cal farm­ing and food systems, dig­i­tal agri­cul­ture, bioe­con­omy, cir­cu­lar agri­cul­ture, and aquapon­ics. In this perspective paper, we argue that more attention is needed for the inclusion and exclusion effects of Agriculture 4.0 technologies, and for reflection on how they relate to diverse transition pathways towards sustainable agricultural and food systems driven by mission-oriented innovation systems. This would require processes of responsible innovation, anticipating the potential impacts of Agriculture 4.0 through inclusive processes, and reflecting on and being responsive to emerging effects and where needed adjusting the direction and course of transition pathways.",
        "DOI": "10.1016/j.gfs.2019.100347",
        "paper_author": "Klerkx L.",
        "affiliation_name": "Wageningen University &amp; Research",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60004156",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Toward systems-centered analysis of patient safety events: Improving root cause analysis by optimized incident classification and information presentation",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "7",
        "cover_date": "2020-03-01",
        "Abstract": "Background: Systems-centered root cause analysis (RCA) of patient safety events presents unique advantages as it aims to disclose vulnerabilities of healthcare systems. However, the increasing number of collected events poses the problems of low efficiency and information overload for traditional RCA. Objectives: This study aims to improve systems-centered RCA by developing optimized information extraction and presentation. Methods: We experimented supervised machine-learning methods to extract safety-related information from 3333 de-identified patient safety event reports from two independent sources. Based on the extracted information, we further evaluated how optimized information presentation could help facilitate the disclosure of system vulnerabilities in traditional RCA. Results: Multilabel text classification is effective in identifying safety-related information from the narrative description of patient safety events. The Pruned Sets in conjunction with Naïve Bayes are the outperformed algorithm in one dataset, with an overall F score of 60.0 % and the highest F score of 96.0 % for identifying “Adverse Drug Reaction”. The Classifier Chains in conjunction with Naïve Bayes are the outperformed algorithm in another dataset, with an overall F score of 43.2 % and the highest F score of 64.0 % for identifying “Medication”. During the RCA, human experts applied the optimized presentation of information which showed advantages of identifying system vulnerabilities. Conclusion: Our study demonstrated the feasibility of using multilabel text classification for identifying safety-related information from the narrative description of patient safety events. The extracted information when grouped by safety-related information can better aid human experts to conduct systems-centered RCA and disclose system vulnerabilities.",
        "DOI": "10.1016/j.ijmedinf.2019.104054",
        "paper_author": "Liang C.",
        "affiliation_name": "University of South Carolina",
        "affiliation_city": "Columbia",
        "affiliation_country": "United States",
        "affiliation_id": "60018179",
        "affiliation_state": "SC"
    },
    {
        "paper_title": "Online model-free controller for flexible wing aircraft: a policy iteration-based reinforcement learning approach",
        "publication": "International Journal of Intelligent Robotics and Applications",
        "citied_by": "6",
        "cover_date": "2020-03-01",
        "Abstract": "The aerodynamic model of flexible wing aircraft is highly nonlinear with continuously time-varying dynamics under kinematic constraints. The nonlinearities stem from the aerodynamic forces and continuous deformations in the flexible wing. In spite of the various experimental attempts and theoretical setups that were made to model these dynamics, an accurate formulation was not achieved. The control paradigms of the aircraft are concerned with the electro-mechanical coupling between the pilot and the wing. It is challenging to design a flight controller for such aircraft while complying with these constraints. In this paper, innovative machine learning technique is employed to design a robust online model-free control scheme for flexible wing aircraft. The controller maintains internal asymptotic stability for the aircraft in real-time using selected set of measurements or states in uncertain dynamical environment. It intelligently incorporates the varying dynamics, geometric parameters, and physical constraints of the aircraft into optimal control strategies. The adaptive learning structure employs a policy iteration approach, taking advantage of Bellman optimality principles, to converge to an optimal control solution for the problem. Artificial neural networks are adopted to implement the adaptive learning algorithm in real-time without prior knowledge of the aerodynamic model of the aircraft. The control scheme is generalized and shown to function effectively for different pilot/wing control mechanisms. It also demonstrated its ability to overcome the undesired stability problems caused by coupling the pilot’s dynamics with the flexible wing’s frame of motion.",
        "DOI": "10.1007/s41315-019-00105-3",
        "paper_author": "Abouheaf M.",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60028897",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Optimal policy for structure maintenance: A deep reinforcement learning framework",
        "publication": "Structural Safety",
        "citied_by": "99",
        "cover_date": "2020-03-01",
        "Abstract": "The cost-effective management of aged infrastructure is an issue of worldwide concern. Markov decision process (MDP) models have been used in developing structural maintenance policies. Recent advances in the artificial intelligence (AI) community have shown that deep reinforcement learning (DRL) has the potential to solve large MDP optimization tasks. This paper proposes a novel automated DRL framework to obtain an optimized structural maintenance policy. The DRL framework contains a decision maker (AI agent) and the structure that needs to be maintained (AI task environment). The agent outputs maintenance policies and chooses maintenance actions, and the task environment determines the state transition of the structure and returns rewards to the agent under given maintenance actions. The advantages of the DRL framework include: (1) a deep neural network (DNN) is employed to learn the state-action Q value (defined as the predicted discounted expectation of the return for consequences under a given state-action pair), either based on simulations or historical data, and the policy is then obtained from the Q value; (2) optimization of the learning process is sample-based so that it can learn directly from real historical data collected from multiple bridges (i.e., big data from a large number of bridges); and (3) a general framework is used for different structure maintenance tasks with minimal changes to the neural network architecture. Case studies for a simple bridge deck with seven components and a long-span cable-stayed bridge with 263 components are performed to demonstrate the proposed procedure. The results show that the DRL is efficient at finding the optimal policy for maintenance tasks for both simple and complex structures.",
        "DOI": "10.1016/j.strusafe.2019.101906",
        "paper_author": "Wei S.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Artificial intelligence and sustainable development",
        "publication": "International Journal of Management Education",
        "citied_by": "386",
        "cover_date": "2020-03-01",
        "Abstract": "Artificial intelligence (AI) is rapidly opening up a new frontier in the fields of business, corporate practices, and governmental policy. The intelligence of machines and robotics with deep learning capabilities have created profound disrupting and enabling impacts on business, governments, and society. They are also influencing the larger trends in global sustainability. As the AI revolution transforms our world, it could herald a utopian future where humanity co-exists harmoniously with machines, or portend a dystopian world filled with conflict, poverty and suffering. More immediately, would AI accelerate our progress on the United Nations (UN) Sustainable Development Goals (SDGs) or bring us further down the path toward greater economic uncertainty, environmental collapse, and social upheaval? What are some of the implications for business leadership and the education of future business leaders? This article aims to address these questions by analyzing the impacts of AI in three case studies. It draws some preliminary inferences for management education and the business of leading corporations in the midst of rapid technological and social change. This study combines the perspectives of business strategy and public policy to analyze the impacts of AI on sustainable development with a specific focus on the advancement of the SDGs. It also draws some lessons on managerial learning and leadership development for global sustainability.",
        "DOI": "10.1016/j.ijme.2019.100330",
        "paper_author": "Goralski M.",
        "affiliation_name": "Quinnipiac University",
        "affiliation_city": "Hamden",
        "affiliation_country": "United States",
        "affiliation_id": "60016342",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Learning-Aided Intelligent Cooperative Collision Avoidance Mechanism in Dynamic Vessel Networks",
        "publication": "IEEE Transactions on Cognitive Communications and Networking",
        "citied_by": "10",
        "cover_date": "2020-03-01",
        "Abstract": "With the increasing traffic density and the highly maritime safety requirements, it is a great challenge to make the optimal motion decision for avoiding the collision in the complex vessel networks. However, the current collision avoidance mechanisms are only considering unilateral static information, ignoring the multilateral dynamic information, which is quite important. In this paper, we investigate the information transmission and the collision avoidance problem in the complex vessel networks, in which the devices are equipped with the capability of Artificial Intelligence (AI). With the empowered learning ability in the networks, we propose a novel two-step-smooth-turn cooperative collision avoidance mechanism for the dynamic vessel networks, considering the motion states of the vessels. In particular, the AI-powered vessels network motion model is designed, which can learn the motion information to predict the safety motion states by automatic collection of the information. Then, a K-Means algorithm combining with genetic algorithm is proposed by expanding the operation of cross genetic and genetic mutations, which can achieve the optimal multi-vessels coordination motion policy for the collision avoidance. Simulation results show that the proposed approach could improve the stability of genetic algorithm and weaken the early convergence of genetic algorithm efficiently. In addition, it shows that the proposed mechanism can achieve an optimal safety route plan for cooperative collision avoidance.",
        "DOI": "10.1109/TCCN.2019.2945790",
        "paper_author": "Yang T.",
        "affiliation_name": "Dongguan University of Technology",
        "affiliation_city": "Dongguan",
        "affiliation_country": "China",
        "affiliation_id": "60073518",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Application of deep reinforcement learning to intrusion detection for supervised problems",
        "publication": "Expert Systems with Applications",
        "citied_by": "246",
        "cover_date": "2020-03-01",
        "Abstract": "The application of new techniques to increase the performance of intrusion detection systems is crucial in modern data networks with a growing threat of cyber-attacks. These attacks impose a greater risk on network services that are increasingly important from a social end economical point of view. In this work we present a novel application of several deep reinforcement learning (DRL) algorithms to intrusion detection using a labeled dataset. We present how to perform supervised learning based on a DRL framework. The implementation of a reward function aligned with the detection of intrusions is extremely difficult for Intrusion Detection Systems (IDS) since there is no automatic way to identify intrusions. Usually the identification is performed manually and stored in datasets of network features associated with intrusion events. These datasets are used to train supervised machine learning algorithms for classifying intrusion events. In this paper we apply DRL using two of these datasets: NSL-KDD and AWID datasets. As a novel approach, we have made a conceptual modification of the classic DRL paradigm (based on interaction with a live environment), replacing the environment with a sampling function of recorded training intrusions. This new pseudo-environment, in addition to sampling the training dataset, generates rewards based on detection errors found during training. We present the results of applying our technique to four of the most relevant DRL models: Deep Q-Network (DQN), Double Deep Q-Network (DDQN), Policy Gradient (PG) and Actor-Critic (AC). The best results are obtained for the DDQN algorithm. We show that DRL, with our model and some parameter adjustments, can improve the results of intrusion detection in comparison with current machine learning techniques. Besides, the classifier obtained with DRL is faster than alternative models. A comprehensive comparison of the results obtained with other machine learning models is provided for the AWID and NSL-KDD datasets, together with the lessons learned from the application of several design alternatives to the four DRL models.",
        "DOI": "10.1016/j.eswa.2019.112963",
        "paper_author": "Lopez-Martin M.",
        "affiliation_name": "Universidad de Valladolid",
        "affiliation_city": "Valladolid",
        "affiliation_country": "Spain",
        "affiliation_id": "60024695",
        "affiliation_state": "Valladolid"
    },
    {
        "paper_title": "Behavior fusion for deep reinforcement learning",
        "publication": "ISA Transactions",
        "citied_by": "4",
        "cover_date": "2020-03-01",
        "Abstract": "For deep reinforcement learning (DRL) system, it is difficult to design a reward function for complex tasks, so this paper proposes a framework of behavior fusion for the actor–critic architecture, which learns the policy based on an advantage function that consists of two value functions. Firstly, the proposed method decomposes a complex task into several sub-tasks, and merges the trained policies for those sub-tasks into a unified policy for the complex task, instead of designing a new reward function and training for the policy. Each sub-task is trained individually by an actor–critic algorithm using a simple reward function. These pre-trained sub-tasks are building blocks that are used to rapidly assemble a rapid prototype of a complicated task. Secondly, the proposed method integrates modules in the calculation of the policy gradient by calculating the accumulated returns to reduce variation. Thirdly, two alternative methods to acquire integrated returns for the complicated task are also proposed. The Atari 2600 pong game and a wafer probe task are used to validate the performance of the proposed methods by comparison with the method using a gate network.",
        "DOI": "10.1016/j.isatra.2019.08.054",
        "paper_author": "Shi H.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Coordinated Load Control of Renewable Powered Small Base Stations Through Layered Learning",
        "publication": "IEEE Transactions on Green Communications and Networking",
        "citied_by": "17",
        "cover_date": "2020-03-01",
        "Abstract": "The massive deployment of Small Base Stations (SBSs) represents one of the most promising solutions adopted by 5G cellular networks to meet the foreseen huge traffic demand. The usage of renewable energies for powering the SBSs attracted particular attention for reducing the energy footprint and, thus, mitigating the environmental impact of mobile networks and enabling cost saving for the operators. The complexity of the system and the variability of the harvesting process suggest the adoption of learning methods. Here, we investigate techniques based on the Layered Learning paradigm to control dense networks of SBSs powered solely by solar energy. In the first layer, SBSs locally select switch ON/OFF policies according to their energy income and traffic demand based on a Heuristically Accelerated Reinforcement Learning method. The second layer relies on an Artificial Neural Network that estimates the network load conditions to implement a centralized controller enforcing local agent decisions. Simulation results prove that the control of the proposed framework mimics the behavior of the upper bound obtained offline with Dynamic Programming. Moreover, the proposed layered framework outperforms both a greedy and a distributed Reinforcement Learning solution in terms of throughput and energy efficiency under different traffic conditions.",
        "DOI": "10.1109/TGCN.2019.2938860",
        "paper_author": "Miozzo M.",
        "affiliation_name": "Centre Tecnológic de Telecomunicacions de Catalunya",
        "affiliation_city": "Castelldefels",
        "affiliation_country": "Spain",
        "affiliation_id": "60016688",
        "affiliation_state": "Barcelona"
    },
    {
        "paper_title": "Mobility-Aware Content Preference Learning in Decentralized Caching Networks",
        "publication": "IEEE Transactions on Cognitive Communications and Networking",
        "citied_by": "20",
        "cover_date": "2020-03-01",
        "Abstract": "Due to the drastic increase of mobile traffic, wireless caching is proposed to serve repeated requests for content download. To determine the caching scheme for decentralized caching networks, the content preference learning problem based on mobility prediction is studied. We first formulate preference prediction as a decentralized regularized multi-task learning (DRMTL) problem without considering the mobility of mobile terminals (MTs). The problem is solved by a hybrid Jacobian and Gauss-Seidel proximal multi-block alternating direction method (ADMM) based algorithm, which is proven to conditionally converge to the optimal solution with a rate {O} (1/ {k} ). Then we use the tool of Markov renewal process to predict the moving path and sojourn time for MTs, and integrate the mobility pattern with the DRMTL model by reweighting the training samples and introducing a transfer penalty in the objective. We solve the problem and prove that the developed algorithm has the same convergence property but with different conditions. Through simulation we show the convergence analysis on proposed algorithms. Our real trace driven experiments illustrate that the mobility-aware DRMTL model can provide a more accurate prediction on geography preference than DRMTL model. Besides, the hit ratio achieved by most popular proactive caching (MPC) policy with preference predicted by mobility-aware DRMTL outperforms the MPC with preference from DRMTL and random caching (RC) schemes.",
        "DOI": "10.1109/TCCN.2019.2937519",
        "paper_author": "Ye Y.",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60002014",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "Employing online social networks in precision-medicine approach using information fusion predictive model to improve substance use surveillance: A lesson from Twitter and marijuana consumption",
        "publication": "Information Fusion",
        "citied_by": "13",
        "cover_date": "2020-03-01",
        "Abstract": "The impact that connected community have on precision health or medicine and vice versa offers opportunities for any type of research and survey information, e. g, to predict trends in health-related issues, specifically people behavior towards drug use. Here, precision medicine influences the way to treat the information and get a better outcome to support the stakeholder decision. Online social networks analysis seems to be good tools to quickly monitor the population behavior where users freely share large amounts of information related to their own lives on day- to- day basis. This novel kind of data can be used to get additional real time insights from people to understand their actual behavior related to drug use (Cortés et al., 2017). The aim of this research is to generated an information fusion model of marijuana use tendency confident enough to be employed by stakeholders. So, we will: (a) collect and process the data from Twitter; (b) design a set of algorithms to estimate the tendency of marijuana use in relation to age, localization and gender, moreover, used a set of processes and activities to verify if our model were performing as expected; and (c) fusion of the information in a model to fully characterize the marijuana use population comparable to the national marijuana consume survey for policy makers utilization to improve drug use prevention. First,we collect the data from Twitter accounts based in Chile using an algorithm for traversing graph data structures, we collected the data from Twitter accounts based in Chile. Then, we estimated marijuana user prevalence during a period from 2006 to 2018 and, within each of the years we predicted the prevalence of user population in relation with age (in range), the localization (regions) and gender. Finally, we built indicators to explore the similarity between data obtained through Twitter (our results) and the actual data collected by the National Service for the Prevention and Rehabilitation of Drug and Alcohol (SENDA) under the same variables analyze in their own survey. When we compare the results of the algorithms and methods developed by us with those provided by the SENDA, we observed that most of the indicators present similar trends, i.e., the variation of the prevalence by years in the age, location and gender, showed similar changes in both analyzes. Also, the algorithms effectiveness and capacity to predict variations of complex cases like marijuana use in Chilean population. This study is a key opportunity to obtain in a faster, low cost and continuous way information about marijuana use, also, is an excellent tool for marijuana surveillance to get information to support policy makers and stakeholder decisions.",
        "DOI": "10.1016/j.inffus.2019.08.006",
        "paper_author": "Guiñazú M.F.",
        "affiliation_name": "Universidad de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile",
        "affiliation_id": "60012464",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Clustering subspace generalization to obtain faster reinforcement learning",
        "publication": "Evolving Systems",
        "citied_by": "4",
        "cover_date": "2020-03-01",
        "Abstract": "In reinforcement learning, very low and even lack of spatial generalization capability result in slow learning. Exploiting possible experience generalization in subspaces, a sub-dimension of the original state representation, is one approach to speed up learning in terms of required interactions. The target of this paper is to alleviate the detriment of the perceptual aliasing in the subspaces further to enhance the benefit of their generalization. We augment an extra dimension to the subspaces coming from a clustering process on the state-space. Through this framework, called Clustered-Model Based Learning with Subspaces (C-MoBLeS), states with similar policies are categorized to the same cluster and the agent can exploit the generalization of the subspace learning more by this localization. Therefore, the agent uses generalization of the subspaces which are in the cluster of the agent’s state. Several experiments show that C-MoBLeS increases the learning speed effectively.",
        "DOI": "10.1007/s12530-019-09290-9",
        "paper_author": "Hashemzadeh M.",
        "affiliation_name": "University of Tehran",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60022927",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Combining intelligent heuristics with simulators in hotel revenue management",
        "publication": "Annals of Mathematics and Artificial Intelligence",
        "citied_by": "13",
        "cover_date": "2020-03-01",
        "Abstract": "Revenue Management uses data-driven modelling and optimization methods to decide what to sell, when to sell, to whom to sell, and for which price, in order to increase revenue and profit. Hotel Revenue Management is a very complex context characterized by nonlinearities, many parameters and constraints, and stochasticity, in particular in the demand by customers. It suffers from the curse of dimensionality (Bellman 2015): when the number of variables increases (number of rooms, number possible prices and capacities, number of reservation rules and constraints) exact solutions by dynamic programming or by alternative global optimization techniques cannot be used and one has to resort to intelligent heuristics, i.e., methods which can improve current solutions but without formal guarantees of optimality. Effective heuristics can incorporate “learning” (“reactive” schemes) that update strategies based on the past history of the process, the past reservations received up to a certain time and the previous steps in the iterative optimization process. Different approaches can be classified according to the specific model considered (stochastic demand and hotel rules), the control mechanism (the pricing policy) and the optimization technique used to determine improving or optimal solutions. In some cases, model definitions, control mechanism and solution techniques are strongly interrelated: this is the case of dynamic programming, which demands suitably simplified problem formulations. We design a flexible discrete-event simulator for the hotel reservation process and experiment different approaches though measurements of the expected effect on profit (obtained by carefully separating a “training” phase from the final “validation” phase obtained from different simulations). The experimental results show the effectiveness of intelligent heuristics with respect to exact optimization methods like dynamic programming, in particular for more constrained situations (cases when demand tends to saturate hotel room availability), when the simplifying assumptions needed to make the problem analytically treatable do not hold.",
        "DOI": "10.1007/s10472-019-09651-9",
        "paper_author": "Brunato M.",
        "affiliation_name": "Università di Trento",
        "affiliation_city": "Trento",
        "affiliation_country": "Italy",
        "affiliation_id": "60015986",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Dynamic provisioning of resources based on load balancing and service broker policy in cloud computing",
        "publication": "Cluster Computing",
        "citied_by": "53",
        "cover_date": "2020-03-01",
        "Abstract": "Dynamic resource allocation is the key objective of the paper motivated due to a large number of user’s service request and increasing network infrastructure complexity. Load balancing and Service Broker Policy are taken as two main key areas for the dynamic provision of resources to the cloud user in order to meet the QoS requirement. While provisioning the resources, the conventional approaches degrade due to QoS performance limits such as time delay, energy, etc. To overcome those problems, we proposed a new approach to provide dynamic provisioning of resources based on load balancing and service brokering. Initially, the Multi-agent Deep Reinforcement Learning-Dynamic Resource Allocation (MADRL-DRA) is used in the Local User Agent (LUA) to predict the environmental activities of user task and allocate the task to the Virtual Machine (VM) based on priority. Next, a Load balancing (LB) is performed in the VM, which increases the throughput and reduces the response time in the resource allocation task. Secondly, the Dynamic Optimal Load-Aware Service Broker (DOLASB) is used in the Global User Agent (GUA) for scheduling the task and provide the services to the users based on the available cloud brokers (CBs). In the global agent, cloud brokers are the mediators between users and providers. The optimization problem in Global Agent (GA) is formulated by the programming of mixed integers, and Bender decomposition algorithm. The result of our proposed method is better as compared with the conventional techniques in terms of Execution Time, Waiting Time, Energy Efficiency, Throughput, Resource Usage, and Makespan.",
        "DOI": "10.1007/s10586-019-02928-y",
        "paper_author": "Jyoti A.",
        "affiliation_name": "JRN Rajasthan Vidyapeeth",
        "affiliation_city": "Udaipur",
        "affiliation_country": "India",
        "affiliation_id": "110625717",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Towards national-scale characterization of grassland use intensity from integrated Sentinel-2 and Landsat time series",
        "publication": "Remote Sensing of Environment",
        "citied_by": "112",
        "cover_date": "2020-03-01",
        "Abstract": "The increased availability of systematically acquired high spatial and temporal resolution optical imagery improves the characterization of dynamic land surface processes such as agriculture. The use of time series phenology can help overcome limitations of conventional classification-based mapping approaches encountered when, for example, attempting to characterize grassland use intensity. In Europe, permanent grasslands account for more than one third of all agricultural land and a considerable share of the EU Common Agricultural Policy (CAP) budget is devoted to grasslands. The frequency and timing of mowing events is an important proxy for grassland use intensity and methods that allow characterizing grassland use intensity at the parcel level and over large areas are urgently needed. Here we present a novel algorithm that allows detecting and quantifying the number and timing of mowing events in central European grasslands. The algorithm utilizes all imagery acquired by Sentinel-2 MSI and Landsat-8 OLI for one entire year as available from the NASA Harmonized Landsat-Sentinel dataset. Cloud-free observations from both sensors are first synthesized through compositing at 10-day interval. Machine learning algorithms are then used to derive a grassland stratum. The intra-annual growing season profiles of NDVI values are subsequently assessed and compared to an idealized growing season trajectory. Residuals between the idealized trajectory and a polynomial model fit to the observed NDVI values are then evaluated to detect potential mowing events. We demonstrate and evaluate the performance of our algorithm and utilize its large area analysis capabilities by mapping the frequency and timing of grassland mowing events in 2016 on the national-scale across Germany. Our results suggest that 25% of the grassland area is not used for mowing. Validation results however suggest a relatively high omission error of the algorithm for areas that only experienced a single mowing event. The date ranges of detected mowing events compare overall well to a sample of interpreted time series points and to farm level reports on mowing dates. The mapped mowing patterns depict typical management regimes across Germany. Overall, our results exemplify the value of multi-sensor time series applications for characterizing land use intensity across large areas.",
        "DOI": "10.1016/j.rse.2019.03.017",
        "paper_author": "Griffiths P.",
        "affiliation_name": "Humboldt-Universität zu Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60000762",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning budget assignment policies for autoscaling scientific workflows in the cloud",
        "publication": "Cluster Computing",
        "citied_by": "7",
        "cover_date": "2020-03-01",
        "Abstract": "Autoscalers exploit cloud-computing elasticity to cope with the dynamic computational demands of scientific workflows. Autoscalers constantly acquire or terminate virtual machines (VMs) on-the-fly to execute workflows minimizing makespan and economic cost. One key problem of workflow autoscaling under budget constraints (i.e. with a maximum limit in cost) is determining the right proportion between: (a) expensive but reliable VMs called on-demand instances, and (b) cheaper but subject-to-failure VMs called spot instances. Spot instances can potentially provide huge parallelism possibilities at low costs but they must be used wisely as they can fail unexpectedly hindering makespan. Given the unpredictability of failures and the inherent performance variability of clouds, designing a policy for assigning the budget for each kind of instance is not a trivial task. For such reason we formalize the described problem as a Markov decision process that allows us learning near-optimal policies from the experience of other baseline policies. Experiments over four well-known scientific workflows, demonstrate that learned policies outperform the baseline policies considering the aggregated relative percentage difference of makespan and execution cost. These promising results encourage the future study of new strategies aiming to find optimal budget policies applied to the execution of workflows in the cloud.",
        "DOI": "10.1007/s10586-018-02902-0",
        "paper_author": "Garí Y.",
        "affiliation_name": "Universidad Nacional de Cuyo",
        "affiliation_city": "Mendoza",
        "affiliation_country": "Argentina",
        "affiliation_id": "60022684",
        "affiliation_state": "Mendoza"
    },
    {
        "paper_title": "Hybrid model for twitter data sentiment analysis based on ensemble of dictionary based classifier and stacked machine learning classifiers-SVM, KNN and C5.0",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "15",
        "cover_date": "2020-02-29",
        "Abstract": "Social Networking sites like Twitter and Facebook has offered the possibility to users to express their opinion on various topics and events. Opinion mining is a technique to find the sentiment of people about these topics, which can be useful in decision support. Various government policies can also be monitored by doing the sentiment analysis of related tweets. The objective of this research is to enhance the accuracy of twitter sentiment classification. The paper proposes a framework for a hybrid approach with an ensemble of stacked machine learning algorithms and dictionary based classifier. Sentiment Score extracted from dictionary based classifier is added as additional feature in the feature set. Three machine learning algorithms SVM, KNN and C5.0 are stacked to build an ensemble by using two Meta learners RF and GLM. Real time manually labeled tweets based on “Clean India Mission” an Indian government policy is used for implementation of the model. Proposed model is compared with different machine learning and ensemble classifiers. Proposed hybrid model recorded higher accuracy of 0.9066377 for 5 fold cross validation and 0.9124793 for 10 fold cross validation as compared to 0.8667328 in case of stacked ensemble of SVMRadial, KNN and C5.0 by using RF as Meta classifier. RF Meta classifier performed better as compared to GLM in all stacked based ensemble. Proposed model also recorded higher accuracy as compared to machine learning classifiers-SVM, Naïve Bayes, Decision Tree, Random forest and Maximum Entropy. The contribution of the research is to enhance the accuracy of stacked based ensemble classifiers for twitter sentiment classification by using additional sentiment score provided by dictionary based classifier.",
        "DOI": "NA",
        "paper_author": "Rani S.",
        "affiliation_name": "Maharshi Dayanand University",
        "affiliation_city": "Rohtak",
        "affiliation_country": "India",
        "affiliation_id": "60004880",
        "affiliation_state": "HR"
    },
    {
        "paper_title": "Reinforcement learning approach for optimal control of multiple electric locomotives in a heavy-haul freight train:A Double-Switch-Q-network architecture",
        "publication": "Knowledge-Based Systems",
        "citied_by": "36",
        "cover_date": "2020-02-29",
        "Abstract": "Electric locomotives provide high tractive power for fast acceleration of heavy-haul freight trains, and significantly reduce the energy consumption with regenerative braking. This paper proposes a reinforcement learning (RL) approach for the optimal control of multiple electric locomotives in a heavy-haul freight train, without using the prior knowledge of train dynamics and the pre-designed velocity profile. The optimization takes the velocity, energy consumption and coupler force as objectives, considering the constraints on locomotive notches and their change rates, speed restrictions, traction and regenerative braking. Besides, since the problem in this paper has continuous state space and large action space, and the adjacent actions’ influences on states share similarities, we propose a Double-Switch Q-network (DSQ-network) architecture to achieve fast approximation of the action-value function, which enhances the parameter sharing of states and actions, and denoises the action-value function. In the numerical experiments, we test DSQ-network in 28 cases using the data of China Railways HXD3B electric locomotive. The results indicate that compared with table-lookup Q-learning, DSQ-network converges much faster and uses less storage space in the optimal control of electric locomotives. Besides, we analyze 1)the influences of ramps and speed restrictions on the optimal policy, and 2)the inter-dependent and inter-conditioned relationships between multiple optimization objectives. Finally, the factors that influence the convergence rate and solution accuracy of DSQ-network are discussed based on the visualization of the high-dimensional value functions.",
        "DOI": "10.1016/j.knosys.2019.105173",
        "paper_author": "Tang H.",
        "affiliation_name": "Southwest Jiaotong University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60010421",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Live tweeting live debates: How Twitter reflects and refracts the US political climate in a campaign season",
        "publication": "Information Communication and Society",
        "citied_by": "23",
        "cover_date": "2020-02-23",
        "Abstract": "Political campaigns mostly run parallel to each other during an election cycle, but intersect when the main candidates face off for televised debates. They offer supporters of these candidates a chance to engage with each other while being exposed to views and opinions different from their own. This study uses a combination of social network analysis and machine learning to examine how the three US presidential debates of 2016 were live tweeted (N = ∼300,000). We find that despite cross-cutting exposure across the ideological divide, people remain highly partisan in terms of who they engage with on Twitter. The issue agendas of Twitter posts during the US presidential debates is set well in advance of the debates themselves; it is highly negative and focused on personality traits of the opposition candidate rather than policy matters. We also detect a shift in the nature of online opinion leadership, with grassroots activists and internet personalities sharing the space with traditional elites such as political leaders and journalists. This shift coincides with the broader anti-establishment turn in the US political climate, as reflected in the early success of Bernie Sanders and the eventual victory of a political outsider like Donald Trump over the seasoned Hillary Clinton.",
        "DOI": "10.1080/1369118X.2018.1503697",
        "paper_author": "Zheng P.",
        "affiliation_name": "Ithaca College",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60012181",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Off-policy synchronous iteration IRL method for multi-player zero-sum games with input constraints",
        "publication": "Neurocomputing",
        "citied_by": "13",
        "cover_date": "2020-02-22",
        "Abstract": "In this paper, a novel synchronous off-policy method is given to solve multi-player zero-sum (ZS) game under the condition that the knowledge of system data are completely unknown, the actuators of controls are constrained and the disturbances are bounded simultaneously. The cost functions are built by nonquadratic functions to reflect the constrained properties of inputs. The integral reinforcement learning (IRL) technology is employed to solve Hamilton–Jacobi–Bellman equation, so that the system dynamics are not necessary anymore. The obtained value function is proved to converge to the optimal game values. And the equivalent of traditional policy iteration (PI) algorithm and the proposed algorithm is given in solving the multi-player ZS game with constrained inputs. Three neural networks in this paper are utilized, the critic neural network (CNN) to approach the cost function, the action neural network (ANN) to approach the control policies and the disturbance neural networks (DNN) to approach the disturbances are utilized. Finally, a simulation example is given to demonstrate the convergence and performance of the proposed algorithm.",
        "DOI": "10.1016/j.neucom.2019.10.075",
        "paper_author": "Ren H.",
        "affiliation_name": "The State Key Laboratory of Synthetical Automation for Process Industries",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60119041",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Q(λ) learning-based dynamic route guidance algorithm for overhead hoist transport systems in semiconductor fabs",
        "publication": "International Journal of Production Research",
        "citied_by": "48",
        "cover_date": "2020-02-16",
        "Abstract": "A learning-based dynamic routing algorithm is proposed for the overhead hoist transport (OHT) systems of semiconductor fabrication facilities (fabs). An OHT system, which consists of multiple vehicles moving at high speeds on guided rails, is the primary automated material-handling system (AMHS) in a fab. Modern large-scale fabs have hundreds of vehicles moving lots between multiple processing machines. The dynamic routing method is a route guidance method that dynamically selects the best vehicle paths under given traffic conditions and congestion levels. Building on the Q(λ) learning method, we develop a reinforcement learning-based dynamic routing algorithm called QLBWR(λ), which consists of a Boltzmann softmax policy and a reward function. The proposed algorithm uses real-time information to effectively guide each vehicle so that it avoids congestion and finds an efficient path. The algorithm is also designed with a low computational burden, such that the efficient route can be found for hundreds of vehicles in real time. Simulation analyses on an actual fab layout are used to compare the performance of the proposed algorithm with common static and dynamic algorithms. The results show that the proposed algorithm outperforms the benchmarking algorithms.",
        "DOI": "10.1080/00207543.2019.1614692",
        "paper_author": "Hwang I.",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60032144",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Comparison of end-to-end and hybrid deep reinforcement learning strategies for controlling cable-driven parallel robots",
        "publication": "Neurocomputing",
        "citied_by": "37",
        "cover_date": "2020-02-15",
        "Abstract": "Deep reinforcement learning (DRL) has been proven effective in learning policies of high-dimensional states and actions. Recently, a variety of robot manipulation tasks have been accomplished using end-to-end DRL strategies. An end-to-end DRL strategy accomplishes a robot manipulation task as a black box. On the other hand, a robot manipulation task can be divided into multiple subtasks and accomplished by non-learning-based approaches. A hybrid DRL strategy integrates DRL with non-learning-based approaches. The hybrid DRL strategy accomplishes some subtasks of a robot manipulation task by DRL and the rest subtasks by non-learning-based approaches. However, the effects of integrating DRL with non-learning-based approaches on the learning speed and the robustness of DRL to model uncertainties have not been discussed. In this study, an end-to-end DRL strategy and a hybrid DRL strategy are developed and compared in controlling a cable-driven parallel robot. This study shows that, by integrating DRL with non-learning-based approaches, the hybrid DRL strategy learns faster and is more robust to model uncertainties than the end-to-end DRL strategy. This study demonstrates that, by taking advantages of both learning and non-learning-based approaches, the hybrid DRL strategy provides an alternative to accomplish a robot manipulation task.",
        "DOI": "10.1016/j.neucom.2019.10.020",
        "paper_author": "Xiong H.",
        "affiliation_name": "Purdue Polytechnic Institute",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60017406",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Data augmentation for discrimination prevention and bias disambiguation",
        "publication": "AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "59",
        "cover_date": "2020-02-07",
        "Abstract": "Machine learning models are prone to biased decisions due to biases in the datasets they are trained on. In this paper, we introduce a novel data augmentation technique to create a fairer dataset for model training that could also lend itself to understanding the type of bias existing in the dataset i.e. if bias arises from a lack of representation for a particular group (sampling bias) or if it arises because of human bias reflected in the labels (prejudice based bias). Given a dataset involving a protected attribute with a privileged and unprivileged group, we create an \"ideal world\" dataset: for every data sample, we create a new sample having the same features (except the protected attribute(s)) and label as the original sample but with the opposite protected attribute value. The synthetic data points are sorted in order of their proximity to the original training distribution and added successively to the real dataset to create intermediate datasets. We theoretically show that two different notions of fairness: statistical parity difference (independence) and average odds difference (separation) always change in the same direction using such an augmentation. We also show submodularity of the proposed fairness-aware augmentation approach that enables an efficient greedy algorithm. We empirically study the effect of training models on the intermediate datasets and show that this technique reduces the two bias measures while keeping the accuracy nearly constant for three datasets.We then discuss the implications of this study on the disambiguation of sample bias and prejudice based bias and discuss how pre-processing techniques should be evaluated in general. The proposed method can be used by policy makers-who want to use unbiased datasets to train machine learning models for their applications-to add a subset of synthetic points to an extent that they are comfortable with to mitigate unwanted bias.",
        "DOI": "10.1145/3375627.3375865",
        "paper_author": "Sharma S.",
        "affiliation_name": "IBM Research",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States",
        "affiliation_id": "60011048",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Algorithmic fairness from a non-ideal perspective",
        "publication": "AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "64",
        "cover_date": "2020-02-07",
        "Abstract": "Inspired by recent breakthroughs in predictive modeling, practitioners in both industry and government have turned to machine learning with hopes of operationalizing predictions to drive automated decisions. Unfortunately, many social desiderata concerning consequential decisions, such as justice or fairness, have no natural formulation within a purely predictive framework. In the hopes of mitigating these problems, researchers have proposed a variety of metrics for quantifying deviations from various statistical parities that we might hope to observe in a fair world, offering a variety of algorithms that attempt to satisfy subsets of these parities or to trade off the degree to which they are satisfied against utility. In this paper, we connect this approach to fair machine learning to the literature on ideal and non-ideal methodological approaches in political philosophy. The ideal approach requires positing the principles according to which a just world would operate. In the most straightforward application of ideal theory, one supports a proposed policy by arguing that it closes a discrepancy between the real and ideal worlds. However, by failing to account for the mechanisms by which our non-ideal world arose, the responsibilities of various decision-makers, and the impacts of their actions, naive applications of ideal thinking can lead to misguided policies. In this paper, we demonstrate a connection between the recent literature on fair machine learning and the ideal approach in political philosophy, and show that some recently uncovered shortcomings in proposed algorithms reflect broader troubles faced by the ideal approach.We work this analysis through for different formulations of fairness and conclude with a critical discussion of real-world impacts and directions for new research.",
        "DOI": "10.1145/3375627.3375828",
        "paper_author": "Fazelpour S.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60027950",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Bayesian sensitivity analysis for offline policy evaluation",
        "publication": "AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "7",
        "cover_date": "2020-02-07",
        "Abstract": "On a variety of complex decision-making tasks, from doctors prescribing treatment to judges setting bail, machine learning algorithms have been shown to outperform expert human judgments. One complication, however, is that it is often difficult to anticipate the effects of algorithmic policies prior to deployment, as one generally cannot use historical data to directly observe what would have happened had the actions recommended by the algorithm been taken. A common strategy is to model potential outcomes for alternative decisions assuming that there are no unmeasured confounders (i.e., to assume ignorability). But if this ignorability assumption is violated, the predicted and actual effects of an algorithmic policy can diverge sharply. In this paper we present a flexible Bayesian approach to gauge the sensitivity of predicted policy outcomes to unmeasured confounders. In particular, and in contrast to past work, our modeling framework easily enables confounders to vary with the observed covariates. We demonstrate the efficacy of our method on a large dataset of judicial actions, in which one must decide whether defendants awaiting trial should be required to pay bail or can be released without payment.",
        "DOI": "10.1145/3375627.3375822",
        "paper_author": "Jung J.",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60012708",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Significant Changes in Chemistry of Fine Particles in Wintertime Beijing from 2007 to 2017: Impact of Clean Air Actions",
        "publication": "Environmental Science and Technology",
        "citied_by": "101",
        "cover_date": "2020-02-04",
        "Abstract": "The Beijing government implemented a number of clean air action plans to improve air quality in the last 10 years, which contributed to changes in the concentration of fine particles and their compositions. However, quantifying the impacts of these interventions is challenging as meteorology masks the real changes in observed concentrations. Here, we applied a machine learning technique to decouple the effect of meteorology and evaluate the changes in the chemistry of nonrefractory PM1 (particulate matter less than 1 μm) in winter 2007, 2016, and 2017 as a result of the clean air actions. The observed mass concentrations of PM1 were 74.6, 90.2, and 36.1 μg m-3 in the three winters, while the deweathered concentrations were 74.2, 78.7, and 46.3 μg m-3, respectively. The deweathered concentrations of PM1, organics, sulfate, ammonium, chloride, SO2, NO2, and CO decreased by -38, -46, -59, -24, -51, -89, -16, and -52% in 2017 in comparison to 2007. On the contrary, the deweathered concentration of nitrates increased by 4%. Our results indicate that the clean air actions implemented in 2017 were highly effective in reducing ambient concentrations of SO2, CO, and PM1 organics, sulfate, ammonium, and chloride, but the control of nitrate and PM1 organics remains a major challenge.",
        "DOI": "10.1021/acs.est.9b04678",
        "paper_author": "Zhang Y.",
        "affiliation_name": "Chinese Academy of Meteorological Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60027451",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement learning for batch bioprocess optimization",
        "publication": "Computers and Chemical Engineering",
        "citied_by": "143",
        "cover_date": "2020-02-02",
        "Abstract": "Bioprocesses have received a lot of attention to produce clean and sustainable alternatives to fossil-based materials. However, they are generally difficult to optimize due to their unsteady-state operation modes and stochastic behaviours. Furthermore, biological systems are highly complex, therefore plant-model mismatch is often present. To address the aforementioned challenges we propose a Reinforcement learning based optimization strategy for batch processes. In this work we applied the Policy Gradient method from batch-to-batch to update a control policy parametrized by a recurrent neural network. We assume that a preliminary process model is available, which is exploited to obtain a preliminary optimal control policy. Subsequently, this policy is updated based on measurements from the true plant. The capabilities of our proposed approach were tested on three case studies (one of which is nonsmooth) using a more complex process model for the true system embedded with adequate process disturbance. Lastly, we discussed advantages and disadvantages of this strategy compared against current existing approaches such as nonlinear model predictive control.",
        "DOI": "10.1016/j.compchemeng.2019.106649",
        "paper_author": "Petsagkourakis P.",
        "affiliation_name": "The University of Manchester",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60003771",
        "affiliation_state": "Greater Manchester"
    },
    {
        "paper_title": "Machine learning could improve innovation policy",
        "publication": "Nature Machine Intelligence",
        "citied_by": "1",
        "cover_date": "2020-02-01",
        "Abstract": "NA",
        "DOI": "10.1038/s42256-020-0155-8",
        "paper_author": "Furman J.L.",
        "affiliation_name": "Boston University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60019674",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Extraction of Rice Planting Areas in Jianghan Plain Based on Spatiotemporal Fusion NDVI and Phenological Characteristics",
        "publication": "Resources and Environment in the Yangtze Basin",
        "citied_by": "4",
        "cover_date": "2020-02-01",
        "Abstract": "Jianghan Plain is an important commodity grain base in China, the acquisition of high-precision rice planting area is of great significance to the country's agricultural development and planning. However, there are many cloud and rain weathers in southern China affected by climate, and the optical remote sensing images are seriously missing. At the same time, due to the satellite revisiting cycle, the available data is less, which affects the accuracy of rice planting area extraction. Obtaining high spatial-temporal resolution remote sensing images is the key to extracting rice growing areas in southern China. In order to solve the problem of high spatial-temporal resolution image loss, the fusion of Landsat 8 OLI and MODIS data based on Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM) is used to obtain Landsat Normalized Difference Vegetation Index(NDVI) time series data with high spatial and temporal resolution. The ESTARFM model could improves the accuracy of heterogeneous landscape extraction for more heterogeneous and fragmented areas with high precision. In the existing crop area information extraction research, the classification relies on a single NDVI data, and the phenological feature information in the process of crop growth has not been fully utilized in the remote sensing classification structure. In this article, we use time NDVI series data to analyze the phenological characteristics of rice and combining key phenological parameters, so that a variety of machine learning methods could be used to extract rice planting areas, in this article, machine learning classification methods including Support Vector Machine(SVM), random forest and neural network were used to extract rice planting area and evaluate which method works best. The results show that this method can extract the rice planting area in the study area well, and the SVM method has the best classification effect. In the meanwhile, the overall classification accuracy of rice planting area extraction is 93.31%, and the Kappa coefficient is 0.920 2. This study provides an effective technical means for the extraction of rice planting area in the southern region, and providing technical support for regional land use planning and food policy.",
        "DOI": "10.11870/cjlyzyyhj202002015",
        "paper_author": "Zhao Y.J.",
        "affiliation_name": "Innovation Academy for Precision Measurement Science and Technology,CAS",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60273094",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Tree-based bagging and boosting algorithms for proactive invoice management",
        "publication": "2019 International Conference on Advances in the Emerging Computing Technologies, AECT 2019",
        "citied_by": "0",
        "cover_date": "2020-02-01",
        "Abstract": "This paper explores the use of machine learning for proactive invoice management through addressing the problem of predicting delinquent invoices and investigating the factors that correlate with delinquency. Unpaid or late-paid invoices lead to the writing-off of millions of dollars for large organizations globally. A key component in account receivables management is to proactively alleviate bad debts and accelerate payments, which considering the 'time-value of money' has a significant impact on ultimate profitability. To achieve this dual goal, the focus is on tree-based ensemble models and use of various learning schemes on real-world invoice data from a Fortune 500 financial company made of several business units servicing several geographies. Our modeling scheme accounts for variations along several customer characteristics including agreed payment policies, type of business, and geo-locations. Our comparative results of Random Forest and LightGBM show that the LightGBM model gives better AUC and Lift across all Business Units.",
        "DOI": "10.1109/AECT47998.2020.9194200",
        "paper_author": "Atir M.",
        "affiliation_name": "S P Global Market Intelligence Data Science",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125203315",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Managing uncertainty during CBR systems vocabulary maintenance using Relational Evidential C-Means",
        "publication": "Proceedings of 2020 International Multi-Conference on: Organization of Knowledge and Advanced Technologies, OCTA 2020",
        "citied_by": "0",
        "cover_date": "2020-02-01",
        "Abstract": "Due to the incremental learning of Case-Based Reasoning (CBR) systems, there is a colossal need to maintain their knowledge containers which are (1) the case base, (2) similarity measures, (3) adaptation, and (4) vocabulary knowledge. Actually, the vocabulary presents the basis of all the other knowledge containers since it is used for their description. Besides, CBR systems store real-world experiences which are full of uncertainty and imprecision. Therefore, we propose, in this paper, a new policy to maintain vocabulary knowledge using one of the most powerful tools for uncertainty management called the belief function theory, as well as the machine learning technique called Relational Evidential C-Means (RECM). We restrict the vocabulary knowledge to be the set of features describing cases, and we aim to eliminate noisy and redundant attributes by taking into account the correlation between them.",
        "DOI": "10.1109/OCTA49274.2020.9151771",
        "paper_author": "Ben Ayed S.",
        "affiliation_name": "Université d'Artois",
        "affiliation_city": "Arras",
        "affiliation_country": "France",
        "affiliation_id": "60018178",
        "affiliation_state": "Hauts-de-France"
    },
    {
        "paper_title": "Climate policy and intelligent transport systems: Application of new transport technologies to reduce greenhouse emissions",
        "publication": "2020 National Conference on Emerging Trends on Sustainable Technology and Engineering Applications, NCETSTEA 2020",
        "citied_by": "3",
        "cover_date": "2020-02-01",
        "Abstract": "CO2 emission has been considered as a key concern in energy and climate policies. Australia's greenhouse gas emissions have been at the highest level in recent years. As about 20% of CO2 emissions coming from transport sections and 68% emission of the transport section is produced in our roads, an urgent solution to this problem is required. The transport industry is moving fast toward being more intelligent and using new technologies such as Connected and Automated Vehicles and intelligent traffic Control Systems on the roads. In this research, the focus will be on the impact of these technologies on transport and effective strategies to reduce the greenhouse gases in Intelligent Transport Systems (ITS). In this paper, relevant recent works have been reviewed and a machine learning method has been applied to forecast traffic congestion. The effect of different ITS technologies has been assessed based on their gradual impact on the congestion each year. The result shows four years traffic forecast model with different annual impact coming from different ITS technologies.",
        "DOI": "10.1109/NCETSTEA48365.2020.9119940",
        "paper_author": "Nejad M.F.",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60028333",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Understanding the relationship between population density and low voltage faults causes in electricity distribution network",
        "publication": "2020 Advances in Science and Engineering Technology International Conferences, ASET 2020",
        "citied_by": "1",
        "cover_date": "2020-02-01",
        "Abstract": "The distribution network operators (DNO) are the companies which bring electricity from the national transmission network to local homes and businesses. The essential primary duty of any DNO is to provide uninterrupted electricity supply to their customers. So, having a deep understanding of network faults has always been principal importance for reliable and sustainable power supply. The purpose of this study is to discover the relationship between population density and low voltage (LV) faults causes in an electricity distribution network using machine learning classification models. The study aims to use different classification models and comparing the results. The results of this study should outline the ideal classification model to use in understanding the relationship between population density and LV faults causes. In this study, the correlation method has been used for feature selection to select the most suitable variables to build the classification models. It should also give more insight into how the data should be prepared before being input into a machine learning classification models. Correlation analysis has revealed the multifaceted relationships that exist among the variables in multivariate fault data. From this study results and analysis, the shows that there is a new relationship between local population density and fault causes which suggest fault causes has a strong relationship with population density. These findings may help DNOs in policy-making and network design. Also, this research may assist Smart City planning projects.",
        "DOI": "10.1109/ASET48392.2020.9118391",
        "paper_author": "Silva C.",
        "affiliation_name": "University of Salford",
        "affiliation_city": "Salford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60008250",
        "affiliation_state": "Greater Manchester"
    },
    {
        "paper_title": "Stock Forecasting Using Natural Language and Recurrent Network",
        "publication": "Proceedings of 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things, ICETCE 2020",
        "citied_by": "6",
        "cover_date": "2020-02-01",
        "Abstract": "The factors affecting the stock price of a company include financial aspects, government policies, international policies, emerging news, which affects the investors and hence the market. Critical technical indicators are taken into account while proposing multi-level machine learning in this paper. Firstly, the sentiments of news articles analyzed using lexicon-based Natural Language Processing (NLP). The lexicon used is exclusively based on financial, social media. Each news article analyzed for aspect extraction and aspect-based sentiment analysis. Along with market news sentiments and the company's historical financial data, feature vector also includes critical technical analyses based on trend, momentum, and volatility. The future stock price movements forecast utilizes Long Short-Term Memory-Recursive Neural Network (LSTM-RNN) model. The results indicate that the discussed model performs well without requiring any data preprocessing, cycle analyses, or seasonality testing.",
        "DOI": "10.1109/ICETCE48199.2020.9091732",
        "paper_author": "Kumar D.",
        "affiliation_name": "Indian Institute of Science",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60014097",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Reinforcement learning for control of flexibility providers in a residential microgrid",
        "publication": "IET Smart Grid",
        "citied_by": "30",
        "cover_date": "2020-02-01",
        "Abstract": "The smart grid paradigm and the development of smart meters have led to the availability of large volumes of data. This data is expected to assist in power system planning/operation and the transition from passive to active electricity users. With recent advances in machine learning, this data can be used to learn system dynamics. This study explores two model-free reinforcement learning (RL) techniques - policy iteration (PI) and fitted Q-iteration (FQI) for scheduling the operation of flexibility providers - battery and heat pump in a residential microgrid. The proposed algorithms are data-driven and can be easily generalised to fit the control of any flexibility provider without requiring expert knowledge to build a detailed model of the flexibility provider and/or microgrid. The algorithms are tested in multi-agent collaborative and single-agent stochastic microgrid settings - with the uncertainty due to lack of knowledge on future electricity consumption patterns and photovoltaic production. Simulation results show that PI outperforms FQI with a 7.2% increase in photovoltaic self-consumption in the multi-agent setting and a 3.7% increase in the single-agent setting. Both RL algorithms perform better than a rule-based controller, and compete with a model-based optimal controller, and are thus, a valuable alternative to model- and rule-based controllers.",
        "DOI": "10.1049/iet-stg.2019.0196",
        "paper_author": "Mbuwir B.V.",
        "affiliation_name": "Vlaamse Instelling voor Technologisch Onderzoek",
        "affiliation_city": "Mol",
        "affiliation_country": "Belgium",
        "affiliation_id": "60019342",
        "affiliation_state": "VAN"
    },
    {
        "paper_title": "A Lightweight Policy-aware Broker for Multi-domain Network Slice Composition",
        "publication": "2020 23rd Conference on Innovation in Clouds, Internet and Networks and Workshops, ICIN 2020",
        "citied_by": "5",
        "cover_date": "2020-02-01",
        "Abstract": "Network virtualization technologies allow 5G and beyond mobile networks to support new vertical applications of various service types. Network slicing (NS) further provides a concept for multi-tenant access to common network infrastructure spreading from core and transport to radio access networks. Nevertheless, the management and orchestration of network slices across multiple infrastructure and administrative domains have only recently gained attention. In this work, we first present a reference architecture for NS management and its brokering layer that enables NS discovery and dynamic composition. We detail the designs of the main NS brokering components, i.e., NS information model and NS request handling, which address some unique challenges of multi-domain NS brokering. Our approach combines machine learning and logic reasoning for the selection of NSs based on their functional, non-functional attributes and other policy constraints. Finally, we validate the NS request matching approach and observe a high prediction accuracy. We conclude the work with a discussion on possible improvement to the NS matching approach and its extension for cross-domain NS management.",
        "DOI": "10.1109/ICIN48450.2020.9059366",
        "paper_author": "Dang X.T.",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "PPMC Training Algorithm: A Deep Learning Based Path Planner and Motion Controller",
        "publication": "2020 International Conference on Artificial Intelligence in Information and Communication, ICAIIC 2020",
        "citied_by": "2",
        "cover_date": "2020-02-01",
        "Abstract": "In the pursuit of a fully autonomous learning agent able to interact, move, and be useful in the real world, two fundamental problems are path planning and motion control, and user-agent interaction. We address these through reinforcement learning using our Path Planning and Motion Controller (PPMC) Training Algorithm, which uses a combination of observable goals and randomization of goals during training, with a customized reward function, to teach a simulated quadruped agent to respond to user commands and to travel to designated areas. In this regard, we identified two critical components of path planning and motion control: the first is region enabled travel, or the ability to travel towards any location within a prescribed area; the second is multi-point travel, or the ability to travel to multiple points in succession. An important open ended question is how many tasks should be handled by a single policy and if a single policy can even learn to manage several tasks. We demonstrate that it is possible to contain both a maples path planner and motion controller on a single neural network, which could prove promising in future work due to their interlinked and synergistic nature. Using control group policies and various test cases and using ACKTR and PPO, we empirically validate our algorithm teaches the agent to respond to user commands as well as path planning and motion control.",
        "DOI": "10.1109/ICAIIC48513.2020.9065237",
        "paper_author": "Blum T.",
        "affiliation_name": "Tohoku University",
        "affiliation_city": "Sendai",
        "affiliation_country": "Japan",
        "affiliation_id": "60008435",
        "affiliation_state": "Miyagi"
    },
    {
        "paper_title": "Research on Classification of Dwarf Nova Based on Deep Architecture Network",
        "publication": "Guang Pu Xue Yu Guang Pu Fen Xi/Spectroscopy and Spectral Analysis",
        "citied_by": "0",
        "cover_date": "2020-02-01",
        "Abstract": "Dwarf nova (DN) is a special and rare class of semi-contiguous binary star. To discovery more DNs is significant for the further study of matter transfer theory. It also has been profound for understanding the evolution of close binary stars. It is a research hot spot to extract features of celestial spectra and then classify them by deep learning. Traditional auto-encoder is a classical neural network model with only one hidden layer. However, its coding ability is limited and data representation learning ability is insufficient. Broadening the depth of the neural network with modularity can make the network learn features of the celestial spectrum successively. High-level features can be obtained through gradual abstract learning of underlying features so as to improve the spectral classification accuracy. In this paper, a deep feedforward stack network is constructed consisting of an input layer, several hidden layers and an output layer on the basis of auto-encoder. This network with multi-layer perceptron architecture is utilized to process massive spectral data sets. It excavates the depth structure features hidden in the spectra and realizes the accurate classification of DN spectra. Parameters set for the network with deep architecture will seriously affect the performance of the constructed network. In this paper, the optimization of network parameters is divided into two processes: hierarchical training and inverse propagation. The preprocessed spectral data first enter the network from the input layer, and then the network parameters are trained layer by layer with the auto-encoder algorithm and weight sharing policy. In the reverse propagation stage, the initial sample data are input into the network again, and the network is initialized with the weights obtained from the hierarchical training process. Then the local optimization training results of each layer are fused and the network parameters are adjusted according to the set output error cost function. Hierarchical training and inverse propagation are operated repeatedly until the global optimal network parameters are obtained. Finally, the last hidden layer is adopted as the reconstruction layer to connect the support vector machine classifier, and the feature extraction and classification of DNs are realized. In the process of network parameter optimization, the idea of mean network is utilized to make the output of network hidden layer unit attenuate according to dropout coefficient. The reverse propagation algorithm is adopted to fine-tune the entire network to prevent depth overfitting in the network. Such operation can reduce to extract duplicate feature caused by mutual moderation of hidden layer neurons, and improve the generalization ability. The distributed multi-layer architecture of the network can provide effective data abstraction and representational learning. The feature detection layer can learn the depth structure features implicitly from the unlabeled data, and effectively characterize the nonlinearity and random fluctuation of spectral data, thus avoiding the explicit extraction of spectral features. The network shows strong data fitting and generalization ability. Weight sharing between different layers can reduce the interference of redundant information and effectively resolve the risk that the traditional multi-layer architecture network is prone to fall into the local minimization of weight. Experiments show that that of the accuracy of the deep architecture network in DNs classification is 95.81%, higher than the classical LM-BP network.",
        "DOI": "10.3964/j.issn.1000-0593(2020)02-0656-05",
        "paper_author": "Zhao Y.J.",
        "affiliation_name": "Shandong University, Weihai",
        "affiliation_city": "Weihai",
        "affiliation_country": "China",
        "affiliation_id": "60108071",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Stimulating implementation of sustainable development goals and conservation action: Predicting future land use/cover change in Virunga national park, Congo",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "31",
        "cover_date": "2020-02-01",
        "Abstract": "The United Nations 2030 Agenda for Sustainable Development and the Sustainable Development Goals (SDG's) presents a roadmap and a concerted platform of action towards achieving sustainable and inclusive development, leaving no one behind, while preventing environmental degradation and loss of natural resources. However, population growth, increased urbanisation, deforestation, and rapid economic development has decidedly modified the surface of the earth, resulting in dramatic land cover changes, which continue to cause significant degradation of environmental attributes. In order to reshape policies and management frameworks conforming to the objectives of the SDG's, it is paramount to understand the driving mechanisms of land use changes and determine future patterns of change. This study aims to assess and quantify future land cover changes in Virunga National Park in the Democratic Republic of the Congo by simulating a future landscape for the SDG target year of 2030 in order to provide evidence to support data-driven decision-making processes conforming to the requirements of the SDG's. The study follows six sequential steps: (a) creation of three land cover maps from 2010, 2015 and 2019 derived from satellite images; (b) land change analysis by cross-tabulation of land cover maps; (c) submodel creation and identification of explanatory variables and dataset creation for each variable; (d) calculation of transition potentials of major transitions within the case study area using machine learning algorithms; (e) change quantification and prediction using Markov chain analysis; and (f) prediction of a 2030 land cover. The model was successfully able to simulate future land cover and land use changes and the dynamics conclude that agricultural expansion and urban development is expected to significantly reduce Virunga's forest and open land areas in the next 11 years. Accessibility in terms of landscape topography and proximity to existing human activities are concluded to be primary drivers of these changes. Drawing on these conclusions, the discussion provides recommendations and reflections on how the predicted future land cover changes can be used to support and underpin policy frameworks towards achieving the SDG's and the 2030 Agenda for Sustainable Development.",
        "DOI": "10.3390/su12041570",
        "paper_author": "Christensen M.",
        "affiliation_name": "Aalborg University",
        "affiliation_city": "Aalborg",
        "affiliation_country": "Denmark",
        "affiliation_id": "60022134",
        "affiliation_state": "Nordjylland"
    },
    {
        "paper_title": "Niche change analysis as a tool to inform management of two invasive species in Eastern Africa",
        "publication": "Ecosphere",
        "citied_by": "30",
        "cover_date": "2020-02-01",
        "Abstract": "Significant progress has been made in providing guidelines and recommendations for assessing the ecological niche, stage of invasion, and probability of invasive alien plant species (IAPS) potential distribution in space and time. We followed these recommendations by developing and comparing ordination and species distribution models (SDMs) of two important woody IAPS in Eastern Africa, Prosopis juliflora and Lantana camara, and interpreting the results to inform IAPS management. The two species differ in their invasion history in Eastern Africa; while L. camara was widely introduced there in the 19th century, P. juliflora was only planted at selected locations in the 1970s and 1980s. For the SDMs, machine learning algorithms were used to generate one ensemble model each for P. juliflora and L. camara. For ordination, we used bioclimatic variables, performed a principal component analysis, and compared the native and global niches of the species with the Eastern African niche. Niches varied substantially depending on the percentage of marginal climates excluded from the models. Additional analysis of the local niches surrounding the original P. juliflora plantations showed that they are complementary, which may have led to an overestimation of regional niche filling. While niche expansion was absent or small depending on the percentage of marginal climates excluded, analysis of the stages of invasion suggested that P. juliflora may have started to adapt to novel climatic conditions and that L. camara is approaching a pseudo-stable equilibrium in Eastern Africa. The SDMs showed that large areas in Eastern Africa that have not yet been invaded by P. juliflora are suitable or will become suitable with climate change. For L. camara, the global SDM predicted a considerably larger suitable area than the Eastern African one, raising uncertainty about the areas to be included in a regional management strategy. Thus, combining ordination and SDMs and integrating a geographic component into ordination is useful in assessing IAPS invasion stages and potential niche shifts, and the results help inform IAPS policy and management. The combined approach can also serve to guide experimental studies addressing divergences between results generated with the different approaches.",
        "DOI": "10.1002/ecs2.2987",
        "paper_author": "Eckert S.",
        "affiliation_name": "University of Bern",
        "affiliation_city": "Bern",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60020486",
        "affiliation_state": "BE"
    },
    {
        "paper_title": "Poverty prediction using satellite imagery and machine learning",
        "publication": "International Journal of Scientific and Technology Research",
        "citied_by": "1",
        "cover_date": "2020-02-01",
        "Abstract": "Poverty is a major problem in developing countries as it becomes an obstacle to development. Identifying poor areas is a big task for the government to make policy. Earlier household survey method takes more time, effort and cost. To overcome this limitation, the method of predicting poverty using satellite images is covered in the paper. Composite data of nighttime satellite images of Rwanda country of Africa is taken from DMSP-OLS’s satellite series under EOG of NOAA is trained with a Regression model. 5 night light intensity features used to train the Regression model with a label of DHS data of Rwanda which includes latitude, longitude and respective wealth index. The result shows there is a good correlation with night light intensity and wealth index with R2 of 0.752. In the second experiment daytime satellite images taken from Google static maps, extracted 4096 CNN features and trained with the CNN model using transfer learning. Which also gives a good result with 82% testing accuracy. Thus both the experiment reveals that satellite data and machine learning can be a useful technique for estimating poverty.",
        "DOI": "NA",
        "paper_author": "Thorat R.S.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Bridges across borders: A clustering approach to support EU regional policy",
        "publication": "Journal of Transport Geography",
        "citied_by": "17",
        "cover_date": "2020-02-01",
        "Abstract": "We present a methodology to analyse high resolution population and transport data in order to assess cross-border connectivity within the European Union. Transport infrastructure can strongly influence cross-border interactions as well as regional, urban or local development. The analysis is carried out using a policy perspective, with network efficiency as the main indicator of accessibility. The aim is to allow the quantification of the quality of cross-border road connections and the identification of areas where infrastructure improvements can lead to higher benefits. We propose a machine learning approach that combines cell level route assignment and k-means clustering at a fine −1 square km- population grid. The outputs cover all internal EU land borders and consist of sets of spatial clusters that meet user-defined policy criteria. The results can be used as input for investment decisions and can be easily combined with other policy support tools for tailored multi-criteria analysis.",
        "DOI": "10.1016/j.jtrangeo.2020.102666",
        "paper_author": "Christodoulou A.",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "60103695",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Discovering anomalous rules in firewall logs using data mining and machine learning classifiers",
        "publication": "International Journal of Scientific and Technology Research",
        "citied_by": "5",
        "cover_date": "2020-02-01",
        "Abstract": "Firewall is the main component of network security that monitors the in-out network packets according to a predetermined security rule. The security rules in companies and institutions are implemented as Firewall rules. Firewall rules in large networks have proven to be sensitive and error-prone. In addition, any improper management of these rules will cause anomalies. The aim of this study is using data mining to analyse and detect anomalies in Firewall logs. A hybrid model based on data mining and machine learning is proposed for analyzing and discovering anomalies from firewall rules. The proposed methods have shown a more superior and precise performance in terms of anomaly detection accuracy and as a result, enabling network administrators to update and optimize Firewall policy rules.",
        "DOI": "NA",
        "paper_author": "As-Suhabni H.E.Q.",
        "affiliation_name": "Swami Ramanand Teerth Marathwada University",
        "affiliation_city": "Nanded",
        "affiliation_country": "India",
        "affiliation_id": "60026737",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Geolocation based decision making for appropriate land use using machine learning model",
        "publication": "International Journal of Scientific and Technology Research",
        "citied_by": "1",
        "cover_date": "2020-02-01",
        "Abstract": "At present days, population explosion in Bangladesh has caused the land resources very limited for both upcoming industrialization and urbanization. Here it is common scenario, that a vast amount of farming land or forests are now turned into human settlement or industrial zones which affect the agriculture significantly. Keeping aside the big crowded cities where the land resources are already rare, we focused on Rajshahi the next prospective zone of Bangladesh. Proper land assessment is direly needed to such decision making for new. Our study depicts an interesting mechanism in the field of land assessment using the technological breakthrough of GIS as well as remote sensing technology from which the spatial details can be obtained and analyzed meticulously instead of conventional site visiting that is time consuming. In this high-tech era GIS offers the satellite data that is indeed greatly effective for spatial planning and resource management. The information of LULC (Land Use Land Cover) is crucial for policy making, business and administrative purposes. The current study propounds a new approach that has made use of the remote sensed satellite data, analyzed those by Land Classification which paves the way for remote land assessment and decision making in Rajshahi for future industrialization and urbanization.",
        "DOI": "NA",
        "paper_author": "Banik S.",
        "affiliation_name": "East West University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60004766",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Practical implementation of privacy preserving clustering methods using a partially homomorphic encryption algorithm",
        "publication": "Electronics (Switzerland)",
        "citied_by": "28",
        "cover_date": "2020-02-01",
        "Abstract": "The protection and processing of sensitive data in big data systems are common problems as the increase in data size increases the need for high processing power. Protection of the sensitive data on a system that contains multiple connections with different privacy policies, also brings the need to use proper cryptographic key exchange methods for each party, as extra work. Homomorphic encryption methods can perform similar arithmetic operations on encrypted data in the same way as a plain format of the data. Thus, these methods provide data privacy, as data are processed in the encrypted domain, without the need for a plain form and this allows outsourcing of the computations to cloud systems. This also brings simplicity on key exchange sessions for all sides. In this paper, we propose novel privacy preserving clustering methods, alongside homomorphic encryption schemes that can run on a common high performance computation platform, such as a cloud system. As a result, the parties of this system will not need to possess high processing power because the most power demanding tasks would be done on any cloud system provider. Our system offers a privacy preserving distance matrix calculation for several clustering algorithms. Considering both encrypted and plain forms of the same data for different key and data lengths, our privacy preserving training method’s performance results are obtained for four different data clustering algorithms, while considering six different evaluation metrics.",
        "DOI": "10.3390/electronics9020229",
        "paper_author": "Catak F.O.",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway",
        "affiliation_id": "60013141",
        "affiliation_state": "Trondelag"
    },
    {
        "paper_title": "Machine learning models for net photosynthetic rate prediction using poplar leaf phenotype data",
        "publication": "PLoS ONE",
        "citied_by": "18",
        "cover_date": "2020-02-01",
        "Abstract": "Background As an essential component in reducing anthropogenic CO2 emissions to the atmosphere, tree planting is the key to keeping carbon dioxide emissions under control. In 1992, the United Nations agreed to take action at the Earth Summit to stabilize and reduce net zero global anthropogenic CO2 emissions. Tree planting was identified as an effective method to offset CO2 emissions. A high net photosynthetic rate (Pn) with fast-growing trees could efficiently fulfill the goal of CO2 emission reduction. Net photosynthetic rate model can provide refernece for plant’s stability of photosynthesis productivity. Methods and results Using leaf phenotype data to predict the Pn can help effectively guide tree planting policies to offset CO2 release into the atmosphere. Tree planting has been proposed as one climate change solution. One of the most popular trees to plant are poplars. This study used a Populus simonii (P. simonii) dataset collected from 23 artificial forests in northern China. The samples represent almost the entire geographic distribution of P. simonii. The geographic locations of these P. simonii trees cover most of the major provinces of northern China. The northwestern point reaches (36°30’N, 98°09’E). The northeastern point reaches (40°91’N, 115°83’E). The southwestern point reaches (32°31’N, 108°90’E). The southeastern point reaches (34°39’N, 113°74’E). The collected data on leaf phenotypic traits are sparse, noisy, and highly correlated. The photosynthetic rate data are nonnormal and skewed. Many machine learning algorithms can produce reasonably accurate predictions despite these data issues. Influential outliers are removed to allow an accurate and precise prediction, and cluster analysis is implemented as part of a data exploratory analysis to investigate further details in the dataset. We select four regression methods, extreme gradient boosting (XGBoost), support vector machine (SVM), random forest (RF) and generalized additive model (GAM), which are suitable to use on the dataset given in this study. Cross-validation and regularization mechanisms are implemented in the XGBoost, SVM, RF, and GAM algorithms to ensure the validity of the outputs. Conclusions The best-performing approach is XGBoost, which generates a net photosynthetic rate prediction that has a 0.77 correlation with the actual rates. Moreover, the root mean square error (RMSE) is 2.57, which is approximately 35 percent smaller than the standard deviation of 3.97. The other metrics, i.e., the MAE, R2, and the min-max accuracy are 1.12, 0.60, and 0.93, respectively. This study demonstrates the ability of machine learning models to use noisy leaf phenotype data to predict the net photosynthetic rate with significant accuracy. Most net photosynthetic rate prediction studies are conducted on herbaceous plants. The net photosynthetic rate prediction of P. simonii, a kind of woody plant, illustrates significant guidance for plant science or environmental science regarding the predictive relationship between leaf phenotypic characteristics and the Pn for woody plants in northern China.",
        "DOI": "10.1371/journal.pone.0228645",
        "paper_author": "Zhang X.Y.",
        "affiliation_name": "Beijing Forestry University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60006782",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Predicting Hospital Readmission: A Joint Ensemble-Learning Model",
        "publication": "IEEE Journal of Biomedical and Health Informatics",
        "citied_by": "31",
        "cover_date": "2020-02-01",
        "Abstract": "Hospital readmission is among the most critical issues in the healthcare system due to its high prevalence and cost. The improvement effort necessitates reliable prediction models which can identify high-risk patients effectively and enable healthcare practitioners to take a strategic approach. Using predictive analytics based on electronic health record (EHR) for hospital readmission is faced with multiple challenges such as high dimensionality and event sparsity of medical codes and the class imbalance. To response to these challenges, an analytical framework is proposed by data-driven approaches using hospital inpatient administrative data from a nationwide healthcare dataset. A joint ensemble-learning model, which combines the modified weight boosting algorithm with stacking algorithm, is developed and validated. Our study first explores the effects of different feature engineering methods, which effectively handles the challenge of medical vector representation and medical vector sparsity. Secondly, ensemble learning with the proposed modified weight boosting algorithm is used to tackle the class imbalance problem and improve predictability. Finally, we provide various misclassification costs by setting different weights for each class during model training. Using the framework with the proposed modified weight boosting algorithm improves overall model performance by 22.7% and recall from 0.726 to the highest of 0.891 comparing to the benchmark models. Hospital practitioners can also utilize the prediction results of different cost weight to select the most suitable readmission intervention for patients according to the penalty policy of Centers for Medicare and Medicaid Services (CMS) and the cost trade-off of their hospitals.",
        "DOI": "10.1109/JBHI.2019.2938995",
        "paper_author": "Yu K.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Policy Implications of Artificial Intelligence and Machine Learning in Diabetes Management",
        "publication": "Current Diabetes Reports",
        "citied_by": "20",
        "cover_date": "2020-02-01",
        "Abstract": "Purpose of Review: Machine learning (ML) is increasingly being studied for the screening, diagnosis, and management of diabetes and its complications. Although various models of ML have been developed, most have not led to practical solutions for real-world problems. There has been a disconnect between ML developers, regulatory bodies, health services researchers, clinicians, and patients in their efforts. Our aim is to review the current status of ML in various aspects of diabetes care and identify key challenges that must be overcome to leverage ML to its full potential. Recent Findings: ML has led to impressive progress in development of automated insulin delivery systems and diabetic retinopathy screening tools. Compared with these, use of ML in other aspects of diabetes is still at an early stage. The Food & Drug Administration (FDA) is adopting some innovative models to help bring technologies to the market in an expeditious and safe manner. Summary: ML has great potential in managing diabetes and the future is in furthering the partnership of regulatory bodies with health service researchers, clinicians, developers, and patients to improve the outcomes of populations and individual patients with diabetes.",
        "DOI": "10.1007/s11892-020-1287-2",
        "paper_author": "Broome D.T.",
        "affiliation_name": "Cleveland Clinic Foundation",
        "affiliation_city": "Cleveland",
        "affiliation_country": "United States",
        "affiliation_id": "60021160",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "REAL-time smartphone activity classification using inertial sensors—recognition of scrolling, typing, and watching videos while sitting or walking",
        "publication": "Sensors (Switzerland)",
        "citied_by": "25",
        "cover_date": "2020-02-01",
        "Abstract": "By developing awareness of smartphone activities that the user is performing on their smartphone, such as scrolling feeds, typing and watching videos, we can develop application features that are beneficial to the users, such as personalization. It is currently not possible to access real-time smartphone activities directly, due to standard smartphone privileges and if internal movement sensors can detect them, there may be implications for access policies. Our research seeks to understand whether the sensor data from existing smartphone inertial measurement unit (IMU) sensors (triaxial accelerometers, gyroscopes and magnetometers) can be used to classify typical human smartphone activities. We designed and conducted a study with human participants which uses an Android app to collect motion data during scrolling, typing and watching videos, while walking or seated and the baseline of smartphone non-use, while sitting and walking. We then trained a machine learning (ML) model to perform real-time activity recognition of those eight states. We investigated various algorithms and parameters for the best accuracy. Our optimal solution achieved an accuracy of 78.6% with the Extremely Randomized Trees algorithm, data sampled at 50 Hz and 5-s windows. We conclude by discussing the viability of using IMU sensors to recognize common smartphone activities.",
        "DOI": "10.3390/s20030655",
        "paper_author": "Zhuo S.",
        "affiliation_name": "The University of Auckland",
        "affiliation_city": "Auckland",
        "affiliation_country": "New Zealand",
        "affiliation_id": "60005686",
        "affiliation_state": "AUK"
    },
    {
        "paper_title": "Accumulating evidence using crowdsourcing and machine learning: A living bibliography about existential risk and global catastrophic risk",
        "publication": "Futures",
        "citied_by": "13",
        "cover_date": "2020-02-01",
        "Abstract": "The study of existential risk — the risk of human extinction or the collapse of human civilization — has only recently emerged as an integrated field of research, and yet an overwhelming volume of relevant research has already been published. To provide an evidence base for policy and risk analysis, this research should be systematically reviewed. In a systematic review, one of many time-consuming tasks is to read the titles and abstracts of research publications, to see if they meet the inclusion criteria. We show how this task can be shared between multiple people (using crowdsourcing) and partially automated (using machine learning), as methods of handling an overwhelming volume of research. We used these methods to create The Existential Risk Research Assessment (TERRA), which is a living bibliography of relevant publications that gets updated each month (www.x-risk.net). We present the results from the first ten months of TERRA, in which 10,001 abstracts were screened by 51 participants. Several challenges need to be met before these methods can be used in systematic reviews. However, we suggest that collaborative and cumulative methods such as these will need to be used in systematic reviews as the volume of research increases.",
        "DOI": "10.1016/j.futures.2019.102508",
        "paper_author": "Shackelford G.E.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Designing robust policies under deep uncertainty for mitigating epidemics",
        "publication": "Computers and Industrial Engineering",
        "citied_by": "26",
        "cover_date": "2020-02-01",
        "Abstract": "Robust supply chain policies under deep uncertainties are developed for minimizing the impact of an epidemic. A generic integrated supply chain-epidemic model is considered in this paper. Exploratory Modelling and Analysis (EMA) methodology is chosen over predictive modelling in order to find the ensembles of all plausible behaviours of an epidemic. The relative importance of the model parameters is analysed using machine learning algorithms, and scenario discovery analysis is conducted to explore the critical combination of parameters and values responsible for specific scenarios. The analysis revealed that the drug (medicine) shortage and the duration of shortage plays an important role in controlling the dynamics of an epidemic. Finally, a few robust supply chain policies are discussed for mitigating an epidemic.",
        "DOI": "10.1016/j.cie.2019.106221",
        "paper_author": "Paul S.",
        "affiliation_name": "Indian Institute of Technology Bombay",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60014153",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Editorial",
        "publication": "Modern Pathology",
        "citied_by": "0",
        "cover_date": "2020-02-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41379-019-0438-y",
        "paper_author": "Netto G.J.",
        "affiliation_name": "UAB Department of Pathology",
        "affiliation_city": "Birmingham",
        "affiliation_country": "United States",
        "affiliation_id": "60022965",
        "affiliation_state": "AL"
    },
    {
        "paper_title": "Adaptive Online Decision Method for Initial Congestion Window in 5G Mobile Edge Computing Using Deep Reinforcement Learning",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "50",
        "cover_date": "2020-02-01",
        "Abstract": "Mobile edge computing provides users with low response time and avoids unnecessary data transmission. Due to the deployment of 5G, the emerging edge systems can provide gigabit bandwidth. However, network protocols have not evolved together. In TCP, the initial congestion window (IW) is such a low value that most short flows still stay in slow start phase when finishing, and do not fully utilize available bandwidth. Naively increasing IW may result in congestion, which causes long latency. Moreover, since the network environment is dynamic, we have a challenging problem - how to adaptively adjust IW such that flow completion time is optimized, while congestion is minimized. In this paper, we propose an adaptive online decision method to solve the problem, which learns the best policy using deep reinforcement learning stably and fast. In addition, we propose an approach to further improve the performance by supervised learning, using data collected during online learning. We also propose to adopt SDN to address the challenges in implementing our method in MEC systems. To evaluate our method, we build an MEC simulator based on ns3. Our simulations demonstrate that our method performs better than existing methods. It can effectively reduce FCT with little congestion caused.",
        "DOI": "10.1109/JSAC.2019.2959187",
        "paper_author": "Xie R.",
        "affiliation_name": "Shenzhen University",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60000937",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Virtual Network Function Placement Optimization with Deep Reinforcement Learning",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "98",
        "cover_date": "2020-02-01",
        "Abstract": "Network Function Virtualization (NFV) introduces a new network architecture framework that evolves network functions, traditionally deployed over dedicated equipment, to software implementations that run on general-purpose hardware. One of the main challenges for deploying NFV is the optimal resource placement of demanded network services in the NFV infrastructure. The virtual network function placement and network embedding can be formulated as a mathematical optimization problem concerned with a set of feasibility constraints that express the restrictions of the network infrastructure and the services contracted. This problem has been reported to be NP-hard, as a result most of the optimization work carried out in the area has focused on designing heuristic and metaheuristic algorithms. Nevertheless, in highly constrained problems, as in this case, inferring a competitive heuristic can be a daunting task that requires expertise. Consequently, an interesting solution is the use of Reinforcement Learning to model an optimization policy. The work presented here extends the Neural Combinatorial Optimization theory by considering constraints in the definition of the problem. The resulting agent is able to learn placement decisions by exploring the NFV infrastructure with the aim of minimizing the overall power consumption. The experiments conducted demonstrate that when the proposed strategy is also combined with heuristics, highly competitive results are achieved using relatively simple algorithms.",
        "DOI": "10.1109/JSAC.2019.2959183",
        "paper_author": "Solozabal R.",
        "affiliation_name": "Universidad del Pais Vasco",
        "affiliation_city": "Leioa",
        "affiliation_country": "Spain",
        "affiliation_id": "60027856",
        "affiliation_state": "Biscay"
    },
    {
        "paper_title": "Incorporating environmental variables into a MODIS-based crop yield estimation method for United States corn and soybeans through the use of a random forest regression algorithm",
        "publication": "ISPRS Journal of Photogrammetry and Remote Sensing",
        "citied_by": "115",
        "cover_date": "2020-02-01",
        "Abstract": "Satellite-based remote sensing is a powerful form of technology that can provide food security policy makers with reliable information. This information allows them to estimate final crop yields on a global scale within reasonable time frames and with higher spatial resolution than with the use of pure statistical data. Satellite-based crop yield estimation methods are commonly based on the high correlation between the crop yield and the vegetation index (VI), taken at a specific phenological stage. Although VI-based crop yield estimation methods that make use of one approximation formula can easily and effectively estimate the spatial distribution of corn and soybean yields in the United States, there are still some associated drawbacks to this approach that result in the underestimation of crop yields, especially in irrigated regions. Furthermore, a fundamental problem with this approach is the difficulty in evaluation of environmental stress-related physiological disorders such as sterility, which cannot be evaluated based on VIs as an alternative value to biomass. This study's objective was, thus, to overcome the limitations associated with the conventional approach by incorporating additional environmental variables into the proposed method along with the application of a random forest regression algorithm for estimating United States (US) corn and soybean yields with higher accuracy. This study compared three methods: (1) a conventional method based on a linear regression model (LM method) calibrated using limited past data, (2) a method, which was slightly altered from the LM method in terms of the use of a polynomial regression model (PM method), and (3) the newly proposed method, which involved the application of a random forest regression algorithm and the use of irrigated harvested cropland percentage and reanalysis data for temperature, precipitation, shortwave radiation, and soil moisture (RF method). The time-series correlation between the moderate resolution imaging spectroradiometer (MODIS) wide dynamic ranged vegetation index (WDRVI) and corn and soybean yields were analyzed as part of a preliminary investigation to determine the best time for recording the MODIS WDRVI as an explanatory variable in the study area. The results revealed that the MODIS WDRVI demonstrated the highest correlation with county-level statistical yields 13 days before the silking stage for corn and 6 days before the setting pods stage for soybeans. The regression formulas for the LM and the PM method were developed based on assigning the MODIS WDRVI to these phenological stages as explanatory variables. The advantage of the PM method over the LM method was found to be its adaptability to high-yield counties because of the inherent effect of using a polynomial regression equation. The LM method, which made use of a linear regression equation calibrated using limited past data (2009–2010), could not be adapted to increased yields encountered in recent years without recalibration with the latest data. The RF method learning models were individually optimized for each state and crop. This optimization revealed, that our learning model that incorporated every available variable did not always perform best, probably due to overfitting. In the major irrigated states of Kansas, and Nebraska, the spatial data of the percentage of irrigated harvested cropland improve the estimation accuracy of the RF method for both corn and soybean. In the states of Illinois and Iowa, the RF method, which incorporated primarily the weather-related variables of soil moisture, precipitation, temperature, and shortwave radiation, improved the estimation accuracy due to a response of rainfed agriculture to environmental stress. This is especially true for soybean. The validation results indicated that the estimation accuracy of the RF method (root mean square error RMSE: 0.539 t/ha for corn, 0.206 t/ha for soybeans) was higher than that of the PM method (RMSE: 0.897 t/ha for corn, 0.283 t/ha for soybeans) at the state level, particularly due to the effect of bias correction in irrigated regions. Moreover, it was confirmed that the RF method could provide an accurate estimate of the yield reduction in soybeans caused by a drought occurring during late vegetative stages in Illinois in 2003. The PM method could not be used to evaluate this drought-induced yield reduction based on the VIs and key phenological stages. According to visual depictions of corn- and soybean-yield estimation maps, the RF-derived maps corresponded better with the yield maps derived from the National Agricultural Statistics Service (NASS)-statistical data than the PM-derived maps, especially in low-yield and irrigated regions.",
        "DOI": "10.1016/j.isprsjprs.2019.12.012",
        "paper_author": "Sakamoto T.",
        "affiliation_name": "National Agriculture and Food Research Organization, NARO",
        "affiliation_city": "Tsukuba",
        "affiliation_country": "Japan",
        "affiliation_id": "60014250",
        "affiliation_state": "Ibaraki"
    },
    {
        "paper_title": "Algorithmic approach to forecasting rare violent events: An illustration based in intimate partner violence perpetration",
        "publication": "Criminology and Public Policy",
        "citied_by": "14",
        "cover_date": "2020-02-01",
        "Abstract": "Research Summary: Mass violence, almost no matter how defined, is (thankfully) rare. Rare events are difficult to study in a systematic manner. Standard statistical procedures can fail badly, and usefully accurate forecasts of rare events often are little more than an aspiration. We offer an unconventional approach for the statistical analysis of rare events illustrated by an extensive case study. We report research aimed at learning about the attributes of very-high-risk intimate partner violence (IPV) perpetrators and the circumstances associated with their IPV incidents reported to the police. “Very high risk” is defined as having a high probability of committing a repeat IPV assault in which the victim is injured. Such individuals represent a very small fraction of all IPV perpetrators; these acts of violence reported to the police are rare. To learn about them nevertheless, we sequentially apply in a novel fashion three algorithms to data collected from a large metropolitan police department: stochastic gradient boosting, a genetic algorithm inspired by natural selection, and agglomerative clustering. We try to characterize not just perpetrators who on balance are predicted to reoffend but also who are very likely to reoffend in a manner that leads to victim injuries. Important lessons for forecasts of mass violence are presented. Policy Implications: If one intends to forecast mass violence, it is probably important to consider approaches less dependent on statistical procedures common in criminology. Given that one needs to “fatten” the right tail of the rare events distribution, a combination of supervised machine learning and genetic algorithms may be a useful approach. One can then study a synthetic population of rare events almost as if they were an empirical population of rare events. Variants on this strategy are increasingly common in machine learning and causal inference. Our overall goal is to unearth predictors that forecast well. In the absence of sufficiently accurate forecasts, scarce resources to help prevent mass violence cannot be allocated where they are most needed.",
        "DOI": "10.1111/1745-9133.12476",
        "paper_author": "Berk R.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60006297",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Artificial intelligence: Power for civilisation - and for better healthcare",
        "publication": "Public Health Genomics",
        "citied_by": "46",
        "cover_date": "2020-02-01",
        "Abstract": "Artificial intelligence (AI) is changing the world we live in, and it has the potential to transform struggling healthcare systems with new efficiencies, new therapies, new diagnostics, and new economies. Already, AI is having an impact on healthcare, and new prospects of far greater advances open up daily. This paper sets out how AI can bring new precision to care, with benefits for patients and for society as a whole. But it also sets out the conditions for realizing the potential: key issues are ensuring adequate access to data, an appropriate regulatory environment, action to sustain innovation in research institutes and industry big and small, promotion of take-up of innovation by the healthcare establishment, and resolution of a range of vital legal and ethical questions centred on safeguarding patients and their rights. For Europe to fulfil the conditions for success, it will have to find a new spirit of cooperation that can overcome the handicaps of the continent's fragmented technical and legal landscape. The start the European Union has made shows some ambition, but a clearer strategic vision and firmer plans for implementation will be needed. The European Alliance for Personalised Medicine (EAPM) has listed its own priorities: data, integrating innovation into care, building trust, developing skills and constructing policy frameworks that guarantee infrastructure, equitable access, and legal clarity.",
        "DOI": "10.1159/000504785",
        "paper_author": "Horgan D.",
        "affiliation_name": "European Alliance for Personalised Medicine",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "116188894",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Identifying high-risk firearm owners to prevent mass violence",
        "publication": "Criminology and Public Policy",
        "citied_by": "13",
        "cover_date": "2020-02-01",
        "Abstract": "Research Summary: In this article, we detail recent efforts in California to identify and target high-risk firearm owners to help prevent firearm violence, including mass shootings. We begin by describing gun violence restraining orders, also known as extreme risk protection orders, which provide a judicial mechanism for firearm recovery and a time-limited prohibition on firearm purchases. Next, we discuss California's Armed and Prohibited Persons (APPS) database and enforcement system. APPS is used to identify newly prohibited persons among legal firearm owners and to help law enforcement recover those firearms. Finally, we highlight early research in which machine learning for rare event detection is employed to forecast individual risk using California's decades worth of firearm transaction records and other readily available administrative data. Policy Implications: The approaches described range in scale, scope, and strategy, but all three allow for targeted intervention at times of heightened risk. In so doing, they offer the potential to provide outsized benefits to efforts to prevent mass violence.",
        "DOI": "10.1111/1745-9133.12477",
        "paper_author": "Laqueur H.S.",
        "affiliation_name": "University of California, Davis",
        "affiliation_city": "Davis",
        "affiliation_country": "United States",
        "affiliation_id": "60014439",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Optimal VNF Placement via Deep Reinforcement Learning in SDN/NFV-Enabled Networks",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "196",
        "cover_date": "2020-02-01",
        "Abstract": "The emerging paradigm - Software-Defined Networking (SDN) and Network Function Virtualization (NFV) - makes it feasible and scalable to run Virtual Network Functions (VNFs) in commercial-off-the-shelf devices, which provides a variety of network services with reduced cost. Benefitting from centralized network management, lots of information about network devices, traffic and resources can be collected in SDN/NFV-enabled networks. Using powerful machine learning tools, algorithms can be designed in a customized way according to the collected information to efficiently optimize network performance. In this paper, we study the VNF placement problem in SDN/NFV-enabled networks, which is naturally formulated as a Binary Integer Programming (BIP) problem. Using deep reinforcement learning, we propose a Double Deep Q Network-based VNF Placement Algorithm (DDQN-VNFPA). Specifically, DDQN determines the optimal solution from a prohibitively large solution space and DDQN-VNFPA then places/releases VNF Instances (VNFIs) following a threshold-based policy. We evaluate DDQN-VNFPA with trace-driven simulations on a real-world network topology. Evaluation results show that DDQN-VNFPA can get improved network performance in terms of the reject number and reject ratio of Service Function Chain Requests (SFCRs), throughput, end-to-end delay, VNFI running time and load balancing compared with the algorithms in existing literatures.",
        "DOI": "10.1109/JSAC.2019.2959181",
        "paper_author": "Pei J.",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China",
        "affiliation_id": "60019118",
        "affiliation_state": "Anhui"
    },
    {
        "paper_title": "Management and Orchestration of Virtual Network Functions via Deep Reinforcement Learning",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "52",
        "cover_date": "2020-02-01",
        "Abstract": "Management and orchestration (MANO) of resources by virtual network functions (VNFs) represents one of the key challenges towards a fully virtualized network architecture as envisaged by 5G standards. Current threshold-based policies inefficiently over-provision network resources and under-utilize available hardware, incurring high cost for network operators, and consequently, the users. In this work, we present a MANO algorithm for VNFs allowing a central unit (CU) to learn to autonomously re-configure resources (processing power and storage), deploy new VNF instances, or offload them to the cloud, depending on the network conditions, available pool of resources, and the VNF requirements, with the goal of minimizing a cost function that takes into account the economical cost as well as latency and the quality-of-service (QoS) experienced by the users. First, we formulate the stochastic resource optimization problem as a parameterized action Markov decision process (PAMDP). Then, we propose a solution based on deep reinforcement learning (DRL). More precisely, we present a novel RL approach, called parameterized action twin (PAT) deterministic policy gradient, which leverages an actor-critic architecture to learn to provision resources to the VNFs in an online manner. Finally, we present numerical performance results, and map them to 5G key performance indicators (KPIs). To the best of our knowledge, this is the first work that considers DRL for MANO of VNFs' physical resources.",
        "DOI": "10.1109/JSAC.2019.2959263",
        "paper_author": "Pujol Roig J.S.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Soybean yield prediction from UAV using multimodal data fusion and deep learning",
        "publication": "Remote Sensing of Environment",
        "citied_by": "646",
        "cover_date": "2020-02-01",
        "Abstract": "Preharvest crop yield prediction is critical for grain policy making and food security. Early estimation of yield at field or plot scale also contributes to high-throughput plant phenotyping and precision agriculture. New developments in Unmanned Aerial Vehicle (UAV) platforms and sensor technology facilitate cost-effective data collection through simultaneous multi-sensor/multimodal data collection at very high spatial and spectral resolutions. The objective of this study is to evaluate the power of UAV-based multimodal data fusion using RGB, multispectral and thermal sensors to estimate soybean (Glycine max) grain yield within the framework of Deep Neural Network (DNN). RGB, multispectral, and thermal images were collected using a low-cost multi-sensory UAV from a test site in Columbia, Missouri, USA. Multimodal information, such as canopy spectral, structure, thermal and texture features, was extracted and combined to predict crop grain yield using Partial Least Squares Regression (PLSR), Random Forest Regression (RFR), Support Vector Regression (SVR), input-level feature fusion based DNN (DNN-F1) and intermediate-level feature fusion based DNN (DNN-F2). The results can be summarized in three messages: (1) multimodal data fusion improves the yield prediction accuracy and is more adaptable to spatial variations; (2) DNN-based models improve yield prediction model accuracy: the highest accuracy was obtained by DNN-F2 with an R2 of 0.720 and a relative root mean square error (RMSE%) of 15.9%; (3) DNN-based models were less prone to saturation effects, and exhibited more adaptive performance in predicting grain yields across the Dwight, Pana and AG3432 soybean genotypes in our study. Furthermore, DNN-based models demonstrated consistent performance over space with less spatial dependency and variations. This study indicates that multimodal data fusion using low-cost UAV within a DNN framework can provide a relatively accurate and robust estimation of crop yield, and deliver valuable insight for high-throughput phenotyping and crop field management with high spatial precision.",
        "DOI": "10.1016/j.rse.2019.111599",
        "paper_author": "Maimaitijiang M.",
        "affiliation_name": "Saint Louis University School of Science and Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60279432",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Society of Toxicologic Pathology Digital Pathology and Image Analysis Special Interest Group Article*: Opinion on the Application of Artificial Intelligence and Machine Learning to Digital Toxicologic Pathology",
        "publication": "Toxicologic Pathology",
        "citied_by": "45",
        "cover_date": "2020-02-01",
        "Abstract": "Toxicologic pathology is transitioning from analog to digital methods. This transition seems inevitable due to a host of ongoing social and medical technological forces. Of these, artificial intelligence (AI) and in particular machine learning (ML) are globally disruptive, rapidly growing sectors of technology whose impact on the long-established field of histopathology is quickly being realized. The development of increasing numbers of algorithms, peering ever deeper into the histopathological space, has demonstrated to the scientific community that AI pathology platforms are now poised to truly impact the future of precision and personalized medicine. However, as with all great technological advances, there are implementation and adoption challenges. This review aims to define common and relevant AI and ML terminology, describe data generation and interpretation, outline current and potential future business cases, discuss validation and regulatory hurdles, and most importantly, propose how overcoming the challenges of this burgeoning technology may shape toxicologic pathology for years to come, enabling pathologists to contribute even more effectively to answering scientific questions and solving global health issues.*This article is a product of a Special Interest Group of the Society of Toxicologic Pathology (STP). The views expressed in this article are those of the authors and do not necessarily represent the policies, positions, or opinions of the STP.",
        "DOI": "10.1177/0192623319881401",
        "paper_author": "Turner O.C.",
        "affiliation_name": "Novartis Institutes for BioMedical Research, Inc.",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60006840",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "STEREOS: Smart Table EntRy Eviction for OpenFlow Switches",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "23",
        "cover_date": "2020-02-01",
        "Abstract": "Software-defined networking (SDN) is fundamentally changing the way networks operate, enabling programmable and flexible network management and configuration. As the de facto standard southbound interface of SDN, OpenFlow defines how the control plane interacts with the data forwarding plane. In OpenFlow, flow tables play a significant role in packet forwarding. However, the size of the flow table is limited due to power, cost, and silicon area constraints and capacity-limited tables cannot hold all of the active flows in medium-to-large-scale SDN networks. Thus, when a flow table reaches capacity, an intelligent eviction strategy, which efficiently manages the limited flow table resource, is critical. In this paper, we propose Smart Table EntRy Eviction for OpenFlow Switches (STEREOS), which uses machine learning to classify flow entries as active or inactive and forms the basis for intelligent eviction. Trace-driven simulations demonstrate that STEREOS increases flow table usage by more than 50% and reduces incorrect flow entry evictions by up to 78%, compared with the dominant Least Recently Used eviction policy. Moreover, packet-level simulations of a datacenter network demonstrate that STEREOS can greatly reduce the control overhead, increase overall network throughput by 19%, and reduce packet loss rate by 70%.",
        "DOI": "10.1109/JSAC.2019.2959184",
        "paper_author": "Yang H.",
        "affiliation_name": "School of Electrical and Computer Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60021032",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "TrojanSense, a participatory sensing framework for occupant-aware management of thermal comfort in campus buildings",
        "publication": "Building and Environment",
        "citied_by": "25",
        "cover_date": "2020-02-01",
        "Abstract": "This paper describes the development of TrojanSense, a participatory sensing framework developed to collect, analyze and report user assessments of thermal preference at the campus scale with room-level spatial resolution. TrojanSense was developed with the goal of supporting initiatives to improve campus community engagement on issues of occupant thermal comfort, energy efficiency, and equity in the environmental control of university buildings. TrojanSense is an open-loop system, where outcomes pairing thermal preference and concurrent indoor temperature measurements are analyzed and reported with room-level resolution on a Campus Thermal Preference Map to support building operators and to inform campus policies related to thermal comfort and energy efficiency. The TrojanSense framework integrates wireless Bluetooth Low Energy (BLE) proximity beacons embedded in campus buildings to sense temperature and to automatically solicit occupant feedback using proximity-based prompts. Data from an exploratory pilot study are analyzed to examine the applicability of the approach for developing predictive models of thermal preference and for placing existing space conditioning assumptions in context with occupant feedback. Results demonstrate the potential for TrojanSense to identify overcooling using objective and subjective measures, increase the accuracy of predictions of thermal preference, and provide greater insight into the impact of outdoor weather on thermal preference to inform future climate-responsive control strategies.",
        "DOI": "10.1016/j.buildenv.2019.106588",
        "paper_author": "Konis K.",
        "affiliation_name": "University of Southern California",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60029311",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Learning through practice? Learning from the REDD+ demonstration project, Kalimantan Forests and Climate Partnership (KFCP) in Indonesia",
        "publication": "Land Use Policy",
        "citied_by": "12",
        "cover_date": "2020-02-01",
        "Abstract": "Despite a growing recognition of the importance of social learning in governing and managing land use, the understanding and practice of learning has received limited attention from researchers. In global environmental programs and projects aimed at supporting sustainable land use in developing countries, learning is often promoted but without explicit learning goals. The focus may be on capacity building and community participation, and on testing policy tools, rather than on collaborative social learning. In this study, we looked behind the rhetoric of learning in the Kalimantan Forests and Climate Partnership (KFCP), a large demonstration project for Reducing Emissions from Deforestation and Forest Degradation (REDD+) in Indonesia. The novelty of such mechanisms, linked to international forest carbon outcomes, means that learning lessons provides a rationale for REDD+ pilot activities. We used a qualitative approach to examine the nature and type of learning that occurred in the KFCP. While the stated project aims were to support policy experimentation and apply learning, the project design was highly technical, and project decision-making did not explicitly encourage joint problem solving. Despite the project's shortcomings, we identified that learning did occur by the end of the project in ways that were different to the initial goals. Our findings suggest that flexibility and openness in project design and implementation can enable different local actors to define shared learning agendas in ways that are meaningful for them. Designing and implementing environmental projects, and learning goals within them, should attend to the needs and aspirations of those who will have to live with their long-term consequences. Learning should be integrated into international environmental programs and projects at all levels, including for policy and funding bodies, rather than focusing on local capacity building and similar project ‘benefits’. Interviewees’ eagerness to learn suggests that building approaches to social learning into program design has the potential to yield opportunities for learning beyond REDD+ to other forms of policy experimentation and governance innovations.",
        "DOI": "10.1016/j.landusepol.2019.104285",
        "paper_author": "Sanders A.J.P.",
        "affiliation_name": "School of Ecosystem and Forest Science",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118639",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Integrated environmental modeling for efficient aquifer vulnerability assessment using machine learning",
        "publication": "Environmental Modelling and Software",
        "citied_by": "21",
        "cover_date": "2020-02-01",
        "Abstract": "Nitrate contamination in groundwater was evaluated using the concept of integrated aquifer assessment by combining groundwater characterization and risk analysis with tiered approaches for land and surface runoff contamination by soil chemicals and leaching of contamination to groundwater in the Upper White River Watershed (UWRW) in Indiana. Integrated aquifer vulnerability assessment was conducted using an integration of a distributed watershed model (Soil and Water Assessment Tool [SWAT]) and a machine learning technique (Geospatial-Artificial Neural Network [Geo-ANN]). The results indicate that integrated aquifer vulnerability assessment performed well based on the model performance (NSE/R2/PBIAS = 0.66/0.70/0.07). Thus, the overall assessment of aquifer vulnerability can be performed using the integrated aquifer vulnerability assessment technique provided in this study. Moreover, this approach provides an efficient guide for managing groundwater resources for policy makers and groundwater-related researchers.",
        "DOI": "10.1016/j.envsoft.2019.104602",
        "paper_author": "Jang W.S.",
        "affiliation_name": "University of Colorado Boulder",
        "affiliation_city": "Boulder",
        "affiliation_country": "United States",
        "affiliation_id": "60000221",
        "affiliation_state": "CO"
    },
    {
        "paper_title": "Study on deep reinforcement learning techniques for building energy consumption forecasting",
        "publication": "Energy and Buildings",
        "citied_by": "211",
        "cover_date": "2020-02-01",
        "Abstract": "Reliable and accurate building energy consumption prediction is becoming increasingly pivotal in building energy management. Currently, data-driven approach has shown promising performances and gained lots of research attention due to its efficiency and flexibility. As a combination of reinforcement learning and deep learning, deep reinforcement learning (DRL) techniques are expected to solve nonlinear and complex issues. However, very little is known about DRL techniques in forecasting building energy consumption. Therefore, this paper presents a case study of an office building using three commonly-used DRL techniques to forecast building energy consumption, namely Asynchronous Advantage Actor-Critic (A3C), Deep Deterministic Policy Gradient (DDPG) and Recurrent Deterministic Policy Gradient (RDPG). The objective is to investigate the potential of DRL techniques in building energy consumption prediction field. A comprehensive comparison between DRL models and common supervised models is also provided. The results demonstrate that the proposed DDPG and RDPG models have obvious advantages in forecasting building energy consumption compared to common supervised models, while accounting for more computation time for model training. Their prediction performances measured by mean absolute error (MAE) can be improved by 16%-24% for single-step ahead prediction, and 19%-32% for multi-step ahead prediction. The results also indicate that A3C performs poor prediction accuracy and shows much slower convergence speed than DDPG and RDPG. However, A3C is still the most efficient technique among these three DRL methods. The findings are enlightening and the proposed DRL methodologies can be positively extended to other prediction problems, e.g., wind speed prediction and electricity load prediction.",
        "DOI": "10.1016/j.enbuild.2019.109675",
        "paper_author": "Liu T.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Bringing statistical learning machines together for hydro-climatological predictions - Case study for Sacramento San joaquin River Basin, California",
        "publication": "Journal of Hydrology: Regional Studies",
        "citied_by": "25",
        "cover_date": "2020-02-01",
        "Abstract": "Study region: Sacramento San Joaquin River Basin, California Study focus: The study forecasts the streamflow at a regional scale within SSJ river basin with largescale climate variables. The proposed approach eliminates the bias resulting from predefined indices at regional scale. The study was performed for eight unimpaired streamflow stations from 1962–2016. First, the Singular Valued Decomposition (SVD) teleconnections of the streamflow corresponding to 500 mbar geopotential height, sea surface temperature, 500 mbar specific humidity (SHUM500), and 500 mbar U-wind (U500) were obtained. Second, the skillful SVD teleconnections were screened non-parametrically. Finally, the screened teleconnections were used as the streamflow predictors in the non-linear regression models (K-nearest neighbor regression and data-driven support vector machine). New hydrological insights: The SVD results identified new spatial regions that have not been included in existing predefined indices. The nonparametric model indicated the teleconnections of SHUM500 and U500 being better streamflow predictors compared to other climate variables. The regression models were capable to apprehend most of the sustained low flows, proving the model to be effective for drought-affected regions. It was also observed that the proposed approach showed better forecasting skills with preprocessed large scale climate variables rather than using the predefined indices. The proposed study is simple, yet robust in providing qualitative streamflow forecasts that may assist water managers in making policy-related decisions when planning and managing watersheds.",
        "DOI": "10.1016/j.ejrh.2019.100651",
        "paper_author": "Thakur B.",
        "affiliation_name": "College of Engineering, Computing, Technology, and Mathematics",
        "affiliation_city": "Carbondale",
        "affiliation_country": "United States",
        "affiliation_id": "60279910",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Robot-assisted flexible needle insertion using universal distributional deep reinforcement learning",
        "publication": "International Journal of Computer Assisted Radiology and Surgery",
        "citied_by": "26",
        "cover_date": "2020-02-01",
        "Abstract": "Purpose: Flexible needle insertion is an important minimally invasive surgery approach for biopsy and radio-frequency ablation. This approach can minimize intraoperative trauma and improve postoperative recovery. We propose a new path planning framework using multi-goal deep reinforcement learning to overcome the difficulties in uncertain needle–tissue interactions and enhance the robustness of robot-assisted insertion process. Methods: This framework utilizes a new algorithm called universal distributional Q-learning (UDQL) to learn a stable steering policy and perform risk management by visualizing the learned Q-value distribution. To further improve the robustness, universal value function approximation is leveraged in the training process of UDQL to maximize generalization and connect to diagnosis by adapting fast re-planning and transfer learning. Results: Computer simulation and phantom experimental results show our proposed framework can securely steer flexible needles with high insertion accuracy and robustness. The framework also improves robustness by providing distribution information to clinicians for diagnosis and decision making during surgery. Conclusions: Compared with previous methods, the proposed framework can perform multi-target needle insertion through single insertion point qunder continuous state space model with higher accuracy and robustness.",
        "DOI": "10.1007/s11548-019-02098-7",
        "paper_author": "Tan X.",
        "affiliation_name": "National University of Singapore",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60017161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Adaptive battery aware power management of a computer with self power-managed components",
        "publication": "Microprocessors and Microsystems",
        "citied_by": "6",
        "cover_date": "2020-02-01",
        "Abstract": "Dynamic power management strategies are generally used to achieve efficient power consumption of battery operated computer systems. Such computer systems usually integrate a number of built-in power-management policies. These policies are generally integrated into device drivers and cannot be changed. This paper addresses the problem of adaptive dynamic power management of a battery operated computer with self-power managed components. The power management task is split into Component Power Manager (CPM) and Global Power Manager (GPM). The CPM is the local-level policy that is pre-defined and can't change. The GPM cannot overwrite the CPM policy. A Service Flow Controller (SFC) is incorporated to control the service request generation for a specific component. The GPM uses model free reinforcement learning to adequately guide SFC actions. Moreover, the GPM implements Reinforcement learning based battery power management aiming at optimizing the battery's State of Charge (SoC) and improving its lifetime. This is performed by letting the GPM adapt the system quality of services to the actual battery SoC. Experiments on measured data traces confirmed the effectiveness of the proposed approach. Up to 57.2% of maximum SoC savings are obtained while good performance levels are maintained. Compared to prior reference studies, the proposed approach is model free, event driven, adapts to non-stationary workloads, considers multiple types of user applications, models the battery nonlinear characteristics, can handle SoC degradation and performance at the same time, and is capable to achieve deep and wide SoC degradation/performance tradeoff curves.",
        "DOI": "10.1016/j.micpro.2019.102947",
        "paper_author": "Ammari A.C.",
        "affiliation_name": "Sultan Qaboos University",
        "affiliation_city": "Muscat",
        "affiliation_country": "Oman",
        "affiliation_id": "60071768",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mining government tweets to identify and predict citizens engagement",
        "publication": "Technology in Society",
        "citied_by": "48",
        "cover_date": "2020-02-01",
        "Abstract": "The rise of social media offered new channels of communication between a government and its citizens. The social media channels are interactive, inclusive, low-cost, and unconstrained by time or place. This two-way communication between governments and citizens is referred to as electronic citizen participation, or e-participation. E-participation in the age of technology is considered as a mean for citizens to express their opinions and as a new input to be integrated by policy makers to take decisions. Governments and policy makers always aim to increase such participation not only to utilize public expertise and experience, but also to increase the transparency, trust, and acceptability of government decisions. In this research we investigate how governments can increase citizens e-participation on social media. We collected 55,809 tweets over a period of one year from Twitter accounts of a progressive government in the Arab world. This was followed by statistical analysis of posts characteristics (Type, Day, Time) and their impact on citizens' engagement. Then, we evaluated how well can different machine learning techniques predict user engagement. Results of the statistical analysis confirmed that post type (video, image, link, and status) impacted citizens' engagement, with videos and images having the highest positive impact on engagement. Furthermore, posting government tweets on weekdays obtained higher citizens’ engagement than weekends. Conversely, time of post had a weak effect on engagement. The results from the machine learning experiments show that two techniques (Random Forest and Adaboost) produced more accurate predictions, particularly when tweet textual contents were also used in the prediction. These results can help governments increase the engagement of their citizens.",
        "DOI": "10.1016/j.techsoc.2019.101211",
        "paper_author": "Siyam N.",
        "affiliation_name": "British University in Dubai",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates",
        "affiliation_id": "60070792",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement learning and non-zero-sum game output regulation for multi-player linear uncertain systems",
        "publication": "Automatica",
        "citied_by": "68",
        "cover_date": "2020-02-01",
        "Abstract": "This paper studies the non-zero-sum game output regulation problem (GORP) for a class of continuous-time multi-player linear systems. Without the knowledge of state and input matrices, the Nash equilibrium solution, N-tuple of feedback control policy, is learned through online data collected along the system trajectories. A key strategy is, for the first time, to combine techniques from reinforcement learning (RL), differential game theory, and output regulation for data-driven control design. Different from the existing literature of adaptive optimal output regulation, the feedforward matrices are considered nontrivial. Theoretical analysis shows the disturbance rejection and tracking ability of the closed-loop system. Simulation results demonstrate the efficacy of the developed data-driven control approach.",
        "DOI": "10.1016/j.automatica.2019.108672",
        "paper_author": "Odekunle A.",
        "affiliation_name": "Georgia Southern University",
        "affiliation_city": "Statesboro",
        "affiliation_country": "United States",
        "affiliation_id": "60020059",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Low-level autonomous control and tracking of quadrotor using reinforcement learning",
        "publication": "Control Engineering Practice",
        "citied_by": "75",
        "cover_date": "2020-02-01",
        "Abstract": "This paper proposes a low-level quadrotor control algorithm using neural networks with model-free reinforcement learning, then explores the algorithm's capabilities on quadrotor hover and tracking tasks. We provide a new point of view by examining the well-known policy gradient algorithm from reinforcement learning, then relaxing its requirements to improve training efficiency. Without requiring expert demonstrations, the improved algorithm is then applied to train a quadrotor controller with its output directly mapped to four actuators in a simulator, which is a technique used to control any linear or nonlinear system under unknown dynamic parameters and disturbances. We show two experimental tasks both in simulation and real-world quadrotors to verify our method and demonstrate performance: 1) hovering at a fixed position, and 2) tracking along a specific trajectory. The video of our experiments can be found at https://youtu.be/oEVcdiFPnMo.",
        "DOI": "10.1016/j.conengprac.2019.104222",
        "paper_author": "Pi C.H.",
        "affiliation_name": "National Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60012370",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Teaching a humanoid robot to walk faster through Safe Reinforcement Learning",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "58",
        "cover_date": "2020-02-01",
        "Abstract": "Teaching a humanoid robot to walk is an open and challenging problem. Classical walking behaviors usually require the tuning of many control parameters (e.g., step size, speed). To find an initial or basic configuration of such parameters could not be so hard, but optimizing them for some goal (for instance, to walk faster) is not easy because, when defined incorrectly, may produce the fall of the humanoid, and the consequent damages. In this paper we propose the use of Safe Reinforcement Learning for improving the walking behavior of a humanoid that permits the robot to walk faster than with a pre-defined configuration. Safe Reinforcement Learning assumes the existence of a safe baseline policy that permits the humanoid to walk, and probabilistically reuse such a policy to learn a better one, which is represented following a case based approach. The proposed algorithm has been evaluated in a real humanoid robot proving that it drastically increases the learning speed while reduces the number of falls during learning when compared with state-of-the-art algorithms.",
        "DOI": "10.1016/j.engappai.2019.103360",
        "paper_author": "García J.",
        "affiliation_name": "Universidade do Porto",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60007249",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "A bad arm existence checking problem: How to utilize asymmetric problem structure?",
        "publication": "Machine Learning",
        "citied_by": "7",
        "cover_date": "2020-02-01",
        "Abstract": "We study a bad arm existence checking problem in a stochastic K-armed bandit setting, in which a player’s task is to judge whether a positive arm exists or all the arms are negative among given K arms by drawing as small number of arms as possible. Here, an arm is positive if its expected loss suffered by drawing the arm is at least a given threshold θU, and it is negative if that is less than another given threshold θL(≤ θU). This problem is a formalization of diagnosis of disease or machine failure. An interesting structure of this problem is the asymmetry of positive and negative arms’ roles; finding one positive arm is enough to judge positive existence while all the arms must be discriminated as negative to judge whole negativity. In the case with Δ= θU- θL> 0 , we propose elimination algorithms with arm selection policy (policy to determine the next arm to draw) and decision condition (condition to conclude positive arm’s existence or the drawn arm’s negativity) utilizing this asymmetric problem structure and prove its effectiveness theoretically and empirically.",
        "DOI": "10.1007/s10994-019-05854-7",
        "paper_author": "Tabata K.",
        "affiliation_name": "Hokkaido University",
        "affiliation_city": "Sapporo",
        "affiliation_country": "Japan",
        "affiliation_id": "60014652",
        "affiliation_state": "Hokkaido"
    },
    {
        "paper_title": "Battery Recovery-Aware Optimization for Embedded System Communications",
        "publication": "Wireless Personal Communications",
        "citied_by": "4",
        "cover_date": "2020-02-01",
        "Abstract": "In this paper, we consider a point-to-point wireless communications for embedded battery powered systems. We aim to provide an optimal use of all the usable capacity inside the battery before it becomes exhausted. For this purpose, we exploit the recovery effect to extend their lifetime. We consider a stochastic battery model and use both dynamic programming and reinforcement learning approaches to compute optimal transmission policies for wireless sensor networks. The obtained results show that the expected total transmitted data and the battery lifetime are maximized when all the charge units inside the battery are consumed.",
        "DOI": "10.1007/s11277-019-06820-1",
        "paper_author": "Assaouy M.",
        "affiliation_name": "Mohammed V University in Rabat",
        "affiliation_city": "Rabat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60019337",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An ensemble method for inverse reinforcement learning",
        "publication": "Information Sciences",
        "citied_by": "16",
        "cover_date": "2020-02-01",
        "Abstract": "In inverse reinforcement learning (IRL), a reward function is learnt to generalize experts’ behavior. This paper proposes a model-free IRL algorithm based on an ensemble method, where the reward function is regarded as a parametric function of expected features. In other words, the parameters are updated based on a weak classification method. The IRL is formulated as a problem of a boosting classifier, akin to the renowned Adaboost algorithm for classification, feature expectations from experts’ demonstration, and the trajectory induced by an agent's current policy. The proposed approach takes individual feature expectation as attractor or expeller, depending on the sign of the residuals of the state trajectories between expert's demonstration and the one induced by RL with the currently approximated reward function, so as to tackle its central challenges of accurate inference, generalizability, and correctness of prior knowledge. Then, the proposed method is applied further to approximate an abstract reward function from observations of more complex behavior composed of several basic actions. The results of the simulations in a labyrinth are shown to validate the proposed algorithm. Furthermore, behaviors composed of a set of primitive actions on a soccer robot field are examined for the applicability of the proposed method.",
        "DOI": "10.1016/j.ins.2019.09.066",
        "paper_author": "Lin J.L.",
        "affiliation_name": "Shih Hsin University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60027223",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Image captioning via hierarchical attention mechanism and policy gradient optimization",
        "publication": "Signal Processing",
        "citied_by": "40",
        "cover_date": "2020-02-01",
        "Abstract": "Automatically generating the descriptions of an image, i.e., image captioning, is an important and fundamental topic in artificial intelligence, which bridges the gap between computer vision and natural language processing. Based on the successful deep learning models, especially the CNN model and Long Short Term Memories (LSTMs) with attention mechanism, we propose a hierarchical attention model by utilizing both of the global CNN features and the local object features for more effective feature representation and reasoning in image captioning. The generative adversarial network (GAN), together with a reinforcement learning (RL) algorithm, is applied to solve the exposure bias problem in RNN-based supervised training for language problems. In addition, through the automatic measurement of the consistency between the generated caption and the image content by the discriminator in the GAN framework and RL optimization, we make the finally generated sentences more accurate and natural. Comprehensive experiments show the improved performance of the hierarchical attention mechanism and the effectiveness of our RL-based optimization method. Our model achieves state-of-the-art results on several important metrics in the MSCOCO dataset, using only greedy inference.",
        "DOI": "10.1016/j.sigpro.2019.107329",
        "paper_author": "Yan S.",
        "affiliation_name": "Queen's University Belfast",
        "affiliation_city": "Belfast",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60029738",
        "affiliation_state": "Northern Ireland"
    },
    {
        "paper_title": "Joint resource allocation and computation offloading in mobile edge computing for SDN based wireless networks",
        "publication": "Journal of Communications and Networks",
        "citied_by": "89",
        "cover_date": "2020-02-01",
        "Abstract": "The rapid growth of the internet usage and the distributed computing resources of edge devices create a necessity to have a reasonable controller to ensure efficient utilization of distributed computing resources in mobile edge computing (MEC). We envision the future MEC services, where quality of experience (QoE) of the services is further enhanced by software defined networks (SDNs) capabilities to reduce the application-level response time without service disruptions. SDN, which is not proposed specifically for edge computing, can in fact serve as an enabler to lower the complexity barriers involved and let the real potential of edge computing be achieved. In this paper, we investigate the task offloading and resource allocation problem in wireless MEC aiming to minimize the delay while saving the battery power of user device simultaneously. However, it is challenging to obtain an optimal policy in such a dynamic task offloading system. Learning from experience plays a vital role in time variant dynamic systems where reinforcement learning (RL) takes a long term goal into consideration besides immediate reward, which is very important for a dynamic environment. A novel software defined edge cloudlet (SDEC) based RL optimization framework is proposed to tackle the task offloading and resource allocation in wireless MEC. Specifically, Q-learning and cooperative Q-learning based reinforcement learning schemes are proposed for the intractable problem. Simulation results show that the proposed scheme achieves 31.39% and 62.10% reduction on the sum delay compared to other benchmark methods such as traditional Q-learning with a random algorithm and Q-learning with epsilon greedy.",
        "DOI": "10.1109/JCN.2019.000046",
        "paper_author": "Kiran N.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Continuous control with Stacked Deep Dynamic Recurrent Reinforcement Learning for portfolio optimization",
        "publication": "Expert Systems with Applications",
        "citied_by": "69",
        "cover_date": "2020-02-01",
        "Abstract": "Recurrent reinforcement learning (RRL) techniques have been used to optimize asset trading systems and have achieved outstanding results. However, the majority of the previous work has been dedicated to systems with discrete action spaces. To address the challenge of continuous action and multi-dimensional state spaces, we propose the so called Stacked Deep Dynamic Recurrent Reinforcement Learning (SDDRRL) architecture to construct a real-time optimal portfolio. The algorithm captures the up-to-date market conditions and rebalances the portfolio accordingly. Under this general vision, Sharpe ratio, which is one of the most widely accepted measures of risk-adjusted returns, has been used as a performance metric. Additionally, the performance of most machine learning algorithms highly depends on their hyperparameter settings. Therefore, we equipped SDDRRL with the ability to find the best possible architecture topology using an automated Gaussian Process (GP) with Expected Improvement (EI) as an acquisition function. This allows us to select the best architectures that maximizes the total return while respecting the cardinality constraints. Finally, our system was trained and tested in an online manner for 20 successive rounds with data for ten selected stocks from different sectors of the S&P 500 from January 1st, 2013 to July 31st, 2017. The experiments reveal that the proposed SDDRRL achieves superior performance compared to three benchmarks: the rolling horizon Mean-Variance Optimization (MVO) model, the rolling horizon risk parity model, and the uniform buy-and-hold (UBAH) index.",
        "DOI": "10.1016/j.eswa.2019.112891",
        "paper_author": "Aboussalah A.M.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "A reinforcement learning approach to optimal part flow management for gas turbine maintenance",
        "publication": "Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability",
        "citied_by": "14",
        "cover_date": "2020-02-01",
        "Abstract": "We consider the maintenance process of gas turbines used in the Oil and Gas industry: the capital parts are first removed from the gas turbines and replaced by parts of the same type taken from the warehouse; then, they are repaired at the workshop and returned to the warehouse for use in future maintenance events. Experience-based rules are used to manage the flow of the parts for a profitable gas turbine operation. In this article, we formalize the part flow management as a sequential decision problem and propose reinforcement learning for its solution. An application to a scaled-down case study derived from real industrial practice shows that reinforcement learning can find policies outperforming those based on experience-based rules.",
        "DOI": "10.1177/1748006X19869750",
        "paper_author": "Compare M.",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60023256",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Efficient Hybrid-Supervised Deep Reinforcement Learning for Person Following Robot",
        "publication": "Journal of Intelligent and Robotic Systems: Theory and Applications",
        "citied_by": "17",
        "cover_date": "2020-02-01",
        "Abstract": "Traditional person following robots usually need hand-crafted features and a well-designed controller to follow the assigned person. Normally it is difficult to be applied in outdoor situations due to variability and complexity of the environment. In this paper, we propose an approach in which an agent is trained by hybrid-supervised deep reinforcement learning (DRL) to perform a person following task in end-to-end manner. The approach enables the robot to learn features autonomously from monocular images and to enhance performance via robot-environment interaction. Experiments show that the proposed approach is adaptive to complex situations with significant illumination variation, object occlusion, target disappearance, pose change, and pedestrian interference. In order to speed up the training process to ensure easy application of DRL to real-world robotic follower controls, we apply an integration method through which the agent receives prior knowledge from a supervised learning (SL) policy network and reinforces its performance with a value-based or policy-based (including actor-critic method) DRL model. We also utilize an efficient data collection approach for supervised learning in the context of person following. Experimental results not only verify the robustness of the proposed DRL-based person following robot system, but also indicate how easily the robot can learn from mistakes and improve performance.",
        "DOI": "10.1007/s10846-019-01030-0",
        "paper_author": "Pang L.",
        "affiliation_name": "College of Information Science and Engineering, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60118697",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Big data analytics in health sector: Theoretical framework, techniques and prospects",
        "publication": "International Journal of Information Management",
        "citied_by": "148",
        "cover_date": "2020-02-01",
        "Abstract": "Clinicians, healthcare providers-suppliers, policy makers and patients are experiencing exciting opportunities in light of new information deriving from the analysis of big data sets, a capability that has emerged in the last decades. Due to the rapid increase of publications in the healthcare industry, we have conducted a structured review regarding healthcare big data analytics. With reference to the resource-based view theory we focus on how big data resources are utilised to create organization values/capabilities, and through content analysis of the selected publications we discuss: the classification of big data types related to healthcare, the associate analysis techniques, the created value for stakeholders, the platforms and tools for handling big health data and future aspects in the field. We present a number of pragmatic examples to show how the advances in healthcare were made possible. We believe that the findings of this review are stimulating and provide valuable information to practitioners, policy makers and researchers while presenting them with certain paths for future research.",
        "DOI": "10.1016/j.ijinfomgt.2019.05.003",
        "paper_author": "Galetsi P.",
        "affiliation_name": "International Hellenic University",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece",
        "affiliation_id": "60158100",
        "affiliation_state": "Central Macedonia"
    },
    {
        "paper_title": "Climate Change and Tourism in English-Language Newspaper Publications",
        "publication": "Journal of Travel Research",
        "citied_by": "34",
        "cover_date": "2020-02-01",
        "Abstract": "Tourism is one of the sectors of the economy that is most dependent on climate, creating multiple vulnerabilities and new opportunities arising with changing climate. Even though the links between tourism and climate have been well researched, this scientific knowledge has not percolated into policies and the ability to act. This disconnect between scientific knowledge and practices is frequently blamed on inadequate climate change communication to the public in mass media. We studied the mass media framing of climate change and tourism by analyzing English newspaper publications worldwide over the past 30 years. The paper presents a Big Data analysis of the content, geographical patterns, and temporal changes in newspapers’ publications on climate change and tourism.",
        "DOI": "10.1177/0047287519839157",
        "paper_author": "Ma S.",
        "affiliation_name": "University of Florida",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States",
        "affiliation_id": "60013959",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Artificial Intelligence Crime: An Interdisciplinary Analysis of Foreseeable Threats and Solutions",
        "publication": "Science and Engineering Ethics",
        "citied_by": "126",
        "cover_date": "2020-02-01",
        "Abstract": "Artificial intelligence (AI) research and regulation seek to balance the benefits of innovation against any potential harms and disruption. However, one unintended consequence of the recent surge in AI research is the potential re-orientation of AI technologies to facilitate criminal acts, term in this article AI-Crime (AIC). AIC is theoretically feasible thanks to published experiments in automating fraud targeted at social media users, as well as demonstrations of AI-driven manipulation of simulated markets. However, because AIC is still a relatively young and inherently interdisciplinary area—spanning socio-legal studies to formal science—there is little certainty of what an AIC future might look like. This article offers the first systematic, interdisciplinary literature analysis of the foreseeable threats of AIC, providing ethicists, policy-makers, and law enforcement organisations with a synthesis of the current problems, and a possible solution space.",
        "DOI": "10.1007/s11948-018-00081-0",
        "paper_author": "King T.C.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175816",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Finite-Horizon Optimal Consensus Control for Unknown Multiagent State-Delay Systems",
        "publication": "IEEE Transactions on Cybernetics",
        "citied_by": "32",
        "cover_date": "2020-02-01",
        "Abstract": "This paper investigates finite-horizon optimal consensus control problem for unknown multiagent systems with state delays. It is well known that optimal consensus control is the solutions to the coupled Hamilton–Jacobi–Bellman (HJB) equations. An off-policy reinforcement learning (RL) algorithm is developed to learn the two-stage optimal consensus solutions to the coupled time-varying HJB equations using the measurable state data instead of the knowledge of the state-delayed system dynamics. Subsequently, for each agent, a single critic neural network (NN) is utilized to approximate the time-varying cost function and help to calculate optimal consensus control policy. Based on the method of weighted residuals, adaptive weight update laws for the critic NNs are proposed. Finally, the simulation results are provided to illustrate the effectiveness of the proposed off-policy RL method.",
        "DOI": "10.1109/TCYB.2018.2856510",
        "paper_author": "Zhang H.",
        "affiliation_name": "Nanjing University of Post and TeleCommunications",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60009400",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "An intelligent scheduling algorithm for resource management of cloud platform",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "9",
        "cover_date": "2020-02-01",
        "Abstract": "Cloud-computing technologies and their application are becoming increasingly popular, which improves both enterprises’ and individuals’ working efficiency while at the same time greatly reducing users’ cost. Besides, the scale of cloud platform and its application are rapidly expanding. Yet it’s a challenging task to effectively utilize resource and guarantee quality of services to users. The quality of cloud task scheduling algorithm plays a key role in it. For one thing, traditional rule-based scheduling algorithms like FCFS and priority-based always focus on the algorithm itself instead of considering characteristics of Virtual Machines (VMs) and task, finally leading to poor operation effect. For another, one carefully selects a set of features based on sample data and employs machine-learning algorithms to train a scheduling policy. This method has the following deficiencies: quality of manually selected sample features directly affects that of the scheduling algorithm; many effective scheduling algorithms are based on a large number of labeled samples; however, it is very difficult to acquire these samples in reality; trained scheduling algorithms are often applicable only to specific environments and easy to be damaged. For the deficiencies of traditional scheduling algorithm and based on deep reinforcement learning (DRL) model, this paper presents a new-type model-free and end-to-end task scheduling agent which can interact with cloud environment and output the information of the virtual machine executing the task while inputting the original tasks of the cloud platform. The agent learns scheduling knowledge through the execution of tasks, and optimizes its scheduling policy. This algorithm completely solves the deficiencies of traditional scheduling algorithms like lower adaptability and flexibility, providing brand-new feasible solutions for task scheduling methods under cloud environments.",
        "DOI": "10.1007/s11042-018-6477-4",
        "paper_author": "Jin H.",
        "affiliation_name": "Hunan City University",
        "affiliation_city": "Yiyang",
        "affiliation_country": "China",
        "affiliation_id": "60092438",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Quantification of Neighborhood-Level Social Determinants of Health in the Continental United States",
        "publication": "JAMA Network Open",
        "citied_by": "147",
        "cover_date": "2020-01-29",
        "Abstract": "Importance: An association between social and neighborhood characteristics and health outcomes has been reported but remains poorly understood owing to complex multidimensional factors that vary across geographic space. Objectives: To quantify social determinants of health (SDOH) as multiple dimensions across the continental United States (the 48 contiguous states and the District of Columbia) at a small-area resolution and to examine the association of SDOH with premature mortality within Chicago, Illinois. Design, Setting, and Participants: In this cross-sectional study, census tracts from the US Census Bureau from 2014 were used to develop multidimensional SDOH indices and a regional typology of the continental United States at a small-area level (n = 71901 census tracts with approximately 312 million persons) using dimension reduction and clustering machine learning techniques (unsupervised algorithms used to reduce dimensions of multivariate data). The SDOH indices were used to estimate age-adjusted mortality rates in Chicago (n = 789 census tracts with approximately 7.5 million persons) with a spatial regression for the same period, while controlling for violent crime. Main Outcomes and Measures: Fifteen variables, measured as a 5-year mean, were selected to characterize SDOH as small-area variations for demographic characteristics of vulnerable groups, economic status, social and neighborhood characteristics, and housing and transportation availability at the census-tract level. This SDOH data matrix was reduced to 4 indices reflecting advantage, isolation, opportunity, and mixed immigrant cohesion and accessibility, which were then clustered into 7 distinct multidimensional neighborhood typologies. The association between SDOH indices and premature mortality (defined as death before age 75 years) in Chicago was measured by years of potential life lost and aggregated to a 5-year mean. Data analyses were conducted between July 1, 2018, and August 30, 2019. Results: Among the 71901 census tracts examined across the continental United States, a median (interquartile range) of 27.2% (47.1%) of residents had minority status, 12.1% (7.5%) had disabilities, 22.9% (7.6%) were 18 years and younger, and 13.6% (8.1%) were 65 years and older. Among the 789 census tracts examined in Chicago, a median (interquartile range) of 80.4% (56.3%) of residents had minority status, 10.2% (8.2%) had disabilities, 23.2% (10.9%) were 18 years and younger, and 9.5% (7.1%) were 65 years and older. Four SDOH indices accounted for 71% of the variance across all census tracts in the continental United States in 2014. The SDOH neighborhood typology of extreme poverty, which is of greatest concern to health care practitioners and policy advocates, comprised only 9.6% of all census tracts across the continental United States but characterized small areas of known public health crises. An association was observed between all SDOH indices and age-adjusted premature mortality rates in Chicago (R2 = 0.63; P <.001), even after accounting for violent crime and spatial structures. Conclusions and Relevance: The modeling of SDOH as multivariate indices rather than as a singular deprivation index may better capture the complexity and spatial heterogeneity underlying SDOH. During a time of increased attention to SDOH, this analysis may provide actionable information for key stakeholders with respect to the focus of interventions.",
        "DOI": "10.1001/jamanetworkopen.2019.19928",
        "paper_author": "Kolak M.",
        "affiliation_name": "Center for Spatial Data Science",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States",
        "affiliation_id": "60117686",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Predicting high-risk opioid prescriptions before they are given",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "33",
        "cover_date": "2020-01-28",
        "Abstract": "Misuse of prescription opioids is a leading cause of premature death in the United States. We use state government administrative data and machine learning methods to examine whether the risk of future opioid dependence, abuse, or poisoning can be predicted in advance of an initial opioid prescription. Our models accurately predict these outcomes and identify particular prior nonopioid prescriptions, medical history, incarceration, and demographics as strong predictors. Using our estimates, we simulate a hypothetical policy which restricts new opioid prescriptions to only those with low predicted risk. The policy's potential benefits likely outweigh costs across demographic subgroups, even for lenient definitions of \"high risk.\" Our findings suggest new avenues for prevention using state administrative data, which could aid providers in making better, data-informed decisions when weighing the medical benefits of opioid therapy against the risks.",
        "DOI": "10.1073/pnas.1905355117",
        "paper_author": "Hastings J.S.",
        "affiliation_name": "Research Improving People's Lives",
        "affiliation_city": "Providence",
        "affiliation_country": "United States",
        "affiliation_id": "123262378",
        "affiliation_state": "RI"
    },
    {
        "paper_title": "Case study: Predictive fairness to reduce misdemeanor recidivism through social service interventions",
        "publication": "FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
        "citied_by": "23",
        "cover_date": "2020-01-27",
        "Abstract": "The criminal justice system is currently ill-equipped to improve outcomes of individuals who cycle in and out of the system with a series of misdemeanor offenses. Often due to constraints of caseload and poor record linkage, prior interactions with an individual may not be considered when an individual comes back into the system, let alone in a proactive manner through the application of diversion programs. The Los Angeles City Attorney's Office recently created a new Recidivism Reduction and Drug Diversion unit (R2D2) tasked with reducing recidivism in this population. Here we describe a collaboration with this new unit as a case study for the incorporation of predictive equity into machine learning based decision making in a resource-constrained setting. The program seeks to improve outcomes by developing individually-tailored social service interventions (i.e., diversions, conditional plea agreements, stayed sentencing, or other favorable case disposition based on appropriate social service linkage rather than traditional sentencing methods) for individuals likely to experience subsequent interactions with the criminal justice system, a time and resource-intensive undertaking that necessitates an ability to focus resources on individuals most likely to be involved in a future case. Seeking to achieve both efficiency (through predictive accuracy) and equity (improving outcomes in traditionally under-served communities and working to mitigate existing disparities in criminal justice outcomes), we discuss the equity outcomes we seek to achieve, describe the corresponding choice of a metric for measuring predictive fairness in this context, and explore a set of options for balancing equity and efficiency when building and selecting machine learning models in an operational public policy setting.",
        "DOI": "10.1145/3351095.3372863",
        "paper_author": "Rodolfa K.T.",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60136640",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "The relationship between trust in AI and trustworthy machine learning technologies",
        "publication": "FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
        "citied_by": "187",
        "cover_date": "2020-01-27",
        "Abstract": "To design and develop AI-based systems that users and the larger public can justifiably trust, one needs to understand how machine learning technologies impact trust. To guide the design and implementation of trusted AI-based systems, this paper provides a systematic approach to relate considerations about trust from the social sciences to trustworthiness technologies proposed for AI-based services and products. We start from the ABI+ (Ability, Benevolence, Integrity, Predictability) framework augmented with a recently proposed mapping of ABI+ on qualities of technologies that support trust. We consider four categories of trustworthiness technologies for machine learning, namely these for Fairness, Explainability, Auditability and Safety (FEAS) and discuss if and how these support the required qualities. Moreover, trust can be impacted throughout the life cycle of AI-based systems, and we therefore introduce the concept of Chain of Trust to discuss trustworthiness technologies in all stages of the life cycle. In so doing we establish the ways in which machine learning technologies support trusted AI-based systems. Finally, FEAS has obvious relations with known frameworks and therefore we relate FEAS to a variety of international 'principled AI' policy and technology frameworks that have emerged in recent years.",
        "DOI": "10.1145/3351095.3372834",
        "paper_author": "Toreini E.",
        "affiliation_name": "Newcastle University",
        "affiliation_city": "Newcastle",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60006222",
        "affiliation_state": "Tyne and Wear"
    },
    {
        "paper_title": "The effects of competition and regulation on error inequality in data-driven markets",
        "publication": "FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
        "citied_by": "5",
        "cover_date": "2020-01-27",
        "Abstract": "Recent work has documented instances of unfairness in deployed machine learning models, and significant researcher efiort has been dedicated to creating algorithms that intrinsically consider fairness. In this work, we highlight another source of unfairness: market forces that drive differential investment in the data pipeline for differing groups. We develop a high-level model to study this question. First, we show that our model predicts unfairness in a monopoly setting. Then, we show that under all but the most extreme models, competition does not eliminate this tendency, and may even exacerbate it. Finally, we consider two avenues for regulating a machine-learning driven monopolist - relative error inequality and absolute error-bounds - and quantify the price of fairness (and who pays it). These models imply that mitigating fairness concerns may require policy-driven solutions, not only technological ones.",
        "DOI": "10.1145/3351095.3372842",
        "paper_author": "Elzayn H.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60006297",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Awareness in practice: Tensions in access to sensitive attribute data for antidiscrimination",
        "publication": "FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
        "citied_by": "32",
        "cover_date": "2020-01-27",
        "Abstract": "Organizations cannot address demographic disparities that they cannot see. Recent research on machine learning and fairness has emphasized that awareness of sensitive attributes, such as race and sex, is critical to the development of interventions. However, on the ground, the existence of these data cannot be taken for granted. This paper uses the domains of employment, credit, and healthcare in the United States to surface conditions that have shaped the availability of sensitive attribute data. For each domain, we describe how and when private companies collect or infer sensitive attribute data for antidiscrimination purposes. An inconsistent story emerges: Some companies are required by law to collect sensitive attribute data, while others are prohibited from doing so. Still others, in the absence of legal mandates, have determined that collection and imputation of these data are appropriate to address disparities. This story has important implications for fairness research and its future applications. If companies that mediate access to life opportunities are unable or hesitant to collect or infer sensitive attribute data, then proposed techniques to detect and mitigate bias in machine learning models might never be implemented outside the lab. We conclude that today's legal requirements and corporate practices, while highly inconsistent across domains, offer lessons for how to approach the collection and inference of sensitive data in appropriate circumstances. We urge stakeholders, including machine learning practitioners, to actively help chart a path forward that takes both policy goals and technical needs into account.",
        "DOI": "10.1145/3351095.3372877",
        "paper_author": "Bogen M.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep Bayesian data mining",
        "publication": "WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining",
        "citied_by": "0",
        "cover_date": "2020-01-20",
        "Abstract": "This tutorial addresses the fundamentals and advances in deep Bayesian mining and learning for natural language with ubiquitous applications ranging from speech recognition [7, 55] to document summarization [8], text classification [5, 75], text segmentation [18], information extraction [50], image caption generation [69, 72], sentence generation [25, 46], dialogue control [22, 76], sentiment classification, recommendation system, question answering [58] and machine translation [2], to name a few. Traditionally, “deep learning” is taken to be a learning process where the inference or optimization is based on the real-valued deterministic model. The “semantic structure” in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs. The “distribution function” in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated. This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process [61], Chinese restaurant process [4], hierarchical Pitman-Yor process [60], Indian buffet process [35], recurrent neural network (RNN) [26, 41, 48, 65], long short-term memory, sequence-to-sequence model [59], variational auto-encoder (VAE) [44], generative adversarial network (GAN) [36], attention mechanism [27, 56], memory-augmented neural network [39, 58], skip neural network [6], temporal difference VAE [40], stochastic neural network [3, 47], stochastic temporal convolutional network [1], predictive state neural network [31], and policy neural network [49, 74]. Enhancing the prior/posterior representation is addressed [53, 62]. We present how these models are connected and why they work for a variety of applications on symbolic and complex patterns in natural language. The variational inference and sampling method are formulated to tackle the optimization for complicated models [54]. The word and sentence embeddings, clustering and co-clustering are merged with linguistic and semantic constraints. A series of case studies, tasks and applications are presented to tackle different issues in deep Bayesian mining, searching, learning and understanding. At last, we will point out a number of directions and outlooks for future studies. This tutorial serves the objectives to introduce novices to major topics within deep Bayesian learning, motivate and explain a topic of emerging importance for data mining and natural language understanding, and present a novel synthesis combining distinct lines of machine learning work.",
        "DOI": "10.1145/3336191.3371870",
        "paper_author": "Chien J.T.",
        "affiliation_name": "National Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60012370",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Scenario based approach to re-imagining future of higher education which prepares students for the future of work",
        "publication": "Higher Education, Skills and Work-based Learning",
        "citied_by": "58",
        "cover_date": "2020-01-20",
        "Abstract": "Purpose: The world of work and education is changing at a rapid pace, driven by continued technological disruption and automation. The future is uncertain and difficult to envisage. A futures thinking scenario planning approach is used in exploring and guiding education policy makers on how best to respond to the range of possible futures. The paper aims to discuss this issue. Design/methodology/approach: This study utilizes elements of prior scenario planning methodologies to devise a practical model of preferred and plausible likely scenarios in the context of rapid and continuing technology disruption. Based on the notion of “impact and uncertainty,” two possible future alternatives of work and learning were developed. Incorporating elements of the possibility space scenario framework and a vignette approach of current emergent technologies, this paper assessed the usefulness of the preferred and likely outcomes. Findings: While preferred future scenarios entailing collaborative styles such as human–machine cooperation, smart virtual active learning campuses and living knowledge learning environments may produce more desirable benefits for education stakeholders, the more likely plausible scenario is one based on continued disruptive technologies. Automation, artificial intelligence and the advent of 5G network technologies will drive customization and personalization in higher education delivery and revolutionize the work landscape in the immediate future. Universities will need to embrace and respond to these changes. Originality/value: The paper gives insights into how universities can prepare their students for future of work and improve their employability. In addition, this author recommends ways in which HEIs can leverage these newer technologies to drive educational services and commercial value.",
        "DOI": "10.1108/HESWBL-12-2018-0136",
        "paper_author": "Ahmad T.",
        "affiliation_name": "The University of the West Indies",
        "affiliation_city": "Kingston",
        "affiliation_country": "Jamaica",
        "affiliation_id": "60071347",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Simulating mangroves rehabilitation with cellular automata",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-01-17",
        "Abstract": "A nation-wide concern for the sustainability of mangrove forests in Mekong Delta (Vietnam) is increasingly recognized. Unfortunately, overexploitation of natural resources, urbanization, deforestation, agriculture, aquaculture and many other threats have caused a severe reduction of mangrove cover. Mangrove forests significantly contribute to the provision of local ecosystems and the Delta's sustainability, although they cover a small proportion of the Delta's surface. Therefore, the rehabilitation of mangrove forests demands strong coordinated efforts in terms of policy and research. This study evaluates the potential for simulating mangroves rehabilitation via cellular automata, e.g. a discrete dynamical system, by characterizing several environmental factors. Two of the largest environmental effects causing the distribution of species in mangrove forests are leaf area index (LAI) and flood-tide. To the best of own research, the applied methodologies are one of the first endeavors that have been investigated in the literature. The research has been conducted at Ong Trang islet, Ca Mau province, Mekong Delta (Vietnam).",
        "DOI": "10.1145/3380688.3380696",
        "paper_author": "Huynh H.X.",
        "affiliation_name": "Can Tho University",
        "affiliation_city": "Can Tho",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60071386",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Nature-inspired metaheuristic ensemble model for forecasting energy consumption in residential buildings",
        "publication": "Energy",
        "citied_by": "89",
        "cover_date": "2020-01-15",
        "Abstract": "As the global economy expands, both residential and commercial buildings consume an increasing proportion of the total energy that is used by buildings. Energy simulation and forecasting are important in setting energy policy and making decisions in pursuit of sustainable development. This work develops a new ensemble model, called the Evolutionary Neural Machine Inference Model (ENMIM), for estimating energy consumption in residential buildings based on actual data. The ensemble model combines two single supervised learning machines - least squares support vector regression (LSSVR), and the radial basis function neural network (RBFNN) –and incorporates symbiotic organism search (SOS) to find automatically its optimal tuning parameters. A set of real data, which were obtained from residential buildings in Ho Chi Minh City, Viet Nam, as well as experimental data from the literature were used to evaluate the performance of the developed model. Comparison results reveal that the ENMIM surpasses other benchmark models with respect to predictive accuracy. This work proves that the developed ensemble model is a promising alternative for the planning of energy management. Furthermore, the fact that the ENMIM has greater predictive accuracy than other artificial intelligence techniques suggests that the developed self-tuning ensemble model can be used in various disciplines.",
        "DOI": "10.1016/j.energy.2019.116552",
        "paper_author": "Tran D.H.",
        "affiliation_name": "Ho Chi Minh City University of Technology - HUTECH",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60071399",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Towards optimal control of air handling units using deep reinforcement learning and recurrent neural network",
        "publication": "Building and Environment",
        "citied_by": "129",
        "cover_date": "2020-01-15",
        "Abstract": "Optimal control of heating, ventilation and air conditioning systems (HVACs) aims to minimize the energy consumption of equipment while maintaining the thermal comfort of occupants. Traditional rule-based control methods are not optimized for HVAC systems with continuous sensor readings and actuator controls. Recent developments in deep reinforcement learning (DRL) enabled control of HVACs with continuous sensor inputs and actions, while eliminating the need of building complex thermodynamic models. DRL control includes an environment, which approximates real-world HVAC operations; and an agent, that aims to achieve optimal control over the HVAC. Existing DRL control frameworks use simulation tools (e.g., EnergyPlus) to build DRL training environments with HVAC systems information, but oversimplify building geometrics. This study proposes a framework aiming to achieve optimal control over Air Handling Units (AHUs) by implementing long-short-term-memory (LSTM) networks to approximate real-world HVAC operations to build DRL training environments. The framework also implements state-of-the-art DRL algorithms (e.g., deep deterministic policy gradient) for optimal control over the AHUs. Three AHUs, each with two-years of building automation system (BAS) data, were used as testbeds for evaluation. Our LSTM-based DRL training environments, built using the first year's BAS data, achieved an average mean square error of 0.0015 across 16 normalized AHU parameters. When deployed in the testing environments, which were built using the second year's BAS data of the same AHUs, the DRL agents achieved 27%–30% energy saving comparing to the actual energy consumption, while maintaining the predicted percentage of discomfort (PPD) at 10%.",
        "DOI": "10.1016/j.buildenv.2019.106535",
        "paper_author": "Zou Z.",
        "affiliation_name": "NYU Tandon School of Engineering",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60108318",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "ACoPE: An adaptive semi-supervised learning approach for complex-policy enforcement in high-bandwidth networks",
        "publication": "Computer Networks",
        "citied_by": "5",
        "cover_date": "2020-01-15",
        "Abstract": "Today's high-bandwidth networks require adaptive analyzing approaches to recognize the network variable behaviors. The analyzing approaches should be robust against the lack of prior knowledge and provide data to impose more complex policies. In this paper, ACoPE is proposed as an adaptive semi-supervised learning approach for complex-policy enforcement in high-bandwidth networks. ACoPE detects and maintains inter-flows relationships to impose complex-policies. It employs a statistical process control technique to monitor accuracy. Whenever the accuracy decreased, ACoPE considers it as a changed behavior and uses data from a deep packet inspection module to adapt itself with the change. The performance of ACoPE in analyzing network traffic is evaluated through UNB ISCX VPN-nonVPN and UNB ISCX Tor-nonTor datasets. The performance is compared with 10 different stream and traditional classification algorithms. ACoPE outperforms the stream classifiers, with 95.92% accuracy, 86.21% precision, and 73.29% recall in VPN dataset, and with 81.12% accuracy, 73.59% precision, and 61.08% recall in Tor dataset. The effectiveness of ACoPE to address the main constraints in analyzing of high-bandwidth networks to enforce security policies, namely comprehensive processing and adaptive learning, are confirmed through three different scenarios. Efficiency and accuracy of ACoPE in real high-bandwidth networks are evaluated by a pilot study, which indicates its efficiency and accuracy in analyzing high-bandwidth networks.",
        "DOI": "10.1016/j.comnet.2019.106943",
        "paper_author": "Noferesti M.",
        "affiliation_name": "Sharif University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60027666",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Assessing Canadians Health Activity and Nutritional Habits Through Social Media",
        "publication": "Frontiers in Public Health",
        "citied_by": "22",
        "cover_date": "2020-01-14",
        "Abstract": "When conducting data analysis in the twenty-first century, social media is crucial to the analysis due to the ability to provide information on a variety of topics such as health, food, feedback on products, and many others. Presently, users utilize social media to share their daily lifestyles. For example, travel locations, exercises, and food are common subjects of social media posts. By analyzing such information collected from users, health of the general population can be gauged. This analysis can become an integral part of federal efforts to study the health of a nation's people on a large scale. In this paper, we focus on such efforts from a Canadian lens. Public health is becoming a primary concern for many governments around the world. It is believed that it is necessary to analyze the current scenario within a given population before creating any new policies. Traditionally, governments use a variety of ways to gauge the flavor for any new policy including door to door surveys, a national level census, or hospital information to decide health policies. This information is limited and sometimes takes a long time to collect and analyze sufficiently enough to aid in decision making. In this paper, our approach is to solve such problems through the advancement of natural language processing algorithms and large scale data analysis. Our in-depth results show that the proposed method provides a viable solution in less time with the same accuracy when compared to traditional methods.",
        "DOI": "10.3389/fpubh.2019.00400",
        "paper_author": "Shah N.",
        "affiliation_name": "Lakehead University",
        "affiliation_city": "Thunder Bay",
        "affiliation_country": "Canada",
        "affiliation_id": "60025949",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "The Machine Learning Solution based on Period and Deep Construction of Mobile Data for Predicting User Habit",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2020-01-11",
        "Abstract": "Information analysis on user habit is becoming hotter as its value for many potential and profitable areas. However, how to excavate hard-core data and obtain the most effective information associated with research target, and how to obtain more precise prediction of user habit timely and fast on mobile terminals, are still big challenges. Most of the traditional methods use static data, which can no longer meet the requirements of the movable era, such as learning daily travel route and predicting the next most possible applications. Additionally, though algorithms based on Artificial Intelligence (AI) have boomed, many researches only based on direct data and pay insufficient attention to the deeper interrelation of data. This paper introduces two relevant AI models improving the phone memories; then, the main solution is recommended in detail. It mines some closely correlated parameters by specific mechanism named Linked Trigger (LT) and filtering policies for positioning, digging their underlying relations for better learning user habit by special construction 'Directed Location Pair Application (DLPA)'. Based theseanalysis on the deep-seated connection between the collected data, the conditional probability referring Bayesian network is used to learn and predict the location habit and application habit.",
        "DOI": "10.1088/1742-6596/1438/1/012027",
        "paper_author": "Du J.",
        "affiliation_name": "New Research and Development Center of Hisense",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China",
        "affiliation_id": "118617098",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Blood count prediction for disease prognosis based on combined multi-modal interaction model with related attributes",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2020-01-10",
        "Abstract": "Many machine learning approaches have been applied in order to predict different types of diseases over last few years. Early diagnosis and prognosis depending on these predictions have become very necessary for further treatment policy in different sectors. Moreover, in order to predict something like these diseases or abnormality might need real-life data interaction. The importance of these predictions has led many researchers to study bioinformatics and machine learning. However, selecting correct attributes to design prediction models is also necessary. In this paper we have introduced an approach where several machine learning models will be fitted with the related attributes while performing the predictions from data interaction.",
        "DOI": "10.1145/3377049.3377059",
        "paper_author": "Nabil R.H.",
        "affiliation_name": "American International University - Bangladesh",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60104425",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "H<inf>∞</inf> tracking control for linear discrete-time systems via reinforcement learning",
        "publication": "International Journal of Robust and Nonlinear Control",
        "citied_by": "33",
        "cover_date": "2020-01-10",
        "Abstract": "In this paper, the H∞ tracking control of linear discrete-time systems is studied via reinforcement learning. By defining an improved value function, the tracking game algebraic Riccati equation with a discount factor is obtained, which is solved by iteration learning algorithms. In particular, Q-learning based on value iteration is presented for H∞ tracking control, which does not require the system model information and the initial allowable control policy. In addition, to improve the practicability of algorithm, the convergence analysis of proposed algorithm with a discount factor is given. Finally, the feasibility of proposed algorithms is verified by simulation examples.",
        "DOI": "10.1002/rnc.4762",
        "paper_author": "Liu Y.Y.",
        "affiliation_name": "The State Key Laboratory of Synthetical Automation for Process Industries",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60119041",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Machine learning approaches for spatial modeling of agricultural droughts in the south-east region of Queensland Australia",
        "publication": "Science of the Total Environment",
        "citied_by": "133",
        "cover_date": "2020-01-10",
        "Abstract": "A quantitative understanding of the hydro-environmental factors that influence the occurrence of agricultural drought events would enable more strategic climate change adaptation and drought management plans. Practical drought hazard mapping remains challenging due to possible exclusion of the most pertinent drought drivers, and to the use of inadequate predictive models that cannot describe drought adequately. This research aims to develop new approaches to map agricultural drought hazard with state-of-the-art machine learning models, including classification and regression trees (CART), boosted regression trees (BRT), random forests (RF), multivariate adaptive regression splines (MARS), flexible discriminant analysis (FDA) and support vector machines (SVM). Hydro-environmental datasets were used to calculate the relative departure of soil moisture (RDSM) for eight severe droughts for drought-prone southeast Queensland, Australia, over the period 1994–2013. RDSM was then used to generate an agricultural drought inventory map. Eight hydro-environmental factors were used as potential predictors of drought. The goodness-of-fit and predictive performance of all models were evaluated using different threshold-dependent and threshold-independent methods, including the true skill statistic (TSS), Efficiency (E), F-score, and the area under the receiver operating characteristic curve (AUC-ROC). The RF model (AUC-ROC = 97.7%, TSS = 0.873, E = 0.929, F-score = 0.898) yielded the highest accuracy, while the FDA model (with AUC-ROC = 73.9%, TSS = 0.424, E = 0.719, F-score = 0.512) showed the worst performance. The plant available water holding capacity (PAWC), mean annual precipitation, and clay content were the most important variables to be used for predicting the agricultural drought. About 21.2% of the area is in high or very high drought risk classes, and therefore, warrant drought and environmental protection policies. Importantly, the models do not require data on the precipitation anomaly for any given drought year; the spatial patterns in AGH were consistent for all drought events, despite very different spatial patterns in precipitation anomaly among events. Such machine-learning approaches are able to construct an overall risk map, thus assisting in the adoption of a robust drought contingency planning measure not only for this area, but also, in other regions where drought presents a pressing challenge, including its influence on key practical dimensions of social, environmental and economic sustainability.",
        "DOI": "10.1016/j.scitotenv.2019.134230",
        "paper_author": "Rahmati O.",
        "affiliation_name": "Ton-Duc-Thang University",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60078563",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep-MARLIN: Using Deep Multi-Agent Reinforcement Learning for Adaptive Traffic Light Control",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2020-01-07",
        "Abstract": "Almost every major city in the world is facing a significant economic loss caused by traffic congestions. In this context, it already has been shown that Adaptive Traffic Light Control (ATLC) can be an effective solution to improve a diversity of different traffic-related metrics. The problem of ATLC can be modeled in various ways with reinforcement learning being one of the most promising frameworks. Especially the application of Multi-Agent Reinforcement Learning (MARL) can be a suitable approach for learning to adaptively control the traffic of realistic road networks. Among the set of MARL algorithms, Multi-Agent Reinforcement Learning for Integrated Network (MARLIN) stands out and is shown to be particularly suited to the problem of ATLC with producing remarkable results. MARLIN models the multi-agent framework as a stochastic game providing an explicit coordination mechanism for the agents. However, in MARLIN, the possible size of the state and action space is limited and the features for the state representation need to be hand-crafted. Therefore, in this study, the algorithm is combined with function approximation by using artificial neural networks to overcome these limitations. deep-MARLIN is explained and bench-marked in a large and realistic traffic environment using Simulation of Urban MObility (SUMO). The results indicate that when compared to MARLIN, deep-MARLIN converges faster to a policy that is producing lower average vehicle delay.",
        "DOI": "10.1145/3378184.3378194",
        "paper_author": "Klöckner R.",
        "affiliation_name": "Goethe-Universität Frankfurt am Main",
        "affiliation_city": "Frankfurt am Main",
        "affiliation_country": "Germany",
        "affiliation_id": "60007762",
        "affiliation_state": "Hessen"
    },
    {
        "paper_title": "Multi-empirical Discriminant Multi-Agent Reinforcement Learning Algorithm Based on Intra-group Evolution",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "1",
        "cover_date": "2020-01-07",
        "Abstract": "In order to find the optimal target in the unknown environment more quickly, a multi-empirical discriminant multi-agent reinforcement learning algorithm based on intra-group evolution is proposed based on the deep deterministic policy gradient algorithm (DDPG). In the unknown environment, the agent can find the target faster by performing Information exchange, group genetics and other mechanisms. The comparison with the traditional reinforcement learning algorithm shows that the proposed algorithm is superior to the traditional reinforcement learning algorithm in solving time and solving accuracy, and can quickly and effectively find the optimal target in the environment. CCS Concepts •Computing methodologies → Multi-agent systems.",
        "DOI": "10.1088/1742-6596/1437/1/012038",
        "paper_author": "Zhang Z.L.",
        "affiliation_name": "Chengdu University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60102085",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Temporal prediction of socio-economic indicators using satellite imagery",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "12",
        "cover_date": "2020-01-05",
        "Abstract": "Machine learning models based on satellite data have been actively researched to serve as a proxy for the prediction of socio-economic development indicators. Such models have however rarely been tested for transferability over time, i.e. whether models learned on data for a certain year are able to make accurate predictions on data for another year. Using a dataset from the Indian census at two time points, for the years 2001 and 2011, we evaluate the temporal transferability of a simple machine learning model at sub-national scales of districts and propose a generic method to improve its performance. This method can be especially relevant when training datasets are small to train a robust prediction model. Then, we go further to build an aggregate development index at the district-level, on the lines of the Human Development Index (HDI) and demonstrate high accuracy in predicting the index based on satellite data for different years. This can be used to build applications to guide data-driven policy making at fine spatial and temporal scales, without the need to conduct frequent expensive censuses and surveys on the ground.",
        "DOI": "10.1145/3371158.3371167",
        "paper_author": "Bansal C.",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60032730",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "New intelligent control strategy hybrid grey-RCMAC algorithm for ocean wave power generation systems",
        "publication": "Energies",
        "citied_by": "14",
        "cover_date": "2020-01-03",
        "Abstract": "In this article, the characteristics of the wave energy converter are considered and a novel dynamic controller (NDC) for a permanent magnet synchronous generator (PMSG) is proposed for Wells turbine applications. The proposed NDC includes a recursive cerebellum model articulation controller (RCMAC) with a grey predictor and innovative particle swarm optimization (IPSO). IPSO is developed to adjust the learning speed and improve learning capability. Based on the supervised learning method, online adjustment law of RCMAC parameters is derived to ensure the system's stability. The NDC scheme is designed to maintain a supply-demand balance between intermittent power generation and grid power supply. The proposed NDC exhibits an improved power regulation and dynamic performance of the wave energy system under various operation conditions. Furthermore, better results are obtained when the RCMAC is used with the grey predictive model method.",
        "DOI": "10.3390/en13010241",
        "paper_author": "Lu K.H.",
        "affiliation_name": "Minnan University of Science and Technology",
        "affiliation_city": "Quanzhou",
        "affiliation_country": "China",
        "affiliation_id": "60261033",
        "affiliation_state": "Fujian"
    },
    {
        "paper_title": "Suicidal ideation prediction in twitter data using machine learning techniques",
        "publication": "Journal of Interdisciplinary Mathematics",
        "citied_by": "47",
        "cover_date": "2020-01-02",
        "Abstract": "People prefer new technology by using online social media as a communication channels to express their suicidal thoughts. Primary identification and detection are viewed as an effective approach to avoid suicidal attempt and suicidal ideation-two basic hazards causing effective suicide. This paper exhibits different techniques to comprehend suicidal ideation through online user contents in particularly by considering twitter data for past last two years as an objective of early detection by means of sentiment analysis and supervised leaning methods. Analysing the text descriptions and users language exposes rich knowledge that can be utilized as a primary cautioning system for suicidal detection. To identify tweets exhibiting suicidal ideation, several features are extracted and a set of features are proposed for training the model over the dataset by using ensemble and baseline classifiers. Based on the outcome of baseline classifier; improved ensemble random forest (RF) algorithm achieved an accuracy of 0.99% compared to other classification methods for suicidal prediction with tweets containing suicidal thought is better when compared to the existing system. Such experimentation and monitoring may help individual and population-wide prevention by counseling and informing to suicidal research and policy. The experimental analysis expresses the feasibility of the methodology used by providing a benchmark for suicidal detection on online social network: Twitter.",
        "DOI": "10.1080/09720502.2020.1721674",
        "paper_author": "Rajesh Kumar E.",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India",
        "affiliation_id": "60079446",
        "affiliation_state": "AP"
    },
    {
        "paper_title": "An autonomous path planning model for unmanned ships based on deep reinforcement learning",
        "publication": "Sensors (Switzerland)",
        "citied_by": "160",
        "cover_date": "2020-01-02",
        "Abstract": "Deep reinforcement learning (DRL) has excellent performance in continuous control problems and it is widely used in path planning and other fields. An autonomous path planning model based on DRL is proposed to realize the intelligent path planning of unmanned ships in the unknown environment. The model utilizes the deep deterministic policy gradient (DDPG) algorithm, through the continuous interaction with the environment and the use of historical experience data; the agent learns the optimal action strategy in a simulation environment. The navigation rules and the ship's encounter situation are transformed into a navigation restricted area, so as to achieve the purpose of planned path safety in order to ensure the validity and accuracy of the model. Ship data provided by ship automatic identification system (AIS) are used to train this path planning model. Subsequently, the improved DRL is obtained by combining DDPG with the artificial potential field. Finally, the path planning model is integrated into the electronic chart platform for experiments. Through the establishment of comparative experiments, the results show that the improved model can achieve autonomous path planning, and it has good convergence speed and stability.",
        "DOI": "10.3390/s20020426",
        "paper_author": "Guo S.",
        "affiliation_name": "Dalian Maritime University",
        "affiliation_city": "Dalian",
        "affiliation_country": "China",
        "affiliation_id": "60029322",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Journal of biopharmaceutical statistics editorial",
        "publication": "Journal of Biopharmaceutical Statistics",
        "citied_by": "1",
        "cover_date": "2020-01-02",
        "Abstract": "NA",
        "DOI": "10.1080/10543406.2019.1709697",
        "paper_author": "Gamalo-Siebers M.",
        "affiliation_name": "Eli Lilly and Company",
        "affiliation_city": "Indianapolis",
        "affiliation_country": "United States",
        "affiliation_id": "60025685",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Finding decision jumps in text classification",
        "publication": "Neurocomputing",
        "citied_by": "26",
        "cover_date": "2020-01-02",
        "Abstract": "Text classification is one of the key problems in natural language processing (NLP), and in early years, it was usually accomplished by feature-based machine learning models. Recently, the deep neural network has become a powerful learning machine, making it possible to work with text itself as raw input for the classification problems. However, existing neural networks are typically end-to-end and lack explicit interpretation of the prediction. In this paper, we propose JUMPER, a novel framework that models text classification as a sequential decision process. Generally, JUMPER is a neural system that scans a piece of text sequentially and makes classification decisions at the time it wishes, which is inspired by the cognitive process of human text reading. In our framework, both the classification result and when to make the classification are part of the decision process, controlled by a policy network and trained with reinforcement learning. Experimental results of real-world applications demonstrate the following properties of a properly trained JUMPER: (1) it tends to make decisions whenever the evidence is enough, therefore reducing total text reading by 30–40% and often finding the key rationale of the prediction; and (2) it achieves classification accuracy better than or comparable to state-of-the-art models in several benchmark and industrial datasets. We further conduct a simulation experiment with mock data, which confirms that JUMPER is able to make a decision at the theoretically optimal decision position.",
        "DOI": "10.1016/j.neucom.2019.08.082",
        "paper_author": "Liu X.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "What Factors Contribute to the Aggressive Foreign Policy of Russian Leaders?",
        "publication": "Problems of Post-Communism",
        "citied_by": "12",
        "cover_date": "2020-01-02",
        "Abstract": "This paper explores the correlates of Russia’s aggressive international policy and argues that rising oil revenues increase the aggressiveness of presidential foreign-policy rhetoric. Using content analysis and machine-learning techniques, I generate a measure of aggressive discourse as the share of anti-Western sentences in Russian presidential speeches delivered between 2000 and 2016. These are analyzed using OLS regression with lagged dependent variables. I conclude that the aggressiveness of foreign-policy rhetoric in Russian presidential speeches positively correlates to oil prices. I also find no support for alternative explanations linking hawkish foreign policy to NATO expansion or domestic legitimacy concerns.",
        "DOI": "10.1080/10758216.2018.1554408",
        "paper_author": "Snegovaya M.",
        "affiliation_name": "University of Maryland, College Park",
        "affiliation_city": "College Park",
        "affiliation_country": "United States",
        "affiliation_id": "60020304",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Network-wide traffic signal control based on the discovery of critical nodes and deep reinforcement learning",
        "publication": "Journal of Intelligent Transportation Systems: Technology, Planning, and Operations",
        "citied_by": "60",
        "cover_date": "2020-01-02",
        "Abstract": "To improve the traffic efficiency of city-wide road networks, we propose a traffic signal control framework that prioritizes the optimal control policies on critical nodes in road networks. In this framework, we first use a data-driven approach to discover the critical nodes. Critical nodes are identified as nodes that would cause a dramatic reduction in the traffic efficiency of the road network if they were to fail. This approach models the dynamic of road networks using a tripartite graph based on the vehicle trajectories and can accurately identify the city-wide critical nodes from a global perspective. Second, for the discovered critical nodes, we introduce a novel traffic signal control approach based on deep reinforcement learning; this approach can learn the optimal policy via constantly interacting with the road network in an iterative mode. We conduct several experiments with a transportation simulator; the results of experiments show that the proposed framework reduces the average delay and travel time compared to the baseline methods.",
        "DOI": "10.1080/15472450.2018.1527694",
        "paper_author": "Xu M.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Regulating the Feedback Effect",
        "publication": "After the Digital Tornado: Networks, Algorithms, Humanity",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Market concentration is a significant and growing problem in precisely the digital markets where the Internet was supposed to herald an era of healthy competition. Algorithmic systems are subject to a significant new force shifting market competition, the “feedback effect.” More data not only produces better results through traditional scale and scope economies, but also by generating better machine learning models. This means that traditional antitrust and regulatory remedies are poorly suited to redress competitive imbalances. Instead, regulators should impose a progressive data-sharing mandate. With this novel mechanism, dominant digital platforms would be required to make data available to competitors, blunting their inherent advantage in algorithm-dominated markets.",
        "DOI": "10.1017/9781108610018",
        "paper_author": "Mayer-Schönberger V.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175816",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "The Dataset Nutrition Label: A Framework to Drive Higher Data Quality Standards",
        "publication": "Data Protection and Privacy: Data Protection and Democracy",
        "citied_by": "66",
        "cover_date": "2020-01-01",
        "Abstract": "Data is a fundamental ingredient in building Artificial Intelligence (AI) models and there are direct correlations between data quality and model robustness, fairness and utility. A growing body of research points to AI systems deployed in a wide range of use cases, where algorithms trained on biased, incomplete, or ill-fitting data produce problematic results. Despite the increased critical attention, data interrogation continues to be a challenging task with many issues being difficult to identify and rectify. Algorithms often come under scrutiny only after they are developed and deployed, which exacerbates this problem and underscores the need for better data vetting practices earlier in the development pipeline. We introduce the Dataset Nutrition Label, 6 a diagnostic framework built by the Data Nutrition Project, comprising a label that provides a distilled yet comprehensive overview of dataset ‘ingredients’. The label is designed to be flexible and adaptable; it is comprised of a diverse set of qualitative and quantitative modules generated through multiple statistical and probabilistic modelling backends. Working with the ProPublica dataset ‘Dollars for Docs’, we developed an open source tool7 consisting of seven sample modules. Consulting such a label prior to AI model development promotes vigorous data interrogation practices, aids in recognising inconsistencies and imbalances, provides an improved means to selecting more appropriate datasets for specific tasks and subsequently increases the overall quality of AI models. We also explore some challenges of the label, including generalising across diverse datasets, as well as discussing research and public policy agendas to further advocate its adoption and ultimately improve the AI development ecosystem.",
        "DOI": "NA",
        "paper_author": "Holland S.",
        "affiliation_name": "Harvard University",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60009982",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "27th Annual Network and Distributed System Security Symposium, NDSS 2020",
        "publication": "27th Annual Network and Distributed System Security Symposium, NDSS 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 88 papers. The topics discussed include: Trident: efficient 4PC framework for privacy preserving machine learning; ABSynthe: automatic Blackbox side-channel synthesis on commodity microarchitectures; a view from the cockpit: exploring pilot reactions to attacks on avionic systems; towards plausible graph anonymization; when match fields do not need to match: buffered packet hijacking in SDN; complex security policy? a longitudinal analysis of deployed content security policies; adversarial classification under differential privacy; genotype extraction and false relative attacks: security risks to third-party genetic genealogy services beyond identity inference; Et Tu Alexa? when commodity Wi-Fi devices turn into adversarial motion sensors; and detecting probe-resistant proxies.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Comparative Study of Feature Selection Methods for Informal Arabic",
        "publication": "Learning and Analytics in Intelligent Systems",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "The advent of web 2.0 and new Big Data technologies has created a diversity of data and information that can be used in many fields of application. The case of opinion mining is of increasing interest to researchers because of its impact on policy, marketing, etc. Through this document, we are interested in the study of sentiments more specifically in informal Arabic. We present a new approach of processing and analysis that is improved through feature selection methods. The experiments we have carried out are based on the comparison of 3 feature selection methods combined with several machine learning algorithms applied on a twitter dataset. Our paper reports the enhanced results (Accuracy of 98%) and shows the importance of feature selection for Arabic Sentiment Analysis.",
        "DOI": "10.1007/978-3-030-36778-7_22",
        "paper_author": "Mihi S.",
        "affiliation_name": "Université Hassan 1er",
        "affiliation_city": "Settat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60026692",
        "affiliation_state": "Casablanca-Settat"
    },
    {
        "paper_title": "6th International Conference on Information Systems Security and Privacy , ICISSP 2020",
        "publication": "International Conference on Information Systems Security and Privacy",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 91 papers. The special focus in this conference is on Information Systems Security and Privacy. The topics include: Privacy-preserving Surveillance Methods using Homomorphic Encryption; maturity Modelling to Prepare for Cyber Crisis Escalation and Management; translating Data Protection into Software Requirements; revisiting Higher-order Computational Attacks against White-box Implementations; modeling Cyber Threat Intelligence; integration of Data Envelopment Analysis in Business Process Models: A Novel Approach to Measure Information Security; Phishing URL Detection Through Top-level Domain Analysis: A Descriptive Approach; an Approach to Secure Legacy Software Systems; Is Ethereum’s ProgPoW ASIC Resistant?; exploring Vulnerabilities in Solidity Smart Contract; quantifying the Significance of Cybersecurity Text through Semantic Similarity and Named Entity Recognition; A Comparison of Blockchain-based PKI Implementations; a Domain-specific Modeling Framework for Attack Surface Modeling; AMNESIA: A Technical Solution towards GDPR-compliant Machine Learning; visualizing Syscalls using Self-organizing Maps for System Intrusion Detection; coProtect: Collaborative Management of Cryptographic Keys for Data Security in Cloud Systems; threat Modeling and Attack Simulations of Smart Cities: A Literature Review and Explorative Study; bident Structure for Neural Network Model Protection; secure Ownership Transfer for the Internet of Things; risk Identification: From Requirements to Threat Models; a Systematic Approach toward Extracting Technically Enforceable Policies from Data Usage Control Requirements; host Fingerprinting for Web Servers Authentication; computer Viruses: The Abstract Theory Revisited; revisiting Privacy-aware Blockchain Public Key Infrastructure; A Formal Approach for the Analysis of the XRP Ledger Consensus Protocol; email Spoofing Attack Detection through an End to End Authorship Attribution System; Harmonized Group Mix for ITS.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning Vision-based Reactive Policies for Obstacle Avoidance",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we address the problem of vision-based obstacle avoidance for robotic manipulators. This topic poses challenges for both perception and motion generation. While most work in the field aims at improving one of those aspects, we provide a unified framework for approaching this problem. The main goal of this framework is to connect perception and motion by identifying the relationship between the visual input and the corresponding motion representation. To this end, we propose a method for learning reactive obstacle avoidance policies. We evaluate our method on goal-reaching tasks for single and multiple obstacles scenarios. We show the ability of the proposed method to efficiently learn stable obstacle avoidance strategies at a high success rate, while maintaining closed-loop responsiveness required for critical applications like human-robot interaction.",
        "DOI": "NA",
        "paper_author": "Aljalbout E.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "We study the problem of learning a robot policy to follow natural language instructions that can be easily extended to reason about new objects. We introduce a few-shot language-conditioned object grounding method trained from augmented reality data that uses exemplars to identify objects and align them to their mentions in instructions. We present a learned map representation that encodes object locations and their instructed use, and construct it from our few-shot grounding output. We integrate this mapping approach into an instruction-following policy, thereby allowing it to reason about previously unseen objects at test-time by simply adding exemplars. We evaluate on the task of learning to map raw observations and instructions to continuous control of a physical quadcopter. Our approach significantly outperforms the prior state of the art in the presence of new objects, even when the prior approach observes all objects during training.",
        "DOI": "NA",
        "paper_author": "Blukis V.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Integrating Egocentric Localization for More Realistic Point-Goal Navigation Agents",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Recent work has presented embodied agents that can navigate to pointgoal targets in novel indoor environments with near-perfect accuracy. However, these agents are equipped with idealized sensors for localization and take deterministic actions. This setting is practically sterile by comparison to the dirty reality of noisy sensors and actuations in the real world - wheels can slip, motion sensors have error, actuations can rebound. In this work, we take a step towards this noisy reality, developing point-goal navigation agents that rely on visual estimates of egomotion under noisy action dynamics. We find these agents outperform naive adaptions of current point-goal agents to this setting as well as those incorporating classic localization baselines. Further, our model conceptually divides learning agent dynamics or odometry (where am I?) from task-specific navigation policy (where do I want to go?). This enables a seamless adaption to changing dynamics (a different robot or floor type) by simply re-calibrating the visual odometry model - circumventing the expense of re-training of the navigation policy. Our agent was the runner-up in the PointNav track of CVPR 2020 Habitat Challenge.",
        "DOI": "NA",
        "paper_author": "Datta S.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Manipulating deformable objects, such as fabric, is a long standing problem in robotics, with state estimation and control posing a significant challenge for traditional methods. In this paper, we show that it is possible to learn fabric folding skills in only an hour of self-supervised real robot experience, without human supervision or simulation. Our approach relies on fully convolutional networks and the manipulation of visual inputs to exploit learned features, allowing us to create an expressive goal-conditioned pick and place policy that can be trained efficiently with real world robot data only. Folding skills are learned with only a sparse reward function and thus do not require reward function engineering, merely an image of the goal configuration. We demonstrate our method on a set of towel-folding tasks, and show that our approach is able to discover sequential folding strategies, purely from trial-and-error. We achieve state-of-the-art results without the need for demonstrations or simulation, used in prior approaches. Videos available at: https://sites.google.com/view/learningtofold.",
        "DOI": "NA",
        "paper_author": "Lee R.",
        "affiliation_name": "Queensland University of Technology",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60011019",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Learning from Demonstrations using Signal Temporal Logic",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Learning-from-demonstrations is an emerging paradigm to obtain effective robot control policies for complex tasks via reinforcement learning without the need to explicitly design reward functions. However, it is susceptible to imperfections in demonstrations and also raises concerns of safety and interpretability in the learned control policies. To address these issues, we use Signal Temporal Logic to evaluate and rank the quality of demonstrations. Temporal logic-based specifications allow us to create non-Markovian rewards, and also define interesting causal dependencies between tasks such as sequential task specifications. We validate our approach through experiments on discrete-world and OpenAI Gym environments, and show that our approach outperforms the state-of-the-art Maximum Causal Entropy Inverse Reinforcement Learning.",
        "DOI": "NA",
        "paper_author": "Puranic A.G.",
        "affiliation_name": "University of Southern California",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60029311",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Explicitly Encouraging Low Fractional Dimensional Trajectories Via Reinforcement Learning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "A key limitation in using various modern methods of machine learning in developing feedback control policies is the lack of appropriate methodologies to analyze their long-term dynamics, in terms of making any sort of guarantees (even statistically) about robustness. The central reasons for this are largely due to the so-called curse of dimensionality, combined with the black-box nature of the resulting control policies themselves. This paper aims at the first of these issues. Although the full state space of a system may be quite large in dimensionality, it is a common feature of most model-based control methods that the resulting closed-loop systems demonstrate dominant dynamics that are rapidly driven to some lower-dimensional sub-space within. In this work we argue that the dimensionality of this subspace is captured by tools from fractal geometry, namely various notions of a fractional dimension. We then show that the dimensionality of trajectories induced by model free reinforcement learning agents can be influenced adding a post processing function to the agents reward signal. We verify that the dimensionality reduction is robust to noise being added to the system and show that that the modified agents are more actually more robust to noise and push disturbances in general for the systems we examined.",
        "DOI": "NA",
        "paper_author": "Gillen S.",
        "affiliation_name": "UC Santa Barbara College of Engineering",
        "affiliation_city": "Santa Barbara",
        "affiliation_country": "United States",
        "affiliation_id": "60142701",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Interactive Imitation Learning in State-Space",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Imitation Learning techniques enable programming the behavior of agents through demonstrations rather than manual engineering. However, they are limited by the quality of available demonstration data. Interactive Imitation Learning techniques can improve the efficacy of learning since they involve teachers providing feedback while the agent executes its task. In this work, we propose a novel Interactive Learning technique that uses human feedback in state-space to train and improve agent behavior (as opposed to alternative methods that use feedback in action-space). Our method titled Teaching Imitative Policies in State-space (TIPS) enables providing guidance to the agent in terms of 'changing its state' which is often more intuitive for a human demonstrator. Through continuous improvement via corrective feedback, agents trained by non-expert demonstrators using TIPS outperformed the demonstrator and conventional Imitation Learning agents.",
        "DOI": "NA",
        "paper_author": "Jauhri S.",
        "affiliation_name": "Department of Cognitive Robotics, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60118240",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Towards Robotic Assembly by Predicting Robust, Precise and Task-oriented Grasps",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Robust task-oriented grasp planning is vital for autonomous robotic precision assembly tasks. Knowledge of the objects' geometry and preconditions of the target task should be incorporated when determining the proper grasp to execute. However, several factors contribute to the challenges of realizing these grasps such as noise when controlling the robot, unknown object properties, and difficulties modeling complex object-object interactions. We propose a method that decomposes this problem and optimizes for grasp robustness, precision, and task performance by learning three cascaded networks. We evaluate our method in simulation on three common assembly tasks: inserting gears onto pegs, aligning brackets into corners, and inserting shapes into slots. Our policies are trained using a curriculum based on large-scale self-supervised grasp simulations with procedurally generated objects. Finally, we evaluate the performance of the first two tasks with a real robot where our method achieves 4.28mm error for bracket insertion and 1.44mm error for gear insertion.",
        "DOI": "NA",
        "paper_author": "Zhao J.",
        "affiliation_name": "The Robotics Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60104841",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Learning Interactively to Resolve Ambiguity in Reference Frame Selection",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "In Learning from Demonstrations, ambiguities can lead to bad generalization of the learned policy. This paper proposes a framework called Learning Interactively to Resolve Ambiguity (LIRA), that recognizes ambiguous situations, in which more than one action have similar probabilities, avoids a random action selection, and uses the human feedback for solving them. The aim is to improve the user experience, the learning performance and safety. LIRA is tested in the selection of the right goal of Movement Primitives (MP) out of a candidate list if multiple contradictory generalizations of the demonstration(s) are possible. The framework is validated on different pick and place operations on a Emika-Franka Robot. A user study showed a significant reduction on the task load of the user, compared to a system that does not allow interactive resolution of ambiguities.",
        "DOI": "NA",
        "paper_author": "Franzese G.",
        "affiliation_name": "Department of Cognitive Robotics, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60118240",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Visual Imitation Made Easy",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "26",
        "cover_date": "2020-01-01",
        "Abstract": "Visual imitation learning provides a framework for learning complex manipulation behaviors by leveraging human demonstrations. However, current interfaces for imitation such as kinesthetic teaching or teleoperation prohibitively restrict our ability to efficiently collect large-scale data in the wild. Obtaining such diverse demonstration data is paramount for the generalization of learned skills to novel scenarios. In this work, we present an alternate interface for imitation that simplifies the data collection process while allowing for easy transfer to robots. We use commercially available reacher-grabber assistive tools both as a data collection device and as the robot's end-effector. To extract action information from these visual demonstrations, we use off-the-shelf Structure from Motion (SfM) techniques in addition to training a finger detection network. We experimentally evaluate on two challenging tasks: non-prehensile pushing and prehensile stacking, with 1000 diverse demonstrations for each task. For both tasks, we use standard behavior cloning to learn executable policies from the previously collected offline demonstrations. To improve learning performance, we employ a variety of data augmentations and provide an extensive analysis of its effects. Finally, we demonstrate the utility of our interface by evaluating on real robotic scenarios with previously unseen objects and achieve a 87% success rate on pushing and a 62% success rate on stacking. Robot videos are available at our project website.",
        "DOI": "NA",
        "paper_author": "Young S.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Transformers for One-Shot Visual Imitation",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "25",
        "cover_date": "2020-01-01",
        "Abstract": "Humans are able to seamlessly visually imitate others, by inferring their intentions and using past experience to achieve the same end goal. In other words, we can parse complex semantic knowledge from raw video and efficiently translate that into concrete motor control. Is it possible to give a robot this same capability? Prior research in robot imitation learning has created agents which can acquire diverse skills from expert human operators. However, expanding these techniques to work with a single positive example during test time is still an open challenge. Apart from control, the difficulty stems from mismatches between the demonstrator and robot domains. For example, objects may be placed in different locations (e.g. kitchen layouts are different in every house). Additionally, the demonstration may come from an agent with different morphology and physical appearance (e.g. human), so one-to-one action correspondences are not available. This paper investigates techniques which allow robots to partially bridge these domain gaps, using their past experience. A neural network is trained to mimic ground truth robot actions given context video from another agent, and must generalize to unseen task instances when prompted with new videos during test time. We hypothesize that our policy representations must be both context driven and dynamics aware in order to perform these tasks. These assumptions are baked into the neural network using the Transformers attention mechanism and a self-supervised inverse dynamics loss. Finally, we experimentally determine that our method accomplishes a ∼ 2x improvement in terms of task success rate over prior baselines in a suite of one-shot manipulation tasks.",
        "DOI": "NA",
        "paper_author": "Dasari S.",
        "affiliation_name": "The Robotics Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60104841",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Learning Obstacle Representations for Neural Motion Planning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Motion planning and obstacle avoidance is a key challenge in robotics applications. While previous work succeeds to provide excellent solutions for known environments, sensor-based motion planning in new and dynamic environments remains difficult. In this work we address sensor-based motion planning from a learning perspective. Motivated by recent advances in visual recognition, we argue the importance of learning appropriate representations for motion planning. We propose a new obstacle representation based on the PointNet architecture and train it jointly with policies for obstacle avoidance. We experimentally evaluate our approach for rigid body motion planning in challenging environments and demonstrate significant improvements of the state of the art in terms of accuracy and efficiency.",
        "DOI": "NA",
        "paper_author": "Strudel R.",
        "affiliation_name": "École Normale Supérieure",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60000179",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "SAM: Squeeze-and-Mimic Networks for Conditional Visual Driving Policy Learning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "We describe a policy learning approach to map visual inputs to driving controls conditioned on turning command that leverages side tasks on semantics and object affordances via a learned representation trained for driving. To learn this representation, we train a squeeze network to drive using annotations for the side task as input. This representation encodes the driving-relevant information associated with the side task while ideally throwing out side task-relevant but driving-irrelevant nuisances. We then train a mimic network to drive using only images as input and use the squeeze network's latent representation to supervise the mimic network via a mimicking loss. Notably, we do not aim to achieve the side task nor to learn features for it; instead, we aim to learn, via the mimicking loss, a representation of the side task annotations directly useful for driving. We test our approach using the CARLA simulator. In addition, we introduce a more challenging but realistic evaluation protocol that considers a run that reaches the destination successful only if it does not violate common traffic rules.",
        "DOI": "NA",
        "paper_author": "Zhao A.",
        "affiliation_name": "University of California, Los Angeles",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60027550",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Uncertainty-Aware Constraint Learning for Adaptive Safe Motion Planning from Demonstrations",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "We present a method for learning to satisfy uncertain constraints from demonstrations. Our method uses robust optimization to obtain a belief over the potentially infinite set of possible constraints consistent with the demonstrations, and then uses this belief to plan trajectories that trade off performance with satisfying the possible constraints. We use these trajectories in a closed-loop policy that executes and replans using belief updates, which incorporate data gathered during execution. We derive guarantees on the accuracy of our constraint belief and probabilistic guarantees on plan safety. We present results on a 7-DOF arm and 12D quadrotor, showing our method can learn to satisfy high-dimensional (up to 30D) uncertain constraints, and outperforms baselines in safety and efficiency.",
        "DOI": "NA",
        "paper_author": "Chou G.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60025778",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Robot Action Selection Learning via Layered Dimension Informed Program Synthesis",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Action selection policies (ASPs), used to compose low-level robot skills into complex high-level tasks are commonly represented as neural networks (NNs) in the state of the art. Such a paradigm, while very effective, suffers from a few key problems: 1) NNs are opaque to the user and hence not amenable to verification, 2) they require significant amounts of training data, and 3) they are hard to repair when the domain changes. We present two key insights about ASPs for robotics. First, ASPs need to reason about physically meaningful quantities derived from the state of the world, and second, there exists a layered structure for composing these policies. Leveraging these insights, we introduce layered dimension-informed program synthesis (LDIPS) - by reasoning about the physical dimensions of state variables, and dimensional constraints on operators, LDIPS directly synthesizes ASPs in a human-interpretable domain-specific language that is amenable to program repair. We present empirical results to demonstrate that LDIPS 1) can synthesize effective ASPs for robot soccer and autonomous driving domains, 2) enables tractable synthesis for robot action selection policies not possible with state of the art synthesis techniques, 3) requires two orders of magnitude fewer training examples than a comparable NN representation, and 4) can repair the synthesized ASPs with only a small number of corrections when transferring from simulation to real robots.",
        "DOI": "NA",
        "paper_author": "Holtz J.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Designing Machine Learning Based Security System for Smart Cities",
        "publication": "IET Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Immense urbanization is putting tremendous pressure on policy makers, city planners and managers to render sustainable plans and designs which ensures good quality of life for the residents of the smart cities. In order to achieve this goal, a city can be made smart with the ubiquitous development and usage in hardware and software technologies, vast advancement in information and communication technologies and speedy furtherance of connected devices. The newest style of smart city initiative, in turn makes the implementation arduous and challenging. Furthermore, the standards for the design and implementation of the smart city is yet to be released. Consequently, security in this ad-hoc technology is premature and overlooked. In this paper we propose security system that offers active and planned approach to protect the smart city in four spots. Firstly, the machine learning based security system should be placed at the data collection points that has IoT enabled devices. Secondly, the data must be protected by implementing complex cryptographic technique while travelling from the collection points to the intended storage location. Thirdly, the data at rest in the storage area for analysis should be conserved by applying some intelligent intrusion detection technique. Finally, the specific machine generated action should be ensured at the target.",
        "DOI": "10.1049/icp.2021.0754",
        "paper_author": "Sengupta N.",
        "affiliation_name": "University College of Bahrain",
        "affiliation_city": "Janabiyah",
        "affiliation_country": "Bahrain",
        "affiliation_id": "60085995",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mixing Enhancement of Free Jet using Deep Reinforcement Learning",
        "publication": "22nd Australasian Fluid Mechanics Conference, AFMC 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In order to develop a new jet mixing procedure, we explore the possibility of DRL (deep reinforcement learning) using numerical simulation. First, we conduct some cases of open-loop control in which a main jet is manipulated by a pair of sub jet being actuated at the inlet of main jet, and examine the effect of actuating frequency on the mixing performance of main jet. Then, we select a DDPG (deep deterministic policy gradient) scheme among of the present DRL schemes, and apply it to the above-mentioned jet control problem. Compared the results of DDPG with that of open-loop control, the DDPG scheme turns out the useful performance of jet mixing control, i. e., the entrainment of fluid from surroundings is enhanced through the DRL while the main jet behaves like a flapping jet. Further DMD(dynamic mode decomposition) analysis is performed to clarify the characteristics of the dominant modes in mixing.",
        "DOI": "10.14264/ac4cdcc",
        "paper_author": "Tsujimoto K.",
        "affiliation_name": "Mie University",
        "affiliation_city": "Tsu",
        "affiliation_country": "Japan",
        "affiliation_id": "60018873",
        "affiliation_state": "Mie"
    },
    {
        "paper_title": "Augmenting GAIL with BC for sample efficient imitation learning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "Imitation learning is the problem of recovering an expert policy without access to a reward signal. Behavior cloning and GAIL are two widely used methods for performing imitation learning. Behavior cloning converges in a few iterations, but does not achieve peak performance due to its inherent iid assumption about the state-action distribution. GAIL addresses the issue by accounting for the temporal dependencies when performing a state distribution matching between the agent and the expert. Although GAIL is sample efficient in the number of expert trajectories required, it is still not very sample efficient in terms of the environment interactions needed for convergence of the policy. Given the complementary benefits of both methods, we present a simple and elegant method to combine both methods to enable stable and sample efficient learning. Our algorithm is very simple to implement and integrates with different policy gradient algorithms. We demonstrate the effectiveness of the algorithm in low dimensional control tasks, gridworlds and in high dimensional image-based tasks.",
        "DOI": "NA",
        "paper_author": "Jena R.",
        "affiliation_name": "The Robotics Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60104841",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Decentralized Network Governance: Blockchain Technology and the Future of Regulation",
        "publication": "Frontiers in Blockchain",
        "citied_by": "89",
        "cover_date": "2020-01-01",
        "Abstract": "Advancements in the digital domain, for example, in blockchain technology, big data, and machine learning, are increasingly shaping the lives of individuals, groups, organizations, and societies. These developments call for effective governance to protect the basic interests and needs of these actors. Simultaneously, the very nature of governance is also changing. Policy-making is increasingly moving away from top-down governance by the state toward more horizontal modes of governance. This paper reviews the literature on governance theory in order to conceptualize governance as a mode of decentralized, networked regulation. We argue that the current dominant modes of governance are inadequate in understanding governance in the digital domain and are poorly equipped to conceptualize novel forms of governance such as decentralized autonomous organizations (DAOs). Therefore, this study proposes a new mode of governance based on the regulation of new power relationships between the state and actors in the digital domain. This model further explores the role that blockchain technology can play in what we term decentralized network governance.",
        "DOI": "10.3389/fbloc.2020.00012",
        "paper_author": "Zwitter A.",
        "affiliation_name": "Rijksuniversiteit Groningen",
        "affiliation_city": "Groningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60010023",
        "affiliation_state": "Groningen"
    },
    {
        "paper_title": "A User's Guide to Calibrating Robotics Simulators",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Simulators are a critical component of modern robotics research. Strategies for both perception and decision making can be studied in simulation first before deployed to real world systems, saving on time and costs. Despite significant progress on the development of sim-to-real algorithms, the analysis of different methods is still conducted in an ad-hoc manner, without a consistent set of tests and metrics for comparison. This paper fills this gap and proposes a set of benchmarks and a framework for the study of various algorithms aimed to transfer models and policies learnt in simulation to the real world. We conduct experiments on a wide range of well known simulated environments to characterize and offer insights into the performance of different algorithms. Our analysis can be useful for practitioners working in this area and can help make informed choices about the behavior and main properties of sim-to-real algorithms.",
        "DOI": "NA",
        "paper_author": "Mehta B.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Application of Unsupervised Machine Learning to Cluster the Population Covered by Health Insurance",
        "publication": "Lecture Notes in Intelligent Transportation and Infrastructure",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Unsupervised learning refers to training an artificial intelligence system based on unlabeled data. One of its main applications is clustering analysis, which is the study of techniques and algorithms used to create clusters from a set of data. Clustering methods can be applied in various fields, particularly in health insurance. Health insurance is one of the ways that individuals finance their medical needs and maintain a stable financial situation in case of illness, which shows the importance of subscribing to a medical insurance coverage. Therefore, studying the behavior of the population benefiting from it is essential. In this paper, we apply K-means algorithm, which is one of the most used and efficient unsupervised learning methods for data clustering, in order to cluster the subscribers covered by health insurance in homogeneous groups or clusters. The clusters created will serve as a decision support tool for policy makers in the insurance field.",
        "DOI": "10.1007/978-3-030-37629-1_23",
        "paper_author": "Zahi S.",
        "affiliation_name": "Université Hassan 1er",
        "affiliation_city": "Settat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60026692",
        "affiliation_state": "Casablanca-Settat"
    },
    {
        "paper_title": "Predicted Influences of Artificial Intelligence on the Domains of Nursing: Scoping Review",
        "publication": "JMIR Nursing",
        "citied_by": "89",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Artificial intelligence (AI) is set to transform the health system, yet little research to date has explored its influence on nurses—the largest group of health professionals. Furthermore, there has been little discussion on how AI will influence the experience of person-centered compassionate care for patients, families, and caregivers. Objective: This review aims to summarize the extant literature on the emerging trends in health technologies powered by AI and their implications on the following domains of nursing: administration, clinical practice, policy, and research. This review summarizes the findings from 3 research questions, examining how these emerging trends might influence the roles and functions of nurses and compassionate nursing care over the next 10 years and beyond. Methods: Using an established scoping review methodology, MEDLINE, CINAHL, EMBASE, PsycINFO, Cochrane Database of Systematic Reviews, Cochrane Central, Education Resources Information Center, Scopus, Web of Science, and ProQuest databases were searched. In addition to the electronic database searches, a targeted website search was performed to access relevant gray literature. Abstracts and full-text studies were independently screened by 2 reviewers using prespecified inclusion and exclusion criteria. Included articles focused on nursing and digital health technologies that incorporate AI. Data were charted using structured forms and narratively summarized. Results: A total of 131 articles were retrieved from the scoping review for the 3 research questions that were the focus of this manuscript (118 from database sources and 13 from targeted websites). Emerging AI technologies discussed in the review included predictive analytics, smart homes, virtual health care assistants, and robots. The results indicated that AI has already begun to influence nursing roles, workflows, and the nurse-patient relationship. In general, robots are not viewed as replacements for nurses. There is a consensus that health technologies powered by AI may have the potential to enhance nursing practice. Consequently, nurses must proactively define how person-centered compassionate care will be preserved in the age of AI. Conclusions: Nurses have a shared responsibility to influence decisions related to the integration of AI into the health system and to ensure that this change is introduced in a way that is ethical and aligns with core nursing values such as compassionate care. Furthermore, nurses must advocate for patient and nursing involvement in all aspects of the design, implementation, and evaluation of these technologies.",
        "DOI": "10.2196/23939",
        "paper_author": "Buchanan C.",
        "affiliation_name": "Registered Nurses' Association of Ontario",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "106948301",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Deep Reinforcement Learning in Unity: With Unity ML Toolkit",
        "publication": "Deep Reinforcement Learning in Unity: With Unity ML Toolkit",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Gain an in-depth overview of reinforcement learning for autonomous agents in game development with Unity. This book starts with an introduction to state-based reinforcement learning algorithms involving Markov models, Bellman equations, and writing custom C# code with the aim of contrasting value and policy-based functions in reinforcement learning. Then, you will move on to path finding and navigation meshes in Unity, setting up the ML Agents Toolkit (including how to install and set up ML agents from the GitHub repository), and installing fundamental machine learning libraries and frameworks (such as Tensorflow). You will learn about: deep learning and work through an introduction to Tensorflow for writing neural networks (including perceptron, convolution, and LSTM networks), Q learning with Unity ML agents, and porting trained neural network models in Unity through the Python-C# API. You will also explore the OpenAI Gym Environment used throughout the book. Deep Reinforcement Learning in Unity provides a walk-through of the core fundamentals of deep reinforcement learning algorithms, especially variants of the value estimation, advantage, and policy gradient algorithms (including the differences between on and off policy algorithms in reinforcement learning). These core algorithms include actor critic, proximal policy, and deep deterministic policy gradients and its variants. And you will be able to write custom neural networks using the Tensorflow and Keras frameworks. Deep learning in games makes the agents learn how they can perform better and collect their rewards in adverse environments without user interference. The book provides a thorough overview of integrating ML Agents with Unity for deep reinforcement learning. What You Will Learn Understand how deep reinforcement learning works in games Grasp the fundamentals of deep reinforcement learning Integrate these fundamentals with the Unity ML Toolkit SDK Gain insights into practical neural networks for training Agent Brain in the context of Unity ML Agents Create different models and perform hyper-parameter tuning Understand the Brain-Academy architecture in Unity ML Agents Understand the Python-C# API interface during real-time training of neural networks Grasp the fundamentals of generic neural networks and their variants using Tensorflow Create simulations and visualize agents playing games in Unity Who This Book Is For Readers with preliminary programming and game development experience in Unity, and those with experience in Python and a general idea of machine learning.",
        "DOI": "10.1007/978-1-4842-6503-1",
        "paper_author": "Majumder A.",
        "affiliation_name": "HSBC Holdings",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60001492",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ahead by a Century: Tim Edgar, Machine-Learning, and the Future of Anti-Avoidance",
        "publication": "Canadian Tax Journal",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Tim Edgar’s contributions to our understanding of tax avoidance and anti-avoidance remain ahead of their time. In this paper, the author argues that Edgar’s work on building better general anti-avoidance rules (GAARs) was particularly prescient—correct in its claim that tax avoidance can and should be eliminated through effective anti-avoidance measures. The author maintains that although Edgar’s position and vision will eventually be realized, Edgar himself did not anticipate the manner in which this would occur. The author’s first claim is that the law is incomplete, and this incompleteness problematizes any insistence on the immediate adoption of strict anti-avoidance measures. The author explains how and why the current stage of legal development falls significantly short of completely specifying the law, including the tax law. The author’s second claim is that the next decades will bring considerably more sophisticated and effective approaches to legal development. Described, in broad terms, are some of the mechanisms through which our tax systems are moving toward a legal singularity (a state of the law that is functionally complete and well specified). The author proceeds to outline the implications of his two main claims for the future of GAARs and anti-avoidance— specifically, how the realization of a much more complete system of law will leave effectively no further scope for tax avoidance. Tax law, in the asymptotic realization of Edgar’s work and vision, will become well targeted and well equipped to address tax avoidance. Tax avoidance as we know it will cease to exist.",
        "DOI": "10.32721/ctj.2020.68.2.sym.alarie",
        "paper_author": "Alarie B.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Learning a Policy Primes Quality Control: Towards Evidence-Based Automation of Learning Engineering",
        "publication": "Proceedings of the 13th International Conference on Educational Data Mining, EDM 2020",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "One of the most challenging issues for online courseware engineering is to maintain the quality of instructional components, such as written text, video, and assessments. Learning engineers would like to know how individual instructional components contributed to students’ learning. However, it is a hard task because it requires significant expertise in learning science, learning technology, and subject matter pedagogy. To address this challenge, we propose an innovative application of reinforcement learning (RL) as an assessor of instructional components implemented in given online courseware. After students activities are converted into Markov decision process (MDP), a collection of actions (each corresponds to an instructional component) suggested as a policy is analyzed. As a consequence, the usefulness of individual actions with regards to achieving ideal learning outcomes will be suggested. The proposed RL application is invented for human-in-the-loop learning engineering method called RAFINE. In the RAFINE framework, a machine generates a list of the least contributing instructional components on the given online courseware by interpreting the whole policy. The courseware developers modify those suggested components. As a proof of concept, this paper describes an evaluation study where online learning was simulated on hypothetical online courseware. The results showed that over 90% of ineffective instructional components were correctly identified as ineffective on average.",
        "DOI": "NA",
        "paper_author": "Shimmei M.",
        "affiliation_name": "NC State University",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States",
        "affiliation_id": "60004923",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Untangling Dense Knots by Learning Task-Relevant Keypoints",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "23",
        "cover_date": "2020-01-01",
        "Abstract": "Untangling ropes, wires, and cables is a challenging task for robots due to the high-dimensional configuration space, visual homogeneity, self-occlusions, and complex dynamics. We consider dense (tight) knots that lack space between self-intersections and present an iterative approach that uses learned geometric structure in configurations. We instantiate this into an algorithm, HULK: Hierarchical Untangling from Learned Keypoints, which combines learning-based perception with a geometric planner into a policy that guides a bilateral robot to untangle knots. To evaluate the policy, we perform experiments both in a novel simulation environment modelling cables with varied knot types and textures and in a physical system using the da Vinci surgical robot. We find that HULK is able to untangle cables with dense figure-eight and overhand knots and generalize to varied textures and appearances. We compare two variants of HULK to three baselines and observe that HULK achieves 43.3% higher success rates on a physical system compared to the next best baseline. HULK successfully untangles a cable from a dense initial configuration containing up to two overhand and figure-eight knots in 97.9% of 378 simulation experiments with an average of 12.1 actions per trial. In physical experiments, HULK achieves 61.7% untangling success, averaging 8.48 actions per trial. Supplementary material, code, and videos can be found at https://tinyurl.com/y3a88ycu.",
        "DOI": "NA",
        "paper_author": "Grannen J.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Static and Dynamic Values of Computation in MCTS",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Monte-Carlo Tree Search (MCTS) is one of the most-widely used methods for planning, and has powered many recent advances in artificial intelligence. In MCTS, one typically performs computations (i.e., simulations) to collect statistics about the possible future consequences of actions, and then chooses accordingly. Many popular MCTS methods such as UCT and its variants decide which computations to perform by trading-off exploration and exploitation. In this work, we take a more direct approach, and explicitly quantify the value of a computation based on its expected impact on the quality of the action eventually chosen. Our approach goes beyond the myopic limitations of existing computation-value-based methods in two senses: (I) we are able to account for the impact of non-immediate (ie, future) computations (II) on non-immediate actions. We show that policies that greedily optimize computation values are optimal under certain assumptions and obtain results that are competitive with the state-of-the-art.",
        "DOI": "NA",
        "paper_author": "Sezener E.",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60111161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Generalized Policy Elimination: an efficient algorithm for Nonparametric Contextual Bandits",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "We propose the Generalized Policy Elimination (GPE) algorithm, an oracle-efficient contextual bandit (CB) algorithm inspired by the Policy Elimination algorithm of Dudik et al. [2011]. We prove the first regret optimality guarantee theorem for an oracle-efficient and CB algorithm competing against a nonparametric class with infinite VC-dimension. Specifically, we show that GPE is regret-optimal (up to logarithmic factors) for policy classes with integrable entropy. For classes with larger entropy, we show that the core techniques used to analyze GPE can be used to design an e-greedy algorithm with regret bound matching that of the best algorithms to date. We illustrate the applicability of our algorithms and theorems with examples of large nonparametric policy classes, for which the relevant optimization oracles can be efficiently implemented.",
        "DOI": "NA",
        "paper_author": "Bibaut A.F.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Efficient Rollout Strategies for Bayesian Optimization",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "Bayesian optimization (BO) is a class of sample-efficient global optimization methods, where a probabilistic model conditioned on previous observations is used to determine future evaluations via the optimization of an acquisition function. Most acquisition functions are myopic, meaning that they only consider the impact of the next function evaluation. Non-myopic acquisition functions consider the impact of the next h function evaluations and are typically computed through rollout, in which h steps of BO are simulated. These rollout acquisition functions are defined as h-dimensional integrals, and are expensive to compute and optimize. We show that a combination of quasi-Monte Carlo, common random numbers, and control variates significantly reduce the computational burden of rollout. We then formulate a policy-search based approach that removes the need to optimize the rollout acquisition function. Finally, we discuss the qualitative behavior of rollout policies in the setting of multimodal objectives and model error.",
        "DOI": "NA",
        "paper_author": "Lee E.H.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "We consider learning policies online in Markov decision processes with the long-run average reward (a.k.a. mean payoff). To ensure implementability of the policies, we focus on policies with finite memory. Firstly, we show that near optimality can be achieved almost surely, using an unintuitive gadget we call forgetfulness. Secondly, we extend the approach to a setting with partial knowledge of the system topology, introducing two optimality measures and providing near-optimal algorithms also for these cases.",
        "DOI": "NA",
        "paper_author": "Kretínský J.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Test-time data augmentation-averaging the predictions of a machine learning model across multiple augmented samples of data-is a widely used technique that improves the predictive performance. While many advanced learnable data augmentation techniques have emerged in recent years, they are focused on the training phase. Such techniques are not necessarily optimal for test-time augmentation and can be outperformed by a policy consisting of simple crops and flips. The primary goal of this paper is to demonstrate that test-time augmentation policies can be successfully learned too. We introduce greedy policy search (GPS), a simple but high-performing method for learning a policy of test-time augmentation. We demonstrate that augmentation policies learned with GPS achieve superior predictive performance on image classification problems, provide better in-domain uncertainty estimation, and improve the robustness to domain shift.",
        "DOI": "NA",
        "paper_author": "Molchanov D.",
        "affiliation_name": "Samsung AI Center",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "121905949",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Provably Efficient Third-Person Imitation from Offline Observation",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Domain adaptation in imitation learning represents an essential step towards improving generalizability. However, even in the restricted setting of third-person imitation where transfer is between isomorphic Markov Decision Processes, there are no strong guarantees on the performance of transferred policies. We present problem-dependent, statistical learning guarantees for third-person imitation from observation in an offline setting, and a lower bound on performance in an online setting.",
        "DOI": "NA",
        "paper_author": "Zweig A.",
        "affiliation_name": "Courant Institute of Mathematical Sciences",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60003261",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Fair Decisions Despite Imperfect Predictions",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "32",
        "cover_date": "2020-01-01",
        "Abstract": "Consequential decisions are increasingly informed by sophisticated data-driven predictive models. However, consistently learning accurate predictive models requires access to ground truth labels. Unfortunately, in practice, labels may only exist conditional on certain decisions-if a loan is denied, there is not even an option for the individual to pay back the loan. In this paper, we show that, in this selective labels setting, learning to predict is suboptimal in terms of both fairness and utility. To avoid this undesirable behavior, we propose to directly learn stochastic decision policies that maximize utility under fairness constraints. In the context of fair machine learning, our results suggest the need for a paradigm shift from “learning to predict” to “learning to decide”. Experiments on synthetic and real-world data illustrate the favorable properties of learning to decide, in terms of both utility and fairness.",
        "DOI": "NA",
        "paper_author": "Kilbertus N.",
        "affiliation_name": "MPI for Intelligent Systems",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "129832730",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Sublinear Optimal Policy Value Estimation in Contextual Bandits",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "We study the problem of estimating the expected reward of the optimal policy in the stochastic disjoint linear bandit setting. We prove that for certain settings it is possible to obtain an accurate estimate of the optimal policy value even with a number of samples that is sublinear in the number that would be required to find a policy that realizes a value close to this optima. We establish nearly matching information theoretic lower bounds, showing that our algorithm achieves near optimal estimation error. Finally, we demonstrate the effectiveness of our algorithm on joke recommendation and cancer inhibition dosage selection problems using real datasets.",
        "DOI": "NA",
        "paper_author": "Kong W.",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Portland",
        "affiliation_country": "United States",
        "affiliation_id": "101964446",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "AsyncQVI: Asynchronous-Parallel Q-Value Iteration for Discounted Markov Decision Processes with Near-Optimal Sample Complexity",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we propose AsyncQVI, an asynchronous-parallel Q-value iteration for discounted Markov decision processes whose transition and reward can only be sampled through a generative model. Given such a problem with |S| states, |A| actions, and a discounted factor γ ∈ (0, 1), AsyncQVI uses memory of size O(|S|) and returns an ε-optimal policy with probability at least 1−δ using (equ)samples.1 AsyncQVI is also the first asynchronous-parallel algorithm for discounted Markov decision processes that has a sample complexity, which nearly matches the theoretical lower bound. The relatively low memory footprint and parallel ability make AsyncQVI suitable for large-scale applications. In numerical tests, we compare AsyncQVI with four sample-based value iteration methods. The results show that our algorithm is highly efficient and achieves linear parallel speedup.",
        "DOI": "NA",
        "paper_author": "Zeng Y.",
        "affiliation_name": "Fudan University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60009860",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Differentiable Causal Backdoor Discovery",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Discovering the causal effect of a decision is critical to nearly all forms of decision-making. In particular, it is a key quantity in drug development, in crafting government policy, and when implementing a real-world machine learning system. Given only observational data, confounders often obscure the true causal effect. Luckily, in some cases, it is possible to recover the causal effect by using certain observed variables to adjust for the effects of confounders. However, without access to the true causal model, finding this adjustment requires brute-force search. In this work, we present an algorithm that exploits auxiliary variables, similar to instruments, in order to find an appropriate adjustment by a gradient-based optimization method. We demonstrate that it outperforms practical alternatives in estimating the true causal effect, without knowledge of the full causal graph.",
        "DOI": "NA",
        "paper_author": "Gultchin L.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Optimization Methods for Interpretable Differentiable Decision Trees in Reinforcement Learning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "39",
        "cover_date": "2020-01-01",
        "Abstract": "Decision trees are ubiquitous in machine learning for their ease of use and interpretability. Yet, these models are not typically employed in reinforcement learning as they cannot be updated online via stochastic gradient descent. We overcome this limitation by allowing for a gradient update over the entire tree that improves sample complexity affords interpretable policy extraction. First, we include theoretical motivation on the need for policy-gradient learning by examining the properties of gradient descent over differentiable decision trees. Second, we demonstrate that our approach equals or outperforms a neural network on all domains and can learn discrete decision trees online with average rewards up to 7x higher than a batch-trained decision tree. Third, we conduct a user study to quantify the interpretability of a decision tree, rule list, and a neural network with statistically significant results (p < 0.001).",
        "DOI": "NA",
        "paper_author": "Silva A.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Why Non-myopic Bayesian Optimization is Promising and How Far Should We Look-ahead? A Study via Rollout",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Lookahead, also known as non-myopic, Bayesian optimization (BO) aims to find optimal sampling policies through solving a dynamic programming (DP) formulation that maximizes a long-term reward over a rolling horizon. Though promising, lookahead BO faces the risk of error propagation through its increased dependence on a possibly mis-specified model. In this work we focus on the rollout approximation for solving the intractable DP. We first prove the improving nature of rollout in tackling lookahead BO and provide a sufficient condition for the used heuristic to be rollout improving. We then provide both a theoretical and practical guideline to decide on the rolling horizon stagewise. This guideline is built on quantifying the negative effect of a mis-specified model. To illustrate our idea, we provide case studies on both single and multi-information source BO. Empirical results show the advantageous properties of our method over several myopic and non-myopic BO algorithms.",
        "DOI": "NA",
        "paper_author": "Yue X.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60025778",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Stochastic Bandits with Delay-Dependent Payoffs",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "Motivated by recommendation problems in music streaming platforms, we propose a nonstationary stochastic bandit model in which the expected reward of an arm depends on the number of rounds that have passed since the arm was last pulled. After proving that finding an optimal policy is NP-hard even when all model parameters are known, we introduce a class of ranking policies provably approximating, to within a constant factor, the expected reward of the optimal policy. We show an algorithm whose regret with respect to_the best ranking policy is bounded by (Equation presented), where k is the number of arms and T is time. Our algorithm uses only O(k ln ln T) switches, which helps when switching between policies is costly. As constructing the class of learning policies requires ordering the arms according to their expectations, we also bound the number of pulls required to do so. Finally, we run experiments to compare our algorithm against UCB on different problem instances.",
        "DOI": "NA",
        "paper_author": "Cella L.",
        "affiliation_name": "Università degli Studi di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60030318",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Multitask Soft Option Learning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "We present Multitask Soft Option Learning (MSOL), a hierarchical multitask framework based on Planning as Inference. MSOL extends the concept of options, using separate variational posteriors for each task, regularized by a shared prior. This “soft” version of options avoids several instabilities during training in a multitask setting, and provides a natural way to learn both intra-option policies and their terminations. Furthermore, it allows fine-tuning of options for new tasks without forgetting their learned policies, leading to faster training without reducing the expressiveness of the hierarchical policy. We demonstrate empirically that MSOL significantly outperforms both hierarchical and flat transfer-learning baselines.",
        "DOI": "NA",
        "paper_author": "Igl M.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Asian Conference on Machine Learning, ACML 2020",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 53 papers. The topics discussed include: a distance-weighted class-homogeneous neighborhood ratio for algorithm selection; semantic-guided shared feature alignment for occluded person re-identification; theory of mind with guilt aversion facilitates cooperative reinforcement learning; a novel higher-order Weisfeiler-Lehman graph convolution; a one-step approach to covariate shift adaptation; a state aggregation approach for solving knapsack problem with deep reinforcement learning; bidirectional dependency-guided attention for relation extraction; bridging ordinary-label learning and complementary-label learning; CCA-Flow: deep multi-view subspace learning with inverse autoregressive flow; constrained reinforcement learning via policy splitting; convergence rates of a momentum algorithm with bounded adaptive step size for nonconvex optimization; and data-dependent conversion to a compact integer-weighted representation of a weighted voting classifier.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Data-Driven Approach for Addressing Sexual and Reproductive Health Needs Among Youth Migrants",
        "publication": "Leveraging Data Science for Global Health",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Every year millions of people migrate across international borders from country to country capturing the attention of governments. While this movement has led to the development of many new international policies and programs that help assist these migrants, still a lot needs to be done to plug the unmet sexual and reproductive health needs of adolescent migrants who are mostly dependent on their families financially and socially and often fall through the cracks of the system. Objective: In order to create new policies and programs, legislators and other government workers must collect extensive data about these migrants to find out more information regarding the reasons for their migration and their immediate health needs in the process of migration for key decision-making. This study explores ways of getting relevant data from the migrants and apply machine learning to derive insights from the data for the stakeholders. Methods: To solve this problem, we have created a web application that will facilitate crucial data collection. Additionally, we have mocked up a data driven recommendation system about predicting most vulnerable migrants. This could help different stakeholders involved in the sexual and reproductive health of youth migrants in clinical decision-making. Results: The study involved building a web-app and curation of a questionnaire for the migrants to build a pipeline of data that could be later used for deriving insights about the patterns in migration and its potential sexual and health risks. It has also explored different ways of disseminating information about sexual and reproductive health needs to the youth migrants. Finally, machine learning was used for predicting vulnerability of migrants based on their backgrounds. Conclusion: Data is of great essence in mitigating the risks associated with various sexual and reproductive health related issues among migrants. First, it can be used to make youth migrants aware of their sexual and reproductive health needs and rights. Second, it can be used by Machine Learning to generate useful recommendations for reducing the risks of migration.",
        "DOI": "10.1007/978-3-030-47994-7_25",
        "paper_author": "Jaiswal P.",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60032499",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "REMIXMATCH: SEMI-SUPERVISED LEARNING WITH DISTRIBUTION ALIGNMENT AND AUGMENTATION ANCHORING",
        "publication": "8th International Conference on Learning Representations, ICLR 2020",
        "citied_by": "313",
        "cover_date": "2020-01-01",
        "Abstract": "We improve the recently-proposed “MixMatch” semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels. Augmentation anchoring feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between 5× and 16× less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to MixMatch's accuracy of 93.58% with 4,000 examples) and a median accuracy of 84.92% with just four labels per class. We make our code and data open-source at https://github.com/google-research/remixmatch.",
        "DOI": "NA",
        "paper_author": "Berthelot D.",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States",
        "affiliation_id": "60006191",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "COMPOSING TASK-AGNOSTIC POLICIES WITH DEEP REINFORCEMENT LEARNING",
        "publication": "8th International Conference on Learning Representations, ICLR 2020",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "The composition of elementary behaviors to solve challenging transfer learning problems is one of the key elements in building intelligent machines. To date, there has been plenty of work on learning task-specific policies or skills but almost no focus on composing necessary, task-agnostic skills to find a solution to new problems. In this paper, we propose a novel deep reinforcement learning-based skill transfer and composition method that takes the agent's primitive policies to solve unseen tasks. We evaluate our method in difficult cases where training policy through standard reinforcement learning (RL) or even hierarchical RL is either not feasible or exhibits high sample complexity. We show that our method not only transfers skills to new problem settings but also solves the challenging environments requiring both task planning and motion control with high data efficiency.",
        "DOI": "NA",
        "paper_author": "Qureshi A.H.",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States",
        "affiliation_id": "60030612",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "DD-PPO: LEARNING NEAR-PERFECT POINTGOAL NAVIGATORS FROM 2.5 BILLION FRAMES",
        "publication": "8th International Conference on Learning Representations, ICLR 2020",
        "citied_by": "140",
        "cover_date": "2020-01-01",
        "Abstract": "We present Decentralized Distributed Proximal Policy Optimization (DD-PPO), a method for distributed reinforcement learning in resource-intensive simulated environments. DD-PPO is distributed (uses multiple machines), decentralized (lacks a centralized server), and synchronous (no computation is ever 'stale'), making it conceptually simple and easy to implement. In our experiments on training virtual robots to navigate in Habitat-Sim (Savva et al., 2019), DD-PPO exhibits near-linear scaling - achieving a speedup of 107x on 128 GPUs over a serial implementation. We leverage this scaling to train an agent for 2.5 Billion steps of experience (the equivalent of 80 years of human experience) - over 6 months of GPU-time training in under 3 days of wall-clock time with 64 GPUs. This massive-scale training not only sets the state of art on Habitat Autonomous Navigation Challenge 2019, but essentially 'solves' the task - near-perfect autonomous navigation in an unseen environment without access to a map, directly from an RGB-D camera and a GPS+Compass sensor. Fortuitously, error vs computation exhibits a power-law-like distribution; thus, 90% of peak performance is obtained relatively early (at 100 million steps) and relatively cheaply (under 1 day with 8 GPUs). Finally, we show that the scene understanding and navigation policies learned can be transferred to other navigation tasks - the analog of 'ImageNet pre-training + task-specific fine-tuning' for embodied AI. Our model outperforms ImageNet pre-trained CNNs on these transfer tasks and can serve as a universal resource (all models and code are publicly available).",
        "DOI": "NA",
        "paper_author": "Wijmans E.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Urban Building Energy CPS (UBE-CPS): Real-Time Demand Response Using Digital Twin",
        "publication": "Cyber-Physical Systems in the Built Environment",
        "citied_by": "23",
        "cover_date": "2020-01-01",
        "Abstract": "Cities are facing unprecedented growth with an increase in population and urbanization. The United Nations estimates that the global population will increase to 9.3 billion by 2050, which is an increase of 30% compared to the population in 2011 (UN, 2015). As development in dense urban areas continues, the scientific community must continue to observe, analyze, and interpret the effects of dense urbanization, including climate change impacts on urban sustainability, particularly buildings. The city governments are gradually modifying their policies, decisions, and strategies towards green and energy efficient approaches. Particularly, decisions related to expanding energy generation facilities are critical. Additionally, cities need to manage their energy consumption, now and in future, as they move toward a time variable sources of renewable energy such as solar and wind. In this chapter, we discuss the development of a novel Urban Building Energy CPS (UBE-CPS) framework that bridges the physical and the digital world through seamless data transfer for real-time demand response. While the data from physical world relates to sensor data obtained from buildings, the digital world is the Digital Twin, an advanced machine-learning model that is coupled with urban-scale EnergyPlus™ models that represent individual buildings. Through a feedback loop to the City Utility Manager / Administrator, UBE-CPS will become an integral part of the city energy management to automate and, potentially, control building-level demand curve to satisfy grid-level demand response.",
        "DOI": "10.1007/978-3-030-41560-0_17",
        "paper_author": "Srinivasan R.S.",
        "affiliation_name": "University of Florida",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States",
        "affiliation_id": "60013959",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "HOW ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING CAN HELP RETHINK ARCHIVES?",
        "publication": "Atlanti+",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Although artificial intelligence is the product of science-fiction literature, it currently represents a significant branch of computer science dealing with intelligent behavior, machine learning, and machine adaptation. It has become a discipline that attempts to answer real-world problems. Artificial intelligence systems are nowadays widely used in economics and medicine, design or military. The role of archives is changing worldwide. In this grandiose transformation, archives need to be at the forefront of their own future, so that they can steer, guide, and not lose out. The vast masses of information in archives provide an excellent platform forthe exploitation of artificial intelligence. The mass of data can be a great help not only for research but also for policy preparation and in some areas of public administration in the not too distant future.",
        "DOI": "NA",
        "paper_author": "Hegedus I.",
        "affiliation_name": "Magyar Országos Levéltár",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary",
        "affiliation_id": "60100915",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Pick the Moment: Identifying Critical Pedagogical Decisions Using Long-Short Term Rewards",
        "publication": "Proceedings of the 13th International Conference on Educational Data Mining, EDM 2020",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "Identifying critical decisions is one of the most challenging decision-making problems in real-world applications. In this work, we propose a novel Reinforcement Learning (RL) based Long-Short Term Rewards (LSTR) framework for critical decisions identification. RL is a machine learning area concerning with inducing effective decision-making policies, following which result in the maximum cumulative reward. Many RL algorithms find the optimal policy via estimating the optimal Q-values, which specify the maximum cumulative reward the agent can receive. In our LSTR framework, the long term rewards are defined as Q-values and the short term rewards are determined by the reward function. Experiments on a synthetic GridWorld game and real-world Intelligent Tutoring System datasets show that the proposed LSTR framework indeed identifies the critical decisions in the sequences. Furthermore, our results show that carrying out the critical decisions alone is as effective as a fully-executed policy.",
        "DOI": "NA",
        "paper_author": "Ju S.",
        "affiliation_name": "NC State College of Engineering",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States",
        "affiliation_id": "60279548",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Generalization Guarantees for Imitation Learning",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "Control policies from imitation learning can often fail to generalize to novel environments due to imperfect demonstrations or the inability of imitation learning algorithms to accurately infer the expert's policies. In this paper, we present rigorous generalization guarantees for imitation learning by leveraging the Probably Approximately Correct (PAC)-Bayes framework to provide upper bounds on the expected cost of policies in novel environments. We propose a two-stage training method where a latent policy distribution is first embedded with multi-modal expert behavior using a conditional variational autoencoder, and then “fine-tuned” in new training environments to explicitly optimize the generalization bound. We demonstrate strong generalization bounds and their tightness relative to empirical performance in simulation for (i) grasping diverse mugs, (ii) planar pushing with visual feedback, and (iii) vision-based indoor navigation, as well as through hardware experiments for the two manipulation tasks.",
        "DOI": "NA",
        "paper_author": "Ren A.Z.",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States",
        "affiliation_id": "60141284",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "SYNTHESIZING PROGRAMMATIC POLICIES THAT INDUCTIVELY GENERALIZE",
        "publication": "8th International Conference on Learning Representations, ICLR 2020",
        "citied_by": "28",
        "cover_date": "2020-01-01",
        "Abstract": "Deep reinforcement learning has successfully solved a number of challenging control tasks. However, learned policies typically have difficulty generalizing to novel environments. We propose an algorithm for learning programmatic state machine policies that can capture repeating behaviors. By doing so, they have the ability to generalize to instances requiring an arbitrary number of repetitions, a property we call inductive generalization. However, state machine policies are hard to learn since they consist of a combination of continuous and discrete structures. We propose a learning framework called adaptive teaching, which learns a state machine policy by imitating a teacher; in contrast to traditional imitation learning, our teacher adaptively updates itself based on the structure of the student. We show that our algorithm can be used to learn policies that inductively generalize to novel environments, whereas traditional neural network policies fail to do so.",
        "DOI": "NA",
        "paper_author": "Inala J.P.",
        "affiliation_name": "MIT Computer Science &amp; Artificial Intelligence Laboratory",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60006320",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "New ways of valuing ecosystem services: big data, machine learning, and the value of urban green spaces",
        "publication": "A Research Agenda for Environmental Economics",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "There is considerable policy interest to integrate the value of ecosystem services into systems of national accounts. Urban green spaces are traditionally valued by merging spatial household data with administrative data on land use to obtain their amount around households; this is then related to residential wellbeing or real estate prices to arrive at a monetary valuation. This traditional approach, however, neglects not only the large heterogeneity in the quality of urban green spaces but also issues of measuring outcomes and issues of reverse causality. We discuss new data and methods to overcome some of these issues. We focus on the use of high-frequency experience-sampling methods on wellbeing or web-scraped real estate prices to better understand impacts; big data from crowdsourced imagery of urban green spaces or satellite imagery of chlorophyll activity to better understand quality; and machine learning to make better use of data. Finally, we discuss the potential of field experiments and quasi-experiments to deal with reverse causality. Together, these approaches can greatly complement our traditional toolkit for valuing ecosystem services.",
        "DOI": "10.4337/9781789900057.00014",
        "paper_author": "Krekel C.",
        "affiliation_name": "London School of Economics and Political Science",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60003059",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Room for Compulsory Product Liability Insurance in the European Union for Smart Robots? Reflections on the Compelling Challenges",
        "publication": "AIDA Europe Research Series on Insurance Law and Regulation",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The twenty-first century has seen the exponential rise of machines capable of assisting people in all sorts of areas and which are placed in use in, inter alia, agricultural, medical, industrial and domestic contexts. These machines gradually becoming ‘smart’ and beginning to operate with self-learning tools has given rise to concerns as to liability in respect of losses arising from their use. The need to safeguard the rights of the parties harmed by their use (victims) without disturbing the policy of fostering innovation in the European Union has recently paved the way for the initiative of the European Parliament Committee on Legal Affairs towards the proposal of a set of rules on civil liability for robotics. The chapter provides an analysis of various potential risks that may emerge from applying the current product liability rules to new technologies, as well as focus on the challenges posed by the adoption of a compulsory product liability insurance scheme, as proposed. As the requirement of a duty to insure may bring along intricate problems of moral hazard, the chapter considers the efficiency of tools such as the monitoring of the insured’s behaviour and the introduction of deductibles into policies in alleviating this problem. It also assesses to what extent the protection of victims may be disturbed because of certain practices of the insurance framework such as the use of claims-made policies in product liability insurance. Overall, the chapter seeks to highlight the advantages and drawbacks of the proposed compulsory product liability insurance scheme.",
        "DOI": "10.1007/978-3-030-27386-6_8",
        "paper_author": "Bugra A.",
        "affiliation_name": "Dr. Nüsret - Semahat Arsel International Business Law Implementation and Research Center (NASAMER)",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey",
        "affiliation_id": "128951825",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Order Acceptance Policy for Make-To-Order Supply Chain",
        "publication": "Studies in Big Data",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "This paper explores a dynamic order acceptance policy of firms in a decentralized supply chain (SC) to improve the profits of an SC by using the machine learning method. The dynamic arrival and due date orders in SC were divided into three types according to the profit that the SC can obtain. Two echelons of the SC, in which a supplier that cooperate with other firms in SC will receive orders in and out of the SC, are employed in this study. Capturing four order characteristics in make-to-order SC, we examine whether this model can make a higher profit by using a simulation model of Support Vector Machines (SVMs) rather than First Come First Serve (FCFS) and Artificial Neural Network (ANN). The experimental results indicate that SVMs is an efficient tool for firms in a dynamic SC to improve the performance of the SC. A numerical example is used to validate the results.",
        "DOI": "10.1007/978-3-030-32587-9_5",
        "paper_author": "Ma J.",
        "affiliation_name": "Shenyang University of Technology",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60023212",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "LEARNING EFFICIENT PARAMETER SERVER SYNCHRONIZATION POLICIES FOR DISTRIBUTED SGD",
        "publication": "8th International Conference on Learning Representations, ICLR 2020",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "We apply a reinforcement learning (RL) based approach to learning optimal synchronization policies used for Parameter Server-based distributed training of machine learning models with Stochastic Gradient Descent (SGD). Utilizing a formal synchronization policy description in the PS-setting, we are able to derive a suitable and compact description of states and actions, allowing us to efficiently use the standard off-the-shelf deep Q-learning algorithm. As a result, we are able to learn synchronization policies which generalize to different cluster environments, different training datasets and small model variations and (most importantly) lead to considerable decreases in training time when compared to standard policies such as bulk synchronous parallel (BSP), asynchronous parallel (ASP), or stale synchronous parallel (SSP). To support our claims we present extensive numerical results obtained from experiments performed in simulated cluster environments. In our experiments training time is reduced by 44% on average and learned policies generalize to multiple unseen circumstances.",
        "DOI": "NA",
        "paper_author": "Zhu R.",
        "affiliation_name": "Alibaba Group Holding Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60118460",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Learning from Interventions: Human-robot interaction as both explicit and implicit feedback",
        "publication": "Robotics: Science and Systems",
        "citied_by": "32",
        "cover_date": "2020-01-01",
        "Abstract": "Scalable robot learning from seamless human-robot interaction is critical if robots are to solve a multitude of tasks in the real world. Current approaches to imitation learning suffer from one of two drawbacks. On the one hand, they rely solely on off-policy human demonstration, which in some cases leads to a mismatch in train-test distribution. On the other, they burden the human to label every state the learner visits, rendering it impractical in many applications. We argue that learning interactively from expert interventions enjoys the best of both worlds. Our key insight is that any amount of expert feedback, whether by intervention or non-intervention, provides information about the quality of the current state, the optimality of the action, or both. We formalize this as a constraint on the learner’s value function, which we can efficiently learn using no regret, online learning techniques. We call our approach Expert Intervention Learning (EIL), and evaluate it on a real and simulated driving task with a human expert, where it learns collision avoidance from scratch with just a few hundred samples (about one minute) of expert control.",
        "DOI": "10.15607/RSS.2020.XVI.055",
        "paper_author": "Spencer J.",
        "affiliation_name": "Princeton University",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States",
        "affiliation_id": "60003269",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Identification and Estimation of Causal Effects Defined by Shift Interventions",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Causal inference quantifies cause effect relationships by means of counterfactual responses had some variable been artificially set to a constant. A more refined notion of manipulation, where a variable is artificially set to a fixed function of its natural value is also of interest in particular domains. Examples include increases in financial aid, changes in drug dosing, and modifying length of stay in a hospital. We define counterfactual responses to manipulations of this type, which we call shift interventions. We show that in the presence of multiple variables being manipulated, two types of shift interventions are possible. Shift interventions on the treated (SITs) are defined with respect to natural values, and are connected to effects of treatment on the treated. Shift interventions as policies (SIPs) are defined recursively with respect to values of responses to prior shift interventions, and are connected to dynamic treatment regimes. We give sound and complete identification algorithms for both types of shift interventions, and derive efficient semi-parametric estimators for the mean response to a shift intervention in a special case motivated by a healthcare problem. Finally, we demonstrate the utility of our method by using an electronic health record dataset to estimate the effect of extending the length of stay in the intensive care unit (ICU) in a hospital by an extra day on patient ICU readmission probability.",
        "DOI": "NA",
        "paper_author": "Sani N.",
        "affiliation_name": "Whiting School of Engineering",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60145911",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Time-delayed pith angle control of wind turbine systems-based Smith ultralocal model machine learning technique",
        "publication": "Control Strategy for Time-Delay Systems: Part II: Engineering Applications",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The time-varying nonlinearity and uncertain nature of the wind turbine (WT) systems lead to changes of an operating point, which necessitates a powerful control methodology to regulate such complex systems. The challenges of regulation of WT systems have been intensified in the presence of time delay. In this research, the pitch angle regulation of a 2-mass WT model with time delay is addressed by the ultralocal model (ULM) control scheme, by means of Smith predictor (SP). In particular, to deal with the difficulties in adjusting the ULM coefficients, we adopt a deep deterministic policy gradient (DDPG) as the tuner mechanism of these coefficients. Firstly, we formulate the ULM scheme in a model-independent manner for the pitch angle control of WT to ameliorate the plant dynamic performance. Secondly, we incorporate the SP into the control structure to compensate for the effects of time delay in the WT plant. Thirdly, we employ the DDPG with the actor-critic framework for adaptive autotuning of the ULM controller coefficients. The analysis and tuning are of tutorial value for practitioners and engineers, and the usefulness and applicability are verified by a comparative simulation.",
        "DOI": "10.1016/B978-0-32-385347-7.00012-2",
        "paper_author": "Gheisarnejad M.",
        "affiliation_name": "Islamic Azad University, Najafabad Branch",
        "affiliation_city": "Najafabad",
        "affiliation_country": "Iran",
        "affiliation_id": "60026904",
        "affiliation_state": "Isfahan"
    },
    {
        "paper_title": "Yellow Fever in Brazil: Using Novel Data Sources to Produce Localized Policy Recommendations",
        "publication": "Leveraging Data Science for Global Health",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Background Yellow fever is a fatal acute viral hemorrhagic disease. This disease that is spread through the bite of the Aedes mosquito is endemic in Africa as well as the Americas, where the tropical climate helps in its transmission. Between January 2016 and March 2018, several territories of the Region of the Americas reported confirmed cases of yellow fever. In view of a global shortage of yellow fever vaccine, it is important to curb the transmission of yellow fever through improved vector surveillance and eliminating mosquito breeding sites. Prompt detection of outbreaks using novel data sources can help in launching immediate responses. Objective We discuss modelling disease propagation and case incidence using novel data sources, including Google Trends and Google Streetview. We also provide recommendations for how to contain and manage the outbreak. Methods We consider three main methods. First, we look at a traditional vector-borne disease propagation model. We also consider Google Trends data to judge how interest in the disease correlates with incidence. Finally, we propose methods for correlating Google Street View images with incidence to improve policy regarding distribution of vaccines. Results In terms of the Google Trends data, we found that we were able to match both peaks with just a basic model, including one week of lag time. Both the traditional vector-borne disease propagation model and the Google Streetview-based computer vision model require further analysis. Conclusion Here, we provide a starting point and guidelines for further improving upon existing disease propagation models and using deep learning methods to better predict where disease outbreaks may occur.",
        "DOI": "10.1007/978-3-030-47994-7_26",
        "paper_author": "De Silva S.",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60032499",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Proceedings - 2020 2nd International Conference on Applied Machine Learning, ICAML 2020",
        "publication": "Proceedings - 2020 2nd International Conference on Applied Machine Learning, ICAML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 86 papers. The topics discussed include: empirical analysis on financial deterioration forecast of listed companies based on cash flow perspective; research on parallel improvement of CVFDT algorithm based on spark; model design of artificial immune system in power cyber security protection; model design of artificial immune system in power cyber security protection; key technology of multifunctional wide area synchronous phasor measurement terminal device in distribution network; research on personal credit evaluation of commercial banks under ensemble learning framework; controller design of catastrophic course in process of airdropping heavy cargo; research on the impact of foreign exchange reserves on the effectiveness of China’s monetary policy from the perspective of Marxist economics; and research on the impact of foreign exchange reserves on the effectiveness of China’s monetary policy from the perspective of Marxist economics.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Aboveground Biomass Estimation In A Tropical Forest With Selective Logging Using Random Forest And Lidar Data",
        "publication": "Floresta",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "The tropical forest is characterized by expressive biomass and stores high amounts of carbon, which is an important variable for climate monitoring. Thus, studies aiming to analyze suitable methods to predict biomass are crucial, especially in the tropics, where dense vegetation makes modeling difficult. Thus, the objective of the present study was to estimate aboveground biomass (AGB) in a tropical forest area with selective logging in the Amazon forest using the Random Forest (RF) machine learning algorithm and LiDAR data. For this, 85 sample units were used at Fazenda Cauaxi, in the municipality of Paragominas, Pará State. LiDAR data were collected in 2014 and made available by the Sustainable Landscapes Project. The software R was used for data analysis. Among the LiDAR metrics, the average height was used as it had the greatest significance to compose the model. The model presented a pseudo R² of 0.69 (value obtained by the RF), Spearman's Correlation Coefficient of 0.80, RMSE of 47.05 Mg.ha-1 (19.84%), and Bias of 2.06 Mg.ha-1 (0.87%). With the results, it was possible to infer that the average height metric was enough to estimate AGB in a tropical forest with selective logging, in addition, the RF algorithm the biomass to be estimated, which can be used to assist in monitoring and action management in areas of selective logging and serve as a basis for climate change mitigation policies",
        "DOI": "10.5380/rf.v50i4.66589",
        "paper_author": "Marchesan J.",
        "affiliation_name": "Universidade Federal de Santa Maria",
        "affiliation_city": "Santa Maria",
        "affiliation_country": "Brazil",
        "affiliation_id": "60033356",
        "affiliation_state": "RS"
    },
    {
        "paper_title": "Data-driven control of water reservoirs using an emulator of the climate system",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "This study presents a novel approach to combine a data-driven control strategy with an emulator model of the climate system in order to make the optimal control of water systems more flexible and adaptive to the increasing frequency and intensity of extreme events. These latter are often associated with global climate anomalies, which are difficult to model and incorporate into optimal control algorithms. In this paper, we compare a traditional control policy conditioned only on the reservoir storage with an informed controller that enlarges the state space to include the emulated dynamics of global Sea Surface Temperature anomalies. The multi-purpose operations of Lake Como in Italy, accounting for flood control and water supply, is used as a case study. Numerical results show that the proposed approach provides a 59% improvement in system performance with respect to traditional solutions. This gain further increases during extreme drought episodes, which are influenced by global climate oscillations.",
        "DOI": "10.1016/j.ifacol.2020.12.771",
        "paper_author": "Giuliani M.",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60023256",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Characterization of Overlap in Observational Studies",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "Overlap between treatment groups is required for non-parametric estimation of causal effects. If a subgroup of subjects always receives the same intervention, we cannot estimate the effect of intervention changes on that subgroup without further assumptions. When overlap does not hold globally, characterizing local regions of overlap can inform the relevance of causal conclusions for new subjects, and can help guide additional data collection. To have impact, these descriptions must be interpretable for downstream users who are not machine learning experts, such as policy makers. We formalize overlap estimation as a problem of finding minimum volume sets subject to coverage constraints and reduce this problem to binary classification with Boolean rule classifiers. We then generalize this method to estimate overlap in off-policy policy evaluation. In several real-world applications, we demonstrate that these rules have comparable accuracy to black-box estimators and provide intuitive and informative explanations that can inform policy making.",
        "DOI": "NA",
        "paper_author": "Oberst M.",
        "affiliation_name": "MIT Computer Science &amp; Artificial Intelligence Laboratory",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60006320",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Machine Translation System Selection from Bandit Feedback",
        "publication": "AMTA 2020 - 14th Conference of the Association for Machine Translation in the Americas, Proceedings",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Adapting machine translation systems in the real world is a difficult problem. In contrast to offline training, users cannot provide the type of fine-grained feedback (such as correct translations) typically used for improving the system. Moreover, different users have different translation needs, and even a single user’s needs may change over time. In this work we take a different approach, treating the problem of adaptation as one of selection. Instead of adapting a single system, we train many translation systems using different architectures, datasets, and optimization methods. Using bandit learning techniques on simulated user feedback, we learn a policy to choose which system to use for a particular translation task. We show that our approach can (1) quickly adapt to address domain changes in translation tasks, (2) outperform the single best system in mixed-domain translation tasks, and (3) make effective instance-specific decisions when using contextual bandit strategies.",
        "DOI": "NA",
        "paper_author": "Naradowsky J.",
        "affiliation_name": "Preferred Networks, Inc.",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60120917",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "ML-adjoint: Learn the adjoint source directly for full-waveform inversion using machine learning",
        "publication": "SEG Technical Program Expanded Abstracts",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The adjoint source is an integral component of the waveform inversion optimization problems. The adjoint source is often derived from the objective function, and fixed regardless of the data. Thus, to utilize data in formulating the adjoint source, we propose to learn the adjoint source in FWI directly. We introduce the new method, we refer to as ML-adjoint, in the framework of Markov decision process (MDP). In MDP, a policy network takes input given by the predicted and measured data and outputs the adjoint source for back propagation in FWI. To achieve fast convergence in training, we specially design the neural network architecture to mimic the computation of the data residual and Jacobian matrix in constructing the adjoint source. The Marmousi model example demonstrates the robustness of the ML-adjoint in converging to an accurate model.",
        "DOI": "10.1190/segam2020-3420587.1",
        "paper_author": "Sun B.",
        "affiliation_name": "King Abdullah University of Science and Technology",
        "affiliation_city": "Thuwal",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60092945",
        "affiliation_state": "Makkah"
    },
    {
        "paper_title": "Data Intensive Industrial Asset Management: IoT-based Algorithms and Implementation",
        "publication": "Data Intensive Industrial Asset Management: IoT-based Algorithms and Implementation",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "This book presents a step by step Asset Health Management Optimization Approach Using Internet of Things (IoT). The authors provide a comprehensive study which includes the descriptive, diagnostic, predictive, and prescriptive analysis in detail. The presentation focuses on the challenges of the parameter selection, statistical data analysis, predictive algorithms, big data storage and selection, data pattern recognition, machine learning techniques, asset failure distribution estimation, reliability and availability enhancement, condition based maintenance policy, failure detection, data driven optimization algorithm, and a multi-objective optimization approach, all of which can significantly enhance the reliability and availability of the system.This book presents a step by step Asset Health Management Optimization Approach Using Internet of Things (IoT). The authors provide a comprehensive study which includes the descriptive, diagnostic, predictive, and prescriptive analysis in detail. The presentation focuses on the challenges of the parameter selection, statistical data analysis, predictive algorithms, big data storage and selection, data pattern recognition, machine learning techniques, asset failure distribution estimation, reliability and availability enhancement, condition based maintenance policy, failure detection, data driven optimization algorithm, and a multi-objective optimization approach, all of which can significantly enhance the reliability and availability of the system.",
        "DOI": "10.1007/978-3-030-35930-0",
        "paper_author": "Balali F.",
        "affiliation_name": "University of Wisconsin-Milwaukee",
        "affiliation_city": "Milwaukee",
        "affiliation_country": "United States",
        "affiliation_id": "60019909",
        "affiliation_state": "WI"
    },
    {
        "paper_title": "Leveraging multimodal behavioral analytics for automated job interview performance assessment and feedback",
        "publication": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Behavioral cues play a significant part in human communication and cognitive perception. In most professional domains, employee recruitment policies are framed such that both professional skills and personality traits are adequately assessed. Hiring interviews are structured to evaluate expansively a potential employee’s suitability for the position - their professional qualifications, interpersonal skills, ability to perform in critical and stressful situations, in the presence of time and resource constraints, etc. Therefore, candidates need to be aware of their positive and negative attributes and be mindful of behavioral cues that might have adverse effects on their success. We propose a multimodal analytical framework that analyzes the candidate in an interview scenario and provides feedback for predefined labels such as engagement, speaking rate, eye contact, etc. We perform a comprehensive analysis that includes the interviewee’s facial expressions, speech, and prosodic information, using the video, audio, and text transcripts obtained from the recorded interview. We use these multimodal data sources to construct a composite representation, which is used for training machine learning classifiers to predict the class labels. Such analysis is then used to provide constructive feedback to the interviewee for their behavioral cues and body language. Experimental validation showed that the proposed methodology achieved promising results.",
        "DOI": "NA",
        "paper_author": "Agrawal A.",
        "affiliation_name": "National Institute of Technology Karnataka",
        "affiliation_city": "Mangalore",
        "affiliation_country": "India",
        "affiliation_id": "60004954",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "ERS international congress, madrid, 2019: Highlights from the epidemiology and environment assembly",
        "publication": "ERJ Open Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "At the European Respiratory Society’s International Congress of 2019, which was held in Madrid, Spain, there were several sessions with exciting poster and oral presentations within the fields of epidemiology and tobacco control. This article is the summary of two of these sessions. One was on the use of Big Data in epidemiology and the other, on the global burden of respiratory disease and tobacco.",
        "DOI": "10.1183/23120541.00320-2019",
        "paper_author": "Jankowski M.",
        "affiliation_name": "Slaski Uniwersytet Medyczny w Katowicach",
        "affiliation_city": "Katowice",
        "affiliation_country": "Poland",
        "affiliation_id": "60027573",
        "affiliation_state": "SL"
    },
    {
        "paper_title": "A reduced-order approach to assist with reinforcement learning for underactuated robotics",
        "publication": "Australasian Conference on Robotics and Automation, ACRA",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Underactuated robot designs are enticing due to their electromechanical simplicity; but, their operation is complex especially for compliant designs that may not have an explicit model. Deep reinforcement learning methods together with multi-joint dynamic simulation may help overcome this control bottleneck. However, such systems tend to have large continuous action spaces and exhibit sparse rewards, thus making control policy exploration variable and non-trivial. Using the observations: (1) that an underactuated system has coupled states, and (2) that a deep function approximator may generalize across compressed (and potentially nonintuitive) states, we consider a reduced order approach based around a generative autoencoder so as to automatically find a better representation to focus a control policy exploration process. To help evaluate this approach, we also introduce The Jitterbug Problem, which is a series of increasingly specific and challenging motion control tasks for a highly compliant legged toy robot with just a single motor locomoting across a field. We benchmarked this problem against off-policy and on-policy deep reinforcement learning algorithms and find that an off-policy approach had better median rewards, but has higher variability. Through this study we find that reducing the model by taking advantage of the latent structure may exhibit similar (reward) performance, yet empirically has less training variance and slightly better learning rates.",
        "DOI": "NA",
        "paper_author": "Augot J.",
        "affiliation_name": "CentraleSupélec - Paris-Saclay",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France",
        "affiliation_id": "60122384",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Long short-term memory network for future-state prediction in water injection pump",
        "publication": "30th European Safety and Reliability Conference, ESREL 2020 and 15th Probabilistic Safety Assessment and Management Conference, PSAM 2020",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Water injection into an oil well increases pressure in the reservoir, preventing its rapid decline in oil recovery. Failure of the injection pump can compromise oil production for as long as it is stopped. Therefore, anticipating failures in advance and adopting predictive maintenance policies will make their availability higher than current values. One approach to do this is by Condition-Based Maintenance (CBM), in which assets are continuously monitored to determine their health state. The obtained data is analyzed to identify and predict failures. Maintenance planning is done according to these results. In recent years, Machine Learning (ML) and Deep Learning (DL) techniques have been used in the context of CBM, since they can deal with large amounts of data. They have the ability to identify complex patterns in the data that provide relevant information regarding the state of the equipment. Amongst DL algorithms, Long Short-Term Memory Networks (LSTM) stand out for being used to deal with time dependencies within the data. This paper presents a model for predicting the operating state of a water injection pump using LSTM. When predicting failures within one day, all performance metrics (precision, recall and F1- score) reach values above 92.0%. Model is compared with an Artificial Neural Network (ANN). Future works include doing remaining useful life (RUL) predictions.",
        "DOI": "NA",
        "paper_author": "Barraza J.F.",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil",
        "affiliation_id": "60008088",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "Amortized Bayesian Optimization over Discrete Spaces",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "13",
        "cover_date": "2020-01-01",
        "Abstract": "Bayesian optimization is a principled approach for globally optimizing expensive, black-box functions by using a surrogate model of the objective. However, each step of Bayesian optimization involves solving an inner optimization problem, in which we maximize an acquisition function derived from the surrogate model to decide where to query next. This inner problem can be challenging to solve, particularly in discrete spaces, such as protein sequences or molecular graphs, where gradient-based optimization cannot be used. Our key insight is that we can train a parameterized policy to generate candidates that maximize the acquisition function. This is faster than standard parameter-free search methods, since we can amortize the cost of learning the policy across rounds of Bayesian optimization. We therefore call this Amortized Bayesian Optimization. On several challenging discrete design problems, we show this method generally outperforms other methods at optimizing the inner acquisition function, resulting in more efficient optimization of the outer black-box objective.",
        "DOI": "NA",
        "paper_author": "Rubanova Y.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Discrete-Event Simulation-Based Q-Learning Algorithm Applied to Financial Leverage Effect",
        "publication": "SN Computer Science",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Discrete-event modeling and simulation and machine learning are two frameworks suited for system of systems modeling which when combined can give a powerful tool for system optimization and decision making. One of the less explored application domains is finance, where this combination can propose a driven tool to investor. This paper presents a discrete-event specification as a universal framework to implement a machine learning algorithm into a modular and hierarchical environment. This approach has been validated on a financial leverage effect based on a Markov decision-making policy.",
        "DOI": "10.1007/s42979-019-0051-7",
        "paper_author": "Barbieri E.",
        "affiliation_name": "Universita di Corsica Pascal Paoli",
        "affiliation_city": "Corte",
        "affiliation_country": "France",
        "affiliation_id": "60031206",
        "affiliation_state": "Corsica"
    },
    {
        "paper_title": "Adversarial grammatical error correction",
        "publication": "Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Recent works in Grammatical Error Correction (GEC) have leveraged the progress in Neural Machine Translation (NMT), to learn rewrites from parallel corpora of grammatically incorrect and corrected sentences, achieving state-of-the-art results. At the same time, Generative Adversarial Networks (GANs) have been successful in generating realistic texts across many different tasks by learning to directly minimize the difference between human-generated and synthetic text. In this work, we present an adversarial learning approach to GEC, using the generator-discriminator framework. The generator is a Transformer model, trained to produce grammatically correct sentences given grammatically incorrect ones. The discriminator is a sentence-pair classification model, trained to judge a given pair of grammatically incorrect-correct sentences on the quality of grammatical correction. We pre-train both the discriminator and the generator on parallel texts and then fine-tune them further using a policy gradient method that assigns high rewards to sentences which could be true corrections of the grammatically incorrect text. Experimental results on FCE, CoNLL-14, and BEA-19 datasets show that Adversarial-GEC can achieve competitive GEC quality compared to NMT-based baselines.",
        "DOI": "10.18653/v1/2020.findings-emnlp.275",
        "paper_author": "Raheja V.",
        "affiliation_name": "Grammarly",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "131781317",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Interpretable sequence learning for COVID-19 forecasting",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "42",
        "cover_date": "2020-01-01",
        "Abstract": "We propose a novel approach that integrates machine learning into compartmental disease modeling (e.g., SEIR) to predict the progression of COVID-19. Our model is explainable by design as it explicitly shows how different compartments evolve and it uses interpretable encoders to incorporate covariates and improve performance. Explainability is valuable to ensure that the model’s forecasts are credible to epidemiologists and to instill confidence in end-users such as policy makers and healthcare institutions. Our model can be applied at different geographic resolutions, and we demonstrate it for states and counties in the United States. We show that our model provides more accurate forecasts compared to the alternatives, and that it provides qualitatively meaningful explanatory insights.",
        "DOI": "NA",
        "paper_author": "Arik S.",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States",
        "affiliation_id": "60006191",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "AutoPrivacy: Automated layer-wise parameter selection for secure neural network inference",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "Hybrid Privacy-Preserving Neural Network (HPPNN) implementing linear layers by Homomorphic Encryption (HE) and nonlinear layers by Garbled Circuit (GC) is one of the most promising secure solutions to emerging Machine Learning as a Service (MLaaS). Unfortunately, a HPPNN suffers from long inference latency, e.g., ~ 100 seconds per image, which makes MLaaS unsatisfactory. Because HE-based linear layers of a HPPNN cost 93% inference latency, it is critical to select a set of HE parameters to minimize computational overhead of linear layers. Prior HPPNNs over-pessimistically select huge HE parameters to maintain large noise budgets, since they use the same set of HE parameters for an entire network and ignore the error tolerance capability of a network. In this paper, for fast and accurate secure neural network inference, we propose an automated layer-wise parameter selector, AutoPrivacy, that leverages deep reinforcement learning to automatically determine a set of HE parameters for each linear layer in a HPPNN. The learning-based HE parameter selection policy outperforms conventional rule-based HE parameter selection policy. Compared to prior HPPNNs, AutoPrivacy-optimized HPPNNs reduce inference latency by 53% ~ 70% with negligible loss of accuracy.",
        "DOI": "NA",
        "paper_author": "Lou Q.",
        "affiliation_name": "Indiana University Bloomington",
        "affiliation_city": "Bloomington",
        "affiliation_country": "United States",
        "affiliation_id": "60021121",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Learning to summarize from human feedback",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "653",
        "cover_date": "2020-01-01",
        "Abstract": "As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task. For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about—summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences. We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts [63] and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN/DM news articles [22], producing summaries nearly as good as the human reference without any news-specific fine-tuning.2 We conduct extensive analyses to understand our human feedback dataset and fine-tuned models.3 We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans. We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.",
        "DOI": "NA",
        "paper_author": "Stiennon N.",
        "affiliation_name": "OpenAI",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "126456906",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep active inference agents using Monte-Carlo methods",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "36",
        "cover_date": "2020-01-01",
        "Abstract": "Active inference is a Bayesian framework for understanding biological intelligence. The underlying theory brings together perception and action under one single imperative: minimizing free energy. However, despite its theoretical utility in explaining intelligence, computational implementations have been restricted to low-dimensional and idealized situations. In this paper, we present a neural architecture for building deep active inference agents operating in complex, continuous state-spaces using multiple forms of Monte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel to active inference. These include: i) selecting free-energy-optimal policies via MC tree search, ii) approximating this optimal policy distribution via a feed-forward ‘habitual’ network, iii) predicting future parameter belief updates using MC dropouts and, finally, iv) optimizing state transition precision (a high-end form of attention). Our approach enables agents to learn environmental dynamics efficiently, while maintaining task performance, in relation to reward-based counterparts. We illustrate this in a new toy environment, based on the dSprites data-set, and demonstrate that active inference agents automatically create disentangled representations that are apt for modeling state transitions. In a more complex Animal-AI environment, our agents (using the same neural architecture) are able to simulate future state transitions and actions (i.e., plan), to evince reward-directed navigation - despite temporary suspension of visual input. These results show that deep active inference – equipped with MC methods – provides a flexible framework to develop biologically-inspired intelligent agents, with applications in both machine learning and cognitive science.",
        "DOI": "NA",
        "paper_author": "Fountas Z.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Instance-based generalization in reinforcement learning",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Agents trained via deep reinforcement learning (RL) routinely fail to generalize to unseen environments, even when these share the same underlying dynamics as the training levels. Understanding the generalization properties of RL is one of the challenges of modern machine learning. Towards this goal, we analyze policy learning in the context of Partially Observable Markov Decision Processes (POMDPs) and formalize the dynamics of training levels as instances. We prove that, independently of the exploration strategy, reusing instances introduces significant changes on the effective Markov dynamics the agent observes during training. Maximizing expected rewards impacts the learned belief state of the agent by inducing undesired instance-specific speed-running policies instead of generaliz-able ones, which are sub-optimal on the training set. We provide generalization bounds to the value gap in train and test environments based on the number of training instances, and use insights based on these to improve performance on unseen levels. We propose training a shared belief representation over an ensemble of specialized policies, from which we compute a consensus policy that is used for data collection, disallowing instance-specific exploitation. We experimentally validate our theory, observations, and the proposed computational solution over the CoinRun benchmark.",
        "DOI": "NA",
        "paper_author": "Bertran M.",
        "affiliation_name": "Pratt School of Engineering",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60140102",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Language as a cognitive tool to imagine goals in curiosity-driven exploration",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "43",
        "cover_date": "2020-01-01",
        "Abstract": "Developmental machine learning studies how artificial agents can model the way children learn open-ended repertoires of skills. Such agents need to create and represent goals, select which ones to pursue and learn to achieve them. Recent approaches have considered goal spaces that were either fixed and hand-defined or learned using generative models of states. This limited agents to sample goals within the distribution of known effects. We argue that the ability to imagine out-of-distribution goals is key to enable creative discoveries and open-ended learning. Children do so by leveraging the compositionality of language as a tool to imagine descriptions of outcomes they never experienced before, targeting them as goals during play. We introduce IMAGINE, an intrinsically motivated deep reinforcement learning architecture that models this ability. Such imaginative agents, like children, benefit from the guidance of a social peer who provides language descriptions. To take advantage of goal imagination, agents must be able to leverage these descriptions to interpret their imagined out-of-distribution goals. This generalization is made possible by modularity: a decomposition between learned goal-achievement reward function and policy relying on deep sets, gated attention and object-centered representations. We introduce the Playground environment and study how this form of goal imagination improves generalization and exploration over agents lacking this capacity. In addition, we identify the properties of goal imagination that enable these results and study the impacts of modularity and social interactions.",
        "DOI": "NA",
        "paper_author": "Colas C.",
        "affiliation_name": "Université de Bordeaux",
        "affiliation_city": "Bordeaux",
        "affiliation_country": "France",
        "affiliation_id": "60102125",
        "affiliation_state": "Nouvelle-Aquitaine"
    },
    {
        "paper_title": "A Noisy-sample-removed Under-sampling Scheme for Imbalanced Classification of Public Datasets",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Classification technology plays an important role in machine learning. In the process of classification, the presence of noisy samples in datasets tends to reduce the performance of a classifier. This work proposes a clustering-based Noisy-sample-Removed Under-sampling Scheme (NUS) for imbalanced classification. First, the samples in the minority class are clustered. For each cluster, its center is taken as a spherical center, and the distance of the minority class samples farthest from the cluster center is taken as the radius to form a hypersphere. The Euclidean distance from the center of the cluster to every of the majority samples is calculated to decide if they are in the hypersphere. Then, we propose a NUS-based policy to decide if a majority sample in the hypersphere is a noisy sample. Similarly, the noises samples of the minority class are found. Second, We remove noisy-samples from the majority and minority classes and propose NUS. Finally, logistics regression, Decision Tree, and Random Forest are used in NUS as the base classifiers, respectively and compare with Random Under-Sampling (RUS), EasyEnsemble (EE), and Inverse Random Under-Sampling (IRUS) on 13 public datasets. Results show that our method can improve the classification performance in comparison with its state-of-the art peers.",
        "DOI": "10.1016/j.ifacol.2021.04.202",
        "paper_author": "Zhu H.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An online evolving framework for advancing reinforcement-learning based automated vehicle control",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, an online evolving framework is proposed to detect and revise a controller's imperfect decision-making in advance. The framework consists of three modules: the evolving Finite State Machine (e-FSM), action-reviser, and controller modules. The e-FSM module evolves a stochastic model (e.g., Discrete-Time Markov Chain) from scratch by determining new states and identifying transition probabilities repeatedly. With the latest stochastic model and given criteria, the action-reviser module checks validity of the controller's chosen action by predicting future states. Then, if the chosen action is not appropriate, another action is inspected and selected. In order to show the advantage of the proposed framework, the Deep Deterministic Policy Gradient (DDPG) w/ and w/o the online evolving framework are applied to control an ego-vehicle in the car-following scenario where control criteria are set by speed and safety. Experimental results show that inappropriate actions chosen by the DDPG controller are detected and revised appropriately through our proposed framework, resulting in no control failures after a few iterations.",
        "DOI": "10.1016/j.ifacol.2020.12.2283",
        "paper_author": "Han T.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Columbus",
        "affiliation_country": "United States",
        "affiliation_id": "60149838",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Identify the contribution of elevated industrial plume to ground air quality by optical and machine learning methods",
        "publication": "Environmental Research Communications",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Regional severe haze caused by atmospheric particle explosion is one of the biggest environmental problems in China that has yet to be fully understood. This research managed to find the linkage between diversified shapes of heavy industrial stack plume (HISP) and local ground particle concentration. We used two optical methods: LIDAR and auto-shoot camera, to catch the HISP’s vertical shape, and two machine leaning models: binary classification and decision tree, to find the quantitative relationship between the HISP’s shape and PM2.5 concentration. The PM2.5 concentration correlated to the polygon length (PL) of HISP’s shape with a logistic function. With a plume length more than twice the height of stack, the spread of HISP’s shape accompanied with PM2.5 concentration decreasing to <100 μgm−3. The residence time of HISP’s particles was longer (>20 h) under uniform offshore dispersion than that in heterogeneous wind field, when the footprint of HISP was estimated to be >7 km. We acquired a decision tree model to yield an exact prediction of PM2.5 concentration, in which the HISP’s length played a statistically significant role. Though the plume shape is just one of the easy-to-use indicators of complex meteorological condition, it is still practical for policy makers to identify the particle pollution caused by the elevated sources in the fastest way.",
        "DOI": "10.1088/2515-7620/ab7634",
        "paper_author": "Feng L.",
        "affiliation_name": "Institute of Atmospheric Physics Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016211",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Agent-based modeling and reinforcement learning for optimizing energy systems operation and maintenance: the pathmind solution",
        "publication": "Proceedings of the 30th European Safety and Reliability Conference and the 15th Probabilistic Safety Assessment and Management Conference",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "The optimization of the Operation and Maintenance (O&M) of energy systems equipped with Prognostics and Health Management (PHM) capabilities can be framed as a sequential decision process, which can be addressed by Reinforcement Learning (RL). However, using RL algorithms requires specific skills, whereas the understanding of the possibly counter-intuitive solutions proposed by RL is not straifhtforward. To sidestep both issues, we use Pathmind, a software tool which enables effectively exploiting the RL capabilities without deep knowledge of machine learning. Pathmind is encoded in the Anylogic environment, which is an Agent-Based simulation software that simplifies the system modeling and allows easily visualizing the effects of the optimized policy. A scaled-down wind farm case study is used to demonstrate the potential of RL in identifying an optimal O&M policy and to show the ease of use of Pathmind and AnyLogic.",
        "DOI": "10.3850/978-981-14-8593-0_5863-cd",
        "paper_author": "Pinciroli L.",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60023256",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Long short-term memory network for future-state prediction in water injection pump",
        "publication": "Proceedings of the 30th European Safety and Reliability Conference and the 15th Probabilistic Safety Assessment and Management Conference",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Water injection into an oil well increases pressure in the reservoir, preventing its rapid decline in oil recovery. Failure of the injection pump can compromise oil production for as long as it is stopped. Therefore, anticipating failures in advance and adopting predictive maintenance policies will make their availability higher than current values. One approach to do this is by Condition-Based Maintenance (CBM), in which assets are continuously monitored to determine their health state. The obtained data is analyzed to identify and predict failures. Maintenance planning is done according to these results. In recent years, Machine Learning (ML) and Deep Learning (DL) techniques have been used in the context of CBM, since they can deal with large amounts of data. They have the ability to identify complex patterns in the data that provide relevant information regarding the state of the equipment. Amongst DL algorithms, Long Short-Term Memory Networks (LSTM) stand out for being used to deal with time dependencies within the data. This paper presents a model for predicting the operating state of a water inject ion pump using LSTM. When predicting failures within one day, all performance metrics (precision, recall and F1-score) reach values above 92.0%. Model is compared with an Artificial Neural Network (ANN). Future works include doing remaining useful life (RUL) predictions.",
        "DOI": "10.3850/978-981-14-8593-0_3831-cd",
        "paper_author": "Barraza J.F.",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil",
        "affiliation_id": "60008088",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "Identification of slum settlements using logistic regression",
        "publication": "ACRS 2020 - 41st Asian Conference on Remote Sensing",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Identifying slum settlements in urban areas is a very important step in the process of the formulation of environment-friendly government policies. There are several methods, which can be used for the identification and delineation of slum areas. Field surveys are time-consuming as well as costlier for this purpose. Whereas remote sensing with the integration of image processing techniques provides an easy, efficient, and quick demarcation of the slum settlements. The presented study highlights a machine learning (ML) logistic-regression based method for the identification of the slums (informal settlements) using remote sensing datasets in Agra city, Uttar Pradesh, India. Agra being a tourist hotspot with the presence of the Taj Mahal needs proper planning for the urban development and improvement or relocation of slum dwellers by way of better future opportunities along with good living conditions. The method utilizes the spectral, textural, and spatial features, which are extracted from openly accessible high-resolution imagery from google earth. The algorithm delivers the confusion matrix performance score of 0.74.",
        "DOI": "NA",
        "paper_author": "Upadhyay V.",
        "affiliation_name": "Banasthali Vidyapith",
        "affiliation_city": "Vanasthali",
        "affiliation_country": "India",
        "affiliation_id": "60028153",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Comparative analysis between the k-means and fuzzy c-means algorithms to detect UDP flood DDoS attack on a SDN/NFV environment",
        "publication": "WEBIST 2020 - Proceedings of the 16th International Conference on Web Information Systems and Technologies",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Distributed Denial of Service (DDoS) attacks are a growing issue for computer networks security and have become a serious network security problem. Environments based on Software Defined Networking (SDN) and Network Function Virtualization (NFV) offers the ability to program a network and allows dynamic creation of flow policies. Allied to that, clustering algorithms can be used to classify and detect DDoS. This paper presents a study and an analysis of two unsupervised machine learning algorithms used to detect DDoS attacks in an SDN/NFV simulated environment. The results obtained by the two algorithms include an accuracy rate of 99% and the k-means algorithm was 33% faster than fuzzy c-means, which demonstrates its effectiveness and scalability.",
        "DOI": "NA",
        "paper_author": "de Almeida Neto J.R.",
        "affiliation_name": "Université Fédérale de Sergipe",
        "affiliation_city": "Sao Cristovao",
        "affiliation_country": "Brazil",
        "affiliation_id": "60003079",
        "affiliation_state": "SE"
    },
    {
        "paper_title": "Persistent Surveillance of Events with Unknown Rate Statistics",
        "publication": "Springer Proceedings in Advanced Robotics",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "We present a novel algorithm for persistent monitoring of stochastic events that occur at discrete locations in the environment with unknown event rates. Prior research on persistent monitoring assumes knowledge of event rates, which is often not the case in robotics applications. We consider the multi-objective optimization of maximizing the total number of events observed in a balanced manner subject to real-world autonomous system constraints. We formulate an algorithm that quantifies and leverages uncertainty over events’ statistics to greedily generate adaptive policies that simultaneously consider learning and monitoring objectives. We analyze the favorable properties of our algorithm as a function of monitoring cycles and provide simulation results demonstrating our method’s effectiveness in real-world inspired monitoring applications.",
        "DOI": "10.1007/978-3-030-43089-4_47",
        "paper_author": "Baykal C.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Interactive Learning with Corrective Feedback for Policies Based on Deep Neural Networks",
        "publication": "Springer Proceedings in Advanced Robotics",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Deep Reinforcement Learning (DRL) has become a powerful strategy to solve complex decision making problems based on Deep Neural Networks (DNNs). However, it is highly data demanding, so unfeasible in physical systems for most applications. In this work, we approach an alternative Interactive Machine Learning (IML) strategy for training DNN policies based on human corrective feedback, with a method called Deep COACH (D-COACH). This approach not only takes advantage of the knowledge and insights of human teachers as well as the power of DNNs, but also has no need of a reward function (which sometimes implies the need of external perception for computing rewards). We combine Deep Learning with the COrrective Advice Communicated by Humans (COACH) framework, in which non-expert humans shape policies by correcting the agent’s actions during execution. The D-COACH framework has the potential to solve complex problems without much data or time required. Experimental results validated the efficiency of the framework in three different problems (two simulated, one with a real robot), with state spaces of low and high dimensions, showing the capacity to successfully learn policies for continuous action spaces like in the Car Racing and Cart-Pole problems faster than with DRL.",
        "DOI": "10.1007/978-3-030-33950-0_31",
        "paper_author": "Pérez-Dattari R.",
        "affiliation_name": "Universidad de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile",
        "affiliation_id": "60012464",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Operation and Imitation Under Safety-Aware Shared Control",
        "publication": "Springer Proceedings in Advanced Robotics",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "We describe a shared control methodology that can, without knowledge of the task, be used to improve a human’s control of a dynamic system, be used as a training mechanism, and be used in conjunction with Imitation Learning to generate autonomous policies that recreate novel behaviors. Our algorithm introduces autonomy that assists the human partner by enforcing safety and stability constraints. The autonomous agent has no a priori knowledge of the desired task and therefore only adds control information when there is concern for the safety of the system. We evaluate the efficacy of our approach with a human subjects study consisting of 20 participants. We find that our shared control algorithm significantly improves the rate at which users are able to successfully execute novel behaviors. Experimental results suggest that the benefits of our safety-aware shared control algorithm also extend to the human partner’s understanding of the system and their control skill. Finally, we demonstrate how a combination of our safety-aware shared control algorithm and Imitation Learning can be used to autonomously recreate the demonstrated behaviors.",
        "DOI": "10.1007/978-3-030-44051-0_52",
        "paper_author": "Broad A.",
        "affiliation_name": "Northwestern University",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States",
        "affiliation_id": "60007363",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "A Dynamic Regret Analysis and Adaptive Regularization Algorithm for On-Policy Robot Imitation Learning",
        "publication": "Springer Proceedings in Advanced Robotics",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "On-policy imitation learning algorithms such as Dagger evolve a robot control policy by executing it, measuring performance (loss), obtaining corrective feedback from a supervisor, and generating the next policy. As the loss between iterations can vary unpredictably, a fundamental question is under what conditions this process will eventually achieve a converged policy. If one assumes the underlying trajectory distribution is static (stationary), it is possible to prove convergence for Dagger. Cheng and Boots (2018) consider the more realistic model for robotics where the underlying trajectory distribution, which is a function of the policy, is dynamic and show that it is possible to prove convergence when a condition on the rate of change of the trajectory distributions is satisfied. In this paper, we reframe that result using dynamic regret theory from the field of Online Optimization to prove convergence to locally optimal policies for Dagger, Imitation Gradient, and Multiple Imitation Gradient. These results inspire a new algorithm, Adaptive On-Policy Regularization (AOR), that ensures the conditions for convergence. We present simulation results with cart-pole balancing and walker locomotion benchmarks that suggest AOR can significantly decrease dynamic regret and chattering. To our knowledge, this the first application of dynamic regret theory to imitation learning.",
        "DOI": "10.1007/978-3-030-44051-0_13",
        "paper_author": "Lee J.N.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "DART: Diversity-Enhanced Autonomy in Robot Teams",
        "publication": "Springer Proceedings in Advanced Robotics",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "This paper defines the research area of Diversity-enhanced Autonomy in Robot Teams (DART), a novel paradigm for the creation and design of policies for multi-robot coordination. While current approaches to multi-robot coordination have been successful in structured, well understood environments, they have not been successful in unstructured, uncertain environments, such as disaster response. The reason for this is not due to limitations in robot hardware, which has advanced significantly in the past decade, but in how multi-robot problems are solved. Even with significant advances in the field of multi-robot systems, the same problem-solving paradigm has remained: assumptions are made to simplify the problem, and a solution is optimized for those assumptions and deployed to the entire team. This results in brittle solutions that prove incapable if the original assumptions are invalidated. This paper introduces a new multi-robot problem-solving paradigm which relies on a diverse set of control policies that work together synergistically to make multi-robot systems more resilient in unstructured and uncertain environments.",
        "DOI": "10.1007/978-3-030-28619-4_2",
        "paper_author": "Ayanian N.",
        "affiliation_name": "University of Southern California",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60029311",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Rapid covid-19 prognostic blood test for disease severity using epigenetic immune system biomarkers",
        "publication": "Delaware Journal of Public Health",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Objective. To develop a novel whole-blood epigenetic biomarker of immune system status, or EpiMarker, that would indicate whether a person with a recent COVID-19 diagnosis is at risk for severe symptoms including Acute Respiratory Distress Syndrome. Methods. Using a novel methyl-sensitive restriction endonuclease approach to measure site-specific DNA methylation profiles, immune system phentoype EpiMarkers are identified using a machine-learning computational bioinformatics platform. The result is a diagnostic network of 20 to 40 immuno DNA methylation sites having the greatest predictive power for identifying patients whose COVID-19 disease will likely progress to ARDS requiring ICU/intubation care. Results. Immune system status in peripheral whole blood provides a sensitive and responsive sentinel signal reflecting how different functional pathways are currently being regulated in a subject. Deciphering this signal status of how immune cells are set to respond provides deep functional information regarding patient health and potential disease phenotypes resulting from a cytokine storm characteristic of a hyper immune inflammatory response to COVID-19 infection. Conclusions. The ability to identify future potential changes in patient health using this novel EpiMarker technology opens new avenues for defending populations from severe disease risks of Acute Respiratory Distress Syndrome. Policy Implications. A successful EpiMarker Assay for COVID-19 disease severity risk would allow for two important applications: (1) patients could be triaged early in the course of infection to allow for critical decisions for allocating resources, both in terms of hospital infrastructure (ICU beds, ventilators) and therapeutic drug treatments; and (2) pre-infection, individuals could be screened to identify personnel at low-risk for mission critical assignments (first responders, doctors, nurses, military personnel, etc.) during future pandemics and ongoing battles with viral pathogens like influenza.",
        "DOI": "NA",
        "paper_author": "Marsh A.G.",
        "affiliation_name": "University of Delaware",
        "affiliation_city": "Newark",
        "affiliation_country": "United States",
        "affiliation_id": "60023004",
        "affiliation_state": "DE"
    },
    {
        "paper_title": "Energy and policy considerations for modern deep learning research",
        "publication": "AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",
        "citied_by": "287",
        "cover_date": "2020-01-01",
        "Abstract": "The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community.",
        "DOI": "NA",
        "paper_author": "Strubell E.",
        "affiliation_name": "Facebook Research",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States",
        "affiliation_id": "60111190",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A study for estimation of high resolution temperature using satellite imagery and machine learning models during heat waves",
        "publication": "Korean Journal of Remote Sensing",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "This study investigates the feasibility of three algorithms, K-Nearest Neighbors (K-NN), Random Forest (RF) and Neural Network (NN), for estimating the air temperature of an unobserved area where the weather station is not installed. The satellite image were obtained from Landsat-8 and MODIS Aqua/Terra acquired in 2019, and the meteorological ground weather data were from AWS/ASOS data of Korea Meteorological Administration and Korea Forest Service. In addition, in order to improve the estimation accuracy, a digital surface model, solar radiation, aspect and slope were used. The accuracy assessment of machine learning methods was performed by calculating the statistics of R2 (determination coefficient) and Root Mean Square Error (RMSE) through 10-fold cross-validation and the estimated values were compared for each target area. As a result, the neural network algorithm showed the most stable result among the three algorithms with R2 = 0.805 and RMSE = 0.508. The neural network algorithm was applied to each data set on Landsat imagery scene. It was possible to generate an mean air temperature map from June to September 2019 and confirmed that detailed air temperature information could be estimated. The result is expected to be utilized for national disaster safety management such as heat wave response policies and heat island mitigation research.",
        "DOI": "10.7780/kjrs.2020.36.5.4.4",
        "paper_author": "Lee D.",
        "affiliation_name": "MOIS",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "126256118",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Understanding the curse of horizon in off-policy evaluation via conditional importance sampling",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "Off-policy policy estimators that use importance sampling (IS) can suffer from high variance in long-horizon domains, and there has been particular excitement over new IS methods that leverage the structure of Markov decision processes. We analyze the variance of the most popular approaches through the viewpoint of conditional Monte Carlo. Surprisingly, we find that in finite horizon MDPs there is no strict variance reduction of per-decision importance sampling or marginalized importance sampling, comparing with vanilla importance sampling. We then provide sufficient conditions under which the perdecision or marginalized estimators will provably reduce the variance over importance sampling with finite horizons. For the asymptotic (in terms of horizon T) case, we develop upper and lower bounds on the variance of those estimators which yields sufficient conditions under which there exists an exponential v.s. polynomial gap between the variance of importance sampling and that of the per-decision or stationary/marginalized estimators. These results help advance our understanding of if and when new types of IS estimators will improve the accuracy of off-policy estimation.",
        "DOI": "NA",
        "paper_author": "Liu Y.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Hierarchically decoupled imitation for morphological transfer",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Learning long-range behaviors on complex high-dimensional agents is a fundamental problem in robot learning. For such tasks, we argue that transferring learned information from a morphologically simpler agent can massively improve the sample efficiency of a more complex one. To this end, we propose a hierarchical decoupling of policies into two parts: an independently learned low-level policy and a transferable high-level policy. To remedy poor transfer performance due to mismatch in morphologies, we contribute two key ideas. First, we show that incentivizing a complex agent's low-level to imitate a simpler agent's low-level significantly improves zero-shot high-level transfer. Second, we show that KL-regularized training of the high level stabilizes learning and prevents modecollapse. Finally, on a suite of publicly released navigation and manipulation environments, we demonstrate the applicability of hierarchical transfer on long-range tasks across morphologies. Our code and videos can be found at https: //sites.google.com/berkeley.edu/ morphology-transfer.",
        "DOI": "NA",
        "paper_author": "Hejna D.J.",
        "affiliation_name": "Department of Electrical Engineering and Computer Sciences",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60121438",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Generating programmatic referring expressions via program synthesis",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Incorporating symbolic reasoning into machine learning algorithms is a promising approach to improve performance on learning tasks that require logical reasoning. We study the problem of generating a programmatic variant of referring expressions that we call referring relational programs. In particular, given a symbolic representation of an image and a target object in that image, the goal is to generate a relational program that uniquely identifies the target object in terms of its attributes and its relations to other objects in the image. We propose a neurosymbolic program synthesis algorithm that combines a policy neural network with enumerative search to generate such relational programs. The policy neural network employs a program interpreter that provides immediate feedback on the consequences of the decisions made by the policy, and also takes into account the uncertainty in the symbolic representation of the image. We evaluate our algorithm on challenging benchmarks based on the CLEVR dataset, and demonstrate that our approach significantly outperforms several baselines.",
        "DOI": "NA",
        "paper_author": "Huang J.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60006297",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Learning calibratable policies using programmatic style-consistency",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "We study the problem of controllable generation of long-Term sequential behaviors, where the goal is to calibrate to multiple behavior styles simultaneously. In contrast to the well-studied areas of controllable generation of images, text, and speech, there are two questions that pose significant challenges when generating long-Term behaviors: how should we specify the factors of variation to control, and how can we ensure that the generated behavior faithfully demonstrates combinatorially many styles? We leverage programmatic labeling functions to specify controllable styles, and derive a formal notion of styleconsistency as a learning objective, which can then be solved using conventional policy learning approaches. We evaluate our framework using demonstrations from professional basketball players and agents in the MuJoCo physics environment, and show that existing approaches that do not explicitly enforce style-consistency fail to generate diverse behaviors whereas our learned policies can be calibrated for up to 45(1024) distinct style combinations.",
        "DOI": "NA",
        "paper_author": "Zhan E.",
        "affiliation_name": "California Institute of Technology",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States",
        "affiliation_id": "60031581",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "When demands evolve larger and noisier: Learning and earning in a growing environment",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "We consider a single-product dynamic pricing problem under a specific non-stationary setting, where the underlying demand process grows over time in expectation and also possibly in the level of random fluctuation. The decision maker sequentially sets price in each time period and learns the unknown demand model, with the goal of maximizing expected cumulative revenue over a time horizon T. We prove matching upper and lower bounds on regret and provide near-optimal pricing policies. We show how the growth rate of random fluctuation over time affects the best achievable regret order and the near-optimal policy design. In the analysis, we show that whether the seller knows the length of time horizon T in advance or not surprisingly render different optimal regret orders. We then extend the demand model such that the optimal price may vary with time and present a novel and near-optimal policy for the extended model. Finally, we consider an analogous nonstationary setting in the canonical multi-Armed bandit problem, and points out that knowing or not knowing the length of time horizon T render the same optimal regret order, in contrast to the non-stationary dynamic pricing problem.",
        "DOI": "NA",
        "paper_author": "Zhu F.",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60014966",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Gradient-free online learning in games with delayed rewards",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "Motivated by applications to online advertising and recommender systems, we consider a gametheoretic model with delayed rewards and asynchronous, payoff-based feedback. In contrast to previous work on delayed multi-armed bandits, we focus on multi-player games with continuous action spaces, and we examine the long-run behavior of strategic agents that follow a no-regret learning policy (but are otherwise oblivious to the game being played, the objectives of their opponents, etc.). To account for the lack of a consistent stream of information (for instance, rewards can arrive out of order, with an a priori unbounded delay, etc.), we introduce a gradient-free learning policy where payoff information is placed in a priority queue as it arrives. In this general context, we derive new bounds for the agents' regret; furthermore, under a standard diagonal concavity assumption, we show that the induced sequence of play converges to Nash equilibrium (NE) with probability 1, even if the delay between choosing an action and receiving the corresponding reward is unbounded.",
        "DOI": "NA",
        "paper_author": "H liou A.l.",
        "affiliation_name": "Criteo AI Lab",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "126155841",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Balancing competing objectives with noisy data: Score-based classifiers for welfare-aware machine learning",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "While real-world decisions involve many competing objectives, algorithmic decisions are often evaluated with a single objective function. In this paper, we study algorithmic policies which explicitly trade off between a private objective (such as profit) and a public objective (such as social welfare). We analyze a natural class of policies which trace an empirical Pareto frontier based on learned scores, and focus on how such decisions can be made in noisy or data-limited regimes. Our theoretical results characterize the optimal strategies in this class, bound the Pareto errors due to inaccuracies in the scores, and show an equivalence between optimal strategies and a rich class of fairness-constrained profit-maximizing policies. We then present empirical results in two different contexts - online content recommendation and sustainable abalone fisheries - to underscore the applicability of our approach to a wide range of practical decisions. Taken together, these results shed light on inherent trade-offs in using machine learning for decisions that impact social welfare.",
        "DOI": "NA",
        "paper_author": "Rolf E.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "On conditional versus marginal bias in multi-armed bandits",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The bias of the sample means of the arms in multiarmed bandits is an important issue in adaptive data analysis that has recently received considerable attention in the literature. Existing results relate in precise ways the sign and magnitude of the bias to various sources of data adaptivity, but do not apply to the conditional inference setting in which the sample means are computed only if some specific conditions are satisfied. In this paper, we characterize the sign of the conditional bias of monotone functions of the rewards, including the sample mean. Our results hold for arbitrary conditioning events and leverage natural monotonicity properties of the data collection policy. We further demonstrate, through several examples from sequential testing and best arm identification, that the sign of the conditional and marginal bias of the sample mean of an arm can be different, depending on the conditioning event. Our analysis offers new and interesting perspectives on the subtleties of assessing the bias in data adaptive settings.",
        "DOI": "NA",
        "paper_author": "Shin J.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60027950",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Efficiently Solving MDPs with Stochastic Mirror Descent",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "We present a unified framework based on primaldual stochastic mirror descent for approximately solving infinite-horizon Markov decision processes (MDPs) given a generative model. When applied to an average-reward MDP with Atot total actions and mixing time bound tmix our method computes an-optimal policy with an expected eO (t2 mixAtot-2) samples from the statetransition matrix, removing the ergodicity dependence of prior art. When applied to a-discounted MDP with Atot total actions our method computes an-optimal policy with an expected eO ((1-)-4Atot-2) samples, improving over previous primal-dual methods and matching the state-ofthe-Art up to a (1-)-1 factor. Both methods are model-free, update state values and policies simultaneously, and run in time linear in the number of samples taken. We achieve these results through a more general stochastic mirror descent framework for solving bilinear saddle-point problems with simplex and box domains and we demonstrate the flexibility of this framework by providing further applications to constrained MDPs.",
        "DOI": "NA",
        "paper_author": "Jin Y.",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60012708",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Robust pricing in dynamic mechanism design",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "Motivated by the repeated sale of online ads via auctions, optimal pricing in repeated auctions has attracted a large body of research. While dynamic mechanisms offer powerful techniques to improve on both revenue and efficiency by optimizing auctions across different items, their reliance on exact distributional information of buyers' valuations (present and future) limits their use in practice. In this paper, we propose robust dynamic mechanism design. We develop a new framework to design dynamic mechanisms that are robust to both estimation errors in value distributions and strategic behavior. We apply the framework in learning environments, leading to the first policy that achieves provably low regret against the optimal dynamic mechanism in contextual auctions, where the dynamic benchmark has full and accurate distributional information.",
        "DOI": "NA",
        "paper_author": "Deng Y.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60140145",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Information particle filter tree: An online algorithm for POMDPs with belief-based rewards on continuous domains",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Planning in Partially Observable Markov Decision Processes (POMDPs) inherently gathers the information necessary to act optimally under uncertainties. The framework can be extended to model pure information gathering tasks by considering belief-based rewards. This allows us to use reward shaping to guide POMDP planning to informative beliefs by using a weighted combination of the original reward and the expected information gain as the objective. In this work we propose a novel online algorithm, Information Particle Filter Tree (IPFT), to solve problems with belief-dependent rewards on continuous domains. It simulates particle-based belief trajectories in a Monte Carlo Tree Search (MCTS) approach to construct a search tree in the belief space. The evaluation shows that the consideration of information gain greatly improves the performance in problems where information gathering is an essential part of the optimal policy.",
        "DOI": "NA",
        "paper_author": "Fischer J.",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany",
        "affiliation_id": "60102538",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Retro*: Learning retrosynthetic planning with neural guided A* search",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "25",
        "cover_date": "2020-01-01",
        "Abstract": "Retrosynthetic planning is a critical task in organic chemistry which identifies a series of reactions that can lead to the synthesis of a target product. The vast number of possible chemical transformations makes the size of the search space very big, and retrosynthetic planning is challenging even for experienced chemists. However, existing methods either require expensive return estimation by rollout with high variance, or optimize for search speed rather than the quality. In this paper, we propose Retro*, a neural-based A*-like algorithm that finds high-quality synthetic routes efficiently. It maintains the search as an AND-OR tree, and learns a neural search bias with off-policy data. Then guided by this neural network, it performs best-first search efficiently during new planning episodes. Experiments on benchmark USPTO datasets show that, our proposed method outperforms existing state-of-the-art with respect to both the success rate and solution quality, while being more efficient at the same time.",
        "DOI": "NA",
        "paper_author": "Chen B.",
        "affiliation_name": "College of Computing",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60097290",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Logarithmic regret for learning linear quadratic regulators efficiently",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "We consider the problem of learning in Linear Quadratic Control systems whose transition parameters are initially unknown. Recent results in this setting have demonstrated efficient learning algorithms with regret growing with the square root of the number of decision steps. We present new efficient algorithms that achieve, perhaps surprisingly, regret that scales only (poly)logarithmically with the number of steps in two scenarios: when only the state transition matrix A is unknown, and when only the stateaction transition matrix B is unknown and the optimal policy satisfies a certain non-degeneracy condition. On the other hand, we give a lower bound that shows that when the latter condition is violated, square root regret is unavoidable.",
        "DOI": "NA",
        "paper_author": "Cassel A.",
        "affiliation_name": "Tel Aviv University",
        "affiliation_city": "Tel Aviv-Yafo",
        "affiliation_country": "Israel",
        "affiliation_id": "60005681",
        "affiliation_state": "Tel Aviv District"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Stochastic flows and geometric optimization on the orthogonal group",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "We present a new class of stochastic, geometrically-driven optimization algorithms on the orthogonal group O(d) and naturally reductive homogeneous manifolds obtained from the action of the rotation group SO(d). We theoretically and experimentally demonstrate that our methods can be applied in various fields of machine learning including deep, convolutional and recurrent neural networks, reinforcement learning, normalizing flows and metric learning. We show an intriguing connection between efficient stochastic optimization on the orthogonal group and graph theory (e.g. matching problem, partition functions over graphs, graph-coloring). We leverage the theory of Lie groups and provide theoretical results for the designed class of algorithms. We demonstrate broad applicability of our methods by showing strong performance on the seemingly unrelated tasks of learning world models to obtain stable policies for the most difficult Humanoid agent from OpenAI Gym and improving convolutional neural networks.",
        "DOI": "NA",
        "paper_author": "Choromanski K.",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States",
        "affiliation_id": "60006191",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Learning to navigate the synthetically accessible chemical space using reinforcement learning",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "35",
        "cover_date": "2020-01-01",
        "Abstract": "Over the last decade, there has been significant progress in the field of machine learning for de novo drug design, particularly in generative modeling of novel chemical structures. However, current generative approaches exhibit a significant challenge: they do not ensure that the proposed molecular structures can be feasibly synthesized nor do they provide the synthesis routes of the proposed small molecules, thereby seriously limiting their practical applicability. In this work, we propose a novel reinforcement learning (RL) setup for de novo drug design: Policy Gradient for Forward Synthesis (PGFS), that addresses this challenge by embedding the concept of synthetic accessibility directly into the de novo drug design system. In this setup, the agent learns to navigate through the immense synthetically accessible chemical space by subjecting initial commercially available molecules to valid chemical reactions at every time step of the iterative virtual synthesis process. The proposed environment for drug discovery provides a highly challenging test-bed for RL algorithms owing to the large state space and high-dimensional continuous action space with hierarchical actions. PGFS achieves state-of-the-art performance in generating structures with high QED and clogP. Moreover, we validate PGFS in an in-silico proof-of-concept associated with three HIV targets. Finally, we describe how the end-to-end training conceptualized in this study represents an important paradigm in radically expanding the synthesizable chemical space and automating the drug discovery process.",
        "DOI": "NA",
        "paper_author": "Gottipati S.K.",
        "affiliation_name": "'99 and Beyond",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "126149836",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Accountable off-policy evaluationwith kernel bellman statistics",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "We consider off-policy evaluation (OPE), which evaluates the performance of a new policy from observed data collected from previous experiments, without requiring the execution of the new policy. This finds important applications in areas with high execution cost or safety concerns, such as medical diagnosis, recommendation systems and robotics. In practice, due to the limited information from off-policy data, it is highly desirable to construct rigorous confidence intervals, not just point estimation, for the policy performance. In this work, we propose a new variational framework which reduces the problem of calculating tight confidence bounds in OPE into an optimization problem on a feasible set that catches the true state-action value function with high probability. The feasible set is constructed by leveraging statistical properties of a recently proposed kernel Bellman loss (Feng et al., 2019). We design an efficient computational approach for calculating our bounds, and extend it to perform post-hoc diagnosis and correction for existing estimators. Empirical results show that our method yields tight confidence intervals in different settings.",
        "DOI": "NA",
        "paper_author": "Feng Y.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60150459",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Inexact tensor methods with dynamic accuracies",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we study inexact high-order Tensor Methods for solving convex optimization problems with composite objective. At every step of such methods, we use approximate solution of the auxiliary problem, defined by the bound for the residual in function value. We propose two dynamic strategies for choosing the inner accuracy: The first one is decreasing as 1=kp+1, where p_1 is the order of the method and k is the iteration counter, and the second approach is using for the inner accuracy the last progress in the target objective. We show that inexact Tensor Methods with these strategies achieve the same global convergence rate as in the error-free case. For the second approach we also establish local superlinear rates (for p_2), and propose the accelerated scheme. Lastly, we present computational results on a variety of machine learning problems for several methods and different accuracy policies.",
        "DOI": "NA",
        "paper_author": "Doikov N.",
        "affiliation_name": "Université Catholique de Louvain",
        "affiliation_city": "Louvain-la-Neuve",
        "affiliation_country": "Belgium",
        "affiliation_id": "60000874",
        "affiliation_state": "WBR"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Causal modeling for fairness in dynamical systems",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "25",
        "cover_date": "2020-01-01",
        "Abstract": "In many application areas-lending, education, and online recommenders, for example-fairness and equity concerns emerge when a machine learning system interacts with a dynamically changing environment to produce both immediate and long-term effects for individuals and demographic groups. We discuss causal directed acyclic graphs (DAGs) as a unifying framework for the recent literature on fairness in such dynamical systems. We show that this formulation affords several new directions of inquiry to the modeler, where causal assumptions can be expressed and manipulated. We emphasize the importance of computing interventional quantities in the dynamical fairness setting, and show how causal assumptions enable simulation (when environment dynamics are known) and off-policy estimation (when dynamics are unknown) of intervention on short- and long-term outcomes, at both the group and individual levels.",
        "DOI": "NA",
        "paper_author": "Creager E.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Global concavity and optimization in a class of dynamic discrete choice models",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Discrete choice models with unobserved heterogeneity are commonly used Econometric models for dynamic Economic behavior which have been adopted in practice to predict behavior of individuals and firms from schooling and job choices to strategic decisions in market competition. These models feature optimizing agents who choose among a finite set of options in a sequence of periods and receive choice-specific payoffs that depend on both variables that are observed by the agent and recorded in the data and variables that are only observed by the agent but not recorded in the data. Existing work in Econometrics assumes that optimizing agents are fully rational and requires finding a functional fixed point to find the optimal policy. We show that in an important class of discrete choice models the value function is globally concave in the policy. That means that simple algorithms that do not require fixed point computation, such as the policy gradient algorithm, globally converge to the optimal policy. This finding can both be used to relax behavioral assumption regarding the optimizing agents and to facilitate Econometric analysis of dynamic behavior. In particular, we demonstrate significant computational advantages in using a simple implementation policy gradient algorithm over existing \"nested fixed point\" algorithms used in Econometrics.",
        "DOI": "NA",
        "paper_author": "Feng Y.",
        "affiliation_name": "Robert R. McCormick School of Engineering and Applied Science",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States",
        "affiliation_id": "60147353",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "On the global convergence rates of softmax policy gradient methods",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "105",
        "cover_date": "2020-01-01",
        "Abstract": "We make three contributions toward better understanding policy gradient methods in the tabular setting. First, we show that with the true gradient, policy gradient with a softmax parametrization converges at a O(1=t) rate, with constants depending on the problem and initialization. This result significantly expands the recent asymptotic convergence results. The analysis relies on two findings: That the softmax policy gradient satisfies a ojasiewicz inequality, and the minimum probability of an optimal action during optimization can be bounded in terms of its initial value. Second, we analyze entropy regularized policy gradient and show that it enjoys a significantly faster linear convergence rate O(et) toward softmax optimal policy. This result resolves an open question in the recent literature. Finally, combining the above two results and additional new (1=t) lower bound results, we explain how entropy regularization improves policy optimization, even with the true gradient, from the perspective of convergence rate. The separation of rates is further explained using the notion of non-uniform ojasiewicz degree. These results provide a theoretical understanding of the impact of entropy and corroborate existing empirical studies.",
        "DOI": "NA",
        "paper_author": "Mei J.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60030835",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "37th International Conference on Machine Learning, ICML 2020",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 1075 papers. The topics discussed include: selective DYNA-style planning under limited model capacity; implicit differentiation of lasso-type models for hyperparameter optimization; a simple framework for contrastive learning of visual representations; probing emergent semantics in predictive agents via question answering; topic modeling via full dependence mixtures; REALM: retrieval-augmented language model pre-training; source separation with deep generative priors; problems with Shapley-value-based explanations as feature importance measures; hallucinative topological memory for zero-shot visual planning; two simple ways to learn individual fairness metrics from data; unsupervised speech decomposition via triple information bottleneck; an explicitly relational neural network architecture; Taylor expansion policy optimization; POKED: a semi-supervised system for word sense disambiguation; and training deep energy-based models with f-divergence minimization.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Distributionally robust policy evaluation and learning in offline contextual bandits",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "29",
        "cover_date": "2020-01-01",
        "Abstract": "Policy learning using historical observational data is an important problem that has found widespread applications. However, existing literature rests on the crucial assumption that the future environment where the learned policy will be deployed is the same as the past environment that has generated the data-an assumption that is often false or too coarse an approximation. In this paper, we lift this assumption and aim to learn a distributionally robust policy with bandit observational data. We propose a novel learning algorithm that is able to learn a robust policy to adversarial perturbations and unknown covariate shifts. We first present a policy evaluation procedure in the ambiguous environment and also give a heuristic algorithm to solve the distributionally robust policy learning problems efficiently. Additionally, we provide extensive simulations to demonstrate the robustness of our policy.",
        "DOI": "NA",
        "paper_author": "Si N.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Machine learning assisted solutions of mixed integer MPC on embedded platforms",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Many control applications, especially in the field of energy systems, require a simultaneous decision for continuous and binary values of control inputs. In optimal control methods like model predictive control (MPC), this leads to the problem of solving expensive mixed-integer programs online. As this solution in practice has to be calculated with low cost embedded hardware with low energy demand, it is necessary to reduce the computational demand in advance. We present an approach to replacing the mixed-integer program by a simpler quadratic program by means of learning techniques. To be more specific, we design a neural network and a support vector machine to classify the optimal control policies for the binary inputs offline and evaluate this decision in the online step as the basis for the solution of the quadratic program. As a result, we achieve a controller suitable for implementation on embedded hardware. We demonstrate its applicability to a domestic heating system. The results indicate a very high quality of the approximation of the primary optimal controller that solves mixed-integer programs online.",
        "DOI": "10.1016/j.ifacol.2020.12.1189",
        "paper_author": "Löhr Y.",
        "affiliation_name": "Ruhr-Universitat Bochum",
        "affiliation_city": "Bochum",
        "affiliation_country": "Germany",
        "affiliation_id": "60005322",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Data-driven energy management strategy for plug-in hybrid electric vehicles with real-world trip information",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "This paper presents a data-driven supervisory energy management strategy (EMS) for plug-in hybrid electric vehicles which leverages Vehicle-to-Cloud connectivity to increase energy efficiency by learning control policies from completed trips. The proposed EMS consists of two layers, a cloud layer and an on-board layer. The cloud layer has two main tasks: the first task is to learn EMS policy parameters from historical trip data, and the second task is to provide the policy parameters along a certain route requested from the vehicle. The on-board layer receives the learned policy parameters from the cloud layer and computes a real-time solution to the powertrain energy management problem, using a model predictive control scheme. The proposed EMS is evaluated on more than 3000 miles (48 independent driving cycles) of real-world trip data, collected along three commuting routes in California. For the routes, the proposed algorithm shows 3.3%, 7.3%, and 6.5% improvement in average MPGe when compared to a baseline EMS.",
        "DOI": "10.1016/j.ifacol.2020.12.1070",
        "paper_author": "Choi Y.",
        "affiliation_name": "Department of Mechanical Engineering",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60121383",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Environment 4.0: How digitalization and machine learning can improve the environmental footprint of the steel production processes",
        "publication": "Materiaux et Techniques",
        "citied_by": "42",
        "cover_date": "2020-01-01",
        "Abstract": "The concepts of Circular Economy and Industrial Symbiosis are nowadays considered by policy makers a key for the sustainability of the whole European Industry. However, in the era of Industry4.0, this results into an extremely complex scenario requiring new business models and involve the whole value chain, and representing an opportunity as well. Moreover, in order to properly consider the environmental pillar of sustainability, the quality of available information represents a challenge in taking appropriate decisions, considering inhomogeneity of data sources, asynchronous nature of data sampling in terms of clock time and frequency, and different available volumes. In this sense, Big Data techniques and tools are fundamental in order to handle, analyze and process such heterogeneity, to provide a timely and meaningful data and information interpretation for making exploitation of Machine Learning and Artificial Intelligence possible. Handling and fully exploiting the complexity of the current monitoring and automation systems calls for deep exploitation of advanced modelling and simulation techniques to define and develop proper Environmental Decision Support Systems. Such systems are expected to extensively support plant managers and operators in taking better, faster and more focused decisions for improving the environmental footprint of production processes, while preserving optimal product quality and smooth process operation. The paper describes a vision from the steel industry on the way in which the above concepts can be implemented in the steel sector through some application examples aimed at improving socio-economic and environmental sustainability of production cycles.",
        "DOI": "10.1051/mattech/2021007",
        "paper_author": "Colla V.",
        "affiliation_name": "Sant'Anna Scuola Universitaria Superiore Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60028039",
        "affiliation_state": "PI"
    },
    {
        "paper_title": "Generative adversarial training of product of policies for robust and adaptive movement primitives",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "In learning from demonstrations, many generative models of trajectories make simplifying assumptions of independence. Correctness is sacrificed in the name of tractability and speed of the learning phase. The ignored dependencies, which often are the kinematic and dynamic constraints of the system, are then only restored when synthesizing the motion, which introduces possibly heavy distortions. In this work, we propose to use those approximate trajectory distributions as close-to-optimal discriminators in the popular generative adversarial framework to stabilize and accelerate the learning procedure. The two problems of adaptability and robustness are addressed with our method. In order to adapt the motions to varying contexts, we propose to use a product of Gaussian policies defined in several parametrized task spaces. Robustness to perturbations and varying dynamics is ensured with the use of stochastic gradient descent and ensemble methods to learn the stochastic dynamics. Two experiments are performed on a 7-DoF manipulator to validate the approach.",
        "DOI": "NA",
        "paper_author": "Pignat E.",
        "affiliation_name": "Institut Dalle Molle D'intelligence Artificielle Perceptive",
        "affiliation_city": "Martigny",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60030109",
        "affiliation_state": "VS"
    },
    {
        "paper_title": "Learning geo-contextual embeddings for commuting flow prediction",
        "publication": "AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",
        "citied_by": "49",
        "cover_date": "2020-01-01",
        "Abstract": "Predicting commuting flows based on infrastructure and land-use information is critical for urban planning and public policy development. However, it is a challenging task given the complex patterns of commuting flows. Conventional models, such as gravity model, are mainly derived from physics principles and limited by their predictive power in real-world scenarios where many factors need to be considered. Meanwhile, most existing machine learning-based methods ignore the spatial correlations and fail to model the influence of nearby regions. To address these issues, we propose Geocontextual Multitask Embedding Learner (GMEL), a model that captures the spatial correlations from geographic contextual information for commuting flow prediction. Specifically, we first construct a geo-adjacency network containing the geographic contextual information. Then, an attention mechanism is proposed based on the framework of graph attention network (GAT) to capture the spatial correlations and encode geographic contextual information to embedding space. Two separate GATs are used to model supply and demand characteristics. To enhance the effectiveness of the embedding representation, a multitask learning framework is used to introduce stronger restrictions, forcing the embeddings to encapsulate effective representation for flow prediction. Finally, a gradient boosting machine is trained based on the learned embeddings to predict commuting flows. We evaluate our model using real-world dataset from New York City and the experimental results demonstrate the effectiveness of our proposed method against the state of the art.",
        "DOI": "NA",
        "paper_author": "Liu Z.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60005244",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Controlling overestimation bias with truncated mixture of continuous distributional quantile critics",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "82",
        "cover_date": "2020-01-01",
        "Abstract": "The overestimation bias is one of the major im_pediments to accurate off-policy learning. This paper investigates a novel way to alleviate the overestimation bias in a continuous control set_ting. Our method-Truncated Quantile Critics, TQC,-blends three ideas: distributional repre_sentation of a critic, truncation of critics predic_tion, and ensembling of multiple critics. Distribu_tional representation and truncation allow for ar_bitrary granular overestimation control, while en_sembling provides additional score improvements. TQC outperforms the current state of the art on all environments from the continuous control bench_mark suite, demonstrating 25% improvement on the most challenging Humanoid environment.",
        "DOI": "NA",
        "paper_author": "Kuznetsov A.",
        "affiliation_name": "Samsung AI Center",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "121905949",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Batch stationary distribution estimation",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "We consider the problem of approximating the stationary distribution of an ergodic Markov chain given a set of sampled transitions. Classical simulation-based approaches assume access to the underlying process so that trajectories of sufficient length can be gathered to approximate stationary sampling. Instead, we consider an alternative setting where a fixed set of transitions has been collected beforehand, by a separate, possibly unknown procedure. The goal is still to estimate properties of the stationary distribution, but without additional access to the underlying system. We propose a consistent estimator that is based on recovering a correction ratio function over the given data. In particular, we develop a variational power method (VPM) that provides provably consistent estimates under general conditions. In addition to unifying a number of existing approaches from different subfields, we also find that VPM yields significantly better estimates across a range of problems, including queueing, stochastic differential equations, post-processing MCMC, and off-policy evaluation.",
        "DOI": "NA",
        "paper_author": "Wen J.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60030835",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Prediction of out-of-pocket health expenditures in Rwanda using machine learning techniques",
        "publication": "The Pan African medical journal",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Introduction: in Rwanda, the estimated out-of-pocket health expenditure has been increased from 24.46% in 2000 to 26% in 2015. Despite the existence of guideline in estimation of out-of-pocket health expenditures provided by WHO (2018), the estimation of out-of-pocket health expenditure still have difficulties in many countries including Rwanda. Methods: the purpose of this paper was to figure out the best model which predicts the out-of-pocket health expenditures in Rwanda during the process of considering various techniques of machine learning by using the Rwanda Integrated Living Conditions Surveys (EICV5) of 14580 households (2018). Results: our findings presented the model which predict the out-of-pocket health expenditures with higher accuracy and was found as treenet model. Furthermore, machine learning techniques were used to judge which predictor variable was important in our prediction process and comparison of the performance of the algorithms through train accuracy and test accuracy metric measures. Finally, the findings show that the tests of accuracy of the models were 50.16% for multivariate adaptive regression splines (MARS) model, 74% decision tree model, 87% for treenet model, 83% for random forest model, gradient boosting 81%, predictor total consumption played a significant role in the model for all tested models. Conclusion: finally, we conclude that the total consumption of the household came out to be the most important variable which is consistently true to all the algorithms tested. The findings from our study have policy implications for policy makers in Rwanda and in the world generally. We recommend the government to significantly increase public spending on health. Domestic financial resources are key to moving closer to universal health coverage (UHC) and should be increased on a long-term basis. In addition, these results will be useful for the future to assess the out-of-pocket health expenditures dataset.",
        "DOI": "10.11604/pamj.2020.37.357.27287",
        "paper_author": "Muremyi R.",
        "affiliation_name": "University of Rwanda",
        "affiliation_city": "Butare",
        "affiliation_country": "Rwanda",
        "affiliation_id": "60072918",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Doubly robust off-policy evaluation with shrinkage",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "25",
        "cover_date": "2020-01-01",
        "Abstract": "We propose a new framework for designing estimators for off-policy evaluation in contextual bandits. Our approach is based on the asymptotically optimal doubly robust estimator, but we shrink the importance weights to minimize a bound on the mean squared error, which results in a better bias-variance tradeoff in finite samples. We use this optimization-based framework to obtain three estimators: (a) a weight-clipping estimator, (b) a new weight-shrinkage estimator, and (c) the first shrinkage-based estimator for combinatorial action sets. Extensive experiments in both standard and combinatorial bandit benchmark problems show that our estimators are highly adaptive and typically outperform state-of-the-art methods.",
        "DOI": "NA",
        "paper_author": "Su Y.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Provably convergent two-Timescale off-policy actor-critic with function approximation",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "We present the first provably convergent twotimescale off-policy actor-critic algorithm (COFPAC) with function approximation. Key to COFPAC is the introduction of a new critic, the emphasis critic, which is trained via Gradient Emphasis Learning (GEM), a novel combination of the key ideas of Gradient Temporal Difference Learning and Emphatic Temporal Difference Learning. With the help of the emphasis critic and the canonical value function critic, we show convergence for COF-PAC, where the critics are linear, and the actor can be nonlinear.",
        "DOI": "NA",
        "paper_author": "Zhang S.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Effective detection of credential thefts from windows memory: Learning access behaviours to local security authority subsystem service",
        "publication": "RAID 2020 Proceedings - 23rd International Symposium on Research in Attacks, Intrusions and Defenses",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Malicious actors that have already penetrated an enterprise network will exploit access to launch attacks within that network. Credential theft is a common preparatory action for such attacks, as it enables privilege escalation or lateral movement. Elaborate techniques for extracting credentials from Windows memory have been developed by actors with advanced capabilities. The state of the art in identifying the use of such techniques is based on malware detection, which can only alert on the presence of specific executable files that are known to perform such techniques. Therefore, actors can bypass detection of credential theft by evading the static detection of malicious code. In contrast, our work focuses directly on the memory read access behaviour to the process that enforces the system security policy. We use machine learning techniques driven by data from real enterprise networks to classify memory read behaviours as malicious or benign. As we show that Mimikatz is a popular tool seen across Microsoft Defender Advanced Threat Protection (MDATP) to steal credentials, our aim is to develop a generic model that detects the techniques it employs. Our classifier is based on novel features of memory read events and the characterisation of three popular techniques for credential theft. We integrated this classifier in a detector that is now running in production and is protecting customers of MDATP. Our experiments demonstrate that this detector has excellent false negative and false positive rates, and does alert on true positives that previous detectors were unable to identify.",
        "DOI": "NA",
        "paper_author": "Ah-Fat P.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Combining observational and experimental data to improve large-scale decision making",
        "publication": "International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "This paper is about devising customized treatment assignment policies (from data) when there is a lot of observational data, but much less (unconfounded) experimental data. We propose to use (large) observational data to learn a complex treatment assignment policy with few supervised learning errors, and then correct for confounding errors in the policy using a (machine learned) model built with both experimental and observational data. Our study details a tree-induction algorithm that may be used to learn the model that corrects for confounding, which we call the deconfounder tree. Finally, we illustrate with a simple example how our approach may lead to better treatment assignments than learning models using exclusively observational or experimental data.",
        "DOI": "NA",
        "paper_author": "Fernández-Loría C.",
        "affiliation_name": "New York University",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60021784",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "PREDIÇÃO DE SINISTROS AGRÍCOLAS: UMA ABORDAGEM COMPARATIVA UTILIZANDO APRENDIZAGEM DE MÁQUINA",
        "publication": "Economia Aplicada",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Crop insurance has gained greater attention in Brazil since the beginning of the past decade, with the implementation of the Rural Insurance Premium Subvention Program. The present study tested the performance of Machine Learning algorithms for insurers to forecast the occurrence of a claim, using data from policies and climate databases between the years of 2006 and 2017. The Random Forest, Support Vector Machine and k-Nearest Neighbors algorithms were tested, and the second method showed a better predictive performance of claims when evaluated by the metrics Accuracy, Precision, Positive and Negative True Rates and Matthews Correlation. However, all methods presented a low predictive capacity for the occurrence of claims.",
        "DOI": "10.11606/1980-5330/ea161194",
        "paper_author": "Mota A.L.",
        "affiliation_name": "Exame Research",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125950822",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Symbolic network: Generalized neural policies for relational MDPs",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "A Relational Markov Decision Process (RMDP) is a first-order representation to express all instances of a single probabilistic planning domain with possibly unbounded number of objects. Early work in RMDPs outputs generalized (instance-independent) first-order policies or value functions as a means to solve all instances of a domain at once. Unfortunately, this line of work met with limited success due to inherent limitations of the representation space used in such policies or value functions. Can neural models provide the missing link by easily representing more complex generalized policies, thus making them effective on all instances of a given domain? We present SYMNET, the first neural approach for solving RMDPs that are expressed in the probabilistic planning language of RDDL. SYMNET trains a set of shared parameters for an RDDL domain using training instances from that domain. For each instance, SYMNET first converts it to an instance graph and then uses relational neural models to compute node embeddings. It then scores each ground action as a function over the first-order action symbols and node embeddings related to the action. Given a new test instance from the same domain, SYMNET architecture with pre-trained parameters scores each ground action and chooses the best action. This can be accomplished in a single forward pass without any retraining on the test instance, thus implicitly representing a neural generalized policy for the whole domain. Our experiments on nine RDDL domains from IPPC demonstrate that SYMNET policies are significantly better than random and sometimes even more effective than training a state-of-the-art deep reactive policy from scratch.",
        "DOI": "NA",
        "paper_author": "Garg S.",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60032730",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Achieving correlated equilibrium by studying opponent's behavior through policy-based deep reinforcement learning",
        "publication": "IEEE Access",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Game theory is a very profound study on distributed decision-making behavior and has been extensively developed by many scholars. However, many existing works rely on certain strict assumptions such as knowing the opponent's private behaviors, which might not be practical. In this work, we focused on two Nobel winning concepts, the Nash equilibrium, and the correlated equilibrium. We proposed a policy-based deep reinforcement learning model which instead of just learning the regions for corresponding strategies and actions, it learns why and how the rational opponent plays. With our proposed policy-based deep reinforcement learning model, we successfully reached the correlated equilibrium which maximizes the utility for each player. Depending on the scenario, the equilibrium can reach outside of the Nash equilibrium convex hull to achieve higher utility for the players, while the traditional non-regret algorithms cannot. In addition, we also proposed a mathematical model to inverse the calculation of the correlated equilibrium probability to estimate the rational opponent player's payoff. Through simulations, with limited interaction among the players, we showed that our proposed method can achieve the optimal correlated equilibrium where each player gains an equal or higher utility than the Nash equilibrium.",
        "DOI": "10.1109/ACCESS.2020.3035362",
        "paper_author": "Tsai K.C.",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "60151362",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Mastering the working sequence in human-robot collaborative assembly based on reinforcement learning",
        "publication": "IEEE Access",
        "citied_by": "40",
        "cover_date": "2020-01-01",
        "Abstract": "A long-standing goal of the Human-Robot Collaboration (HRC) in manufacturing systems is to increase the collaborative working efficiency. In line with the trend of Industry 4.0 to build up the smart manufacturing system, the collaborative robot in the HRC system deserves better designing to be more self-organized and to find the superhuman proficiency by self-learning. Inspired by the impressive machine learning algorithms developed by Google Deep Mind like Alphago Zero, in this paper, the humanrobot collaborative assembly working process is formatted into a chessboard and the selection of moves in the chessboard is used to analogize the decision-making by both human and robot in the HRC assembly working process. To obtain the optimal policy of the working sequence to maximize the working efficiency, agents in the system are trained with a self-play algorithm based on reinforcement learning, without guidance or domain knowledge beyond game rules. A convolution neural network (CNN) is also trained to predict the distribution of the priority of move selections and whether a working sequence is the one resulting in the maximum of the HRC efficiency. A height-adjustable standing desk assembly is used to demonstrate the proposed HRC assembly algorithm and its efficiency in real-time task planning.",
        "DOI": "10.1109/ACCESS.2020.3021904",
        "paper_author": "Yu T.",
        "affiliation_name": "University of Virginia School of Engineering and Applied Science",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States",
        "affiliation_id": "60152865",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Path-following control of fish-like robots: A deep reinforcement learning approach",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we propose a deep reinforcement learning (DRL) approach for path-following control of a fish-like robot. The desired path may be a randomly generated Bézier curve. First, to implement the locomotion control of the fish-like robot, we design a modified Central Pattern Generated (CPG) model, using which the fish achieves varied swimming behaviors just by adjusting a single control input. To reduce the reality gap between simulation and the physical system, using the experimental data of the real fish-like robot, we build a surrogate simulation environment, which also well balances the accuracy and the speed of training. Second, for the path-following control, we select the advantage actorcritic (A2C) approach and train the control policy in the surrogate simulation environment with a straight line as the desired path. Then the trained control policy is directly deployed on a physical fish-like robot to follow a randomly generated Bézier curve. The experimental results show that our proposed approach has good practical applicability in view of its efficiency and feasibility in controlling the physical fishlike robot. This work shows a novel and promising way to control biomimetic underwater robots in the real world.",
        "DOI": "10.1016/j.ifacol.2020.12.2306",
        "paper_author": "Zhang T.",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60014966",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reducing congestion in an intelligent traffic system with collaborative and adaptive signaling on the edge",
        "publication": "IEEE Access",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "The advancements in Edge computing have paved the way for deep learning in real-time systems. One of the beneficiaries is an adaptive traffic control system that responds to real-time traffic observations by governing the signal phase and timings. Reinforcement Learning (RL) is extensively utilized in the literature in order to decrease traffic congestion in a road network. However, most of the previous works leverage centralized and cloud-based RL due to the computational complexity of underlying deep neural networks (DNN). Therefore, a persistent challenge towards adopting Edge learning is in devising a Multi-Agent RL in which agents are simplified, and their state spaces are localized but they perform comparable to the centralized RL. This article presents a Collaborative and Adaptive Signaling on the Edge (CASE), a novel Multi-Agent RL approach to control the traffic signals' phase and timing. Each signalized intersection in the road network is provided with an Edge Learning Platform which hosts an RL-Agent that observes local traffic states and learns an optimum signal policy. Moreover, CASE allows collaboration among RL-Agents by sharing their signal phase and timings to achieve convergence and performance. This collaboration is limited to one's direct neighbours only to minimize the computational complexity. We performed rigorous evaluations in terms of the choice of RL methods and their state space/reward and found that our collaborative state-space has resulted in a performance comparable to a centralized RL yet with a cost similar to the decentralized RL. Finally, a performance comparison of the CASE controller ported to the state-of-the-art Edge learning platforms is presented in this article. The results show that the proposed CASE controller can achieve real-time performance when ported to a general-purpose GPU-based platform. This arrangement achieves more than 8 times improvement in computational time over conventional embedded platforms.",
        "DOI": "10.1109/ACCESS.2020.3037348",
        "paper_author": "Jaleel A.",
        "affiliation_name": "Rachna College of Engineering and Technology",
        "affiliation_city": "Lahore",
        "affiliation_country": "Pakistan",
        "affiliation_id": "124081834",
        "affiliation_state": "Gujranwala"
    },
    {
        "paper_title": "Clustering life course to understand the heterogeneous effects of life events, gender, and generation on habitual travel modes",
        "publication": "IEEE Access",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Daily transportation mode choice is largely habitual, but transitions between life events may disrupt travel habits and can shift choices between alternative transportation modes. Although much is known about general mode switches following life event transitions, less is understood about differences that may exist between subpopulations, especially from a long-term perspective. Understanding these differences will help planners and policymakers introduce more targeted policy interventions to promote sustainable transportation modes and inform longer-term predictions. Extending beyond existing literature, we use data collected from a retrospective survey to investigate the effects of life course events on mode use situated within different long-term life trajectory contexts. We apply a machine-learning method called joint social sequence clustering to define five distinct and interpretable cohorts based on trajectory patterns in family and career domains over their life courses. We use these patterns as an innovative contextual system to investigate (1) the heterogeneous effects of life events on travel mode use and (2) further differentiation between gender and generation groups in these life event effects. We find that events occurring relatively early in life are more strongly associated with changes in mode-use behavior, and that mode use can also be affected by the relative order of events. This timing and order effect can have lasting impacts on mode use aggregated over entire life cycles: members of our ‘‘Have-it-alls’’ cohort—who finish their education, start working, partner up, and have children early in life—ramp up car use at each event, resulting in the highest rate of car use occurring the earliest among all the cohorts. Women drive more when having children primarily when their family formation and career formation are intertwined early in life, and younger generations rely relatively more on car use during familial events when their careers have a later start.",
        "DOI": "10.1109/ACCESS.2020.3032328",
        "paper_author": "Jin L.",
        "affiliation_name": "Lawrence Berkeley National Laboratory",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60007174",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "From importance sampling to doubly robust policy gradient",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "We show that on-policy policy gradient (PG) and its variance reduction variants can be derived by taking finite difference of function evaluations supplied by estimators from the importance sampling (IS) family for off-policy evaluation (OPE). Starting from the doubly robust (DR) estimator (Jiang and Li, 2016), we provide a simple derivation of a very general and flexible form of PG, which subsumes the state-of-the-art variance reduction technique (Cheng et al., 2019) as its special case and immediately hints at further variance reduction opportunities overlooked by existing literature. We analyze the variance of the new DR-PG estimator, compare it to existing methods as well as the Cramer-Rao lower bound of policy gradient, and empirically show its effectiveness.",
        "DOI": "NA",
        "paper_author": "Huang J.",
        "affiliation_name": "Siebel School of Computing and Data Science",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States",
        "affiliation_id": "60282642",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "A convolutional neural network model for marble quality classification",
        "publication": "Journal of the Faculty of Engineering and Architecture of Gazi University",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "The basic policy of marble enterprises is to establish sustainable high-quality products in a standardized manner. Identification and classification of different types of marbles is a critical task that is usually carried out by human experts. However, marble quality classification by human experts can be time-consuming, error-prone, unreliable, and subjective. Automated and computerized methods are needed to obtain more reliable, faster, and less subjective results. In this study, a deep learning model is developed in order to perform multi-classification of marble slab images with six different quality types. Some special image pre-processing operations were applied to the images for data augmentation and a special convolutional neural network (CNN) architecture was designed and implemented. It has been observed that the data augmentation approach for marble image samples has significantly improved the accuracy of the CNN model. We have obtained outstanding results with our CNN model, which surpassed the alternative machine learning algorithms and even equalized the human experts’ classification performance.",
        "DOI": "10.17341/gazimmfd.720041",
        "paper_author": "Karaali İ.",
        "affiliation_name": "Dokuz Eylül Üniversitesi",
        "affiliation_city": "Izmir",
        "affiliation_country": "Türkiye",
        "affiliation_id": "60014930",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "When and how to lift the lockdown? Global COVID-19 scenario analysis and policy assessment using compartmental Gaussian processes",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "21",
        "cover_date": "2020-01-01",
        "Abstract": "The coronavirus disease 2019 (COVID-19) global pandemic has led many countries to impose unprecedented lockdown measures in order to slow down the outbreak. Questions on whether governments have acted promptly enough, and whether lockdown measures can be lifted soon, have since been central in public discourse. Data-driven models that predict COVID-19 fatalities under different lockdown policy scenarios are essential for addressing these questions and informing governments on future policy directions. To this end, this paper develops a Bayesian model for predicting the effects of COVID-19 lockdown policies in a global context — we treat each country as a distinct data point, and exploit variations of policies across countries to learn country-specific policy effects. Our model utilizes a two-layer Gaussian process (GP) prior — the lower layer uses a compartmental SEIR (Susceptible, Exposed, Infected, Recovered) model as a prior mean function with “country-and-policy-specific” parameters that capture fatality curves under “counterfactual” policies within each country, whereas the upper layer is shared across all countries, and learns lower-layer SEIR parameters as a function of a country’s features and its policy indicators. Our model combines the solid mechanistic foundations of SEIR models (Bayesian priors) with the flexible data-driven modeling and gradient-based optimization routines of machine learning (Bayesian posteriors) — i.e., the entire model is trained end-to-end via stochastic variational inference. We compare the projections of COVID-19 fatalities in our model with other models listed by the Center for Disease Control (CDC), and provide scenario analyses for various lockdown and reopening strategies highlighting their impact on COVID-19 fatalities.",
        "DOI": "NA",
        "paper_author": "Qian Z.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "A NEW VIRUS-CENTRIC EPIDEMIC MODELING APPROACH 1. GENERAL THEORY AND MACHINE LEARNING SIMULATION OF 2020 SARS COV 2 (COVID-19) FOR BELGIUM, FRANCE, ITALY, AND SPAIN",
        "publication": "Mathematics and Mechanics of Complex Systems",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "We are trying to test the capacity of a simplified macroscopic virus-centric model to simulate the evolution of the SARS CoV 2 epidemic (COVID 19) at the level of a country or a geographical entity, provided that the evolution of the conditions of its development (behaviors, containment policies) are sufficiently homogeneous on the considered territory. For example, a uniformly deployed lockdown on the territory, or a sufficiently uniform overall crisis management. The virus-centric approach means that we favor to model the population dynamic of the virus rather than the evolution of the human cases. In other words, we model the interactions between the virus and its environment – for instance a specific human population with a specific behavior on a territory, instead of modeling the interactions between individuals. Therefore, our approach assumes that an epidemic can be analyzed as the combination of several elementary epidemics which represent a different part of the population with different behaviors through time. The modeling proposed here is based on the finite superposition of Verhulst equations commonly known as logistic functions and used in dynamics of population. Modelling the lockdown effect at the macroscopic level is therefore possible. our model has parameters with a clear epidemiological interpretation, therefore the evolution of the epidemic can be discussed and compared among four countries: Belgium, France, Italy, and Spain. Parameter optimization is carried out by a classical machine learning process. We present the number of infected patients with SARS-CoV-2 and a comparison between data from the European Centre for Disease Prevention and Control and the modeling. In a general formulation, the model is applicable to any country with similar epidemic management characteristics. These results show that a simple two epidemics decomposition is sufficient to simulate with accuracy the effect of a lockdown on the evolution of the COVID-19 cases.",
        "DOI": "10.2140/memocs.2020.8.233",
        "paper_author": "Rémond J.",
        "affiliation_name": "Stanwell Consulting",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "125884776",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Fast adaptation to new environments via policy-dynamics value functions",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Standard RL algorithms assume fixed environment dynamics and require a significant amount of interaction to adapt to new environments. We introduce Policy-Dynamics Value Functions (PDVF), a novel approach for rapidly adapting to dynamics different from those previously seen in training. PD-VF explicitly estimates the cumulative reward in a space of policies and environments. An ensemble of conventional RL policies is used to gather experience on training environments, from which embeddings of both policies and environments can be learned. Then, a value function conditioned on both embeddings is trained. At test time, a few actions are sufficient to infer the environment embedding, enabling a policy to be selected by maximizing the learned value function (which requires no additional environment interaction). We show that our method can rapidly adapt to new dynamics on a set of MuJoCo domains. Code available at policy-dynamics-value-functions.",
        "DOI": "NA",
        "paper_author": "Raileanu R.",
        "affiliation_name": "NYU CS department",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60147012",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Explicit gradient learning for black-box optimization",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Black-Box Optimization (BBO) methods can find optimal policies for systems that interact with complex environments with no analytical representation. As such, they are of interest in many Artificial Intelligence (AI) domains. Yet classical BBO methods fall short in high-dimensional non-convex problems. They are thus often overlooked in real-world AI tasks. Here we present a BBO method, termed Explicit Gradient Learning (EGL), that is designed to optimize highdimensional ill-behaved functions. We derive EGL by finding weak spots in methods that fit the objective function with a parametric Neural Network (NN) model and obtain the gradient signal by calculating the parametric gradient. Instead of fitting the function, EGL trains a NN to estimate the objective gradient directly. We prove the convergence of EGL to a stationary point and its robustness in the optimization of integrable functions. We evaluate EGL and achieve state-ofthe- art results in two challenging problems: (1) the COCO test suite against an assortment of standard BBO methods; and (2) in a high-dimensional non-convex image generation task.",
        "DOI": "NA",
        "paper_author": "Sarafian E.",
        "affiliation_name": "Bar-Ilan University",
        "affiliation_city": "Ramat Gan",
        "affiliation_country": "Israel",
        "affiliation_id": "60002765",
        "affiliation_state": "Tel Aviv District"
    },
    {
        "paper_title": "Multi-agent mission planning with reinforcement learning",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "State of the art mission planning software packages such as AFSIM use traditional AI approaches including allocation algorithms and scripted state machines to control the simulated behavior of military aircraft, ships, and ground units. We have developed a novel AI system that uses reinforcement learning to produce more effective high-level strategies for military engagements. However, instead of learning a policy from scratch with initially random behavior, it also leverages existing traditional AI approaches for automation of simple low-level behaviors, to simplify the cooperative multi-agent aspect of the problem, and to bootstrap learning with available prior knowledge to achieve order of magnitude faster training.",
        "DOI": "NA",
        "paper_author": "Soleyman S.",
        "affiliation_name": "HRL Laboratories",
        "affiliation_city": "Malibu",
        "affiliation_country": "United States",
        "affiliation_id": "60021939",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Backdoor attacks in sequential decision-making agents",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Recent work has demonstrated robust mechanisms by which attacks can be orchestrated on machine learning models. In contrast to adversarial examples, backdoor or trojan attacks embed surgically modified samples in the model training process to cause the targeted model to learn to misclassify samples in the presence of specific triggers, while keeping the model performance stable across other nominal samples. However, current published research on trojan attacks mainly focuses on classification problems, which ignores sequential dependency between inputs. In this paper, we propose methods to discreetly introduce and exploit novel backdoor attacks within a sequential decision-making agent, such as a reinforcement learning agent, by training multiple benign and malicious policies within a single long short-term memory (LSTM) network, where the malicious policy can be activated by a short realizable trigger introduced to the agent.We demonstrate the effectiveness through initial outcomes generated from our approach as well as discuss the impact of such attacks in defense scenarios.We also provide evidence as well as intuition on how the trojan trigger and malicious policy is activated. In the end, we propose potential approaches to defend against or serve as early detection for such attacks.",
        "DOI": "NA",
        "paper_author": "Yang Z.",
        "affiliation_name": "GE Global Research",
        "affiliation_city": "Niskayuna",
        "affiliation_country": "United States",
        "affiliation_id": "60021211",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "A class of algorithms for general instrumental variable models",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "21",
        "cover_date": "2020-01-01",
        "Abstract": "Causal treatment effect estimation is a key problem that arises in a variety of real-world settings, from personalized medicine to governmental policy making. There has been a flurry of recent work in machine learning on estimating causal effects when one has access to an instrument. However, to achieve identifiability, they in general require one-size-fits-all assumptions such as an additive error model for the outcome. An alternative is partial identification, which provides bounds on the causal effect. Little exists in terms of bounding methods that can deal with the most general case, where the treatment itself can be continuous. Moreover, bounding methods generally do not allow for a continuum of assumptions on the shape of the causal effect that can smoothly trade off stronger background knowledge for more informative bounds. In this work, we provide a method for causal effect bounding in continuous distributions, leveraging recent advances in gradient-based methods for the optimization of computationally intractable objective functions. We demonstrate on a set of synthetic and real-world data that our bounds capture the causal effect when additive methods fail, providing a useful range of answers compatible with observation as opposed to relying on unwarranted structural assumptions.",
        "DOI": "NA",
        "paper_author": "Kilbertus N.",
        "affiliation_name": "Helmholtz AI",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "126457000",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting poultry turnovers with machine learning and multiple factors",
        "publication": "Data Analysis and Knowledge Discovery",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "[Objective] This paper tries to forecast the trends of poultry market influenced by multiple factors, aiming to strengthen the decision makings and policies for livestock and poultry production. [Methods] We chose 50 variables to construct machine learning models for predicting daily turnovers of dressed chicken. Our models were created based on popular machine learning algorithms. [Results] We found that GBRT, Random Forest and Elastic Net yielded stable prediction results and their MAEs were 25. 30, 26. 67, and 28. 21 respectively. The prediction was improved with more large training sets and longer training time. We could forecast the turnovers of three periods in advance. [Limitations] The training sets needs to include more features and historical data. [Conclusions] The proposed models could quantatively assess and forecast the impacts of emergencies on industrial output, which imrpoves governmental policy making.",
        "DOI": "10.11925/INFOTECH.2096-3467.2020.0323",
        "paper_author": "Dong C.",
        "affiliation_name": "State Information Center",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "100325630",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Greedy policy search: A simple baseline for learnable test-time augmentation",
        "publication": "Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence, UAI 2020",
        "citied_by": "39",
        "cover_date": "2020-01-01",
        "Abstract": "Test-time data augmentation-averaging the predictions of a machine learning model across multiple augmented samples of data-is a widely used technique that improves the predictive performance. While many advanced learnable data augmentation techniques have emerged in recent years, they are focused on the training phase. Such techniques are not necessarily optimal for test-time augmentation and can be outperformed by a policy consisting of simple crops and flips. The primary goal of this paper is to demonstrate that test-time augmentation policies can be successfully learned too. We introduce greedy policy search (GPS), a simple but high-performing method for learning a policy of test-time augmentation. We demonstrate that augmentation policies learned with GPS achieve superior predictive performance on image classification problems, provide better in-domain uncertainty estimation, and improve the robustness to domain shift.",
        "DOI": "NA",
        "paper_author": "Molchanov D.",
        "affiliation_name": "Samsung AI Center",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "121905949",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Applying Machine Learning to Anomaly Detection in Car Insurance Sales",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Financial revenue, in the insurance sector, is systematically rising. This growth is, primarily, related to an increasing number of sold policies. While there exists a substantial body of work focused on discovering insurance fraud, e.g. related to car accidents, an open question remains, is it possible to capture incorrect data in the sales systems. Such erroneous data can result in financial losses. It may be caused by mistakes made by the sales person(s), but may be also a result of a fraud. In this work, research is focused on detecting anomalies in car insurance contracts. It is based on a dataset obtained from an actual insurance company, based in Poland. This dataset is thoroughly analysed, including preprocessing and feature selection. Next, a number of anomaly detection algorithms are applied to it, and their performance is compared. Specifically, clustering algorithms, dynamic classifier selection, and gradient boosted decision trees, are experimented with. Furthermore, the scenario where the size of the dataset is increasing is considered. It is shown that use of, broadly understood, machine learning has a realistic potential to facilitate anomaly detection, during insurance policy sales.",
        "DOI": "10.1007/978-3-030-66665-1_17",
        "paper_author": "Piesio M.",
        "affiliation_name": "Politechnika Warszawska",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60003675",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "A comparative study on the prediction model of COVID-19",
        "publication": "NA",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "With the large-scale outbreak of the COVID-19 epidemic in 2020, scientists and medical workers around the world made contributions to reducing the epidemic outbreak, curing patients, and developing vaccines against the epidemic. In response to the COVID-19 epidemic in various countries, many scholars have used machine learning and infectious disease dynamics models to make corresponding predictions for the subsequent development of the epidemic. In order to acquire a more accurate forecast of the global epidemic, this paper used the ARIMA model, Logistic model, SIR model, and improved SEIR model to make predictions. Moreover, we compared these models' benefits, drawbacks, and the degree of fit between the predicted data of various models and the real data to obtain a highly accurate model. Experiments have proved that among these models, the improved SEIR model can predict the future development trend of the global epidemic more precisely. In addition, the improved SEIR model also provides a certain theoretical basis for the government to issue a series of policies, prevention methods and control measures.",
        "DOI": "10.1109/ITAIC49862.2020.9338466",
        "paper_author": "Zhou Q.",
        "affiliation_name": "Anhui Polytechnic University",
        "affiliation_city": "Wuhu",
        "affiliation_country": "China",
        "affiliation_id": "60083914",
        "affiliation_state": "Anhui"
    },
    {
        "paper_title": "Visual navigation of wheeled mobile robots using deep reinforcement learning: Simulation to real-time implementation",
        "publication": "ASME 2020 Dynamic Systems and Control Conference, DSCC 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR), both in simulation and real-time implementation under dynamic and unknown environments. The policy gradient based asynchronous advantage actor critic (A3C), has been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of A3C algorithm to generate control commands for autonomous navigation of WMR. The initial A3C network was generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven visual navigation of Turlebot2 through DRL. The performance of A3C with multiple computation threads (4, 6, and 8) was simulated and compared in three simulation environments. The performance of A3C improved with number of threads. The trained model of A3C with 8 threads was implemented with online learning using Nvidia Jetson TX2 on-board Turtlebot2 for mapless navigation in different real-life environments. Details of the methodology, results of simulation and real-time implementation through transfer learning are presented along with recommendations for future work.",
        "DOI": "10.1115/DSCC2020-3279",
        "paper_author": "Nwaonumah E.",
        "affiliation_name": "Georgia Southern University",
        "affiliation_city": "Statesboro",
        "affiliation_country": "United States",
        "affiliation_id": "60020059",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Cutting the deployment costs of physics-based mpc in buildings by simulation-based imitation learning",
        "publication": "ASME 2020 Dynamic Systems and Control Conference, DSCC 2020",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "It has been shown that model predictive control (MPC) is a promising solution for energy-efficient building operations. However, the deployment of MPC in a large portion of the building stock has not been possible partially because of high installation costs. Every building is unique and requires a tailored MPC solution. The best performing solutions are often based on physics-based modeling, which is, however, computationally expensive and requires dedicated software. A promising direction that tackles this problem is to train a neural network-based optimal control policy to imitate the behavior of physics-based MPC from the simulation data generated offline. The neural networks give control actions that closely approximate those produced by physics-based MPC, but with a fraction of the computational and memory requirements and without the need for licensed software. The main advantage of the proposed approach stems from simple evaluation at execution time, leading to low computational footprints and easy deployment on embedded HW platforms. In the case study, we present the energy savings potential of physics-based MPC applied to an office building in Belgium. We demonstrate how neural network approximators can be used to cut the implementation and maintenance costs of MPC deployment without compromising performance. We also critically assess the presented approach by pointing out the remaining challenges and open research questions.",
        "DOI": "10.1115/DSCC2020-3118",
        "paper_author": "Drgona J.",
        "affiliation_name": "Pacific Northwest National Laboratory",
        "affiliation_city": "Richland",
        "affiliation_country": "United States",
        "affiliation_id": "60023471",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Achieving improved personalization and energy efficiency in cohabited work-spaces through data-driven predictive control",
        "publication": "ASME 2020 Dynamic Systems and Control Conference, DSCC 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "This paper studies the problem of indoor zone temperature control in shared work-spaces equipped with heterogeneous heating and cooling sources with the goal of increased energy savings and environment personalization. We consider two scenarios to assess the performance of our control strategies. The first scenario requires time-bound pre-cooling/pre-heating of a shared space in preparation for a scheduled activity (Scenario A). The second scenario considers a cohabited work-space where occupants have different temperature preferences (Scenario B). Utilizing an on-campus smart conference room (SCR) as a testbed, we use data-driven model learning to establish a relationship between the room's heating, ventilation and cooling (HVAC) operations and the zone temperatures. Next, we use a model predictive control (MPC)-based approach to achieve a desired average temperature while minimizing power consumption (for Scenario A) and minimize the thermal discomfort experienced by individuals based on their temperature preferences (for Scenario B). The experimental results show that for Scenario A, the proposed control policy can save a significant amount of energy and achieve the desired mean temperature in the space fairly accurately. We further note that for Scenario B, the control scheme can achieve a significant spatial differentiation in temperature towards satisfying the occupants' thermal preferences.",
        "DOI": "10.1115/DSCC2020-3229",
        "paper_author": "Naqvi S.A.R.",
        "affiliation_name": "Rensselaer Polytechnic Institute",
        "affiliation_city": "Troy",
        "affiliation_country": "United States",
        "affiliation_id": "60025534",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "6th International Conference on Machine Learning, Optimization, and Data Science, LOD 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 116 papers. The special focus in this conference is on Machine Learning, Optimization, and Data Science. The topics include: A Generalized Quadratic Loss for SVM and Deep Neural Networks; reliable Solution of Multidimensional Stochastic Problems Using Metamodels; understanding Production Process Productivity in the Glass Container Industry: A Big Data Approach; random Forest Parameterization for Earthquake Catalog Generation; convolutional Neural Network and Stochastic Variational Gaussian Process for Heating Load Forecasting; Explainable AI as a Social Microscope: A Case Study on Academic Performance; policy Feedback in Deep Reinforcement Learning to Exploit Expert Knowledge; gradient Bias to Solve the Generalization Limit of Genetic Algorithms Through Hybridization with Reinforcement Learning; relational Bayesian Model Averaging for Sentiment Analysis in Social Networks; variance Loss in Variational Autoencoders; wasserstein Embeddings for Nonnegative Matrix Factorization; machine Learning Application to Family Business Status Classification; investigating the Compositional Structure of Deep Neural Networks; optimal Scenario-Tree Selection for Multistage Stochastic Programming; deep 3D Convolution Neural Network for Alzheimer’s Detection; combinatorial Reliability-Based Optimization of Nonlinear Finite Element Model Using an Artificial Neural Network-Based Approximation; CMAC: Clustering Class Association Rules to Form a Compact and Meaningful Associative Classifier; GPU Accelerated Data Preparation for Limit Order Book Modeling; can Big Data Help to Predict Conditional Stock Market Volatility? An Application to Brexit; importance Weighting of Diagnostic Trouble Codes for Anomaly Detection; Identifying Key miRNA–mRNA Regulatory Modules in Cancer Using Sparse Multivariate Factor Regression; a Krill Herd Algorithm for the Multiobjective Energy Reduction Multi-Depot Vehicle Routing Problem; using Hessians as a Regularization Technique; preface.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Behavioral Analysis to Detect Social Spammer in Online Social Networks (OSNs)",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The faster and regular usage of Web 2.0 technologies like Online Social Networks (OSNs) addicted to millions of users worldwide. This popularity made target for spammers and fake users to spread phishing attack, viruses, false news, pornography and unwanted advertisements like URLs, images and videos etc. The present paper proposes a behavioral analysis-based framework for classifying spam contents in real time by aggregating machine learning techniques and genetic algorithm. The main procedure of the work is, firstly based on social networks spam policy, novel profile based and content-based features are proposed to facilitate spam detection. Secondly, accumulate a dataset from various social networks like Facebook, Twitter, and Instagram including spam and non-spam profiles. For suitable feature selections, we have used a genetic algorithm and various classifiers for decision making. In order to attest the effectiveness of our proposed framework, we have compared with existing techniques.",
        "DOI": "10.1007/978-3-030-66046-8_26",
        "paper_author": "Sahoo S.R.",
        "affiliation_name": "National Institute of Technology Kurukshetra",
        "affiliation_city": "Kurukshetra",
        "affiliation_country": "India",
        "affiliation_id": "60000674",
        "affiliation_state": "HR"
    },
    {
        "paper_title": "Single-Agent Policies for the Multi-Agent Persistent Surveillance Problem via Artificial Heterogeneity",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Modelling and planning as well as Machine Learning techniques such as Reinforcement Learning are often difficult in multi-agent problems. With increasing numbers of agents the decision space grows rapidly and is made increasingly complex through interacting agents. This paper is motivated by the question of if it is possible to train single-agent policies in isolation and without the need for explicit cooperation or coordination still successfully deploy them to multi-agent scenarios. In particular we look at the multi-agent Persistent Surveillance Problem (MAPSP), which is the problem of using a number of agents to continually visit and re-visit areas of a map to maximise a metric of surveillance. We outline five distinct single-agent policies to solve the MAPSP: Reinforcement Learning (DDPG); Neuro-Evolution (NEAT); a Gradient Descent (GD) heuristic; a random heuristic; and a pre-defined ‘ploughing pattern’ (Trail). We will compare the performance and scalability of these single-agent policies to the Multi-Agent PSP. Importantly, in doing so we will demonstrate an emergent property which we call the Homogeneous-Policy Convergence Cycle (HPCC), whereby agents following homogeneous policies can get stuck together, continuously repeating the same action as other agents, significantly impacting performance. This paper will show that just a small amount of noise, at the state or action level, is sufficient to solve the problem, essentially creating artificially-heterogeneous policies for the agents.",
        "DOI": "10.1007/978-3-030-66412-1_16",
        "paper_author": "Kent T.",
        "affiliation_name": "University of Bristol",
        "affiliation_city": "Bristol",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60020650",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Novel Hybrid Forecasting Model Based on Time Series",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The forecast of cigarette sales is crucial for tobacco companies to formulate long term development policies and optimize the inventory control system. Considering the long-term trend and seasonal fluctuation characteristics of cigarette sales sequence, a hybrid method including wavelet decomposition, auto-regression and fusion of several intelligent algorithms is proposed. The original time series of cigarette sales are first decomposed into two components of low-frequency component and high-frequency component which simulate overall trends and seasonal fluctuation, by using wavelet decomposition. Then they are predicted by auto-regression and fusion of several intelligent algorithms, and the final result is the combination of the predictions of the two components. The experimental results show that the hybrid forecasting model performed well, and its minimum MAPE (mean absolute percentage error) is 3.58%. Compared with BP (back-propagation neural network), SVM (support vector machine), and ELM (extreme learning machine) algorithms, the hybrid model proposed in this paper decreases MAPE by 2.01%, 1.58%, and 0.93%, while the stability of the model increased by 16.92%, 22.85%, and 56.09%, respectively. The proposed hybrid model provides a valid way for improving the accuracy and stability of time series forecasting.",
        "DOI": "10.1007/978-981-33-6378-6_35",
        "paper_author": "Pu Y.",
        "affiliation_name": "China Jiliang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60017080",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "A Systematic Frame Work Using Machine Learning Approaches in Supply Chain Forecasting",
        "publication": "Learning and Analytics in Intelligent Systems",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Forecasting is an important study in the field of Supply Chain and Logistics for Operations Management. Based on a study a systematic framework has been worked and has been proposed for the same. Artificial Neural Network has been into this field and has been utilized for an efficient way to forecast and reduce errors marginally. The purpose of such a systematic approach using the proposed architecture is to reduce inventory holdings which shall largely account for important decision-making policies in the future.",
        "DOI": "10.1007/978-3-030-39033-4_15",
        "paper_author": "Prahathish K.",
        "affiliation_name": "SASTRA Deemed University",
        "affiliation_city": "Thanjavur",
        "affiliation_country": "India",
        "affiliation_id": "60005147",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "6th International Conference on Machine Learning, Optimization, and Data Science, LOD 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 116 papers. The special focus in this conference is on Machine Learning, Optimization, and Data Science. The topics include: A Generalized Quadratic Loss for SVM and Deep Neural Networks; reliable Solution of Multidimensional Stochastic Problems Using Metamodels; understanding Production Process Productivity in the Glass Container Industry: A Big Data Approach; random Forest Parameterization for Earthquake Catalog Generation; convolutional Neural Network and Stochastic Variational Gaussian Process for Heating Load Forecasting; Explainable AI as a Social Microscope: A Case Study on Academic Performance; policy Feedback in Deep Reinforcement Learning to Exploit Expert Knowledge; gradient Bias to Solve the Generalization Limit of Genetic Algorithms Through Hybridization with Reinforcement Learning; relational Bayesian Model Averaging for Sentiment Analysis in Social Networks; variance Loss in Variational Autoencoders; wasserstein Embeddings for Nonnegative Matrix Factorization; machine Learning Application to Family Business Status Classification; investigating the Compositional Structure of Deep Neural Networks; optimal Scenario-Tree Selection for Multistage Stochastic Programming; deep 3D Convolution Neural Network for Alzheimer’s Detection; combinatorial Reliability-Based Optimization of Nonlinear Finite Element Model Using an Artificial Neural Network-Based Approximation; CMAC: Clustering Class Association Rules to Form a Compact and Meaningful Associative Classifier; GPU Accelerated Data Preparation for Limit Order Book Modeling; can Big Data Help to Predict Conditional Stock Market Volatility? An Application to Brexit; importance Weighting of Diagnostic Trouble Codes for Anomaly Detection; Identifying Key miRNA–mRNA Regulatory Modules in Cancer Using Sparse Multivariate Factor Regression; a Krill Herd Algorithm for the Multiobjective Energy Reduction Multi-Depot Vehicle Routing Problem; using Hessians as a Regularization Technique; preface.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Optimal Scenario-Tree Selection for Multistage Stochastic Programming",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "We propose an algorithmic strategy for Multistage Stochastic Optimization, to learn a decision policy able to provide feasible and optimal decisions for every possible value of the random variables of the problem. The decision policy is built using a scenario-tree based solution combined with a regression model able to provide a decision also for those scenarios not included in the tree. For building an optimal policy, an iterative scenario generation procedure is used which selects through a Bayesian Optimization process the more informative scenario-tree. Some preliminary numerical tests show the validity of such an approach.",
        "DOI": "10.1007/978-3-030-64583-0_31",
        "paper_author": "Galuzzi B.G.",
        "affiliation_name": "Università degli Studi di Milano-Bicocca",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60012306",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Learning to stop while learning to predict",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "There is a recent surge of interest in designing deep architectures based on the update steps in traditional algorithms, or learning neural networks to improve and replace traditional algorithms. While traditional algorithms have certain stopping criteria for outputting results at different iterations, many algorithm-inspired deep models are restricted to a \"fixed-depth\" for all inputs. Similar to algorithms, the optimal depth of a deep architecture may be different for different input instances, either to avoid \"over-thinking\", or because we want to compute less for operations converged already. In this paper, we tackle this varying depth problem using a steerable architecture, where a feed-forward deep model and a variational stopping policy are learned together to sequentially determine the optimal number of layers for each input instance. Training such architecture is very challenging. We provide a variational Bayes perspective and design a novel and effective training procedure which decomposes the task into an oracle model learning stage and an imitation stage. Experimentally, we show that the learned deep model along with the stopping policy improves the performances on a diverse set of tasks, including learning sparse recovery, few-shot meta learning, and computer vision tasks.",
        "DOI": "NA",
        "paper_author": "Chen X.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "OrganITE: Optimal transplant donor organ offering using an individual treatment effect",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "Transplant-organs are a scarce medical resource. The uniqueness of each organ and the patients’ heterogeneous responses to the organs present a unique and challenging machine learning problem. In this problem there are two key challenges: (i) assigning each organ \"optimally\" to a patient in the queue; (ii) accurately estimating the potential outcomes associated with each patient and each possible organ. In this paper, we introduce OrganITE, an organ-to-patient assignment methodology that assigns organs based not only on its own estimates of the potential outcomes but also on organ scarcity. By modelling and accounting for organ scarcity we significantly increase total life years across the population, compared to the existing greedy approaches that simply optimise life years for the current organ available. Moreover, we propose an individualised treatment effect model capable of addressing the high dimensionality of the organ space. We test our method on real and simulated data, resulting in as much as an additional year of life expectancy as compared to existing organ-to-patient policies.",
        "DOI": "NA",
        "paper_author": "Berrevoets J.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Policy Feedback in Deep Reinforcement Learning to Exploit Expert Knowledge",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In Deep Reinforcement Learning (DRL), agents learn by sampling transitions from a batch of stored data called Experience Replay. In most DRL algorithms, the Experience Replay is filled by experiences gathered by the learning agent itself. However, agents that are trained completely Off-Policy, based on experiences gathered by behaviors that are completely decoupled from their own, cannot learn to improve their own policies. In general, the more algorithms train agents Off-Policy, the more they become prone to divergence. The main contribution of this research is the proposal of a novel learning framework called Policy Feedback, used both as a tool to leverage offline-collected expert experiences, and also as a general framework to improve the understanding of the issues behind Off-Policy Learning.",
        "DOI": "10.1007/978-3-030-64583-0_25",
        "paper_author": "Espositi F.",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60023256",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Proceedings of the 13th IADIS International Conference ICT, Society and Human Beings 2020, ICT 2020 and Proceedings of the 6th IADIS International Conference Connected Smart Cities 2020, CSC 2020 and Proceedings of the 17th IADIS International Conference Web Based Communities and Social Media 2020, WBC 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020",
        "publication": "Proceedings of the 13th IADIS International Conference ICT, Society and Human Beings 2020, ICT 2020 and Proceedings of the 6th IADIS International Conference Connected Smart Cities 2020, CSC 2020 and Proceedings of the 17th IADIS International Conference Web Based Communities and Social Media 2020, WBC 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 40 papers. The topics discussed include: managing millennials as outsourced information technology professionals: a systematic review; estimation of social capital based on user behavior information on regional electronic coupon; creation of a publicly accessible resource for increasing the volume of freely distributed medical datasets; a collective awareness platform for missing children investigation and rescue; you just reminded me – I’m human!: viewing or interacting with robots increases human conformity to other humans; designing for transitions in rural transport; counter terrorism finance by detecting money laundering hidden networks using unsupervised machine learning algorithm; the role of sustainable transportation in the public health improvement; evidence-driven policy making using heterogeneous sources of data - the case of a control parking system; and virtual brand community influence on brand loyalty: customer relationships and trust mediators.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Towards the trustworthy AI: Insights from the regulations on data protection and information security",
        "publication": "Medijska Istrazivanja",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "After decades of theoretical deliberations, the rapid development of advanced information technology has allowed machine learning as a first practical step towards artificial intelligence to enter widespread commercial and government use. The transition into a post-industrial, information society has revealed the value of data as an important resource whose processing is the basis of the new innovative information society services. The European Union has enacted several important regulations and directives in the recent past to protect the recognized fundamental rights of individuals and to regulate the obligations of service providers to ensure safe and secure processing. The Charter of Fundamental Rights as the legal basis of the European system of human rights contains significant checks and limitations to the effect and purpose of future EU AI regulation. Whenever and however this regulation is adopted, it will need to comply with and contain existing European legal standards regarding the fundamental rights of individuals in the EU. The European Commission’s ethical guidelines establish ethical principles based on the recognized fundamental rights that future AI systems need to adhere to in order to be recognized as trustworthy. The purpose of this paper is to present and analyse the mechanisms present in existing European regulations in the fields of data protection and information security and in the European Union documents regarding the future artificial intelligence regulation and to offer suggestions for future regulations. The research methodology includes a comparative analysis of available regulations and policy documents of the European Union, national laws, legal literature, and other sources.",
        "DOI": "10.22572/mi.26.2.1",
        "paper_author": "Katulić T.",
        "affiliation_name": "University of Zagreb, Faculty of Law",
        "affiliation_city": "Zagreb",
        "affiliation_country": "Croatia",
        "affiliation_id": "60159857",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Interactive model for assessing mangrove health, ecosystem services, policy consequences, and satellite design in Rio de Janeiro using earth observation data",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "There is an increasing need for tools to translate earth observation data into societally relevant metrics to inform human decision-making. To address this need, we present a multi-disciplinary, interactive modeling framework to advance ecological forecasting and policymaking using earth observation data. The Environment-Vulnerability-Decision-Technology (EVDT) Modeling Framework will integrate four models into one tool that can be adapted to specific applications; the four models address the following: earth science models of the Environment: Human Vulnerability and Societal Impact; Human Behavior and Decision-Making; and Technology Design for earth observation systems including satellites, airborne platforms and in-situ sensors The capabilities provided by this framework will improve the management of earth observation and socioeconomic data in a format usable by non-experts, while harnessing cloud computing, machine learning, economic analysis, complex systems modeling, and model-based systems engineering. This paper presents a prototype that demonstrates the viability of the framework via a case study: the mangrove forests in the Guaratiba area of Rio de Janeiro. These mangroves are vulnerable due to urbanization and rising sea levels. They provide a variety of ecosystem services, including serving as a mechanism for carbon sequestration, supporting subsistence fishing, preventing coastal erosion, and attracting an ecotourism industry. The case study of mangrove and community health in Rio de Janeiro demonstrates all four model components. The Environment Model builds upon work by biospheric scientists Fatoyinbo and Lagomasino to use earth observation data, cloud computing, and machine learning to track mangrove extent, health, and vulnerability over time for a 600 km2 area, as well as work by the ESPAÇO research group at the Federal University of Rio de Janeiro on the local mangrove ecosystem. To build the Human Vulnerability and Societal Impact Model, we are collaborating with ecosystem services economist Suhyun Jung to explain how policies impact mangrove health and how mangroves impact socioeconomic wellbeing. To create the Human Decision Making Model, we have partnered with the Pereira Passos Institute (the data science office of the Rio de Janeiro municipal government) to understand the policy history and socioeconomic factors. The Technology Model accounts for the types of data collection used by policy makers since 1975. Through such collaborations, we are able to build an integrated, interactive decision support tool that policymakers can use to assess mangrove health, ecosystem services value, and policy consequences. The model helps answer such questions as: (a) What is the state of the mangroves over time? (b) How are human communities impacting the mangroves? (c) what is the value of the mangrove ecosystem services to human communities? and (d) what policies can improve human and mangrove outcomes? This case study is demonstrative of the viability of a similar approach for ecosystems around the world.",
        "DOI": "NA",
        "paper_author": "Reid J.B.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Developmental reinforcement learning of control policy of a quadcopter uav with thrust vectoring rotors",
        "publication": "ASME 2020 Dynamic Systems and Control Conference, DSCC 2020",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we present a novel developmental reinforcement learning-based controller for a quadcopter with thrust vectoring capabilities. This multirotor UAV design has tilt-enabled rotors. It utilizes the rotor force magnitude and direction to achieve the desired state during flight. The control policy of this robot is learned using the policy transfer from the learned controller of the quadcopter (comparatively simple UAV design without thrust vectoring). This approach allows learning a control policy for systems with multiple inputs and multiple outputs. The performance of the learned policy is evaluated by physics-based simulations for the tasks of hovering and way-point navigation. The flight simulations utilize a flight controller based on reinforcement learning without any additional PID components. The results show faster learning with the presented approach as opposed to learning the control policy from scratch for this new UAV design created by modifications in a conventional quadcopter, i.e., the addition of more degrees of freedom (4-actuators in conventional quadcopter to 8-actuators in tilt-rotor quadcopter). We demonstrate the robustness of our learned policy by showing the recovery of the tilt-rotor platform in the simulation from various non-static initial conditions in order to reach a desired state. The developmental policy for the tilt-rotor UAV also showed superior fault tolerance when compared with the policy learned from the scratch. The results show the ability of the presented approach to bootstrap the learned behavior from a simpler system (lower-dimensional action-space) to a more complex robot (comparatively higher-dimensional action-space) and reach better performance faster.",
        "DOI": "10.1115/DSCC2020-3319",
        "paper_author": "Deshpande A.M.",
        "affiliation_name": "College of Engineering and Applied Science",
        "affiliation_city": "Cincinnati",
        "affiliation_country": "United States",
        "affiliation_id": "60142887",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Using the lstm network to forecthe demand for hard coal",
        "publication": "Gospodarka Surowcami Mineralnymi / Mineral Resources Management",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "Securing the certainty of supplies of the necessary minimum energy in each country is a basic condition for the energy security of the state and its citizens. The concept of energy security combines several aspects at the same time, as it can be considered in terms of the availability of own energy resources, it concerns technical aspects related to technical infrastructure, as well as political aspects related to the management and diversification of energy supplies. Another aspect of the issue of energy security is the environmental perspective, which is now becoming a priority in the light of the adopted objectives of the European Union’s energy policy. The restrictive requirements for reducing greenhouse gas emissions and increasing the required level of renewable energy sources in the energy balance of the Member States is becoming a challenge for economies that use fossil fuels to a large extent in the raw material structure, including Poland. Poland is the largest producer of hard coal in the European Union and hard coal is a strategic raw material as it satisfies about 50% of the country’s energy demand. In this context, the main goal of the article was to determine the future sale of hard coal by 2030 in relation to environmental regulations introduced in the energy sector. For this purpose, a mathematical model with a 95% confidence interval was developed using artificial LSTM neural networks, which belong to deep learning machine learning techniques, which reflects the key relationships between hard coal mining and the assumptions adopted in the National Energy and Climate Plan for the years 2021–2030 (NECP).",
        "DOI": "10.24425/gsm.2020.133945",
        "paper_author": "Manowska A.",
        "affiliation_name": "Silesian University of Technology",
        "affiliation_city": "Gliwice",
        "affiliation_country": "Poland",
        "affiliation_id": "60009081",
        "affiliation_state": "Silesian"
    },
    {
        "paper_title": "COLREG-compliant collision avoidance for unmanned surface vehicle using deep reinforcement learning",
        "publication": "IEEE Access",
        "citied_by": "64",
        "cover_date": "2020-01-01",
        "Abstract": "Path Following and Collision Avoidance, be it for unmanned surface vessels or other autonomous vehicles, are two fundamental guidance problems in robotics. For many decades, they have been subject to academic study, leading to a vast number of proposed approaches. However, they have mostly been treated as separate problems, and have typically relied on non-linear first-principles models with parameters that can only be determined experimentally. The rise of deep reinforcement learning in recent years suggests an alternative approach: end-to-end learning of the optimal guidance policy from scratch by means of a trial-and-error based approach. In this article, we explore the potential of Proximal Policy Optimization, a deep reinforcement learning algorithm with demonstrated state-of-the-art performance on Continuous Control tasks, when applied to the dual-objective problem of controlling an autonomous surface vehicle in a COLREGs compliant manner such that it follows an a priori known desired path while avoiding collisions with other vessels along the way. Based on high-fidelity elevation and AIS tracking data from the Trondheim Fjord, an inlet of the Norwegian sea, we evaluate the trained agent's performance in challenging, dynamic real-world scenarios where the ultimate success of the agent rests upon its ability to navigate nonuniform marine terrain while handling challenging, but realistic vessel encounters.",
        "DOI": "10.1109/ACCESS.2020.3022600",
        "paper_author": "Meyer E.",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway",
        "affiliation_id": "60013141",
        "affiliation_state": "Trondelag"
    },
    {
        "paper_title": "Multi-agent Actor-Critic Reinforcement Learning Based In-network Load Balance",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "21",
        "cover_date": "2020-01-01",
        "Abstract": "Load balancing is a difficult online decision-making problem in the current network. Recently, with the development of the programmable data-plane, it is feasible to perform flexibly load balance directly inside the network. This in-network load balance scheme can quickly adapt to the volatility of network traffic. However, previous in-network solutions are largely relying on the manual process. Inspired by recent successes in applying machine learning in online control, automating the in-network load balance process is thus appealing. But as a distributed control system, it behooves us to ask the critical question: 'Can the distributed switches learn globally optimal scheduling policy and still be deployed in a distributed fashion to allow rapid reaction in real-time?' To tackle this question, we adopt a centralized learning and distributed execution framework and propose a multi-agent actor-critic reinforcement learning algorithm in this paper. The centralized 'critic' is reinforced with the global network state and joint actions of all agents to ease the training process whilst distributed switches can take actions relaying on their local observations. In addition, a baseline scheme is introduced to solve the credit assignment problem in the multi-agent system. The extensive simulations are conducted to evaluate our proposed algorithm in comparison to state-of-the-art schemes.",
        "DOI": "10.1109/GLOBECOM42002.2020.9322277",
        "paper_author": "Mai T.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Reinforcement Learning for Minimizing Age of Information under Realistic Physical Dynamics",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, the problem of minimizing the weighted sum of age of information (AoI) and total energy consumption of Internet of Things (IoT) devices is studied. In particular, each IoT device monitors a physical process that follows nonlinear dynamics. As the dynamic of the physical process varies over time, each device must sample the real-time status of the physical system and send the status information to a base station (BS) so as to monitor the physical process. The dynamics of the realistic physical process will influence the sampling frequency and status update scheme of each device. In particular, as the physical process varies rapidly, the sampling frequency of each device must be increased to capture these physical dynamics. Meanwhile, changes in the sampling frequency will also impact the energy usage of the device. Thus, it is necessary to determine a subset of devices to sample the physical process at each time slot so as to accurately monitor the dynamics of the physical process using minimum energy. This problem is formulated as an optimization problem whose goal is to minimize the weighted sum of AoI and total device energy consumption. To solve this problem, a machine learning framework based on the repeated update Q-learning (RUQL) algorithm is proposed. The proposed method enables the BS to overcome the biased action selection problem (e.g., an agent always takes a subset of actions while ignoring other actions), and hence, dynamically and quickly finding a device sampling and status update policy so as to minimize the sum of AoI and energy consumption of all devices. Simulations with real data of PM 2.5 pollution in Beijing from the Center for Statistical Science at Peking University show that the proposed algorithm can reduce the sum of AoI by up to 26.9% compared to the conventional Q-learning method.",
        "DOI": "10.1109/GLOBECOM42002.2020.9322139",
        "paper_author": "Wang S.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Learning-based Load Balancing Handover in Mobile Millimeter Wave Networks",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Millimeter-wave (mmWave) communication is a promising solution to the high data rate demands in the upcoming 5G and beyond communication networks. When it comes to supporting seamless connectivity in mobile scenarios, resource and handover management are two of the main challenges in mmWave networks. In this paper, we address these two problems jointly and propose a learning-based load balancing handover in multi-user mobile mmWave networks. Our handover algorithm selects a backup base station and allocates the resource to maximize the sum rate of all the users while ensuring a target rate threshold and preventing excessive handovers. We model the user association as a non-convex optimization problem. Then, by applying a deep deterministic policy gradient (DDPG) method, we approximate the solution of the optimization problem. Through simulations, we show that our proposed algorithm minimizes the number of the events where a user's rate is less than its minimum rate requirement and minimizes the number of handovers while increasing the sum rate of all users.",
        "DOI": "10.1109/GLOBECOM42002.2020.9322601",
        "paper_author": "Khosravi S.",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60002014",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "FormulaZero: Distributionally robust online adaptation via offline population synthesis",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Balancing performance and safety is crucial to deploying autonomous vehicles in multi-agent environments. In particular, autonomous racing is a domain that penalizes safe but conservative policies, highlighting the need for robust, adaptive strategies. Current approaches either make simplifying assumptions about other agents or lack robust mechanisms for online adaptation. This work makes algorithmic contributions to both challenges. First, to generate a realistic, diverse set of opponents, we develop a novel method for self-play based on replica-exchange Markov chain Monte Carlo. Second, we propose a distributionally robust bandit optimization procedure that adaptively adjusts risk aversion relative to uncertainty in beliefs about opponents' behaviors. We rigorously quantify the tradeoffs in performance and robustness when approximating these computations in real-time motion-planning, and we demonstrate our methods experimentally on autonomous vehicles that achieve scaled speeds comparable to Formula One racecars.",
        "DOI": "NA",
        "paper_author": "Sinha A.",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60012708",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "From the gut? Questions on artificial intelligence and music",
        "publication": "Queen Mary Journal of Intellectual Property",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "AI applications are manifold in the music industry, both as tools assisting composers in creating and as music generating machines. AI applications assisting composers are widely used, for example in providing drum sequences or mastering services. AI-generated music is mainly used as production music, for example in synchronizing YouTube videos. Copyright implications relate initially to the use of existing works to train the computer, and secondly to the copyright protection for AI-generated musical works or sound record-ings. This article firstly looks at the copyright acts involved in the training process in the EU, UK and US as well as potentially applicable exceptions. Secondly, it addresses the copyright position of AI-generated music and in particular the legal requirement of human creativity as the basis of copyright protection for musical works. The situation for sound recordings might be different.",
        "DOI": "10.4337/qmjip.2020.04.05",
        "paper_author": "Koempel F.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ubiquitous distributed deep reinforcement learning at the edge: Analyzing Byzantine agents in discrete action spaces",
        "publication": "Procedia Computer Science",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The integration of edge computing in next-generation mobile networks is bringing low-latency and high-bandwidth ubiquitous connectivity to a myriad of cyber-physical systems. This will further boost the increasing intelligence that is being embedded at the edge in various types of autonomous systems, where collaborative machine learning has the potential to play a significant role. This paper discusses some of the challenges in multi-agent distributed deep reinforcement learning that can occur in the presence of byzantine or malfunctioning agents. As the simulation-to-reality gap gets bridged, the probability of malfunctions or errors must be taken into account. We show how wrong discrete actions can significantly affect the collaborative learning effort. In particular, we analyze the effect of having a fraction of agents that might perform the wrong action with a given probability. We study the ability of the system to converge towards a common working policy through the collaborative learning process based on the number of experiences from each of the agents to be aggregated for each policy update, together with the fraction of wrong actions from agents experiencing malfunctions. Our experiments are carried out in a simulation environment using the Atari testbed for the discrete action spaces, and advantage actor-critic (A2C) for the distributed multi-agent training.",
        "DOI": "10.1016/j.procs.2020.10.043",
        "paper_author": "Zhao W.",
        "affiliation_name": "Turun yliopisto",
        "affiliation_city": "Turku",
        "affiliation_country": "Finland",
        "affiliation_id": "60006876",
        "affiliation_state": "Southwest Finland"
    },
    {
        "paper_title": "Automated Lane Change Strategy using Proximal Policy Optimization-based Deep Reinforcement Learning",
        "publication": "IEEE Intelligent Vehicles Symposium, Proceedings",
        "citied_by": "93",
        "cover_date": "2020-01-01",
        "Abstract": "Lane-change maneuvers are commonly executed by drivers to follow a certain routing plan, overtake a slower vehicle, adapt to a merging lane ahead, etc. However, improper lane change behaviors can be a major cause of traffic flow disruptions and even crashes. While many rule-based methods have been proposed to solve lane change problems for autonomous driving, they tend to exhibit limited performance due to the uncertainty and complexity of the driving environment. Machine learning-based methods offer an alternative approach, as Deep reinforcement learning (DRL) has shown promising success in many application domains including robotic manipulation, navigation, and playing video games. However, applying DRL to autonomous driving still faces many practical challenges in terms of slow learning rates, sample inefficiency, and safety concerns. In this study, we propose an automated lane change strategy using proximal policy optimization-based deep reinforcement learning, which shows great advantages in learning efficiency while still maintaining stable performance. The trained agent is able to learn a smooth, safe, and efficient driving policy to make lane-change decisions (i.e. when and how) in challenging situation such as dense traffic scenarios. The effectiveness of the proposed policy is validated by using metrics of task success rate and collision rate. The simulation results demonstrate the lane change maneuvers can be efficiently learned and executed in a safe, smooth and efficient manner.",
        "DOI": "10.1109/IV47402.2020.9304668",
        "paper_author": "Ye F.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Efficient policy learning from surrogate-loss classification reductions",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Recent work on policy learning from observational data has highlighted the importance of efficient policy evaluation and has proposed reductions to weighted (cost-sensitive) classification. However, efficient policy evaluation need not yield efficient estimation of optimal policy parameters. We consider the estimation problem given by a weighted surrogate-loss classification reduction of policy learning with any score function-either direct, inverse-propensity weighted, or doubly robust-And show that, under a correct specification assumption, the weighted classification formulation need not be efficient for policy parameters. We draw a contrast to actual (possibly weighted) binary classification, where correct specification implies a parametric model, while for policy learning it only implies a semiparametric model, and we show that efficiency in optimal parameter estimation implies optimal regret. In light of this, we instead propose an estimation approach based on the generalized method of moments, which is efficient for the policy parameters. We propose a particular method based on recent developments on solving moment problems using neural networks and demonstrate the efficiency and regret benefits of this method empirically.",
        "DOI": "NA",
        "paper_author": "Bennett A.",
        "affiliation_name": "Cornell Tech",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60104837",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "A decision trees-based knowledge mining approach for controlling a complex production system",
        "publication": "Procedia Manufacturing",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "In this study, we use decision trees constructed by learning-with-supervision techniques for representing the best policies found by a Reinforcement Learning algorithm applied to an optimization problem of a complex production system. Until now, the relative scientific literature includes studies that mainly propose dynamic programming-based approaches for treating such kind of combinatorial problems. Decision trees are used to approximate functions of multiple variables with discrete values. In this case the “leaves” of the tree correspond to the set of function values while the non-terminal nodes to its independent variables. In the present research, the parameters of the optimization problem and the corresponding optimal policies found by the Reinforcement Learning algorithm applied, will be used as the training data set. Representing the best found policies using decision trees will support more effective qualitative analysis and further understanding of their properties.",
        "DOI": "10.1016/j.promfg.2020.10.200",
        "paper_author": "Koulinas G.",
        "affiliation_name": "Democritus University of Thrace",
        "affiliation_city": "Komotini",
        "affiliation_country": "Greece",
        "affiliation_id": "60030988",
        "affiliation_state": "Eastern Macedonia and Thrace"
    },
    {
        "paper_title": "18th International Conference on Metal Forming, Metal Forming 2020",
        "publication": "Procedia Manufacturing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 252 papers. The topics discussed include: a collaborative robot cell for random bin-picking based on deep learning policies and a multi-gripper switching strategy; a machine learning approach for collaborative robot smart manufacturing inspection for quality control systems; an integrated and interoperable automation ML-based platform for the robotic process of metal additive manufacturing; cognitive grasping system: a grasping solution for industrial robotic manipulation using convolutional neural network; collaborative robot and mixed reality assisted microgravity assembly for large space mechanism; collaborative robot based architecture to train flexible automated disassembly systems for critical materials; and concept for virtual safety training system for human-robot collaboration.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Inferring learning rules from animal decision-making",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "How do animals learn? This remains an elusive question in neuroscience. Whereas reinforcement learning often focuses on the design of algorithms that enable artificial agents to efficiently learn new tasks, here we develop a modeling framework to directly infer the empirical learning rules that animals use to acquire new behaviors. Our method efficiently infers the trial-to-trial changes in an animal’s policy, and decomposes those changes into a learning component and a noise component. Specifically, this allows us to: (i) compare different learning rules and objective functions that an animal may be using to update its policy; (ii) estimate distinct learning rates for different parameters of an animal’s policy; (iii) identify variations in learning across cohorts of animals; and (iv) uncover trial-to-trial changes that are not captured by normative learning rules. After validating our framework on simulated choice data, we applied our model to data from rats and mice learning perceptual decision-making tasks. We found that certain learning rules were far more capable of explaining trial-to-trial changes in an animal’s policy. Whereas the average contribution of the conventional REINFORCE learning rule to the policy update for mice learning the International Brain Laboratory’s task was just 30%, we found that adding baseline parameters allowed the learning rule to explain 92% of the animals’ policy updates under our model. Intriguingly, the best-fitting learning rates and baseline values indicate that an animal’s policy update, at each trial, does not occur in the direction that maximizes expected reward. Understanding how an animal transitions from chance-level to high-accuracy performance when learning a new task not only provides neuroscientists with insight into their animals, but also provides concrete examples of biological learning algorithms to the machine learning community.",
        "DOI": "NA",
        "paper_author": "Ashwood Z.C.",
        "affiliation_name": "Princeton University",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States",
        "affiliation_id": "60003269",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Building the uncertainty indicator regarding adjustment of the Bank of Russiaâs monetary policy relying on news sources",
        "publication": "Business Informatics",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Text analysis with machine learning support can be implemented for studying expertsâ relations to the Bank of Russia. To reach macroeconomic goals, the communication policy of the bank must be predictable and trustworthy. Surveys addressing this theme are still insufficient compare to the theoretical studies on the subject of other bank tools. The goal of this research is to analyze the perception of uncertainty by economic agents. For that purpose, we built an uncertainty indicator based on news sources from the Internet and on textual analysis. The dynamics of the indicator reflect unexpected statements of the Bank of Russia and events affecting monetary policy. Financial theory links monetary policy and stock prices, so we used this fact to examine the impact of the uncertainty indicator on the MOEX and RTS indices. We tested the hypothesis that our indicator is significant in GARCH models for chosen financial series. We found out several specifications in which our indicator is significant. Among the specifications considered, the uncertainty indicator contributes the most to explaining variances of the RTS index. The obtained uncertainty indicator can be used for forecasting of different macroeconomic variables.",
        "DOI": "10.17323/2587-814X.2020.4.62.75",
        "paper_author": "Golovanova E.A.",
        "affiliation_name": "Russian Presidential Academy of National Economy and Public Administration",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60107804",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessing job market dynamics using elk stack",
        "publication": "Ibero-American WWW / Internet Conference 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The adoption of digital technologies promises to accelerate the transformation and the agility of processes, work activities and revenue models. Yet, the promised gains come together with dramatic needs for qualified professionals who can effectively leverage the technology potential. Job contexts are being reshaped as new models for the interaction and integration of humans and technologies take shape. To increase the readiness of the job market in this fast-changing context it is important that all stakeholders - companies, professionals, policy makers - are aware of the job market dynamics and needs. This can be observed from the collection of job announcements, but its high volume requires effective tools for analyzing and simplifying it in order to draw timely and correct conclusions. ELK stack was used for dealing with the high volume of job announcements. ELK is a stable platform that can manage large quantities of data and the Kibana layer enables to rapidly explore data and create visualization dashboards. As job announcements have distinct formulations for similar roles, depending on the hiring company, this raises the necessity of establishing a common ground for comparing the job descriptions. In this work were mapped job descriptions to ESCO occupations. ESCO is an ontology published by the European Union and its occupations are job positions. Results show that the ELK stack is a suitable tool for providing a visual interpretation on the job market dynamics. Moreover, the first experiments using natural language processing techniques and machine learning algorithms revealed an accuracy over 0.9 in mapping job descriptions to ESCO occupations. This result is very promising and shows that ESCO a good candidate as common ground to enable comparison of job market dynamics for distinct environments.",
        "DOI": "NA",
        "paper_author": "Silva G.",
        "affiliation_name": "Deti",
        "affiliation_city": null,
        "affiliation_country": "United Kingdom",
        "affiliation_id": "125683002",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Emotional and cognitive affordances of collaborative learning environments",
        "publication": "Computer-Supported Collaborative Learning Conference, CSCL",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Collaborative learning involves intricate interactions in which students participate in cognitive activities within social-emotional environments. Cognitive interactions mediate knowledge sharing, construction, and creation, while social-emotional interactions shape student perception of community climate and influence their emotional expressions, which, in turn, have a significant impact on their cognitive interactions. Although research has consistently found that social presence and student-student interaction has a positive influence on students' learning through emotional engagement, subject-based teaching remained largely more of cognitive activities. Teachers tend to treat lessons that heightened social-emotional aspects separate from subject-based lessons. This symposium brings together an international group of scholars to present recent studies on emotion and cognition in collaborative learning environments. Methods, such as self-report, video observation, affective state detection using FACET, and machine learning models, were adopted to investigate students' emotions. The results collectively suggest that these methods indeed served to uncover students' emotions; emotions such as joy/enjoyment/happiness, confidence, and surprise were associated with students' knowledge building progress; and that students' online interactions had a high impact on the emotional and linguistic tone of learners. The symposium aims to discuss the theoretical, practical and policy implications of these studies on collaborative learning.",
        "DOI": "NA",
        "paper_author": "Zhu G.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Hepatitis C Virus (HCV) Prediction by Machine Learning Techniques",
        "publication": "Applications of Modelling and Simulation",
        "citied_by": "40",
        "cover_date": "2020-01-01",
        "Abstract": "Hepatitis C being as a prevalent disease in the world especially in countries like Egypt. It is estimated that 3-4 million new cases every year, indicating as a public health problem and should be addressed with identification and treatment policies. In the initial stage, it is asymptomatic however when infection progress it leads to chronic conditions such as liver cirrhosis and hepatocellular carcinoma. Some of the various non-invasive serum biochemical markers are used to identify this disease. This study aims to know the performance comparisons between multi and binary class labels of the same dataset, not limited to tool comparison, and to know which selected features play a key role in the prediction of Hepatitis C Virus (HCV) by using Egyptian patient’s dataset. The highest accuracy is shown by KNN (51.06%, R) and random forest (54.56%, Python) in multi and binary class label respectively. The overall evaluation metrics comparison shows R as a better tool for this case. On the other hand, the performance score of the binary class shows better that the multiclass label. The multi-feature selection methods did not show any similar arrangement/topology in the ranking order of selected features. Finally, the 12 selected features by principal component analysis show similar performances to complete dataset and also the 21 selected features, thus showing these features may play a role in the prediction of the HCV dataset.",
        "DOI": "NA",
        "paper_author": "Nandipati S.C.R.",
        "affiliation_name": "Universiti Sains Malaysia",
        "affiliation_city": "Minden",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60000906",
        "affiliation_state": "Penang"
    },
    {
        "paper_title": "Mitigating Biases in CORD-19 for Analyzing COVID-19 Literature",
        "publication": "Frontiers in Research Metrics and Analytics",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "On the behest of the Office of Science and Technology Policy in the White House, six institutions, including ours, have created an open research dataset called COVID-19 Research Dataset (CORD-19) to facilitate the development of question-answering systems that can assist researchers in finding relevant research on COVID-19. As of May 27, 2020, CORD-19 includes more than 100,000 open access publications from major publishers and PubMed as well as preprint articles deposited into medRxiv, bioRxiv, and arXiv. Recent years, however, have also seen question-answering and other machine learning systems exhibit harmful behaviors to humans due to biases in the training data. It is imperative and only ethical for modern scientists to be vigilant in inspecting and be prepared to mitigate the potential biases when working with any datasets. This article describes a framework to examine biases in scientific document collections like CORD-19 by comparing their properties with those derived from the citation behaviors of the entire scientific community. In total, three expanded sets are created for the analyses: 1) the enclosure set CORD-19E composed of CORD-19 articles and their references and citations, mirroring the methodology used in the renowned “A Century of Physics” analysis; 2) the full closure graph CORD-19C that recursively includes references starting with CORD-19; and 3) the inflection closure CORD-19I, that is, a much smaller subset of CORD-19C but already appropriate for statistical analysis based on the theory of the scale-free nature of the citation network. Taken together, all these expanded datasets show much smoother trends when used to analyze global COVID-19 research. The results suggest that while CORD-19 exhibits a strong tilt toward recent and topically focused articles, the knowledge being explored to attack the pandemic encompasses a much longer time span and is very interdisciplinary. A question-answering system with such expanded scope of knowledge may perform better in understanding the literature and answering related questions. However, while CORD-19 appears to have topical coverage biases compared to the expanded sets, the collaboration patterns, especially in terms of team sizes and geographical distributions, are captured very well already in CORD-19 as the raw statistics and trends agree with those from larger datasets.",
        "DOI": "10.3389/frma.2020.596624",
        "paper_author": "Kanakia A.",
        "affiliation_name": "Microsoft Research",
        "affiliation_city": "Redmond",
        "affiliation_country": "United States",
        "affiliation_id": "60021726",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Towards a combination of discrete-event simulation with machine learning for smart-parking",
        "publication": "Simulation Series",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In several cities, finding a parking spot is often a source of frustration for many drivers. If we ignore the obvious solution to add more parking slots, a less expensive and easier solution could then be to optimize the current parking slots by visibility, management and policies. This is how Smart-parking projects has become popular, it has allowed to upgrade parking productivity and effectiveness without adding parking slots. This paper propose to combine the discrete-event simulation provided by the discrete-event system specification formalism with a supervised learning algorithm in order to classify parking slots depending on their occupation time in order to predict departures. In comparison, the city Bastia (France) currently accommodates more than 450 sensors. These have been used to test the proposed approach from the case above.",
        "DOI": "NA",
        "paper_author": "Dominici A.",
        "affiliation_name": "Universita di Corsica Pascal Paoli",
        "affiliation_city": "Corte",
        "affiliation_country": "France",
        "affiliation_id": "60031206",
        "affiliation_state": "Corsica"
    },
    {
        "paper_title": "Global convergence of policy gradient methods to (almost) locally optimal policies",
        "publication": "SIAM Journal on Control and Optimization",
        "citied_by": "88",
        "cover_date": "2020-01-01",
        "Abstract": "Policy gradient (PG) methods have been one of the most essential ingredients of reinforcement learning, with application in a variety of domains. In spite of the empirical success, a rigorous understanding of the global convergence of PG methods appears to be relatively lacking in the literature, especially for the infinite-horizon setting with discounted factors. In this work, we close the gap by viewing PG methods from a nonconvex optimization perspective. In particular, we propose a new variant of PG methods for infinite-horizon problems that uses a random rollout horizon for the Monte Carlo estimation of the policy gradient. This method then yields an unbiased estimate of the policy gradient with bounded variance, which enables using the tools from nonconvex optimization to establish the global convergence. Employing this perspective, we first point to an alternative method to recover the convergence to stationary-point policies in the literature. Motivated by the recent advances in nonconvex optimization, we have modified the proposed PG method by introducing a periodically enlarged stepsize rule. More interestingly, this modified algorithm is shown to be able to escape saddle points under mild assumptions on the reward functions and the policy parameterization of the reinforcement learning (RL) problem. Specifically, we connect the correlated negative curvature condition of [H. Daneshmand et al., Escaping saddles with stochastic gradients, in Proceedings of the International Conference on Machine Learning, Stockholm, Sweden, 2018, pp. 1155-1164] to the fact that the reward must be strictly positive or negative. Under the additional assumption that all saddle points are strict, this result essentially establishes the convergence to actual locally optimal policies of the underlying problem and thus rigorously corroborates the overclaimed argument in the literature on the convergence of PG methods. In this aspect, our findings justify the benefit of reward-reshaping in terms of escaping saddle points from a nonconvex optimization perspective.",
        "DOI": "10.1137/19M1288012",
        "paper_author": "Zhang K.",
        "affiliation_name": "The Grainger College of Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States",
        "affiliation_id": "60158506",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "A Novel Consumer Purchase Behavior Recognition Method Using Ensemble Learning Algorithm",
        "publication": "Mathematical Problems in Engineering",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "With the prosperous development of e-commerce platforms, consumer returns often occur. The issue of returns has become a stumbling block to the profitability of e-commerce companies. To protect consumers' purchase rights, the Chinese government has introduced a 7-day unreasonable return policy. In order to use the return policy to attract consumers to buy, various e-commerce platforms have created a more relaxed and convenient return environment for consumers. On the one hand, the introduction of the return policy has increased customer trust in e-commerce platforms and stimulated purchase demand. On the other hand, the return behavior also increases the cost of the e-commerce platform. With the upgrading of consumption, customers pay more attention to personalized experience. In addition to considering price when purchasing online, the quality of services provided by e-commerce platforms will also directly affect customers' purchasing decisions and return behavior. Therefore, under the personalized return policy of the e-commerce platform, whether consumers will make another purchase is worth studying. In order to achieve this goal, an ensemble learning method (AdaBoost-FSVM) based on fuzzy support vector machine (FSVM) is applied to predict the purchase intention of consumers. First, the grid search method is used to optimize the modeling parameters of the FSVM base classifier. Second, the AdaBoost-FSVM ensemble prediction model is constructed by using multiple base classifiers. In order to evaluate the performance of the prediction models used, logistic regression (LR), support vector machine (SVM), FSVM, random forest (RF), and XGBoost were used to construct prediction models for purchasing behavior. The experimental results demonstrate that the method used in this study has a more accurate prediction effect than the comparison algorithms. The predictive model used in this study can be used in the recommendation system of shopping websites and can also be used to guide e-commerce companies to customize various preferential policies and services, so as to quickly and accurately stimulate the purchase intention of more potential consumers.",
        "DOI": "10.1155/2020/6673535",
        "paper_author": "Wang P.",
        "affiliation_name": "Jilin University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60007711",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Data science skills: Building partnership for efficient school curriculum delivery in Africa",
        "publication": "Statistical Journal of the IAOS",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Data science is a concept to unify statistics, data analysis, machine learning and their related methods in order to analyze actual phenomena with data to provide better understanding. This article focused its investigation on acquisition of data science skills in building partnership for efficient school curriculum delivery in Africa, especially in the area of teaching statistics courses at the beginners' level in tertiary institutions. Illustrations were made using Big data of selected 18 African countries sourced from United Nations Educational, Scientific and Cultural Organization (UNESCO) with special focus on some macro-economic variables that drives economic policy. Data description techniques were adopted in the analysis of the sourced open data with the aid of R analytics software for data science, as improvement on the traditional methods of data description for learning and thus open a new charter of education curriculum delivery in African schools. Though, the collaboration is not without its own challenges, its prospects in creating self-driven learning culture among students of tertiary institutions has greatly enhanced the quality of teaching, advancing students skills in machine learning, improved understanding of the role of data in global perspective and being able to critique claims based on data.",
        "DOI": "10.3233/SJI-200693",
        "paper_author": "Adeboye N.O.",
        "affiliation_name": "The Federal Polytechnic Ilaro",
        "affiliation_city": "Ilaro",
        "affiliation_country": "Nigeria",
        "affiliation_id": "60107502",
        "affiliation_state": "Ogun"
    },
    {
        "paper_title": "Rocorl: Transferable Reinforcement Learning-Based Robust Control for Cyber-Physical Systems with Limited Data Updates",
        "publication": "IEEE Access",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Autonomous control systems are increasingly using machine learning technologies to process sensor data, making timely and informed decisions about performing control functions based on the data processing results. Among such machine learning technologies, reinforcement learning (RL) with deep neural networks has been recently recognized as one of the feasible solutions, since it enables learning by interaction with environments of control systems. In this paper, we consider RL-based control models and address the problem of temporally outdated observations often incurred in dynamic cyber-physical environments. The problem can hinder broad adoptions of RL methods for autonomous control systems. Specifically, we present an RL-based robust control model, namely rocorl, that exploits a hierarchical learning structure in which a set of low-level policy variants are trained for stale observations and then their learned knowledge can be transferred to a target environment limited in timely data updates. In doing so, we employ an autoencoder-based observation transfer scheme for systematically training a set of transferable control policies and an aggregated model-based learning scheme for data-efficiently training a high-level orchestrator in a hierarchy. Our experiments show that rocorl is robust against various conditions of distributed sensor data updates, compared with several other models including a state-of-the-art POMDP method.",
        "DOI": "10.1109/ACCESS.2020.3044945",
        "paper_author": "Yoo G.",
        "affiliation_name": "Sungkyunkwan University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60007511",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Optimization of amplifier circuits by using gradient boosted trees and probability annealing policy",
        "publication": "Journal of Integrated Circuits and Systems",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Automatic optimization of analog circuits befits a hard and costly optimization problem. This work focus on the optimization of analog amplifier circuits. Here, we propose two contributions to design automation methodologies based on machine learning. Firstly, we propose a probability annealing pol-icy to boost early data collection and restrict electronic simulations later on in the optimization. Secondly, we employ multiple gradient boosted trees to predict design superiority in order reduces overfitting to learned designs. When compared to the state-of-the art, our approach reduces the number of electronic simulations, the number of queries made to the machine learning module required to finish the optimization.",
        "DOI": "10.29292/jics.v15i3.184",
        "paper_author": "Lima E.d.O.",
        "affiliation_name": "Universidade Federal do Maranhão",
        "affiliation_city": "Sao Luis",
        "affiliation_country": "Brazil",
        "affiliation_id": "60015786",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Prediction-guided multi-objective reinforcement learning for continuous robot control",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "80",
        "cover_date": "2020-01-01",
        "Abstract": "Many real-world control problems involve conflicting objectives where we desire a dense and high-quality set of control policies that are optimal for different objective preferences (called Pareto-optimal). While extensive research in multi-objective reinforcement learning (MORL) has been conducted to tackle such problems, multi-objective optimization for complex continuous robot control is still under-explored. In this work, we propose an efficient evolutionary learning algorithm to find the Pareto set approximation for continuous robot control problems, by extending a state-of-the-art RL algorithm and presenting a novel prediction model to guide the learning process. In addition to efficiently discovering the individual policies on the Pareto front, we construct a continuous set of Pareto-optimal solutions by Pareto analysis and interpolation. Furthermore, we design seven multi-objective RL environments with continuous action space, which is the first benchmark platform to evaluate MORL algorithms on various robot control problems. We test the previous methods on the proposed benchmark problems, and the experiments show that our approach is able to find a much denser and higher-quality set of Pareto policies than the existing algorithms.",
        "DOI": "NA",
        "paper_author": "Xu J.",
        "affiliation_name": "MIT Computer Science &amp; Artificial Intelligence Laboratory",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60006320",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Learning robot skills with temporal variational inference",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "17",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we address the discovery of robotic options from demonstrations in an unsupervised manner. Specifically, we present a framework to jointly learn low-level control policies and higherlevel policies of how to use them from demonstrations of a robot performing various tasks. By representing options as continuous latent variables, we frame the problem of learning these options as latent variable inference. We then present a temporal formulation of variational inference based on a temporal factorization of trajectory likelihoods, that allows us to infer options in an unsupervised manner. We demonstrate the ability of our framework to learn such options across three robotic demonstration datasets, and provide our code 1.",
        "DOI": "NA",
        "paper_author": "Shankar T.",
        "affiliation_name": "Facebook Research",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States",
        "affiliation_id": "60111190",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Exploration through reward biasing: Reward-biased maximum likelihood estimation for stochastic multi-armed bandits",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Inspired by the Reward-Biased Maximum Likelihood Estimate method of adaptive control, we propose RBMLE - a novel family of learning algorithms for stochastic multi-armed bandits (SMABs). For a broad range of SMABs including both the parametric Exponential Family as well as the non-parametric sub-Gaussian/Exponential family, we show that RBMLE yields an index policy. To choose the bias-growth rate.",
        "DOI": "NA",
        "paper_author": "Liu X.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60148980",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Fault-tolerant control of degrading systems with on-policy reinforcement learning",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "We propose a novel adaptive reinforcement learning control approach for fault tolerant control of degrading systems that is not preceded by a fault detection and diagnosis step. Therefore, a priori knowledge of faults that may occur in the system is not required. The adaptive scheme combines online and offline learning of the on-policy control method to improve exploration and sample efficiency, while guaranteeing stable learning. The offline learning phase is performed using a data-driven model of the system, which is frequently updated to track the system's operating conditions. We conduct experiments on an aircraft fuel transfer system to demonstrate the effectiveness of our approach.",
        "DOI": "10.1016/j.ifacol.2020.12.878",
        "paper_author": "Ahmed I.",
        "affiliation_name": "Vanderbilt University School of Engineering",
        "affiliation_city": "Nashville",
        "affiliation_country": "United States",
        "affiliation_id": "60010060",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Striving for simplicity and performance in off-policy drl: Output normalization and non-uniform sampling",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "We aim to develop off-policy DRL algorithms that not only exceed state-of-The-Art performance but are also simple and minimalistic. For standard continuous control benchmarks, Soft Actor-Critic (SAC), which employs entropy maximization, currently provides state-of-The-Art performance. We frst demonstrate that the entropy term in SAC addresses action saturation due to the bounded nature of the action spaces, with this insight, we propose a streamlined algorithm with a simple normalization scheme or with inverted gradients. We show that both approaches can match SAC s sample effciency performance without the need of entropy maximization, we then propose a simple non-uniform sampling method for selecting transitions from the replay buffer during training. Extensive experimental results demonstrate that our proposed sampling scheme leads to state of the art sample effciency on challenging continuous control tasks. We combine all of our fndings into one simple algorithm, which we call Streamlined Off Policy with Emphasizing Recent Experience, for which we provide robust public-domain code.",
        "DOI": "NA",
        "paper_author": "Wang C.",
        "affiliation_name": "NYU CS department",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60147012",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Using AI (artificial intelligence) to measure IA (impervious acreage) in a rapidly changing landscape",
        "publication": "93rd Water Environment Federation Technical Exhibition and Conference 2020, WEFTEC 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Improving DWSD’s workflows from manually derived data to machine learning derived data delivered annually allows DWSD to keep departmental metrics current. With the City of Detroit experiencing so much change, this new process will aid decision makers in understanding how and where the landscape is shifting. The accuracy of this data allows decision makers to share information across multiple agencies and have confidence regarding land use and economic development.",
        "DOI": "NA",
        "paper_author": "Mobley P.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "11th Conference on Decision and Game Theory for Security, GameSec 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 29 papers. The special focus in this conference is on Decision and Game Theory for Security. The topics include: Farsighted Risk Mitigation of Lateral Movement Using Dynamic Cognitive Honeypots; exploiting Bounded Rationality in Risk-Based Cyber Camouflage Games; a Realistic Approach for Network Traffic Obfuscation Using Adversarial Machine Learning; security Games with Insider Threats; hardware Security and Trust: A New Battlefield of Information; a Review of Multi Agent Perimeter Defense Games; attacking Machine Learning Models for Social Good; a Data-Driven Distributionally Robust Game Using Wasserstein Distance; using One-Sided Partially Observable Stochastic Games for Solving Zero-Sum Security Games with Sequential Attacks; MASAGE: Model-Agnostic Sequential and Adaptive Game Estimation; on the Characterization of Saddle Point Equilibrium for Security Games with Additive Utility; combating Online Counterfeits: A Game-Theoretic Analysis of Cyber Supply Chain Ecosystem; a Game Theoretic Framework for Software Diversity for Network Security; normalizing Flow Policies for Multi-agent Systems; blocking Adversarial Influence in Social Networks; popular Imperceptibility Measures in Visual Adversarial Attacks are Far from Human Perception; lie Another Day: Demonstrating Bias in a Multi-round Cyber Deception Game of Questionable Veracity; adversarial Deep Reinforcement Learning Based Adaptive Moving Target Defense; learning and Planning in the Feature Deception Problem; moving Target Defense for Robust Monitoring of Electric Grid Transformers in Adversarial Environments; secure Discrete-Time Linear-Quadratic Mean-Field Games; harnessing the Power of Deception in Attack Graph-Based Security Games; partially Observable Stochastic Games for Cyber Deception Against Network Epidemic; decoy Allocation Games on Graphs with Temporal Logic Objectives.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning counterfactual representations for estimating individual dose-response curves",
        "publication": "AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",
        "citied_by": "70",
        "cover_date": "2020-01-01",
        "Abstract": "Estimating what would be an individual's potential response to varying levels of exposure to a treatment is of high practical relevance for several important fields, such as healthcare, economics and public policy. However, existing methods for learning to estimate counterfactual outcomes from observational data are either focused on estimating average dose-response curves, or limited to settings with only two treatments that do not have an associated dosage parameter. Here, we present a novel machine-learning approach towards learning counterfactual representations for estimating individual dose-response curves for any number of treatments with continuous dosage parameters with neural networks. Building on the established potential outcomes framework, we introduce performance metrics, model selection criteria, model architectures, and open benchmarks for estimating individual dose-response curves. Our experiments show that the methods developed in this work set a new state-of-the-art in estimating individual dose-response.",
        "DOI": "NA",
        "paper_author": "Schwab P.",
        "affiliation_name": "Institute of Robotics and Intelligent Systems",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "126274003",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "IFIP WG 8.6 International Conference on Transfer and Diffusion of IT, TDIT 2020",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 62 papers. The special focus in this conference is on Transfer and Diffusion of IT. The topics include: Public Policy and Regulatory Challenges of Artificial Intelligence (AI); performance Modelling on Banking System: A Data Envelopment Analysis-Artificial Neural Network Approach; a Study on Attributes of Websites with Specific Reference to Online Purchase Intentions of Baby Products in Chennai; preface; artificial Intelligence in Practice – Real-World Examples and Emerging Business Models; learning Environments in the 21st Century: A Mapping of the Literature; an Intention-Adoption Behavioral Model for Open Government Data in Pakistan’s Public Sector Organizations–An Exploratory Study; analysis of Factors Influencing the Adoption of Artificial Intelligence for Crime Management; determinants and Barriers of Artificial Intelligence Adoption – A Literature Review; design Space Exploration for Aerospace IoT Products; Contribution of Trust Factor Towards IOT Diffusion – An Empirical Study Using Acceptance Model; occupant Adoption of IoT Based Environment Service in Office Spaces: An Empirical Investigation; Emerging Technologies and Emergent Workplaces: Findings from an Ethnographic Study at an Indian IT Organization; ioT Based Climate Control Systems Diffusion in Intelligent Buildings - A System Dynamics Model; a Data Driven Approach for Customer Relationship Management for Airlines with Internet of Things & Artificial Intelligence; understanding Factors Influencing the Usage Intention of Mobile Pregnancy Applications; Social Media and Public Health Emergency of International Concern: The COVID-19 Outbreak; Multiple Machine Learning Models for Detection of Alzheimer’s Disease Using OASIS Dataset; physicians’ and Nurses’ Perceived Threats Toward Health Information Technology: A Military Hospital Case Study.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "IFIP WG 8.6 International Conference on Transfer and Diffusion of IT, TDIT 2020",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 62 papers. The special focus in this conference is on Transfer and Diffusion of IT. The topics include: Public Policy and Regulatory Challenges of Artificial Intelligence (AI); performance Modelling on Banking System: A Data Envelopment Analysis-Artificial Neural Network Approach; a Study on Attributes of Websites with Specific Reference to Online Purchase Intentions of Baby Products in Chennai; preface; artificial Intelligence in Practice – Real-World Examples and Emerging Business Models; learning Environments in the 21st Century: A Mapping of the Literature; an Intention-Adoption Behavioral Model for Open Government Data in Pakistan’s Public Sector Organizations–An Exploratory Study; analysis of Factors Influencing the Adoption of Artificial Intelligence for Crime Management; determinants and Barriers of Artificial Intelligence Adoption – A Literature Review; design Space Exploration for Aerospace IoT Products; Contribution of Trust Factor Towards IOT Diffusion – An Empirical Study Using Acceptance Model; occupant Adoption of IoT Based Environment Service in Office Spaces: An Empirical Investigation; Emerging Technologies and Emergent Workplaces: Findings from an Ethnographic Study at an Indian IT Organization; ioT Based Climate Control Systems Diffusion in Intelligent Buildings - A System Dynamics Model; a Data Driven Approach for Customer Relationship Management for Airlines with Internet of Things & Artificial Intelligence; understanding Factors Influencing the Usage Intention of Mobile Pregnancy Applications; Social Media and Public Health Emergency of International Concern: The COVID-19 Outbreak; Multiple Machine Learning Models for Detection of Alzheimer’s Disease Using OASIS Dataset; physicians’ and Nurses’ Perceived Threats Toward Health Information Technology: A Military Hospital Case Study.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Public Policy and Regulatory Challenges of Artificial Intelligence (AI)",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Artificial Intelligence (AI) usage is rapidly expanding in our society. Private sector has already taken the leap of faith in using AI for efficiency and for generating better value for the customers and shareholders. The promise of AI is quite alluring for the governments as well. It promises to be the breakthrough technology which can catapult public sector to hitherto unseen efficiency and productivity. It has the potential to truly transform the public service delivery and the way government interfaces with citizens – from a demand driven model to a predictive model of public service delivery. However, there are a large number of pitfalls and blind-spots associated with AI, which make its adoption in government particularly challenging. For successful adoption of AI in public sector, governments must understand these challenges clearly and lay down regulatory public policies to ensure that the possible adverse impacts (such as exclusion, bias etc.) of AI are mitigated. This paper attempts to systematically explore these challenges with a view to enable public policy makers to respond to them.",
        "DOI": "10.1007/978-3-030-64849-7_10",
        "paper_author": "Misra S.K.",
        "affiliation_name": "CEO",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "124678509",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Artificial intelligence against disinformation: The FANDANGO practical case",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The present paper discusses how Artificial Intelligence can support the fight to disinformation to support a correct access to the news and content to the citizens, allowing the right democratic participation. Even if automatic detection of Fake News and disinformation is not possible for the moment and not in the intention of the authors, Machine Learning technologies and Big Data analysis can strongly support journalists and media professionals to detect disinformation in their day-by-day working activity. The paper presents some results of a running EU co-funded project, named FANDANGO, describing its technological approach and architecture. In the first and second chapters the context of disinformation is presented, in chapter 3 and 4 the FANDANGO project is shortly described, including its AI approach and dataflow architecture, chapter 5 describes the project use cases: climate change, immigration, and European policies. Finally, some short conclusions conclude the paper with general considerations on the status of digital media and with some preliminary suggestions to enforce the media in European ecosystem.",
        "DOI": "NA",
        "paper_author": "Nucci F.S.",
        "affiliation_name": "Sooft SpA",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "113547527",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An imitation learning approach for cache replacement",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "36",
        "cover_date": "2020-01-01",
        "Abstract": "Program execution speed critically depends on increasing cache hits, as cache hits are orders of magnitude faster than misses. To increase cache hits, we focus on the problem of cache replacement: choosing which cache line to evict upon inserting a new line. This is challenging because it requires planning far ahead and currently there is no known practical solution. As a result, current replacement policies typically resort to heuristics designed for specific common access patterns, which fail on more diverse and complex access patterns. In contrast, we propose an imitation learning approach to automatically learn cache access patterns by leveraging Belady's, an oracle policy that computes the optimal eviction decision given the future cache accesses. While directly applying Belady's is infeasible since the future is unknown, we train a policy conditioned only on past accesses that accurately approximates Belady's even on diverse and complex access patterns, and call this approach PARROT. When evaluated on 13 of the most memory-intensive SPEC applications, PARROT increases cache miss rates by 20% over the current state of the art. In addition, on a large-scale web search benchmark, PARROT increases cache hit rates by 61% over a conventional LRU policy. We release a Gym environment to facilitate research in this area, as data is plentiful, and further advancements can have significant real-world impact.",
        "DOI": "NA",
        "paper_author": "Liu E.Z.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Voltage Regulation for Photovoltaics-Battery-Fuel Systems Using Adaptive Group Method of Data Handling Neural Networks (GMDH-NN)",
        "publication": "IEEE Access",
        "citied_by": "19",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper a new control system on basis of group method for data handling neural networks (GMDH-NNs) is designed for voltage and power regulation in the photovoltaic (PV)/Fuel/Battery systems. The dynamics of all subsystems are considered to be fully uncertain. The suggested GMDH-NN is learned using online tuning rules that are concluded through the robustness investigation. The challenging operation conditions such as variable unknown dynamics, unknown temperature and irradiation and suddenly changes in output load are taken into account and are handled by suggested control system. The superiority of the suggested method is shown by simulation in several scenarios and comparison with other techniques.",
        "DOI": "10.1109/ACCESS.2020.3037134",
        "paper_author": "Band S.S.",
        "affiliation_name": "National Yunlin University of Science and Technology",
        "affiliation_city": "Douliou",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60014261",
        "affiliation_state": "Yunlin"
    },
    {
        "paper_title": "RL-Duet: Online music accompaniment generation using deep reinforcement learning",
        "publication": "AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",
        "citied_by": "45",
        "cover_date": "2020-01-01",
        "Abstract": "This paper presents a deep reinforcement learning algorithm for online accompaniment generation, with potential for real-time interactive human-machine duet improvisation. Different from offline music generation and harmonization, online music accompaniment requires the algorithm to respond to human input and generate the machine counterpart in a sequential order. We cast this as a reinforcement learning problem, where the generation agent learns a policy to generate a musical note (action) based on previously generated context (state). The key of this algorithm is the well-functioning reward model. Instead of defining it using music composition rules, we learn this model from monophonic and polyphonic training data. This model considers the compatibility of the machine-generated note with both the machine-generated context and the human-generated context. Experiments show that this algorithm is able to respond to the human part and generate a melodic, harmonic and diverse machine part. Subjective evaluations on preferences show that the proposed algorithm generates music pieces of higher quality than the baseline method.",
        "DOI": "10.1609/aaai.v34i01.5413",
        "paper_author": "Jiang N.",
        "affiliation_name": "Beijing National Research Center for Information Science and Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60104026",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Text categorization Performance examination Using Machine Learning Algorithms",
        "publication": "IOP Conference Series: Materials Science and Engineering",
        "citied_by": "99",
        "cover_date": "2020-01-01",
        "Abstract": "Automated text categorization has been measured as a crucial technique for run and practice a huge quantity of papers in digital appearances that were extensive & constantly growing. In common, text categorization acts a significant responsibility in data mining and summarization, text recovery, and query responding. Interruption recognition scheme plays an vital responsibility in network protection. Intrusion recognition method was a analytical method utilized for forecasting network information collision is common or Intrusion. ML algorithms were utilized to construct exact methods to grouping, categorization & guessing. Labeled text papers were utilized for classify text with supervised categorizations. This article used these classifiers in many types for labeled papers & evaluates correctness to classifiers. An artificial neural network (ANN) method utilizing back propagation network (BPN) is worked by more than a few additional techniques to build a autonomous policy to labeled & supervised text categorization procedure. The obtainable standard mechanism was used for analyzing working of categorization utilizing labeled papers. Investigational examination on actual information discloses for mechanism runs good in stipulations of categorization exactness.",
        "DOI": "10.1088/1757-899X/981/2/022044",
        "paper_author": "Yadav B.P.",
        "affiliation_name": "Sumathi Reddy Institute of Technology for Women",
        "affiliation_city": "Warangal",
        "affiliation_country": "India",
        "affiliation_id": "60194689",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Deep learning time series to forecast COVID-19 active cases in INDIA: A comparative study",
        "publication": "IOP Conference Series: Materials Science and Engineering",
        "citied_by": "31",
        "cover_date": "2020-01-01",
        "Abstract": "In the present situation of \"COVID-19 pandemic\"which devastated worldwide socioeconomic implications that led by Indian government to initiate and to perform intense procedures to control the spread and impact by dispensing the capability to predict the outbreak, which hits the crest to decrease the impact of disease and guiding the government to update its policies as required for implementing protective steps needed for \"Public Health System (PHS)\". These methodologies tend to be transforming among people for improvisation of vigor system. In this paper, we investigate thoroughly the precision of various \"Time series\"modeling techniques for detecting \"corona virus outbreak\"in topmost ten different states with the maximum number of \"confirmed cases\"as on 31 August 2020. We implemented six different deep learning approaches on time series for comparing the values associated in datasets that relates to the progression of the virus in each state based on the population as the attained results represent the scaling of time series methods accurately and predict various affected aspects in near future.",
        "DOI": "10.1088/1757-899X/981/2/022041",
        "paper_author": "Shaik M.A.",
        "affiliation_name": "SR University",
        "affiliation_city": "Warangal",
        "affiliation_country": "India",
        "affiliation_id": "60114867",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "17th International Conference on Economics of Grids, Clouds, Systems, and Services, GECON 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 19 papers. The special focus in this conference is on Economics of Grids, Clouds, Systems, and Services. The topics include: A MDE Approach for Modelling and Distributed Simulation of Health Systems; preface; a Blockchain Consensus for Message Queue Based on Byzantine Fault Tolerance; south Korea as the Role Model for Covid-19 Policies? An Analysis of the Effect of Government Policies on Infection Chain Structures; a Network Reliability Game; NuPow: Managing Power on NUMA Multiprocessors with Domain-Level Voltage and Frequency Control; multi-tier Power-Saving Method in Cloud Storage Systems for Content Sharing Services; instant Virtual Machine Live Migration; towards Economical Live Migration in Data Centers; Index-Selection for Minimizing Costs of a NoSQL Cloud Database; A Developer-Centric API Value Chain; bridging Education Services and Consumer Expectations Through Reusable Learning Objects; exascale Computing Deployment Challenges; Automatic Q.A-Pair Generation for Incident Tickets Handling: An Application of NLP; ProtectDDoS: A Platform for Trustworthy Offering and Recommendation of Protections; delivering Privacy-Friendly Location-Based Advertising Over Smartwatches: Effect of Virtual User Interface; GEM-Analytics: Cloud-to-Edge AI-Powered Energy Management.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A qualitative tool condition monitoring framework using convolution neural network and transfer learning",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "29",
        "cover_date": "2020-01-01",
        "Abstract": "Tool condition monitoring is one of the classical problems of manufacturing that is yet to see a solution that can be implementable in machine shops around the world. In tool condition monitoring, we are mostly trying to define a tool change policy. This tool change policy would identify a tool that produces a non-conforming part. When the non-conforming part producing tool is identified, it could be changed, and a proactive approach to machining quality that saves resources invested in non-conforming parts would be possible. The existing studies highlight three barriers that need to be addressed before a tool condition monitoring solution can be implemented to carry out tool change decision-making autonomously and independently in machine shops around the world. First, these systems are not flexible enough to include different quality requirements of the machine shops. The existing studies only consider one quality aspect (for example, surface finish), which is difficult to generalize across the different quality requirements like concentricity or burrs on edges commonly seen in machine shops. Second, the studies try to quantify the tool condition, while the question that matters is whether the tool produces a conforming or a non-conforming part. Third, the qualitative answer to whether the tool produces a conforming or a non-conforming part requires a large amount of data to train the predictive models. The proposed model addresses these three barriers using the concepts of computer vision, a convolution neural network (CNN), and transfer learning (TL) to teach the machines how a conforming component-producing tool looks and how a non-conforming component-producing tool looks.",
        "DOI": "10.3390/app10207298",
        "paper_author": "Mamledesai H.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60030835",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Working time and digital transition: A complex and ambiguous relationship",
        "publication": "Proceedings of the European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "The digital transition underway combines different types of technology: digital, physical and biological. These three families of technologies interact, drawing on the progress in artificial intelligence and machine learning, and creating the opportunity of digitalizing all stages of production and services systems. The increase of digital work represents a deep transformation of economy and society, posing huge challenges to companies, employees and policy makers, and therefore to social scientists. In this context, in European countries, working time regulation has become central to employment policies. The guiding principles of working time management are based on three aspects: the conventional definition of working time flexibility; the development of public measures that aim at making the reduction of working hours advantageous; and the adequacy of working time management to the whole of working life. Advances in information and communication technologies that bring high convenience to personal life are also blurring the lines of work-time and personal time, threatening work-life balance. This situation is raising not only important legal issues, but also ethical considerations related to mandatory or unpaid overtime, and the possibility of employer subtle or explicit coercion. Additionally, the ethicality of unconventional shift work and long work-hour schedules is also at stake in issues like the gender-based inequities related to working hours, and employers’ responsibilities for protecting individuals who are not employees from the indirect effects of demanding work schedules, namely affecting the work-family balance. In terms of research methods, after an assessment of the transformations underway, based on literature review and documentary analysis, we will develop a qualitative approach with semi-structured interviews, which will allow to analyse the position of different key actors (employers' and trade union confederations) on long working hours and their effects.",
        "DOI": "10.34190/EAIR.20.052",
        "paper_author": "Rebelo G.",
        "affiliation_name": "Lusófona University",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal",
        "affiliation_id": "60000015",
        "affiliation_state": "Lisbon"
    },
    {
        "paper_title": "Learning selection strategies in Buchberger’s algorithm",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Studying the set of exact solutions of a system of polynomial equations largely depends on a single iterative algorithm, known as Buchberger’s algorithm. Optimized versions of this algorithm are crucial for many computer algebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach to Buchberger’s algorithm that uses reinforcement learning agents to perform S-pair selection, a key step in the algorithm. We then study how the diffculty of the problem depends on the choices of domain and distribution of polynomials, about which little is known. Finally, we train a policy model using proximal policy optimization (PPO) to learn S-pair selection strategies for random systems of binomial equations. In certain domains, the trained model outperforms state-of-the-art selection heuristics in total number of polynomial additions performed, which provides a proof-of-concept that recent developments in machine learning have the potential to improve performance of algorithms in symbolic computation.",
        "DOI": "NA",
        "paper_author": "Peifer D.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "16th International Conference on Information Systems Security, ICISS 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 17 papers. The special focus in this conference is on Information Systems Security. The topics include: Preface; a Unified Access Control Model for Calibration Traceability in Safety-Critical IoT; Forensic Source Identification of OSN Compressed Images; cheating Detectable Ramp Secret Sharing with Optimal Cheating Resiliency; LiARX: A Lightweight Cipher Based on the LTS Design Strategy of ARX; color Visual Cryptography Schemes Using Linear Algebraic Techniques over Rings; secure Calculation for Position Information of IoT Device with Few Communication and Small Secret Information; Attacks on Android-Based Smartphones and Impact of Vendor Customization on Android OS Security; Detection of Malign and Benign PE Files Using Texture Analysis; Estimating the Cost of Cybersecurity Activities with CAsPeA: A Case Study and Comparative Analysis; learning Attribute-Based and Relationship-Based Access Control Policies with Unknown Values; reliability and Security for Safety-Critical Service Compositions; a Defence Against Input-Agnostic Backdoor Attacks on Deep Neural Networks; an Overview of Cyber Threat Intelligence Platform and Role of Artificial Intelligence and Machine Learning; machine Learning Based Android Vulnerability Detection: A Roadmap.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning to Plan with Uncertain Topological Maps",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "We train an agent to navigate in 3D environments using a hierarchical strategy including a high-level graph based planner and a local policy. Our main contribution is a data driven learning based approach for planning under uncertainty in topological maps, requiring an estimate of shortest paths in valued graphs with a probabilistic structure. Whereas classical symbolic algorithms achieve optimal results on noise-less topologies, or optimal results in a probabilistic sense on graphs with probabilistic structure, we aim to show that machine learning can overcome missing information in the graph by taking into account rich high-dimensional node features, for instance visual information available at each location of the map. Compared to purely learned neural white box algorithms, we structure our neural model with an inductive bias for dynamic programming based shortest path algorithms, and we show that a particular parameterization of our neural model corresponds to the Bellman-Ford algorithm. By performing an empirical analysis of our method in simulated photo-realistic 3D environments, we demonstrate that the inclusion of visual features in the learned neural planner outperforms classical symbolic solutions for graph based planning.",
        "DOI": "10.1007/978-3-030-58580-8_28",
        "paper_author": "Beeching E.",
        "affiliation_name": "Centre d’Innovation en Télécommunications et Intégration de Services",
        "affiliation_city": "Villeurbanne",
        "affiliation_country": "France",
        "affiliation_id": "60108197",
        "affiliation_state": "Auvergne-Rhone-Alpes"
    },
    {
        "paper_title": "Explainability is not enough: Requirements for human-AI-partnership in complex socio-technical systems",
        "publication": "Proceedings of the European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Explainability has been recognized as an important requirement of artificial intelligence (AI) systems. Transparent decision policies and explanations regarding why an AI system comes about a certain decision is a pre-requisite if AI is supposed to support human decision-making or if human-AI collaborative decision-making is envisioned. Human-AI interaction and joint decision-making is required in many real-world domains, where risky decisions have to be made (e.g. medical diagnosis) or complex situations have to be assessed (e.g. states of machines or production processes). However, in this paper we theorize that explainability is necessary but not sufficient. Coming from the point of view of work psychology we argue that for the human part of the human-AI system much more is required than intelligibility. In joint human-AI decision-making a certain role is assigned to the human, which normally encompasses tasks such as (i) verifying AI based decision suggestions, (ii) improving AI systems, (iii) learning from AI systems, and (iv) taking responsibility for the final decision as well as for compliance with legislation and ethical standards. Empowering the human to take this demanding role requires not only human expertise but e.g. also human motivation, which is triggered by a suitable task design. Furthermore, at work humans normally do not take decisions as lonely wolves but in formal and informal cooperation with other humans. Hence, to design effective explainability and to empower for true human-AI collaborative decision-making, embedding human-AI dyads into a socio-technical context is necessary. Coming from theory, this paper presents system design criteria on different levels substantiated by work psychology. The criteria are described and confronted with a use case scenario of AI-supported medical decision making in the context of digital pathology. On this basis, the need for further research is outlined.",
        "DOI": "10.34190/EAIR.20.007",
        "paper_author": "Waefler T.",
        "affiliation_name": "Fachhochschule Nordwestschweiz FHNW",
        "affiliation_city": "Windisch",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60011274",
        "affiliation_state": "AG"
    },
    {
        "paper_title": "Designing low-correlation GPS spreading codes via a policy gradient reinforcement learning algorithm",
        "publication": "Proceedings of the 33rd International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS+ 2020",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "With the birth of the next-generation GPS III constellation and the upcoming launch of the Navigation Technology Satellite-3 (NTS-3) testing platform to explore future technologies for GPS, we are indeed entering a new era of satellite navigation. Correspondingly, it is time to revisit the design methods of the GPS spreading code families. In this work, we develop a Gaussian policy gradient-based reinforcement learning algorithm which constructs high-quality families of spreading code sequences. We demonstrate the ability of our algorithm to achieve better mean-squared auto- and cross-correlation than well-chosen families of equal-length Gold codes and Weil codes. Furthermore, we compare our algorithm with an analogous genetic algorithm implementation assigned the same code evaluation metric. To the best of the authors' knowledge, this is the first work to explore using a machine learning / reinforcement learning approach to design navigation spreading code signals.",
        "DOI": "10.33012/2020.17650",
        "paper_author": "Mina T.Y.",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60012708",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "33rd Australasian Joint Conference on Artificial Intelligence, AI 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 36 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A Tri-level Programming Framework for Modelling Attacks and Defences in Cyber-Physical Systems; a Mixed-Integer Programming Approach for Scheduling Roadworks in Urban Regions; reducing Traffic Congestion in Urban Areas via Real-Time Re-Routing: A Simulation Study; Analysis and Prediction of Player Population Changes in Digital Games During the COVID-19 Pandemic; a Comparison of Machine Learning Methods for Cross-Domain Few-Shot Learning; an Elastic Gradient Boosting Decision Tree for Concept Drift Learning; online Semi-supervised Learning in Contextual Bandits with Episodic Reward; activity-Independent Person Identification Based on Daily Activities Using Wearable Sensors; real-Time Decision Making for Train Carriage Load Prediction via Multi-stream Learning; how to Encode Dynamic Gaussian Bayesian Networks as Gaussian Processes?; an Information-Theoretic Perspective on Overfitting and Underfitting; exploring a Learning Architecture for General Game Playing; autonomous Recognition of Collective Behaviour in Robot Swarms; train Small, Deploy Big: Do Relative World Views Permit Swarm-Safety During Policy Transplantation for Multi-Agent Reinforcement Learning Problems?; Improving StarCraft II Player League Prediction with Macro-Level Features; comparing Three Data Representations for Music with a Sequence-to-Sequence Model; Designing Curriculum for Deep Reinforcement Learning in StarCraft II; can Lethal Autonomous Robots Learn Ethics?; building Fair Predictive Models; non-monotonic Reasoning for Machine Ethics with Situation Calculus; improving Distribution-Based Discrete Particle Swarm Optimization Using Lévy Flight; a Novel Mutation Operator for Variable Length Algorithms; genetic Programming-Based Selection of Imputation Methods in Symbolic Regression with Missing Values; multi-diseases Classification from Chest-X-ray: A Federated Deep Learning Approach.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mining of Social Media on Covid-19 Big Data Infodemic in Indonesia",
        "publication": "Journal of Computer Science",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "Covid-19 is an unprecedented disaster that is still difficult to contain. During the pandemic, there were a lot of cases that were reported to increase exponentially. In this situation, the dissemination of messages and information was very important. The social media platform has contributed as a channel of communication with unprecedented speed. However, the uncontrolled and irresponsible dissemination of information will result in new problems that can be detrimental to many parties. A lot of information may trigger panic, fear and result in lose hope and even paranoia. The provision of correct and timely information as well as any curative and preventive effort to stop the disease are very important. This study aims to present a method in finding out public opinion through Twitter social media mining in the Indonesian context. We are particularly interested in finding out what people’s stance with the pandemic. Some people may fully aware of this threat, but the remaining could be careless about what is going on. It is assumed that this stance could lead to people’s obedience to the government’s policy on COVID 19 Protocol. It is believed that the opinion is hidden behind the comments in the media. By scrapping the tweets on Twitter during March 2020 using Corona and COVID Keywords, we obtained as many as 31,003 tweets. We manually classified the tweets into 3 classes, positive, negative and neutral stances. Predictive models are derived using Support Vector Machine, Random Forest and Naïve Bayes algorithms. Random Forest-based model gives the highest accuracy level as high as 89%, followed by Support Vector Machine as high as 87% and Naïve Bayes as high as 68%. The model can further be used to classify opinions in the future giving valuable information for the government in making policies and steps in overcoming the pandemic.",
        "DOI": "10.3844/JCSSP.2020.1598.1609",
        "paper_author": "Binsar F.",
        "affiliation_name": "Bina Nusantara University",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60103610",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Transfer learning and domain adaptation based on modeling of socio-economic systems",
        "publication": "Business Informatics",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "This article deals with the application of transfer learning methods and domain adaptation in a recurrent neural network based on the long short-term memory architecture (LSTM) to improve the efficiency of management decisions and state economic policy. Review of existing approaches in this area allows us to draw a conclusion about the need to solve a number of practical issues of improving the quality of predictive analytics for preparing forecasts of the development of socio-economic systems. In particular, in the context of applying machine learning algorithms, one of the problems is the limited number of marked data. The authors have implemented training of the original recurrent neural network on synthetic data obtained as a result of simulation, followed by transfer training and domain adaptation. To achieve this goal, a simulation model was developed by combining notations of system dynamics with agent-based modeling in the AnyLogic system, which allows us to investigate the influence of a combination of factors on the key parameters of the efficiency of the socio-economic system. The original LSTM training was realized with the help of TensorFlow, an open source software library for machine learning. The suggested approach makes it possible to expand the possibilities of complex application of simulation methods for building a neural network in order to justify the parameters of the development of the socio-economic system and allows us to get information about its future state.",
        "DOI": "10.17323/2587-814X.2020.2.7.20",
        "paper_author": "Kazakov O.D.",
        "affiliation_name": "Bryansk State Technological University of Engineering",
        "affiliation_city": "Bryansk",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "112924520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Learning-Assisted Compartmentalization Scheme for Bare-Metal Systems",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "A primary concern in creating compartments (i.e., protection domains) for bare-metal systems is to adopt the applicable compartmentalization policy. Existing studies have proposed several typical policies in literature. However, neither of the policies consider the influence of unsafe functions on the compartment security that a vulnerable function would expose unpredictable attack surfaces, which could be exploited to manipulate any contents that are stored in the same compartment. In this paper, we design a machine learning-assisted compartmentalization scheme, which adopts a new policy that takes every function’s security into full account, to create compartments for bare-metal systems. First, the scheme takes advantage of the machine learning method to predict how likely a function holds an exploitable security bug. Second, the prediction results are used to create a new instrumented firmware that isolates vulnerable and normal functions into different compartments. Further, the scheme provides some optional optimization plans to the developer to improve the performance. The PoC of the scheme is incorporated into an LLVM-based compiler and evaluated on a Cortex-M based IoT device. Compared with the firmware adopting other typical policies, the firmware with the new policy not only shows better security but also assures the overhead basically unchanged.",
        "DOI": "10.1007/978-3-030-61078-4_2",
        "paper_author": "Huo D.",
        "affiliation_name": "Institute of Information Engineering",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60273040",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of feature extraction method based on support vector machine in Internet of things",
        "publication": "Journal of Intelligent and Fuzzy Systems",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Although much less fatal than the Ebola and previous SARS virus epidemics, the current coronavirus outbreak (COVID-19) has spread to more people in more countries in a much shorter time frame. With the rapid development of the Internet of things, it has played an important role to track/monitor transmission movements throughout the population. The technology infrastructure between mobile devices, wearable devices and sensors, smart home device makes it possible to readily deploy solutions to monitor and collect data and perform analysis to ensure policy make intelligent, rapid decisions. This research combines AOL and Support Vector Machine to form the Internet of things cycle through smart home. The parameters of Support Vector Machine model are optimized by ALO algorithm, which shortens the learning time and improves the performance of classifier. Then, the algorithm of ALO is used to optimize the Support Vector Machine intrusion detection method and agent technology, and the intrusion detection model is established. Experimental results show that the combination of these two can effectively reduce the false alarm rate of network intrusion.",
        "DOI": "10.3233/JIFS-189258",
        "paper_author": "Lin T.",
        "affiliation_name": "Mianyang Normal University",
        "affiliation_city": "Mianyang",
        "affiliation_country": "China",
        "affiliation_id": "60088062",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "A machine learning approach to open public comments for policymaking",
        "publication": "Information Polity",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, the author argues that the conflict between the copious amount of digital data processed by public organisations and the need for policy-relevant insights to aid public participation constitutes a 'public information paradox'. Machine learning (ML) approaches may offer one solution to this paradox through algorithms that transparently collect and use statistical modelling to provide insights for policymakers. Such an approach is tested in this paper. The test involves applying an unsupervised machine learning approach with latent Dirichlet allocation (LDA) analysis of thousands of public comments submitted to the United States Transport Security Administration (TSA) on a 2013 proposed regulation for the use of new full body imaging scanners in airport security terminals. The analysis results in salient topic clusters that could be used by policymakers to understand large amounts of text such as in an open public comments process. The results are compared with the actual final proposed TSA rule, and the author reflects on new questions raised for transparency by the implementation of ML in open rule-making processes.",
        "DOI": "10.3233/IP-200256",
        "paper_author": "Ingrams A.",
        "affiliation_name": "Faculty Governance and Global Affairs",
        "affiliation_city": "The Hague",
        "affiliation_country": "Netherlands",
        "affiliation_id": "125536711",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep reinforcement learning applied to managed pressure drilling",
        "publication": "Society of Petroleum Engineers - SPE Norway Subsurface Conference 2020",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "During drilling operations, maintaining a desired downhole pressure between pressure margins is crucial to avoid damage to the formation and the well. The process is highly nonlinear, changing with depth, and every section in every well is different. Standard solutions with PID controllers are widely accepted for this purpose, although methods such as deep reinforcement learning (DRL) could be investigated as an alternative approach. A smooth update deep Q learning algorithm is used to train an agent embedded in a managed pressure drilling system. The aim is to control downhole pressure during pipe connections by use of a topside choke valve with nonlinear characteristics. The agent is trained on previously gathered data, from situations featuring step changes in pressure setpoint and changing mud flows, all at various well depths. After training, the agent is tasked with controlling BHP during connection, herein demonstrated by use of a numerically simulated low-order hydraulics model. Through episodic training, it becomes clear that the agent purely through interaction with the environment, and without any prerequisite knowledge of system dynamics and reward design, converges to an optimal control policy. The trained agent is then tested on pipe connections with well depths in the lower and upper bounds of the training data. The pipe connection scenario presents changes in operating conditions in terms of changing mud flows with changing conditions like increased frictional pressure losses due to increased depth. Still, the results presented show the agent's ability to track a pressure setpoint at various depths in the changing conditions present during connection, while seamlessly incorporating controller constraints. There are several advantages associated with this approach, among them eliminating the need for development of a complex dynamic model for the process. Also, the approach is applicable to both linear and nonlinear systems, deterministic and stochastic systems, and lower- and higher-level decision-making. These methods could possibly also be applied to other key challenges in drilling such as ROP optimization or autonomous directional drilling.",
        "DOI": "NA",
        "paper_author": "Arnø M.",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway",
        "affiliation_id": "60013141",
        "affiliation_state": "Trondelag"
    },
    {
        "paper_title": "Recommendation rules mining for reducing the spread of COVID-19 cases",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "The COVID-19 pandemic is having an unprecedented impact on society and the economy, affecting virtually every aspect of people's daily life and all sectors of the economy. In this situation, society and the health care system need help from modern technologies such as Artificial Intelligence, Big Data, and Machine Learning, which intended to help governments to choose and implement an adequate strategy to combat the spread of the disease by balancing between human safety and the constraints of social and economic life. This paper considers the recommendation rules extracted from the novel ensemble of machine learning methods such as regression tree and clustering. The merged Oxford COVID-19 Government Response Tracker and European Centre for Disease Prevention and Control Covid-19 Cases datasets have been used with the data ranged from January 01 to October 04, 2020. The conclusions and findings of the study could be helpful for decision making on appropriated state policy for reducing the spread of new Covid-19 cases.",
        "DOI": "NA",
        "paper_author": "Yakovyna V.",
        "affiliation_name": "Uniwersytet Warminsko-Mazurski w Olsztynie",
        "affiliation_city": "Olsztyn",
        "affiliation_country": "Poland",
        "affiliation_id": "60024421",
        "affiliation_state": "WM"
    },
    {
        "paper_title": "Enabling clustering for privacy-aware data dissemination based on medical healthcare-Iots (MH-IoTS) for wireless body area network",
        "publication": "Journal of Healthcare Engineering",
        "citied_by": "13",
        "cover_date": "2020-01-01",
        "Abstract": "There is a need to develop an effective data preservation scheme with minimal information loss when the patient's data are shared in public interest for different research activities. Prior studies have devised different approaches for data preservation in healthcare domains; however, there is still room for improvement in the design of an elegant data preservation approach. With that motivation behind, this study has proposed a medical healthcare-IoTs-based infrastructure with restricted access. The infrastructure comprises two algorithms. The first algorithm protects the sensitivity information of a patient with quantifying minimum information loss during the anonymization process. The algorithm has also designed the access polices comprising the public access, doctor access, and the nurse access, to access the sensitivity information of a patient based on the clustering concept. The second suggested algorithm is K-anonymity privacy preservation based on local coding, which is based on cell suppression. This algorithm utilizes a mapping method to classify the data into different regions in such a manner that the data of the same group are placed in the same region. The benefit of using local coding is to restrict third-party users, such as doctors and nurses, when trying to insert incorrect values in order to access real patient data. Efficiency of the proposed algorithm is evaluated against the state-of-the-art algorithm by performing extensive simulations. Simulation results demonstrate benefits of the proposed algorithms in terms of efficient cluster formation in minimum time, minimum information loss, and execution time for data dissemination.",
        "DOI": "10.1155/2020/8824907",
        "paper_author": "Ullah F.",
        "affiliation_name": "University of Macau",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao",
        "affiliation_id": "60022317",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Integrating Mobile Devices with Cohort Analysis into Personalised Weather-Based Healthcare",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Mobile healthcare applications can empower users to self-monitor their health conditions without the need to visit any medical centre. However, the lack of attention on engagement aspects of mobile healthcare applications often result in users choosing to uninstall the application after the first usage experience. This results in failure of effective prolonged personalised healthcare, especially for users with chronic disease related to weather conditions such as asthma and eczema which require long-term monitoring and self-care. Therefore, this paper aims to identify the pattern of application user engagement with a weather-based mobile healthcare application through cohort retention analysis. Enhancement features for improving the engagement of personalised healthcare can provide meaningful insight. The proposed application allows the patient to conduct disease control tests to check the severity of their condition on a daily basis. To measure the application engagement, we distribute the mobile application designed for primary testing over a period of ten days. Based on the primary testing, data related to retention rate and the number of control test reported were collected via Firebase Analytic to determine the application engagement. Subsequently, we apply cohort analysis using a machine learning clustering technique implemented in Python to identify the pattern of the engagement by application users. Finally, useful insights were analysed and implemented as enhancement features within the application for improving the personalised weather-based mobile healthcare. The findings in this paper can assist machine learning facilitators design effective use policies for weather-based mobile healthcare with fundamental knowledge enhanced with personalisation and user engagement.",
        "DOI": "10.1007/978-3-030-63007-2_47",
        "paper_author": "Ho S.B.",
        "affiliation_name": "Multimedia University",
        "affiliation_city": "Cyberjaya",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60012005",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Role of data science in managing COVID-19 pandemic",
        "publication": "Indian Chemical Engineer",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "In December of 2019, the first outbreak of COVID-19 was detected in mainland China, eventually spreading to every continent in the world except Antarctica. Named Coronavirus Disease 19 (COVID-19) by the World Health Organization (WHO), this highly contagious disease was caused by the virus SARS-CoV-2. With a transmission rate greater than SARS or common flu, continued tremendous efforts will be needed to successfully combat this disease. In this article, we review the role that data science is playing in this war. Data science, combined with statistical analysis, computer science and computational biology, is helping in myriad ways with applications including epidemiology, drug discovery, and molecular design for diagnostic and therapeutic purposes. A number of data driven models, mathematical models, correlations and predictive models have been developed for COVID-19. Challenges faced by the data scientists today have been highlighted. Finally, open source datasets sources are mentioned that can be potentially used in diagnostics and evaluation of health policies.",
        "DOI": "10.1080/00194506.2020.1855085",
        "paper_author": "Saxena N.",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60032730",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Performance Evaluation of SRELM on Bio-signal Pattern Recognition Using Two Electromyography Channels",
        "publication": "International Journal on Advanced Science, Engineering and Information Technology",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The classification accuracy of pattern recognition is determined by the extracted features and the utilized classifiers. Many efforts have been conducted to obtain the best features either by introducing a new feature or proposing a new projection method to increase class separability. Recently, spectral regression extreme learning machine (SRELM) has been introduced to improve the class separability of the features. However, the evaluation of SRELM was only focused on the myoelectric or electromyography pattern recognition from many EMG channels. In practical application, the user is more convenient with less number of channels. Then, the problem is whether the SRELM would be able to work efficiently for less EMG channels. The objective of this paper is to examine the performance of SRELM for bio-signal pattern recognition using two EMG channels. The EMG electrodes were located on flexor policies lounges and flexor digitorium superficial muscles of ten healthy subjects. Various time domain features were involved with various sizes. SRELM will project these features to more recognize features before being feed to multiple classifiers. Those classifiers are randomized Variable Translation Wavelet Neural Networks (RVT-WNN), extreme learning machine(ELM), support vector machine (SVM), and linear discriminant analysis (LDA). The performance of SREM was compared to other feature methods, such as LDA, uncorrelated LDA (ULDA), orthogonal fuzzy neighborhood dimensionality reduction (OFNDA), and spectral regression discriminant analysis (SRDA). The experimental results show that SRELM performed well when dealing with different class numbers by classification accuracy of around 95.67% for ten class movements and performed better than SRDA.",
        "DOI": "10.18517/ijaseit.10.5.7131",
        "paper_author": "Anam K.",
        "affiliation_name": "Universitas Jember",
        "affiliation_city": "Jember",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069412",
        "affiliation_state": "East Java"
    },
    {
        "paper_title": "Approaches to Analyzing the Vulnerability of Community Water Systems to Groundwater Contamination in Los Angeles County",
        "publication": "Association for Women in Mathematics Series",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Groundwater resources are increasingly drawn on as means to buffer surface water shortages during droughts as well as to improve the Los Angeles region’s reliance on local, rather than imported, water sources. However, the Los Angeles region is home to a legacy of contamination that threatens the quality and safety of groundwater as a drinking water resource. As utilities and other water management entities in the Los Angeles region look to increase their reliance on groundwater resources, a comprehensive understanding of which community water systems may be vulnerable to contamination can help planners, policy makers and regulators support these communities. This paper details the objectives, process and lessons learned from a workshop-based research project that examined the spatial extent of groundwater contamination in Los Angeles County’s groundwater basins. Our team of researchers cleaned and processed multiple geospatial datasets and utilized logistic regression and machine learning methods to predict which community drinking water systems are particularly vulnerable to groundwater contamination.",
        "DOI": "10.1007/978-3-030-58748-2_2",
        "paper_author": "Miro M.E.",
        "affiliation_name": "RAND Corporation",
        "affiliation_city": "Santa Monica",
        "affiliation_country": "United States",
        "affiliation_id": "60003873",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Physics-Driven Machine Learning for Time-Optimal Path Planning in Stochastic Dynamic Flows",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Optimal path planning of autonomous marine agents is important to minimize operational costs of ocean observation systems. Within the context of DDDAS, we present a Reinforcement Learning (RL) framework for computing a dynamically adaptable policy that minimizes expected travel time of autonomous vehicles between two points in stochastic dynamic flows. To forecast the stochastic dynamic environment, we utilize the reduced order data-driven dynamically orthogonal (DO) equations. For planning, a novel physics-driven online Q-learning is developed. First, the distribution of exact time optimal paths predicted by stochastic DO Hamilton-Jacobi level set partial differential equations are utilized to initialize the action value function (Q-value) in a transfer learning approach. Next, the flow data collected by onboard sensors are utilized in a feedback loop to adaptively refine the optimal policy. For the adaptation, a simple Bayesian estimate of the environment is performed (the DDDAS data assimilation loop) and the inferred environment is used to update the Q-values in an greedy exploration approach (the RL step). To validate our Q-learning solution, we compare it with a fully offline, dynamic programming solution of the Markov Decision Problem corresponding to the RL framework. For this, novel numerical schemes to efficiently utilize the DO forecasts are derived and computationally efficient GPU-implementation is completed. We showcase the new RL algorithm and elucidate its computational advantages by planning paths in a stochastic quasi-geostrophic double gyre circulation.",
        "DOI": "10.1007/978-3-030-61725-7_34",
        "paper_author": "Chowdhury R.",
        "affiliation_name": "Indian Institute of Science",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60014097",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Exploring the Application of Machine Learning for Downscaling Climate Projections",
        "publication": "Association for Women in Mathematics Series",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Policy makers need information about future climate change on spatial scales much finer than is available from typical climate model grids. New and creative methods are being advanced to downscale climate change projections with statistical methods. Important requirements are to reliably downscale the climate parameter means, variability, extremes and trends, while preserving spatial and temporal correlations and permitting uncertainty quantification. In this proof-of-concept study, datasets derived from both observations and climate models were used together to train and test statistical methods. Two machine learning techniques—artificial neural networks and random forests—were tested on the problem of using coarse-scale climate projections (here represented by ERA-Interim reanalyses) to create temperature predictions at specific locations in areas of complex terrain. The methods are trained on and validated by temperature readings from mesonet weather stations in Colorado. This work has implications for fire prevention and water resources management, among other applications.",
        "DOI": "10.1007/978-3-030-58748-2_1",
        "paper_author": "Van Abel K.",
        "affiliation_name": "RAND Corporation",
        "affiliation_city": "Santa Monica",
        "affiliation_country": "United States",
        "affiliation_id": "60003873",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "7th International Conference on Future Data and Security Engineering, FDSE 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 26 papers. The special focus in this conference is on Future Data and Security Engineering. The topics include: A Comparative Study of Join Algorithms in Spark; blockchain-Based Forward and Reverse Supply Chains for E-waste Management; a Pragmatic Blockchain Based Solution for Managing Provenance and Characteristics in the Open Data Context; OAK: Ontology-Based Knowledge Map Model for Digital Agriculture; A Novel Approach to Diagnose ADHD Using Virtual Reality; a Three-Way Energy Efficient Authentication Protocol Using Bluetooth Low Energy; clustering-Based Deep Autoencoders for Network Anomaly Detection; flexible Platform for Integration, Collection, and Analysis of Social Media for Open Data Providers in Smart Cities; post-quantum Digital-Signature Algorithms on Finite 6-Dimensional Non-commutative Algebras; data Quality for Medical Data Lakelands; malicious-Traffic Classification Using Deep Learning with Packet Bytes and Arrival Time; detecting Malware Based on Dynamic Analysis Techniques Using Deep Graph Learning; understanding the Decision of Machine Learning Based Intrusion Detection Systems; combining Support Vector Machines for Classifying Fingerprint Images; toward an Ontology for Improving Process Flexibility; sentential Semantic Dependency Parsing for Vietnamese; An In-depth Analysis of OCR Errors for Unconstrained Vietnamese Handwriting; authorization Policy Extension for Graph Databases; A Model-Driven Approach for Enforcing Fine-Grained Access Control for SQL Queries; on Applying Graph Database Time Models for Security Log Analysis; integrating Web Services in Smart Devices Using Information Platform Based on Fog Computing Model; adaptive Contiguous Scheduling for Data Aggregation in Multichannel Wireless Sensor Networks; relating Network-Diameter and Network-Minimum-Degree for Distributed Function Computation; growing Self-Organizing Maps for Metagenomic Visualizations Supporting Disease Classification.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Transparency Tools for Fairness in AI (Luskin)",
        "publication": "Association for Women in Mathematics Series",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "We propose new tools for policy-makers to use when assessing and correcting fairness and bias in AI algorithms. The three tools are: A new definition of fairness called “controlled fairness” with respect to choices of protected features and filters. The definition provides a simple test of fairness of an algorithm with respect to a dataset. This notion of fairness is suitable in cases where fairness is prioritized over accuracy, such as in cases where there is no “ground truth” data, only data labeled with past decisions (which may have been biased).Algorithms for retraining a given classifier to achieve “controlled fairness” with respect to a choice of features and filters. Two algorithms are presented, implemented and tested. These algorithms require training two different models in two stages. We experiment with combinations of various types of models for the first and second stage and report on which combinations perform best in terms of fairness and accuracy.Algorithms for adjusting model parameters to achieve a notion of fairness called “classification parity.” This notion of fairness is suitable in cases where accuracy is prioritized. Two algorithms are presented, one which assumes that protected features are accessible to the model during testing, and one which assumes protected features are not accessible during testing. We evaluate our tools on three different publicly available datasets. We find that the tools are useful for understanding various dimensions of bias, and that in practice the algorithms are effective in starkly reducing a given observed bias when tested on new data.",
        "DOI": "10.1007/978-3-030-58748-2_4",
        "paper_author": "Chen M.",
        "affiliation_name": "University of Maryland, College Park",
        "affiliation_city": "College Park",
        "affiliation_country": "United States",
        "affiliation_id": "60020304",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Modeling 3D Shapes by Reinforcement Learning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "18",
        "cover_date": "2020-01-01",
        "Abstract": "We explore how to enable machines to model 3D shapes like human modelers using deep reinforcement learning (RL). In 3D modeling software like Maya, a modeler usually creates a mesh model in two steps: (1) approximating the shape using a set of primitives; (2) editing the meshes of the primitives to create detailed geometry. Inspired by such artist-based modeling, we propose a two-step neural framework based on RL to learn 3D modeling policies. By taking actions and collecting rewards in an interactive environment, the agents first learn to parse a target shape into primitives and then to edit the geometry. To effectively train the modeling agents, we introduce a novel training algorithm that combines heuristic policy, imitation learning and reinforcement learning. Our experiments show that the agents can learn good policies to produce regular and structure-aware mesh models, which demonstrates the feasibility and effectiveness of the proposed RL framework.",
        "DOI": "10.1007/978-3-030-58607-2_32",
        "paper_author": "Lin C.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Context Aware Control Systems: An Engineering Applications Perspective",
        "publication": "IEEE Access",
        "citied_by": "26",
        "cover_date": "2020-01-01",
        "Abstract": "Cyber-physical systems revolve around context awareness, empowering objective-oriented services, products and operations based on real data. Self-aware and self-control systems are core elements in the Industry 4.0 framework towards self-sustainable adaptive manufacturing and personalized services. This development is witnessed by the context-aware pervasive assistance to users and machines in decisions making process for optimizing product performance and economic yield. While integration of the virtual and the physical world entails smart sensors communication and complex data analytics, it relies on artificial intelligence tools to manage process operations. The objective of the article is to create awareness that systems control community must address theoretical and practical aspects from a larger perspective. Context aware control is emerging as a natural solution to maximize the use of available sensing instrumentation and the relatively low cost data logging, i.e. an important source for extracting information, interpreting and using context information and adapt its functionality to the current context of use. This article presents a concise overview of applications where context aware systems and control methodologies are relevant in the seven societal challenges acknowledged by European policy-makers: Digital Society; Food; Health and Well-Being; Smart Resource Management; Urban Planning, Mobility Dynamics and Logistics; New Energy Demand and Delivery; and Society.",
        "DOI": "10.1109/ACCESS.2020.3041357",
        "paper_author": "Diaz R.A.C.",
        "affiliation_name": "Universiteit Gent",
        "affiliation_city": "Ghent",
        "affiliation_country": "Belgium",
        "affiliation_id": "60033316",
        "affiliation_state": "VOV"
    },
    {
        "paper_title": "SVRG for policy evaluation with fewer gradient evaluations",
        "publication": "IJCAI International Joint Conference on Artificial Intelligence",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Stochastic variance-reduced gradient (SVRG) is an optimization method originally designed for tackling machine learning problems with a finite sum structure. SVRG was later shown to work for policy evaluation, a problem in reinforcement learning in which one aims to estimate the value function of a given policy. SVRG makes use of gradient estimates at two scales. At the slower scale, SVRG computes a full gradient over the whole dataset, which could lead to prohibitive computation costs. In this work, we show that two variants of SVRG for policy evaluation could significantly diminish the number of gradient calculations while preserving a linear convergence speed. More importantly, our theoretical result implies that one does not need to use the entire dataset in every epoch of SVRG when it is applied to policy evaluation with linear function approximation. Our experiments demonstrate large computational savings provided by the proposed methods.",
        "DOI": "NA",
        "paper_author": "Peng Z.",
        "affiliation_name": "Université McGill",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60002494",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Optimal policy for deployment of machine learning models on energy-bounded systems",
        "publication": "IJCAI International Joint Conference on Artificial Intelligence",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "With the recent advances in both machine learning and embedded systems research, the demand to deploy computational models for real-time execution on edge devices has increased substantially. Without deploying computational models on edge devices, the frequent transmission of sensor data to the cloud results in rapid battery draining due to the energy consumption of wireless data transmission. This rapid power dissipation leads to a considerable reduction in the battery lifetime of the system, therefore jeopardizing the real-world utility of smart devices. It is well-established that for difficult machine learning tasks, models with higher performance often require more computation power and thus are not power-efficient choices for deployment on edge devices. However, the trade-offs between performance and power consumption are not well studied. While numerous methods (e.g., model compression) have been developed to obtain an optimal model, these methods focus on improving the efficiency of a “single” model. In an entirely new direction, we introduce an effective method to find a combination of “multiple” models that are optimal in terms of power-efficiency and performance by solving an optimization problem in which both performance and power consumption are taken into account. Experimental results demonstrate that on the ImageNet dataset, we can achieve a 20% energy reduction with only 0.3% accuracy drop compared to Squeeze-and-Excitation Networks. Compared to a pruned neural network for human activity recognition, while consuming 1.7% less energy, our proposed policy achieves 1.3% higher accuracy.",
        "DOI": "NA",
        "paper_author": "Mirzadeh S.I.",
        "affiliation_name": "Washington State University Pullman",
        "affiliation_city": "Pullman",
        "affiliation_country": "United States",
        "affiliation_id": "60018208",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Statistical learning with a nuisance component (extended abstract)",
        "publication": "IJCAI International Joint Conference on Artificial Intelligence",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "We provide excess risk guarantees for statistical learning in a setting where the population risk with respect to which we evaluate a target parameter depends on an unknown parameter that must be estimated from data (a “nuisance parameter”). We analyze a two-stage sample splitting meta-algorithm that takes as input two arbitrary estimation algorithms: one for the target parameter and one for the nuisance parameter. We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order. Our theorem is agnostic to the particular algorithms used for the target and nuisance and only makes an assumption on their individual performance. This enables the use of a plethora of existing results from statistical learning and machine learning literature to give new guarantees for learning with a nuisance component. Moreover, by focusing on excess risk rather than parameter estimation, we can give guarantees under weaker assumptions than in previous works and accommodate the case where the target parameter belongs to a complex nonparametric class. We characterize conditions on the metric entropy such that oracle rates-rates of the same order as if we knew the nuisance parameter-are achieved. We also analyze the rates achieved by specific estimation algorithms such as variance-penalized empirical risk minimization, neural network estimation and sparse high-dimensional linear model estimation. We highlight the applicability of our results in four settings of central importance in the literature: 1) heterogeneous treatment effect estimation, 2) offline policy optimization, 3) domain adaptation, and 4) learning with missing data.",
        "DOI": "NA",
        "paper_author": "Foster D.J.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Sample factory: Egocentric 3D control from pixels at 100000 FPS with asynchronous reinforcement learning",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "43",
        "cover_date": "2020-01-01",
        "Abstract": "Increasing the scale of reinforcement learning experiments has allowed researchers to achieve unprecedented results in both training sophisticated agents for video games, and in sim-to-real transfer for robotics. Typically such experiments rely on large distributed systems and require expensive hardware setups, limiting wider access to this exciting area of research. In this work we aim to solve this problem by optimizing the efficiency and resource utilization of reinforcement learning algorithms instead of relying on distributed computation. We present the “Sample Factory”, a high-throughput training system optimized for a single-machine setting. Our architecture combines a highly efficient, asynchronous, GPU-based sampler with off-policy correction techniques, allowing us to achieve throughput higher than 105 environment frames/second on non-trivial control problems in 3D without sacrificing sample efficiency. We extend Sample Factory to support self-play and population-based training and apply these techniques to train highly capable agents for a multiplayer first-person shooter game. Github: https://github.com/alex-petrenko/sample-factory",
        "DOI": "NA",
        "paper_author": "Petrenko A.",
        "affiliation_name": "Intel Labs",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "126155618",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep learning for agricultural land use classification from sentinel-2",
        "publication": "Revista de Teledeteccion",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "The use of deep learning techniques for remote sensing applications has recently increased. These algorithms have proven to be successful in estimation of parameters and classification of images. However, little effort has been made to make them understandable, leading to their implementation as “black boxes”. This work aims to evaluate the performance and clarify the operation of a deep learning algorithm, based on a bi-directional recurrent network of long short-term memory (2-BiLSTM). The land use classification in the Valencian Community based on Sentinel-2 image time series in the framework of the common agricultural policy (CAP) is used as an example. It is verified that the accuracy of the deep learning techniques is superior (98.6 % overall success) to that other algorithms such as decision trees (DT), k-nearest neighbors (k-NN), neural networks (NN), support vector machines (SVM) and random forests (RF). The performance of the classifier has been studied as a function of time and of the predictors used. It is concluded that, in the study area, the most relevant information used by the network in the classification are the images corresponding to summer and the spectral and spatial information derived from the red and near infrared bands. These results open the door to new studies in the field of the explainable deep learning in remote sensing applications.",
        "DOI": "10.4995/raet.2020.13337",
        "paper_author": "Campos-Taberner M.",
        "affiliation_name": "Universitat de València",
        "affiliation_city": "Valencia",
        "affiliation_country": "Spain",
        "affiliation_id": "60002644",
        "affiliation_state": "Valencia"
    },
    {
        "paper_title": "Automated Excavator Based on Reinforcement Learning and Multibody System Dynamics",
        "publication": "IEEE Access",
        "citied_by": "43",
        "cover_date": "2020-01-01",
        "Abstract": "Fully autonomous earth-moving heavy equipment able to operate without human intervention can be seen as the primary goal of automated earth construction. To achieve this objective requires that the machines have the ability to adapt autonomously to complex and changing environments. Recent developments in automation have focused on the application of different machine learning approaches, of which the use of reinforcement learning algorithms is considered the most promising. The key advantage of reinforcement learning is the ability of the system to learn, adapt and work independently in a dynamic environment. This article investigates an application of reinforcement learning algorithm for heavy mining machinery automation. To this end, the training associated with reinforcement learning is done using the multibody approach. The procedure used combines a multibody approach and proximal policy optimization with a covariance matrix adaptation learning algorithm to simulate an autonomous excavator. The multibody model includes a representation of the hydraulic system, multiple sensors observing the state of the excavator and deformable ground. The task of loading a hopper with soil taken from a chosen point on the ground is simulated. The excavator is trained to load the hopper effectively within a given time while avoiding collisions with the ground and the hopper. The proposed system demonstrates the desired behavior after short training times.",
        "DOI": "10.1109/ACCESS.2020.3040246",
        "paper_author": "Kurinov I.",
        "affiliation_name": "LUT University",
        "affiliation_city": "Lappeenranta",
        "affiliation_country": "Finland",
        "affiliation_id": "60014304",
        "affiliation_state": "South Karelia"
    },
    {
        "paper_title": "How to apply the novel dynamic ARDL simulations (dynardl) and Kernel-based regularized least squares (krls)",
        "publication": "MethodsX",
        "citied_by": "87",
        "cover_date": "2020-01-01",
        "Abstract": "The application of dynamic Autoregressive Distributed Lag (dynardl) simulations and Kernel-based Regularized Least Squares (krls) to time series data is gradually gaining recognition in energy, environmental and health economics. The Kernel-based Regularized Least Squares technique is a simplified machine learning-based algorithm with strength in its interpretation and accounting for heterogeneity, additivity and nonlinear effects. The novel dynamic ARDL Simulations algorithm is useful for testing cointegration, long and short-run equilibrium relationships in both levels and differences. Advantageously, the novel dynamic ARDL Simulations has visualization interface to examine the possible counterfactual change in the desired variable based on the notion of ceteris paribus. Thus, the novel dynamic ARDL Simulations and Kernel-based Regularized Least Squares techniques are useful and improved time series techniques for policy formulation. • We customize ARDL and dynamic simulated ARDL by adding plot estimates with confidence intervals. • A step-by-step procedure of applying ARDL, dynamic ARDL Simulations and Kernel-based Regularized Least Squares is provided. • All techniques are applied to examine the economic effect of denuclearization in Switzerland by 2034.",
        "DOI": "10.1016/j.mex.2020.101160",
        "paper_author": "Sarkodie S.A.",
        "affiliation_name": "Nord Universitet",
        "affiliation_city": "Bodo",
        "affiliation_country": "Norway",
        "affiliation_id": "60021876",
        "affiliation_state": "Nordland"
    },
    {
        "paper_title": "A SEIR Model Optimization Using the Differential Evolution",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The SEIR is a crucial mathematical model for solving infectious disease prediction and other problems in the field of artificial intelligence. It is used to effectively prevent and control infectious diseases by studying the infectious diseases’ propagation speed, spatial range, transmission route, dynamic mechanism and other issues. In order to improve the prediction of infectious diseases in a certain area, a SEIR model optimization approach based on differential evolution (DE) algorithm is proposed in this paper. In this method, the differential evolution is used to optimization the related variables in the model. The overall prediction of the adjusted and optimized SEIR model algorithm is conformed to the regional development laws. The experimental results show that the SEIR infectious disease model optimized by DE algorithm is accurate and reliable in the analysis of COVID-19 propagation situation, and the model can be used to provide certain theoretical methods and technical support for future outbreak policy formulation.",
        "DOI": "10.1007/978-3-030-62460-6_34",
        "paper_author": "Wang D.",
        "affiliation_name": "Jiangxi University of Science and Technology",
        "affiliation_city": "Ganzhou",
        "affiliation_country": "China",
        "affiliation_id": "60104225",
        "affiliation_state": "Jiangxi"
    },
    {
        "paper_title": "A Novel Intrusion Detection System for Malware Based on Time-Series Meta-learning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, frequent occurrence of network security incidents indicates that host security is more and more fragile. However, current protection tools leads to reduce the efficiency of CPU or GPU. Meanwhile, they give up active defense and increase the security risk. Unfortunately, the existing intrusion detection systems seldom adjust the defense policy according to the host’s performance and the time when the attack might occur. Thus, different from traditional intrusion detection systems, our system is capable of intelligently detecting and predicting threats. Firstly, our system converts the malware into gray-scale images according to the instruction execution logic. Secondly, the system uses a computer vision method to identify the signature of the gray-scale images. Finally, the proposed system classifies malware family. Specifically, the system can also predict the time when a host faces a severe threat using time-series datasets and create a multi-neural network task for defending the threat. Then, a meta-learning framework is utilized to improve malware detection accuracy and defend against attacks effectively. The experimental results show that our system can accurately classify 15 malware families, and we compare our detection results with that of other IDSs, which proves that our system achieves a better performance.",
        "DOI": "10.1007/978-3-030-62223-7_5",
        "paper_author": "Wang F.",
        "affiliation_name": "Hebei Normal University",
        "affiliation_city": "Shijiazhuang",
        "affiliation_country": "China",
        "affiliation_id": "60002786",
        "affiliation_state": "Hebei"
    },
    {
        "paper_title": "17th International Conference on Quantitative Evaluation Systems, QEST 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 20 papers. The special focus in this conference is on Quantitative Evaluation Systems. The topics include: Machine Learning for Reliability Analysis of Large Scale Systems; CogQN: A Queueing Model that Captures Human Learning of the User Interfaces of Session-Based Systems; a Matlab Toolkit for the Analysis of Two-Level Processor Sharing Queues; m/M/1 Vacation Queue with Multiple Thresholds: A Fluid Analysis; bounding Mean First Passage Times in Population Continuous-Time Markov Chains; markovian Arrival Processes in Multi-dimensions; automatic Pre- and Postconditions for Partial Differential Equations; Importance of Interaction Structure and Stochasticity for Epidemic Spreading: A COVID-19 Case Study; the Dynamic Fault Tree Rare Event Simulator; entropy Measurement of Concurrent Disorder; hardening Critical Infrastructure Networks Against Attacker Reconnaissance; tracking the Race Between Deep Reinforcement Learning and Imitation Learning; sensitivity Analysis and Uncertainty Quantification of State-Based Discrete-Event Simulation Models Through a Stacked Ensemble of Metamodels; $$\\mathsf {SafePILCO}$$ : A Software Tool for Safe and Data-Efficient Policy Synthesis; stochNetV2: A Tool for Automated Deep Abstractions for Stochastic Reaction Networks; alternative Characterizations of Probabilistic Trace Equivalences on Coherent Resolutions of Nondeterminism; Probabilistic Model Checking of AODV; multi-player Equilibria Verification for Concurrent Stochastic Games.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning for predictive maintenance diagnosis with motor fault spectrum",
        "publication": "Journal of Taiwan Society of Naval Architects and Marine Engineers",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, the increase of green energy awareness has risen with the policy to “20% of green electricity in 2025.” Many green energy companies have sprung up. The establishment of the Taiwan Wind Industry Association in 2019 further highlights the development potential and importance of offshore wind energy in Taiwan. As the maintenance cost of equipment in the offshore wind farm is higher than that of the onshore wind farm, the fault prediction and health management of offshore wind turbines have become important research. In recent years, Artificial Intelligence (AI) has been widely used in Prognostic and Health Management (PHM). By equipment monitoring with the Industrial Internet of Things (IIoT) architecture, huge amounts of data collected can be transmitted through Supervisory Control and Data Acquisition (SCADA) system. How to apply this big data for PHM has a decisive influence on the maintenance cost of equipment in the offshore wind farm. The goal of our study is to import and test some machine learning algorithms, including decision tree classifier, K-nearest neighbor classifier, logistic regression classifier, and support vector machine, for Predictive Maintenance (PdM). The experimental results show that the accuracy is over 95%. It provides a preliminary discussion on machine learning algorithms for a possible reference to PdM analysis of wind turbines in the future.",
        "DOI": "NA",
        "paper_author": "Lu Y.C.",
        "affiliation_name": "National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60005429",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Kung Fu: Making training in distributed machine learning adaptive",
        "publication": "Proceedings of the 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020",
        "citied_by": "51",
        "cover_date": "2020-01-01",
        "Abstract": "When using distributed machine learning (ML) systems to train models on a cluster of worker machines, users must configure a large number of parameters: hyper-parameters (e.g. the batch size and the learning rate) affect model convergence; system parameters (e.g. the number of workers and their communication topology) impact training performance. In current systems, adapting such parameters during training is ill-supported. Users must set system parameters at deployment time, and provide fixed adaptation schedules for hyper-parameters in the training program. We describe KungFu, a distributed ML library for TensorFlow that is designed to enable adaptive training. KungFu allows users to express high-level Adaptation Policies (APs) that describe how to change hyper- and system parameters during training. APs take real-time monitored metrics (e.g. signal-to-noise ratios and noise scale) as input and trigger control actions (e.g. cluster rescaling or synchronisation strategy updates). For execution, APs are translated into monitoring and control operators, which are embedded in the dataflow graph. APs exploit an efficient asynchronous collective communication layer, which ensures concurrency and consistency of monitoring and adaptation operations.",
        "DOI": "NA",
        "paper_author": "Mai L.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Analyzing reinforcement learning benchmarks with random weight guessing",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "We propose a novel method for analyzing and visualizing the complexity of standard reinforcement learning (RL) benchmarks based on score distributions. A large number of policy networks are generated by randomly guessing their parameters, and then evaluated on the benchmark task; the study of their aggregated results provide insights into the benchmark complexity. Our method guarantees objectivity of evaluation by sidestepping learning altogether: the policy network parameters are generated using Random Weight Guessing (RWG), making our method agnostic to (i) the classic RL setup, (ii) any learning algorithm, and (iii) hyperparameter tuning. We show that this approach isolates the environment complexity, highlights specific types of challenges, and provides a proper foundation for the statistical analysis of the task's difficulty. We test our approach on a variety of classic control benchmarks from the OpenAI Gym, where we show that small untrained networks can provide a robust baseline for a variety of tasks. The networks generated often show good performance even without gradual learning, incidentally highlighting the triviality of a few popular benchmarks.",
        "DOI": "NA",
        "paper_author": "Oller D.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "META-learning state-based eligibility traces for more sample-efficient policy evaluation",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Temporal-Difference (TD) learning is a standard and very successful reinforcement learning approach, at the core of both algorithms that learn the value of a given policy, as well as algorithms which learn how to improve policies. TD-learning with eligibility traces provides a way to boost sample efficiency by temporal credit assignment, i.e. deciding which portion of a reward should be assigned to predecessor states that occurred at different previous times, controlled by a parameter λ. However, tuning this parameter can be time-consuming, and not tuning it can lead to inefficient learning. For better sample efficiency of TD-learning, we propose a meta-learning method for adjusting the eligibility trace parameter, in a state-dependent manner. The adaptation is achieved with the help of auxiliary learners that learn distributional information about the update targets online, incurring roughly the same computational complexity per step as the usual value learner. Our approach can be used both in on-policy and off-policy learning. We prove that, under some assumptions, the proposed method improves the overall quality of the update targets, by minimizing the overall target error. This method can be viewed as a plugin to assist prediction with function approximation by meta-learning feature (observation)-based λ online, or even in the control case to assist policy improvement. Our empirical evaluation demonstrates significant performance improvements, as well as improved robustness of the proposed algorithm to learning rate variation.",
        "DOI": "NA",
        "paper_author": "Zhao M.",
        "affiliation_name": "Université McGill",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60002494",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Multimodal representation learning for robotic cross-modality policy transfer",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "In this thesis, we aim at endowing robots with mechanisms to learn multimodal representations from sensory data and to allow them to execute tasks considering different subsets of available perceptions. We address the learning of these representations from supervised, unsupervised and reinforcement learning methodologies in the context of virtual agents and robots. We hope that, by achieving the proposed goals, the contributions of this thesis might prompt future research on applications of multimodal representations in robots and other artificial agents.",
        "DOI": "NA",
        "paper_author": "Vasco M.",
        "affiliation_name": "Instituto Superior Técnico",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal",
        "affiliation_id": "60004956",
        "affiliation_state": "Lisbon"
    },
    {
        "paper_title": "Multi-vehicle mixed reality reinforcement learning for autonomous multi-lane driving",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Autonomous driving promises to transform road transport. Multivehicle and multi-lane scenarios, however, present unique challenges due to constrained navigation and unpredictable vehicle interactions. Learning-based methods-such as deep reinforcement learning-are emerging as a promising approach to automatically design intelligent driving policies that can cope with these challenges. Yet, the process of safely learning multi-vehicle driving behaviours is hard: while collisions-and their near-avoidance-are essential to the learning process, directly executing immature policies on autonomous vehicles raises considerable safety concerns. In this article, we present a safe and efficient framework that enables the learning of driving policies for autonomous vehicles operating in a shared workspace, where the absence of collisions cannot be guaranteed. Key to our learning procedure is a sim2real approach that uses real-world online policy adaptation in a mixed reality setup, where other vehicles and static obstacles exist in the virtual domain. This allows us to perform safe learning by simulating (and learning from) collisions between the learning agent(s) and other objects in virtual reality. Our results demonstrate that, after only a few runs in mixed reality, collisions are significantly reduced.",
        "DOI": "NA",
        "paper_author": "Mitchell R.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Objective social choice: Using auxiliary information to improve voting outcomes",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "How should one combine noisy information from diverse sources to make an inference about an objective ground truth? This frequently recurring, normative question lies at the core of statistics, machine learning, policy-making, and everyday life. It has been called “combining forecasts”, “meta-analysis”, “ensembling”, and the “MLE approach to voting”, among other names. Past studies typically assume that noisy votes are identically and independently distributed (i.i.d.), but this assumption is often unrealistic. Instead, we assume that votes are independent but not necessarily identically distributed and that our ensembling algorithm has access to certain auxiliary information related to the underlying model governing the noise in each vote. In our present work, we: (1) define our problem and argue that it reflects common and socially relevant real world scenarios, (2) propose a multi-arm bandit noise model and count-based auxiliary information set, (3) derive maximum likelihood aggregation rules for ranked and cardinal votes under our noise model, (4) propose, alternatively, to learn an aggregation rule using an order-invariant neural network, and (5) empirically compare our rules to common voting rules and naive experience-weighted modifications. We find that our rules successfully use auxiliary information to outperform the naive baselines.*",
        "DOI": "NA",
        "paper_author": "Pitis S.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Manage the present or focus on the future? Leveraging new technologies in post-pandemic education",
        "publication": "IMSCI 2020 - 14th International Multi-Conference on Society, Cybernetics and Informatics, Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Many schools closed during the Covid-19 pandemic, and this was also the case in Canada where schooling was seriously disrupted because schools closed for seven months. At the present time, little is known about the extent of the impact of school closures on student learning but it is evident that some educational institutions such as universities and colleges were able to shift to online more easily than others. Globally, those persons who had internet access and tech skills were able to maintain social contacts and work from home. It became evident, however, during the school closures that schools and school systems who had blended learning in place fared better overall because they had systems and processes to fall back on. The uneven levels of technology adoption in the K-12 education sector also became apparent during the school closures. At the time of writing, schools in Canada are planning to re-open to students in September, 2020. School administrators will be challenged to manage pandemic protocols and the predicted learning gaps in students who were at home since March. At the same time, however, technology continues to evolve and change how persons outside schools interact with each other. New technologies such as artificial intelligence (AI) and machine learning are changing the day-to-day landscape and schooling needs to continue to adapt and shift to consider how to use these emergent technologies. In this paper, the authors review some of the emergent technologies and concerns that have been raised about them. They suggest that a critical, interdisciplinary approach is needed to assess the affordances and risks of emergent technology and how these technologies might support learners in schools. Given the present rate of technology change, schools will need to build capacity and competence to help them solve the problems of the present and the future.",
        "DOI": "NA",
        "paper_author": "Robertson L.",
        "affiliation_name": "Ontario Tech University",
        "affiliation_city": "Oshawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60002146",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "29th International Conference on Artificial Neural Networks, ICANN 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 70 papers. The special focus in this conference is on Artificial Neural Networks. The topics include: Multi-label Quadruplet Dictionary Learning; pareto Multi-task Deep Learning; Convex Graph Laplacian Multi-Task Learning SVM; prediction Stability as a Criterion in Active Learning; neural Spectrum Alignment: Empirical Study; nonlinear, Nonequilibrium Landscape Approach to Neural Network Dynamics; hopfield Networks for Vector Quantization; prototype-Based Online Learning on Homogeneously Labeled Streaming Data; neural Network Training with Safe Regularization in the Null Space of Batch Activations; the Effect of Batch Normalization in the Symmetric Phase; a Lightweight Fully Convolutional Neural Network of High Accuracy Surface Defect Detection; regularized Pooling; deep Recurrent Deterministic Policy Gradient for Physical Control; exploration via Progress-Driven Intrinsic Rewards; an Improved Reinforcement Learning Based Heuristic Dynamic Programming Algorithm for Model-Free Optimal Control; PBCS: Efficient Exploration and Exploitation Using a Synergy Between Reinforcement Learning and Motion Planning; understanding Failures of Deterministic Actor-Critic with Continuous Action Spaces and Sparse Rewards; GAN-Based Planning Model in Deep Reinforcement Learning; guided Reinforcement Learning via Sequence Learning; neural Machine Translation Based on Improved Actor-Critic Method; neural Machine Translation Based on Prioritized Experience Replay; Detecting Uncertain BNN Outputs on FPGA Using Monte Carlo Dropout Sampling; improving Multi-agent Reinforcement Learning with Imperfect Human Knowledge; adaptive Skill Acquisition in Hierarchical Reinforcement Learning; social Navigation with Human Empowerment Driven Deep Reinforcement Learning; curious Hierarchical Actor-Critic Reinforcement Learning; policy Entropy for Out-of-Distribution Classification; analysis of Reservoir Structure Contributing to Robustness Against Structural Failure of Liquid State Machine; morphological Computation of Skin Focusing on Fingerprint Structure.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Prediction of COVID-19 corona virus pandemic based on time series data using support vector machine",
        "publication": "Journal of Discrete Mathematical Sciences and Cryptography",
        "citied_by": "140",
        "cover_date": "2020-01-01",
        "Abstract": "Predicting the probability of CORONA virus outbreak has been studied in recent days, but the published literature seldom contains multiple model comparisons or predictive analysis of uncertainty. Time series parameters are the core factors influencing infectious diseases such as severe acute respiratory syndrome (SARS) and influenza. As a global pandemic is imminent, the prediction of real-time transmission of COVID-19 is crucial. The objective of this paper is to produce a real-time forecasts using the SVM model. The purpose of this study is to investigate the Corona Virus Disease 2019 (COVID-19) prediction of confirmed, deceased and recovered cases. This prediction will help to plan resources, determine government policy, and provide survivors with immunity passports, and use the same plasma for care. In this analysis, data including attributes such as location wise confirmed, deceased, recovered COVID-19, longitude and latitude were collected from January 22, 2020 to April 25, 2020 worldwide. Support Vector Machine was used to explore the impact on identification, deceased, and recovery.",
        "DOI": "10.1080/09720529.2020.1784535",
        "paper_author": "Singh V.",
        "affiliation_name": "Manipal University Jaipur",
        "affiliation_city": "Jaipur",
        "affiliation_country": "India",
        "affiliation_id": "60108737",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "9th International Congress on Telematics and Computing, WITCOM 2020",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 31 papers. The special focus in this conference is on Telematics and Computing. The topics include: Fuzzy logic-based covid-19 and other respiratory conditions pre-clinical diagnosis system; computer vision navigation system for an indoors unmanned aerial vehicle; a review of the security information controls in wireless networks wi-fi; local tours recommendation applying machine learning in social networks; embedded human detection system for home security; file restore automation with machine learning; open educational resource on responsible, ethical, aesthetic and functional learning in surgery procedures requiring management of incisions and sutures; on the computation of optimized trading policies using deep reinforcement learning; high data rate efficiency improvement via variable length coding for lorawan; design of a watt mechanism with crossed axes; preface; Deep learning systems for automated segmentation of brain tissues and tumors in MRIs; learning analytics in m-learning: Periodontic education; evaluation of a machine vision system applied to quality control in a liquid filling, lid and labeling line for bottles; an approach for development and testing a reliable speedometer software for speed competitions on motorsport; offline optimum tuning of the proportional integral controller for speed regulation of a bldc motor through bio-inspired algorithms; reinforcement learning applied to hexapod robot locomotion: An overview; lockdown or unlock in covid-19 disease? a reinforcement learning approach; cybersecurity analysis on pacs-dicom servers in chile; experimental based-analisis of the optimal transmission thresholds for wsns in noisy channels; a parallel rollout algorithm for wildfire suppression; the effect of bilateral filtering in 3d reconstruction using psp.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Using machine learning to assess solar energy grid disturbances",
        "publication": "Proceedings of the International Conference on Industrial Engineering and Operations Management",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Energy generation, sources and distribution methods have been continuously evolving over the past decade. With the increased efficiency associated with solar energy production and distribution, local homeowners have also assumed the role of energy generators, even getting credit for access electricity supplied to the grid given the policy around net-metering. When planning their energy distribution frameworks, electricity providers have to take these changes in energy consumption and generation into account. However, little is known about how solar energy systems impact the demand and supply of grid electricity managed by utility companies. This study proposes a new approach to solar energy predictive modeling which combines machine learning and a variety of publicly available data sources to predict site-specific temperature and solar irradiance (the two primary “missing ingredients”). The preliminary findings show a decreased error when using the new approach (near-future data) in comparison to the traditional approach (historical data) for predicting solar energy generation. As the adoption of solar energy increases, so will potential disruptions to the grid. These preliminary findings show the potential for aggregating individual site-specific predictions to the regional level for the purpose of estimating area-specific solar energy disturbances and moving efforts towards predictive grid optimization.",
        "DOI": "NA",
        "paper_author": "Ramirez J.",
        "affiliation_name": "Purdue Polytechnic Institute",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60017406",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "On the computation of optimized trading policies using deep reinforcement learning",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper we present a deep reinforcement learning-based methodology for computing optimized trading policies. During the first stage of the methodology, we employ Gated Recurrent Units (GRUs) to predict the immediate future behaviour of the time series that describe the temporal dynamics of the value of a set of assets. Then, we employ a Deep Q-Learning Architecture to compute optimized trading policies that describe, at every point in time, which assets have to be bought and which have to be sold in order to maximize profit. Our experimental results, which are based on trading cryptocurrencies, show that the proposed algorithm effectively computes trading policies that achieve incremental profits from an initial budget.",
        "DOI": "10.1007/978-3-030-62554-2_7",
        "paper_author": "Corona-Bermudez U.",
        "affiliation_name": "Centro de Investigación en Computación",
        "affiliation_city": "Mexico City",
        "affiliation_country": "Mexico",
        "affiliation_id": "106283805",
        "affiliation_state": "Mexico, D.F"
    },
    {
        "paper_title": "Measure What Matters: A Dual Outcome Service Quality Model for Government Service Delivery",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Measuring customer service quality evaluations has been important since the rise of the service industry and many models in this area have been published. Most models focus on one outcome with a set of predictors. These outcomes are often ill defined and concepts are used interchangeably causing issues in creating good and consistent measures of quality. In this study we develop a new model combining multiple outcome variables and a series of predictors to show the interdependent nature of service outcomes. We test the model using machine learning based on survey responses from 3702 Dutch people. The results indicate that two types of outcome variables are important; quality of the outcome and satisfaction with the process. Each is predicted in different ways by four dimensions. This means governments could benefit from a better specification of the desired outcomes of service delivery and targeted measurement approaches.",
        "DOI": "10.1007/978-3-030-57599-1_11",
        "paper_author": "Pieterson W.",
        "affiliation_name": "Center for eGovernment Studies/Pieterson Strategic",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "125409886",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Using Government Data and Machine Learning for Predicting Firms’ Vulnerability to Economic Crisis",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The COVID-19 pandemic is expected to lead to a severe recessionary economic crisis with quite negative consequences for large numbers of firms and citizens; however, this is an ‘old story’: recessionary economic crises appear repeatedly in the last 100 years in the market-based economies, and they are recognized as one of the most severe and threatening weaknesses of them. They can result in closure of numerous firms, and decrease of activities of many more, as well as poverty and social exclusion for large parts of the population, and finally lead to political upheaval and instability; so they constitute one of the most threatening and difficult problems that governments often face. For the above reasons it is imperative that governments develop effective public policies and make drastic interventions for addressing these economic crises. Quite useful for these interventions can be the prediction of the vulnerability of individual firms to recessionary economic crisis, so that government can focus its attention as well as its scarce economic resources on the most vulnerable ones. In this direction our paper presents a methodology for using existing government data in order to predict the vulnerability of individual firms to economic crisis, based on Artificial Intelligence (AI) Machine Learning (ML) algorithms. Furthermore, a first application of the proposed methodology is presented, based on existing data from the Greek Ministry of Finance and Statistical Authority concerning 363 firms for the economic crisis period 2009–2014, which gives encouraging results.",
        "DOI": "10.1007/978-3-030-57599-1_26",
        "paper_author": "Loukis E.",
        "affiliation_name": "University of the Aegean",
        "affiliation_city": "Mytilene",
        "affiliation_country": "Greece",
        "affiliation_id": "60017404",
        "affiliation_state": "North Aegean"
    },
    {
        "paper_title": "The data-based methodology for crime forecasting system",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The project's main goal was to create an analytical service platform for forecasting crime, which can strengthen the ability to prevent and combat crime based on verifiable forecasts and optimize the use of available Police forces and resources. As in forecasting criminal events over time, future events are associated with a sequence of historical ones by time series of observational irregularly spaced data and other exogenous variables affecting crime, especially various factors related to the entire environment: natural, social, economic, legal, and political, to which the forecast is to affect crime level and structure. The development of sufficient crime threat data-based prediction models may require an appropriate combination of criminal event history, determining the risk level, and geographic data characterizing the areas for which the threat is predicted. The article presents the data-based methodology for crime forecasting system and exemplary operating results. The final evaluation was done to verify the forecasts obtained based on actual data for selected categories of crime, considering the optimization of the use of forces and resources and identify proposals for changes in the criminal policy.",
        "DOI": "10.1117/12.2583580",
        "paper_author": "Wawrzyniak Z.M.",
        "affiliation_name": "Politechnika Warszawska",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60003675",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Artificial intelligence and automation in financial services: The case of Russian banking sector",
        "publication": "Law and Economics Yearly Review",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "This article discusses the impact of innovation in the Russian banking sector. This innovation, often referred to as FinTech, comprises cryptoassets, artificial intelligence and RegTech (i.e., applications of digital technology by regulation and compliance actors). The aim of the article is to examine the importance of the new frontiers of technologies in financial services like smart contracts, peer-to-peer lending and crowdfunding platforms. In this context, the article analyses the evolution of artificial intelligence in Russia with emphasis on robotics and automated mechanisms implemented in the financial firms. It also provides an overview of the initiatives of the Central Bank of Russia and their main effects in the payment system. The implications of machine learning and automation are discussed in terms of monetary policy, prudential regulation and investor protection.",
        "DOI": "NA",
        "paper_author": "Goncharenko I.A.",
        "affiliation_name": "Moscow State Institute of International Relations (MGIMO)",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60032576",
        "affiliation_state": "Moscow Oblast"
    },
    {
        "paper_title": "Cyber Resilience in Healthcare Digital Twin on Lung Cancer",
        "publication": "IEEE Access",
        "citied_by": "87",
        "cover_date": "2020-01-01",
        "Abstract": "As a key service of the future 6G network, healthcare digital twin is the virtual replica of a person, which employs Internet of Things (IoT) technologies and AI-powered models to predict the state of health and provide suggestions to a range of clinical questions. To support healthcare digital twins, the right cyber resilience technologies and policies must be applied and maintained to preserve cyber resilience. Vulnerability detection is a fundamental technology for cyber resilience in healthcare digital twins. Recently, deep learning (DL) has been applied to address the limitations of traditional machine learning in vulnerability detection. However, it is important to consider code context relationships and pay attention on the vulnerability related keywords for searching an IoT vulnerability in healthcare digital twins. Due to massive software and complexity of healthcare digital twin, a full automatic solution is really needed for assisting cyber resilience check in the real-world scenarios. This article presents a novel scheme for recognising potential vulnerable functions to support healthcare digital twins. We develop a new deep neural model to capture bi-directional context relationships among the risky code keywords. A number of well-designed experiments are carried out on a large ground truth, which consists of tens of thousands of vulnerable and non-vulnerable functions from IoT related software. The results show our new scheme outperforms the state-of-the-art DL-based methods for vulnerability detection.",
        "DOI": "10.1109/ACCESS.2020.3034324",
        "paper_author": "Zhang J.",
        "affiliation_name": "Yunnan Normal University",
        "affiliation_city": "Chenggong",
        "affiliation_country": "China",
        "affiliation_id": "60019218",
        "affiliation_state": "Yunnan"
    },
    {
        "paper_title": "Detecting and characterizing archetypes of unintended consequences in engineered systems",
        "publication": "Proceedings of the ASME Design Engineering Technical Conference",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "When designing engineered systems, the potential for unintended consequences of design policies exists despite best intentions. The effect of risk factors for unintended consequences are often known only in hindsight. However, since historical knowledge is generally associated with a single event, it is difficult to uncover general trends in the formation and types of unintended consequences. In this research, archetypes of unintended consequences are learned from historical data. This research contributes toward the understanding of archetypes of unintended consequences by using machine learning over a large data set of lessons learned from adverse events at NASA. Sixtysix archetypes are identified because they share similar sets of risk factors such as complexity and human-machine interaction. To validate the learned archetypes, system dynamics representations of the archetypes are compared to known high-level archetypes of unintended consequences. The main contribution of the paper is a set of archetypes that apply to many engineered systems and a pattern of leading indicators that open a new path to manage unintended consequences and mitigate the magnitude of potentially adverse outcomes.",
        "DOI": "NA",
        "paper_author": "Walsh H.S.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Corvallis",
        "affiliation_country": "United States",
        "affiliation_id": "60137364",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Using artificial neural networks in reinforcement learning algorithms",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement learning algorithms represent a specific category in the machine learning field precisely because of their unique approach based on a trial-error basis. We introduce a new approach into the Q-algorithm, namely maximizing k-future rewards policy, which decreases learning time and increases maximal and average score value of an optimizing function significantly. Our modified Deep NNQ-learning using feed-forward networks instead of originally proposed convolutional neural networks gives the best results in a tested problem. We implemented the developed algorithm for the Flappy Bird game where significant improvements are achieved by appropriate setting of state space, act policy, and by pretraining neural networks.",
        "DOI": "NA",
        "paper_author": "Glova M.",
        "affiliation_name": "Pavol Jozef Šafárik University in Košice",
        "affiliation_city": "Kosice",
        "affiliation_country": "Slovakia",
        "affiliation_id": "60031236",
        "affiliation_state": "Kosice Region"
    },
    {
        "paper_title": "Learning robots and human responsibility",
        "publication": "Machine Ethics and Robot Ethics",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Epistemic limitations concerning prediction and explanation of the behaviour of robots that learn from experience are selectively examined by reference to machine learning methods and computational theories of supervised inductive learning. Moral responsibility and liability ascription problems concerning damages caused by learning robot actions are discussed in the light of these epistemic limitations. In shaping responsibility ascription policies one has to take into account the fact that robots and softbots - by combining learning with autonomy, pro-activity, reasoning, and planning - can enter cognitive interactions that human beings have not experienced with any other non-human system.",
        "DOI": "10.4324/9781003074991-33",
        "paper_author": "Marino D.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The Need for Artificial Intelligence in Digital Therapeutics",
        "publication": "Digital Biomarkers",
        "citied_by": "40",
        "cover_date": "2020-01-01",
        "Abstract": "Digital therapeutics is a newly described concept in healthcare which is proposed to change patient behavior and treat medical conditions using a variety of digital technologies. However, the term is rarely defined with criteria that make it distinct from simply digitizedversions of traditional therapeutics. Our objective is to describe a more valuable characteristic of digital therapeutics, which is distinct from traditional medicine or therapy: that is, the utilization of artificial intelligence and machine learning systems to monitor and predict individual patient symptom data in an adaptive clinical feedback loop via digital biomarkers to provide a precision medicine approach to healthcare. Artificial intelligence platforms can learn and predict effective interventions for individuals using a multitude of personal variables to provide a customized and more tailored therapy regimen. Digital therapeutics coupled with artificial intelligence and machine learning also allows more effective clinical observations and management at the population level for various health conditions and cohorts. This vital differentiation of digital therapeutics compared to other forms of therapeutics enables a more personalized form of healthcare that actively adapts to patients' individual clinical needs, goals, and lifestyles. Importantly, these characteristics are what needs to be emphasized to patients, physicians, and policy makers to advance the entire field of digital healthcare.",
        "DOI": "10.1159/000506861",
        "paper_author": "Palanica A.",
        "affiliation_name": "Klick Inc.",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "114784616",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Key performance indicators for decision making in building energy systems",
        "publication": "ECOS 2020 - Proceedings of the 33rd International Conference on Efficiency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "Policy makers and energy operator have the responsibility to select indicators for their mission to lead the renewable energy transition ensuring energy independence and security of supply in the context of decarbonisation of the energy mix and and/or nuclear phase-out with increasing cost for flexibility. Engineers are therefore asked to propose key performance indicators (KPI) allowing to quantify the positive impact of operation strategies and efficient technology solutions to harvest and distribute more renewable resources, while minimizing the environmental impact and overall costs. The aim of this paper is to analyze the impact of KPIs and their different definitions on planning building energy systems (BES) in order to support decision maker to define, monitor and fulfill their objective. A wide-range of alternative solutions are generated using Mixed Linear Integer Programming (MILP) and Multi Objective Optimization (MOO) to capture the decision space of BES. Machine learning techniques, like principle component analysis and k-medoids clustering, are applied to identify the major trends, thus supporting multi - criteria decision making. Results highlight the correlations between twenty-six indicators, showing the importance of (i) setting appropriate system boundaries, (ii) using hourly resolution and (iii) constructional footprint to characterize flexible systems. Low emission electrical grid mix has a high impact on strategic planning and is in conflict with decentralized, self-sufficient energy systems. Including life cycle assessment (LCA) of the system shows besides operational emission, the constructional footprint is significantly contributing to the total Global Warming Potential (GWP). Considering the ecological optimal BES in Switzerland, this contribution is more than 40%, while for high emission electrical grid mix the latter accounts for more than 90%.",
        "DOI": "NA",
        "paper_author": "Middelhauve L.",
        "affiliation_name": "École Polytechnique Fédérale de Lausanne",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60028186",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Towards making the most of BERT in neural machine translation",
        "publication": "AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",
        "citied_by": "103",
        "cover_date": "2020-01-01",
        "Abstract": "GPT-2 and BERT demonstrate the effectiveness of using pretrained language models (LMs) on various natural language processing tasks. However, LM fine-tuning often suffers from catastrophic forgetting when applied to resource-rich tasks. In this work, we introduce a concerted training framework (CTNMT) that is the key to integrate the pre-trained LMs to neural machine translation (NMT). Our proposed CTNMT consists of three techniques: a) asymptotic distillation to ensure that the NMT model can retain the previous pre-trained knowledge; b) a dynamic switching gate to avoid catastrophic forgetting of pre-trained knowledge; and c) a strategy to adjust the learning paces according to a scheduled policy. Our experiments in machine translation show CTNMT gains of up to 3 BLEU score on the WMT14 English-German language pair which even surpasses the previous state-of-the-art pretraining aided NMT by 1.4 BLEU score. While for the large WMT14 English-French task with 40 millions of sentencepairs, our base model still significantly improves upon the state-of-the-art Transformer big model by more than 1 BLEU score.",
        "DOI": "NA",
        "paper_author": "Yang J.",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60025084",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The differentiable cross-entropy method",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "We study the cross-entropy method (CEM) for the non-convex optimization of a continuous and parameterized objective function and introduce a differentiable variant that enables us to differentiate the output of CEM with respect to the objective function s parameters. In the machine learning setting this brings CEM inside of the endto-end learning pipeline where this has otherwise been impossible. We show applications in a synthetic energy-based structured prediction task and in non-convex continuous control. In the control setting we show how to embed optimal action sequences into a lower-dimensional space. DCEM enables us to fine-Tune CEM-based controllers with policy optimization.",
        "DOI": "NA",
        "paper_author": "Amos B.",
        "affiliation_name": "Facebook Research",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States",
        "affiliation_id": "60111190",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Adaptive targeted infectious disease testing",
        "publication": "Oxford Review of Economic Policy",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "We show how to efficiently use costly testing resources in an epidemic, when testing outcomes can be used to make quarantine decisions. If the costs of false quarantine and false release exceed the cost of testing, the optimal myopic testing policy targets individuals with an intermediate likelihood of being infected. A high cost of false release means that testing is optimal for individuals with a low probability of infection, and a high cost of false quarantine means that testing is optimal for individuals with a high probability of infection. If individuals arrive over time, the policy-maker faces a dynamic trade-off: using tests for individuals for whom testing yields the maximum immediate benefit vs spreading out testing capacity across the population to learn prevalence rates thereby benefiting later individuals. We describe a simple policy that is nearly optimal from a dynamic perspective. We briefly discuss practical aspects of implementing our proposed policy, including imperfect testing technology, appropriate choice of prior, and non-stationarity of the prevalence rate.",
        "DOI": "10.1093/oxrep/graa018",
        "paper_author": "Kasy M.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "MultiMBNN: Matched and balanced causal inference with neural networks",
        "publication": "ESANN 2020 - Proceedings, 28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Causal inference (CI) in observational studies has received a lot of attention in healthcare, education, ad attribution, policy evaluation, etc. Confounding is a typical hazard, where the context affects both, the treatment assignment and response. In a multiple treatment scenario, we propose the neural network based MultiMBNN, where we overcome confounding by employing generalized propensity score based matching, and learning balanced representations. We benchmark the performance on synthetic and real-world datasets using PEHE, and mean absolute percentage error over ATE as metrics. MultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and Perfect Match (PM).",
        "DOI": "NA",
        "paper_author": "Sharma A.",
        "affiliation_name": "TCS Research",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60283297",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Learning to optimize variational quantum vircuits to solve combinatorial problems",
        "publication": "AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",
        "citied_by": "76",
        "cover_date": "2020-01-01",
        "Abstract": "Quantum computing is a computational paradigm with the potential to outperform classical methods for a variety of problems. Proposed recently, the Quantum Approximate Optimization Algorithm (QAOA) is considered as one of the leading candidates for demonstrating quantum advantage in the near term. QAOA is a variational hybrid quantumclassical algorithm for approximately solving combinatorial optimization problems. The quality of the solution obtained by QAOA for a given problem instance depends on the performance of the classical optimizer used to optimize the variational parameters. In this paper, we formulate the problem of finding optimal QAOA parameters as a learning task in which the knowledge gained from solving training instances can be leveraged to find high-quality solutions for unseen test instances. To this end, we develop two machine-learning-based approaches. Our first approach adopts a reinforcement learning (RL) framework to learn a policy network to optimize QAOA circuits. Our second approach adopts a kernel density estimation (KDE) technique to learn a generative model of optimal QAOA parameters. In both approaches, the training procedure is performed on small-sized problem instances that can be simulated on a classical computer; yet the learned RL policy and the generative model can be used to efficiently solve larger problems. Extensive simulations using the IBM Qiskit Aer quantum circuit simulator demonstrate that our proposed RL- and KDE-based approaches reduce the optimality gap by factors up to 30.15 when compared with other commonly used off-the-shelf optimizers.",
        "DOI": "NA",
        "paper_author": "Khairy S.",
        "affiliation_name": "Illinois Institute of Technology",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States",
        "affiliation_id": "60002873",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Relational economic geography and firm-level export activities at trade fairs: A study of south Korean sme machine tool manufacturers",
        "publication": "Pennsylvania Geographer",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Small and medium-sized enterprises (SMEs) are faced with myriad disadvantages when trying to enhance their competitiveness and expand into international markets. International trade fairs (ITFs) are one way firms may mitigate these disadvantages. This article deploys a multi-faceted relational economic geography (REG) framework and four research questions to examine South Korean SME, export-related, ITF dynamics and their resulting organizational, spatial, and structural outcomes. Results, based on quantitative analyses of firm-level data, reveal the effect of firm-level variables on the relational context at an ITF; the impact of organizational learning at ITFs on longer-term, export-oriented routines; evidence of spatial and structural lock-in and avenues to counter them; the importance of an ITF in the innovation context; and impacts of specific antecedents of power vis-à-vis relationship building and maintenance taking place at an ITF. Implications for Korea's SME and ITF policies as well as broader implications for exporting and REG-based research are discussed.",
        "DOI": "NA",
        "paper_author": "Gress D.R.",
        "affiliation_name": "Seoul National University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60013682",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A performance-based start state curriculum framework for reinforcement learning",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "Sparse reward problems present a challenge for reinforcement learning (RL) agents. Previous work has shown that choosing start states according to a curriculum can significantly improve the learning performance. We observe that many existing curriculum generation algorithms rely on two key components: Performance measure estimation and a start selection policy. Therefore, we propose a unifying framework for performance-based start state curricula in RL, which allows to analyze and compare the performance influence of the two key components. Furthermore, a new start state selection policy using spatial performance measure gradients is introduced. We conduct extensive empirical evaluations to compare performance-based start state curricula and investigate the influence of performance measure model choice and estimation. Benchmarking on difficult robotic navigation tasks and a high-dimensional robotic manipulation task, we demonstrate state-of-the-art performance of our novel spatial gradient curriculum.",
        "DOI": "NA",
        "paper_author": "Wöhlke J.",
        "affiliation_name": "Universiteit van Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60002483",
        "affiliation_state": "Noord-Holland"
    },
    {
        "paper_title": "Integrating behavior cloning and reinforcement learning for improved performance in dense and sparse reward environments",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "36",
        "cover_date": "2020-01-01",
        "Abstract": "This paper investigates how to efficiently transition and update policies, trained initially with demonstrations, using off-policy actor-critic reinforcement learning. It is well-known that techniques based on Learning from Demonstrations, for example behavior cloning, can lead to proficient policies given limited data. However, it is currently unclear how to efficiently update that policy using reinforcement learning as these approaches are inherently optimizing different objective functions. Previous works have used loss functions, which combine behavior cloning losses with reinforcement learning losses to enable this update. However, the components of these loss functions are often set anecdotally, and their individual contributions are not well understood. In this work, we propose the Cycle-of-Learning (CoL) framework that uses an actor-critic architecture with a loss function that combines behavior cloning and 1-step Q-learning losses with an off-policy pre-training step from human demonstrations. This enables transition from behavior cloning to reinforcement learning without performance degradation and improves reinforcement learning in terms of overall performance and training time. Additionally, we carefully study the composition of these combined losses and their impact on overall policy learning. We show that our approach outperforms state-of-the-art techniques for combining behavior cloning and reinforcement learning for both dense and sparse reward scenarios. Our results also suggest that directly including the behavior cloning loss on demonstration data helps to ensure stable learning and ground future policy updates.",
        "DOI": "NA",
        "paper_author": "Goecks V.G.",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60020547",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
        "publication": "37th International Conference on Machine Learning, ICML 2020",
        "citied_by": "17",
        "cover_date": "2020-01-01",
        "Abstract": "Finite-horizon sequential experimental design (SED) arises naturally in many contexts, including hyperparameter tuning in machine learning among more traditional settings. Computing the optimal policy for such problems requires solving Bellman equations, which are generally intractable. Most existing work resorts to severely myopic approximations by limiting the decision horizon to only a single time-step, which can underweight exploration in favor of exploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid SED, a general framework for deriving efficient, nonmyopic approximations to the optimal experimental policy. Our key idea is simple and surprisingly effective: we first compute a one-step optimal batch of experiments, then select a single point from this batch to evaluate. We realize BINOCULARS for Bayesian optimization and Bayesian quadrature-Two notable SED problems with radically different objectives-And demonstrate that BINOCULARS significantly outperforms myopic alternatives in real-world scenarios.",
        "DOI": "NA",
        "paper_author": "Jiang S.",
        "affiliation_name": "McKelvey School of Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60105336",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Implementing FAIR data for people and machines: Impacts and implications-Results of a research data community workshop",
        "publication": "Information Services and Use",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "The Implementing FAIR Data for People and Machines: Impacts and Implications workshop was organized by the Board on Research Data and Information of the National Academies of Sciences, Engineering, and Medicine (NASEM), the CENDI Federal Information Managers Group, the Research Data Alliance (RDA), and the National Federation of Advanced Information Services (NFAIS), and held at NASEM's Keck Center in Washington, DC on September 11, 2019. The goals of the Implementing FAIR Data workshop were to discuss the current status of FAIR data implementation, share what is being done to encourage scientists to share data in machine-readable formats, and examine the implications of FAIR data implementation for people and machines. FAIR data policies, tools, and measures of FAIR data compliance were considered from multiple perspectives. Marcia McNutt, President of the National Academy of Sciences (NAS), offered opening remarks, and the keynote address was presented by Barend Mons, Professor of Bioinformatics at Leiden University Medical Center and President of the International Science Council's Committee on Data (CODATA). Three panel discussions addressed (1) the perspectives of scientists and administrators from U.S. federal agencies, (2) case studies on the implementation of FAIR data practices, and (3) principles and methods of measuring FAIR data compliance. The automation of scientific workflows was discussed by Stuart Feldman, Chief Scientist of Schmidt Futures, a philanthropic organization devoted to investing in research, technology, and science. The workshop closed with highlights and takeaways from each session as summarized by the moderators, followed by general questions.",
        "DOI": "10.3233/ISU-200083",
        "paper_author": "Borycz J.",
        "affiliation_name": "Vanderbilt University",
        "affiliation_city": "Nashville",
        "affiliation_country": "United States",
        "affiliation_id": "60003915",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Efficient processing of image processing applications on CPU/GPU",
        "publication": "Mathematical Problems in Engineering",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "Heterogeneous systems have gained popularity due to the rapid growth in data and the need for processing this big data to extract useful information. In recent years, many healthcare applications have been developed which use machine learning algorithms to perform tasks such as image classification, object detection, image segmentation, and instance segmentation. The increasing amount of big visual data requires images to be processed efficiently. It is common that we use heterogeneous systems for such type of applications, as processing a huge number of images on a single PC may take months of computation. In heterogeneous systems, data are distributed on different nodes in the system. However, heterogeneous systems do not distribute images based on the computing capabilities of different types of processors in the node; therefore, a slow processor may take much longer to process an image compared to a faster processor. This imbalanced workload distribution observed in heterogeneous systems for image processing applications is the main cause of inefficient execution. In this paper, an efficient workload distribution mechanism for image processing applications is introduced. The proposed approach consists of two phases. In the first phase, image data are divided into an ideal split size and distributed amongst nodes, and in the second phase, image data are further distributed between CPU and GPU according to their computation speeds. Java bindings for OpenCL are used to configure both the CPU and GPU to execute the program. The results have demonstrated that the proposed workload distribution policy efficiently distributes the images in a heterogeneous system for image processing applications and achieves 50% improvements compared to the current state-of-the-art programming frameworks.",
        "DOI": "10.1155/2020/4839876",
        "paper_author": "Naz N.",
        "affiliation_name": "University of Peshawar",
        "affiliation_city": "Peshawar",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60050751",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep Reinforcement Learning Agent with Varying Actions Strategy for Solving the Eco-Approach and Departure Problem at Signalized Intersections",
        "publication": "Transportation Research Record",
        "citied_by": "26",
        "cover_date": "2020-01-01",
        "Abstract": "Eco-approach and departure is a complex control problem wherein a driver’s actions are guided over a period of time or distance so as to optimize fuel consumption. Reinforcement learning (RL) is a machine learning paradigm that mimics human learning behavior, in which an agent attempts to solve a given control problem by interacting with the environment and developing an optimal policy. Unlike the methods implemented in previous studies for solving the eco-driving problem, RL does not require prior knowledge of the environment to be learned and processed. This paper develops a deep reinforcement learning (DRL) agent for solving the eco-approach and departure problem in the vicinity of signalized intersections for minimization of fuel consumption. The DRL algorithm utilizes a deep neural network for the RL. Novel strategies such as varying actions, prioritized experience replay, target network, and double learning were implemented to overcome the expected instabilities during the training process. The results revealed the significance of the DRL algorithm in reducing fuel consumption. Interestingly, the DRL algorithm was able to successfully learn the environment and guide vehicles through the intersection without red light running violation. On average, the DRL provided fuel savings of about 13.02% with no red light running violations.",
        "DOI": "10.1177/0361198120931848",
        "paper_author": "Mousa S.R.",
        "affiliation_name": "Booz Allen Hamilton, Inc.",
        "affiliation_city": "McLean",
        "affiliation_country": "United States",
        "affiliation_id": "60027432",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Classification of wheat seeds using image processing and fuzzy clustered random forest",
        "publication": "International Journal of Agricultural Resources, Governance and Ecology",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "A reliable and autonomic seed classification technique can overcome the issues of manual seed classification. It is a highly practical and economically vital need of the agriculture industry. The current techniques of machine learning and artificial intelligence allows the researchers to design a new data mining mechanism with higher accuracy. In this article, a new adaptive technique has been proposed using a digital image processing system (DIPS) and fuzzy clustered random forest (FCRF) techniques. The DIPS is used to extract the parameters such as area, perimeter, height, width, length of the groove and asymmetry coefficient. Further, FCRF model is applied to classify the wheat seeds based on these parameters in a time-efficient manner. The devised approach helps the agriculture industry for seed classification, separation of damaged seeds and controlling the quality of seeds based on grading policy. The experiment result demonstrates that the accuracy of the proposed technique is better than the existing wheat seed classification algorithm. The average performance gain of the proposed technique is up to 97.7%.",
        "DOI": "10.1504/ijarge.2020.109048",
        "paper_author": "Singh P.",
        "affiliation_name": "Lovely Professional University",
        "affiliation_city": "Phagwara",
        "affiliation_country": "India",
        "affiliation_id": "60094571",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Nonmyopic Gaussian Process Optimization with Macro-Actions",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "This paper presents a multi-staged approach to nonmyopic adaptive Gaussian process optimization (GPO) for Bayesian optimization (BO) of unknown, highly complex objective functions that, in contrast to existing nonmyopic adaptive BO algorithms, exploits the notion of macro-actions for scaling up to a further lookahead to match up to a larger available budget. To achieve this, we generalize GP upper confidence bound to a new acquisition function defined w.r.t. a nonmyopic adaptive macro-action policy, which is intractable to be optimized exactly due to an uncountable set of candidate outputs. The contribution of our work here is thus to derive a nonmyopic adaptive ∊-Bayes-optimal macro-action GPO (∊-Macro-GPO) policy. To perform nonmyopic adaptive BO in real time, we then propose an asymptotically optimal anytime variant of our ∊-Macro-GPO policy with a performance guarantee. We empirically evaluate the performance of our ∊-Macro-GPO policy and its anytime variant in BO with synthetic and real-world datasets.",
        "DOI": "NA",
        "paper_author": "Kharkovskii D.",
        "affiliation_name": "National University of Singapore",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60017161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "New U.S. And International Water Main Break Studies: More Detailed Pipe Analysis but What Are We Doing with the Data?",
        "publication": "Pipelines 2020: Utility Engineering, Surveying, and Multidisciplinary Topics - Proceedings of Sessions of the Pipelines 2020 Conference",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "This paper reviews the water main break research and findings from Utah State University, Purdue University, Louisiana Tech, which have formed the new foundation to help utilities to better understand what future trends of water main breaks may look like nationally. International main break data from Australia is also available to be used to contrast results from the U.S. The next generation of water main pipe performance research will include advanced analytics and predictive analysis using machine learning taking into consideration hundreds of potential pipe performance variables such as climate and environmental corrosive soil variables. Private digital pipe condition assessment firms are amassing huge predictive data sets not based in survey results but GIS main break files. Another effort includes the development of national pipe inventory and pipe performance database called the PipeID project at Virginia Tech. This federally funded project while offering direct benefits to over 500 participating water utilities can also provide regional insight to utilities and the aggregate data will be used for federal policy making on regarding water pipe performance standards.",
        "DOI": "10.1061/9780784483213.035",
        "paper_author": "Baird G.M.",
        "affiliation_name": "Water Finance Research",
        "affiliation_city": "Provo",
        "affiliation_country": "United States",
        "affiliation_id": "125151814",
        "affiliation_state": "UT"
    },
    {
        "paper_title": "Artificial intelligence and its’ legal risk to cybersecurity",
        "publication": "European Conference on Information Warfare and Security, ECCWS",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "The risk pertaining to data and technology are continuously growing in scale and severity as the dependence on, and advancement in technology grows. The last decade has seen hundreds of cases of identity theft, loss of money and data breaches. It is estimated that by the year 2021, cybercrime losses may cost upwards of $6 million annually. Due to the constant risk of intrusions, the tech industry, businesses and government bodies must safeguard technology and data and this is where cybersecurity plays a major and critical role. It may be considered as the first line of defense against intrusions. The tools and techniques developed and supported by AI and machine learning (ML) are now expanding to cybersecurity to protect against cybercrime. There are many advantages in using AI-ML technology for cybersecurity but it is a double-edged sword. Just as AI cybersecurity technology may be used to more accurately identify and stop intrusions, the AI systems may be exploited for the commission of cybercrime. Cybersecurity is not an issue that a government can address on its own; it requires multi-stakeholders to work together in addressing the legal risk AI-ML technology presents to cybersecurity. The discussion is divided into two parts: Part 1 explores the beneficial use of AI cybersecurity technology; and Part 2 considers the harmful use of AI such as data breaches and the commission of cybercrimes. Cybersecurity and cybercrime are issues that cannot be separated from each other. AI-driven cybersecurity technology must keep pace with the legal risk that the use of AI in the commission of cybercrime poses otherwise it cannot effectively prevent, detect, respond to and recover from an intrusion. A preventative approach rather than a detection-focused approach should be applied to cybersecurity. The discussion identifies the legal risk that the use of AI for cybersecurity presents and how it may be addressed by means of ethics, policies and laws.",
        "DOI": "10.34190/EWS.20.026",
        "paper_author": "Watney M.M.",
        "affiliation_name": "University of Johannesburg",
        "affiliation_city": "Johannesburg",
        "affiliation_country": "South Africa",
        "affiliation_id": "60000717",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "Renewable energy firm's performance analysis using machine learning approach",
        "publication": "Procedia Computer Science",
        "citied_by": "13",
        "cover_date": "2020-01-01",
        "Abstract": "This study aims to identify the trend in the financial performance of renewable energy companies and to outline the renewable energy policies impacting their performance. The study is conducted on major renewable energy companies of India and US for the study period of 2015-2019. The financial performance of these companies is analyzed by using return on equity (ROE) decomposition and the trend in their performance is identified by utilizing k-means cluster of machine learning algorithm. Based on their ROE performance, five clusters are formed for Indian companies and four for US companies. It is observed that the performance of the companies in the renewable sector is heavily influenced by the government policies and for these companies to succeed, it is important that the government sets out policies which motivate these companies to invest more for clean energy development.",
        "DOI": "10.1016/j.procs.2020.07.071",
        "paper_author": "Rastogi R.",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India",
        "affiliation_id": "60000414",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Landsat’s past paves the way for data democratization in earth science",
        "publication": "Data Democracy: At the Nexus of Artificial Intelligence, Software Development, and Knowledge Engineering",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "The Landsat Program has been observing and collecting Earth system data from space since 1972. Over this time, advances in spatial, spectral, and radiometric resolution have allowed the Landsat satellites to evolve into powerful global Earth observation imaging systems. The longevity of the Landsat Program has produced a massive catalogue of imagery data. The sheer magnitude of this collection necessitates the use of scalable techniques to extract value from decades of remote sensing data. With the introduction of commercial cloud computing, it is now possible to cheaply provision resources for processing and storing enormous amounts of such data. Machine learning-based computer vision is advancing at a blistering pace and has shown great promise when applied to satellite imagery. The combination of cloud computing and machine learning offers the ability to analyze the decades of imagery collected by the Landsat Program at a cost never before possible. The focus of this chapter is to discuss the Landsat Program progression, cloud computing, machine learning, and data policy and how all these components contribute to greater understanding on the state of our planet Earth.",
        "DOI": "10.1016/B978-0-12-818366-3.00008-3",
        "paper_author": "Yuan K.",
        "affiliation_name": "George Mason University",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States",
        "affiliation_id": "60018319",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Human-Machine Shared Contexts",
        "publication": "Human-Machine Shared Contexts",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Human-Machine Shared Contexts considers the foundations, metrics, and applications of human-machine systems. Editors and authors debate whether machines, humans, and systems should speak only to each other, only to humans, or to both and how. The book establishes the meaning and operation of “shared contexts” between humans and machines; it also explores how human-machine systems affect targeted audiences (researchers, machines, robots, users) and society, as well as future ecosystems composed of humans and machines. This book explores how user interventions may improve the context for autonomous machines operating in unfamiliar environments or when experiencing unanticipated events; how autonomous machines can be taught to explain contexts by reasoning, inferences, or causality, and decisions to humans relying on intuition; and for mutual context, how these machines may interdependently affect human awareness, teams and society, and how these “machines” may be affected in turn. In short, can context be mutually constructed and shared between machines and humans? The editors are interested in whether shared context follows when machines begin to think, or, like humans, develop subjective states that allow them to monitor and report on their interpretations of reality, forcing scientists to rethink the general model of human social behavior. If dependence on machine learning continues or grows, the public will also be interested in what happens to context shared by users, teams of humans and machines, or society when these machines malfunction. As scientists and engineers “think through this change in human terms, \" the ultimate goal is for AI to advance the performance of autonomous machines and teams of humans and machines for the betterment of society wherever these machines interact with humans or other machines. This book will be essential reading for professional, industrial, and military computer scientists and engineers; machine learning (ML) and artificial intelligence (AI) scientists and engineers, especially those engaged in research on autonomy, computational context, and human-machine shared contexts; advanced robotics scientists and engineers; scientists working with or interested in data issues for autonomous systems such as with the use of scarce data for training and operations with and without user interventions; social psychologists, scientists and physical research scientists pursuing models of shared context; modelers of the internet of things (IOT); systems of systems scientists and engineers and economists; scientists and engineers working with agent-based models (ABMs); policy specialists concerned with the impact of AI and ML on society and civilization; network scientists and engineers; applied mathematicians (e.g., holon theory, information theory); computational linguists; and blockchain scientists and engineers.",
        "DOI": "10.1016/B978-0-12-820543-3.09990-9",
        "paper_author": "Lawless W.F.",
        "affiliation_name": "Paine College",
        "affiliation_city": "Augusta",
        "affiliation_country": "United States",
        "affiliation_id": "60103945",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Forecasting of Wind Turbine Output Power Using Machine learning",
        "publication": "Proceedings - International Conference on Advanced Computer Information Technologies, ACIT",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "Most of the countries around the world are facing huge environmental impact, and the most promising solution to mitigate these is the use of renewable energy, especially wind power. Though, the use of offshore wind energy is rapidly increasing to meet the elevating electricity demand. The researchers and policymakers have become aware of the importance of providing near accurate prediction of output power. Wind energy is tied to variabilities of weather patterns, especially wind speed, which are irregular in climates with erratic weather conditions. In this paper, we predicted the output power of the wind turbines using the random forest regressor algorithm. The SCADA data is collected for two years from a wind farm located in France. The model is trained using the data from 2017. The wind direction, wind speed and outdoor temperature are used as input parameters to predict output power. We test our model for two different capacity factors. The estimated mean absolute errors for the proposed model in this study were 3.6% and 7.3% for and 0.2 capacity factors, respectively. The proposed model in this study offers an efficient method to predict the output power of wind turbine with preferably low error.",
        "DOI": "10.1109/ACIT49673.2020.9208852",
        "paper_author": "Rashid H.",
        "affiliation_name": "Middle East Technical University (METU)",
        "affiliation_city": "Ankara",
        "affiliation_country": "Turkey",
        "affiliation_id": "60004305",
        "affiliation_state": "Ankara"
    },
    {
        "paper_title": "Predicting the Evolution of COVID-19 Cases and Deaths Through a Correlations-Based Temporal Network",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Given the most recent events involving the fast spreading of COVID-19, policy makers around the world have been challenged with the difficult task of developing efficient strategies to contain the dissemination of the disease among the population, sometimes by taking severe measures to restrict local activities, both socially and economically. Within this context, models which can help on predicting the spread evolution of COVID-19 in a specific region would surely help the authorities on their planning. In this paper, we introduce a semi-supervised regression model which makes use of a correlations-based temporal network, by considering the evolution of COVID-19 in different world regions, in order to predict the evolution of new confirmed cases and deaths in 27 federal units of Brazil. In this approach, each node in the network represents the COVID-19 time series in a specific region, and the edges are created according to the variations similarity between each pair of nodes, at each new time step. The results obtained, by predicting the weekly new confirmed cases and deaths in each region, are promising, with a median and mean absolute percentage error of 21% and 24%, respectively, when predicting new cases, and a median and mean absolute percentage error of 16% and 23%, respectively, when predicting new deaths, for the considered period.",
        "DOI": "10.1007/978-3-030-61380-8_27",
        "paper_author": "Colliri T.",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil",
        "affiliation_id": "60008088",
        "affiliation_state": "SP"
    },
    {
        "paper_title": "29th International Conference on Artificial Neural Networks, ICANN 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 70 papers. The special focus in this conference is on Artificial Neural Networks. The topics include: Multi-label Quadruplet Dictionary Learning; pareto Multi-task Deep Learning; Convex Graph Laplacian Multi-Task Learning SVM; prediction Stability as a Criterion in Active Learning; neural Spectrum Alignment: Empirical Study; nonlinear, Nonequilibrium Landscape Approach to Neural Network Dynamics; hopfield Networks for Vector Quantization; prototype-Based Online Learning on Homogeneously Labeled Streaming Data; neural Network Training with Safe Regularization in the Null Space of Batch Activations; the Effect of Batch Normalization in the Symmetric Phase; a Lightweight Fully Convolutional Neural Network of High Accuracy Surface Defect Detection; regularized Pooling; deep Recurrent Deterministic Policy Gradient for Physical Control; exploration via Progress-Driven Intrinsic Rewards; an Improved Reinforcement Learning Based Heuristic Dynamic Programming Algorithm for Model-Free Optimal Control; PBCS: Efficient Exploration and Exploitation Using a Synergy Between Reinforcement Learning and Motion Planning; understanding Failures of Deterministic Actor-Critic with Continuous Action Spaces and Sparse Rewards; GAN-Based Planning Model in Deep Reinforcement Learning; guided Reinforcement Learning via Sequence Learning; neural Machine Translation Based on Improved Actor-Critic Method; neural Machine Translation Based on Prioritized Experience Replay; Detecting Uncertain BNN Outputs on FPGA Using Monte Carlo Dropout Sampling; improving Multi-agent Reinforcement Learning with Imperfect Human Knowledge; adaptive Skill Acquisition in Hierarchical Reinforcement Learning; social Navigation with Human Empowerment Driven Deep Reinforcement Learning; curious Hierarchical Actor-Critic Reinforcement Learning; policy Entropy for Out-of-Distribution Classification; analysis of Reservoir Structure Contributing to Robustness Against Structural Failure of Liquid State Machine; morphological Computation of Skin Focusing on Fingerprint Structure.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "D-GHNAS for Joint Intent Classification and Slot Filling",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Intent classification and slot filling are two classical problems for spoken language understanding and dialog systems. The existing works, either accomplishing intent classification or slot filling separately or using a joint model, are all human-designed models with trial and error. In order to explore the variety of network architecture and to find whether there exist possible network architectures with better results, we proposed the D-GHNAS (Deep deterministic policy gradient based Graph Hypernetwork Neural Architecture Search) to accomplish intent classification and slot filling via a NAS (Neural Architecture Search) method. NAS based techniques can automatically search for network architectures without experts’ trial and error. Different from early NAS methods with hundreds of GPU days to find an ideal neural architecture that takes too much computation resource, in this work, hypernetwork is used to decrease the computation cost. Experimental results demonstrate that our model improves intent classification and slot filling results on public benchmark datasets ATIS and SNIPS compared with other joint models for these tasks.",
        "DOI": "10.1007/978-3-030-60259-8_58",
        "paper_author": "Tang Y.",
        "affiliation_name": "Ping An Technology (Shenzhen) Co. Ltd.",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "121437946",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Risks and Consequences of Hazard Agents to Human Health",
        "publication": "NATO Science for Peace and Security Series A: Chemistry and Biology",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Human health, as a state of complete physical, mental and social well-being and not merely the absence of disease or infirmity, is under continuous threat posed by various factors, among which the environment plays an instrumental role. Biological, chemical and physical health hazard agents trigger adverse health effects on human health. Notably, the adverse effects of biological health hazards (biohazards) on people is further dependent on both the proximal and on the worldwide environment context, bringing the need of integrative, interdisciplinary and comprehensive approaches, such as One Health and Global Health, to provide sustainable public health strategies. To fight antimicrobial resistance, recognized now as one of the major public health threat, such integrative One and Global Health strategies will be instrumental. Furthermore, because of their versatility, biohazards can be weaponized for use in bioterrorism. In this context, critical and transparent risk analysis is of utmost importance to provide informed support for delineating priorities and for defining opportunities for research, prevention, and policy. Finally, preparedness (commitment to implement and continuously monitor the International Health Regulation, measures to foster research areas like biosurveillance and cyberbiosecurity) at global scale is paramount, as highlighted by the recent report of the Global Preparedness Monitoring Board (September 2019).",
        "DOI": "10.1007/978-94-024-2041-8_8",
        "paper_author": "Schmid D.C.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "A spatial time series forecasting for mapping the risk of COVID-19 pandemic over Bandung Metropolitan Area, West Java, Indonesia",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "West Java is in the five line on the list of provinces in Indonesia with the most COVID-19 cases, as Bandung Metropolitan Area (BMA) is the second most densely populated showing the highest number after Jakarta Greater Area. Bandung Metropolitan Area consist of Bandung City, Cimahi City, Bandung Regency, and West Bandung Regency. Then, an intense movement of people created between the connected city and regency. Bandung City became the epicenter of movement BMA, since it is the province capital city, business, and education center. This fact, putting BMA at the highest risk not only for the pandemic but also socioeconomic issues. The spatial time series risk forecasting information is an essential for the decision-maker to develop a day by day policy aimed for combating the COVID-19 pandemic issue. In this study, the pandemic risk is calculated by combining vulnerability, hazard, and geodemography information. Infimap provides the People in Pixels geodemographic data, added not only the exposure of population distribution to COVID-19 but also the ratio of age. Beside those data, the daily distribution of COVID-19 cases, network data, business point, health facility point, residentials area, geodemographic (People in Pixels), and daily COVID-19 Community Mobility Reports is also been used in this study. The daily vulnerability and hazard data created since the first case on March 4th until August 21st. The hazard area is create based on the expected travel area of positive COVID-19 patient. While the vulnerability area is create using Spatial Multi Criteria Analysis (SMCA) of following data: service area of hospital, groceries (local market), and workspace. Further, the time series data of hazard and vulnerability area was inputted to develop the forecasting model based on the machine learning pipeline of Gaussian algorithm. As a result, this study shows the possibility to predict the future risk area of COVID-19 until the next 100 days condition, based on spatial timeseries forecasting model.",
        "DOI": "10.1117/12.2572536",
        "paper_author": "Manessa M.D.M.",
        "affiliation_name": "Infimap Geospasial Sistem",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia",
        "affiliation_id": "125256389",
        "affiliation_state": "Jakarta"
    },
    {
        "paper_title": "Underlying cause of death identification from death certificates using reverse coding to text and a NLP based deep learning approach",
        "publication": "Informatics in Medicine Unlocked",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "The identification of the underlying cause of death is a matter of primary importance and one of the most challenging issues in the setting of healthcare policy making. The World Health Organisation provides guidelines for death certificates coding using the ICD-10 classification. Guidelines can be manually applied, but there exist some coding support systems that implement them to simplify the coding work. Nevertheless, there is disparity among countries with respect to the level and the quality of death certificates registration. In this work we propose an effective supervised model based on Natural Language Processing algorithms to the aim of correctly classifying the underlying cause of death from death certificates. In our study we compared tabular representations of the death certificate, including the hierarchical path of each condition in the classification, with a novel representation consisting in translating back to their standard title the conditions expressed as ICD-10 codes. Our experimental evaluation, after training on 10.5 million certificates, reached a 99.03% accuracy, which currently outperforms state-of-the-art systems. For its practical applicability, we studied performance by classification chapter and found that accuracy is low only for chapters including very rare death causes. Finally, to show the robustness of our model, we leverage the model confidence to help identifying death certificates for which a manual coding is needed.",
        "DOI": "10.1016/j.imu.2020.100456",
        "paper_author": "Della Mea V.",
        "affiliation_name": "Università degli Studi di Udine",
        "affiliation_city": "Udine",
        "affiliation_country": "Italy",
        "affiliation_id": "60025965",
        "affiliation_state": "UD"
    },
    {
        "paper_title": "Towards deployment of robust cooperative ai agents: An algorithmic framework for learning adaptive policies",
        "publication": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "We study the problem of designing an AI agent that can robustly cooperate with agents of unknown type (i.e., previously unobserved behavior) in multi-agent scenarios. Our work is inspired by real-world applications in which an AI agent, e.g., a virtual assistant, has to cooperate with new types of agents/users after its deployment. We model this problem via parametric Markov Decision Processes where the parameters correspond to a user's type and characterize her behavior. In the test phase, the AI agent has to interact with a user of an unknown type. We develop an algorithmic framework for learning adaptive policies: our approach relies on observing the user's actions to make inferences about the user's type and adapting the policy to facilitate efficient cooperation. We show that without being adaptive, an AI agent can end up performing arbitrarily bad in the test phase. Using our framework, we propose two concrete algorithms for computing policies that automatically adapt to the user in the test phase. We demonstrate the effectiveness of our algorithms in a cooperative gathering game environment for two agents.",
        "DOI": "NA",
        "paper_author": "Ghosh A.",
        "affiliation_name": "Max Planck Institute for Software Systems",
        "affiliation_city": "Saarbrucken",
        "affiliation_country": "Germany",
        "affiliation_id": "60002485",
        "affiliation_state": "Saarland"
    },
    {
        "paper_title": "Health data pools under european policy and data protection law: Research as a new efficiency defence?",
        "publication": "Journal of Intellectual Property, Information Technology and E-Commerce Law",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "The increasing employment of artificial intelligence and machine learning in the biomedical sector as well as the growing number of partnerships aimed at pooling together different types of digital health data, stress the importance of an effective regulation and governance of data sharing in the health and life sciences. This paper explores the emerging economic reality of health data pools from the perspective of European Union policy and law. The goal of the study is to validate the role of the internal market integration objective in the data protection framework of special categories of data, and thus to unveil the alignment of the General Data Protection Regulation's research exemption with the broader policy goals of the Digital Single Market Strategy. After having described the phenomenon of health data pools as a primary means to conduct research in digital health markets, the study first contextualizes health data sharing practices at European policy level, with specific reference to the Digital Single Market Strategy. Here, both the digital health sector and the free-flow of information are emerging as strategic areas of European intervention. Against this backdrop, the second section will enquire the regulatory framework regarding the processing of special categories of data for research purposes under the General Data Protection Regulation. As will be demonstrated, this framework partly disavows fundamental rights protection objectives, in order to promote research based on health data and related market objectives.",
        "DOI": "NA",
        "paper_author": "Schneider G.",
        "affiliation_name": "Sant'Anna Scuola Universitaria Superiore Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60028039",
        "affiliation_state": "PI"
    },
    {
        "paper_title": "Analysing first birth interval by a CART survival tree",
        "publication": "International Journal of Fertility and Sterility",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Birth spacing, especially the first birth interval (FBI), is a suitable index to investigate the delayed fertility that results in a low fertility pattern. Non-parametric familiar alternatives to the Cox proportional hazard regression (CPH) model include survival trees that can automatically discover certain types of covariate interactions according to the survival length. The aim of this research is to study FBI influential factors by applying survival trees. Materials and Methods: In this cross-sectional study, 610 married women (aged 15-49 years), were selected from different regions of Tehran, Iran in the Winter and Spring of 2017. Classification and regression trees (CART) for the FBI survival tree were fitted by taking into consideration the predictors of each woman’s age, age at first marriage, educational level, partner’s educational level, activity, region, house ownership, kinship, partner’s race, marriage time attitude, and expenditure using R packages. Results: Since the PH assumption of the CPH model was not confirmed for the covariates of age at first marriage (P=0.001), kinship (P=0.000), partner’s race (P=0.001), and marriage time attitude (P=0.042), the results of this model were not valid. Thus, a CART survival tree was fitted. The validity of the fitted model in assessing FBI was confirmed by the significant result of the log rank test (P<0.01) for the terminal nodes and the value of the separation measure, which was greater than 1. The fitted tree had 13 terminal nodes and the most vital FBI predictor was women’s age. The longest FBI belonged to educated and employed women, ages 30-37 years. Conclusion: Analysing patterns of birth spacing by selecting the appropriate statistical method provides important information for health policymakers. In order to formulate appropriate demographic policies, it is essential to take into consideration age, educational level and job status of the women, all of which have essential roles on their decision to have children.",
        "DOI": "10.22074/ijfs.2020.6038",
        "paper_author": "Saadati M.",
        "affiliation_name": "National Population Studies and Comprehensive Management Institute",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "114477470",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "19th Mexican International Conference on Artificial Intelligence, MICAI 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 77 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Impact of Memory Control on Batch Learning in Human Activity Recognition Scenario in Comparison to Data Stream Learning; automated Characterization and Prediction of Wind Conditions Using Gaussian Mixtures; a Survey on Freezing of Gait Detection and Prediction in Parkinson’s Disease; zeChipC: Time Series Interpolation Method Based on Lebesgue Sampling; machine Leaning Based Urdu Language Tutor for Primary School Students; selection Schemes Analysis in Genetic Algorithms for the Maximum Influence Problem; a Comparative Analysis of Evolutionary Learning in Artificial Hydrocarbon Networks; fatty Chain Acids Risk Factors in Sudden Infant Death Syndrome: A Genetic Algorithm Approach; An NSGA-III-Based Multi-objective Intelligent Autoscaler for Executing Engineering Applications in Cloud Infrastructures; speaker Identification Using Entropygrams and Convolutional Neural Networks; the Improvement Direction Mapping Method; a Genetic Programming Framework for Heuristic Generation for the Job-Shop Scheduling Problem; a Genetic Algorithm Approach for a Truck and Trailer Routing Problem in a Loading/Unloading Bays Application; a Tensor-Based Markov Decision Process Representation; object-Based Goal Recognition Using Real-World Data; comparing Multi-issue Multi-lateral Negotiation Approaches for Group Recommendation; guidance in the Visual Analytics of Cartographic Images in the Decision-Making Process; risk Sensitive Markov Decision Process for Portfolio Management; risk-Sensitive Piecewise-Linear Policy Iteration for Stochastic Shortest Path Markov Decision Processes; why Majority Rule Does Not Work in Quantum Computing: A Pedagogical Explanation; convolutional Neural Networks with Hebbian-Based Rules in Online Transfer Learning; how Powersets of Individual Fuzzy Sets Can Be Defined?.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "19th Mexican International Conference on Artificial Intelligence, MICAI 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 77 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Impact of Memory Control on Batch Learning in Human Activity Recognition Scenario in Comparison to Data Stream Learning; automated Characterization and Prediction of Wind Conditions Using Gaussian Mixtures; a Survey on Freezing of Gait Detection and Prediction in Parkinson’s Disease; zeChipC: Time Series Interpolation Method Based on Lebesgue Sampling; machine Leaning Based Urdu Language Tutor for Primary School Students; selection Schemes Analysis in Genetic Algorithms for the Maximum Influence Problem; a Comparative Analysis of Evolutionary Learning in Artificial Hydrocarbon Networks; fatty Chain Acids Risk Factors in Sudden Infant Death Syndrome: A Genetic Algorithm Approach; An NSGA-III-Based Multi-objective Intelligent Autoscaler for Executing Engineering Applications in Cloud Infrastructures; speaker Identification Using Entropygrams and Convolutional Neural Networks; the Improvement Direction Mapping Method; a Genetic Programming Framework for Heuristic Generation for the Job-Shop Scheduling Problem; a Genetic Algorithm Approach for a Truck and Trailer Routing Problem in a Loading/Unloading Bays Application; a Tensor-Based Markov Decision Process Representation; object-Based Goal Recognition Using Real-World Data; comparing Multi-issue Multi-lateral Negotiation Approaches for Group Recommendation; guidance in the Visual Analytics of Cartographic Images in the Decision-Making Process; risk Sensitive Markov Decision Process for Portfolio Management; risk-Sensitive Piecewise-Linear Policy Iteration for Stochastic Shortest Path Markov Decision Processes; why Majority Rule Does Not Work in Quantum Computing: A Pedagogical Explanation; convolutional Neural Networks with Hebbian-Based Rules in Online Transfer Learning; how Powersets of Individual Fuzzy Sets Can Be Defined?.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Scheduling Policy and Power Allocation for Federated Learning in NOMA Based MEC",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "39",
        "cover_date": "2020-01-01",
        "Abstract": "Federated learning (FL) is a highly pursued machine learning technique that can train a model centrally while keeping data distributed. Distributed computation makes FL attractive for bandwidth limited applications especially in wireless communications. There can be a large number of distributed edge devices connected to a central parameter server (PS) and iteratively download/upload data from/to the PS. Due to limited bandwidth, only a subset of connected devices can be scheduled in each round. There are usually millions of parameters in the state-of-art machine learning models such as deep learning, resulting in a high computation complexity as well as a high communication burden on collecting/distributing data for training. To improve communication efficiency and make the training model converge faster, we propose a new scheduling policy and power allocation scheme using non-orthogonal multiple access (NOMA) settings to maximize the weighted sum data rate under practical constraints during the entire learning process. NOMA allows multiple users to transmit on the same channel simultaneously. The user scheduling problem is transformed into a maximum-weight independent set problem that can be solved using graph theory. Simulation results show that the proposed scheduling and power allocation scheme can help achieve a higher FL testing accuracy in NOMA based wireless networks than other existing schemes within the same learning time.",
        "DOI": "10.1109/GLOBECOM42002.2020.9322270",
        "paper_author": "Ma X.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Logan",
        "affiliation_country": "United States",
        "affiliation_id": "60279654",
        "affiliation_state": "UT"
    },
    {
        "paper_title": "Design of a reinforcement learning based controller for gliding control of an experimental design vehicle",
        "publication": "AIAA Scitech 2020 Forum",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Achieving autonomy for aerospace vehicles control has been an active area of research in the past; especially when the design of vehicles is becoming more challenging for achieving optimum performance. Usually, devised control strategies for these vehicles employ proportional integral (PI) or proportional integral derivative (PID) controllers using feedback loops. Though, these controllers have performed quite well with stable environments, however more intelligent and active flight control system is required, when dealing with unknown or harsh domains. Under the bigger umbrella of Machine Learning (ML), Reinforcement Learning (RL) has started to address these limitations of the conventional controllers and emerges as the most active, conceptually prudent and best suited machine learning category for autonomous control; which in recent years, has increasingly found use in aerospace control applications for platforms like aircraft, missile trajectory control, fixed wing UAVs, Quadcopters and so on. Additionally, RL coupled with neural nets has emerged as a robust methodology in solving complex domain control problems with continuous action and state spaces, thus, unleashing the hidden power of RL and outperforming both linear and orthodox nonlinear control strategies, which have their own inherent limitations. In the current research, we demonstrate the ability of the proposed RL agent or controller for an experimental glide vehicle to learn gliding strategies and to control the vehicle’s descent, thus eventually optimizing its glide range. At first, we model the experimental design vehicle using a 6-DoF model registering the translational and rotational response of aerial platform. Later, based on extensive literature review, two unique RL algorithms are developed namely ‘Modified Model-Free Dynamic Programming (MMDP) and Deep Deterministic Policy Gradient (DDPG)’; in relation with the current problem, same are applied and their results are compared and analyzed highlighting the success of RL over the performance of control policies obtained by classical approaches. Results are also verified by 6-DoF simulation of the experimental design vehicle.",
        "DOI": "10.2514/6.2020-1849",
        "paper_author": "Ud Din A.F.",
        "affiliation_name": "Air University Islamabad",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60070604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Prediction of 30-day hospital readmissions for all-cause dental conditions using machine learning",
        "publication": "Risk Management and Healthcare Policy",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Introduction: It is unknown whether patients admitted for all-cause dental conditions (ACDC) are at high risk for hospital readmission, or what are the risk factors for dental hospital readmission. Objective: We examined the prevalence of, and risk factors associated with, 30-day hospital readmission for patients with an all-cause dental admission. We applied artificial intelligence to develop machine learning (ML) algorithms to predict patients at risk of 30-day hospital readmission. Methods: This study used data extracted from the 2013 Nationwide Readmissions Database (NRD). There were a total of 11,341 cases for all-cause index admission for dental patients admitted to the hospitals. Descriptive statistics were used to analyze patient characteristics. This study applied five techniques to build risk prediction models and to identify risk factors. Model performance was evaluated using area under the receiver operating characteristic curve (AUC), and accuracy, sensitivity, specificity and precision. Results: There were 11% of patients admitted for ACDC readmitted within 30 days of hospital discharge. On average, the total charge per patient was $131,004 for those with 30-day readmission (n=1254) and $69,750 for those without readmission (n=10,087). Factors significantly associated with 30-day hospital readmission included total charges, number of diagnoses, age, number of chronic conditions, length of hospital stays, number of procedures, Medicare insurance and Medicaid insurance, and severity of illness. Model performance from all methods was similar with the artificial neural network showing the highest AUC of 0.739. Conclusion: Our results demonstrate that readmission after hospitalization with ACDC is fairly common. If one-third of the 30-day readmission cases can be avoided, there is a potential annual saving of over $25 million among the twenty-one states represented in the NRD. The ML algorithms can predict hospital readmission in dental patients and should be further tested to aid the reduction of hospital readmission and enhancement of patient-centered care.",
        "DOI": "10.2147/RMHP.S272824",
        "paper_author": "Hung M.",
        "affiliation_name": "Roseman University of Health Sciences",
        "affiliation_city": "Henderson",
        "affiliation_country": "United States",
        "affiliation_id": "60025100",
        "affiliation_state": "NV"
    },
    {
        "paper_title": "A COMPARISON of MACHINE LEARNING-BASED INDIVIDUAL MOBILITY CLASSIFICATION MODELS DEVELOPED on SENSOR READINGS from LOOSELY ATTACHED SMARTPHONES",
        "publication": "Communications - Scientific Letters of the University of Žilina",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "General mobility estimation is demanded for strategy, policy, systems and services developments and operations in transport, urban development and telecommunications. Here is proposed an individual motion readings collection with preserved privacy through loosely fit smartphones, as a novel sole inertial sensors use in commercial-grade smartphones for a wide population data collection, without the need for the new infrastructure and attaching devices. It is shown that the statistical learning-based models of individual mobility classification per means of transport are capable of overcoming the variance introduced by the proposed data collection method. The success of the proposed methodology in a small-scale experiment for the Individual Mobility Classification Model development, using selected statistical learning methods, is demonstrated.",
        "DOI": "10.26552/com.C.2020.4.153-162",
        "paper_author": "Filjar R.",
        "affiliation_name": "Krapina University of Applied Sciences",
        "affiliation_city": "Krapina",
        "affiliation_country": "Croatia",
        "affiliation_id": "124720855",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Land-Cover Mapping of Agricultural Areas Using Machine Learning in Google Earth Engine",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Land-cover mapping is critically needed in land-use planning and policy making. Compared to other techniques, Google Earth Engine (GEE) offers a free cloud of satellite information and high computation capabilities. In this context, this article examines machine learning with GEE for land-cover mapping. For this purpose, a five-phase procedure is applied: (1) imagery selection and pre-processing, (2) selection of the classes and training samples, (3) classification process, (4) post-classification, and (5) validation. The study region is located in the San Salvador basin (Uruguay), which is under agricultural intensification. As a result, the 1990 land-cover map of the San Salvador basin is produced. The new map shows good agreements with past agriculture census and reveals the transformation of grassland to cropland in the period 1990–2018.",
        "DOI": "10.1007/978-3-030-58811-3_52",
        "paper_author": "Hastings F.",
        "affiliation_name": "Universidad de la Republica",
        "affiliation_city": "Montevideo",
        "affiliation_country": "Uruguay",
        "affiliation_id": "60071612",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modeling and Prediction of Freight Delivery for Blocked and Unblocked Street Using Machine Learning Techniques",
        "publication": "Transportation Research Procedia",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Freight deliveries on signalized city road are recognized as lane obstructions throughout delivery. Traffic jamming associated with urban freight deliveries has gained increasing attention recently. As traffic engineers and planners are tasked with findingsolutions to accomplishcomprehensive demand more sustainably with restrictedroad capacity. The goal of this research is to evaluatethe model for quantifying the capacity and delay effect of a freight delivery on a signalized city road in Ahmedabad. The all or nothing model similar to the procedure used in the highway capacity manual (HCM2010). The persistence is to provide an understandingof the use of these tools for analysis of urban freight delivery policy. The present study covers delay and vehicle capacity estimation that can account for the changeable locality of deliveries, duration, and different impact on different lane groups. To predict the vehicle capacity and delay estimation, machine learning models, Support vector machine and Artificial neural network was utilized. Result shows excellent agreement between experimental and predicted observations.",
        "DOI": "10.1016/j.trpro.2020.08.059",
        "paper_author": "Pandya P.",
        "affiliation_name": "Pandit Deendayal Energy University",
        "affiliation_city": "Gandhinagar",
        "affiliation_country": "India",
        "affiliation_id": "60106943",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Artificial and Internet of Healthcare Things Based Alzheimer Care During COVID 19",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "46",
        "cover_date": "2020-01-01",
        "Abstract": "Alzheimer patient’s routine care at the onset of a catastrophe like coronavirus disease 2019 (COVID-19) pandemic is interrupted as healthcare is providing special attention to the patient having severe acute respiratory syndrome coronavirus 2 (SARS-COV-2) or COVID-19 infection. In order to decrease the spread of the disease, government has shut down regular services at the hospital, and advised all vulnerable people to stay at home and maintain social distance (of 3 fts) which hampered the routine care and rehabilitation therapy of elderly patient having a chronic disease like Alzheimer. On the other hand, the artificial intelligence (AI)-based internet of healthcare things allows clinicians to monitor physiological conditions of patients in real-time and machine learning models can able to detect any anomaly in the patient’s condition. Besides, the advancement in Information and Communication Technology enable us to provide special distance care (such as medication and therapy) by dedicated medical teams or special therapists. This paper discusses the effect of COVID-19 on patient care of Alzheimer’s Disease (AD) and how AI-based IoT can help special care of AD patients at home. Finally, we have outlined some recommendations for Family and Caregiver, Volunteer and Social Care which will help to develop the Government policy.",
        "DOI": "10.1007/978-3-030-59277-6_24",
        "paper_author": "Jesmin S.",
        "affiliation_name": "Jahangirnagar University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60029276",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data-driven robust optimization for greenhouse temperature control using model predictive control",
        "publication": "Chemical Engineering Transactions",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "This work proposes a novel data-driven robust model predictive control (DDRMPC) framework for automatic control of greenhouse temperature and CO2 concentration level. The essential concept is to combine dynamic models of greenhouse temperature and CO2 concentration level with data-driven models that identify uncertainty in weather forecast error. By leveraging a machine learning approach, support vector clustering with weighted generalized intersection kernel, data-driven uncertainty sets for ambient temperature and solar radiation are constructed from historical weather data. A training-calibration procedure that tunes the size of uncertainty sets is implemented to ensure that data-driven uncertainty sets attain appropriate performance guarantee. In order to solve the optimization problem in DDRMPC, an affine disturbance feedback policy that provides tractable approximations of optimal control is utilized. A case study of controlling temperature and CO2 concentration level in a greenhouse is carried out. The results show that the proposed DDRMPC framework can prevent the greenhouse climate from becoming harmful to plant and fruit. DDRMPC approach ends up with 20 % less total economic cost than rule-based control strategy. The proposed DDRMPC approach also gives better control performance comparing to certainty equivalent MPC and robust MPC.",
        "DOI": "10.3303/CET2081121",
        "paper_author": "Chen W.H.",
        "affiliation_name": "Cornell University College of Engineering",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60104946",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Automating distributed tiered storage management in cluster computing",
        "publication": "Proceedings of the VLDB Endowment",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Data-intensive platforms such as Hadoop and Spark are routinely used to process massive amounts of data residing on distributed le systems like HDFS. Increasing memory sizes and new hardware technologies (e.g., NVRAM, SSDs) have recently led to the introduction of storage tiering in such settings. However, users are now burdened with the additional complexity of managing the multiple storage tiers and the data residing on them while trying to optimize their workloads. In this paper, we develop a general framework for automatically moving data across the available storage tiers in distributed le systems. Moreover, we employ machine learning for tracking and predicting le access patterns, which we use to decide when and which data to move up or down the storage tiers for increasing system performance. Our approach uses incremental learning to dynamically rene the models with new le accesses, allowing them to naturally adjust and adapt to workload changes over time. Our extensive evaluation using realistic workloads derived from Facebook and CMU traces compares our approach with several other policies and showcases signicant bene ts in terms of both workload performance and cluster effciency.",
        "DOI": "10.14778/3357377.3357381",
        "paper_author": "Herodotou H.",
        "affiliation_name": "Cyprus University of Technology",
        "affiliation_city": "Limassol",
        "affiliation_country": "Cyprus",
        "affiliation_id": "60077474",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "35th IFIP TC 11 International Conference on Information Security and Privacy Protection, SEC 2020",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 29 papers. The special focus in this conference is on Information Security and Privacy Protection. The topics include: RouAlign: Cross-Version Function Alignment and Routine Recovery with Graphlet Edge Embedding; code Between the Lines: Semantic Analysis of Android Applications; IMShell-Dec: Pay More Attention to External Links in PowerShell; secure Attestation of Virtualized Environments; Security and Performance Implications of BGP Rerouting-Resistant Guard Selection Algorithms for Tor; Actively Probing Routes for Tor AS-Level Adversaries with RIPE Atlas; zeek-Osquery: Host-Network Correlation for Advanced Monitoring and Intrusion Detection; revisiting Security Vulnerabilities in Commercial Password Managers; evaluation of Risk-Based Re-Authentication Methods; evaluation of Statistical Tests for Detecting Storage-Based Covert Channels; fuzzy Vault for Behavioral Authentication System; improvements of the Balance Discovery Attack on Lightning Network Payment Channels; CCBRSN: A System with High Embedding Capacity for Covert Communication in Bitcoin; privacy-Friendly Monero Transaction Signing on a Hardware Wallet; a Matter of Life and Death: Analyzing the Security of Healthcare Networks; establishing a Strong Baseline for Privacy Policy Classification; cross-Platform File System Activity Monitoring and Forensics – A Semantic Approach; a Correlation-Preserving Fingerprinting Technique for Categorical Data in Relational Databases; FDFtNet: Facing Off Fake Images Using Fake Detection Fine-Tuning Network; escaping Backdoor Attack Detection of Deep Learning; IE-Cache: Counteracting Eviction-Based Cache Side-Channel Attacks Through Indirect Eviction; Refined Detection of SSH Brute-Force Attackers Using Machine Learning; MultiTLS: Secure Communication Channels with Cipher Suite Diversity; improving Big Data Clustering for Jamming Detection in Smart Mobility; assisting Users to Create Stronger Passwords Using ContextBased MicroTraining.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "25th International Symposium on Methodologies for Intelligent Systems, ISMIS 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 44 papers. The special focus in this conference is on Methodologies for Intelligent Systems. The topics include: A Deep Learning Approach to Fake News Detection; satirical News Detection with Semantic Feature Extraction and Game-Theoretic Rough Sets; comparing State-of-the-Art Neural Network Ensemble Methods in Soccer Predictions; static Music Emotion Recognition Using Recurrent Neural Networks; saliency Detection in Hyperspectral Images Using Autoencoder-Based Data Reconstruction; mesoscale Anisotropically-Connected Learning; empirical Comparison of Graph Embeddings for Trust-Based Collaborative Filtering; neural Spike Sorting Using Unsupervised Adversarial Learning; poriferal Vision: Classifying Benthic Sponge Spicules to Assess Historical Impacts of Marine Climate Change; the Construction of Action Rules to Raise Artwork Prices; Experimental Evaluation of GAN-Based One-Class Anomaly Detection on Office Monitoring; ranking Speech Features for Their Usage in Singing Emotion Classification; leveraging Machine Learning in IoT to Predict the Trustworthiness of Mobile Crowd Sensing Data; a Hierarchical-Based Web-Platform for Crowdsourcing Distinguishable Image Patches; performing Arithmetic Using a Neural Network Trained on Digit Permutation Pairs; CatIO - A Framework for Model-Based Diagnosis of Cyber-Physical Systems; data Publishing: Availability of Data Under Security Policies; matrix Factorization Based Heuristics Learning for Solving Constraint Satisfaction Problems; explaining Object Motion Using Answer Set Programming; The GraphBRAIN System for Knowledge Graph Management and Advanced Fruition; metric-Guided Multi-task Learning; mining Exceptional Mediation Models; multivariate Predictive Clustering Trees for Classification; comparison of Machine Learning Methods to Detect Anomalies in the Activity of Dairy Cows; clustering Algorithm Consistency in Fixed Dimensional Spaces; estimating the Importance of Relational Features by Using Gradient Boosting.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Establishing a Strong Baseline for Privacy Policy Classification",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "26",
        "cover_date": "2020-01-01",
        "Abstract": "Digital service users are routinely exposed to Privacy Policy consent forms, through which they enter contractual agreements consenting to the specifics of how their personal data is managed and used. Nevertheless, despite renewed importance following legislation such as the European GDPR, a majority of people still ignore policies due to their length and complexity. To counteract this potentially dangerous reality, in this paper we present three different models that are able to assign pre-defined categories to privacy policy paragraphs, using supervised machine learning. In order to train our neural networks, we exploit a dataset containing 115 privacy policies defined by US companies. An evaluation shows that our approach outperforms state-of-the-art by 5% over comparable and previously-reported F1 values. In addition, our method is completely reproducible since we provide open access to all resources. Given these two contributions, our approach can be considered as a strong baseline for privacy policy classification.",
        "DOI": "10.1007/978-3-030-58201-2_25",
        "paper_author": "Mousavi Nejad N.",
        "affiliation_name": "Universität Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany",
        "affiliation_id": "60007493",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Classification, analysis, and prediction of the daily operations of airports using machine learning",
        "publication": "AIAA Scitech 2020 Forum",
        "citied_by": "18",
        "cover_date": "2020-01-01",
        "Abstract": "The Federal Aviation Administration (FAA) is the regulatory body in the United States responsible for the advancement, safety, and regulation of civil aviation. The FAA also oversees the development of the air traffic control system in the U.S. Over the years, the FAA has made tremendous progress in modernizing the National Airspace System (NAS) by way of technological advancements and the introduction of procedures and policies that have maintained the safety of the United States airspace. However, as with any other system, there is a need to continuously address evolving challenges pertaining to the sustainment and resiliency of the NAS. One of these challenges involves efficiently analyzing and assessing the operations of airports. In particular, there is a need to assess the impact and effectiveness of the implementation of Traffic Management Initiatives (TMI) and other procedures on daily airport operations, as this will lead to the identification of trends and patterns to inform better decision making. The FAA currently manually classifies the daily operations of airports into three categories: “Good Days”, “Average Days”, and “Bad Days” as a means to assess their efficiency. However, this exercise is time-consuming and can be improved. In particular, Big Data Analytics can be leveraged to develop a systematic approach for classifying or clustering the daily operations of airports. This research presents a methodology for clustering the daily operations of Newark International Airport (EWR) using metrics such as the number of diversions, Ground Stops, departure delays, etc. Each of these categories/clusters is then analyzed to identify key characteristics, trends and patterns, which can then be used by airport operators, and FAA analysts and researchers to improve the operations at the airport. Finally, the Boosting Ensemble Machine Learning algorithm is used to predict the category of operations at the airport, hence enabling airport operators, FAA analysts and researchers to take appropriate actions.",
        "DOI": "10.2514/6.2020-1196",
        "paper_author": "Mangortey E.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "AI4DL: Mining behaviors of deep learning workloads for resource management",
        "publication": "HotCloud 2020 - 12th USENIX Workshop on Hot Topics in Cloud Computing, co-located with USENIX ATC 2020",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "The more we know about the resource usage patterns of workloads, the better we can allocate resources. Here we present a methodology to discover resource usage behaviors of containers training Deep Learning (DL) models. From monitoring, we can observe repeating patterns and similitude of resource usage among containers training different DL models. The repeating patterns observed can be leveraged by the scheduler or the resource autoscaler to reduce resource fragmentation and overall resource utilization in a dedicated DL cluster. Specifically, our approach combines Conditional Restricted Boltzmann Machines (CRBMs) and clustering techniques to discover common sequences of behaviors (phases) of containers running the DL training workloads in clusters providing IBM Deep Learning Services. By studying the resource usage pattern at each phase and the typical sequences of phases among different containers, we discover a reduced set of prototypical executions representing the majority of executions. We use statistical information from each phase to refine resource provisioning by dynamically tuning the amount of resource each container requires at each phase. Evaluation of our method shows that by leveraging typical resource usage patterns, we can auto-scale containers to reduce CPU and Memory allocation by 30% compared to statistics based reactive policies, which is close to having a-priori knowledge of resource usage while fulfilling resource demand over 95% of the time.",
        "DOI": "NA",
        "paper_author": "Berral J.L.",
        "affiliation_name": "Centro Nacional de Supercomputación",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain",
        "affiliation_id": "60097745",
        "affiliation_state": "Barcelona"
    },
    {
        "paper_title": "Development of an improved hybrid back propagation ANN for low wind speed prediction and wind energy evaluation",
        "publication": "Journal of Advanced Research in Fluid Mechanics and Thermal Sciences",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Wind energy is clean, reliable, and affordable renewable energy which can be harnessed during the day and night. Before a wind turbine is installed, wind resource assessment (WRA) must be conducted in order to evaluate the wind power potential. The most important parameter in WRA is the wind speed values. The traditional ways of measuring wind speed could not be relied on, due to time constraint and cost. Because of these problems, a prediction model using deep learning is proposed in paper to solve the lingering problem. The objective of this paper is to develop a machine learning, prediction model using available data. Wind data were obtained from Malaysia Meteorological Department (MMD) for a period of ten years starting from 2008-2018. The wind energy evaluation was conducted at 10m-40m meters, respectively. In the areas with limited data or without data a prediction model was developed using different Artificial Neural Networks (ANNs) structures. The model was trained, tested, and validated using measured wind speed in the nearby location. The optimized model in terms of less structure with high prediction accuracy was selected for the final prediction has a correlation value of 0.952. A detailed wind resource assessment was conducted in the areas based on most fitted wind speed distribution model. It was found that Weibull and Rayleigh fitted the wind speed in the areas examined. At the end of the analysis, low wind speed turbine was selected for the wind farm sitting; the results show that wind energy can be harnessed for small Pico scale application such as rural electrification, and grain grinding. Because, in all the cases the wind power density falls within class 1 (PD≤100 W/m2). The outcomes of this study would be useful for policy makers to implement 3-Es Model (Earth-Energy and Empowerment) in rural and remote areas of Sarawak.",
        "DOI": "10.37934/ARFMTS.75.1.112126",
        "paper_author": "Lawan S.M.",
        "affiliation_name": "Kano University of Science and Technology",
        "affiliation_city": "Wudil",
        "affiliation_country": "Nigeria",
        "affiliation_id": "60105048",
        "affiliation_state": "Kano"
    },
    {
        "paper_title": "Auto content moderation in C2C e-Commerce",
        "publication": "OpML 2020 - 2020 USENIX Conference on Operational Machine Learning",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Consumer-to-consumer (C2C) e-Commerce is a large and growing industry with millions of monthly active users. In this paper, we propose auto content moderation for C2C e-Commerce to moderate items using Machine Learning (ML). We will also discuss practical knowledge gained from our auto content moderation system. The system has been deployed to production at Mercari since late 2017 and has significantly reduced the operation cost in detecting items violating our policies. This system has increased coverage by 554.8 % over a rule-based approach.",
        "DOI": "NA",
        "paper_author": "Ueta S.",
        "affiliation_name": "Mercari, Inc.",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60276211",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning in situ: A randomized experiment in video streaming",
        "publication": "Proceedings of the 17th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2020",
        "citied_by": "179",
        "cover_date": "2020-01-01",
        "Abstract": "We describe the results of a randomized controlled trial of video-streaming algorithms for bitrate selection and network prediction. Over the last year, we have streamed 38.6 years of video to 63,508 users across the Internet. Sessions are randomized in blinded fashion among algorithms. We found that in this real-world setting, it is difficult for sophisticated or machine-learned control schemes to outperform a “simple” scheme (buffer-based control), notwithstanding good performance in network emulators or simulators. We performed a statistical analysis and found that the heavy-tailed nature of network and user behavior, as well as the challenges of emulating diverse Internet paths during training, present obstacles for learned algorithms in this setting. We then developed an ABR algorithm that robustly outperformed other schemes, by leveraging data from its deployment and limiting the scope of machine learning only to making predictions that can be checked soon after. The system uses supervised learning in situ, with data from the real deployment environment, to train a probabilistic predictor of upcoming chunk transmission times. This module then informs a classical control policy (model predictive control). To support further investigation, we are publishing an archive of data and results each week, and will open our ongoing study to the community. We welcome other researchers to use this platform to develop and validate new algorithms for bitrate selection, network prediction, and congestion control.",
        "DOI": "NA",
        "paper_author": "Yan F.Y.",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60012708",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "THEMIS: Fair and efficient GPU cluster scheduling",
        "publication": "Proceedings of the 17th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2020",
        "citied_by": "145",
        "cover_date": "2020-01-01",
        "Abstract": "Modern distributed machine learning (ML) training workloads benefit significantly from leveraging GPUs. However, significant contention ensues when multiple such workloads are run atop a shared cluster of GPUs. A key question is how to fairly apportion GPUs across workloads. We find that established cluster scheduling disciplines are a poor fit because of ML workloads' unique attributes: ML jobs have long-running tasks that need to be gang-scheduled, and their performance is sensitive to tasks' relative placement. We propose THEMIS, a new scheduling framework for ML training workloads. It's GPU allocation policy enforces that ML workloads complete in a finish-time fair manner, a new notion we introduce. To capture placement sensitivity and ensure efficiency, THEMIS uses a two-level scheduling architecture where ML workloads bid on available resources that are offered in an auction run by a central arbiter. Our auction design allocates GPUs to winning bids by trading off fairness for efficiency in the short term, but ensuring finish-time fairness in the long term. Our evaluation on a production trace shows that THEMIS can improve fairness by more than 2.25X and is ~5% to 250% more cluster efficient in comparison to state-of-the-art schedulers.",
        "DOI": "NA",
        "paper_author": "Mahajan K.",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States",
        "affiliation_id": "60032179",
        "affiliation_state": "WI"
    },
    {
        "paper_title": "Kernel interpolation-based technique for privacy protection of pluggable data in cloud computing",
        "publication": "International Journal of Cloud Computing",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Recent technological revolution has been reported as the revolution of the cloud computing technology. The explosive availability of the unstructured data in the cloud has gained the attention of the researchers and the users store their data in the cloud without any right over controlling the data, causing the privacy concerns. Therefore, there is a need for the effective privacy protection techniques that assure the privacy of the user data in the cloud. Accordingly, this paper proposes a kernel interpolation-based technique for preserving the privacy of the data in the cloud. Privacy and accuracy are the two factors assuring the privacy for the data, which are afforded using the proposed technique that uses the proposed rider-cat swarm optimisation (R-CSO) algorithm for computing the kernel interpolation coefficient, which is associated with affording the privacy in the cloud. The proposed rider-cat swarm optimisation (R-CSO) algorithm is the integration of the standard cat swarm optimisation (CSO) in the standard rider optimisation algorithm (ROA). The analysis of the methods using the dataset from UCI machine learning repository reveals that the proposed method acquired the maximal accuracy and minimal database difference ratio (DBDR) of 80.552% and 15.58%, respectively.",
        "DOI": "10.1504/IJCC.2020.109385",
        "paper_author": "Bangare M.L.",
        "affiliation_name": "Savitribai Phule Pune University",
        "affiliation_city": "Pune",
        "affiliation_country": "India",
        "affiliation_id": "60031475",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Neural trees: Using neural networks as an alternative to binary comparison in classical search trees",
        "publication": "HotStorage 2020 - 12th USENIX Workshop on Hot Topics in Storage and File Systems, co-located with USENIX ATC 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Binary comparison, the basis of the venerable B Tree, is perhaps the most successful operator for indexing data on secondary storage. We introduce a different technique, called Neural Trees, that is based on neural networks. Neural Trees increase the fan-out per byte of a search tree by up to 40% compared to B Trees. Increasing fan-out reduces memory demands and leads to increased cacheability while decreasing height and media accesses. A Neural Tree also permits search path layout policies that divorce a key's value from its physical location in a data structure. This is an advantage over the total ordering required by binary comparison, which totally determines the physical location of keys in a tree. Previous attempts to apply machine learning to indices are based on learning the data directly, which renders insertion too expensive to be supported. The Neural Tree is a hybrid scheme using a tree of small neural networks to learn search paths instead of the data directly. Neural Trees can efficiently handle a general read/write workload. We evaluate Neural Trees with weeks of traces from production storage and SPC1 workloads to demonstrate their viability.",
        "DOI": "NA",
        "paper_author": "Santry D.",
        "affiliation_name": "NetApp",
        "affiliation_city": null,
        "affiliation_country": null,
        "affiliation_id": "125175500",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The human-centered AI and the EC policies: Risks &amp; chances",
        "publication": "Technological and Digital Risk: Research Issues",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Antonella Napoli Artificial Intelligence (AI) is a central theme in the contemporary debate. The availability of a large amount of data and the possibility of processing it thanks to the use of powerful computing capabilities is in fact favoring the implementation of patterns and classification structures that accelerate the progress of technological development linked to all systems under the great semantic hat of AI - from human-machine interface systems, to machine learning, machine reasoning, and robotics (see Tegmark 2017). The huge development already achieved by artificial intelligence systems and the expectations for future developments contribute to feeding narratives about opportunities, but above all the risks linked to the human-technology relationship. In particular, many fears refer to the level of autonomy that these technologies can achieve: these fears often find expression in media representations as well as in prefiguration of imaginery products, from literature to fiction to art. In fact, less investigated than the imaginery products, the public discourse also contributes in generating representations of AI that highlight the ambiguous relationship between human and technology, the fears related to the autonomy’s issue despite the unquestionable opportunities offered by the AI to overcome the challenges of the present time. The public discourse ultimately questions the degree of human awareness and freedom or whether AI has a conscience and is able to decide independently. Starting from a classic work like Langdon Winner’s (1978) and from his still current reflections on the relationship between power and autonomy….",
        "DOI": "NA",
        "paper_author": "Napoli A.",
        "affiliation_name": "Università degli Studi di Salerno",
        "affiliation_city": "Salerno",
        "affiliation_country": "Italy",
        "affiliation_id": "60007061",
        "affiliation_state": "SA"
    },
    {
        "paper_title": "25th European Symposium on Research in Computer Security, ESORICS 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 72 papers. The special focus in this conference is on Research in Computer Security. The topics include: Dynamic and secure memory transformation in userspace; understanding the security risks of docker hub; de-auth of the blue! transparent de-authentication using bluetooth low energy beacon; similarity of binaries across optimization levels and obfuscation; hart: Hardware-assisted kernel module tracing on arm; zipper stack: Shadow stacks without shadow; restructured cloning vulnerability detection based on function semantic reserving and reiteration screening; legiot: Ledgered trust management platform for iot; bulwark: Holistic and verified security monitoring of web protocols; privcoll: Practical privacy-preserving collaborative machine learning; an efficient 3-party framework for privacy-preserving neural network inference; deep learning side-channel analysis on large-scale traces: A case study on a polymorphic aes; towards poisoning the neural collaborative filtering-based recommender systems; data poisoning attacks against federated learning systems; interpretable probabilistic password strength meters via deep learning; polisma - a framework for learning attribute-based access control policies; a framework for evaluating client privacy leakages in federated learning; an accountable access control scheme for hierarchical content in named data networks with revocation; pgc: Decentralized confidential payment system with auditability; a practical model for collaborative databases: Securely mixing, searching and computing; secure cloud auditing with efficient ownership transfer; encrypt-to-self: Securely outsourcing storage; pglp: Customizable and rigorous location privacy through policy graph; where are you bob? privacy-preserving proximity testing with a napping party; distributed pcfg password cracking; your pin sounds good! augmentation of pin guessing strategies via audio leakage; anonymity preserving byzantine vector consensus.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Polisma - a framework for learning attribute-based access control policies",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "32",
        "cover_date": "2020-01-01",
        "Abstract": "Attribute-based access control (ABAC) is being widely adopted due to its flexibility and universality in capturing authorizations in terms of the properties (attributes) of users and resources. However, specifying ABAC policies is a complex task due to the variety of such attributes. Moreover, migrating an access control system adopting a low-level model to ABAC can be challenging. An approach for generating ABAC policies is to learn them from data, namely from logs of historical access requests and their corresponding decisions. This paper proposes a novel framework for learning ABAC policies from data. The framework, referred to as Polisma, combines data mining, statistical, and machine learning techniques, capitalizing on potential context information obtained from external sources (e.g., LDAP directories) to enhance the learning process. The approach is evaluated empirically using two datasets (real and synthetic). Experimental results show that Polisma is able to generate ABAC policies that accurately control access requests and outperforms existing approaches.",
        "DOI": "10.1007/978-3-030-58951-6_26",
        "paper_author": "Abu Jabal A.",
        "affiliation_name": "Purdue University",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60009254",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "17th International Conference on Trust, Privacy and Security in Digital Business, TrustBus 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 15 papers. The special focus in this conference is on Trust, Privacy and Security in Digital Business. The topics include: Empowering Users Through a Privacy Middleware Watchdog; utility Requirement Description for Utility-Preserving and Privacy-Respecting Data Pseudonymization; DEFeND DSM: A Data Scope Management Service for Model-Based Privacy by Design GDPR Compliance; a Distributed Trust Framework for Privacy-Preserving Machine Learning; a Fuzzy Trust Model for Autonomous Entities Acting in Pervasive Computing; cloud Computing Framework for e-Health Security Requirements and Security Policy Rules Case Study: A European Cloud-Based Health System; On the Suitability of Using SGX for Secure Key Storage in the Cloud; employment of Secure Enclaves in Cheat Detection Hardening; SECONDO: A Platform for Cybersecurity Investments and Cyber Insurance Decisions; are Sensor-Based Business Models a Threat to Privacy? The Case of Pay-How-You-Drive Insurance Models; microtargeting or Microphishing? Phishing Unveiled; privacy-Preserving Service Composition with Enhanced Flexibility and Efficiency; An Empirical Investigation of the Right to Explanation Under GDPR in Insurance.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "25th European Symposium on Research in Computer Security, ESORICS 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 72 papers. The special focus in this conference is on Research in Computer Security. The topics include: Dynamic and secure memory transformation in userspace; understanding the security risks of docker hub; de-auth of the blue! transparent de-authentication using bluetooth low energy beacon; similarity of binaries across optimization levels and obfuscation; hart: Hardware-assisted kernel module tracing on arm; zipper stack: Shadow stacks without shadow; restructured cloning vulnerability detection based on function semantic reserving and reiteration screening; legiot: Ledgered trust management platform for iot; bulwark: Holistic and verified security monitoring of web protocols; privcoll: Practical privacy-preserving collaborative machine learning; an efficient 3-party framework for privacy-preserving neural network inference; deep learning side-channel analysis on large-scale traces: A case study on a polymorphic aes; towards poisoning the neural collaborative filtering-based recommender systems; data poisoning attacks against federated learning systems; interpretable probabilistic password strength meters via deep learning; polisma - a framework for learning attribute-based access control policies; a framework for evaluating client privacy leakages in federated learning; an accountable access control scheme for hierarchical content in named data networks with revocation; pgc: Decentralized confidential payment system with auditability; a practical model for collaborative databases: Securely mixing, searching and computing; secure cloud auditing with efficient ownership transfer; encrypt-to-self: Securely outsourcing storage; pglp: Customizable and rigorous location privacy through policy graph; where are you bob? privacy-preserving proximity testing with a napping party; distributed pcfg password cracking; your pin sounds good! augmentation of pin guessing strategies via audio leakage; anonymity preserving byzantine vector consensus.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Research on Rasterized Population Evaluation Method Based on Multi-class Machine Learning Method",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The size of the city’s population directly determines the economic and social structure of the construction of ideas and development policies, so the accurate assessment of the urban population is extremely important. However, this paper is different from most other population assessment studies by the national, provincial and other large-scale administrative regions as the evaluation scope, taking Hunan Province as an example to rasterize the relevant regions, and take the systematic analysis and regional comprehensive research on the grid unit scale. In this paper, 30-dimensional irrelevant data of relevant regions in Hunan Province were obtained by crawlers, and each grid population was evaluated by using neural network model, SVM model and random forest model. Compared with the past yearbook population data, the experimental findings can still obtain a lower population assessment error index by using limited data. The average error of the three models is 5.8%, 5.7%, and 3.1%, respectively. The final analysis determined that random forests performed best on population estimates at grid cell scales. Therefore, it is possible to obtain a better population assessment result for each city through the geographic grid population assessment method of random forest with only limited data, which can save a great deal of resources and manpower consumption.",
        "DOI": "10.1007/978-981-15-8083-3_54",
        "paper_author": "Han J.",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60064143",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Behavior specific user simulation in spoken dialogue systems",
        "publication": "Sprachkommunikation - 10. ITG-Fachtagung",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Spoken dialogue systems provide an opportunity for man machine interaction using spoken language as the medium of interaction. In recent years reinforcement learning-based dialogue policy optimization has evolved to be state of the art. In order to cope with the data requirement for policy optimization and also to evaluate dialogue policies user simulators are introduced. Almost all existing data driven methods for user modelling aims at simulating some generic user behavior from some reference dialogue corpus. However, this corpus consists of dialogues from multiple users and thus exhibit different user behaviors. In this paper we explore the possibility of identifying and simulating different user behaviors observed in the corpus. For this purpose inverse reinforcement learning-based user simulation method is employed. Using experimental results, we validate the effectiveness of the proposed method for building multiple behavior specific user simulators.",
        "DOI": "NA",
        "paper_author": "Chandramohan S.",
        "affiliation_name": "SUPELEC École Supérieure d'Électricité",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France",
        "affiliation_id": "60009379",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "DeepCOVIDNet: An Interpretable Deep Learning Model for Predictive Surveillance of COVID-19 Using Heterogeneous Features and Their Interactions",
        "publication": "IEEE Access",
        "citied_by": "54",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we propose a deep learning model to forecast the range of increase in COVID-19 infected cases in future days and we present a novel method to compute equidimensional representations of multivariate time series and multivariate spatial time series data. Using this novel method, the proposed model can both take in a large number of heterogeneous features, such as census data, intra-county mobility, inter-county mobility, social distancing data, past growth of infection, among others, and learn complex interactions between these features. Using data collected from various sources, we estimate the range of increase in infected cases seven days into the future for all U.S. counties. In addition, we use the model to identify the most influential features for prediction of the growth of infection. We also analyze pairs of features and estimate the amount of observed second-order interaction between them. Experiments show that the proposed model obtains satisfactory predictive performance and fairly interpretable feature analysis results; hence, the proposed model could complement the standard epidemiological models for national-level surveillance of pandemics, such as COVID-19. The results and findings obtained from the deep learning model could potentially inform policymakers and researchers in devising effective mitigation and response strategies. To fast-track further development and experimentation, the code used to implement the proposed model has been made fully open source.",
        "DOI": "10.1109/ACCESS.2020.3019989",
        "paper_author": "Ramchandani A.",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60020547",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Deep learning for qos-aware resource allocation in cognitive radio networks",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "This paper focuses on the application of deep learning (DL) to obtain solutions for radio resource allocation problems in cognitive radio networks (CRNs). In the proposed approach, a deep neural network (DNN) as a DL model is proposed which can decide the transmit power without any help from other nodes. The resource allocation policies have been shown in the context of effective capacity theory. The numerical results demonstrate that the proposed model outperforms the scheme in terms of radio resource utilization efficiency. Simulation results also support the effectiveness on the delay guarantee performance.",
        "DOI": "10.1007/978-3-030-55789-8_28",
        "paper_author": "Martyna J.",
        "affiliation_name": "Uniwersytet Jagielloński",
        "affiliation_city": "Krakow",
        "affiliation_country": "Poland",
        "affiliation_id": "60021361",
        "affiliation_state": "Małopolska"
    },
    {
        "paper_title": "COVID-19: A master stroke of Nature",
        "publication": "AIMS Public Health",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "This article presents the status of countries affected by COVID-19 (as of mid-May 2020) and their preparedness to combat the after-effects of the pandemic. The report also provides an analysis of how human behavior may have triggered such a global pandemic and why humans need to consider living sustainably to make our future world livable for all. COVID-19 originated in the city of Wuhan, China in December 2019. As of mid-May, it has spread to 213 countries and territories worldwide. The World Health Organization has declared COVID-19 a global pandemic, with a death toll of over 300,000 to date. The U.S. is currently the most impacted country. Collaborative efforts of scientists and politicians across the world will be needed to better plan and utilize global health resources to combat this global pandemic. Machine learning-based prediction models could also help by identifying potential COVID-19-prone areas and individuals. The cause of the emergence of COVID-19 is still a matter of research; however, one consistent theme is humanity’s unsustainable behavior. By sustainably interacting with nature, humans may have avoided this pandemic. If unsustainable human practices are not controlled through education, awareness, behavioral change, as well as sustainable policy creation and enforcement, there could be several such pandemics in our future.",
        "DOI": "10.3934/publichealth.2020033",
        "paper_author": "Singh S.K.",
        "affiliation_name": "Virtusa Corporation",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "122485116",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Digital soil mapping using Sentinel-2 imagery supported by ASTER thermal infrared bands",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "The importance of monitoring soil properties is constantly increasing among researchers and policy-makers. In this context, it is imperative to identify cost effective and reliable strategies for soil mapping compared to the costlier traditional solutions. A wide range of tools are becoming available that enable better utilization of Earth Observation capabilities to monitor the soil ecosystem. This work is an effort of assessing the potential of Sentinel-2 imagery data for mapping Soil Organic Matter (SOM) contents and investigating the possibilities of its enhancement through ASTER derived information. The rural area around the lake Zazari, located in the Western Macedonia district of Greece, was chosen as study area. Initially, pixel-wise vegetation indices (NDVI and NBR2) were calculated, utilizing a local version of the CEOS Open Data Cube for masking Sentinel-2 bare soil pixels extending a three-year period (2017-2019). The generated mask was used to extract soil spectral signatures at the image level over selected 100 field samples. The resulting time series was expanded through the conjunction of ASTER Thermal InfraRed bands by matching the exact data acquisition dates of two platforms. The conclusive part of the work contains the application of regression modelling to effectively assess soil variables. The local Partial Least Square regression algorithm was chosen, due to its characteristics of performing inherently local predictions. Five-fold cross-validation technique was used for reporting the models' accuracy, which was assessed through R 2 coefficient, RPIQ ratio and RMSE. The model estimated SOM values among a synthetic bare soil composite image that was acquired over study area's agricultural fields. Two models were trained and compared; one over Sentinel-2 imagery bands that were used as the predictor variables' set and a second over an expanded predictor variables' set, including ASTER thermal bands. The results signified evidence of accuracy increase of SOM content assessment, through spaceborne imagery analysis.",
        "DOI": "10.1117/12.2570821",
        "paper_author": "Karyotis K.",
        "affiliation_name": "International Hellenic University",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece",
        "affiliation_id": "60158100",
        "affiliation_state": "Central Macedonia"
    },
    {
        "paper_title": "13th International Conference on the Quality of Information and Communications Technology, QUATIC 2020",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 39 papers. The special focus in this conference is on Quality of Information and Communications Technology. The topics include: Challenges for layout validation: Lessons learned; preface; perceived quality of artificial intelligence in smart service systems: A structured approach; towards automated taxonomy generation for grouping app reviews: A preliminary empirical study; zones of pain: Visualising the relationship between software architecture and defects; an empirical study on the persistence of spotbugs issues in open-source software evolution; applying continual service improvement practices to study quality of healthcare information system services: A case study; a personal opinion survey on process compliance checking in the safety context; systematic literature review of devops models; measuring the maturity of bizdevops; process compliance re-certification efficiency enabled by epf-c ∘ bvr-t: A case study; design of secure coding challenges for cybersecurity education in the industry; q-scrum: A framework for quality in safety-critical development; towards guidelines for assessing qualities of machine learning systems; reverse engineering of quantum programs toward kdm models; math and physics tools for quality quantum programming; adapting cobit for quantum computing governance; quantum agile development framework; on the source code structure of quantum code: Insights from q# and qdk; towards a framework for improving experiments on dos attacks; a cloud secdevops methodology: From design to testing; accountability in the a posteriori access control: A requirement and a mechanism; secure agile software development: Policies and practices for agile teams; a privacy-by-design architecture for indoor localization systems; reverse engineering of android applications: Reimpact.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Performance evaluation of enterprises' innovation capacity based on fuzzy system model and convolutional neural network",
        "publication": "Journal of Intelligent and Fuzzy Systems",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Influenced by national policies and macro-economic environment, large domestic enterprises is actively promoting strategic transformation to enhance their core competitiveness, and performance evaluation of enterprises' innovation capacity has become a hot topic in recent years. This paper proposes a performance evaluation method of enterprises' innovation capacity based on deep learning fuzzy system model and convolutional neural network analysis of innovation network. First of all, on account of the characteristics of breakthrough innovation and drawing on the traditional innovation performance evaluation model, this paper constructs a breakthrough innovation performance evaluation index system for enterprises from the six dimensions of main resource input, technology out-turn, process management, product performance, social value and commercial Value. Secondly, the introduction of machine learning of fuzzy convolutional neural network to assess the advancement execution of enterprises is of great significance for enterprise managers to find out the problems and causes of enterprises' innovation, optimize the allocation of enterprises' resources and further improve the innovation performance of enterprises. The experimental results show to verify the adequacy of the algorithm.",
        "DOI": "10.3233/JIFS-179929",
        "paper_author": "Abudureheman A.",
        "affiliation_name": "Xinjiang University of Finance and Economics",
        "affiliation_city": "Urumqi",
        "affiliation_country": "China",
        "affiliation_id": "60210345",
        "affiliation_state": "Xinjiang"
    },
    {
        "paper_title": "Development of downscaling method using the RBF network assessing the hourly population inflow: A case study of the Sapporo urban area",
        "publication": "Asian Transport Studies",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "In Japan in recent years, policies for compact cities have been promoted as the population has decreased, and the use of micro-geo data has attracted attention in urban planning. Therefore, when considering a compact city, it is important to know the relationship between the urban facility layout and the population flow. In this research, we created a data set using demographic data, location information of mobile phones, and detailed building data and used a radial basis function (RBF) network. In short, the purpose of this study was to develop a method to reduce the estimated area of population inflow per hour. Population inflow is expressed as the visiting population, which is defined by the difference in the staying population in the time of two sections. By spatially visualizing the results, we were able to downscale the population flow data on a 500 ​m grid.",
        "DOI": "10.1016/j.eastsj.2020.100019",
        "paper_author": "Okumura K.",
        "affiliation_name": "Muroran Institute of Technology",
        "affiliation_city": "Muroran",
        "affiliation_country": "Japan",
        "affiliation_id": "60014729",
        "affiliation_state": "Hokkaido"
    },
    {
        "paper_title": "Artificial Intelligence, Machine Learning, and Cardiovascular Disease",
        "publication": "Clinical Medicine Insights: Cardiology",
        "citied_by": "105",
        "cover_date": "2020-01-01",
        "Abstract": "Artificial intelligence (AI)-based applications have found widespread applications in many fields of science, technology, and medicine. The use of enhanced computing power of machines in clinical medicine and diagnostics has been under exploration since the 1960s. More recently, with the advent of advances in computing, algorithms enabling machine learning, especially deep learning networks that mimic the human brain in function, there has been renewed interest to use them in clinical medicine. In cardiovascular medicine, AI-based systems have found new applications in cardiovascular imaging, cardiovascular risk prediction, and newer drug targets. This article aims to describe different AI applications including machine learning and deep learning and their applications in cardiovascular medicine. AI-based applications have enhanced our understanding of different phenotypes of heart failure and congenital heart disease. These applications have led to newer treatment strategies for different types of cardiovascular diseases, newer approach to cardiovascular drug therapy and postmarketing survey of prescription drugs. However, there are several challenges in the clinical use of AI-based applications and interpretation of the results including data privacy, poorly selected/outdated data, selection bias, and unintentional continuance of historical biases/stereotypes in the data which can lead to erroneous conclusions. Still, AI is a transformative technology and has immense potential in health care.",
        "DOI": "10.1177/1179546820927404",
        "paper_author": "Mathur P.",
        "affiliation_name": "UAMS College of Medicine",
        "affiliation_city": "Little Rock",
        "affiliation_country": "United States",
        "affiliation_id": "60031189",
        "affiliation_state": "AR"
    },
    {
        "paper_title": "Intelligent Performance-Aware Adaptation of Control Policies for Optimizing Banking Teller Process Using Machine Learning",
        "publication": "IEEE Access",
        "citied_by": "32",
        "cover_date": "2020-01-01",
        "Abstract": "In the current banking systems and business processes, the permission granted to employees is controlled and managed by the configured access control methods, in which static role-based models focus on access to information and functions. The deployed configuration is not reviewed/updated systematically and is handled manually by managers. Consequently, banks and companies are looking for systems and applications to automate and optimize their business processes and data management intelligently. In this context, the notion of integrating machine learning (ML) techniques in banking business processes has emerged. In order to build an intelligent and systematic solution, we combine in this paper ML and dynamic authorization techniques to enable performance-based policy evaluation into the banking teller process, where policies adapt to the changes recognized by the ML model. The objective of this work is to focus on the banking teller process that may be generalized to other operational banking processes. In this context, we propose in this paper a new model providing Intelligent Performance-Aware Adaptation of Roles and Policy Control using a support vector machine (SVM). We demonstrate that our model is capable of assessing the deployed control policies and updating them systematically with new roles and authorization levels based on tellers' performance, work history, and system constraints. We evaluated different machine learning models on a real dataset generated from a real-life banking environment. Experimental results explore the relevance and efficiency of our proposed scheme in terms of prediction accuracy, required authorizations, transaction time, and employees' working hours.",
        "DOI": "10.1109/ACCESS.2020.3015616",
        "paper_author": "Tay B.",
        "affiliation_name": "Lebanese American University",
        "affiliation_city": "Beirut",
        "affiliation_country": "Lebanon",
        "affiliation_id": "60068769",
        "affiliation_state": "Beirut Governorate"
    },
    {
        "paper_title": "Data as a strategic asset: Improving results through a systematic data governance framework",
        "publication": "SPE Latin American and Caribbean Petroleum Engineering Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "This paper presents a systematic proven and effective nine-step data governance framework that helps to enable oil and gas organizations to improve results by treating data as a strategic asset. The world is becoming increasingly data driven and technologically disrupted, and this momentum is expected to continue. According to the World Economic Forum (Kirk Bresniker 2018), \"every two years we create more data than we've created in all of history. Our ambitions are growing faster than our computers can improve.\" Our industry's success will depend on timely development and appropriate application of machine learning, artificial intelligence (AI), and other advanced analytics. However, these tools may be ineffective and even destructive if the data used is compromised. In our study, we identified the factors that contribute to the problem of compromised data. Technical data and business landscapes are highly complex, segmented and largely disjointed. Most organizations are fragmented, working in silos rather than collaboratively. Production data owners in the field are traditionally far removed from data users at the office. Often \"raw\" data owners in the field have limited appreciation of the importance of \"trusted data,\" while data users at the office spend 80% of their time looking for and cleansing data, and only 20% of their time transforming data into actionable insights to drive informed decisions (Gabernet and Limburn 2017). The disconnect between departments often results in significant \"hard-dollar\" loss, which contributes to unknown potential value loss. Our data governance framework (Fig. 1) is a nine-step, methodical procedure that helps address these problems and positions the company to be more agile moving forward. 1. Determine organizational priorities and define the scope 2. Invest in organizational change management - key for adoption and sustainability 3. Establish the data governance organization, demonstrating comprehensive leadership support 4. Connect and align teams through a fit-for-purpose data catalog 5. Establish data governance policies to support priorities 6. Define new operating model by transforming policies into new ways of working 7. Design enabling technologies to support the data governance objectives 8. Implement ongoing data quality and availability monitoring 9. Facilitate sustainability via periodic audits based on pre-defined key performance indicators (KPIs) We developed and applied this systematic procedure to create trusted data in a world-leading natural resources company. Quality production data clearly enabled better informed and more strategic decisions and helped protect the company against potential litigations. Specific benefits were quantified to the following annual recurring economic value (in the context of sub-USD 60/bbl oil price environment) for 1,700 wells in the U.S. shale: • Improved information and decision quality (USD 3.7 million) • Reduced cost and cycle time (USD 4.4 million) • Increased production (USD 3.2 million) Trusted production data converted into robust, actionable insights improved performance in the following functions: • Well performance • Predictive maintenance • Operational intervention • Revenue and joint venture accounting • Regulatory reporting • Reservoir analysis In this paper we detail our tested and effective nine-step data governance framework, developed based on years of experience in the oil and gas industry, ranging from operations, engineering, and production volumes allocations to information technology and continuous improvement. Key to the importance of this work is treating data as a strategic asset and recognizing that, without trustworthy data, planning and performance analysis, whether performed by human colleague or robotics/advanced analytics, is of limited and misleading value.",
        "DOI": "NA",
        "paper_author": "Huff E.",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60020547",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Predicting the Regional Adoption of Electric Vehicle (EV) with Comprehensive Models",
        "publication": "IEEE Access",
        "citied_by": "22",
        "cover_date": "2020-01-01",
        "Abstract": "Adoption of electric vehicles (EVs) has been regarded as one of the most important strategies to address the issues of energy dependence and greenhouse effect. Empirical reviews demonstrate that wide acceptance of EV is still difficult to achieve. This research proposes to investigate the factors that might trigger the wide usage of EVs to support the energy policy. The real-world owners of EV were extracted from the 2017 National Household Travel Survey (NHTS), which provides large-scale individual characteristics. NHTS dataset was processed to establish the comprehensive estimation model for EV adoption with considering vehicle, personal and household factors. Besides the commonly social-economic factors, the gasoline price and car sharing program were found to be significant for EV adoption. Additionally, since the EV owners are only 1.29% of all vehicle owners, this article introduced the imbalanced dataset technique, which was seldom considered in existing researches. Subsequently, several machine learning methods were utilized to build the prediction model, and the model performance analysis indicates the Decision Tree (DT) model outperforms other models. A regional EV penetration map was also generated for the U.S. to validate the proposed approach. Implications for further research, transport policy and EV market are discussed.",
        "DOI": "10.1109/ACCESS.2020.3014851",
        "paper_author": "Jia J.",
        "affiliation_name": "Shandong Jianzhu University",
        "affiliation_city": "Jinan",
        "affiliation_country": "China",
        "affiliation_id": "60083498",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Reinforcement Learning Based Control Design for a Floating Piston Pneumatic Gearbox Actuator",
        "publication": "IEEE Access",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Electro-pneumatic actuators play an essential role in various areas of the industry, including heavy-duty vehicles. This article deals with the control problem of an Automatic Manual Transmission, where the actuator of the system is a double-acting floating-piston cylinder, with dedicated inner-position. During the control design of electro-pneumatic cylinders, one must implement a set-valued control on a nonlinear system, when, as in the present case, non-proportional valves provide the airflow. As both the system model itself and the qualitative control goals can be formulated as a Partially Observable Markov Decision Process, Machine learning frameworks are a conspicuous choice for handling such control problems. To this end, six different solutions are compared in the article, of which a new agent named PG-MCTS, using a modified version of the 'Upper Confidence bound for Trees' algorithm, is also presented. The performance and strategic choice comparison of the six methods are carried out in a simulation environment. Validation tests performed on an actual transmission system and implemented on an automotive control unit to prove the applicability of the concept. In this case, a Policy Gradient agent, selected by implementation and computation capacity restrictions. The results show that the presented methods are suitable for the control of floating-piston cylinders and can be extended to other fluid mechanical actuators, or even different set-valued nonlinear control problems.",
        "DOI": "10.1109/ACCESS.2020.3015576",
        "paper_author": "Becsi T.",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary",
        "affiliation_id": "60030035",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Local Training Strategy-Based Artificial Neural Network for Predicting the Power Production of Solar Photovoltaic Systems",
        "publication": "IEEE Access",
        "citied_by": "35",
        "cover_date": "2020-01-01",
        "Abstract": "Power production prediction from Renewable Energy (RE) sources has been widely studied in the last decade. This is extremely important for utilities to counterpart electricity supply with consumer demands across centralized grid networks. In this context, we propose a local training strategy-based Artificial Neural Network (ANN) for predicting the power productions of solar Photovoltaic (PV) systems. Specifically, the timestamp, weather variables, and corresponding power productions collected locally at each hour interval h , h = [1, 24] (i.e., an interval of \\Delta h=1 hour), are exploited to build, optimize, and evaluate H=24 different ANNs for the 24 hourly solar PV production predictions. The proposed local training strategy-based ANN is expected to provide more accurate predictions with short computational times than those obtained by a single (i.e., H=1 ) ANN model (hereafter called benchmark) built, optimized, and evaluated globally on the entire available dataset. The proposed strategy is applied to a case study regarding a 264kWp solar PV system located in Amman, Jordan, and its effectiveness compared to the benchmark is verified by resorting to different performance metrics from the literature. Further, its effectiveness is verified and compared when Extreme Learning Machines (ELMs) are adopted instead of the ANNs, and when the Persistence model is used. The prediction performance of the two training strategies-based ANN is also investigated and compared in terms of i) different weather conditions (i.e., seasons) experienced by the solar PV system under study and ii) different hour intervals (i.e., Δ h=2 , 3, and 4 hours) used for partitioning the overall dataset and, thus, establishing the different ANNs (i.e., H =12 , 8, and 6 models, respectively).",
        "DOI": "10.1109/ACCESS.2020.3016165",
        "paper_author": "Al-Dahidi S.",
        "affiliation_name": "German Jordanian University",
        "affiliation_city": "Amman",
        "affiliation_country": "Jordan",
        "affiliation_id": "60070287",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Verifiable RNN-based policies for pomdps under temporal logic constraints",
        "publication": "IJCAI International Joint Conference on Artificial Intelligence",
        "citied_by": "22",
        "cover_date": "2020-01-01",
        "Abstract": "Recurrent neural networks (RNNs) have emerged as an effective representation of control policies in sequential decision-making problems. However, a major drawback in the application of RNN-based policies is the difficulty in providing formal guarantees on the satisfaction of behavioral specifications, e.g. safety and/or reachability. By integrating techniques from formal methods and machine learning, we propose an approach to automatically extract a finite-state controller (FSC) from an RNN, which, when composed with a finite-state system model, is amenable to existing formal verification tools. Specifically, we introduce an iterative modification to the so-called quantized bottleneck insertion technique to create an FSC as a randomized policy with memory. For the cases in which the resulting FSC fails to satisfy the specification, verification generates diagnostic information. We utilize this information to either adjust the amount of memory in the extracted FSC or perform focused retraining of the RNN. While generally applicable, we detail the resulting iterative procedure in the context of policy synthesis for partially observable Markov decision processes (POMDPs), which is known to be notoriously hard. The numerical experiments show that the proposed approach outperforms traditional POMDP synthesis methods by 3 orders of magnitude within 2% of optimal benchmark values.",
        "DOI": "NA",
        "paper_author": "Carr S.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Deep Reinforcement Learning with Temporal Logics",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "34",
        "cover_date": "2020-01-01",
        "Abstract": "The combination of data-driven learning methods with formal reasoning has seen a surge of interest, as either area has the potential to bolstering the other. For instance, formal methods promise to expand the use of state-of-the-art learning approaches in the direction of certification and sample efficiency. In this work, we propose a deep Reinforcement Learning (RL) method for policy synthesis in continuous-state/action unknown environments, under requirements expressed in Linear Temporal Logic (LTL). We show that this combination lifts the applicability of deep RL to complex temporal and memory-dependent policy synthesis goals. We express an LTL specification as a Limit Deterministic Büchi Automaton (LDBA) and synchronise it on-the-fly with the agent/environment. The LDBA in practice monitors the environment, acting as a modular reward machine for the agent: accordingly, a modular Deep Deterministic Policy Gradient (DDPG) architecture is proposed to generate a low-level control policy that maximises the probability of the given LTL formula. We evaluate our framework in a cart-pole example and in a Mars rover experiment, where we achieve near-perfect success rates, while baselines based on standard RL are shown to fail in practice.",
        "DOI": "10.1007/978-3-030-57628-8_1",
        "paper_author": "Hasanbeig M.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Compassion in healthcare pilgrimage, practice, and civic life",
        "publication": "Compassion in Healthcare: Pilgrimage, Practice, and Civic Life",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "This book gives an account of the nature and content of compassion and its role in healthcare. The argument considers how and why contested beliefs about political life, suffering, the human condition, time, and responsibility make a difference to ‘compassion’. While compassion appears to be a straightforward aspect of life and practice, the appearance is deceptive. Compassion is plagued by both conceptual and practical ills and needs some quite specific kinds of therapy. The first step therefore is to diagnose precisely what is wrong with ‘compassion’ including its debilitating political entanglements, the vagueness of its meaning and the risk of burn-out it threatens. With diagnosis in hand, three therapies are prescribed for compassion’s ills: (i) an understanding of patients and healthcare workers as those who pass through the life-course, encountering each other as wayfarers and pilgrims; (ii) a grasp of the nature of compassion in healthcare; and (iii) an embedding of healthcare within the realities of civic life. With this therapy applied, the argument shows how compassionate relationships acquire their content in healthcare practice. First, the form that compassion takes is shown to depend on how different doctrines of time, tragedy, salvation, responsibility, fault, and theodicy set the terms of people’s lives and relationships. Second, how such compassion matters to practice and policy is worked out in the detail of healthcare professionalism, marketisation, and technology, drawing on the author’s collaborations. Covering everything from conception to old age, and from machine learning to religious diversity, this book draws on philosophy, theology, and everyday experience to stretch the imagination of what compassion might mean in healthcare practice.",
        "DOI": "10.1093/oso/9780198790860.001.0001",
        "paper_author": "Hordern J.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Extending sliding-step importance weighting from supervised learning to reinforcement learning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Stochastic gradient descent (SGD) has been in the center of many advances in modern machine learning. SGD processes examples sequentially, updating a weight vector in the direction that would most reduce the loss for that example. In many applications, some examples are more important than others and, to capture this, each example is given a non-negative weight that modulates its impact. Unfortunately, if the importance weights are highly variable they can greatly exacerbate the difficulty of setting the step-size parameter of SGD. To ease this difficulty, Karampatziakis and Langford[6] developed a class of elegant algorithms that are much more robust in the face of highly variable importance weights in supervised learning. In this paper we extend their idea, which we call “sliding step”, to reinforcement learning, where importance weighting can be particularly variable due to the importance sampling involved in off-policy learning algorithms. We compare two alternative ways of doing the extension in the linear function approximation setting, then introduce specific sliding-step versions of the TD(0) and Emphatic TD(0) learning algorithms. We prove the convergence of our algorithms and demonstrate their effectiveness on both on-policy and off-policy problems. Overall, our new algorithms appear to be effective in bringing the robustness of the sliding-step technique from supervised learning to reinforcement learning.",
        "DOI": "10.1007/978-3-030-56150-5_4",
        "paper_author": "Tian T.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60030835",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Intelligent Learning based Opinion Mining Model for Governmental Decision Making",
        "publication": "Procedia Computer Science",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Government in a country is the foremost legislative body responsible for taking decisive steps, planning schemes and implementing them with zero margins of error. These schemes and policies directly or indirectly affect the population of the country and direct the rate of social and economic growth. Effective policy framing and implementations have been the primary aim of all governments. But for good governance with long term sustainability taking opinions of the general public becomes indispensable. Twitter is one such open platform for a new type of social interaction where people come forward and express their views not only on products, movies and celebrities but also those critical policies and schemes designed by the government with aim of the overall development. These opinions have a lot more weight and convey a major message to the policymakers if evaluated correctly. This paper elucidates one such framework which mines opinion of general users tweeting on twitter about government policies and classifies them into three different polarities i.e. positive, negative and neutral. Machine Learning and Deep Learning method along with Natural Language Processing techniques has been utilized to extract the sentiments of the tweet and perform analysis on its polarity. The results of this detailed analysis can act as feedback to the governing bodies which can give them a better idea of the demography of the public's opinion in an effective manner. Thus, this research works presents a technology-based solution for smart governance and interactive policy framing.",
        "DOI": "10.1016/j.procs.2020.06.026",
        "paper_author": "Sharma A.",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60002874",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Effectiveness of the public health measures to prevent the spread of covid-19",
        "publication": "Communications in Mathematical Biology and Neuroscience",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "COVID-19 which has become a global pandemic, recently, has spread to hundreds of countries and territories. This pandemic spreads rapidly through human transmission. In order to reduce the spread of COVID-19, the government emerged several policies. Numerous public health measures can be implemented to counter the risk of an emerging outbreak with pandemic potential. Meanwhile, Jakarta and West Java are the regions with the most confirmed cases in Indonesia, the government announced Large-Scale Social Restrictions (PSBB) policy in both provinces. Many researchers conducted forecasting methods for modeling or predict the further number of cases of this pandemic. Forecasting is slightly hard because of those interventions. In this study, we involved some of neural network forecasting methods, including Multi-Layer Perceptron, Neural Network Auto-Regressive, and Extreme Learning Machine meanwhile neural networks become well-known at this time for forecasting the number of active, confirmed, recovered, death, and daily new cases in Jakarta and West Java. These methods are undertaking automatically without considering any factors that will be impacted the result as the reason that we assumed those factors have pursued the pattern of each case. The best model for all of the cases is the MLP (10,10) model. This intervention carried out by the government, namely PSBB, proved effective in reducing the spread of this pandemic in Jakarta and West Java. This can be seen from the results of the daily new cases which show a downward trend for both although still fluctuating.",
        "DOI": "10.28919/cmbn/4711",
        "paper_author": "Pontoh R.S.",
        "affiliation_name": "Universitas Padjadjaran",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069388",
        "affiliation_state": "West Java"
    },
    {
        "paper_title": "Impact of large scale social restriction on the COVID-19 cases in East Java",
        "publication": "Communications in Mathematical Biology and Neuroscience",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Indonesia is one of the countries affected by COVID-19. The Indonesian government and local governments have issued several guidelines to limit the spread of cases that spread across people in the form of restrictions on physical activity between people. One of the guidelines is large-scale social restrictions (PSBB). PSBB is being implemented in several regions of Indonesia with high COVID-19 cases, including Jakarta, West Java and East Java. Recently, East Java became a province with the highest number of daily new cases, reaching more than 300 reported cases in one day. Some time ago, several regions in Indonesia stopped PSBB policy and took the direction of the New Normal, including East Java. This study suggests machine learning methods that are recognized based on high accuracy, containing Extreme Learning Machines, Multi-Layer Perceptron, and Auto-Regressive Neural Networks to predict the number of daily new, active, confirmed, recovered, and death cases. The MLP (10,10) model was obtained as the best model for predicting the five case variables in East Java for the next 7 days. Based on these results, it can be concluded that the cases in East Java are still increasing. According to this study, the application of the PSBB and the abolition of the PSBB directive, which was replaced by the New Normal directive, had a significant impact on the increase in cases in the East Java region. This is in line with the estimation results, which show that cases in East Java tend to increase with fluctuating new daily cases.",
        "DOI": "10.28919/cmbn/4837",
        "paper_author": "Toharudin T.",
        "affiliation_name": "Universitas Padjadjaran",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069388",
        "affiliation_state": "West Java"
    },
    {
        "paper_title": "Combat COVID-19 with artificial intelligence and big data",
        "publication": "Journal of Travel Medicine",
        "citied_by": "88",
        "cover_date": "2020-01-01",
        "Abstract": "NA",
        "DOI": "10.1093/JTM/TAAA080",
        "paper_author": "Lin L.",
        "affiliation_name": "London School of Hygiene &amp; Tropical Medicine",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031331",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Could dementia be detected from UK primary care patients' records by simple automated methods earlier than by the treating physician? A retrospective case-control study",
        "publication": "Wellcome Open Research",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Timely diagnosis of dementia is a policy priority in the United Kingdom (UK). Primary care physicians receive incentives to diagnose dementia; however, 33% of patients are still not receiving a diagnosis. We explored automating early detection of dementia using data from patients' electronic health records (EHRs). We investigated: a) how early a machine-learning model could accurately identify dementia before the physician; b) if models could be tuned for dementia subtype; and c) what the best clinical features were for achieving detection. Methods: Using EHRs from Clinical Practice Research Datalink in a case-control design, we selected patients aged >65y with a diagnosis of dementia recorded 2000-2012 (cases) and matched them 1:1 to controls; we also identified subsets of Alzheimer's and vascular dementia patients. Using 77 coded concepts recorded in the 5 years before diagnosis, we trained random forest classifiers, and evaluated models using Area Under the Receiver Operating Characteristic Curve (AUC). We examined models by year prior to diagnosis, subtype, and the most important features contributing to classification. Results: 95,202 patients (median age 83y; 64.8% female) were included (50% dementia cases). Classification of dementia cases and controls was poor 2-5 years prior to physician-recorded diagnosis (AUC range 0.55-0.65) but good in the year before (AUC: 0.84). Features indicating increasing cognitive and physical frailty dominated models 2-5 years before diagnosis; in the final year, initiation of the dementia diagnostic pathway (symptoms, screening and referral) explained the sudden increase in accuracy. No substantial differences were seen between all-cause dementia and subtypes. Conclusions: Automated detection of dementia earlier than the treating physician may be problematic, if using only primary care data. Future work should investigate more complex modelling, benefits of linking multiple sources of healthcare data and monitoring devices, or contextualising the algorithm to those cases that the GP would need to investigate.",
        "DOI": "10.12688/wellcomeopenres.15903.1",
        "paper_author": "Ford E.",
        "affiliation_name": "Brighton and Sussex Medical School",
        "affiliation_city": "Brighton",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60100018",
        "affiliation_state": "East Sussex"
    },
    {
        "paper_title": "Prediction of Systemic Risk Contagion Based on a Dynamic Complex Network Model Using Machine Learning Algorithm",
        "publication": "Complexity",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "It is well known that the interbank market is able to effectively provide financial liquidity for the entire banking system and maintain the stability of the financial market. In this paper, we develop an innovative complex network approach to simulate an interbank network with systemic risk contagion that takes into account the balance sheet of each bank, from which we can identify if the financial institutions have sufficient capital reserves to prevent risk contagion. Cascading defaults are also generated in the simulation according to different crisis-triggering (targeted defaults) methods. We also use machine learning techniques to identify the synthetic features of the network. Our analysis shows that the topological factors and market factors in the interbank network have significant impacts on the risk spreading. Overall, this paper provides a scientific method for policy-makers to select the optimal management policy for handling systemic risk.",
        "DOI": "10.1155/2020/6035372",
        "paper_author": "Yu J.",
        "affiliation_name": "Harbin Engineering University",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60003353",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "A peer-to-peer crowdsourcing platform for the labeled datasets forming",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Training dataset forming is quite labor intensive and frequently is of high costs. Also the cost overheads depend on the policies of the service, which implements the crowdsourcing approach to data labeling. In this paper a new peer-to-peer data labeling platform concept is presented, as well as the framework of the decentralized labeling approach is described briefly. The architecture proposed allows to avoid the intermediary labeling service and to perform the crowdsourcing-based data labeling by the computational facilities of users involved. Besides, the additional consensus procedure improves the quality of the labeled data by means of the voting procedure.",
        "DOI": "10.1007/978-3-030-51974-2_9",
        "paper_author": "Melnik E.V.",
        "affiliation_name": "Southern Scientific Centre, Russian Academy of Sciences",
        "affiliation_city": "Rostov-on-Don",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60085215",
        "affiliation_state": "Rostov Oblast"
    },
    {
        "paper_title": "Policy Space Exploration for Linear Quadratic Regulator (LQR) Using Augmented Random Search (ARS) Algorithm",
        "publication": "Lecture Notes in Networks and Systems",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Considering the recent developments in embedded systems and automotive industry, it is quite evident that in very near future many application-based electronic devices will adapt the automation in its daily based activities. This automation will make the devices more powerful and will enhance its services. Currently, automation is the result of the algorithms which are pre-coded into the devices, but its future is the result of algorithms which enable devices to learn from environment in which it needs to work. It can be achieved utilizing the resources developed for a particular domain popularly known as reinforcement learning (RL). Main objective of this paper is to enable an agent to explore a policy for achieving a control of dynamic system such that it will be capable to find an optimal solution to solve the environment. It can be achieved using an algorithm known as augmented random search algorithm. To improve the training speed, we will use concept of multiprocessing and environment-specific customizations along with ARS algorithm.",
        "DOI": "10.1007/978-981-15-3172-9_74",
        "paper_author": "Velamati S.",
        "affiliation_name": "Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering &amp; Technology",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India",
        "affiliation_id": "60109586",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Variational Quantum Circuits for Deep Reinforcement Learning",
        "publication": "IEEE Access",
        "citied_by": "231",
        "cover_date": "2020-01-01",
        "Abstract": "The state-of-the-art machine learning approaches are based on classical von Neumann computing architectures and have been widely used in many industrial and academic domains. With the recent development of quantum computing, researchers and tech-giants have attempted new quantum circuits for machine learning tasks. However, the existing quantum computing platforms are hard to simulate classical deep learning models or problems because of the intractability of deep quantum circuits. Thus, it is necessary to design feasible quantum algorithms for quantum machine learning for noisy intermediate scale quantum (NISQ) devices. This work explores variational quantum circuits for deep reinforcement learning. Specifically, we reshape classical deep reinforcement learning algorithms like experience replay and target network into a representation of variational quantum circuits. Moreover, we use a quantum information encoding scheme to reduce the number of model parameters compared to classical neural networks. To the best of our knowledge, this work is the first proof-of-principle demonstration of variational quantum circuits to approximate the deep Q -value function for decision-making and policy-selection reinforcement learning with experience replay and target network. Besides, our variational quantum circuits can be deployed in many near-term NISQ machines.",
        "DOI": "10.1109/ACCESS.2020.3010470",
        "paper_author": "Chen S.Y.C.",
        "affiliation_name": "National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60005429",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Current Practices of Solar Photovoltaic Panel Cleaning System and Future Prospects of Machine Learning Implementation",
        "publication": "IEEE Access",
        "citied_by": "49",
        "cover_date": "2020-01-01",
        "Abstract": "Solar Photovoltaic System (SPV) is one of the growing green energy sources having immense penetration in the national grid as well as the off-grid around the globe. Regardless of different solar insolation level at various regions of the world, SPV performance is also affected by several factors: conversion efficiency of PV cell technology, ambient temperature and humidity, soiling and seasonal/weather patterns. The rise in PV cell temperature and soiling is found to be detrimental issues regarding power plant performance and life expectancy leading alterations in the levelised cost of energy (LCoE). In this paper, authors present a short glance about factors affecting the performance of photovoltaic modules and re-discuss their usability in cleaning intervention decision-making models. With some highlights on the essence of cleaning to mitigate the soiling issues in PV power plants, this paper presents the existing cleaning techniques and practices along with their evaluations. The need for an optimal cleaning intervention by using advanced scientific tools rather than by visual inspection is drawing the attention of PV experts. The authors finally suggest a schematic of a decision-making model which involves the use of probable parameters, data processing techniques and machine learning tools. The implementation of data science and machine learning in a solar PV panel cleaning system could be a remarkable advancement in the field of renewable energy.",
        "DOI": "10.1109/ACCESS.2020.3011553",
        "paper_author": "Khadka N.",
        "affiliation_name": "Kathmandu University",
        "affiliation_city": "Dhulikhel",
        "affiliation_country": "Nepal",
        "affiliation_id": "60071792",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "8th International Conference on Data Management Technologies and Applications, DATA 2019",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 8 papers. The special focus in this conference is on Data Management Technologies and Applications. The topics include: Industry 4.0: Sensor data analysis using machine learning; scalable architecture, storage and visualization approaches for time series analysis systems; optimizing steering of roaming traffic with a-number billing under a rolling horizon policy; a web-based decision support system for quality prediction in manufacturing using ensemble of regressor chains; farm area segmentation in satellite images using deeplabv3+ neural networks; about the fairness of database performance comparisons.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Novel Multi-Agent Parallel-Critic Network Architecture for Cooperative-Competitive Reinforcement Learning",
        "publication": "IEEE Access",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "Multi-agent deep reinforcement learning (MDRL) is an emerging research hotspot and application direction in the field of machine learning and artificial intelligence. MDRL covers many algorithms, rules and frameworks, it is currently researched in swarm system, energy allocation optimization, stocking analysis, sequential social dilemma, and with extremely bright future. In this paper, a parallel-critic method based on classic MDRL algorithm MADDPG is proposed to alleviate the training instability problem in cooperative-competitive multi-agent environment. Furthermore, a policy smoothing technique is introduced to our proposed method to decrease the variance of learning policies. The suggested method is evaluated in three different scenarios of authoritative multi-agent particle environment (MPE). Multiple statistical data of experimental results show that our method significantly improves the training stability and performance compared to vanilla MADDPG.",
        "DOI": "10.1109/ACCESS.2020.3011670",
        "paper_author": "Sun Y.",
        "affiliation_name": "Peoples Liberation Army Engineering University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60226539",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "On the path to AI: Law’s prophecies and the conceptual foundations of the machine learning age",
        "publication": "On the Path to AI: Law's Prophecies and the Conceptual Foundations of the Machine Learning Age",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Introduction This open access book explores machine learning and its impact on how we make sense of the world. It does so by bringing together two ‘revolutions’ in a surprising analogy: the revolution of machine learning, which has placed computing on the path to artificial intelligence, and the revolution in thinking about the law that was spurred by Oliver Wendell Holmes Jr in the last two decades of the 19th century. Holmes reconceived law as prophecy based on experience, prefiguring the buzzwords of the machine learning age-prediction based on datasets. On the path to AI introduces readers to the key concepts of machine learning, discusses the potential applications and limitations of predictions generated by machines using data, and informs current debates amongst scholars, lawyers and policy makers on how it should be used and regulated wisely. Technologists will also find useful lessons learned from the last 120 years of legal grappling with accountability, explainability, and biased data.",
        "DOI": "10.1007/978-3-030-43582-0",
        "paper_author": "Grant T.D.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Hindu kush-himalaya watersheds downhill: Landscape ecology and conservation perspectives",
        "publication": "Hindu Kush-Himalaya Watersheds Downhill: Landscape Ecology and Conservation Perspectives",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "This book describes the myriad components of the Hindu Kush-Himalaya (HKH) region. The contributors elaborate on challenges, failures, and successes in efforts to conserve the HKH, its indigenous plants and animals, and the watershed that runs from the very roof of the planet via world-rivers to marine estuaries, supporting a human population of some two billion people. Readers will learn how the landforms, animal species and humans of this globally fascinating region are connected, and understand why runoff from snow and ice in the world’s tallest mountains is vital to inhabitants far downstream. The book comprises forty-five chapters organized in five parts. The first section, Landscapes, introduces the mountainous watersheds of the HKH, its weather systems, forests, and the 18 major rivers whose headwaters are here. The second part explores concepts, cultures, and religions, including ethnobiology and indigenous regimes, two thousand years of religious tradition, and the history of scientific and research expeditions. Part Three discusses policy, wildlife conservation management, habitat and biodiversity data, as well as the interaction of animals and humans. The fourth part examines the consequences of development and globalization, from hydrodams, to roads and railroads, to poaching and illegal wildlife trade. This section includes studies of animal species including river dolphins, woodpeckers and hornbills, langurs, snow leopards and more. The concluding section offers perspectives and templates for conservation, sustainability and stability in the HKH, including citizen-science projects and a future challenged by climate change, growing human population, and global conservation decay. A large assemblage of field and landscape photos, combined with eye-witness accounts, presents a 50-year local and wider perspective on the HKH. Also included are advanced digital topics: data sharing, open access, metadata, web portal databases, geographic information systems (GIS) software and machine learning, and data mining concepts all relevant to a modern scientific understanding and sustainable management of the Hindu Kush-Himalaya region. This work is written for scholars, landscape ecologists, naturalists and researchers alike, and it can be especially well-suited for those readers who want to learn in a more holistic fashion about the latest conservation issues.",
        "DOI": "10.1007/978-3-030-36275-1",
        "paper_author": "Regmi G.R.",
        "affiliation_name": "Third Pole Conservancy",
        "affiliation_city": "Kathmandu",
        "affiliation_country": "Nepal",
        "affiliation_id": "123611893",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Preserving Privacy in Multimedia Social Networks Using Machine Learning Anomaly Detection",
        "publication": "Security and Communication Networks",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "Nowadays, user's privacy is a critical matter in multimedia social networks. However, traditional machine learning anomaly detection techniques that rely on user's log files and behavioral patterns are not sufficient to preserve it. Hence, the social network security should have multiple security measures to take into account additional information to protect user's data. More precisely, access control models could complement machine learning algorithms in the process of privacy preservation. The models could use further information derived from the user's profiles to detect anomalous users. In this paper, we implement a privacy preservation algorithm that incorporates supervised and unsupervised machine learning anomaly detection techniques with access control models. Due to the rich and fine-grained policies, our control model continuously updates the list of attributes used to classify users. It has been successfully tested on real datasets, with over 95% accuracy using Bayesian classifier, and 95.53% on receiver operating characteristic curve using deep neural networks and long short-term memory recurrent neural network classifiers. Experimental results show that this approach outperforms other detection techniques such as support vector machine, isolation forest, principal component analysis, and Kolmogorov-Smirnov test.",
        "DOI": "10.1155/2020/5874935",
        "paper_author": "Aljably R.",
        "affiliation_name": "Shaqra University",
        "affiliation_city": "Shaqra",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60110524",
        "affiliation_state": "Ar Riyad"
    },
    {
        "paper_title": "Why is Internet of Autonomous Vehicles not as Plug and Play as We Think ? Lessons to Be Learnt from Present Internet and Future Directions",
        "publication": "IEEE Access",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "The recent race for autonomous or 'driverless' vehicles, has spawned a lot of research in the area of Internet of Autonomous Vehicles (IAVs). With the advent of the latest technology fueled by Artificial Intelligence and Machine Learning, Autonomous Vehicles (AVs) can now determine the best possible route to a destination based on the current traffic situation and take dynamic driving decisions accordingly, while preventing accidents. Field trials for single autonomous vehicles have been largely successful. However, as more autonomous vehicles will be added to the intelligent transport networks, current research is now centered around their synergistic coexistence in the offering of network-centric and user-centric services. This development is governed by borrowing several concepts from the legacy Internet to address the problems of IAVs. In this paper, we present an extensive overview of the research challenges in the IAVs. Moreover, our contributions in this paper are that (i) We show how the network-oriented cooperative client-server model will give way to a more unorthodox and 'selfish' decentralized and peer-to-peer (P2P) model, for example in the offering of navigation services on the IAV. (ii) We discuss how centralized architecture will give way to more distributed architectures for real-time information propagation over the IAV. (iii) We discuss how network-centric policies will begin to shift to user-centric under more beneficial revenue models by offering network-assisted quality of service (QoS) provisioning. (iv) We discuss in detail how vehicle traffic grooming in the IAV would present as much of a challenge as in the legacy Internet. (v) We discuss the disruptive role of value-added services on the IAV, and (iv) Finally, we discuss the problem of cyber threats in the IAV just as in the legacy Internet.",
        "DOI": "10.1109/ACCESS.2020.3009336",
        "paper_author": "Qazi S.",
        "affiliation_name": "Karachi Institute of Economics and Technology",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60166769",
        "affiliation_state": "Sindh"
    },
    {
        "paper_title": "Adversarial attacks and countermeasures against ML models in army multi-domain operations",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "To systematically understand the effects of vulnerabilities introduced by AI/ML-enabled Army Multi-domain Operations, we provide an overview of characterization of ML attacks with an emphasis on black-box vs. white-box attacks. We then study a system and attack model for Army MDO applications and services, and introduce the roles of stakeholders in this system. We show, in various attack scenarios and under different knowledges of the deployed system, how peer adversaries can employ deceptive techniques to defeat algorithms, and how the system should be designed to minimize the attacks. We demonstrate the feasibility of our approach in a cyber threat intelligence use case. We conclude with a path forward for design and policy recommendations for robust and secure deployment of AI/ML applications in Army MDO environments.",
        "DOI": "10.1117/12.2548798",
        "paper_author": "Savas O.",
        "affiliation_name": "Accenture Technology Labs",
        "affiliation_city": "Arlington",
        "affiliation_country": "United States",
        "affiliation_id": "113521361",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications II",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 61 papers. The topics discussed include: policy based ensembles for multi domain operations; special datasets for training learning algorithms; achieving a trusted, reliable, AI-ready infrastructure for military medicine and civilian care; reasoning with small data samples for organized crime; repairing highly corrupted speech and images with U-net autoencoders; few-shot learning for defense and security; routing of an unmanned vehicle for classification; securing autonomous systems in multi-domain tactical environment; comparison of skeleton models and classification accuracy for posture-based threat assessment using deep-learning; and machine learning based automatic threat level assessment in fiber-optic distributed acoustic sensing (DAS) intrusion detection system.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Policy-based ensembles for multi domain operations",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "In multi-domain operations, different domains get different modalities of input signals, and as a result end up training different models for the same decision-making task. The input modalities could be overlapping with each other, which leads to the situation that models created in one domain may be reusable partially for tasks being conducted in other domains. In order to share the knowledge embedded in different models trained independently in each individual domain, we propose the concept of hybrid policy-based ensembles, in which the heterogeneous models from different domains are combined into an ensemble whose operations are controlled by policies specifying which subset of the models ought to be used for an operation. We show how these policies can expressed based on properties of training datasets, and discuss the performance of these hybrid policy-based ensembles on a dataset used for training network intrusion detection models.",
        "DOI": "10.1117/12.2558727",
        "paper_author": "Verma D.C.",
        "affiliation_name": "IBM Thomas J. Watson Research Center",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States",
        "affiliation_id": "60017366",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Mining conversation data for reward estimation in dialog policy learning",
        "publication": "Proceedings of the 24th Pacific Asia Conference on Information Systems: Information Systems (IS) for the Future, PACIS 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement Learning approaches are commonly used for dialog policy learning. Reward function is an important part of RL algorithms which affects the training and quality of the policy. Handcrafted reward functions have been replaced by machine-learned reward functions in recent approaches with promising results. Such reward models compare agent actions with human actions, more human-like agent actions receive higher rewards. Reward models so far consider only the latest dialog turn when computing reward for agent action. In this paper, we hypothesize that using a sequence of turns to decide next agent action is more beneficial. Towards this claim we mine for common patterns in human-human task-oriented dialog data. The experiment results suggest that there are obvious patterns i.e., human-human communication in task-oriented dialogs follows some common sequences of actions. Such patterns can be potentially incorporated into reward models to train agents that could better imitate human behaviors.",
        "DOI": "NA",
        "paper_author": "Nguyen A.D.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Machine learning for attribution of heat and drought in Southwestern Australia",
        "publication": "Procedia Computer Science",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Temperature and precipitation datasets, extending back over 100 years, are analyzed at Perth, Australia. Observational analyses reveal the emergence of hot and dry years since the 1980s, with changes in maximum temperatures ~1.5-2 ?C above historical means. These temperatures far exceed recorded natural variability measured in the early 20th century and, in the past few decades, have accelerated above the danger threshold established in the Paris Accords. Permutation testing of mean Perth temperature (precipitation) for the 20-year periods 1979-1998 and 1999-2018 shows an increase (decrease) of 0.855 ?C (98.1 mm); p-value 0.001 (0.0087). Attribution of interannual data variability is established by wavelet analyses. Linear and support vector regression (LR, SVR), neural network (NN) and random forests (RF) are used for temperature and precipitation prediction after attribute selection methods are applied to a set of climate drivers. Forecasts on independent testing data show that for temperature and precipitation forecasts, SVR, LR and NN (temperature only) provide more accurate predictions than RF. The features selected by attribute selection and machine learning provide important guidance for climate forecasting, policy planning and management.",
        "DOI": "10.1016/j.procs.2020.02.244",
        "paper_author": "Richman M.B.",
        "affiliation_name": "The University of Oklahoma",
        "affiliation_city": "Norman",
        "affiliation_country": "United States",
        "affiliation_id": "60030931",
        "affiliation_state": "OK"
    },
    {
        "paper_title": "Forecasting CDS Term Structure Based on Nelson-Siegel Model and Machine Learning",
        "publication": "Complexity",
        "citied_by": "13",
        "cover_date": "2020-01-01",
        "Abstract": "In this study, we analyze the term structure of credit default swaps (CDSs) and predict future term structures using the Nelson-Siegel model, recurrent neural network (RNN), support vector regression (SVR), long short-term memory (LSTM), and group method of data handling (GMDH) using CDS term structure data from 2008 to 2019. Furthermore, we evaluate the change in the forecasting performance of the models through a subperiod analysis. According to the empirical results, we confirm that the Nelson-Siegel model can be used to predict not only the interest rate term structure but also the CDS term structure. Additionally, we demonstrate that machine-learning models, namely, SVR, RNN, LSTM, and GMDH, outperform the model-driven methods (in this case, the Nelson-Siegel model). Among the machine learning approaches, GMDH demonstrates the best performance in forecasting the CDS term structure. According to the subperiod analysis, the performance of all models was inconsistent with the data period. All the models were less predictable in highly volatile data periods than in less volatile periods. This study will enable traders and policymakers to invest efficiently and make policy decisions based on the current and future risk factors of a company or country.",
        "DOI": "10.1155/2020/2518283",
        "paper_author": "Kim W.J.",
        "affiliation_name": "Pohang University of Science and Technology",
        "affiliation_city": "Pohang",
        "affiliation_country": "South Korea",
        "affiliation_id": "60032330",
        "affiliation_state": "Gyeongsangbuk-do"
    },
    {
        "paper_title": "Indonesian rupiah exchange rate in facing COVID-19 (A time series-machine learning approach)",
        "publication": "Journal of Advanced Research in Dynamical and Control Systems",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Nowadays, the world is currently facing COVID-19 health issues. In addition to the risk of health problems, this pandemic has also disrupted the global economy. The exchange rate of Rupiah also devalued during the COVID 19 outbreak. The interventions from the government to reduce the spread of COVID-19 have impacted the Rupiah exchange rate too. This study tries to use the most appropriate forecasting method to predict further values of the Rupiah exchange rate. The aim of this research is to look for the most useful method of predicting the Rupiah exchange rate, which can be used to capture various data patterns caused by the COVID-19 pandemic. The methods that will be involved in this research are Long Short Term Memory (LSTM), NNAR (Neural Network Auto-Regressive), Extreme Learning Machine, and Support Vector Machine. The result is that the LSTM model is the best prediction method for predicting an exchange rate from Rupiah that can allow long-term dependency. This model shows that although there were no COVID-19 events based on the model formed, it was predicted that the rupiah would decline in value against the US dollar. The COVID-19 case made the depreciation of the rupiah currency far greater than predicted. The declining growth of Covid-19 cases in Indonesia, accompanied by the Indonesian government's policy on large-scale social restrictions (Bahasa: PSBB), appears to have managed to increase the value of the rupiah against the US dollar.",
        "DOI": "10.5373/JARDCS/V12I6/S20201103",
        "paper_author": "Zahroh S.",
        "affiliation_name": "Faculty of Mathematics and Natural Sciences",
        "affiliation_city": "Semarang",
        "affiliation_country": "Indonesia",
        "affiliation_id": "122536007",
        "affiliation_state": "OK"
    },
    {
        "paper_title": "Learning to communicate proactively in human-agent teaming",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Artificially intelligent agents increasingly collaborate with humans in human-agent teams. Timely proactive sharing of relevant information within the team contributes to the overall team performance. This paper presents a machine learning approach to proactive communication in AI-agents using contextual factors. Proactive communication was learned in two consecutive experimental steps: (a) multi-agent team simulations to learn effective communicative behaviors, and (b) human-agent team experiments to refine communication suitable for a human team member. Results consist of proactive communication policies for communicating both beliefs and goals within human-agent teams. Agents learned to use minimal communication to improve team performance in simulation, while they learned more specific socially desirable behaviors in the human-agent team experiment.",
        "DOI": "10.1007/978-3-030-51999-5_20",
        "paper_author": "van Zoelen E.M.",
        "affiliation_name": "Nederlandse Organisatie voor toegepast natuurwetenschappelijk onderzoek- TNO",
        "affiliation_city": "The Hague",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60019984",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Model-driven ml-ops for intelligent enterprise applications: vision, approaches and challenges",
        "publication": "Lecture Notes in Business Information Processing",
        "citied_by": "19",
        "cover_date": "2020-01-01",
        "Abstract": "This paper explores a novel vision for the disciplined, repeatable, and transparent model-driven development and Machine-Learning operations (ML-Ops) of intelligent enterprise applications. The proposed framework treats model abstractions of AI/ML models (named AI/ML Blueprints) as first-class citizens and promotes end-to-end transparency and portability from raw data detection- to model verification, and, policy-driven model management. This framework is grounded on the intelligent Application Architecture (iA2) and entails a first attempt to incorporate requirements stemming from (more) intelligent enterprise applications into a logically-structured architecture. The logical separation is grounded on the need to enact MLOps and logically separate basic data manipulation requirements (data-processing layer), from more advanced functionality needed to instrument applications with intelligence (data intelligence layer), and continuous deployment, testing and monitoring of intelligent application (knowledge-driven application layer). Finally, the paper sets out exploring a foundational metamodel underpinning blueprint-model-driven MLOps for iA2 applications, and presents its main findings and open research agenda.",
        "DOI": "10.1007/978-3-030-52306-0_11",
        "paper_author": "van den Heuvel W.J.",
        "affiliation_name": "Tilburg University",
        "affiliation_city": "Tilburg",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60017145",
        "affiliation_state": "Noord-Brabant"
    },
    {
        "paper_title": "5th International Conference on Information Systems Security and Privacy, ICISSP 2019",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 19 papers. The special focus in this conference is on Information Systems Security and Privacy. The topics include: Protection of User-Defined Sensitive Attributes on Online Social Networks Against Attribute Inference Attack via Adversarial Data Mining; user Behavioral Biometrics and Machine Learning Towards Improving User Authentication in Smartphones; threat Modeling and Attack Simulations of Connected Vehicles: Proof of Concept; the Security of the Speech Interface: A Modelling Framework and Proposals for New Defence Mechanisms; hypervisor Memory Introspection and Hypervisor Based Malware Honeypot; Guidelines and Tool Support for Building a Cybersecurity Awareness Program for SMEs; analysing the Provenance of IoT Data; improving Interoperability in Multi-domain Enterprise Right Management Applications; fine-Grained Access Control for Querying Over Encrypted Document-Oriented Database; next Generation Information Warfare: Rationales, Scenarios, Threats, and Open Issues; information Technology Consulting Firms’ Readiness for Managing Information Security Incidents; Evaluation of Side-Channel Key-Recovery Attacks on LoRaWAN End-Device; black-Box Attacks via the Speech Interface Using Linguistically Crafted Input; proposal and Performance Evaluation of an Order-Specified Aggregate Authority-Transfer Signature; context-Aware Software-Defined Networking for Automated Incident Response in Industrial Networks; Transparency Enhancing Tools and the GDPR: Do They Match?; user Study of the Effectiveness of a Privacy Policy Summarization Tool.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning based risk-adaptive access control system to identify genuineness of the requester",
        "publication": "Studies in Computational Intelligence",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "Data access can be controlled in a static manner using role based or policy based access control. These access control systems can easily handle situations in structured databases. In today’s era of big data where lot of research work is done in storing huge and unstructured data, there is still a big gap in providing data access security. There are many real world applications where static access control systems are not effective, such as defense, airport surveillance and hospital management system. There is a need for a system which learns and adapts according to the genuineness of the requester. Existing role based access control methodology easily attracts intruders. The main drawback of policy based access control is lack of adaptability as the policy decided initially cannot be changed dynamically. Proposed risk adaptive access control is a framework which, understands the genuineness of the requester, calculates the risk and then acts accordingly. This framework considers many real world attributes in its design, such as time of access, location of access, previous history of the requester (how many times the same request is been asked by the requester) and sensitivity of information which is requested. The system will sense the situation (emergency or normal) and learns from the past history. It calculates a risk score and based on the risk score access is provided. We have tested accuracy of the system as well as false negative which ensures that the framework is adaptable.",
        "DOI": "10.1007/978-3-030-38445-6_10",
        "paper_author": "Srivastava K.",
        "affiliation_name": "Dwarkadas Jivanlal Sanghvi College of Engineering",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60114754",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Hybrid blockchain-enabled secure microservices fabric for decentralized multi-domain avionics systems",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Advancement in artificial intelligence (AI) and machine learning (ML), dynamic data driven application systems (DDDAS), and hierarchical cloud-fog-edge computing paradigm provide opportunities for enhancing multi-domain systems performance. As one example that represents multi-domain scenario, a \"fly-by-feel\" system utilizes DDDAS framework to support autonomous operations and improve maneuverability, safety and fuel efficiency. The DDDAS \"fly-by-feel\" avionics system can enhance multi-domain coordination to support domain specific operations. However, conventional enabling technologies rely on a centralized manner for data aggregation, sharing and security policy enforcement, and it incurs critical issues related to bottleneck of performance, data provenance and consistency. Inspired by the containerized microservices and blockchain technology, this paper introduces BLEM, a hybrid BLockchain-Enabled secure Microservices fabric to support decentralized, secure and efficient data fusion.",
        "DOI": "10.1117/12.2559036",
        "paper_author": "Xu R.",
        "affiliation_name": "Binghamton University State University of New York",
        "affiliation_city": "Binghamton",
        "affiliation_country": "United States",
        "affiliation_id": "60020273",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Predicting number of hospital appointments when no data is available",
        "publication": "International Journal of Advanced Computer Science and Applications",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Usually, in a hospital, the data generated by each department or section is treated in isolation, believing that there is no relationship between them. It is thought that while one department is in high demand, it can not influence that another may have the same demand or not have any demand. In this paper, we question this approach by considering information from departments as components of a large system in the hospital. Thus, we present an algorithm to predict the appointments of departments when data is not available using data from other departments. This algorithm uses a model based on multiple linear regression using a correlation matrix to measure the relationship between the departments with different time windows. After running our algorithm for different time windows and departments, we experimentally find that while we increase the extension of a time window and learn dependencies in the data, its corresponding precision decreases. Indeed, a month of data is the minimum sweet spot to leverage information from other departments and still provide accurate predictions. These results are important to develop per-department health policies under limited data, an interesting problem that we plan to investigate in future works.",
        "DOI": "10.14569/IJACSA.2020.0110681",
        "paper_author": "Cáceres H.",
        "affiliation_name": "Universidad Nacional de San Agustin de Arequipa",
        "affiliation_city": "Arequipa",
        "affiliation_country": "Peru",
        "affiliation_id": "60089535",
        "affiliation_state": "Arequipa"
    },
    {
        "paper_title": "Predicting landslide susceptibility and risks using GIS-based machine learning simulations, case of upper Nyabarongo catchment",
        "publication": "Geomatics, Natural Hazards and Risk",
        "citied_by": "46",
        "cover_date": "2020-01-01",
        "Abstract": "Sustainable landslide mitigation requires appropriate approaches to predict susceptible zones. This study compared the performance of Logistic Model Tree (LMT), Random Forest (RF) and Naïve-Bayes Tree (NBT) in predicting landslide susceptibility for the upper Nyabarongo catchment (Rwanda). 196 past landslides were mapped using field investigations. Thus, the inventory map was split into training and testing datasets. Fifteen predisposing factors were analysed and information gain (IG) technique was used to analyse the correlation between factors and observed landslides. Therefore, the area under receiver operating characteristic (AUROC) with other statistical estimators including accuracy, precision, and root mean square error (RMSE) were employed to compare the models. The AUC values were 78.7%, 80.9% and 82.4% for RF, LMT and NBT models, respectively. Additionally, the NBT produced the highest accuracy and precision values (0.799 and 0.745, respectively). Regarding RMSE values, the NBT model achieved an optimized prediction than RF and LMT models (0.301; 0.428 and 0.364, respectively). The results of the current study may inform further studies and appropriate landslide risk reduction and mitigation measures. They can also be instrumental for policy and decision making in regards with natural risk management.",
        "DOI": "10.1080/19475705.2020.1785555",
        "paper_author": "Nsengiyumva J.B.",
        "affiliation_name": "Institute of Policy Analysis and Research",
        "affiliation_city": "Kigali",
        "affiliation_country": "Rwanda",
        "affiliation_id": "114086183",
        "affiliation_state": "Kigali"
    },
    {
        "paper_title": "Prediction of Protein-Protein Interactions with Local Weight-Sharing Mechanism in Deep Learning",
        "publication": "BioMed Research International",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "Protein-protein interactions (PPIs) are important for almost all cellular processes, including metabolic cycles, DNA transcription and replication, and signaling cascades. The experimental methods for identifying PPIs are always time-consuming and expensive. Therefore, it is important to develop computational approaches for predicting PPIs. In this paper, an improved model is proposed to use a machine learning method in the study of protein-protein interactions. With the consideration of the factors affecting the prediction of the PPIs, a method of feature extraction and fusion is proposed to improve the variety of the features to be considered in the prediction. Besides, with the consideration of the effect affected by the different input order of the two proteins, we propose a \"Y-type\"Bi-RNN model and train the network by using a method which both needs backward and forward training. In order to insure the training time caused on the extra training either a backward one or a forward one, this paper proposes a weight-sharing policy to minimize the parameters in the training. The experimental results show that the proposed method can achieve an accuracy of 99.57%, recall of 99.36%, sensitivity of 99.76%, precision of 99.74%, MCC of 99.14%, and AUC of 99.56% under the benchmark dataset.",
        "DOI": "10.1155/2020/5072520",
        "paper_author": "Yang L.",
        "affiliation_name": "Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60031863",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Dynamic pricing of product clusters: A multi-agent reinforcement learning approach",
        "publication": "27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Retailers sell a multitude of products which are interrelated to each other. However, often the strategies to price products neither consider these dependencies nor changing market conditions, resulting in inefficient price setting. The objective of this study is to investigate whether a system of multiple agents, each representing a single product, combined with a machine learning approach can optimize pricing strategies. To achieve this objective, a design science research approach is used to implement a multi-agent reinforcement learning (MARL) system that learns a pricing policy for a product cluster and aims on maximizing the cluster's total profits by optimizing the prices of products dynamically. Six market simulation scenarios with predetermined market events were used to evaluate the MARL system in comparison to static pricing strategies and single-agent approaches. In all six scenarios, the MARL system leads to increasing profits: The daily average profits were 7.8% higher in comparison to the static pricing strategy and even 27% higher in comparison with a single-agent approach. The results indicate that retailers can gain a significant competitive advantage by considering product clusters and utilize ML algorithms to implement dynamic pricing strategies.",
        "DOI": "NA",
        "paper_author": "Kropp L.A.",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Self-supervised learning based anomaly detection in online social media",
        "publication": "International Journal of Intelligent Engineering and Systems",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Online Social Media (OSM) produce enormous data related to the human behaviours based on their interactions. One such data is the opinions expressed and posted for any specific issue addressed in the OSM. Majority of the opinions posted would be categorized as positive, negative and neutral. The lighter group's opinions are termed anomalous as it is not conforming the regular opinions posted by other users. Though, lot of conventional classification and clustering based learning algorithms works well under supervised and un-supervised environment, due to the inherent ambiguity in the tweeted data, anomaly detection poses a bigger challenge in text mining. Though the data is un-supervised, for the learning purpose it is treated as Supervised Learning by assigning class labels for the training data. This paper attempts to give an insight into various anomalies of OSM and identify behavioural anomalies for a Twitter Dataset on user's opinions on demonetization policy in India. Through Self-Supervised learning, it is observed that 86% of the user's opinions did agree to the demonetization policy and the remaining have posted negative opinions for the policy implemented.",
        "DOI": "10.22266/IJIES2020.0630.40",
        "paper_author": "Kokatnoor S.A.",
        "affiliation_name": "Christ University",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60106812",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Mapping summer soybean and corn with remote sensing on Google Earth Engine cloud computing in Parana state–Brazil",
        "publication": "International Journal of Digital Earth",
        "citied_by": "22",
        "cover_date": "2020-01-01",
        "Abstract": "Brazilian farming influences directly the worldwide economy. Thus, fast and reliable information on areas sown with the main crops is essential for planning logistics and public or private commodity market policies. Recent farming practices have embraced remote sensing to provide fast and reliable information on commodity dynamics. Medium-to-low resolution free orbital images, such as those from Landsat 8 and Sentinel 2, have been used for crop mapping; however, satellite image processing requires high computing power, especially when monitoring vast areas. Therefore, cloud data processing has been the only feasible option to deal with a large amount of orbital data and its processing and analysis. Thus, our goal was to develop a method to map the two main crops (soybeans and corn) in Paraná, one of the major Brazilian state producers. Landsat-8, Sentinel-2, SRTM+, and field data from 2016 to 2018 were used with the Simple Non-Iterative Clustering segmentation method and the Continuous Naive Bayes classifier, to identify cropped areas. A minimum global accuracy of 90% was found for both crops. Comparison with field data showed correlations of 0.96 and agreement coefficients no lower than 0.86. This ensures mapping quality when using Sentinel and/or Landsat imagery on the GEE platform.",
        "DOI": "10.1080/17538947.2020.1772893",
        "paper_author": "Paludo A.",
        "affiliation_name": "Universidade Estadual do Oeste do Paraná",
        "affiliation_city": "Cascavel",
        "affiliation_country": "Brazil",
        "affiliation_id": "60005993",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "Estimation of turkey’s natural gas consumption by machine learning techniques",
        "publication": "Gazi University Journal of Science",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Technological advancements coupled with growing world population require the increasing need of energy. Natural gas is one of the most important usable energy resources. Turkey is with high external dependency on energy as it has its own limited natural and underground energy resources. Thus, in order to effectively and productively use of natural gas purchased from foreign countries and to make reliable and robust energy policies for the years ahead, it is crucial to make a reasonable and plausible prediction for natural gas consumption of Turkey. In this paper, we estimate the natural gas consumption using machine learning techniques on the basis of real monthly data representing natural gas consumption of Turkey between the years 2010 and 2018. The performances of machine learning techniques involving Artificial Neural Networks, Random Forest Tree, Regression, Time Series and Multiple Seasonality Time Series are compared in predicting the natural gas consumption of Turkey. Experimental results show that among the five techniques, artificial neural networks produce the best estimation, having the lowest mean square errors, followed by regression method. Time series shows the worst performance among all the techniques.",
        "DOI": "10.35378/gujs.586107",
        "paper_author": "Erdem O.E.",
        "affiliation_name": "Konya Technical University",
        "affiliation_city": "Konya",
        "affiliation_country": "Turkey",
        "affiliation_id": "60193845",
        "affiliation_state": "Konya"
    },
    {
        "paper_title": "Table-to-Dialog: Building Dialog Assistants to Chat with People on Behalf of You",
        "publication": "IEEE Access",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Artificial Intelligence (AI) personal assistant has attracted much attention from both academia and industry. Almost all existing AI personal assistants serve as service terminals to chat with human users for certain tasks. We are instead interested in building AI personal assistants for a different yet important dialog scenario, where they chat with people to fulfill specific tasks on behalf of their human users. As the personal assistants are playing a requester role, instead of a service terminal role, the conversation goal becomes delivering or requesting information according to specific user requests precisely and efficiently. The challenge for the conversation policy is that all user requests must be delivered precisely, while the challenge for the response generation is that it's generally expected for machine generated responses to cover multiple information slots, either requesting or delivering, to make the conversation efficient. In this paper, we present Table-to-Dialogue, a novel approach to address the above challenges when building a requester role AI personal assistant. We employ an encoder-decoder network to learn explicit conversation policy, which generates the corresponding information slots based on the conversation context and the user request table. We further integrate a novel Multi-Slot Constrained Bi-directional Decoder (MS-CBD) into the above encoder-decoder network, to generate machine response according to the multiple slot values and their intermediate representations from the policy decoder. Different from the existing single direction text decoder approaches, MS-CBD leverage the bi-directional context of the response when generating it to enhance the semantic coherence. The experiments shows that our approach significantly outperform the state-of-the-art conversation approaches on automatic and human evaluation metrics.",
        "DOI": "10.1109/ACCESS.2020.2998432",
        "paper_author": "Haihong E.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Application of machine learning technique for prediction of road accidents in Haryana-A novel approach",
        "publication": "Journal of Intelligent and Fuzzy Systems",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Over the last few years, road accidents in developing countries are increasing at an alarming rate. In India, almost 3% of GDP is getting wasted in road accidents, which not only cause social problems but, also, imposes a huge burden on the Indian economy. Various researches have been done to analyze this situation using different methods and techniques on different stretches and intersections. This paper makes one of the first attempts to develop an Accident Prediction Model (APM) in the Indian State of Haryana. This study describes the procedure for collection and analysis of accident data, as well as the detailed methodology used to develop APMs. The Models were developed using one of the most common algorithms of machine learning i.e. linear regression technique. Results obtained from APM of Haryana State were compared with the results given by some of the highly successful APMs like Smeed's Model, Valli's Model and their comparisons were discussed to find the most efficient model. It was observed that the proposed model shows highly accurate results in predicting road accidents in Haryana. The output of this work can be used for theoretical as well as practical applications like road safety management for improving existing conditions of the road network in Haryana and to regulate new traffic safety policies in the future.",
        "DOI": "10.3233/JIFS-179742",
        "paper_author": "Mor N.",
        "affiliation_name": "National Institute of Technical Teachers Training &amp; Research",
        "affiliation_city": "Chandigarh",
        "affiliation_country": "India",
        "affiliation_id": "60101560",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Malicious Domain Detection Using Machine Learning on Domain Name Features, Host-Based Features and Web-Based Features",
        "publication": "Procedia Computer Science",
        "citied_by": "36",
        "cover_date": "2020-01-01",
        "Abstract": "Internet has plenty of vulnerabilities which are exploited by cyber criminals to send spam, commit financial frauds, perform phishing, indulge in command & control, disseminate malware and other malicious activities. Many times these exploits are carried out through malicious domain names which are the vital part of an Internet resource URL. Few vulnerabilities in the Internet setup and its related administrative policies allows such malicious domain names to be registered with the DNS servers. Though blacklisting happens to be the simplest and quickest solution to identify such malicious domains, the technique cannot cope up with the speed at which the domain names are generated and registered, and hence we look forward for other effective means of identifying malicious domains. The researchers have been using features from DNS data and features from lexical analysis of domain names, but there exists a need to identify more related features and introduce machine-learning to meet challenges due to IP flux and domain flux. In this paper, we have introduced usage of web-based features of domain names in addition to using blacklists, DNS data and lexical features to identify malicious domains. Using the features extracted from the domain names, we build a classifier model using the logistic regression classification algorithm and use that classifier to identify benign and malicious domains. Our experiment is based on active DNS analysis and we look forward to take this work for passive DNS analysis.",
        "DOI": "10.1016/j.procs.2020.04.071",
        "paper_author": "Palaniappan G.",
        "affiliation_name": "C-DAC",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "122718589",
        "affiliation_state": "TG"
    },
    {
        "paper_title": "Learning Adaptable Approach to Classify Sentiment with Incremental Datasets.",
        "publication": "Procedia Computer Science",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Identification of sentiment type is considered as a new business tool for the market and its policies, which involves different learning algorithms. Capability to automatically increase performance from experience and learning through data is the concept behind learning algorithms, which often requires large amount of data to train a model. The aim of this article is to find an adaptable classifier with increasing size of dataset. The experiment starts with splitting a dataset of size 10000 samples into multiple sub-set to check performance of different classifiers using term frequency-inverse document frequency (TF-IDF) and count vectorizer (CV) feature extraction techniques. The classifiers are train with sub-set of dataset and their adaptability performance was analyzed. Support vector machine (SVM) and logistic regression (LR) obtained stable and incremental performance with increase in dataset size using CV. Multinomial naive bayes (MNB) outperformed well with TF-IDF. We also analysed of classifiers with respect to performance, feature extraction techniques and data-set size.",
        "DOI": "10.1016/j.procs.2020.04.262",
        "paper_author": "Devi M.D.",
        "affiliation_name": "Indian Institute of Information Technology Manipur",
        "affiliation_city": "Imphal",
        "affiliation_country": "India",
        "affiliation_id": "60283054",
        "affiliation_state": "MN"
    },
    {
        "paper_title": "Which policies matter? Using emphases in the legislative agenda to measure salience",
        "publication": "Revista Brasileira de Ciencias Sociais",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "What are the most emphasized themes in the Brazilian legislative agenda? This article explores the thematic emphases based on the classification of legislative proposals in the Brazilian Chamber of Deputies between 1995 and 2014. The aim is to present a specific and comprehensive classification to identify emphases differences and describe which are the most prioritized themes, by whom and how they vary over time. I present a classification on legislative agenda topics carried out using unsupervised machine learning. The salience measure is constructed based on the number of initiatives proposed by each actor on a given theme over time. The research contributes to the debate by offering a measure of salience for the main political actors over time, which can be applied in a range of assessments, from the Executive-Legislative relationship to National Congress clashes of interests.",
        "DOI": "10.1590/3510411/2020",
        "paper_author": "Batista M.",
        "affiliation_name": "Universidade Federal de Pernambuco",
        "affiliation_city": "Recife",
        "affiliation_country": "Brazil",
        "affiliation_id": "60031482",
        "affiliation_state": "PE"
    },
    {
        "paper_title": "Mining and Analysis of Air Quality Data to Aid Climate Change",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "The data science and AI community has gathered around the world to support tackling the climate change problem in different domains. This research aims to work on the air quality through emissions and pollutant concentration data along with vegetation information. Authorities especially in urban cities like London have been very vigilant in monitoring these different aspects of air quality and reliable sources of big data are available in this domain. This study aims to mine and collate this information spread all over the place in different formats into usable knowledge base on which further data analysis and powerful Machine Learning approaches can be built to extract strong evidences useful in building better policies around climate change.",
        "DOI": "10.1007/978-3-030-49190-1_21",
        "paper_author": "Babu Saheer L.",
        "affiliation_name": "Anglia Ruskin University",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60000913",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "16th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2020",
        "publication": "IFIP Advances in Information and Communication Technology",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 75 papers. The special focus in this conference is on Artificial Intelligence Applications and Innovations. The topics include: Manifold learning for innovation funding: Identification of potential funding recipients; network aggregation to enhance results derived from multiple analytics; PolicyCLOUD: Analytics as a service facilitating efficient data-driven public policy management; demand forecasting of short life cycle products using data mining techniques; Arbitrary scale super-resolution for brain MRI images; knowledge-based fusion for image tampering localization; Transfer learning using convolutional neural network architectures for brain tumor classification from MRI images; a novel learning automata-based strategy to generate melodies from chordal inputs; graph neural networks to advance anticancer drug design; Boosted ensemble learning for anomaly detection in 5G RAN; optimizing self-organizing lists-on-lists using transitivity and pursuit-enhanced object partitioning; task-projected hyperdimensional computing for multi-task learning; cross-domain authorship attribution using pre-trained language models; indoor localization with multi-objective selection of Radiomap models; STDP plasticity in TRN within hierarchical spike timing model of visual information processing; Tensor-based CUDA optimization for ANN inferencing using parallel acceleration on embedded GPU; the random neural network in price predictions; joint multi-object detection and segmentation from an untrimmed video; robust 3D detection in traffic scenario with tracking-based coupling system; Automated MeSH indexing of biomedical literature using contextualized word representations; machine learning for cognitive load classification – A case study on contact-free approach; knowledge-based management and reasoning on cultural and natural touristic routes; ontological foundations of modelling security policies for logical analytics; RDF reasoning on large ontologies: A study on cultural heritage and wikidata.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "What technology is needed for future offshore development?",
        "publication": "Proceedings of the Annual Offshore Technology Conference",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Prior to 2007, the U.S. Department of Energy (DOE) upstream oil and gas research program focusedprimarily on onshore applications. In 2000, the DOE published the Offshore Technology Roadmap for theUltra-Deepwater Gulf of Mexico. Then, the Energy Policy Act of 2005 required the DOE to expand itsresearch portfolio to include ultra-deepwater research. DOE has continued this offshore research focus tothe present, and this paper presents an overview of past accomplishments and results, the DOE's currentresearch portfolio, and outlines the potentially key elements of a technology roadmap for the entire OCS. Discussion focuses on key research findings from the DOE ultra-deepwater research portfolio of2007-2013. Then the paper describes the current offshore research portfolio 2014-2019. Finally, thepaper describes the outcomes and insights from key discussions with industry, academia, research and non-government and government stakeholders that could become a frame for a technology research roadmapfor the entire Outer Continental Shelf. DOE research investments in public-private partnerships with industry, academia, research labs, andothers have made an important contribution to the current state-of-the-art in offshore technology-contributions that most people may not realize are tied to previous research investments by DOE. Tracingthese contributions, tracking them back to the Offshore Technology Roadmap for the Ultra-Deepwater Gulfof Mexico published in November 2000, and framing a technology research roadmap for the OCS willdemonstrate the value of public-private partnerships. The information in this paper will both inform and inspire new frontiers of research for the OCS. Asthe USA moves forward with onshore development of unconventional resources, there are features of theDOE onshore research portfolio that may have merit in the OCS. For example, the DOE Field Laboratoryprogram is focused on basin-specific research strategies where new technology can be applied to operatingoilfields and evaluated via the scientific method. Then the data captured can potentially become part offurther research by the DOE National Laboratories including geophysical, geomechanical, geochemical,and data analytics such as machine learning. This DOE program has been very successful onshore, andperhaps there is a place for a comparable multi-disciplinary, multi-partner approach in the OCS.",
        "DOI": "10.4043/30469-ms",
        "paper_author": "Melchert E.S.",
        "affiliation_name": "United States Department of Energy",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60027757",
        "affiliation_state": "DC"
    },
    {
        "paper_title": "19th International Conference on Computer Information Systems and Industrial Management Applications, CISIM 2020",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 40 papers. The special focus in this conference is on Computer Information Systems and Industrial Management Applications. The topics include: Event Ordering Using Graphical Notation for Event-B Models; intraday Patterns in Trading Volume. Evidence from High Frequency Data on the Polish Stock Market; an Efficient Metaheuristic for the Time-Dependent Team Orienteering Problem with Time Windows; measurement and Optimization Models of Risk Management System Usability; development Methodology to Share Vehicles Optimizing the Variability of the Mileage; optimisation Model of Military Simulation System Maintenance; imbalanced Data: Rough Set Methods in Approximation of Minority Classes; run-Time Schedule Adaptation Methods for Sensor Networks Coverage Problem; artificial Intelligence System for Drivers Fatigue Detection; spectral Cluster Maps Versus Spectral Clustering; automatic Marking of Allophone Boundaries in Isolated English Spoken Words; Combined State Splitting and Merging for Implementation of Fast Finite State Machines in FPGA; securing Event Logs with Blockchain for IoT; securing Data of Biotechnological Laboratories Using Blockchain Technology; The Synthesis Method of High-Speed Finite State Machines in FPGA; preface; Transfer Learning Approach in Classification of BCI Motor Imagery Signal; a Framework of Business Intelligence System for Decision Making in Efficiency Management; generalized Approach to Support Business Group Decision-Making by Using of Different Strategies; a Generic Materials and Operations Planning Approach for Inventory Turnover Optimization in the Chemical Industry; evolutionary Adaptation of (r, Q) Inventory Management Policy in Complex Distribution Systems; design of a Decision Support System for Multiobjective Activity Planning and Programming Using Global Bacteria Optimization; representation Learning for Diagnostic Data.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Motivation of participants in crowdsourcing platforms using intelligent agents",
        "publication": "International Journal of Computing",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Crowdsourcing is a model where individuals or organizations receive services from a large group of Internet users including ideas, finances, completing a complex task, etc. Several crowdsourcing websites have failed due to lack of user participation; hence, the success of crowdsourcing platforms is manifested by the mass of user participation. However, an issue of motivating users to participate in crowdsourcing platform stays challenging. We have proposed a new approach, i.e., reinforcement learning-based gamification method to motivate users. Gamification has been a practical approach to engaging users in many fields, but still, it needs an improvement in the Crowdsourcing platform. In this paper, the gamification approach is strengthened by a reinforcement learning algorithm. We have created an intelligent agent using the Reinforcement learning algorithm (Q-learning). This agent suggests an optimal action plan that yields maximum reward points to the users for their active participation in the Crowdsourcing application. Also, its performance is compared with the SARSA algorithm (On-policy learning), which is another Reinforcement learning algorithm.",
        "DOI": "NA",
        "paper_author": "Anand V.",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India",
        "affiliation_id": "60000414",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Spatio-temporal multicomponent optimal learning state estimation of direct numerically simulated turbulent features: A smart sensing approach",
        "publication": "Proceedings of SPIE - The International Society for Optical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Geo-intelligence remote sensing platforms situated over spatially diverse areas are often tasked with geo-intelligence surveillance and adversarial monitoring for military organizations. Limited resources disallow continuous sampling of local areas at the same time, necessitating a need for smart sensing of diverse environments according to a rational evidence-based rule. Such algorithms should not only provide insight into which local region should be focused on, but should also facilitate decisions as to which environmental features should be measured over time once a local site has been selected. Multicomponent optimal learning observational arrays are demonstrated using numerically simulated data of turbulent flow to show not only the feasibility of how individual observational platforms should be chosen in a Bayesian sense, but also how goal state directed sampling of complex systems or turbulent processes over local regions can be accomplished. A Bayesian amalgamation algorithm guides which observational arrays perform knowledge gradient policy based optimal learning to smartly sample observations in local regions. Machine learning and operations research algorithms function as data agnostic, Bayesian processors demonstrating how geo-intelligence information can be efficiently captured to help solve data-driven problems.",
        "DOI": "10.1117/12.2559818",
        "paper_author": "Scott N.V.",
        "affiliation_name": "Open Innovation Center",
        "affiliation_city": "Beavercreek",
        "affiliation_country": "United States",
        "affiliation_id": "124531870",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Simulating the evolution of homeless populations in canada using modified deep Q-Learning (MDQL) and modified neural fitted Q-Iteration (MNFQ) algorithms",
        "publication": "IEEE Access",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "It is estimated that over 235,000 Canadians experience homelessness at some point each year. With the emergence of smart cities, it would be beneficial to leverage the processing power of deep learning to assist in the planning and testing of different policies to address this issue. When examining a population of homeless individuals, one can view them as being distributed, at any one point in time, among several possible states: for example, the street or an emergency shelter. Our work aims to provide a means of simulating across these states, including no longer homeless, over time. The probability that an individual will transition from one state to another is called a transition probability. Thus, by creating a matrix of transition probabilities between all of the states, we have a transition probability matrix. If we simply approached this problem by using a mathematical model such as a Markov decision process, we run into the issue of how to accurately adjust the probabilities to produce realistic results. Ideally, we would have a model that can reasonably modify them based on real-life data. To do this, we introduce two modified deep learning algorithms; modified deep q-learning (MDQL) and modified neural fitted q-iteration (MNFQ). These algorithms dynamically produce a set of transition probability matrices for each week of the year. We discuss the modifications we made to these algorithms to adapt to the homelessness problem and create our simulation. After training our model on high resolution, weekly data, we will show that when running it on a low resolution data set that spans 3 years, our model is able to achieve a relative percent difference from the final population of 12.5%. The end result is a model that can be further improved over time with real world data to provide realistic results.",
        "DOI": "10.1109/ACCESS.2020.2994519",
        "paper_author": "Fisher A.",
        "affiliation_name": "Lakehead University",
        "affiliation_city": "Thunder Bay",
        "affiliation_country": "Canada",
        "affiliation_id": "60025949",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Efficient product representations for automotive demand and capacity management",
        "publication": "Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Motived by the experience with a large online marketplace, we study a middle-mile network design problem in e-commerce. One novel feature in our problem is that while we decide the network configuration, the network flow and shortfall are controlled by the fulfillment policy employed by a different decision entity and are unknown. We develop a predictive model for the unknown response using observed shipment data. In particular, we apply the idea of decomposition in developing the predictive model. The predictive model is then embedded in the network design. To solve this problem, we characterize it as a c-supermodular minimization problem and propose two linear time approximation algorithms. In a numerical study, we demonstrate that these two algorithms are scalable and effective.",
        "DOI": "NA",
        "paper_author": "Fruhner D.",
        "affiliation_name": "Fachhochschule Dortmund",
        "affiliation_city": "Dortmund",
        "affiliation_country": "Germany",
        "affiliation_id": "60020120",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Data-driven scalable E-commerce transportation network design with unknown flow response",
        "publication": "Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Motived by the experience with a large online marketplace, we study a middle-mile network design problem in e-commerce. One novel feature in our problem is that while we decide the network configuration, the network flow and shortfall are controlled by the fulfillment policy employed by a different decision entity and are unknown. We develop a predictive model for the unknown response using observed shipment data. In particular, we apply the idea of decomposition in developing the predictive model. The predictive model is then embedded in the network design. To solve this problem, we characterize it as a c-supermodular minimization problem and propose two linear time approximation algorithms. In a numerical study, we demonstrate that these two algorithms are scalable and effective.",
        "DOI": "10.2139/ssrn.3590865",
        "paper_author": "Chen S.",
        "affiliation_name": "Fuqua School of Business",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60116608",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Women onquantitativeboards of philippineexplorationscorporations",
        "publication": "International Journal of Business and Society",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "This inductive study explored the likelihood and correlates of gender diversity in corporate boards in the Philippines. The improvement of gender diversity on boards is of advocacy and policy interest as the country emerges to middle-high income status. Logistic regression analyses from individuals’ (in a directors’ talent pool) responses to an online survey showed that females had a likely odds of 0.10 to be on the boards, compared to males. For every one female getting onto boards, 9 would be unable to. Females with advanced degrees were 7x likely to be on boards than female and male counterparts. The odds of a board seat is significantly likely for individuals in some industries compared to a referent industry (government). At the firm level, controlling other variables in the model, as the size of boards are increased by a unit, the odds of having a woman on board increase 1.3 times. This implies that the likelihood of having a woman board of director rises if the size of boards is raised by a third. Corroboration from text mining technique applied to survey responses showed strong correlation across academic degrees (both bachelor’s and advanced), industry, and job title; pointing that having more women in C-roles increase the odds of increasing their numbers on corporate boards. Gender diversity on boards have been studied largely from the developed economy lens and/or international comparisons. These quantitative explorations showed pathways that can advance not only understanding and support for extant theories (human capital, resource dependence), but also point to further work (institutional, industry) that can provide levers for policy and advocacy, for countries with similar challenges.",
        "DOI": "NA",
        "paper_author": "Bautista M.C.G.",
        "affiliation_name": "Ateneo de Manila University",
        "affiliation_city": "Quezon City",
        "affiliation_country": "Philippines",
        "affiliation_id": "60071457",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Urbanization change analysis based on SVM and RF machine learning algorithms",
        "publication": "International Journal of Advanced Computer Science and Applications",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "To maintain sustainability in the development, measured the yearly change rate of the land through Land Cover classified maps that hold the data which is surveyed as an influential factor for environment management and urbanization. This paper measured the change rate, which is helpful for the management of the city to define the new policy and implement the best one to maintain the natural resources. Machine Learning algorithms are utilized to produce the most acknowledged Land Cover maps using the GEE cloud-based reliable platform using the LANDSAT8 satellite imagery. For the classification used the Random Forest (RF) and Support Vector Machine (SVM) Algorithm. This investigation also found that the Support Vector Machine (SVM) classifier accomplished better over-all accuracy and Kappa coefficient as compared to the Random Forest (RF) classifier while the training sample for both is the same.",
        "DOI": "10.14569/IJACSA.2020.0110573",
        "paper_author": "Hassan F.",
        "affiliation_name": "Air University Islamabad",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60070604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Cross-data Automatic Feature Engineering via Meta-learning and Reinforcement Learning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Feature Engineering (FE) is one of the most beneficial, yet most difficult and time-consuming tasks of machine learning projects, and requires strong expert knowledge. It is thus significant to design generalized ways to perform FE. The primary difficulties arise from the multiform information to consider, the potentially infinite number of possible features and the high computational cost of feature generation and evaluation. We present a framework called Cross-data Automatic Feature Engineering Machine (CAFEM), which formalizes the FE problem as an optimization problem over a Feature Transformation Graph (FTG). CAFEM contains two components: a FE learner (FeL) that learns fine-grained FE strategies on one single dataset by Double Deep Q-learning (DDQN) and a Cross-data Component (CdC) that speeds up FE learning on an unseen dataset by the generalized FE policies learned by Meta-Learning on a collection of datasets. We compare the performance of FeL with several existing state-of-the-art automatic FE techniques on a large collection of datasets. It shows that FeL outperforms existing approaches and is robust on the selection of learning algorithms. Further experiments also show that CdC can not only speed up FE learning but also increase learning performance.",
        "DOI": "10.1007/978-3-030-47426-3_63",
        "paper_author": "Zhang J.",
        "affiliation_name": "Tianjin University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60019533",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Strategy Inference via Real-Time Homeomorphic and Isomorphic Tree Matching of Probabilistic Graphical Models",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In many common gaming and real-world scenarios agents are trying to predict the behavior of the other agents. This assumes that there is some underlying strategy that these players are following, that such strategies can be inferred, and that a reasonable player can counter such strategies in real-time. These strategies can be modeled as various graph structures such as trees, finite state machines (FSMs), or probabilistic graphical models (PGMs). With these models created, one approach to best determine which strategy an agent is following is to match prospective trees, built from observed behaviors or policies, with known trees, representing previously learned strategies and policies. While matching two trees can be done in super-linear time in the small scale, the matching problem quickly becomes NP for the more complicated cases. This leads to a well-known NP-Complete problem (e.g., (Kumar et al. 2011)) when one considers homeomorphic trees (one is a subgraph of the other) and isomorphic trees (the bijection is true (i.e., homeomorphic in both directions)) and their matching. Isomorphic graph matching is much more complex (Vazirani 1989). At scale, most solutions for graph matching utilize highly-parallel processes running on high-performance computing clusters. This is intractable for real-time low-power computer systems. This paper presents an approximation algorithm for tree matching in order to accomplish strategy inference in real-time multi-agent systems.",
        "DOI": "10.1007/978-981-15-4301-2_9",
        "paper_author": "Franklin D.M.",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States",
        "affiliation_id": "60019740",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Pseudo Random Number Generation: A Reinforcement Learning approach",
        "publication": "Procedia Computer Science",
        "citied_by": "27",
        "cover_date": "2020-01-01",
        "Abstract": "Pseudo-Random Numbers Generators (PRNGs) are algorithms produced to generate long sequences of statistically uncorrelated numbers, i.e. Pseudo-Random Numbers (PRNs). These numbers are widely employed in mid-level cryptography and in software applications. Test suites are used to evaluate PRNGs quality by checking statistical properties of the generated sequences. Machine learning techniques are often used to break these generators, i.e. approximating a certain generator or a certain sequence using a neural network. But what about using machine learning to generate PRNs generators? This paper proposes a Reinforcement Learning (RL) approach to the task of generating PRNGs from scratch by learning a policy to solve an N-dimensional navigation problem. In this context, N is the length of the period of the sequence to generate and the policy is iteratively improved using the average score of an appropriate test suite run over that period. Aim of this work is to demonstrate the feasibility of the proposed approach, to compare it with classical methods, to lay the foundation of a research path which combines RL and PRNGs.",
        "DOI": "10.1016/j.procs.2020.03.057",
        "paper_author": "Pasqualini L.",
        "affiliation_name": "Università degli Studi di Siena",
        "affiliation_city": "Siena",
        "affiliation_country": "Italy",
        "affiliation_id": "60002838",
        "affiliation_state": "SI"
    },
    {
        "paper_title": "A Combined Fuzzy Soft Set—Machine Learning Approach for Effective Party Recommendation",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In the recent times Voting Advice Applications (VAAs) have become a widespread online tool for electoral campaigns in Europe. These online tools are designed to suggest voters the best suitable political party that matches their policies. In typical VAAs answers are collected for policy based questions from the candidate/party and also the voter, then these answers are compared and the user is suggested with the party/candidate whose answers matches the most. But there are chances of over promising answers form the party. This paves the way for a collaborative recommendation in VAAs, called Social VAAs (SVAA). In SVAA users are suggested with parties that other similar users prefer. Motivated with the goodness of fuzzy soft sets and various classifiers in the previous work, an approach combining both fuzzy soft set and machine learning is proposed so as to bring together the goodness of both. This paper explains and evaluates the combined approach and is found to perform the preceding methods.",
        "DOI": "10.1007/978-981-15-1420-3_44",
        "paper_author": "Nagarjan S.",
        "affiliation_name": "Mahatma Gandhi University",
        "affiliation_city": "Kottayam",
        "affiliation_country": "India",
        "affiliation_id": "60029694",
        "affiliation_state": "KL"
    },
    {
        "paper_title": "Exploring the Access Control Policies of Web-Based Social Network",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "The usage of the web based social networks is growing day by day. Our daily life has become dependent on the usage of these social networking applications (apps). These apps allow the people of different ages to share their ideas and remain connected to the people they like to connect with through the medium of internet. There are several web based social networking apps such as Instagram, Twitter, LinkedIn, and Facebook. Facebook has experienced the rapid growth in the number of users in last few years. The access control paradigm of Facebook is different from the way it is generally being provided. The access control is mainly defined through: Role based access control, Trust Management System, Discretionary Access Control. Web based social networks offer attractive means for interaction and communication; on the other hand they also raise privacy and security concerns. There are risks related to the privacy of the users attached to the usage of web based social networks as most of the users accept the privacy and access control policies of such apps without understanding the threat associated with the same. We try to explore some of the threats related to the privacy and access control of web based social network that helps the users to keep their profile safe and avoid any type of data breach.",
        "DOI": "10.1007/978-981-15-1420-3_168",
        "paper_author": "Shah K.",
        "affiliation_name": "Parul University",
        "affiliation_city": "Vadodara",
        "affiliation_country": "India",
        "affiliation_id": "60117108",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Role of Technology in Utilizing Water as a Resource for Sustainable Development",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Water plays a vital role in preserving and giving us a quality life, which has an impact on the people in day-to-day activities such as household and other productive purposes. In tribal areas where the resource-settings are limited, implementation of an organized water accessible system has an impact on the health and sanitation related problems. There has been an alarming awareness that is essential, to have a public water distribution system possessing a high service reliability among the policy makers in the health centers as well as various higher authorities which implement various programs through organizations which help to facilitate basic requirements of the people in tribal areas. A qualitative study was conducted in Barapita village in the Khordha district of Odisha. The interviews conducted were analyzed using Participatory Rural Appraisal (PRA) tools, AEIOU frameworks, personas and direct observation using the six senses. The cardinal problem statement identified is the lack of any water distribution plan in the village, despite being in the vicinity of one of the largest dams in Odisha (DERAS). The perceptions and experiences shared by ward members of the village suggests the need for the implementation of an organized and sustainable water accessible system. The well- being of the tribal people depends upon efficient watershed management which helps to improve the socio-economic conditions that has a positive impact in the overall development of the village.",
        "DOI": "10.1007/978-981-15-1420-3_141",
        "paper_author": "Akshaya S.",
        "affiliation_name": "Amrita School of Engineering, Coimbatore",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India",
        "affiliation_id": "60076784",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Two-Dimensional Release Policy for Software Systems Incorporating FRF, Opportunity Cost and Environment Factor",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Software development team intent to provide the best quality products under time and resource constraints. They single out their product in the market using various tools like advertisements, discounts, free trials, social networking etc. Warranty is one such tool used for product promotion. It assures customers from failure risks after product release. On one hand this helps to build the customer trust and brand image while on the other side it involves cost to developers in terms of cost incurred due to fault corrections during warranty period. Hence management has to maintain a balance so that they don’t have to bear undue financial losses. Therefore they plan release policies to determine the release time and the warranty time period that minimizes the cost. In this paper we have proposed a cost optimization model considering FRF based Two-Dimensional Delayed S-Shaped SRGM to define the failure behaviour under imperfect debugging, market opportunity cost, environmental factor and warranty policy. The model differentiates between the number of failures experienced and faults removed along with the probability of error generation. Once software is released it is affected by various external factors that may affect its failure behaviour. To accommodate the effect of external factor we have introduced an environment factor in the cost model. We have validated the model using the Tandem computers failure dataset. The optimization problem has been solved in MATLAB to determine optimal warranty and release time periods so that the total expected cost for software development is minimized.",
        "DOI": "10.1007/978-981-15-1420-3_95",
        "paper_author": "Verma V.",
        "affiliation_name": "University of Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60029284",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Intelligent and Adaptive Machine Learning-based Algorithm for Power Saving in Mobile Hotspot",
        "publication": "2020 IEEE 17th Annual Consumer Communications and Networking Conference, CCNC 2020",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "In current Wi-Fi technology trend, Mobile Hotspot (MHS) or Soft Access Point (S-AP) is an integral part of our day-to-day life. At any time, MHS could be enabled as Wi-Fi Hotspot in mobility devices (smart phone, tablet) with cellular backhaul network (3G/4G/5G) and provides Internet access to client devices such as laptop, TV etc. Unlike Wi-Fi Access Point, which is typically a powered device, MHS is enabled as battery-operated device. In addition, MHS consumes higher power and reported as one of the primary Voice of Customer (VoC) issue. Due to high power consumption, many customers are skeptical about MHS feature and its continuous usage. Apart from few literatures, there is no specific IEEE 802.11 standard for MHS and its power management. In this paper, we have proposed a Machine Learning (ML) based Intelligent MHS Power Save (I-MHSPS) algorithm using Wi-Fi parameters such as RSSI, SNR, TX power and channel condition. In addition, we have used other contextual parameters such as client behavior, battery level, application usage and internet backhaul to improve the accuracy of our algorithm. In I-MHSPS, we have proposed Intelligent Transmit Power Control (I-TPC): MHS TX power regulation based on client vicinity, Intelligent Ultra Power Save (I-UPS): Applying different system power level for MHS operation and Intelligent Low Power Encryption (I-LPE): Enabling low power encryption for short range MHS. In our first experiment with I-TPC idea has reduced power consumption by 10-16% approximately when compared to existing methodologies. In second experiment for I-UPS, we have applied different system power levels for MHS operation and achieved power saving around 22% without any performance degradation. Further, in third experiment, using I-LPE method, we have observed the power required for encryption of data packets reduced by 20%.",
        "DOI": "10.1109/CCNC46108.2020.9045535",
        "paper_author": "Thangadorai K.K.",
        "affiliation_name": "Samsung R&amp;D Institute India-Bangalore",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60283810",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Role-Based Authorization and Authentication Framework for Remote Service Access by In-Vehicle Users",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we propose an authorization and authentication framework for enabling users to access remote Cloud-based services in a moving vehicle. We utilize role-based access control model for authorization, and light-weight cryptographic operations for authentication. To verify the correctness of the access control policies, we implement the same on Access Control Policy Testing (ACPT) tool from National Institute of Standards and Technology (NIST). Moreover, we discuss and analyze the security and performance aspects of the proposed framework in detail.",
        "DOI": "10.1007/978-981-15-1420-3_82",
        "paper_author": "Goel D.",
        "affiliation_name": "University of Petroleum and Energy Studies",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India",
        "affiliation_id": "60107631",
        "affiliation_state": "UK"
    },
    {
        "paper_title": "Emerging Opportunities Provided by Technology to Advance Research in Child Health Globally",
        "publication": "Global Pediatric Health",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Current approaches to longitudinal assessment of children’s developmental and psychological well-being, as mandated in the United Nations Sustainable Development Goals, are expensive and time consuming. Substantive understanding of global progress toward these goals will require a suite of new robust, cost-effective research tools designed to assess key developmental processes in diverse settings. While first steps have been taken toward this end through efforts such as the National Institutes of Health’s Toolbox, experience-near approaches including naturalistic observation have remained too costly and time consuming to scale to the population level. This perspective presents 4 emerging technologies with high potential for advancing the field of child health and development research, namely (1) affective computing, (2) ubiquitous computing, (3) eye tracking, and (4) machine learning. By drawing attention of scientists, policy makers, investors/funders, and the media to the applications and potential risks of these emerging opportunities, we hope to inspire a fresh wave of innovation and new solutions to the global challenges faced by children and their families.",
        "DOI": "10.1177/2333794X20917570",
        "paper_author": "van Heerden A.",
        "affiliation_name": "Human Sciences Research Council of South Africa",
        "affiliation_city": "Pretoria",
        "affiliation_country": "South Africa",
        "affiliation_id": "60015399",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "Artificial intelligence as a disruptive technology: Economic transformation and government regulation",
        "publication": "Artificial Intelligence as a Disruptive Technology: Economic Transformation and Government Regulation",
        "citied_by": "51",
        "cover_date": "2020-01-01",
        "Abstract": "Introduction Artificial intelligence (AI) is the latest technological evolution which is transforming the global economy and is a major part of the “Fourth Industrial Revolution.” This book covers the meaning, types, subfields and applications of AI, including U.S. governmental policies and regulations, ethical and privacy issues, particularly as they pertain and affect facial recognition programs and the Internet-of Things (IoT). There is a lengthy analysis of bias, AI’s effect on the current and future job market, and how AI precipitated fake news. In addition, the text covers basics of intellectual property rights and how AI will transform their protection. The author then moves on to explore international initiatives from the European Union, China’s New Generation Development Plan, other regional areas, and international conventions. The book concludes with a discussion of super intelligence and the question and applicability of consciousness in machines. The interdisciplinary scope of the text will appeal to any scholars, students and general readers interested in the effects of AI on our society, particularly in the fields of STS, economics, law and politics.",
        "DOI": "10.1007/978-3-030-35975-1",
        "paper_author": "Girasa R.",
        "affiliation_name": "Pace University",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60022559",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Strategic policy options for bracing Nigeria for the future of trade",
        "publication": "Strategic Policy Options for Bracing Nigeria for the Future of Trade",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "As the fourth industrial era evolves, the role of blockchain technology, Artificial Intelligence (AI), and machine learning in transforming national commerce cannot be overemphasized, especially with the expansion of e-commerce in Africa. In other words, technological advancement and innovation are becoming essential to many aspects of Nigerian businesses, thereby considerably enhancing trade and productivity. This book provides a primer on the role that digital technology may play in Nigeria’s trade flows, and the implications for enabling an economy-wide deployment of digitization in trade facilitation. This book analyzes the importance of STI’s contributions to the Nigerian economy, focusing on the transition to digital solutions and their potential to significantly increase trade and commerce. Since AfCFTA’s 2018 launch, academic and political responses to the automation of business have increased. Further, business promotion, aid-for-trade, regional integration and trade facilitation issues are at the forefront of business development policy and intellectual discourse in Nigeria. This book details Nigeria’s business opportunities, capacities and challenges with a special interest in sustainably enhancing the nation’s business ecosystem in the digital age. Through the examination of trade facilitation policies, programs, tools, models and technologies, this book demonstrates Nigeria’s need for strategic public-private partnership in digital trade to foster a more sustainable business future.",
        "DOI": "10.1007/978-3-030-34552-5",
        "paper_author": "Odularu G.",
        "affiliation_name": "Bay Atlantic University",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "124468296",
        "affiliation_state": "DC"
    },
    {
        "paper_title": "How well can the migration component of regional population change be predicted? A machine learning approach applied to German municipalities",
        "publication": "Comparative Population Studies",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "For several decades, demographic forecasts had predicted that the ma-jority of Germany’s cities and rural areas would experience population decline in the early 21st century. Instead, recent trends show a growing population size in three out of every four German districts. As a result, there are currently severe shortages of housing and childcare in regions that were projected to decline but have instead grown in recent years. Other regions, by contrast, continue to lose young people in particular. Most of these differences between regions stem from within-country as well as international migration. An important question for both regional demographic research as well as local policy-makers is thus how well net migration rates in cities and rural districts can be predicted several years into the future. In this study, we develop models that predict migration (both within-country as well as international migration) at the level of municipalities for two demographic groups, namely young people aged 18 to 24 years, and families (people aged 30 to 49 years and underage children). We collect data on economic, demographic and other char-acteristics such as distances to large cities or universities for around 3,000 German municipalities (Gemeinden). The model is trained on a subset of these data from the period 2005-2009 and predicts net migration rates among young people on an unseen test dataset in the future (i.e. for the period 2011-2015). The results show that the model can predict future net migration by young people aged 18 to 24 years reasonably well (R² > 0.5), although there were quite significant changes during the period under study, for example refugee immigration to Germany. Family migration, on the other hand, cannot be predicted equally well (R² = 0.25). Some important les-sons emerge concerning the predictability of regional and international migration and the usefulness of demographic forecasts for local policy-makers.",
        "DOI": "10.12765/cpos-2020-08",
        "paper_author": "Weber H.",
        "affiliation_name": "Mannheimer Zentrum für Europäische Sozialforschung",
        "affiliation_city": "Mannheim",
        "affiliation_country": "Germany",
        "affiliation_id": "60115573",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Rainfall prediction to aid agriculture by analysing rainfall data using ensemble learning",
        "publication": "Journal of Advanced Research in Dynamical and Control Systems",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Rainfall, owing to its erratic nature at most times, is considered one of the most destructive natural disasters, making it highly complex to model. Hence, extensive research has been conducted on the advancement of rainfall prediction models, focusing mainly on risk reduction, policy reformation suggestions, minimization of the loss of human life, and reduction of the property damage associated with rainfall. The objective of the paper is to aid rainfall prediction for solving the various aforementioned problems by investigating the rainfall dataset of India using ensemble learning method-based techniques. The dataset is first pre-processed to deal with missing values, eliminate duplicate values and such, and then it is subject to various machine learning algorithms to predict the occurrence of rainfall. Finally, the results are analysed by the voting classifier algorithm. Accuracy calculation using the confusion matrix is performed, and a evaluation classification report is generated, to graphically represent the predicted information to the users, on a GUI based application, thus relaying the prediction effectively to the intended audience.",
        "DOI": "10.5373/JARDCS/V12SP4/20201490",
        "paper_author": "Kalpana G.",
        "affiliation_name": "Rajalakshmi Institute of Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60121924",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Deep convolutional neural networks for forensic age estimation: A review",
        "publication": "Advanced Sciences and Technologies for Security Applications",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Forensic age estimation is usually requested by courts, but applications can go beyond the legal requirement to enforce policies or offer age-sensitive services. Various biological features such as the face, bones, skeletal and dental structures can be utilised to estimate age. This article will cover how modern technology has developed to provide new methods and algorithms to digitalise this process for the medical community and beyond. The scientific study of Machine Learning (ML) have introduced statistical models without relying on explicit instructions, instead, these models rely on patterns and inference. Furthermore, the large-scale availability of relevant data (medical images) and computational power facilitated by the availability of powerful Graphics Processing Units (GPUs) and Cloud Computing services have accelerated this transformation in age estimation. Magnetic Resonant Imaging (MRI) and X-ray are examples of imaging techniques used to document bones and dental structures with attention to detail making them suitable for age estimation. We discuss how Convolutional Neural Network (CNN) can be used for this purpose and the advantage of using deep CNNs over traditional methods. The article also aims to evaluate various databases and algorithms used for age estimation using facial images and dental images.",
        "DOI": "10.1007/978-3-030-35746-7_17",
        "paper_author": "Alkaabi S.",
        "affiliation_name": "Universiti Tenaga Nasional",
        "affiliation_city": "Kajang",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60005762",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Sentiment Analysis Approach Based on Combination of Word Embedding Techniques",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "Sentiment analysis is a field of research that attracts the attention of companies and governments to understand the opinion of the client and citizens, about products, services, policies and more other. With the increased volume of user-generated content on the Web, especially social networks, textual information becomes freely accessible and with a gigantic quantity, which requires powerful automated analysis tools to extract such kind of information (positive or negative sentiment). In this paper, we present sentiment analysis approach depends on pre-trained word embeddings, a frilly high-quality word representation vectors, namely, AraVec and fastText models, and we proposed a combination of the two models, based on vectors concatenation of both models. Sentiment classification was executed employing six different machine learning algorithms, we find that in most of the cases, our proposed method achieves the best results in terms of accuracy, especially with NuSVC classifier which is a type of SVM.",
        "DOI": "10.1007/978-981-15-0947-6_76",
        "paper_author": "Kaibi I.",
        "affiliation_name": "Université Mohammed Premier Oujda",
        "affiliation_city": "Oujda",
        "affiliation_country": "Morocco",
        "affiliation_id": "60013094",
        "affiliation_state": "Oriental"
    },
    {
        "paper_title": "PodNet: A neural network for discovery of plannable options",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Learning from demonstration has been widely studied in machine learning but becomes challenging when the demonstrated trajectories are unstructured and follow different objectives. This short-paper proposes PODNet, Plannable Option Discovery Network, addressing how to segment an unstructured set of demonstrated trajectories for option discovery. This enables learning from demonstration to perform multiple tasks and plan high-level trajectories based on the discovered option labels. PODNet combines a custom categorical variational autoencoder, a recurrent option inference network, option-conditioned policy network, and option dynamics model in an end-to-end learning architecture. Due to the concurrently trained option-conditioned policy network and option dynamics model, the proposed architecture has implications in multi-task and hierarchical learning, explainable and interpretable artificial intelligence, and applications where the agent is required to learn only from observations.",
        "DOI": "NA",
        "paper_author": "Bera R.",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60020547",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Attribution-based Salience Method towards Interpretable Reinforcement Learning",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement Learning (RL), a general learning, predicting and decision-making paradigm, has achieved great success in a wide range of games and robotics. Recently, RL has also proven its worth in real world scenarios, such as adaptive decision control and recommendation. It is promising to deploy RL in the real world to gain real benefits. However, RL is criticized for its being black-box. The real systems are owned and operated by humans, who need to be reassured about the controller’s intentions and insights regarding failure cases. Therefore, policy explanation is important. Existing methods towards interpretable RL include Jacobian saliency map and perturbation-based saliency map, which are limited to visual input problems. To model the complicated real-world use cases, numerical data are widely employed. In this paper, we propose an attribution-based salience method that is applicable on visual and numerical input. We aim to understand RL agents in terms of the information they attend to for decision making. We verify our method with a machine control use case. Explanations we provided are understandable to both AI experts and non-experts alike. (short paper)",
        "DOI": "NA",
        "paper_author": "Wang Y.",
        "affiliation_name": "Hitachi, Ltd.",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60003381",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Building energy management for demand response using kernel lifelong learning",
        "publication": "IEEE Access",
        "citied_by": "21",
        "cover_date": "2020-01-01",
        "Abstract": "Demand response (DR) aims at improving the reliability and efficiency of the power grids by shaping the power demand over time. Given that building energy consumption constitutes a significant portion of the overall grid load, building energy management is a critical component for the DR portfolio. In this study, DR control policies for lighting and air-conditioner systems for the individual spaces in buildings are proposed. The policies are designed to achieve the energy reduction amount specified in the DR request while minimizing the user discomfort. A significant challenge is to cope with the uncertainty of various environmental factors such as the solar illuminance and ambient temperature, as well as the psycho-economic factors such as the energy usage preferences of the occupants. We employ a data-driven machine learning approach to tackle this challenge. Our novel idea is to take advantage of the structural similarity of the control policies across the spaces in a lifelong multi-task learning framework. To accommodate significant nonlinearity in efficient policies, a kernel-based learning approach is pursued. The dual decomposition method is employed to relax the constraint coupled across the spaces, which allows solving the overall learning problem via a series of unconstrained subproblems. The efficacy of the proposed method is verified by numerical experiments based on semi-real data sets.",
        "DOI": "10.1109/ACCESS.2020.2991110",
        "paper_author": "Kim S.",
        "affiliation_name": "Gwangju Institute of Science and Technology",
        "affiliation_city": "Gwangju",
        "affiliation_country": "South Korea",
        "affiliation_id": "60068688",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Online data-driven energy management of a hybrid electric vehicle using model-based Q-learning",
        "publication": "IEEE Access",
        "citied_by": "48",
        "cover_date": "2020-01-01",
        "Abstract": "The energy management strategy of a hybrid electric vehicle directly determines the fuel economy of the vehicle. As a supervisory control strategy to divide the required power into its multiple power sources, engines and batteries, many studies have been conducting using rule-based and optimization-based approaches for energy management strategy so far. Recently, studies using various machine learning techniques have been conducted. In this paper, a novel control framework implementing Model-based Q-learning is developed for the optimal control problem of hybrid electric vehicles. As an online energy management strategy, a new approach could learn the characteristics of a current given driving environment and adaptively change the control policy through learning. Especially, for the proposed algorithm, the internal powertrain environment and external driving environment are separated so they can be learned via the reinforcement learning framework, which results in a simpler and more intuitive control strategy that can be explained using the vehicle state approximation model. The proposed algorithm is tested and verified through simulations, and the simulation results present near optimal solution. The simulation results are compared with conventional rule-based strategies and optimal control solutions acquired from Dynamic Programming.",
        "DOI": "10.1109/ACCESS.2020.2992062",
        "paper_author": "Lee H.",
        "affiliation_name": "Seoul National University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60013682",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data-Driven Policy on Feasibility Determination for the Train Shunting Problem",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Parking, matching, scheduling, and routing are common problems in train maintenance. In particular, train units are commonly maintained and cleaned at dedicated shunting yards. The planning problem that results from such situations is referred to as the Train Unit Shunting Problem (TUSP). This problem involves matching arriving train units to service tasks and determining the schedule for departing trains. The TUSP is an important problem as it is used to determine the capacity of shunting yards and arises as a sub-problem of more general scheduling and planning problems. In this paper, we consider the case of the Dutch Railways (NS) TUSP. As the TUSP is complex, NS currently uses a local search (LS) heuristic to determine if an instance of the TUSP has a feasible solution. Given the number of shunting yards and the size of the planning problems, improving the evaluation speed of the LS brings significant computational gain. In this work, we use a machine learning approach that complements the LS and accelerates the search process. We use a Deep Graph Convolutional Neural Network (DGCNN) model to predict the feasibility of solutions obtained during the run of the LS heuristic. We use this model to decide whether to continue or abort the search process. In this way, the computation time is used more efficiently as it is spent on instances that are more likely to be feasible. Using simulations based on real-life instances of the TUSP, we show how our approach improves upon the previous method on prediction accuracy and leads to computational gains for the decision-making process.",
        "DOI": "10.1007/978-3-030-46133-1_43",
        "paper_author": "de Oliveira da Costa P.R.",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60032882",
        "affiliation_state": "Noord-Brabant"
    },
    {
        "paper_title": "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2019",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 140 papers. The special focus in this conference is on Machine Learning and Principles and Practice of Knowledge Discovery in Databases. The topics include: Stochastic One-Sided Full-Information Bandit; belMan: An Information-Geometric Approach to Stochastic Bandits; a Ranking Model Motivated by Nonnegative Matrix Factorization with Applications to Tennis Tournaments; a Reduction of Label Ranking to Multiclass Classification; learning to Calibrate and Rerank Multi-label Predictions; pairwise Learning to Rank by Neural Networks Revisited: Reconstruction, Theoretical Analysis and Practical Performance; sequential Learning over Implicit Feedback for Robust Large-Scale Recommender Systems; automatic Recognition of Student Engagement Using Deep Learning and Facial Expression; marine Mammal Species Classification Using Convolutional Neural Networks and a Novel Acoustic Representation; learning Disentangled Representations of Satellite Image Time Series; sample-Efficient Model-Free Reinforcement Learning with Off-Policy Critics; pushing the Limits of Exoplanet Discovery via Direct Imaging with Deep Learning; j3R: Joint Multi-task Learning of Ratings and Review Summaries for Explainable Recommendation; augmenting Semantic Representation of Depressive Language: From Forums to Microblogs; augmenting Physiological Time Series Data: A Case Study for Sleep Apnea Detection; wearable-Based Parkinson’s Disease Severity Monitoring Using Deep Learning; Investigating Time Series Classification Techniques for Rapid Pathogen Identification with Single-Cell MALDI-TOF Mass Spectrum Data; CASTNet: Community-Attentive Spatio-Temporal Networks for Opioid Overdose Forecasting; scalable Bid Landscape Forecasting in Real-Time Bidding; a Deep Multi-task Approach for Residual Value Forecasting; transfer Learning in Credit Risk; learning 3D Navigation Protocols on Touch Interfaces with Cooperative Multi-agent Reinforcement Learning; cold-Start Recommendation for On-Demand Cinemas; LSTM Encoder-Predictor for Short-Term Train Load Forecasting.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Gaussian Process Reinforcement Learning for Fast Opportunistic Spectrum Access",
        "publication": "IEEE Transactions on Signal Processing",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Opportunistic spectrum access (OSA) is envisioned to support the spectrum demand of future-generation wireless networks. The majority of existing work assumed independent primary channels with the knowledge of network dynamics. However, the channels are usually correlated and network dynamics is unknown a-priori. This entails a great challenge on the sensing policy design for spectrum opportunity tracking, and the conventional partially observable Markov decision process (POMDP) formulation with model-based solutions are generally inapplicable. In this paper, we take a different approach, and formulate the sensing policy design as a time-series POMDP from a model-free perspective. To solve this time-series POMDP, we propose a novel Gaussian process reinforcement learning (GPRL) based solution. It achieves accurate channel selection and a fast learning rate. In essence, GP is embedded in RL as a Q-function approximator to efficiently utilize the past learning experience. A novel kernel function is first tailor designed to measure the correlation of time-series spectrum data. Then a covariance-based exploration strategy is developed to enable a proactive exploration for better policy learning. Finally, for GPRL to adapt to multichannel sensing, we propose a novel action-trimming method to reduce the computational cost. Our simulation results show that the designed sensing policy outperforms existing ones, and can obtain a near-optimal performance within a short learning phase.",
        "DOI": "10.1109/TSP.2020.2986354",
        "paper_author": "Yan Z.",
        "affiliation_name": "Faculty of Engineering",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60090755",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "A framework for analysis and expansion of public charging infrastructure under fast penetration of electric vehicles",
        "publication": "World Electric Vehicle Journal",
        "citied_by": "18",
        "cover_date": "2020-01-01",
        "Abstract": "The improvement commercial competitiveness of private electric vehicles supported by the European policy for the decarbonisation of transport and with the consumers awareness-raising about CO2 emissions and climate change, are driving the increase of electric vehicles on the roads. Therefore, public charging networks are facing the challenge of supply electricity to a fast increasing number of electric cars. The objective of this paper is to establish an assessment framework for analysis and monitor of existing charging networks. The developed methodology comprises modelling the charging infrastructure electricity profile, analysing the data by using machine learning models such as functional k-means clustering and defining a novel congestion metric. The described framework has been tested against Irish public charging network historical datasets. The analyses reveal a lack of reliability of the communication network infrastructure, frequent congestion events for commercial and shopping areas in specific clusters of charge points and the presence of power peaks caused by the high number of simultaneous charging events. Several recommendations for future network expansion have been highlighted.",
        "DOI": "10.3390/wevj11010018",
        "paper_author": "Pallonetto F.",
        "affiliation_name": "University College Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland",
        "affiliation_id": "60005141",
        "affiliation_state": "Leinster"
    },
    {
        "paper_title": "Artificial intelligence for smart renewable energy sector in europe - Smart energy infrastructures for next generation smart cities",
        "publication": "IEEE Access",
        "citied_by": "157",
        "cover_date": "2020-01-01",
        "Abstract": "One of the most challenging areas of Future Smart Cities Research is the Smart Energy domain. Critical issues related to optimization, provision of smart customizable networks and sophisticated computational techniques and methods enabled by artificial intelligence and machine learning need further investigation. The renewable energy (RE) is a powerful resource for the future global development in the context of climate change and resources depletion. Artificial intelligence (AI) implies new rules of organizing the activities in order to respond to these new requirements. It is necessary to improve the design of the energy infrastructure, the deployment and production of RE in order to face the multiple challenges that will affect the sector's growth and resilience.. In this research work we exploit the recent developments on the AI adoption for RE sector in European Union (EU). In this respect, we analysed (i) the efficiency of the transformation processes of the RE within the energy chain from Gross Inland Consumption to Final Energy Consumption, (ii) its implications on the structure of renewable energy by source (solar, wind, biomass etc.), (iii) the labour productivity in RE sector compared to the economy as a whole and its correlation with investments level, (iv) the implication of the adoption of AI for RE towards Future Smart Cities Research. The main contribution of this research is the development of a framework for understanding the contribution of AI in the RE sector in Europe. Another bold contribution of this work is the discussion of the implications for Future Smart Cities Research and future research directions.",
        "DOI": "10.1109/ACCESS.2020.2990123",
        "paper_author": "Serban A.C.",
        "affiliation_name": "Bucharest University of Economic Studies",
        "affiliation_city": "Bucharest",
        "affiliation_country": "Romania",
        "affiliation_id": "60107810",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Practical Open-Loop Optimistic Planning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "We consider the problem of online planning in a Markov Decision Process when given only access to a generative model, restricted to open-loop policies - i.e. sequences of actions - and under budget constraint. In this setting, the Open-Loop Optimistic Planning (OLOP) algorithm enjoys good theoretical guarantees but is overly conservative in practice, as we show in numerical experiments. We propose a modified version of the algorithm with tighter upper-confidence bounds, KL-OLOP, that leads to better practical performances while retaining the sample complexity bound. Finally, we propose an efficient implementation that significantly improves the time complexity of both algorithms.",
        "DOI": "10.1007/978-3-030-46133-1_5",
        "paper_author": "Leurent E.",
        "affiliation_name": "INRIA Lille - Nord Europe",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "124425520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Aggregate Learning Approach for Interpretable Semi-supervised Population Prediction and Disaggregation Using Ancillary Data",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Census data provide detailed information about population characteristics at a coarse resolution. Nevertheless, fine-grained, high-resolution mappings of population counts are increasingly needed to characterize population dynamics and to assess the consequences of climate shocks, natural disasters, investments in infrastructure, development policies, etc. Disaggregating these census is a complex machine learning, and multiple solutions have been proposed in past research. We propose in this paper to view the problem in the context of the aggregate learning paradigm, where the output value for all training points is not known, but where it is only known for aggregates of the points (i.e. in this context, for regions of pixels where a census is available). We demonstrate with a very simple and interpretable model that this method is on par, and even outperforms on some metrics, the state-of-the-art, despite its simplicity.",
        "DOI": "10.1007/978-3-030-46133-1_40",
        "paper_author": "Derval G.",
        "affiliation_name": "Université Catholique de Louvain",
        "affiliation_city": "Louvain-la-Neuve",
        "affiliation_country": "Belgium",
        "affiliation_id": "60000874",
        "affiliation_state": "WBR"
    },
    {
        "paper_title": "Development of a novel machine learning methodology for the generation of a gasoline surrogate laminar flame speed database under water injection engine conditions",
        "publication": "SAE International Journal of Fuels and Lubricants",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "The water injection is one of the technologies assessed in the development of new internal combustion engines fulfilling new emission regulation and policy on Auxiliary Emission Strategy assessment. Besides all the positive aspects about the reduction of mixture temperature at top dead center and exhaust gases temperature at turbine inlet, it is well known that the water vapor acts as a mixture diluter, thus diminishing the reactants burning rate. A common methodology employed for the Reynolds-Averaged Navier-Stokes Computational Fluid Dynamics (RANS CFD) simulation of the reciprocating internal combustion engines' turbulent combustion relies on the flamelet approach, which requires knowledge of the Laminar Flame Speed (LFS) and thickness. Typically, these properties are calculated by means of correlation laws, but they do not keep into account the presence of water mass fraction. A more precise methodology for the definition of both the LFS and thickness is thus required. The interrogation of a previously computed look-up table of such properties during run time seems to be a suitable and more accurate method than using correlations. In order to generate a database with all the possible combinations of chemical and physical properties that can be reached during the simulation of internal combustion engines, including the presence of a given mass fraction of water vapor and exhaust gases, a very high number of detailed chemical kinetics simulations need to be performed. The present work aims to introduce a new methodology for the fast generation of laminar flame characteristics look-up tables that account also for the presence of water vapor in the reacting mixture. By using this new approach, engine designers will have the possibility to generate look-up tables of laminar flame characteristics for different fuels with the same computational cost that is currently required to generate a single table.",
        "DOI": "10.4271/04-13-01-0001",
        "paper_author": "Pulga L.",
        "affiliation_name": "Alma Mater Studiorum Università di Bologna",
        "affiliation_city": "Bologna",
        "affiliation_country": "Italy",
        "affiliation_id": "60028218",
        "affiliation_state": "BO"
    },
    {
        "paper_title": "The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence",
        "publication": "Big Data and Society",
        "citied_by": "122",
        "cover_date": "2020-01-01",
        "Abstract": "This paper sheds light on the role of digital platform labour in the development of today’s artificial intelligence, predicated on data-intensive machine learning algorithms. Focus is on the specific ways in which outsourcing of data tasks to myriad ‘micro-workers’, recruited and managed through specialized platforms, powers virtual assistants, self-driving vehicles and connected objects. Using qualitative data from multiple sources, we show that micro-work performs a variety of functions, between three poles that we label, respectively, ‘artificial intelligence preparation’, ‘artificial intelligence verification’ and ‘artificial intelligence impersonation’. Because of the wide scope of application of micro-work, it is a structural component of contemporary artificial intelligence production processes – not an ephemeral form of support that may vanish once the technology reaches maturity stage. Through the lens of micro-work, we prefigure the policy implications of a future in which data technologies do not replace human workforce but imply its marginalization and precariousness.",
        "DOI": "10.1177/2053951720919776",
        "paper_author": "Tubaro P.",
        "affiliation_name": "Université Paris-Saclay",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France",
        "affiliation_id": "60106017",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Unsupervised machine learning to analyze City Logistics through Twitter",
        "publication": "Transportation Research Procedia",
        "citied_by": "9",
        "cover_date": "2020-01-01",
        "Abstract": "City Logistics is characterized by multiple stakeholders that often have different views on such a complex system. From a public policy perspective, identifying stakeholders, issues and trends is a daunting challenge, only partially addressed by traditional observation systems. Nowadays, social media is one of the biggest channels of public expression and is often used to communicate opinions and content related to City Logistics. The idea of this research is that analyzing social media content could help in understanding the public perception of City Logistics. This paper offers a methodology for collecting content from Twitter and implementing machine learning techniques (Unsupervised Learning and Natural Language Processing), to perform content and sentiment analysis. The proposed methodology is applied to more than 110 000 tweets containing City Logistics key-terms. Results allowed the building of an Interest Map of concepts and a Sentiment Analysis to determine if City Logistics entries are positive, negative or neutral.",
        "DOI": "10.1016/j.trpro.2020.03.184",
        "paper_author": "Tamayo S.",
        "affiliation_name": "Mines Paris - PSL",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60030506",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "A novel hybrid mitigation technique against dos attacks in software defined network with entropy, SVM and reinforcement learning",
        "publication": "International Journal on Emerging Technologies",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Software Defined Network (SDN), also known as a Smart Network, as it performs significant role in regulating and managing number of heterogeneous networks. Tragically, SDN faces a great deal of security issues that may seriously influence the system activities if not appropriately tended to. In the SDN network, there is centralization of the controller and hence any DoS attack will cause the entire system to collapse. The DoS attack on centralized model brings about huge challenge of communication overhead, packet delay and loss of genuine packets. Another challenge is there is a lack of research on finding a common methodology for intelligently evaluating the security of SDN controllers. Thus, the paper contributes by evaluating an intelligent hybrid method for detection and mitigation of DoS attack with Entropy, SVM and Reinforcement Learning with Markovian Process model. The paper proposes a profound reinforcement learning based system, which can intelligently gain proficiency in learning the optimal mitigation policies under various attack scenarios and mitigate the DoS flooding attack in real time. Practical experiments are conducted in the Mininet environment, to defend against a wide range of DoS flooding attacks such as TCP SYN, UDP, and ICMP flooding and proves that the proposed novel hybrid mechanism can be an effective against DoS attacks, causing benign traffic to keep flowing, keeping the network working. The framework also proposes a novel flow based algorithm which can determine the attacker in crucial attack.",
        "DOI": "NA",
        "paper_author": "Lotlikar T.",
        "affiliation_name": "Terna Engineering College",
        "affiliation_city": "Navi Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60114821",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Influential factor analysis and projection of industrial CO<inf>2</inf> emissions in China based on extreme learning machine improved by genetic algorithm",
        "publication": "Polish Journal of Environmental Studies",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "In China, CO2 emissions from industrial sectors on a larger scale than other end-use sectors. In order to reduce CO2 emissions, it is necessary to study the influencing factors and projection of industrial CO2 emissions. Based on accounting for CO2 emissions from the industrial sectors, this paper carries out bivariate correlation analysis and linear regression analysis on 15 preselected influencing factors and industrial CO2 emissions, removing two factors that have failed the significance test. In order to obtain some potential commonalities among the influencing factors, the remaining 13 influencing factors are divided into four categories, and then factor analysis is performed on each category in order to obtain five latent factors. An extreme learning machine algorithm that uses genetic algorithms to optimize the input weights and bias thresholds - the genetic algorithm extreme learning machine (GA-ELM) algorithm - to predict industrial CO2 emissions, the empirical results show that the GA-ELM algorithm using five factors as inputs has a higher prediction accuracy and performance for industrial CO2 emissions than the extreme learning machine, back propagation neural network, and back propagation neural network optimized by the genetic algorithm. It also shows that the five influencing factors have a significant impact on industrial CO2 emissions. Finally, based on the analysis of five influencing factors, some policy recommendations are proposed for the CO2 emissions reduction path in the industrial sectors.",
        "DOI": "10.15244/pjoes/110973",
        "paper_author": "Li Y.",
        "affiliation_name": "North China Electric Power University (Baoding)",
        "affiliation_city": "Baoding",
        "affiliation_country": "China",
        "affiliation_id": "60108757",
        "affiliation_state": "Hebei"
    },
    {
        "paper_title": "HiLITE: Hierarchical and Lightweight Imitation Learning for Power Management of Embedded SoCs",
        "publication": "IEEE Computer Architecture Letters",
        "citied_by": "13",
        "cover_date": "2020-01-01",
        "Abstract": "Modern systems-on-chip (SoCs) use dynamic power management (DPM) techniques to improve energy efficiency. However, existing techniques are unable to efficiently adapt the runtime decisions considering multiple objectives (e.g., energy and real-time requirements) simultaneously on heterogeneous platforms. To address this need, we propose HiLITE, a hierarchical imitation learning framework that maximizes the energy efficiency while satisfying soft real-time constraints on embedded SoCs. Our approach first trains DPM policies using imitation learning; then, it applies a regression policy at runtime to minimize deadline misses. HiLITE improves the energy-delay product by 40 percent on average, and reduces deadline misses by up to 76 percent, compared to state-of-the-art approaches. In addition, we show that the trained policies not only achieve high accuracy, but also have negligible prediction time overhead and small memory footprint.",
        "DOI": "10.1109/LCA.2020.2992182",
        "paper_author": "Sartor A.L.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60104842",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "A supply chain management based patient forecasting model for dental hospital",
        "publication": "Journal of Critical Reviews",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Management is in fact on the verge of a major breakthrough in finding out exactly how service sector success is actually determined by the interactions between the flows of information, materials, money, manpower, and capital equipment. The way these five flow principles interlock to be able to amplify one another as well as to bring about switch and fluctuation will build the grounds for anticipating the look of decisions, policies, organizational forms, and investment choices . A concept of distribution management which recognized the integrated dynamics of organizational associations since companies are so intertwined, expert argued that technique attributes can influence the general functionality of abilities as investigation, engineering, sales, and promotion. Illustrated phenomena is actually utilizing a laptop computer or perhaps computer simulation of order information flow along with the impact of its effect on development in addition to distribution general functionality for each supply chain member, in addition to the entire supply chain application. A Machine Learning based proposed model for patient forecasting is implemented to show the research analysis work for patient forecasting for the dental hospital located in Bhopal, Madhya Pradesh, India. This research paper is indicating about the use, application and implementation of Kernel based Support Vector Machine for regression analysis purpose and also select the best Kernel for the implementation of the predicted model.",
        "DOI": "10.31838/jcr.07.03.76",
        "paper_author": "Singh S.",
        "affiliation_name": "Sarvepalli Radhakrishnan University, Bhopal",
        "affiliation_city": "Bhopal",
        "affiliation_country": "India",
        "affiliation_id": "60282907",
        "affiliation_state": "MP"
    },
    {
        "paper_title": "Fourth industrial revolution: Progression, scope and preparedness in India—Intervention of MSMEs",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "MSME (Micro, Small and Medium Enterprise) sector constitutes more than 99% of private firms operating in India which generate crores of jobs across the country. In fact, the MSME firms aim to support the large companies either in the form of outsourcing partners for supplying raw materials, W-I-P or adding value to one or few processes as ancillary to the big establishments. However, in the growing competition and the market complexity, the MSMEs have to compete with the large firms. The world is emerging toward Fourth Industrial Revolution (4IR) which not only prescribes for automation, speed, and prompt delivery mechanism but also it attempts to duplicate Human Intelligence in the form of Machine Learning or Artificial Intelligence (AI). In the dynamics of rapid changes across the Industrial Ecosystem, it is emergent for the MSMEs to re-module its business directions. The threshold level technology needs to be transferred, absorbed, and adopted by the MSME firms so that the can play a meaningful role in today’s knowledge economies. This paper has explored the Scope and Preparedness for the sector and has prescribed desired Policy Reforms to make the transition smooth, value-adding and resourceful.",
        "DOI": "10.1007/978-981-15-2780-7_26",
        "paper_author": "Chakrabarty A.",
        "affiliation_name": "Rajiv Gandhi University, Doimukh",
        "affiliation_city": "Doimukh",
        "affiliation_country": "India",
        "affiliation_id": "60008434",
        "affiliation_state": "AR"
    },
    {
        "paper_title": "Actor-critic deep reinforcement learning for solving job shop scheduling problems",
        "publication": "IEEE Access",
        "citied_by": "196",
        "cover_date": "2020-01-01",
        "Abstract": "In the past decades, many optimization methods have been devised and applied to job shop scheduling problem (JSSP) to find the optimal solution. Many methods assumed that the scheduling results were applied to static environments, but the whole environments in the real world are always dynamic. Moreover, many unexpected events such as machine breakdowns and material problems may be present to adversely affect the initial job scheduling. This work views JSSP as a sequential decision making problem and proposes to use deep reinforcement learning to cope with this problem. The combination of deep learning and reinforcement learning avoids handcraft features as used in traditional reinforcement learning, and it is expected that the combination will make the whole learning phase more efficient. Our proposed model comprises actor network and critic network, both including convolution layers and fully connected layer. Actor network agent learns how to behave in different situations, while critic network helps agent evaluate the value of statement then return to actor network. This work proposes a parallel training method, combining asynchronous update as well as deep deterministic policy gradient (DDPG), to train the model. The whole network is trained with parallel training on a multi-agent environment and different simple dispatching rules are considered as actions. We evaluate our proposed model on more than ten instances that are present in a famous benchmark problem library - OR library. The evaluation results indicate that our method is comparative in static JSSP benchmark problems, and achieves a good balance between makespan and execution time in dynamic environments. Scheduling score of our method is 91.12% in static JSSP benchmark problems, and 80.78% in dynamic environments.",
        "DOI": "10.1109/ACCESS.2020.2987820",
        "paper_author": "Liu C.L.",
        "affiliation_name": "National Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60012370",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Episodic memory reader: Learning what to remember for question answering from streaming data",
        "publication": "ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "We consider a novel question answering (QA) task where the machine needs to read from large streaming data (long documents or videos) without knowing when the questions will be given, which is difficult to solve with existing QA methods due to their lack of scalability. To tackle this problem, we propose a novel end-to-end deep network model for reading comprehension, which we refer to as Episodic Memory Reader (EMR) that sequentially reads the input contexts into an external memory, while replacing memories that are less important for answering unseen questions. Specifically, we train an RL agent to replace a memory entry when the memory is full, in order to maximize its QA accuracy at a future timepoint, while encoding the external memory using either the GRU or the Transformer architecture to learn representations that considers relative importance between the memory entries. We validate our model on a synthetic dataset (bAbI) as well as real-world large-scale textual QA (TriviaQA) and video QA (TVQA) datasets, on which it achieves significant improvements over rule-based memory scheduling policies or an RL-based baseline that independently learns the query-specific importance of each memory.",
        "DOI": "NA",
        "paper_author": "Han M.",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60032144",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Environmental predictors of deep-sea polymetallic nodule occurrence in the global ocean",
        "publication": "Geology",
        "citied_by": "45",
        "cover_date": "2020-01-01",
        "Abstract": "Polymetallic nodules found on the abyssal plains of the oceans represent one of the slowest known geological processes, and are a source of critical and rare metals for frontier technologies. A quantitative assessment of their occurrence worldwide has been hampered by a research focus on the northeastern Pacific Ocean and the lack of a global open-access data set of nodules. We have compiled a global data set of >10,000 seabed nodule and control samples, and combine it with digital grids of key environmental parameters to generate a predictive machine-learning model of nodule occurrence. In order of decreasing parameter ranking, we find that nodules are associated with very low sedimentation rates (< 0.5 cm/k.y.), moderately high oxygen values (150 and 210 mmol/m3), lithologies of clay followed by calcareous ooze, low summer surface productivity (<300 mgC/m2/day), low benthic biomass concentration (<1 log mgC/m2), water depths >4500 m, and low total organic carbon content (0.3-0.5 wt%). Competing hypotheses for nodule sustention and thus continued growth on the seafloor are the removal of sediment by bottom-water currents and biological activity. Using a high-resolution eddy-resolving ocean circulation model, we find that the bottom-current speeds over nodule fields are too low (<5 cm/s) to remove sediment, implicating the activity of epibenthic megafauna as the most likely mechanism. Our global nodule probability map combined with the assessment of a range of environmental drivers provides an improved basis for decision and policy making in the controversial area of deep-sea exploration.",
        "DOI": "10.1130/G46836.1",
        "paper_author": "Dutkiewicz A.",
        "affiliation_name": "The University of Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60025709",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Socio economic analysis of India with high resolution satellite imagery to predict poverty",
        "publication": "Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Eradicating poverty is the numero uno objective of the United Nations for sustainable development of the world by 2030. But, in order to develop a feasible, targeted solution to this problem, an exact poverty map is required. In India, especially in rural areas, there is a dearth of reliable and frequent data related to indicators of poverty line as the national statistics division of the country releases data only once in five years. In this paper, we look at an alternative to the slow, ineffective collection of data on ground: mapping poverty from outer space using medium and high-resolution satellite imagery. Using both satellite imagery and survey data for the rural areas of India, we review how machine learning tools like convolutional neural networks have been harnessed to efficiently identify image features that help us effectively predict socio-economic indicators of poverty. We also explore how these methods offer promising means for policy makers to tackle poverty at the grassroot level and a potential for application across several domains of science.",
        "DOI": "10.1109/Confluence47617.2020.9057972",
        "paper_author": "Das P.S.",
        "affiliation_name": "Amity University",
        "affiliation_city": "Noida",
        "affiliation_country": "India",
        "affiliation_id": "60076774",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "13th International Conference on Parallel Processing and Applied Mathematics, PPAM 2019",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 91 papers. The special focus in this conference is on Parallel Processing and Applied Mathematics. The topics include: Performance/Energy Aware Optimization of Parallel Applications on GPUs Under Power Capping; improving Energy Consumption in Iterative Problems Using Machine Learning; automatic Software Tuning of Parallel Programs for Energy-Aware Executions; overview of Application Instrumentation for Performance Analysis and Tuning; Energy-Efficiency Tuning of a Lattice Boltzmann Simulation Using MERIC; Evaluating the Advantage of Reactive MPI-aware Power Control Policies; application-Aware Power Capping Using Nornir; A New Hardware Counters Based Thread Migration Strategy for NUMA Systems; alea – Complex Job Scheduling Simulator; studying the Performance of Vector-Based Quicksort Algorithm; makespan Minimization in Data Gathering Networks with Dataset Release Times; overlapping Schwarz Preconditioner for Fourth Order Multiscale Elliptic Problems; MATLAB Implementation of C1 Finite Elements: Bogner-Fox-Schmit Rectangle; simple Preconditioner for a Thin Membrane Diffusion Problem; a Numerical Scheme for Evacuation Dynamics; Additive Average Schwarz with Adaptive Coarse Space for Morley FE; application of Multiscale Computational Techniques to the Study of Magnetic Nanoparticle Systems; clique: A Parallel Tool for the Molecular Nanomagnets Simulation and Modelling; Modelling of Limitations of BHJ Architecture in Organic Solar Cells; monte Carlo Study of Spherical and Cylindrical Micelles in Multiblock Copolymer Solutions; Parallel Tiled Cache and Energy Efficient Code for Zuker’s RNA Folding; electronic and Optical Properties of Carbon Nanotubes Directed to Their Applications in Solar Cells; The MPFI Library: Towards IEEE 1788–2015 Compliance; softmax and McFadden’s Discrete Choice Under Interval (and Other) Uncertainty; experiments with Heterogenous Automata-Based Multi-agent Systems.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The Potential of Restarts for ProbSAT",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "This work analyses the potential of restarts for probSAT by estimating its runtime distributions on random 3-SAT instances that are close to the phase transition. We estimate optimal restart times from empirical data, reaching a potential speedup factor of 1.39. Calculating restart times from fitted probability distributions reduces this factor to a maximum of 1.25. We find that the Weibull distribution approximates the runtime distribution well for over 93% of the used instances. A machine learning pipeline is presented to compute a restart time for a fixed-cutoff strategy to exploit this potential. The presented approach performs statistically significantly better than Luby’s restart strategy and the policy without restarts. The structure is particularly advantageous for hard problems.",
        "DOI": "10.1007/978-3-030-45093-9_43",
        "paper_author": "Lorenz J.H.",
        "affiliation_name": "Universität Ulm",
        "affiliation_city": "Ulm",
        "affiliation_country": "Germany",
        "affiliation_id": "60010586",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "A Novel Adaptive Approach for Sentiment Analysis on Social Media Data",
        "publication": "Lecture Notes in Networks and Systems",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Sentiment analysis (SA) is the approach of determining polarity of any content whether the given sentence contains positive, negative, or neutral sentiments. In many real-world situations, it is required to know the public emotions about happening in surrounding environment. Thus, this analysis helps in decision making on a particular task. There is a huge area where sentiment analysis can be utilized to improve the decision making like while launching a new product, adding additional features in existing products, announcing of a new government policy, etc. This paper shows sentiment analysis system which is based on machine learning algorithm used by TextBlob API using python. Proposed system uses natural language tool kit (NLTK) dataset for training the algorithm. This newly implemented application is used to do sentiment analysis on “twitter” (a social networking application) real-time data. Its experimental results are also presented in this paper. The results/analysis can help big brands, companies, and governments in planning future activities.",
        "DOI": "10.1007/978-981-15-2071-6_60",
        "paper_author": "Amrutphale Y.",
        "affiliation_name": "Malwa Institute of Technology",
        "affiliation_city": "Indore",
        "affiliation_country": "India",
        "affiliation_id": "109596356",
        "affiliation_state": "MP"
    },
    {
        "paper_title": "No amount of “AI” in content moderation will solve filtering’s prior-restraint problem",
        "publication": "Big Data and Society",
        "citied_by": "28",
        "cover_date": "2020-01-01",
        "Abstract": "Contemporary policy debates about managing the enormous volume of online content have taken a renewed focus on upload filtering, automated detection of potentially illegal content, and other “proactive measures”. Often, policymakers and tech industry players invoke artificial intelligence as the solution to complex challenges around online content, promising that AI is a scant few years away from resolving everything from hate speech to harassment to the spread of terrorist propaganda. Missing from these promises, however, is an acknowledgement that proactive identification and automated removal of user-generated content raises problems beyond issues of “accuracy” and overbreadth--problems that will not be solved with more sophisticated AI. In this commentary, I discuss how the technical realities of content filtering stack up against the protections for freedom of expression in international human rights law. As policymakers and companies around the world turn to AI for communications governance, it is crucial that we recall why legal protections for speech have included presumptions against prior censorship, and consider carefully how proactive content moderation will fundamentally re-shape the relationship between rules, people, and their speech.",
        "DOI": "10.1177/2053951720920686",
        "paper_author": "Llansó E.J.",
        "affiliation_name": "Center for Democracy &amp; Technology",
        "affiliation_city": null,
        "affiliation_country": "United States",
        "affiliation_id": "117372732",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Analysis of vocational education and training and the labour market in catalonia. A data-driven approach",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we introduce BDFP, an ongoing project developed by the Big Data Center of Excellence of Barcelona which aims at analysing the Vocational Education and Training (VET) and its demand in the labour market. The main contribution of the project is the development of a data science-based solution to assist policymakers to design effective policies that help on building the bridge between the VET educational system and the labour demand. The project combines data sources from both the job market and educational domains, leveraging machine learning for breaking the existing information silos and develop a set of visualisations, reports and dashboards that enable the combined study of both the VET and the jobs market. The present article describes the process of inception and development of the tools and details preliminary results that are currently being analysed together with domain experts of both fields. The final results will be compiled in a final report that will be publicly available.",
        "DOI": "10.1007/978-3-030-43823-4_42",
        "paper_author": "Mena J.",
        "affiliation_name": "Eurecat, Technology Centre of Catalonia",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain",
        "affiliation_id": "60108713",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Temporal Graph Traversals Using Reinforcement Learning with Proximal Policy Optimization",
        "publication": "IEEE Access",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "Graphs in real-world applications are dynamic both in terms of structures and inputs. Information discovery in such networks, which present dense and deeply connected patterns locally and sparsity globally can be time consuming and computationally costly. In this paper we address the shortest path query in spatio-temporal graphs which is a fundamental graph problem with numerous applications. In spatio-temporal graphs, shortest path query classical algorithms are insufficient or even flawed because information consistency can not be guaranteed between two timestamps and path recalculation is computationally costly. In this work, we address the complexity and dynamicity of the shortest path query in spatio-temporal graphs with a simple, yet effective model based on Reinforcement Learning with Proximal Policy Optimization. Our solution simplifies the problem by decomposing the spatio-temporal graph in two components: a static and a dynamic sub-graph. The static graph, known and immutable, is efficiently solved with A^{*} algorithm. The sub-graphs interconnecting the static graph have unknown dynamics and we address such issue by estimating the unknown dynamic portion of the graph as a Markov Chain which correlates the observations of the agents in the environment and the path to be followed. We then derive an action policy through Proximal Policy Optimization to select the local optimal actions in the Markov Process that will lead to the shortest path, given the estimated system dynamics. We evaluate the system in a simulation environment constructed in Unity3D. In partially structured and unknown environments, with variable environment parameters we've obtained an efficiency 75% greater than the comparable deterministic solution.",
        "DOI": "10.1109/ACCESS.2020.2985295",
        "paper_author": "Silva S.H.",
        "affiliation_name": "The University of Texas at San Antonio",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States",
        "affiliation_id": "60003212",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Defender Vs Attacker Security Game Model for an Optimal Solution to Co-resident DoS Attack in Cloud",
        "publication": "Lecture Notes on Data Engineering and Communications Technologies",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Virtual Machines (VM) are considered as the fundamental components to cloud computing systems. Though VMs provide efficient computing resources, they are also exposed to several security threats. While some threats are easy to block, some attacks such as co-resident attacks are much harder even to detect. This paper proposes Defender Vs Attacker Security Game Model otherwise called Two-Player security game approach based defense mechanism for minimizing the Co-resistance DOS attacks by making it hard for intruders to initiate attacks. The proposed defense mechanism first analyzes the attacker behavior difference between attacker and normal users under PSSF VM allocation policy. Then the clustering analysis is performed by EDBSCAN (Enhanced Density-based Spatial Clustering of Applications with Noise). The partial labeling is done depending on the clustering algorithm to partially distinguish the users as legal or malicious. Then the semi-supervised learning using Deterministic Annealing Semi-supervised SVM (DAS3VM) optimized by branch and bounds method is done to classify the nodes. Once the user accounts are classified, the two-player security game approach is utilized to increase the cost of launching new VMs thus minimizing the probability of initiating co-resident DOS attack.",
        "DOI": "10.1007/978-3-030-28364-3_54",
        "paper_author": "Rethishkumar S.",
        "affiliation_name": "Mahatma Gandhi University",
        "affiliation_city": "Kottayam",
        "affiliation_country": "India",
        "affiliation_id": "60029694",
        "affiliation_state": "KL"
    },
    {
        "paper_title": "Enhancing multi-level cache performance using dynamic R-F characteristics",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Cache memory or CPU memory is a high-speed static random access memory that a computer microprocessor can access more quickly than it can access regular random access memory. Hence, the high-performance cache memory is used to bridge the performance gap between the processor and main memory. Multi-level caches refer to a type of memory hierarchy which uses memory stores with different access speed to cache data. Our proposed work uses combination of different tuning algorithms considering the R-F characteristics of page to provide an efficient solution for cache replacement in multi-level cache hierarchy which has an easy implementation and a better performance compared to traditional cache replacement policies like clock with adaptive replacement (CAR), least recently used (LRU), and first in, first out (FIFO) on a cache of equivalent size.",
        "DOI": "10.1007/978-981-15-1884-3_26",
        "paper_author": "Motwani A.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India",
        "affiliation_id": "60099671",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "A Review on Security Attacks and Protective Strategies of Machine Learning",
        "publication": "Lecture Notes on Data Engineering and Communications Technologies",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "Machine learning is the powerful techniques in computing and Linguistics Science. It is broadly applied in various domains such as computer vision, pattern recognition, image processing, network security and Natural language processing. Machine learning (ML) techniques have generated huge social impacts in a variety of applications such as malware detection, spam detection and health care. It is also more sensitive towards security attack. In supervised learning algorithm Machine Learning Models mainly depend upon the large input datasets, called training data and testing data. The slight modifications in the input data will affect the model performance to a greater extent. Many research works have been carried out by analysing various security threats against ML algorithms such as Naïve Bayes Algorithm, Decision tree, Support Vector Machine and Artificial Deep Neural Networks. In this paper, we have explained taxonomy of security threats happened in training and testing stage of learning. Finally we have presented various defending techniques, counter measures which are used in training and testing phases, few security policies to prevent adversarial attacks and make a robust Machine Learning model.",
        "DOI": "10.1007/978-3-030-32150-5_109",
        "paper_author": "Meenakshi K.",
        "affiliation_name": "SRM Institute of Science and Technology",
        "affiliation_city": "Kattankulathur",
        "affiliation_country": "India",
        "affiliation_id": "60014340",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Mobile device transmission security policy decision making using PROMETHEE",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "This paper focuses on the brand of mobile devices having the better quality transmission security policy available in the market as per the need of the customers. However, the criteria for each brand of the mobile device have its own functions. So, to choose the reasonable one among accessible options is a challenge and leads to decision-making issues. These issues might be tended to by multiple-criteria decision-making (MCDM) approach. PROMETHEE is one of the decision-making processes that encourage clients to choose the appropriate option depending on their own observation and the criteria they take into consideration. The experiment has been performed based on the feedback provided and the outcome is recorded.",
        "DOI": "10.1007/978-981-15-1884-3_1",
        "paper_author": "Samantraj S.",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India",
        "affiliation_id": "60079452",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Machine Learning Methods Applications for Estimating Unevenness Level of Regional Development",
        "publication": "Lecture Notes on Data Engineering and Communications Technologies",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The article deals with the issues of regional socio-economic development. Particular attention is paid to the estimation and analysis of the level of unevenness on different levels of hierarchy. Some international ratings of countries are considered and the place of Ukraine is determined. It is proved that the relatively low position of the country is determined by lots of different external and internal factors, but one of the most significant ones is the regional unevenness of development. From the other hand existing disparities in the development of particular regions can play the role of incentives and to contribute to the improvement of the situation in the country. The crucial condition of such improvement is high-quality and grounded control signals. Implementation of inefficient control signals may deepen the gaps between the levels of regional development. The main aim of the research is to construct the complex of models for estimation and forecasting the unevenness level of social and economic development of regions. The complex is based on methods of modeling of multidimensional objects. The proposed models are united in three consecutive blocks. The aim of the fist block is to conduct a priory analysis of the initial set of socio-economic indicators and to form the representative indicator system. The second block applies methods of multidimensional analysis. The third block represents models of forecasting of the structural components of the unevenness level. The proposed models should be implemented in the decision-making process and to became the foundation for efficient regional socio-economic policy.",
        "DOI": "10.1007/978-3-030-35649-1_6",
        "paper_author": "Chagovets L.",
        "affiliation_name": "Simon Kuznets Kharkiv National University of Economics",
        "affiliation_city": "Kharkiv",
        "affiliation_country": "Ukraine",
        "affiliation_id": "60104362",
        "affiliation_state": "Kharkiv Oblast"
    },
    {
        "paper_title": "Pursuit-evasion with Decentralized Robotic Swarm in Continuous State Space and Action Space via Deep Reinforcement Learning",
        "publication": "ICAART 2020 - Proceedings of the 12th International Conference on Agents and Artificial Intelligence",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper we address the pursuit-evasion problem using deep reinforcement learning techniques. The goal of this project is to train each agent in a swarm of pursuers to learn a control strategy to capture the evaders in optimal time while displaying collaborative behavior. Additional challenges addressed in this paper include the use of continuous agent state and action spaces, and the requirement that agents in the swarm must take actions in a decentralized fashion. Our technique builds on the actor-critic model-free Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm that operates over continuous spaces. The evader strategy is not learned and is based on Voronoi regions, which the pursuers try to minimize and the evader tries to maximize. We assume global visibility of all agents at all times. We implement the algorithm and train the models using Python Pytorch machine learning library. Our results show that the pursuers can learn a control strategy to capture evaders.",
        "DOI": "NA",
        "paper_author": "Singh G.",
        "affiliation_name": "Naval Air Warfare Cent",
        "affiliation_city": "Indianapolis",
        "affiliation_country": "United States",
        "affiliation_id": "100331334",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Reinforcement learning in the load balancing problem for the IFDAQ of the COMPASS experiment at CERN",
        "publication": "ICAART 2020 - Proceedings of the 12th International Conference on Agents and Artificial Intelligence",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Currently, modern experiments in high energy physics impose great demands on the reliability, efficiency, and data rate of Data Acquisition Systems (DAQ). The paper deals with the Load Balancing (LB) problem of the intelligent, FPGA-based Data Acquisition System (iFDAQ) of the COMPASS experiment at CERN and presents a methodology applied in finding optimal solution. Machine learning approaches, seen as a subfield of artificial intelligence, have become crucial for many well-known optimization problems in recent years. Therefore, algorithms based on machine learning are worth investigating with respect to the LB problem. Reinforcement learning (RL) represents a machine learning search technique using an agent interacting with an environment so as to maximize certain notion of cumulative reward. In terms of RL, the LB problem is considered as a multi-stage decision making problem. Thus, the RL proposal consists of a learning algorithm using an adaptive ε-greedy strategy and a policy retrieval algorithm building a comprehensive search framework. Finally, the performance of the proposed RL approach is examined on two LB test cases and compared with other LB solution methods.",
        "DOI": "NA",
        "paper_author": "Šubrt O.",
        "affiliation_name": "Czech Technical University in Prague",
        "affiliation_city": "Prague",
        "affiliation_country": "Czech Republic",
        "affiliation_id": "60013323",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting Road Deaths in Malaysia Using Support Vector Machine",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "An average of 6,350 people died every year in Malaysia due to road traffic accidents. A published data of Malaysian road deaths in 20 years since 1997 reveals that the number of fatalities has not really declined with a difference of less than 10% from one year to the next. Forecasting the number of fatalities is beneficial in planning a countermeasure to bring down the death toll. A predictive model of Malaysian road death has been developed using a time-series model known as autoregressive integrated moving average (ARIMA). The model was used in the previous Road Safety Plan of Malaysia to set a target death toll to be reduced in 2020, albeit being inaccurate. This study proposes a new approach in forecasting the road deaths, by means of a machine learning algorithm known as Support Vector Machine. The length of various types of road, number of registered vehicles and population were among the eight features used to develop the model. Comparison between the actual road deaths and the prediction demonstrates a good agreement, with a mean absolute percentage error of 2% and an R-squared value of 85%. The Linear kernel-based Support Vector Machine was found to be able to predict the road deaths in Malaysia with reasonable accuracy. The developed model could be used by relevant stakeholders in devising appropriate policies and regulations to reduce road fatalities in Malaysia.",
        "DOI": "10.1007/978-981-15-2317-5_22",
        "paper_author": "Radzuan N.Q.",
        "affiliation_name": "Universiti Malaysia Pahang Al-Sultan Abdullah",
        "affiliation_city": "Pekan",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090654",
        "affiliation_state": "Pahang"
    },
    {
        "paper_title": "Epidemiology of Breast Cancer (BC) and Its Early Identification via Evolving Machine Learning Classification Tools (MLCT)–A Study",
        "publication": "Learning and Analytics in Intelligent Systems",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Now a day Breast cancer (BC) is very common and terrific disease in women, most detected and second leading cause of the ladies’ demise from the worldwide. Big number of people is passing their life or poor survival rate is because of this disease every year. Females are at high risk of BC, so it became quite essential and necessary for doctors to choose for an exact and suitable treatment for avoidance and remedy of cancer patients. So the basic motive is to find the cancer cells very correctly. Forecasting and categorization of BC using an effective and correct model of machine learning (ML) is essential for creation a new type of BC prognostic and diagnostic policies that really give a reduction push to the sufferer. Diversified technology, including Bayesian classifiers, Artificial Neural Networks and Decision Trees have been commonly applied in cancerous tumor. Undoubtedly methods used for Machine Learning may increase our understanding about breast cancer prediction and progression. It is important to consider these approaches in daily clinical practice. Neural networks are now a day’s very key and popular field in computational biology, chiefly in the area of radiology, oncology, cardiology and urology. In this study, we had summarized numerous ML techniques which could be used as an important tool by surgeons for timely detection, and prediction of cancerous cells has been studied and introduced.",
        "DOI": "10.1007/978-3-030-39033-4_11",
        "paper_author": "Maurya R.K.",
        "affiliation_name": "Sam Higginbottom University of Agriculture, Technology and Sciences",
        "affiliation_city": "Prayagraj",
        "affiliation_country": "India",
        "affiliation_id": "60076016",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Hindsight reward shaping in deep reinforcement learning",
        "publication": "2020 International SAUPEC/RobMech/PRASA Conference, SAUPEC/RobMech/PRASA 2020",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Recent developments in the field of deep reinforcement learning (DRL) have shown that reinforcement learning (RL) techniques are able to solve highly complex problems by learning an optimal policy for autonomous control tasks. Although RL shows great promise in sequential decision-making problems in dynamic environments, there are still caveats associated with the framework. One such pitfall is the time taken to converge due to sparse and delayed rewards, known as the temporal credit assignment problem in RL. This paper addresses the problem by introducing a simple yet effective method of distributing the discounted terminal state reward backwards in time for episodic environments after an episode has reached terminal state. The shaped reward transitions are then added to the experience replay buffer.",
        "DOI": "10.1109/SAUPEC/RobMech/PRASA48453.2020.9041058",
        "paper_author": "De Villiers B.",
        "affiliation_name": "University of Johannesburg",
        "affiliation_city": "Johannesburg",
        "affiliation_country": "South Africa",
        "affiliation_id": "60000717",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "Leveraging digital data to inform and improve quality cancer care",
        "publication": "Cancer Epidemiology Biomarkers and Prevention",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Efficient capture of routine clinical care and patient outcomes is needed at a population-level, as is evidence on important treatment-related side effects and their effect on well-being and clinical outcomes. The increasing availability of electronic health records (EHR) offers new opportunities to generate populationlevel patient-centered evidence on oncologic care that can better guide treatment decisions and patient-valued care. Methods: This study includes patients seeking care at an academic medical center, 2008 to 2018. Digital data sources are combined to address missingness, inaccuracy, and noise common to EHR data. Clinical concepts were identified and extracted from EHR unstructured data using natural language processing (NLP) and machine/ deep learning techniques. All models are trained, tested, and validated on independent data samples using standard metrics. Results: We provide use cases for using EHR data to assess guideline adherence and quality measurements among patients with cancer. Pretreatment assessment was evaluated by guideline adherence and quality metrics for cancer staging metrics. Our studies in perioperative quality focused on medications administered and guideline adherence. Patient outcomes included treatment-related side effects and patient-reported outcomes. Conclusions: Advanced technologies applied to EHRs present opportunities to advance population-level quality assessment, to learn from routinely collected clinical data for personalized treatment guidelines, and to augment epidemiologic and population health studies. The effective use of digital data can inform patient-valued care, quality initiatives, and policy guidelines. Impact: A comprehensive set of health data analyzed with advanced technologies results in a unique resource that facilitates wide-ranging, innovative,and impactful researchon prostate cancer. This work demonstrates new ways to use the EHRs and technology to advance epidemiologic studies and benefit oncologic care.",
        "DOI": "10.1158/1055-9965.EPI-19-0873",
        "paper_author": "Hernandez-Boussard T.",
        "affiliation_name": "Stanford University School of Medicine",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60032838",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A Novel Restricted Boltzmann Machine Training Algorithm with Fast Gibbs Sampling Policy",
        "publication": "Mathematical Problems in Engineering",
        "citied_by": "14",
        "cover_date": "2020-01-01",
        "Abstract": "The restricted Boltzmann machine (RBM) is one of the widely used basic models in the field of deep learning. Although many indexes are available for evaluating the advantages of RBM training algorithms, the classification accuracy is the most convincing index that can most effectively reflect its advantages. RBM training algorithms are sampling algorithms essentially based on Gibbs sampling. Studies focused on algorithmic improvements have mainly faced challenges in improving the classification accuracy of the RBM training algorithms. To address the above problem, in this paper, we propose a fast Gibbs sampling (FGS) algorithm to learn the RBM by adding accelerated weights and adjustment coefficient. An important link based on Gibbs sampling theory was established between the update of the network weights and mixing rate of Gibbs sampling chain. The proposed FGS method was used to accelerate the mixing rate of Gibbs sampling chain by adding accelerated weights and adjustment coefficients. To further validate the FGS method, numerous experiments were performed to facilitate comparisons with the classical RBM algorithm. The experiments involved learning the RBM based on standard data. The results showed that the proposed FGS method outperformed the CD, PCD, PT5, PT10, and DGS algorithms, particularly with respect to the handwriting database. The findings of our study suggest the potential applications of FGS to real-world problems and demonstrate that the proposed method can build an improved RBM for classification.",
        "DOI": "10.1155/2020/4206457",
        "paper_author": "Wang Q.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Machine learning supported next-maintenance prediction for industrial vehicles",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Industrial and construction vehicles require tight periodic maintenance operations. Their schedule depends on vehicle characteristics and usage. The latter can be accurately monitored through various on-board devices, enabling the application of Machine Learning techniques to analyze vehicle usage patterns and design predictive analytics. This paper presents a data-driven application to automatically schedule the periodic maintenance operations of industrial vehicles. It aims to predict, for each vehicle and date, the actual remaining days until the next maintenance is due. Our Machine Learning solution is designed to address the following challenges: (i) the non-stationarity of the per-vehicle utilization time series, which limits the effectiveness of classic scheduling policies, and (ii) the potential lack of historical data for those vehicles that have recently been added to the fleet, which hinders the learning of accurate predictors from past data. Preliminary results collected in a real industrial scenario demonstrate the effectiveness of the proposed solution on heterogeneous vehicles. The system we propose here is currently under deployment, enabling further tests and tunings.",
        "DOI": "NA",
        "paper_author": "Mishra S.",
        "affiliation_name": "Politecnico di Torino",
        "affiliation_city": "Turin",
        "affiliation_country": "Italy",
        "affiliation_id": "60012162",
        "affiliation_state": "TO"
    },
    {
        "paper_title": "Increased carbon uptake and water use efficiency in global semi-arid ecosystems",
        "publication": "Environmental Research Letters",
        "citied_by": "59",
        "cover_date": "2020-01-01",
        "Abstract": "The semi-arid ecosystems dominate the inter-annual variability of the global carbon sink and the driving role of semi-arid ecosystems is becoming increasingly important. However, the impacts of climate change on the dynamics of carbon and water fluxes in global semi-arid ecosystems are still not well understood. We used a data-driven (or machine learning) approach, along with observations from a number of FLUXNET sites and spatially continuous satellite and meteorological data, to generate gridded carbon and water flux estimates for semi-arid regions globally, and then examined the magnitude, spatial patterns, and trends of carbon and water fluxes and their responses to climate change during the period 1982-2015. The average annual gross primary productivity (GPP), net ecosystem productivity (NEP), evapotranspiration (ET), and water use efficiency (WUE) were 628.6 g C m-2 yr-1, 9.6 g C m-2 yr-1, 463.1 mm yr-1, and 1.60 g C Kg-1 H2O, respectively. The climate conditions during the period 1982-2015 enhanced gross and net carbon uptake in global semi-arid regions. The spatially-averaged annual GPP, NEP, ET, and WUE in semi-arid regions showed significant increases both globally and regionally (Asia, Africa, and Australia). As with GPP and ET, WUE significantly increased in North America, Asia, Africa, and Australia. Australia was the most sensitive semi-arid region in terms of changes in carbon and water fluxes and their responses to climate. Semi-arid forests, shrublands, and savannas were net carbon sinks; croplands were minor carbon sources; grasslands were nearly carbon neutral. Overall, precipitation was the most important climate factor influencing the carbon and water fluxes; WUE in 40.9% of the semi-arid region was significantly influenced by precipitation. The global climate change is expected to influence global semi-arid ecosystems in many ways and our findings have implications for semi-arid ecosystem management and policy making.",
        "DOI": "10.1088/1748-9326/ab68ec",
        "paper_author": "Zhang L.",
        "affiliation_name": "Aerospace Information Research Institute",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60273019",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Design and Evaluation of a Reliable Low-Cost Atmospheric Pollution Station in Urban Environment",
        "publication": "IEEE Access",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "The pollution of the air constitutes an environmental risk to health, crops, animals, forests and water. There are several policies for reducing air pollution regarding industry, energy, transportation, and agriculture. Unfortunately, there is limited monitoring of the air quality in cities and rural areas for supervising the accomplishment of these policies. Reliable monitoring of air pollutants is, typically, based on expensive fixed stations, which constitutes a barrier to tackle. This research presents the design, implementation and evaluation of a small, low-cost, station for monitoring atmospheric pollution. The prototype registers ozone ( O_{3} ) and carbon monoxide ( CO ) using inexpensive sensors. To assure high reliability of the measurements obtained by the sensors installed in this station, it is proposed a calibration procedure based on the selection of the best performance analysis of the following machine learning techniques: multiple linear regression, artificial neural networks, and random forest. Additionally, a decision rule is implemented to select an optimal combination of sensors for the estimation models, while the sample timestamp is considered as a temporal heuristic at the input of the system, assuming similarities in the daily environmental dynamics. In order to test the station in a realistic scenario, the calibration and evaluation sets were taken in two different time frames of one and two months, respectively. The overall process was implemented with reference data coming from a certified air quality fixed station in the city of Cuenca - Ecuador. Experimental results showed that the real-time reports of ozone provided by the prototype are quite similar to the fixed station during the evaluation period, with a resulting correlation of up to r=0.92 and r=0.91 in the calibration and evaluation set, respectively. However, signal drift and aging in CO_{x} sensors diminished the accuracy of carbon monoxide calibration models, resulting in lower correlation ( r leq 0.76 ) with the evaluation set.",
        "DOI": "10.1109/ACCESS.2020.2980736",
        "paper_author": "Astudillo G.D.",
        "affiliation_name": "Tecnológico de Monterrey",
        "affiliation_city": "Monterrey",
        "affiliation_country": "Mexico",
        "affiliation_id": "60007966",
        "affiliation_state": "NLE"
    },
    {
        "paper_title": "Distributed Training in Access Control Model",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Classification and regression prediction of access objects in distributed access control model is a very important basic task in distributed access control model. Machine learning plays an important role in the field of intelligent access control in the future, especially in the application of machine learning methods to solve classification and regression problems. The paper proposes a learning method of distributed collaborative training, which can reduce the communication consumption of node policy update and increase the access execution margin of a single node. Improve model performance.",
        "DOI": "10.1007/978-981-15-3250-4_116",
        "paper_author": "Cai F.",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022281",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Asynchronous Advantage Actor-Critic with Double Attention Mechanisms",
        "publication": "Jisuanji Xuebao/Chinese Journal of Computers",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, deep reinforcement learning (DRL), which combines deep learning and reinforcement learning together, is a new research hotspot in artificial intelligence. As DRL takes advantage of deep learning, it is able to take raw images as input, which extends applications of reinforcement learning. At the mean while time, DRL retains the advantages of reinforcement learning in application such as intelligent policy decision or robotic control. However, traditional DRL such as deep Q-network (DQN) or double deep Q-network (DDQN), could hardly deal with complex tasks with high-dimensional state in a short time. Researchers have proposed many methods to solve this problem, and asynchronous advantage actor-critic (A3C) is one of the most used algorithm. As we know, traditional asynchronous deep reinforcement learning can use multi-threading techniques to reduce large amounts of training time. However, when it comes to high-dimensional large-state space tasks, some valuable and important image areas and features are often ignored, such as Atari 2600 games. The reason is that Agent's attention is focused on the entire input image and all features of the image, without any emphases on some important features. To handle this problem, we employ the attention mechanism to ameliorate the performance of traditional asynchronous deep reinforcement learning models. In recent years, inspired by human vision, the attention mechanism has been extensively used in machine translation, image recognition and speech recognition, becoming one of the most noteworthy and in-depth research techniques in the area of deep learning technologies. Based on this, we put forward an asynchronous advantage actor-critic with double attention mechanisms (DAM-A3C). In DAM-A3C, there are two main characteristics: visual attention mechanism(VAM) and feature attention mechanism(FAM). First, the application of visual attention mechanism can enable Agent to adaptively engage in the image region, especially in those more important areas which can enhance the cumulative reward at each moment, reducing the computational cost of the network's training and finally accelerating the process of learning the approximate optimal strategy. Second, via the exertion of FAM, an asynchronous advantage actor-critic is expected to pay more attention to those features with more value. What we know is that different convolution kernels can generate different feature maps by operating convolution on the image in convolutional neural network. And feature maps completely describe the image from different features. The traditional training of convolutional neural network treats each extracted feature equally, which means all features have the same proportion, instead of different levels of focus according to their value. However, some image features have a crucial role in the description of images, such as color features, shape features and spatial relationship features, etc. In order to alleviate this problem, FAM can assist Agent to converge on feature maps with rich values, which will facilitate Agent to make correct decisions. To sum up, we introduce FAM in VAM-A3C model and propose DAM-A3C model. DAM-A3C utilizes visual attention mechanism and feature attention mechanism to enable Agent to concentrate on the important areas and important features of the image, which advances the network model to recognize important information and key features of the image in a short time. We select some classic Atari 2600 games as experimental objects to evaluate the performance of the new model. The experimental result shows that the new model has better performance than the traditional asynchronous advantage actor-critic algorithm in experimental tasks.",
        "DOI": "10.11897/SP.J.1016.2020.00093",
        "paper_author": "Ling X.H.",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China",
        "affiliation_id": "60010432",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Twin Security Model—A Machine Learning-Based Approach for DDoS Attack Detection in SDN",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In the world of emerging network technologies, the software-defined network (SDN) architecture provides the global view of the entire network. Its agility and directly programming ability helped the administrators to dynamically adjust the network, so that whenever required the flow of the traffic can be directed to meet the changing needs of the network and also enhances the security perspective. SDN architecture actively monitors the incoming and outgoing traffic and identifies the threats to further enhance modification or addition of security policies by the administrator. Decoupling of control plane and data plane in SDN increased the attack perspective for the attackers (i.e., DDoS attack, replay attack, man-in-the-middle attack, overloading, etc.). This paper proposes a “twin security model” based on machine learning which amalgamates the two techniques so that the security performance with respect to detection rate will be improved.",
        "DOI": "10.1007/978-981-15-2475-2_6",
        "paper_author": "Singh S.",
        "affiliation_name": "Pondicherry University",
        "affiliation_city": "Puducherry",
        "affiliation_country": "India",
        "affiliation_id": "60013919",
        "affiliation_state": "PY"
    },
    {
        "paper_title": "14th International Conference on Risks and Security of Internet and Systems, CRiSIS 2019",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 24 papers. The special focus in this conference is on Risks and Security of Internet and Systems. The topics include: WPA3 Connection Deprivation Attacks; An Approach for Thwarting Malicious Secret Channel: The Case of IP Record Route Option Header-Based Covert Channels; toward Ciphertext Policy Attribute Based Encryption Model: A Revocable Access Control Solution in Cloud Computing; A Framework for GDPR Compliance in Big Data Systems; “I do it because they do it”: Social-Neutralisation in Information Security Practices of Saudi Medical Interns; unsupervised Machine Learning for Card Payment Fraud Detection; intrusion Detection Study and Enhancement Using Machine Learning; watch Out! Doxware on the Way..; CDISS-BEMOS: A New Color Document Image Steganography System Based on Beta Elliptic Modeling of the Online Signature; an Industrial Trial of an Approach to Identification and Modelling of Cybersecurity Risks in the Context of Digital Secondary Substations; A Graph Based Model for UAVs Group-Wide Collaboration Applied on an Anti-terrorism Scenario; modelling and Executing Time-Aware Processes in Trustless Blockchain Environment; Multi-scale Adaptive Threshold for DDoS Detection; a Recommender System for User-Specific Vulnerability Scoring; distributed Detection System Using Wavelet Decomposition and Chi-Square Test; continuous Risk Management for Industrial IoT: A Methodological View; systematic Asset Identification and Modeling During Requirements Engineering; inference Control in Distributed Environment: A Comparison Study; MAPPER: Mapping Application Description to Permissions; Delegation of Computation Using FV Cryptosystem; Hardware Optimization on FPGA for the Modular Multiplication in the AMNS Representation; a Semantic Framework with Humans in the Loop for Vulnerability-Assessment in Cyber-Physical Production Systems.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Interactive Skill Based Labor Market Mechanics and Dynamics Analysis System Using Machine Learning and Big Data",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "Interest in talent recognition, talent recruitment, education and labor mobility has been on the rise in last years. Business sector is changing its human resources (HR) policies globally, changing ways in policies and practices related to employee management and employer branding. The process of talent recognition and/or search was mostly manual work, often carried by professional agencies or HR officer in organization. In today’s challenging labor market environment, this process is inefficient and slow with and often limited in success. In this paper we are focused on skills, education and lifelong learning domain which has an important role in the 10 priorities of the European Commission (EC) 2014–2019. Our starting point was to look for machine learning and big data techniques to support the policy makers and analysts in reducing mismatch between jobs and skills at regional level in the European Union (EU) through the use of data. Our research includes massive semi structured resume dataset (50+ million documents) combined with several official statistical surveys. We were able to leverage the advances in machine learning and big data to automate resume/skill classification and to improve productivity in skill-based labor market mechanics and dynamics analysis. This paper proposes a model of extracting important information after resumes are being partially classified, classify skills using European multilingual classification of Skills, Competences, Qualifications and Occupations (ESCO) by skill pillar matching and use modern interactive visualization tools to gain smart insights powered by geospatial and time-series analysis. Research goals are to point attention towards data science and machine learning and its usage in labor and educational market mechanics and dynamics.",
        "DOI": "10.1007/978-981-15-3380-8_44",
        "paper_author": "Mrsic L.",
        "affiliation_name": "Algebra University",
        "affiliation_city": "Zagreb",
        "affiliation_country": "Croatia",
        "affiliation_id": "60282550",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Routing in congested baggage handling systems using deep reinforcement learning",
        "publication": "Integrated Computer-Aided Engineering",
        "citied_by": "25",
        "cover_date": "2020-01-01",
        "Abstract": "The increasing number of people choosing to travel by airplane puts pressure on the baggage handling systems in airports. As the load increases, the risk of deadlocks in the systems increase as well. Therefore, it is increasingly important to find routing solutions which can handle the high loads. Currently this is achieved by using shortest path algorithms and hand engineered site-specific routing rules, based on the experience of the employees and on trial and error processes using complex emulators. This is a time-consuming and costly approach, as every airport needs its own set of routing rules. New development within machine learning, and especially reinforcement learning allows very complex control policies to be found in large environments. This could therefore potentially solve the need of manually creating site-specific routing rules. This paper proposes to use a single global deep reinforcement learning agent to route a fleet of baggage-totes to continuously pick up and deliver baggage in simple yet functionally realistic simulations of baggage handling systems. This is achieved using a Dueling DQN architecture with prioritized experience reply and a multi action approach. Training and testing are performed in three baggage handling system environments of different size and complexity. The results show that by training with a broad distribution of loads, it is possible to get a model, capable of routing in highly congested baggage handling systems. The results also show that the reinforcement learning agent can limit the number of deadlocks up until a higher load than both a static shortest path and a dynamic shortest path method, even if the dynamic shortest path method is using a naive deadlock avoidance add-on.",
        "DOI": "10.3233/ICA-190613",
        "paper_author": "Sørensen R.A.",
        "affiliation_name": "Aarhus Universitet",
        "affiliation_city": "Aarhus",
        "affiliation_country": "Denmark",
        "affiliation_id": "60029616",
        "affiliation_state": "Midtjylland"
    },
    {
        "paper_title": "Imagine all the people",
        "publication": "Biomedical Instrumentation and Technology",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "NA",
        "DOI": "10.2345/0899-8205-54.2.140",
        "paper_author": "Wirth A.",
        "affiliation_name": "MedCrypt",
        "affiliation_city": "San Diego",
        "affiliation_country": "United States",
        "affiliation_id": "123262350",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Taming an Autonomous Surface Vehicle for Path following and Collision Avoidance Using Deep Reinforcement Learning",
        "publication": "IEEE Access",
        "citied_by": "57",
        "cover_date": "2020-01-01",
        "Abstract": "In this article, we explore the feasibility of applying proximal policy optimization, a state-of-the-art deep reinforcement learning algorithm for continuous control tasks, on the dual-objective problem of controlling an underactuated autonomous surface vehicle to follow an a priori known path while avoiding collisions with non-moving obstacles along the way. The AI agent, which is equipped with multiple rangefinder sensors for obstacle detection, is trained and evaluated in a challenging, stochastically generated simulation environment based on the OpenAI gym Python toolkit. Notably, the agent is provided with real-time insight into its own reward function, allowing it to dynamically adapt its guidance strategy. Depending on its strategy, which ranges from radical path-adherence to radical obstacle avoidance, the trained agent achieves an episodic success rate close to 100%.",
        "DOI": "10.1109/ACCESS.2020.2976586",
        "paper_author": "Meyer E.",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway",
        "affiliation_id": "60013141",
        "affiliation_state": "Trondelag"
    },
    {
        "paper_title": "Improving policy-capturing with active learning for real-time decision support",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Thales Research and Technology Canada is developing a decision support system consisting in multiple classification models trained simultaneously online to capture experts’ decision policies based on their previous decisions. The system learns decision patterns from examples annotated by a human expert during a training phase of knowledge capture. Because of the small volume of labeled data, we investigated a machine learning technique called active learning that copes with the dilemma of learning with minimal resources and aims at requesting the most informative samples in a pool given the current models. The current study evaluates the impact of using active learning over an uninformed strategy (e.g., random sampling) in the context of policy capturing to reduce the annotation cost during the knowledge capture phase. This work shows that active learning has potential over random sampling for capturing human decision policies with minimal amount of examples and for reducing annotation cost significantly.",
        "DOI": "10.1007/978-3-030-39512-4_28",
        "paper_author": "Chatelais B.",
        "affiliation_name": "Thales Research and Technology Canada",
        "affiliation_city": "Quebec",
        "affiliation_country": "Canada",
        "affiliation_id": "120049398",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Enhanced Skin Condition Prediction through Machine Learning Using Dynamic Training and Testing Augmentation",
        "publication": "IEEE Access",
        "citied_by": "46",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, deep learning has taken the spotlight in automated medical bioimaging. However, the performance of current state-of-the-art score stems primarily from well-tuned parameters and architecture. There is still only limited research focused on dynamic data augmentation, even in the fields of machine learning and computer vision. In this study, we propose a dynamic training and testing augmentation capable of increasing performance significantly. The searching augmentation framework used in this study requires fewer GPU hours than a conventional search algorithm, which needs to train a new model every time augmentation is proposed. Speeding up of the search algorithm is achieved by using Bayesian optimization on a trained model, so we do not have to train a new model every time a new augmentation policy is proposed. The performance of our method is compared with that of a single model and the ensemble model that happens to be the winner of the ISIC 2019 challenge. Furthermore, we use the latest compact yet significantly accurate network architecture EfficientNet as the backbone system. Our method delivers a superior result, and this study also shares the searched augmentation policy utilized, which requires extraordinary resources. Thus, other researchers can use the searched augmentation policies for dermoscopic images to improve performance.",
        "DOI": "10.1109/ACCESS.2020.2976045",
        "paper_author": "Putra T.A.",
        "affiliation_name": "National Taiwan University of Science and Technology",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60027709",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement Learning for Inventory Management",
        "publication": "Lecture Notes in Mechanical Engineering",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "The decision of “how much to order” at each stage of the supply chain is a major task to minimize inventory costs. Managers tend to follow particular ordering policy seeking individual benefit which hampers the overall performance of the supply chain. Major findings from the literature show that, with the advent of machine learning and artificial intelligence, the trend in this area has been heading from simple base stock policy to intelligence-based learning algorithms to gain near-optimal solution. This paper initially focuses on formulating a multi-agent four-stage serial supply chain as reinforcement learning (RL) model for ordering management problem. In the final step, RL model for a single-agent supply chain is optimized using Q-learning algorithm. The results from the simulations show that the RL model with Q-learning algorithm is found to be better than Order-Up-To policy and 1–1 policy.",
        "DOI": "10.1007/978-981-15-2696-1_85",
        "paper_author": "Bharti S.",
        "affiliation_name": "National Institute of Technology Calicut",
        "affiliation_city": "Kozhikode",
        "affiliation_country": "India",
        "affiliation_id": "60013170",
        "affiliation_state": "KL"
    },
    {
        "paper_title": "Revisited: Machine Intelligence in Heterogeneous Multi-Agent Systems",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Machine-learning techniques have been widely applied for solving decision-making problems. Machine-learning algorithms perform better as compared to other algorithms while dealing with complex environments. The recent development in the area of neural network has enabled reinforcement learning techniques to provide the optimal policies for sophisticated and capable agents. In this paper, we would like to explore some algorithms people have applied recently based on interaction of multiple agents and their components. We would like to provide a survey of reinforcement-learning techniques to solve complex and real-world scenarios.",
        "DOI": "10.1007/978-981-15-1773-0_17",
        "paper_author": "Borah K.J.",
        "affiliation_name": "Toronto Metropolitan University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60030838",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Algorithmic content moderation: Technical and political challenges in the automation of platform governance",
        "publication": "Big Data and Society",
        "citied_by": "441",
        "cover_date": "2020-01-01",
        "Abstract": "As government pressure on major technology companies builds, both firms and legislators are searching for technical solutions to difficult platform governance puzzles such as hate speech and misinformation. Automated hash-matching and predictive machine learning tools – what we define here as algorithmic moderation systems – are increasingly being deployed to conduct content moderation at scale by major platforms for user-generated content such as Facebook, YouTube and Twitter. This article provides an accessible technical primer on how algorithmic moderation works; examines some of the existing automated tools used by major platforms to handle copyright infringement, terrorism and toxic speech; and identifies key political and ethical issues for these systems as the reliance on them grows. Recent events suggest that algorithmic moderation has become necessary to manage growing public expectations for increased platform responsibility, safety and security on the global stage; however, as we demonstrate, these systems remain opaque, unaccountable and poorly understood. Despite the potential promise of algorithms or ‘AI’, we show that even ‘well optimized’ moderation systems could exacerbate, rather than relieve, many existing problems with content policy as enacted by platforms for three main reasons: automated moderation threatens to (a) further increase opacity, making a famously non-transparent set of practices even more difficult to understand or audit, (b) further complicate outstanding issues of fairness and justice in large-scale sociotechnical systems and (c) re-obscure the fundamentally political nature of speech decisions being executed at scale.",
        "DOI": "10.1177/2053951719897945",
        "paper_author": "Gorwa R.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175816",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "A novel virtual resource pricing policy based on game model in federated clouds",
        "publication": "International Journal of Networking and Virtual Organisations",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, more and more cloud providers are unified together to form a federated cloud market, where a suitable pricing strategy plays a key role to help they attracting more users. However, many existing pricing policies can not deal with the competition between different cloud providers. In this study, we take efforts on the resource pricing policy in federated cloud market. To obtain an optimal pricing scheme among multiple IaaS providers (ISPs), we firstly use the learning curve model to model the production supply behaviours of ISPs, and then we use a standard Markov decision process to describe the pricing game model and present an efficient algorithm to solve this game model in a distributed manner. The proposed pricing model has been fully investigated and evaluated in a real-world federated cloud platform, and the results indicate that it can significantly improve the profits of ISPs comparing to several existing pricing mechanisms.",
        "DOI": "10.1504/IJNVO.2020.105515",
        "paper_author": "Tian Y.",
        "affiliation_name": "Hunan Institute of Engineering",
        "affiliation_city": "Xiangtan",
        "affiliation_country": "China",
        "affiliation_id": "60073716",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Measuring impacts of urban environmental elements on housing prices based on multisource data-a case study of Shanghai, China",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "62",
        "cover_date": "2020-01-01",
        "Abstract": "Diverse urban environmental elements provide health and amenity value for residents. People are willing to pay a premium for a better environment. Thus, it is essential to assess the benefits and values of these environmental elements. However, limited by the interpretability of the machine learning model, existing studies cannot fully excavate the complex nonlinear relationships between housing prices and environmental elements, as well as the spatial variations of impacts of urban environmental elements on housing prices. This study explored the impacts of urban environmental elements on residential housing prices based on multisource data in Shanghai. A SHapley Additive exPlanations (SHAP) method was introduced to explain the impacts of urban environmental elements on housing prices. By combining the ensemble learning model and SHAP, the contributions of environmental characteristics derived from street view data and remote sensing data were computed and mapped. The experimental results show that all the urban environmental characteristics account for 16 percent of housing prices in Shanghai. The relationships between housing prices and two green characteristics (green view index from street view data and urban green coverage rate from remote sensing) are both nonlinear. Shanghai's homebuyers are willing to pay a premium for green only when the green view index or urban green coverage rate are of higher value. However, there are significant differences between the impacts of the green view index and urban green coverage rate on housing prices. The sky view index has a negative influence on housing prices, which is probably because the high-density and high-rise residential area often has better living facilities. Residents in Shanghai are willing to pay a premium for high urban water coverage. The case of Shanghai shows that the proposed framework is practical and efficient. This framework is believed to provide a tool to inform the decisions of housing buyers, property developers and policies concerning land-selling and buying, property development and urban environment improvement.",
        "DOI": "10.3390/ijgi9020106",
        "paper_author": "Chen L.",
        "affiliation_name": "Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60019499",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Price discovery and integration in U.S. peanut markets",
        "publication": "Journal of Food Distribution Research",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The United States is a major supplier in the world peanut market. Using grower-level monthly peanut price data from 1982 to 2018, we estimate market integration and price discovery patterns at the grower level by applying causality structures identified through machine-learning algorithms. Preliminary analysis shows that Georgia is a price leader and others are followers in current and lag time. Peanut prices in Texas and Georgia are important determinants of prices in other markets such as North Carolina, Virginia, and Alabama. Findings from this study are useful for peanut producers, marketers, and policy makers designing peanut marketing programs.",
        "DOI": "NA",
        "paper_author": "Hawkins H.",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60020547",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Max-Plus Approach Based Intelligent Coordinated Transmission for Robot Swarms",
        "publication": "IEEE Access",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Communication is vital to complete tasks coordinately for robot swarms. In this paper, we investigate massive MIMO enabled robot swarms. Specifically, for the robot swarms, the transceiver beamforming not only needs to maximize the rate, but also has to restrict the interference on other receivers. Therefore, the transceiver design of robots is critical to optimize the sum-rate performance under the restriction of the interference on the a specific robot. Currently, only exhaustive search is able to provide the optimal solution for the problem, whereas its complexity is unacceptable. In this paper, to address the intractable issue, based on the max-plus approach, we consider each transmitter or receiver as an independent decision agent, and all robots coordinately choose the optimal joint beam combination by max-plus algorithm. In the multi-agent framework, each agent learns the policy of choosing analog beam by reinforcement learning (RL). Furthermore, to improve the learning efficiency of RL and reduce the transmission latency, we exploit the efficient ELM network to replace the deep network of deep RL, and propose a ELM-based RL method to conduct the transmission between robots in robot swarm. Analysis and simulation results reveal that, the proposed method is able to achieve a near-optimal sum-rate performance, while the complexity is acceptable.",
        "DOI": "10.1109/ACCESS.2019.2963039",
        "paper_author": "Zhong S.",
        "affiliation_name": "Ningbo University",
        "affiliation_city": "Ningbo",
        "affiliation_country": "China",
        "affiliation_id": "60031419",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "From predictive to prescriptive analytics",
        "publication": "Management Science",
        "citied_by": "325",
        "cover_date": "2020-01-01",
        "Abstract": "We combine ideas from machine learning (ML) and operations research and management science (OR/MS) in developing a framework, along with specific methods, for using data to prescribe optimal decisions in OR/MS problems. In a departure from other work on data-driven optimization, we consider data consisting, not only of observations of quantities with direct effect on costs/revenues, such as demand or returns, but also predominantly of observations of associated auxiliary quantities. Themain problemof interest is a conditional stochastic optimization problem, given imperfect observations, where the joint probability distributions that specify the problem are unknown. We demonstrate how our proposed methods are generally applicable to a wide range of decision problems and prove that they are computationally tractable and asymptotically optimal under mild conditions, even when data are not independent and identically distributed and for censored observations. We extend these to the case in which some decision variables, such as price, may affect uncertainty and their causal effects are unknown. We develop the coefficient of prescriptiveness P to measure the prescriptive content of data and the efficacy of a policy from an operations perspective. We demonstrate our approach in an inventory management problem faced by the distribution arm of a large media company, shipping 1 billion units yearly. We leverage both internal data and public data harvested from IMDb, Rotten Tomatoes, and Google to prescribe operational decisions that outperform baseline measures. Specifically, the data we collect, leveraged by our methods, account for an 88% improvement as measured by our coefficient of prescriptiveness.",
        "DOI": "10.1287/mnsc.2018.3253",
        "paper_author": "Bertsimas D.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Pretrained convolutional neural network for classifying rice-cropping systems based on spatial and spectral trajectories of Sentinel-2 time series",
        "publication": "Journal of Applied Remote Sensing",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "The rice-cropping system in southern China experienced a major change in the past few decades. Rice-cropping systems not only affect the comprehensive utilization intensity of agricultural resources, food security, and the ecological environment but also reveal the conditions of the agricultural policy, regional economy, and rural labor force. Consequently, accurate detection of rice-cropping systems is an essential issue. We present a method for classifying rice-cropping systems using a pretrained convolutional neural network (CNN) that involves extracting deep features of spatial and spectral trajectories. The study area is a major rice-growing region located in Zhuzhou City, Hunan Province, China. Multitemporal Sentinel-2 satellite images were collected to obtain time series curves of texture (spatial trajectories) and the first derivative vegetation index (spectral trajectories) as inputs of the hierarchical classification model. The classification results of land cover and rice-cropping systems were acquired using the pretrained CNN, and the method achieved overall accuracy of 94.78% and 94.87%, respectively. This method was then compared with the support vector machine (SVM). The accuracy of rice-cropping systems using the pretrained CNN was 7.11% higher than that of the SVM. The adaptability of the model was also investigated using the time series curve in another year with relatively insufficient data. The model obtained satisfactory performance with the overall accuracy of land cover types and rice-cropping systems of 93.52% and 93.23%, respectively. We suggest that the pretrained CNN can improve the accuracy of rice-cropping system mapping by extracting deep features of spatial and spectral trajectories during the rice growth cycle and such method may be applied in other fine crop classifications.",
        "DOI": "10.1117/1.JRS.14.014506",
        "paper_author": "Wang L.",
        "affiliation_name": "School of Information Engineering",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60130028",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Utilizing Deep Learning and RDF to Predict Heart Transplantation Survival",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we describe the conversion of three different heart transplantation data sets to a Resource Description Framework (RDF) representation and how it can be utilized to train deep learning models. These models were used to predict the outcome of patients both pre- and post-transplant and to calculate their survival time. The International Society for Heart & Lung Transplantation (ISHLT) maintains a registry of heart transplantations that it gathers from grafts performed worldwide. The American organization United Network for Organ Sharing (UNOS) and the Scandinavian Scandiatransplant are contributors to this registry, although they use different data models. We designed a unified graph representation covering these three data sets and we converted the databases into RDF triples. We used the resulting triplestore as input to several machine learning models trained to predict different aspects of heart transplantation patients. Recipient and donor properties are essential to predict the outcome of heart transplantation patients. In contrast with the manual techniques we used to extract data from the tabulated files, the RDF triplestore together with SPARQL, enables us to experiment quickly and automatically with different combinations of features sets, to predict the survival, and simulate the effectiveness of organ allocation policies.",
        "DOI": "10.1007/978-3-030-39951-1_11",
        "paper_author": "Medved D.",
        "affiliation_name": "Lunds Universitet",
        "affiliation_city": "Lund",
        "affiliation_country": "Sweden",
        "affiliation_id": "60029170",
        "affiliation_state": "Skane"
    },
    {
        "paper_title": "Predicting Green Consumption Behaviors of Students Using Efficient Firefly Grey Wolf-Assisted K-Nearest Neighbor Classifiers",
        "publication": "IEEE Access",
        "citied_by": "67",
        "cover_date": "2020-01-01",
        "Abstract": "Understanding the green consumption behaviors of college students is highly demanded to update the public and educational policies of universities. For this purpose, this research is devoted to advance an efficient model for identifying prominent features and predicting the green consumption behaviors of college students. The proposed prediction model is based on the K-Nearest Neighbor (KNN) with an effective swarm intelligence method, which is called OBLFA_GWO. The optimization core takes advantage of the firefly algorithm (FA) and opposition-based learning (OBL) to mitigate the immature convergence of the grey wolf algorithm (GWO). In the proposed prediction framework, OBLFA_GWO is utilized to identify influential features. Then, the enhanced KNN model is used to identify the importance and interrelationships of features in samples and construct an effective and stable predictive model for decision support. Five other well-known algorithms are employed to validate the effectiveness of the proposed OBLFA_GWO strategy using 13 benchmark test problems. Also, the non-parametric statistical Wilcoxon sign rank and Friedman tests are conducted to validate the significance of the proposed OBLFA_GWO against other peers. Experimental results indicate that the FA and OBL can significantly boost the core exploratory and exploitative trends of GWO in dealing with the optimization tasks. Also, the OBLFA_GWO-based KNN (OBLFA_GWO-KNN) model is compared with four classical classifiers, such as kernel extreme learning machine (KELM), backpropagation neural network method (BPNN), and random forest (RF) and five advanced feature selection methods in terms of four standard evaluation indexes. The experimental results show that the classification accuracy of the proposed OBLFA_GWO-KNN can reach to 96.334 % on the real-life dataset collected from nine universities. Also, the proposed binary OBLFA_GWO algorithm has improved the classification performance of KNN compared to the other peers. Hopefully, the established adaptive OBLFA_GWO-KNN model can be considered as a useful tool for predicting students' behavior of green consumption.",
        "DOI": "10.1109/ACCESS.2020.2973763",
        "paper_author": "Tang H.",
        "affiliation_name": "Wenzhou University",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China",
        "affiliation_id": "60020224",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Comparative study on crop type classification using support vector machine on UAV imagery",
        "publication": "Lecture Notes in Civil Engineering",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "In Indian agricultural practices, single crop cultivation is rare and uncommon. This poses a real challenge for crop type classification using single date imagery. Site-specific information of crop type is required for agricultural management which includes technologies aiming at productivity and profit while practicing eco-friendly environment. Unmanned Air Vehicles (UAV) are effective image acquisition platforms for many agricultural applications. UAV’s can acquire high levels of spatial details compared to standard remote sensing platforms. Single date RGB imagery of 5 cm spatial resolution obtained from processing the raw data was used for the classification of different types of crop. Traditional pixel-based analysis of remote sensing data results in inaccurate classification due to low spatial resolution, mixed pixels, and crop pattern variability. This can be overcome by using high-resolution UAV data and machine learning methods like Support Vector Machine (SVM). In the present study SVM kernel functions namely linear, sigmoid, radial basis and polynomial function are adopted and compared for mapping the crop types. The classification shows that the radial and sigmoid kernel functions give high accuracy when compared with the rest by performing the accuracy assessment for all four classifiers. These crop classifications are important for greenhouse gas modeling, agrarian policy, and agro-environmental studies.",
        "DOI": "10.1007/978-3-030-37393-1_8",
        "paper_author": "Vasantha V.K.",
        "affiliation_name": "National Institute of Technology, Warangal",
        "affiliation_city": "Warangal",
        "affiliation_country": "India",
        "affiliation_id": "60007886",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Simulation study on the electricity data streams time series clustering",
        "publication": "Energies",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Currently, thanks to the rapid development of wireless sensor networks and network traffic monitoring, the data stream is gradually becoming one of the most popular data generating processes. The data stream is different from traditional static data. Cluster analysis is an important technology for data mining, which is why many researchers pay attention to grouping streaming data. In the literature, there are many data stream clustering techniques, unfortunately, very few of them try to solve the problem of clustering data streams coming from multiple sources. In this article, we present an algorithm with a tree structure for grouping data streams (in the form of a time series) that have similar properties and behaviors. We have evaluated our algorithm over real multivariate data streams generated by smart meter sensors-the Irish Commission for Energy Regulation data set. There were several measures used to analyze the various characteristics of a tree-like clustering structure (computer science perspective) and also measures that are important from a business standpoint. The proposed method was able to cluster the flows of data and has identified the customers with similar behavior during the analyzed period.",
        "DOI": "10.3390/en13040924",
        "paper_author": "Gajowniczek K.",
        "affiliation_name": "Szkola Glówna Gospodarstwa Wiejskiego w Warszawie",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60085173",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Empower good governance with public assessed schemes by improved sentiment analysis accuracy",
        "publication": "Electronic Government",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Many government schemes were unsuccessful because lack of proper feedback on the ongoing schemes, where billion dollars investment is going to be in vain. Sentiment analysis is one of best approach to analyse opinions of the peoples on various government schemes. Sentiment analysis and machine learning techniques emerged to analyse huge social media corpora to track people's views on government policies, products and services. Sentiment analysis process consists of various phases which include data discovery, data collection, data pre-processing, and data analysis. Stemming is a process to generate the morphemes in natural language sentences for various applications such as sentiment analysis, information retrieval, and domain analysis. The stemming process involved two major errors, which are over-stemming and under-stemming errors. Most of sentiment analysis natural languages processing applications used Lancaster and Porter stemming algorithms where more than one word inflected into same morpheme, which causes the etymology behaviour of the stemming word and prone to classify the tweets false positives and false negative. The proposed un-prejudice light stemming algorithm prevent etymology behaviour of morpheme and sustain its meaning during stemming process by selecting a word which has maximum number of synonyms in lexical database.",
        "DOI": "10.1504/EG.2020.105252",
        "paper_author": "Siva Rama Rao A.V.S.",
        "affiliation_name": "Hindustan Institute of Technology and Science",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60107090",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Big data research for social science and social impact",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "This Special Issue of Sustainability devoted to the topic of \"Big Data Research for Social Sciences and Social Impact\" attracted significant attention of scholars, practitioners, and policy-makers from all over the world. Locating themselves at the cross-section of advanced information systems and computer science research and insights from social science and engineering, all papers included in this Special Issue contribute to the debate on the use of big data in social sciences and big data social impact. By promoting a debate on the multifaceted challenges that our societies are exposed to today, this Special Issue offers an in-depth, integrative, well-organized, comparative study into the most recent developments shaping the future directions of interdisciplinary research and policymaking.",
        "DOI": "10.3390/SU12010180",
        "paper_author": "Lytras M.D.",
        "affiliation_name": "The American College of Greece",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece",
        "affiliation_id": "60031663",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "SEPSIS. Educational and best practice frontiers. beyond the boundaries of fatality, enhancing clinical skills and precision medicine",
        "publication": "Therapeutics and Clinical Risk Management",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Dissemination and exploitation of knowledge regarding affordable clinical skills and innovative precision medicine, two current topics in active development in medicine, may contribute to improve also sepsis management. Sepsis is a life-threatening organ dysfunction due to a dysregulated host response to infection. Sepsis is strongly related to all body organs or to systemic diseases and to the quality of the best-practice in use, which is particularly critical in surgical or intervention techniques. Trauma, surgical and mini-invasive procedures, vascular or endoscopic interventions, otolaryngology, obstetrics-gynecological and urological procedures, malnutrition, dental, skin, chronic liver, kidney and respiratory disease are frequently involved. Accordingly, apart from the clinical risk analysis and management of the process of care, the actual factors that may be easily neglected are the techniques used, the personal skills of the health professionals and the quality of the equipment. The quest for biomarkers consistent with the unmet needs of medical doctors and of their patient and the efforts for overcoming bacterial antibiotic resistances are currently the main foci of medical research. In addition, in this regard, research and innovation would benefit from greater knowledge, skills and use of bioinformatics and omics. The caveats related to in-silico approaches must be flagged: algorithms may equally warrant scientific innovations or hide the lack of them; a patient is more than a set of covariates. Epidemiology and prevention includes all the actions suitable for achieving an adequate hygiene and immunization of populations and for safer hospital policies and procedures during Patients’ stays. In any subset, the most unresolved critical point in sepsis is a timely diagnosis. This is impaired by low degrees of suspicion for the possibility of emerging sepsis, by the shortage of use of the simplest microbiological testing but, equally or more, by the insufficient diffusion of non-invasive imaging skills suitable to detect and monitor the emerging sites and sources of infection. In primary care, in emergency facilities, in hospital wards and in intensive care units, inclusion of appropriate knowledge, skills, expertise and imaging equipment must be extended as much as possible. The low cost of UltraSound machines and of increasing bioinformatics literacy by e-learning, makes such investments affordable even in limited-resources contexts. Frontier educational and best practice intervention enhancing affordable clinical skills and innovative precision medicine may lead beyond the boundaries of fatal outcomes in sepsis.",
        "DOI": "10.2147/TCRM.S232530",
        "paper_author": "Trovato G.",
        "affiliation_name": "Università degli Studi di Catania",
        "affiliation_city": "Catania",
        "affiliation_country": "Italy",
        "affiliation_id": "60010146",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Optimizing virtual resource dynamic allocation (OVRDA) and load prediction in cloud computing",
        "publication": "Journal of Advanced Research in Dynamical and Control Systems",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The growth of data storage in a virtual environment is becoming more essential and also the demand on the computation for an optimized performance are increasing in par with the enterprises requirements leads to substantial increase in the power consumption of very large infrastructures. This is resolves with the implementation of cloud storage which saves more energy. This proposed research focus on the different methods for enforcing the cloud storage for effective consumption of energy. Currently, advancement of cloud computing methodology leads huge data center size and network resources are expanding rapidly. According to the minimum migration policy and Virtual Resource Dynamic Integration (VRDI) for energy efficiency, Virtual Machines (VM) selection algorithms were launched. High energy consumption of network resources was drawn by mobile internet development sequentially. Primarily VRDI method doesn’t consider the consequence of the network resources on the energy consumption of a data center and so the proposed work influences the criteria like bandwidth, data size etc. On the other hand, VMs load pattern’s prediction in the VM selection algorithm becomes a tedious process. Extreme Learning Machine (ELM) classifier is proposed for prediction of VMs load pattern in order to rectify this issue. An energy-efficient Optimization Virtual Resource Dynamic Allocation (OVRDA) method is proposed to reduce the energy consumption of a data center. Loading the patterns of the Physical Machines (PMs) and the subsequent thresholds of PMs were computed with the help of the statistical data, in this proposed OVRDA. Another proposed work is, PM selection algorithms based on the Enhanced Firefly Algorithm (Enhanced FA) established a set of PMs which should be incorporated. According to the minimum migration policy to select the VMs, which are installed on the integrated PMs, VM selection algorithm will be executed. According to the enhanced FA, the goal of the VM placement will be confirmed. The experiments report that the proposed OVRDA method reduces the energy consumption of data center and assures the Quality of Service (QoS) of the cloud applications which are established on the VMs.",
        "DOI": "10.5373/JARDCS/V12SP1/20201112",
        "paper_author": "Rajkumar R.",
        "affiliation_name": "Kumaraguru College of Technology",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India",
        "affiliation_id": "60012454",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Prediction of Bitcoin Transactions Included in the Next Block",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "This paper proposes a method to predict transactions that are likely to be included in the next block from the mempool of unconfirmed transactions in the Bitcoin network. To implement the proposed method, we applied machine learning to the transactions data collected from the Bitcoin network and divided our implementation into the following three objects: Data Collector; Data Preprocessor; and Analyzer. We used the random forest classifier algorithm because the problem of predicting the likelihood of a transaction to be included in the next block is a binary classification problem. We evaluated the performance of our model by comparing transactions in the mempool against transaction published in the next two blocks mined at the time of our experiments. For both blocks, our model has a prediction accuracy of more than 80% and a minimal false negative error. The analysis of transaction inclusion in the next block is fundamental as it could drive the price of Bitcoin or signify the properties of a given transaction such as illegal or legal.",
        "DOI": "10.1007/978-981-15-2777-7_48",
        "paper_author": "Ko K.",
        "affiliation_name": "Pohang University of Science and Technology",
        "affiliation_city": "Pohang",
        "affiliation_country": "South Korea",
        "affiliation_id": "60032330",
        "affiliation_state": "Gyeongsangbuk-do"
    },
    {
        "paper_title": "Comparative analysis of tree, meta-learning and function classifiers to predict the atmospheric concentration of NO<inf>2</inf>",
        "publication": "Journal of Environmental Accounting and Management",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "The concentration of airborne pollutants is rising in recent years. Due to serious health effects of NO2, SO2 etc. their constant monitoring is important for the policy makers, as it provides early pollution estimates before it crosses permissible limits set by the state. For air quality modelling, several statistical techniques based on Artificial Neural Networks have been applied, however, Tree and meta-learning based classifiers have rarely been adopted for air pollution prediction purpose. Thus, for this study, Tree (Random Forest, Reduces Error Pruning (REP) Tree), meta-learning (Bagging, Random Subspace) and Function (Multilayer Perceptron and Support Vector Machine) based classifiers have been employed to predict atmospheric concentrations of Nitrogen dioxide (NO2). The study uses 3 atmospheric pollutants; Sulphur dioxide (SO2), Carbon monoxide (CO), and Hydrochloric acid (HCl) and 5 meteorological parameters temperature, humidity, wind speed, wind direction and atmospheric pressure. Moreover, for validation of prediction models the performance of different classifiers were compared. The results obtained suggest that Tree classifiers in general and Random Forest in particular, can outperform Function (MLP and SVM) and meta-learning (Bagging and Random Subspace) classifiers to predict the atmospheric concentration of NO2.",
        "DOI": "10.5890/JEAM.2020.03.003",
        "paper_author": "Masih A.",
        "affiliation_name": "Ural Federal University",
        "affiliation_city": "Yekaterinburg",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60103702",
        "affiliation_state": "Sverdlovskaya"
    },
    {
        "paper_title": "International Symposium on Computer Science, Digital Economy and Intelligent Systems, CSDEIS 2019",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 42 papers. The special focus in this conference is on Computer Science, Digital Economy and Intelligent Systems. The topics include: A Model of Cognitive Disorders upon the Algebra of Fourier-Dual Operations; Intelligent OFDM Telecommunication Systems Based on Many-Parameter Complex or Quaternion Fourier Transforms; vibration Monitoring Systems for Power Equipment as an Analogue of an Artificial Neural Network; Integrated Computer Analysis of Genomic Sequencing Data Based on ICGenomics Tool; statistical and Linguistic Decision-Making Techniques Based on Fuzzy Set Theory; studying the Crack Growth Rate Variability by Applying the Willenborg’s Model to the Markov’s Simulated Trials; creating Spaces of Temporary Features for the Task of Diagnosing Complex Pathologies of Vision; a Modified Particle Swarm Algorithm for Solving Group Robotics Problem; Mathematical Modeling of DC Motors for the Construction of Prostheses; analysis of Diagnostic Signs of Defective States of Mechatronic Mechanisms of Cyclic Action; development and Performance Evaluation of a Software System for Multi-objective Design of Strain Gauge Force Sensors; optimization of the Structure of the Intelligent Active System as a Necessary Condition for the Harmonization of Creative Solutions; parallel Hybrid Genetic Algorithm for Solving Design and Optimization Problems; optimal Real-Time Image Processing with Imperfect Information on Convolution-Type Distortion; scalability and Parallelization of Sequential Processing: Big Data Demands and Information Algebras; aggregate Estimates for Probability of Social Engineering Attack Success: Sustainability of the Structure of Access Policies; a Machine Learning Approach to the Vector Prediction of Moments of Finite Normal Mixtures; complex Risks Control for Processes in Heat Technological Systems.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Scheduling Virtual Machine Migration During Datacenter Upgrades with Reinforcement Learning",
        "publication": "Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Physical machines in modern datacenters are routinely upgraded due to their maintenance requirements, which involves migrating all the virtual machines they currently host to alternative physical machines. For this kind of datacenter upgrades, it is critical to minimize the time it takes to upgrade all the physical machines in the datacenter, so as to reduce disruptions to cloud services. To minimize the upgrade time, it is essential to carefully schedule the migration of virtual machines on each physical machine during its upgrade, without violating any constraints imposed by virtual machines that are currently running. Rather than resorting to heuristic algorithms, we propose a new scheduler, Raven, that uses an experience-driven approach with deep reinforcement learning to schedule the virtual machine migration process. With our design of the state space, action space and reward function, Raven trains a fully-connected neural network using the cross-entropy method to approximate the policy of a choosing destination physical machine for each migrating virtual machine. We compare Raven with state-of-the-art heuristic algorithms in the literature, and our results show that Raven effectively leads to shorter time to complete the datacenter upgrade process.",
        "DOI": "10.1007/978-3-030-38819-5_7",
        "paper_author": "Ying C.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Deep Ensemble Reinforcement Learning with Multiple Deep Deterministic Policy Gradient Algorithm",
        "publication": "Mathematical Problems in Engineering",
        "citied_by": "22",
        "cover_date": "2020-01-01",
        "Abstract": "Deep deterministic policy gradient algorithm operating over continuous space of actions has attracted great attention for reinforcement learning. However, the exploration strategy through dynamic programming within the Bayesian belief state space is rather inefficient even for simple systems. Another problem is the sequential and iterative training data with autonomous vehicles subject to the law of causality, which is against the i.i.d. (independent identically distributed) data assumption of the training samples. This usually results in failure of the standard bootstrap when learning an optimal policy. In this paper, we propose a framework of m-out-of-n bootstrapped and aggregated multiple deep deterministic policy gradient to accelerate the training process and increase the performance. Experiment results on the 2D robot arm game show that the reward gained by the aggregated policy is 10%-50% better than those gained by subpolicies. Experiment results on the open racing car simulator (TORCS) demonstrate that the new algorithm can learn successful control policies with less training time by 56.7%. Analysis on convergence is also given from the perspective of probability and statistics. These results verify that the proposed method outperforms the existing algorithms in both efficiency and performance.",
        "DOI": "10.1155/2020/4275623",
        "paper_author": "Wu J.",
        "affiliation_name": "Shenzhen Institute of Advanced Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60102083",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reinforcement learning for efficient network penetration testing",
        "publication": "Information (Switzerland)",
        "citied_by": "94",
        "cover_date": "2020-01-01",
        "Abstract": "Penetration testing (also known as pentesting or PT) is a common practice for actively assessing the defenses of a computer network by planning and executing all possible attacks to discover and exploit existing vulnerabilities. Current penetration testing methods are increasingly becoming non-standard, composite and resource-consuming despite the use of evolving tools. In this paper, we propose and evaluate an AI-based pentesting system which makes use of machine learning techniques, namely reinforcement learning (RL) to learn and reproduce average and complex pentesting activities. The proposed system is named Intelligent Automated Penetration Testing System (IAPTS) consisting of a module that integrates with industrial PT frameworks to enable them to capture information, learn from experience, and reproduce tests in future similar testing cases. IAPTS aims to save human resources while producing much-enhanced results in terms of time consumption, reliability and frequency of testing. IAPTS takes the approach of modeling PT environments and tasks as a partially observed Markov decision process (POMDP) problem which is solved by POMDP-solver. Although the scope of this paper is limited to network infrastructures PT planning and not the entire practice, the obtained results support the hypothesis that RL can enhance PT beyond the capabilities of any human PT expert in terms of time consumed, covered attacking vectors, accuracy and reliability of the outputs. In addition, this work tackles the complex problem of expertise capturing and re-use by allowing the IAPTS learning module to store and re-use PT policies in the same way that a human PT expert would learn but in a more efficient way.",
        "DOI": "10.3390/info11010006",
        "paper_author": "Ghanem M.C.",
        "affiliation_name": "University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60033387",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep reinforcement-learning-based driving policy for autonomous road vehicles",
        "publication": "IET Intelligent Transport Systems",
        "citied_by": "35",
        "cover_date": "2020-01-01",
        "Abstract": "In this work, the problem of path planning for an autonomous vehicle that moves on a freeway is considered. The most common approaches that are used to address this problem are based on optimal control methods, which make assumptions about the model of the environment and the system dynamics. On the contrary, this work proposes the development of a driving policy based on reinforcement learning. In this way, the proposed driving policy makes minimal or no assumptions about the environment, since a priori knowledge about the system dynamics is not required. Driving scenarios where the road is occupied both by autonomous and manual driving vehicles are considered. To the best of the authors' knowledge, this is one of the first approaches that propose a reinforcement learning driving policy for mixed driving environments. The derived reinforcement learning policy, firstly, is compared against an optimal policy derived via dynamic programming, and, secondly, its efficiency is evaluated under realistic scenarios generated by the established SUMO microscopic traffic flow simulator. Finally, some initial results regarding the effect of autonomous vehicles' behaviour on the overall traffic flow are presented.",
        "DOI": "10.1049/iet-its.2019.0249",
        "paper_author": "Makantasis K.",
        "affiliation_name": "Technical University of Crete",
        "affiliation_city": "Chania",
        "affiliation_country": "Greece",
        "affiliation_id": "60022461",
        "affiliation_state": "Crete"
    },
    {
        "paper_title": "Acceleration methods for centralized multiagent reinforcement learning",
        "publication": "IEEJ Transactions on Electronics, Information and Systems",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "For multiagent environments, a centralized reinforcement learner can find optimal policies, but it is time-consuming. A method is proposed for finding the optimal policies acceleratingly. The method basically uses the centralized learner and supplementarily uses independent learners in the former phase. The independent learners transfer their learning results to the centralized learner, but excessive transfers cause the failure of learning. Therefore the independent learners should stop according to an appropriate condition. However, it is difficult for this method to find optimal policies for environments in which initial states are far from termination states. In order to find the optimal policies acceleratingly for such environments, this paper proposes multiagent reinforcement learning methods introducing new stop conditions.",
        "DOI": "10.1541/ieejeiss.140.242",
        "paper_author": "Akahane T.",
        "affiliation_name": "Kyoto Institute of Technology",
        "affiliation_city": "Kyoto",
        "affiliation_country": "Japan",
        "affiliation_id": "60031225",
        "affiliation_state": "Kyoto"
    },
    {
        "paper_title": "Performance Improvement of Linux CPU Scheduler Using Policy Gradient Reinforcement Learning for Android Smartphones",
        "publication": "IEEE Access",
        "citied_by": "12",
        "cover_date": "2020-01-01",
        "Abstract": "The Energy Aware Scheduler (EAS) was developed and applied to the Linux kernel of recent Android smartphones in order to exploit the ARM big.LITTLE processing architecture efficiently. EAS organizes CPU hardware information into Energy Model which are used to improve CPU scheduling performance. In particular, it reduces power consumption and improves process scheduling performance. However, EAS has limitations in improving CPU scheduling performance, because the Energy Model configures the CPU hardware information to fixed values, which does not reflect the characteristics of running tasks, such as the workload changes and the transition between running state and sleep state. To solve this problem, this paper introduces the Learning Energy Aware Scheduler (Learning EAS). The Learning EAS adjusts the TARGET-LOAD used to set the CPU frequency and the sched-migration-cost used as the task migration criteria according to the characteristics of the running task through the policy gradient reinforcement learning. In LG G8 ThinQ, Learning EAS improved power consumption by 2.3% - 5.7%, hackbench results for process scheduling performance by 2.8% - 25.5%, applications entry time by 4.4% - 6.1%, and applications entry time under high CPU workload by 9.6% - 12.5%, respectively compared with EAS. This paper also showed that the Learning EAS is scalable by applying the Learning EAS to high-end and low-end chipset platforms of Qualcomm.Inc and MediaTek.Inc and improving power consumption by 2.8% - 7.8%, application entry time by 2.2% - 7.2%, respectively compared with EAS. Finally, this paper showed that the performance of CPU scheduling is improved gradually by the repetition of reinforcement learning.",
        "DOI": "10.1109/ACCESS.2020.2965548",
        "paper_author": "Han J.",
        "affiliation_name": "LG Electronics, Korea",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60094206",
        "affiliation_state": "Yeongdeungpo-gu"
    },
    {
        "paper_title": "Predicting Popularity of Electric Vehicle Charging Infrastructure in Urban Context",
        "publication": "IEEE Access",
        "citied_by": "56",
        "cover_date": "2020-01-01",
        "Abstract": "The availability of charging infrastructure is essential for large-scale adoption of electric vehicles (EV). Charging patterns and the utilization of infrastructure have consequences not only for the energy demand by loading local power grids, but influence the economic returns, parking policies and further adoption of EVs. We develop a data-driven approach that exploits predictors compiled from Geographic Information Systems data describing the urban context and urban activities near charging infrastructure to explore correlations with a comprehensive set of indicators that measure the performance of charging infrastructure. The best fit was identified for the size of the unique group of visitors (popularity) attracted by the charging infrastructure. Consecutively, charging infrastructure is ranked by popularity. The question of whether or not a given charging spot belongs to the top tier is posed as a binary classification problem and predictive performance of logistic regression regularized with an mathit {l}{1} penalty, random forests and gradient boosted regression trees is evaluated. Obtained results indicate that the collected predictors contain information that can be used to predict the popularity of charging infrastructure. The significance of predictors and how they are linked with the popularity are explored as well. The proposed methodology can be used to inform charging infrastructure deployment strategies.",
        "DOI": "10.1109/ACCESS.2020.2965621",
        "paper_author": "Straka M.",
        "affiliation_name": "University of Žilina",
        "affiliation_city": "Zilina",
        "affiliation_country": "Slovakia",
        "affiliation_id": "60005088",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Smart Access Control Method for Online Social Networks Based on Support Vector Machine",
        "publication": "IEEE Access",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "With the rapid development of Internet technology, online social networks (OSNs) has become one of the main ways for people to develop social activities. In order to maintain and strengthen interpersonal relationships, users are willing to share personal behaviors, feelings and other things through OSNs. Whether these resources reveal private information or not depends on the appropriateness of the access control policies set by the owner. However, with the increasing number of friends and complex relationships, it becomes more and more difficult for OSNs users to set appropriate access control policies. Aiming at above problems, a smart access control method for online social networks is proposed based on SVM algorithm to realize smart access control on the basis of integrating relationship types and description information of published content as eigenvectors. The experimental results show that this mechanism can automatically recommend the list of visible friends according to the content published by users and the relationship between users and friends, allowing users to modify the list to obtain the final access control policy, which can effectively protect users' privacy information.",
        "DOI": "10.1109/ACCESS.2020.2963932",
        "paper_author": "Shan F.",
        "affiliation_name": "Zhengzhou University",
        "affiliation_city": "Zhengzhou",
        "affiliation_country": "China",
        "affiliation_id": "60018554",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "Maneuver Decision of UAV in Short-Range Air Combat Based on Deep Reinforcement Learning",
        "publication": "IEEE Access",
        "citied_by": "150",
        "cover_date": "2020-01-01",
        "Abstract": "With the development of artificial intelligence and integrated sensor technologies, unmanned aerial vehicles (UAVs) are more and more applied in the air combats. A bottleneck that constrains the capability of UAVs against manned vehicles is the autonomous maneuver decision, which is a very challenging problem in the short-range air combat undergoing highly dynamic and uncertain maneuvers of enemies. In this paper, an autonomous maneuver decision model is proposed for the UAV short-range air combat based on reinforcement learning, which mainly includes the aircraft motion model, one-to-one short-range air combat evaluation model and the maneuver decision model based on deep Q network (DQN). However, such model includes a high dimensional state and action space which requires huge computation load for DQN training using traditional methods. Then, a phased training method, called 'basic-confrontation', which is based on the idea that human beings gradually learn from simple to complex is proposed to help reduce the training time while getting suboptimal but efficient results. Finally, one-to-one short-range air combats are simulated under different target maneuver policies. Simulation results show that the proposed maneuver decision model and training method can help the UAV achieve autonomous decision in the air combats and obtain an effective decision policy to defeat the opponent.",
        "DOI": "10.1109/ACCESS.2019.2961426",
        "paper_author": "Yang Q.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Sequential Association Rule Mining for Autonomously Extracting Hierarchical Task Structures in Reinforcement Learning",
        "publication": "IEEE Access",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement learning (RL) techniques, while often powerful, can suffer from slow learning speeds, particularly in high dimensional spaces or in environments with sparse rewards. The decomposition of tasks into a hierarchical structure holds the potential to significantly speed up learning, generalization, and transfer learning. However, the current task decomposition techniques often cannot extract hierarchical task structures without relying on high-level knowledge provided by an expert (e.g., using dynamic Bayesian networks (DBNs) in factored Markov decision processes), which is not necessarily available in autonomous systems. In this paper, we propose a novel method based on Sequential Association Rule Mining that can extract Hierarchical Structure of Tasks in Reinforcement Learning (SARM-HSTRL) in an autonomous manner for both Markov decision processes (MDPs) and factored MDPs. The proposed method leverages association rule mining to discover the causal and temporal relationships among states in different trajectories and extracts a task hierarchy that captures these relationships among sub-goals as termination conditions of different sub-tasks. We prove that the extracted hierarchical policy offers a hierarchically optimal policy in MDPs and factored MDPs. It should be noted that SARM-HSTRL extracts this hierarchical optimal policy without having dynamic Bayesian networks in scenarios with a single task trajectory and also with multiple tasks' trajectories. Furthermore, we show theoretically and empirically that the extracted hierarchical task structure is consistent with trajectories and provides the most efficient, reliable, and compact structure under appropriate assumptions. The numerical results compare the performance of the proposed SARM-HSTRL method with conventional HRL algorithms in terms of the accuracy in detecting the sub-goals, the validity of the extracted hierarchies, and the speed of learning in several testbeds. The key capabilities of SARM-HSTRL including handling multiple tasks and autonomous hierarchical task extraction can lead to the application of this HRL method in reusing, transferring, and generalization of knowledge in different domains.",
        "DOI": "10.1109/ACCESS.2020.2965930",
        "paper_author": "Ghazanfari B.",
        "affiliation_name": "Steve Sanghi College of Engineering",
        "affiliation_city": "Flagstaff",
        "affiliation_country": "United States",
        "affiliation_id": "60147261",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Learning from Demonstrations and Human Evaluative Feedbacks: Handling Sparsity and Imperfection Using Inverse Reinforcement Learning Approach",
        "publication": "Journal of Robotics",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "Programming by demonstrations is one of the most efficient methods for knowledge transfer to develop advanced learning systems, provided that teachers deliver abundant and correct demonstrations, and learners correctly perceive them. Nevertheless, demonstrations are sparse and inaccurate in almost all real-world problems. Complementary information is needed to compensate these shortcomings of demonstrations. In this paper, we target programming by a combination of nonoptimal and sparse demonstrations and a limited number of binary evaluative feedbacks, where the learner uses its own evaluated experiences as new demonstrations in an extended inverse reinforcement learning method. This provides the learner with a broader generalization and less regret as well as robustness in face of sparsity and nonoptimality in demonstrations and feedbacks. Our method alleviates the unrealistic burden on teachers to provide optimal and abundant demonstrations. Employing an evaluative feedback, which is easy for teachers to deliver, provides the opportunity to correct the learner's behavior in an interactive social setting without requiring teachers to know and use their own accurate reward function. Here, we enhance the inverse reinforcement learning (IRL) to estimate the reward function using a mixture of nonoptimal and sparse demonstrations and evaluative feedbacks. Our method, called IRL from demonstration and human's critique (IRLDC), has two phases. The teacher first provides some demonstrations for the learner to initialize its policy. Next, the learner interacts with the environment and the teacher provides binary evaluative feedbacks. Taking into account possible inconsistencies and mistakes in issuing and receiving feedbacks, the learner revises the estimated reward function by solving a single optimization problem. The IRLDC is devised to handle errors and sparsities in demonstrations and feedbacks and can generalize different combinations of these two sources expertise. We apply our method to three domains: a simulated navigation task, a simulated car driving problem with human interactions, and a navigation experiment of a mobile robot. The results indicate that the IRLDC significantly enhances the learning process where the standard IRL methods fail and learning from feedbacks (LfF) methods has a high regret. Also, the IRLDC works well at different levels of sparsity and optimality of the teacher's demonstrations and feedbacks, where other state-of-the-art methods fail.",
        "DOI": "10.1155/2020/3849309",
        "paper_author": "Mourad N.",
        "affiliation_name": "University of Tehran",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60022927",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "How to teach machines to read human rights reports and identify judgments at scale",
        "publication": "Journal of Human Rights",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "The accelerating availability of information from human rights monitors such as Amnesty International, Human Rights Watch, and the US State Department has led to new opportunities to measure repression and human rights protections in higher resolution. However, to date, most approaches that attempt to automatically structure textual reports use simple, lower-dimensional observations such as the counts of words that ignore syntax and word order. While these representations are useful for some applications, they limit the inferences scholars and policy-makers can extract from human rights reports. In this article, we present a new system, PULSAR, that takes syntax and word order into account. This system uniquely allows researchers to extract both the judgements and the aspects/rights being judged from texts at scale. We illustrate that this more detailed information is useful both for improving predictions of physical integrity rights and women's political rights, but also for generating machine learning models that are more interpretable than conventional specifications. This latter benefit holds the promise of coherently connecting qualitative and quantitative analyses of human rights texts.",
        "DOI": "10.1080/14754835.2019.1671174",
        "paper_author": "Park B.",
        "affiliation_name": "University of Pittsburgh",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60015543",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Context-Interactive CNN for Person Re-Identification",
        "publication": "IEEE Transactions on Image Processing",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "Despite growing progresses in recent years, cross-scenario person re-identification remains challenging, mainly due to the pedestrians commonly surrounded by highly-complex environment contexts. In reality, the human perception mechanism could adaptively find proper contextualized spatialoral clues towards pedestrian recognition. However, conventional methods fall short in adaptively leveraging the long-term spatialoral information due to ever-increasing computational cost. Moreover, CNN-based deep learning methods are hard to conduct optimization due to the non-differentiable property of the built-in context search operation. To ameliorate, this paper proposes a novel Context-Interactive CNN (CI-CNN) to dynamically find both spatial and temporal contexts by embedding multi-task Reinforcement Learning (MTRL). The CI-CNN streamlines the multi-task reinforcement learning by using an actor-critic agent to capture the temporal-spatial context simultaneously, which comprises a context-policy network and a context-critic network. The former network learns policies to determine the optimal spatial context region and temporal sequence range. Based on the inferred temporal-spatial cues, the latter one focuses on the identification task and provides feedback for the policy network. Thus, CI-CNN can simultaneously zoom in/out the perception field in spatial and temporal domain for the context interaction with the environment. By fostering the collaborative interaction between the person and context, our method could achieve outstanding performance on various public benchmarks, which confirms the rationality of our hypothesis, and verifies the effectiveness of our CI-CNN framework.",
        "DOI": "10.1109/TIP.2019.2953587",
        "paper_author": "Song W.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013789",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "MQLV: Optimal Policy of Money Management in Retail Banking with Q-Learning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement learning has become one of the best approach to train a computer game emulator capable of human level performance. In a reinforcement learning approach, an optimal value function is learned across a set of actions, or decisions, that leads to a set of states giving different rewards, with the objective to maximize the overall reward. A policy assigns to each state-action pairs an expected return. We call an optimal policy a policy for which the value function is optimal. QLBS, Q-Learner in the Black-Scholes(-Merton) Worlds, applies the reinforcement learning concepts, and noticeably, the popular Q-learning algorithm, to the financial stochastic model of Black, Scholes and Merton. It is, however, specifically optimized for the geometric Brownian motion and the vanilla options. Its range of application is, therefore, limited to vanilla option pricing within the financial markets. We propose MQLV, Modified Q-Learner for the Vasicek model, a new reinforcement learning approach that determines the optimal policy of money management based on the aggregated financial transactions of the clients. It unlocks new frontiers to establish personalized credit card limits or bank loan applications, targeting the retail banking industry. MQLV extends the simulation to mean reverting stochastic diffusion processes and it uses a digital function, a Heaviside step function expressed in its discrete form, to estimate the probability of a future event such as a payment default. In our experiments, we first show the similarities between a set of historical financial transactions and Vasicek generated transactions and, then, we underline the potential of MQLV on generated Monte Carlo simulations. Finally, MQLV is the first Q-learning Vasicek-based methodology addressing transparent decision making processes in retail banking.",
        "DOI": "10.1007/978-3-030-37720-5_1",
        "paper_author": "Charlier J.",
        "affiliation_name": "University of Luxembourg",
        "affiliation_city": "Esch-sur-Alzette",
        "affiliation_country": "Luxembourg",
        "affiliation_id": "60072562",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning to branch: Accelerating resource allocation in wireless networks",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "52",
        "cover_date": "2020-01-01",
        "Abstract": "Resource allocation in wireless networks, such as device-to-device (D2D) communications, is usually formulated as mixed integer nonlinear programming (MINLP) problems, which are generally NP-hard and difficult to get the optimal solutions. Traditional methods to solve these MINLP problems are all based on mathematical optimization techniques, such as the branch-and-bound (B&B) algorithm that converges slowly and has forbidding complexity for real-time implementation. Therefore, machine leaning (ML) has been used recently to address the MINLP problems in wireless communications. In this paper, we use imitation learning method to accelerate the B&B algorithm. With invariant problem-independent features and appropriate problem-dependent feature selection for D2D communications, a good auxiliary prune policy can be learned in a supervised manner to speed up the most time-consuming branch process of the B&B algorithm. Moreover, we develop a mixed training strategy to further reinforce the generalization ability and a deep neural network (DNN) with a novel loss function to achieve better dynamic control over optimality and computational complexity. Extensive simulation demonstrates that the proposed method can achieve good optimality and reduce computational complexity simultaneously.",
        "DOI": "10.1109/TVT.2019.2953724",
        "paper_author": "Lee M.",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60003970",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Application of automated tools in researching internet discourses: Experience of using the recurrent neural networks for studying discussions on pension reform",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The paper presents the results of an experiment that applied the Recurrent Neural Network (RNN) and long short-term memory (LSTM) networks to assess how accurately they can determine the attitude of 998 participants towards the pension reform policy in Russia who posted 10,592 comments on 16 online forums in 11 cities. The training set was assembled and coded according to a proposed conceptual model of a moral discourse based on Jurgen Habermas’s discourse ethics theory. The main conclusion of this experiment is that the discourse-based approach — based on the identification of basic validity claims — can be instrumental in building training datasets for deep machine learning on a socially salient topic. The experiment also shows benefits and limitations of using artificial neural networks for a deeper understanding of the results of public discussions in an online environment. The main benefit was that the built neural networks have proven to be sufficiently accurate in predicting positions of discourse participants towards the pension reform policy, with almost 90% in the case of binary classification (two “For” and “Against” positions). However, the accuracy level drops with the inclusion of a third “Neutral” category (to 78%), which was a major limitation of the research; that is, the variation in the prediction accuracy is due to the uneven distribution of data among categories and an increase of new data. Yet this indicator is still acceptable when working with Internet discourse data.",
        "DOI": "NA",
        "paper_author": "Begen P.",
        "affiliation_name": "Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO",
        "affiliation_city": "Saint Petersburg",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60072485",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Introduce Artificial Intelligence in Controlling a Solar Tracker",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "According to the report on the global status of renewable energies 2016 published by REN21 (Renewable Energy Policy Network For The 21st Century) the production of solar photovoltaic energy for the year 2015 reached 227 GW with more than 50 GW compared to the year 2014 that was 177 GW this rapid growth is due to research and dedicated scientific developments for this type of energies all these last have the same goal to improve the energy production capacity of these panels. In order to increase the efficiency of the solar panels, we have thought about the design and the realization of a two-axis solar tracker, which will allow the panels to follow the sun and to have the optimal position where there is the maximum of solar power that our panel can acquire. In principle, our system consists of three cards, the first one is the acquisition card or the sensors card it delivers the information on the position of the sun, the second is the control card where we have programmed our algorithm which is responsible for continuously regulating of the position of our tracker, the third is a power card that acts as the intermediary between the control board and the actuators (the two motors of the two axes). By using a PID algorithm and after a real test of our solar tracker it was found that the regulation is done in a correct way but we noticed that the actuators consume a lot of energy to keep the optimal position and we lose the information after the position change, this is why we introduced the notion of artificial intelligence through the development of an algorithm based on advanced fuzzy logic with adaptable rules. Our algorithm will replace the old algorithm (PID) to control the movement of the axes of our tracker as well to find the optimal point where there is the maximum of solar irradiation. Our algorithm will also memorize all the optimal points found during the day for used as much as references and to add it’s as the elements that constitute these rules taking into account also the energy consumption of the system. Our system is developed from such a fate to be reliable, fair and tough.",
        "DOI": "10.1007/978-3-030-36475-5_14",
        "paper_author": "Glilah I.",
        "affiliation_name": "Faculté des Sciences et Techniques de Tanger",
        "affiliation_city": "Tangier",
        "affiliation_country": "Morocco",
        "affiliation_id": "60001620",
        "affiliation_state": "Tanger-Tetouan-Al Hoceima"
    },
    {
        "paper_title": "2nd Ibero-American Congress of Smart Cities, ICSC-CITIES 2019",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 22 papers. The special focus in this conference is on Smart Cities. The topics include: Control of a Bidirectional Single-Phase Grid Interface for Electric Vehicles; multiobjective Household Energy Planning Using Evolutionary Algorithms; noise and Ozone Continuous Monitoring in an Industrial Urban Area of Northeastern Portugal; energy Storage Systems for Power Supply of Ultrahigh Speed Hyperloop Trains; designing a Backbone Trunk for the Public Transportation Network in Montevideo, Uruguay; bus Stops as a Tool for Increasing Social Inclusiveness in Smart Cities; urban Data Analysis for the Public Transportation System of Montevideo, Uruguay; Monthly Characterization of the Generation of Photovoltaic Arrays. Microgrid Case CEDER, Soria, Spain; Electric Microgrid in Smart Cities: CEDER-CIEMAT a Case Study; potential for Thermal Water Desalination Using Microgrid and Solar Thermal Field Energy Surpluses in an Isolated Community; short Term Load Forecasting of Industrial Electricity Using Machine Learning; implementation of a Smart Microgrid in a Small Museum: The Silk House; general Purpose I-V Tester Developed to Measure a Wide Range of Photovoltaic Systems; segmentation of Thermography Image of Solar Cells and Panels; preface; assessing the Environmental Impact of Car Restrictions Policies: Madrid Central Case; IPN Sustainability Program: Solar Photovoltaic Electricity Generation and Consumption Reduction; sustainable Mobility in the Public Transportation of Montevideo, Uruguay; loRa-Based IoT Data Monitoring and Collecting Platform; a Hybrid Energy Storage System for Renewable-Based Power Plants.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep reinforcement learning for UAV navigation through massive MIMO technique",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "122",
        "cover_date": "2020-01-01",
        "Abstract": "Unmanned aerial vehicles (UAVs) technique has been recognized as a promising solution in future wireless connectivity from the sky, and UAV navigation is one of the most significant open research problems, which has attracted wide interest in the research community. However, the current UAV navigation schemes are unable to capture the UAV motion and select the best UAV-ground links in real-time, and these weaknesses overwhelm the UAV navigation performance. To tackle these fundamental limitations, in this paper, we merge the state-of-the-art deep reinforcement learning with the UAV navigation through massive multiple-input-multiple-output (MIMO) technique. To be specific, we carefully design a deep Q-network (DQN) for optimizing the UAV navigation by selecting the optimal policy, and then we propose a learning mechanism for processing the DQN. The DQN is trained so that the agent is capable of making decisions based on the received signal strengths for navigating the UAVs with the aid of the powerful Q-learning. Simulation results are provided to corroborate the superiority of the proposed schemes in terms of the coverage and convergence compared with those of the other schemes.",
        "DOI": "10.1109/TVT.2019.2952549",
        "paper_author": "Huang H.",
        "affiliation_name": "School of Communications and Information Engineering",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60278898",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Semi-active suspension control based on deep reinforcement learning",
        "publication": "IEEE Access",
        "citied_by": "59",
        "cover_date": "2020-01-01",
        "Abstract": "The performance of vehicle body vibration and ride comfort of active or semi-active suspension with proper control is better than that with passive suspension. The key to achieve good control effect is that the suspension control system should have strong real-time learning ability according to changes in the road surface and suspension parameters. In the control strategies adopted by previous researchers, the classical neural network controller has some learning ability, but it is mainly based on offline learning with a large number of samples. In this paper, the deep reinforcement learning strategy is used to solve the above problems.Aiming at the continuity of state space and execution action in vehicle active suspension system, the control of the semi-active suspension is realized by using improved DDPG (Deep Deterministic Policy Gradient) algorithm. To overcome the shortcoming of low efficiency of this algorithm in the initial stage of learning, the DDPG algorithm is improved and using empirical samples in the learning method is proposed. Based on Mujoco, the physical model of semi-active suspension is established, and its dynamic characteristics are analyzed under the condition of various road level and vehicle speed. The simulation results show that compared with the passive suspension, the semi-active suspension based on improved DDPG algorithm with learning method using experienced samples can better adapt to various road level, more effectively reduce the vertical acceleration of the vehicle body and the dynamic deflection of the suspension, and further improve the ride comfort.",
        "DOI": "10.1109/ACCESS.2020.2964116",
        "paper_author": "Ming L.",
        "affiliation_name": "Shandong University",
        "affiliation_city": "Jinan",
        "affiliation_country": "China",
        "affiliation_id": "60031031",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Firms Default Prediction with Machine Learning",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Academics and practitioners have studied over the years models for predicting firms bankruptcy, using statistical and machine-learning approaches. An earlier sign that a company has financial difficulties and may eventually bankrupt is going in default, which, loosely speaking means that the company has been having difficulties in repaying its loans towards the banking system. Firms default status is not technically a failure but is very relevant for bank lending policies and often anticipates the failure of the company. Our study uses, for the first time according to our knowledge, a very large database of granular credit data from the Italian Central Credit Register of Bank of Italy that contain information on all Italian companies’ past behavior towards the entire Italian banking system to predict their default using machine-learning techniques. Furthermore, we combine these data with other information regarding companies’ public balance sheet data. We find that ensemble techniques and random forest provide the best results, corroborating the findings of Barboza et al. (Expert Syst. Appl., 2017).",
        "DOI": "10.1007/978-3-030-37720-5_4",
        "paper_author": "Aliaj T.",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60032350",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Deterministic promotion reinforcement learning applied to longitudinal velocity control for automated vehicles",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "36",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement learning is regarded as a potential method to be applied in automated vehicles, but the stability and efficiency of algorithms are concerns. To improve them, the deterministic promotion reinforcement learning method is put forward, which can promote the policy determinately. Correspondingly, the policy evaluation in critic and the exploration in actor are improved, which combines a normalization-based evaluation and a model-free search guide. The aim is finding the right action exploration direction by critic, then the direction is used to update and guide action exploration in actor. The modified method decreases the dependencies of exploring a good action for promotional updating and only makes deterministic promotion in policy. Consequently, the efficiency of the algorithm is improved without loss in stability. More notably, it can relieve the cold-start and circumvent the limitations in learning with constrained physical systems. To verify the proposed method, the longitudinal velocity control problem for automated vehicles is considered, which contains car-following and non-car-following conditions in a unitized form. The learning system is established in Carsim. Furthermore, some different reinforcement learning technologies are used to accelerate learning. Real-vehicle experiments for validation are also given. The results indicate that the proposed method can achieve permissible learning performance in the longitudinal velocity continuous control problem.",
        "DOI": "10.1109/TVT.2019.2955959",
        "paper_author": "Zhang Y.",
        "affiliation_name": "Jilin University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60007711",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "4th Workshop on Mining Data for Financial Applications, MIDAS 2019, held in conjunction with the 19th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2019",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 11 papers. The special focus in this conference is on Mining Data for Financial Applications. The topics include: Curriculum Learning in Deep Neural Networks for Financial Forecasting; a Brand Scoring System for Cryptocurrencies Based on Social Media Data; big Data Financial Sentiment Analysis in the European Bond Markets; MQLV: Optimal Policy of Money Management in Retail Banking with Q-Learning; preface; multi-step Prediction of Financial Asset Return Volatility Using Parsimonious Autoregressive Sequential Model; monitoring the Business Cycle with Fine-Grained, Aspect-Based Sentiment Extraction from News; mining Financial Risk Events from News and Assessing their Impact on Stocks; mining Business Relationships from Stocks and News.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "LORM: Learning to Optimize for Resource Management in Wireless Networks with Few Training Samples",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "92",
        "cover_date": "2020-01-01",
        "Abstract": "Effective resource management plays a pivotal role in wireless networks, which, unfortunately, typically results in challenging mixed-integer nonlinear programming (MINLP) problems. Machine learning-based methods have recently emerged as a disruptive way to obtain near-optimal performance for MINLPs with affordable computational complexity. There have been some attempts in applying such methods to resource management in wireless networks, but these attempts require huge amounts of training samples and lack the capability to handle constrained problems. Furthermore, they suffer from severe performance deterioration when the network parameters change, which commonly happens and is referred to as the task mismatch problem. In this paper, to reduce the sample complexity and address the feasibility issue, we propose a framework of Learning to Optimize for Resource Management (LORM). In contrast to the end-to-end learning approach adopted in previous studies, LORM learns the optimal pruning policy in the branch-and-bound algorithm for MINLPs via a sample-efficient method, namely, imitation learning. To further address the task mismatch problem, we develop a transfer learning method via self-imitation in LORM, named LORM-TL, which can quickly adapt a pre-trained machine learning model to the new task with only a few additional unlabeled training samples. Numerical simulations demonstrate that LORM outperforms specialized state-of-the-art algorithms and achieves near-optimal performance, while providing significant speedup compared with the branch-and-bound algorithm. Moreover, LORM-TL, by relying on a few unlabeled samples, achieves comparable performance with the model trained from scratch with sufficient labeled samples.",
        "DOI": "10.1109/TWC.2019.2947591",
        "paper_author": "Shen Y.",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008592",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "5G vehicular network resource management for improving radio access through machine learning",
        "publication": "IEEE Access",
        "citied_by": "113",
        "cover_date": "2020-01-01",
        "Abstract": "The current cellular technology and vehicular networks cannot satisfy the mighty strides of vehicular network demands. Resource management has become a complex and challenging objective to gain expected outcomes in a vehicular environment. The 5G cellular network promises to provide ultra-high-speed, reduced delay, and reliable communications. The development of new technologies such as the network function virtualization (NFV) and software defined networking (SDN) are critical enabling technologies leveraging 5G. The SDN-based 5G network can provide an excellent platform for autonomous vehicles because SDN offers open programmability and flexibility for new services incorporation. This separation of control and data planes enables centralized and efficient management of resources in a very optimized and secure manner by having a global overview of the whole network. The SDN also provides flexibility in communication administration and resource management, which are of critical importance when considering the ad-hoc nature of vehicular network infrastructures, in terms of safety, privacy, and security, in vehicular network environments. In addition, it promises the overall improved performance. In this paper, we propose a flow-based policy framework on the basis of two tiers virtualization for vehicular networks using SDNs. The vehicle to vehicle (V2V) communication is quite possible with wireless virtualization where different radio resources are allocated to V2V communications based on the flow classification, i.e., safety-related flow or non-safety flows, and the controller is responsible for managing the overall vehicular environment and V2X communications. The motivation behind this study is to implement a machine learning-enabled architecture to cater the sophisticated demands of modern vehicular Internet infrastructures. The inclination towards robust communications in 5G-enabled networks has made it somewhat tricky to manage network slicing efficiently. This paper also presents a proof of concept for leveraging machine learning-enabled resource classification and management through experimental evaluation of special-purpose testbed established in custom mininet setup. Furthermore, the results have been evaluated using Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). While concluding the paper, it is shown that the LSTM has outperformed the rest of classification techniques with promising results.",
        "DOI": "10.1109/ACCESS.2020.2964697",
        "paper_author": "Tayyaba S.K.",
        "affiliation_name": "COMSATS University Islamabad",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60089631",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep Reinforcement Learning Approaches for Content Caching in Cache-Enabled D2D Networks",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "106",
        "cover_date": "2020-01-01",
        "Abstract": "Internet of Things (IoT) technology suffers from the challenge that rare wireless network resources are difficult to meet the influx of a huge number of terminal devices. Cache-enabled device-to-device (D2D) communication technology is expected to relieve network pressure with the fact that the requesting contents can be easily obtained from nearby users. However, how to design an effective caching policy becomes very challenging due to the limited content storage capacity and the uncertainty of user mobility pattern. In this article, we study the jointly cache content placement and delivery policy for the cache-enabled D2D networks. Specifically, two potential recurrent neural network approaches [the echo state network (ESN) and the long short-term memory (LSTM) network] are employed to predict users' mobility and content popularity, so as to determine which content to cache and where to cache. When the local cache of the user cannot satisfy its own request, the user may consider establishing a D2D link with the neighboring user to implement the content delivery. In order to decide which user will be selected to establish the D2D link, we propose the novel schemes based on deep reinforcement learning to implement the dynamic decision making and optimization of the content delivery problems, aiming at improving the quality of experience of overall caching system. The simulation results suggest that the cache hit ratio of the system can be well improved by the proposed content placement strategy, and the proposed content delivery approaches can effectively reduce the request content delivery delay and energy consumption.",
        "DOI": "10.1109/JIOT.2019.2951509",
        "paper_author": "Li L.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Predicting asthma attacks: Effects of indoor PM concentrations on peak expiratory flow rates of asthmatic children",
        "publication": "IEEE Access",
        "citied_by": "39",
        "cover_date": "2020-01-01",
        "Abstract": "Despite ample research on the association between indoor air pollution and allergic disease prevalence, public health and environmental policies still lack predictive evidence for developing a preventive guideline for patients or vulnerable populations mostly due to limitation of real-time big data and model predictability. Recent popularity of IoT and machine learning techniques could provide enabling technologies for collecting real-time big data and analyzing them for more accurate prediction of allergic disease risks for evidence-based intervention, but the effort is still in its infancy. This pilot study explored and evaluated the feasibility of a deep learning algorithm for predicting asthma risk. It is based on peak expiratory flow rates (PEFR) of 14 pediatric asthma patients visiting the Korea University Medical Center and indoor particulate matter PM10 and PM2.5 concentration data collected at their residence every 10 minutes using a PM monitoring device with a low-cost sensor between September 1, 2017 and August 31, 2018. We interpolated the PEFR results collected twice a day for each patient throughout the day so that it can be matched to the PM and other weather data. The PEFR results were classified into three categories such as 'Green' (normal), 'Yellow' (mild to moderate exacerbation) and 'Red' (severe exacerbation) with reference to their best peak flow value. Long Short-Term Memory (LSTM) model was trained using the first 10 months of the linked data and predicted asthma risk categories for the next 2 months during the study period. LSTM model is found to predict the asthma risk categories better than multinomial logistic (MNL) regression as it incorporates the cumulative effects of PM concentrations over time. Upon successful modifications of the algorithm based on a larger sample, this approach could potentially play a groundbreaking role for the scientific data-driven medical decision making.",
        "DOI": "10.1109/ACCESS.2019.2960551",
        "paper_author": "Kim D.",
        "affiliation_name": "The University of Texas at Dallas",
        "affiliation_city": "Richardson",
        "affiliation_country": "United States",
        "affiliation_id": "60009415",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Analysis of sex trafficking in India-a view on health care context",
        "publication": "International Journal on Emerging Technologies",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Human trafficking is a modernist form of heavy labor and is a well-known fact throughout the world. In addition to drug trafficking and the arms industry, sex trafficking is now the second-largest illegal activity in the world and is a growing crime. Sex trafficking is a crime when women or children participate by force in commercial sexual acts. While the twilight world of sexual relations around the world corresponds to an intriguing theme in our way of life, many people are unaware that sexual relations are happening on our terraces. The most common forms of sex trafficking are including forced labor, sexual exploitation, and child trafficking. There are many forms of human trafficking that are not as well-known but that, nevertheless, also require legal and policy responses. In this research, the authors attempted to analyze the crime of women in three phases. The first step is the analysis of the types of crimes, especially for women in every state of India. In the next step, the analysis of the purpose of kidnapping women and children in India and identified the most affected age group. Finally, based on previous results, the authors described the health problems of people affected by sex trafficking. The authors used three machine learning algorithms, such as the hierarchical agglomerative clustering algorithm, the multivariate linear regression and the OneR algorithm for analysis. The above methods are solved through the use of the R software and identify valuable results, such as the dangerous states of India in the crimes of women, identify the age group most affected for kidnapping and abduction and discussing symptoms important for victims of sex trafficking.",
        "DOI": "NA",
        "paper_author": "Aarthee R.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India",
        "affiliation_id": "60010618",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Power Allocation in Cache-Aided NOMA Systems: Optimization and Deep Reinforcement Learning Approaches",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "62",
        "cover_date": "2020-01-01",
        "Abstract": "This work exploits the advantages of two prominent techniques in future communication networks, namely caching and non-orthogonal multiple access (NOMA). Particularly, a system with Rayleigh fading channels and cache-enabled users is analyzed. It is shown that the caching-NOMA combination provides a new opportunity of cache hit which enhances the cache utility as well as the effectiveness of NOMA. Importantly, this comes without requiring users' collaboration, and thus, avoids many complicated issues such as users' privacy and security, selfishness, etc. In order to optimize users' quality of service and, concurrently, ensure the fairness among users, the probability that all users can decode the desired signals is maximized. In NOMA, a combination of multiple messages are sent to users, and the defined objective is approached by finding an appropriate power allocation for message signals. To address the power allocation problem, two novel methods are proposed. The first one is a divide-and-conquer-based method for which closed-form expressions for the optimal resource allocation policy are derived making this method simple and flexible to the system context. The second one is based on deep reinforcement learning method that allows all users to share the full bandwidth. Finally, simulation results are provided to demonstrate the effectiveness of the proposed methods and to compare their performance.",
        "DOI": "10.1109/TCOMM.2019.2947418",
        "paper_author": "Doan K.N.",
        "affiliation_name": "Singapore University of Technology and Design",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60104290",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep Reinforcement Learning for Cooperative Content Caching in Vehicular Edge Computing and Networks",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "288",
        "cover_date": "2020-01-01",
        "Abstract": "In this article, we propose a cooperative edge caching scheme, a new paradigm to jointly optimize the content placement and content delivery in the vehicular edge computing and networks, with the aid of the flexible trilateral cooperations among a macro-cell station, roadside units, and smart vehicles. We formulate the joint optimization problem as a double time-scale Markov decision process (DTS-MDP), based on the fact that the time-scale of content timeliness changes less frequently as compared to the vehicle mobility and network states during the content delivery process. At the beginning of the large time-scale, the content placement/updating decision can be obtained according to the content popularity, vehicle driving paths, and resource availability. On the small time-scale, the joint vehicle scheduling and bandwidth allocation scheme is designed to minimize the content access cost while satisfying the constraint on content delivery latency. To solve the long-term mixed integer linear programming (LT-MILP) problem, we propose a nature-inspired method based on the deep deterministic policy gradient (DDPG) framework to obtain a suboptimal solution with a low computation complexity. The simulation results demonstrate that the proposed cooperative caching system can reduce the system cost, as well as the content delivery latency, and improve content hit ratio, as compared to the noncooperative and random edge caching schemes.",
        "DOI": "10.1109/JIOT.2019.2945640",
        "paper_author": "Qiao G.",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60005465",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Scheduling Policies for Federated Learning in Wireless Networks",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "509",
        "cover_date": "2020-01-01",
        "Abstract": "Motivated by the increasing computational capacity of wireless user equipments (UEs), e.g., smart phones, tablets, or vehicles, as well as the increasing concerns about sharing private data, a new machine learning model has emerged, namely federated learning (FL), that allows a decoupling of data acquisition and computation at the central unit. Unlike centralized learning taking place in a data center, FL usually operates in a wireless edge network where the communication medium is resource-constrained and unreliable. Due to limited bandwidth, only a portion of UEs can be scheduled for updates at each iteration. Due to the shared nature of the wireless medium, transmissions are subjected to interference and are not guaranteed. The performance of FL system in such a setting is not well understood. In this paper, an analytical model is developed to characterize the performance of FL in wireless networks. Particularly, tractable expressions are derived for the convergence rate of FL in a wireless setting, accounting for effects from both scheduling schemes and inter-cell interference. Using the developed analysis, the effectiveness of three different scheduling policies, i.e., random scheduling (RS), round robin (RR), and proportional fair (PF), are compared in terms of FL convergence rate. It is shown that running FL with PF outperforms RS and RR if the network is operating under a high signal-to-interference-plus-noise ratio (SINR) threshold, while RR is more preferable when the SINR threshold is low. Moreover, the FL convergence rate decreases rapidly as the SINR threshold increases, thus confirming the importance of compression and quantization of the update parameters. The analysis also reveals a trade-off between the number of scheduled UEs and subchannel bandwidth under a fixed amount of available spectrum.",
        "DOI": "10.1109/TCOMM.2019.2944169",
        "paper_author": "Yang H.H.",
        "affiliation_name": "Singapore University of Technology and Design",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60104290",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Occupational classifications: A machine learning approach",
        "publication": "Journal of Economic and Social Measurement",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "Characterizing people's occupations is important for both policy and research. However, as large scale administrative records are increasingly being used to describe labor market activity, it will become important to find new automated approaches to describing occupations. We apply new machine learning techniques to new sources of data and investigate the potential of using algorithms to classify occupations. We find that job titles are both inherently noisy and inconsistent across organizations, but a subset of them can be assigned algorithmically, with little impact on accuracy.",
        "DOI": "10.3233/JEM-190463",
        "paper_author": "Ikudo A.",
        "affiliation_name": "University of California, Los Angeles",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60027550",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Applying artificial intelligence to explore sexual cyberbullying behaviour",
        "publication": "Heliyon",
        "citied_by": "26",
        "cover_date": "2020-01-01",
        "Abstract": "Sexual cyberbullying is becoming a serious problem in today's society. In the workplace, this issue is more complex because of the power imbalance between potential perpetrators and victims. Preventing sexual cyberbullying in organizations is very important for a safety and respectful workplace. Occupational Safety and Health (OSH) standards establish certain policies to be considered to create an organizational culture based on zero tolerance to sexual cyberbullying. The research aims to broaden knowledge about personality and sexual cyberbullying. Therefore, this paper proposes a crucial tool to explore potential sexual cyberbullying behaviour. This study analysed how personality traits, particularly those related to the Dark Triad (psychopathy, Machiavellianism and narcissism), might influence this behaviour. Participants (N = 374) were Spanish young adults, using the convenience sampling to recruit them. The methodology focused on the use of structural equation modelling and ensemble classification tree. First, we tested the proposed hypotheses with structural equation method based on covariance using the Lavaan R-package. Second, for the ensemble of classification trees, we applied the package randomForest and Adabag (bagging and boosting) in R. Results proposed high levels of psychopathy and Machiavellianism are more likely to be related to sexual cyberbullying behaviours. Organizations could use the tool proposed in this research to develop internal policies and procedures for detection and deterrence of potential cyberbullying behaviours. By raising awareness about cyberbullying behaviour including its conceptualisation and measurement in training courses, organizations might build an organizational culture based on a respectful workplace without sexual cyberbullying behaviours. Cyberbullying; Dark triad; Machiavellianism; Narcissism; Psychopathy; Structural equation modelling; Ensemble classification tree, Artificial intelligence; Machine learning; Business; Human resource management",
        "DOI": "10.1016/j.heliyon.2020.e03218",
        "paper_author": "Sánchez-Medina A.J.",
        "affiliation_name": "Universidad de Las Palmas de Gran Canaria",
        "affiliation_city": "Las Palmas de Gran Canaria",
        "affiliation_country": "Spain",
        "affiliation_id": "60009669",
        "affiliation_state": "Canary Islands"
    },
    {
        "paper_title": "Measuring the diffusion of innovations with paragraph vector topic models",
        "publication": "PLoS ONE",
        "citied_by": "23",
        "cover_date": "2020-01-01",
        "Abstract": "Measuring the diffusion of innovations from textual data sources besides patent data has not been studied extensively. However, early and accurate indicators of innovation and the recognition of trends in innovation are mandatory to successfully promote economic growth through technological progress via evidence-based policy making. In this study, we propose Paragraph Vector Topic Model (PVTM) and apply it to technology-related news articles to analyze innovation-related topics over time and gain insights regarding their diffusion process. PVTM represents documents in a semantic space, which has been shown to capture latent variables of the underlying documents, e.g., the latent topics. Clusters of documents in the semantic space can then be interpreted and transformed into meaningful topics by means of Gaussian mixture modeling. In using PVTM, we identify innovation-related topics from 170, 000 technology news articles published over a span of 20 years and gather insights about their diffusion state by measuring the topic importance in the corpus over time. Our results suggest that PVTM is a credible alternative to widely used topic models for the discovery of latent topics in (technology-related) news articles. An examination of three exemplary topics shows that innovation diffusion could be assessed using topic importance measures derived from PVTM. Thereby, we find that PVTM diffusion indicators for certain topics are Granger causal to Google Trend indices with matching search terms.",
        "DOI": "10.1371/journal.pone.0226685",
        "paper_author": "Lenz D.",
        "affiliation_name": "Justus-Liebig-Universität Gießen",
        "affiliation_city": "Giessen",
        "affiliation_country": "Germany",
        "affiliation_id": "60017134",
        "affiliation_state": "Hessen"
    },
    {
        "paper_title": "Space situational awareness sensor tasking: Comparison of machine learning with classical optimization methods",
        "publication": "Journal of Guidance, Control, and Dynamics",
        "citied_by": "29",
        "cover_date": "2020-01-01",
        "Abstract": "The object population in the space around the Earth is subject to increase. With the advancements in sensor capabilities, it can be expected that, at the same time, more of those objects will be detected. Although this allows for significant advances in understanding of the detectable objects and the expansion of object catalogs, it also leads to significant stress on the sensor systems and makes efficient sensor tasking a prime challenge. To solve sensor tasking as an optimization problem of observing objects when a priori information is available, various methods exist. Classical methods rely on the problem being formulated in a convex representation. Computationally intensive methods based on artificial intelligence, such as machine learning, have recently gained a lot of attention and are suitable for problems even when no convex formulation can be found. In this paper, performances of a simple traditional greedy algorithm and the more complex Weapon-Target Assignment algorithm are compared with the performance of two machine learning algorithms: ant colony and distributed Q-learning. Ant colony optimization is a swarm optimization path finding methodology based on probabilistic principles; distributed Q-learning aims to find an optimal policy by maximizing the expected reward received. As an application case the observation of known objects in the geosynchronous region with a ground-based sensor is used, and performance is evaluated in terms of the number of objects successfully tracked, the computational efficiency of running the algorithms, and the difficulty of tuning the algorithms. The ant colony solutions track the most objects, whereas the greedy algorithm is the most efficient; additionally, the ant colony and distributed Q-learning require significant tuning of the algorithms before employment.",
        "DOI": "10.2514/1.G004279",
        "paper_author": "Little B.D.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60148444",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Using neural networks to reduce sensor cluster interferences and power consumption in smart cities",
        "publication": "International Journal of Sensor Networks",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "In the future smart cities, billions of communicating Internet of Things (IoT) devices are expected which communicate wirelessly in the limited spectrum offered by 5G and long-range technologies. This means that a huge amount of interferences must be overcome by new agile technologies without wasting power resources in the IoT nodes. In this paper, these challenges are addressed by a neural-network-based machine learning system that is based on frequency-domain features extracted from the communication channel. This machine learning system predicts the needed transmit power to overcome the interferences by a predefined margin. Extensive system simulations have been performed on a real-world dataset that shows power savings in the range of 35-83% and a packet receive-ratio of at least 95%. Similarly, it has been found that the system converts after approximately 50 supervised samples, which supports efficient tracking of parameter variations in the communication channel.",
        "DOI": "10.1504/IJSNET.2020.104460",
        "paper_author": "Lynggaard P.",
        "affiliation_name": "Technical University of Denmark",
        "affiliation_city": "Lyngby",
        "affiliation_country": "Denmark",
        "affiliation_id": "60011373",
        "affiliation_state": "Hovedstaden"
    },
    {
        "paper_title": "Active Balance Control of Humanoid Locomotion Based on Foot Position Compensation",
        "publication": "Journal of Bionic Engineering",
        "citied_by": "17",
        "cover_date": "2020-01-01",
        "Abstract": "A foot positioning compensator is developed in this paper for a full-body humanoid to retrieve its balance during continuous walking. An online Foot Position Compensator (FPC) is designed to improve the robustness of biped walking, which can modify predefined step position and step duration online with sensory feedback. Foot placement parameters are learned by the FPC based on the Policy Gradient Reinforcement Learning (PGRL) method. Moreover, the FPC assists the humanoid robot in rejecting external disturbances and recovering the walking position by re-planning the trajectories of walking pattern and the Center of Mass (CoM). An upper body pose control strategy is also presented to further enhance the performance of humanoid robots to overcome strong external disturbances. The advantages of this proposed method are that it neither requires prior information about the walking terrain conditions, nor relies on range sensor information for surface topology measurement. The effectiveness of the proposed method is verified via Webots simulation and real experiments on a full-body humanoid NAO robot.",
        "DOI": "10.1007/s42235-020-0011-x",
        "paper_author": "Liu C.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Dialog management of healthcare consulting system by utilizing deceptive information",
        "publication": "Transactions of the Japanese Society for Artificial Intelligence",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "In the past few years, there has been an increasing number of works on negotiation dialog. These studies mainly focus on situations where interlocutors work cooperatively to agree on a mutual objective that can fulfill each of their own requirements. However, in real-life negotiation, such situations do not happen all the time, and participants can tell lies to gain an advantage. In this research, we propose a negotiation dialog management system that detects when a user is lying and a dialog behavior for how the system should react when faced with a lie. We design our system for a living habits consultation scenario, where the system tries to persuade users to adopt healthy living habits. We show that we can use the partially observable Markov decision process (POMDP) to model this conversation and use reinforcement learning to train the system's policy. Our experimental results demonstrate that the dialog manager considering deceptive states outperformed a dialog manager without this consideration in terms of the accuracy of action selection, and improved the true success rate of the negotiation in the healthcare consultation domin.",
        "DOI": "10.1527/tjsai.DSI-C",
        "paper_author": "Nguyen T.T.",
        "affiliation_name": "Nara Institute of Science and Technology",
        "affiliation_city": "Ikoma",
        "affiliation_country": "Japan",
        "affiliation_id": "60025017",
        "affiliation_state": "Nara"
    },
    {
        "paper_title": "Learning from animals: How to Navigate Complex Terrains",
        "publication": "PLoS Computational Biology",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "We develop a method to learn a bio-inspired motion control policy using data collected from hawkmoths navigating in a virtual forest. A Markov Decision Process (MDP) framework is introduced to model the dynamics of moths and sparse logistic regression is used to learn control policy parameters from the data. The results show that moths do not favor detailed obstacle location information in navigation, but rely heavily on optical flow. Using the policy learned from the moth data as a starting point, we propose an actor-critic learning algorithm to refine policy parameters and obtain a policy that can be used by an autonomous aerial vehicle operating in a cluttered environment. Compared with the moths’ policy, the policy we obtain integrates both obstacle location and optical flow. We compare the performance of these two policies in terms of their ability to navigate in artificial forest areas. While the optimized policy can adjust its parameters to outperform the moth’s policy in each different terrain, the moth’s policy exhibits a high level of robustness across terrains.",
        "DOI": "10.1371/journal.pcbi.1007452",
        "paper_author": "Zhu H.",
        "affiliation_name": "Boston University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60019674",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Propagation of the Multi-Scalar Aggregative Standardized Precipitation Temperature Index and its Application",
        "publication": "Water Resources Management",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "Nowadays, drought monitoring with various probabilistic indices has become common. However, the interpretation and applicability issues of multi-scalar drought indices are the main problems in establishing accurate drought mitigation policies. In addition, the spatial structure of environmental variables such as rainfall, and the spatial distribution of meteorological stations have a vital role in the precise and accurate analysis. In this paper, a comprehensive drought index “the Multi-Scalar Aggregative Standardized Precipitation Temperature Index (MASPTI)” is proposed. In MASPTI procedure, temporal vectors of various time scales of SPTI index are accumulated by giving long term transient weights. These weights are determined from the steady state probabilities of drought classification states in each time scale. Application of the proposed index is based on spatio-temporal data of SPTI index at its various time scales. However, before proceeding to evaluate MASPTI, we first observed the spatial relevancy of important time scale of SPTI index using the machine learning wrapper Boruta algorithm. The preliminary evaluation of MASPTI is based on four meteorological stations located in different homogeneous climatic clusters in Pakistan. The comparative analysis includes the ordinal association, where historical qualitative series of drought classes attained from MASPTI are compared with existing SPTI time scales. Outcomes show that MASPTI has the ability to capture joint characterization of drought by incorporating long term probabilities as a transient weight.",
        "DOI": "10.1007/s11269-019-02469-4",
        "paper_author": "Ali Z.",
        "affiliation_name": "Quaid-i-Azam University",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60064058",
        "affiliation_state": "Islamabad"
    },
    {
        "paper_title": "Online model-free reinforcement learning for the automatic control of a flexible wing aircraft",
        "publication": "IET Control Theory and Applications",
        "citied_by": "17",
        "cover_date": "2020-01-01",
        "Abstract": "The control problem of the flexible wing aircraft is challenging due to the prevailing high non-linear deformations in the flexible wing system. This urged for new control mechanisms that are robust to the real-time variations in the wing's aerodynamics. An online control mechanism based on a value iteration reinforcement learning process is developed for flexible wing aerial structures. It employs a model-free control policy framework and a guaranteed convergent adaptive learning architecture to solve the system's Bellman optimality equation. A Riccati equation is derived and shown to be equivalent to solving the underlying Bellman equation. The online reinforcement learning solution is implemented using means of an adaptive-critic mechanism. The controller is proven to be asymptotically stable in the Lyapunov sense. It is assessed through computer simulations and its superior performance is demonstrated in two scenarios under different operating conditions.",
        "DOI": "10.1049/iet-cta.2018.6163",
        "paper_author": "Abouheaf M.",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60028897",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Using Machine Learning in Psychiatry: The Need to Establish a Framework That Nurtures Trustworthiness",
        "publication": "Schizophrenia Bulletin",
        "citied_by": "51",
        "cover_date": "2020-01-01",
        "Abstract": "The rapid embracing of artificial intelligence in psychiatry has a flavor of being the current \"wild west\"; a multidisciplinary approach that is very technical and complex, yet seems to produce findings that resonate. These studies are hard to review as the methods are often opaque and it is tricky to find the suitable combination of reviewers. This issue will only get more complex in the absence of a rigorous framework to evaluate such studies and thus nurture trustworthiness. Therefore, our paper discusses the urgency of the field to develop a framework with which to evaluate the complex methodology such that the process is done honestly, fairly, scientifically, and accurately. However, evaluation is a complicated process and so we focus on three issues, namely explainability, transparency, and generalizability, that are critical for establishing the viability of using artificial intelligence in psychiatry. We discuss how defining these three issues helps towards building a framework to ensure trustworthiness, but show how difficult definition can be, as the terms have different meanings in medicine, computer science, and law. We conclude that it is important to start the discussion such that there can be a call for policy on this and that the community takes extra care when reviewing clinical applications of such models.",
        "DOI": "10.1093/schbul/sbz105",
        "paper_author": "Chandler C.",
        "affiliation_name": "College of Engineering and Applied Science",
        "affiliation_city": "Boulder",
        "affiliation_country": "United States",
        "affiliation_id": "60154476",
        "affiliation_state": "CO"
    },
    {
        "paper_title": "Definition and evaluation of model-free coordination of electrical vehicle charging with reinforcement learning",
        "publication": "IEEE Transactions on Smart Grid",
        "citied_by": "107",
        "cover_date": "2020-01-01",
        "Abstract": "Demand response (DR) becomes critical to manage the charging load of a growing electric vehicle (EV) deployment. Initial DR studies mainly adopt model predictive control, but models are largely uncertain for the EV scenario (e.g., customer behavior). Model-free approaches, based on reinforcement learning (RL), are an attractive alternative. We propose a new Markov decision process (MDP) formulation in the RL framework, to jointly coordinate a set of charging stations. State-of-the-art algorithms either focus on a single EV, or control an aggregate of EVs in multiple steps (e.g., 1) make aggregate load decisions and 2) translate the aggregate decision to individual EVs). In contrast, our RL approach jointly controls the whole set of EVs at once. We contribute a new MDP formulation with a scalable state representation independent of the number of charging stations. Using a batch RL algorithm, fitted Q-iteration, we learn an optimal charging policy. With simulations using real-world data, we: 1) differentiate settings in training the RL policy (e.g., the time span covered by training data); 2) compare its performance to an oracle all-knowing benchmark (providing an upper performance bound); 3) analyze performance fluctuations throughout a full year; and 4) demonstrate generalization capacity to larger sets of charging stations.",
        "DOI": "10.1109/TSG.2019.2920320",
        "paper_author": "Sadeghianpourhamami N.",
        "affiliation_name": "Universiteit Gent",
        "affiliation_city": "Ghent",
        "affiliation_country": "Belgium",
        "affiliation_id": "60033316",
        "affiliation_state": "VOV"
    },
    {
        "paper_title": "7th International Conference on Applied Computing and Information Technology, ACIT 2019",
        "publication": "Studies in Computational Intelligence",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 12 papers. The special focus in this conference is on Applied Computing and Information Technology. The topics include: Implementation of Creation and Distribution Processes of DACS Rules for the Cloud Type Virtual Policy Based Network Management Scheme for the Specific Domain; Transforming YAWL Workflows into Petri Nets; improvement of Data Sparsity and Scalability Problems in Collaborative Filtering Based Recommendation Systems; a Study on the Methods for Establishing Security Information & Event Management; Multi-TSV (Through Silicon Via) Error Detection Using the Non-contact Probing Method; real-Time Ultra-Wide Viewing Player for Spatial and Temporal Random Access; a Study on the Faith Score of Telephone Voices Using Machine Learning; a Comparative Study of Using Bag-of-Words and Word-Embedding Attributes in the Spoiler Classification of English and Thai Text; fall Detection of Elderly Persons by Action Recognition Using Data Augmentation and State Transition Diagram; Elliptic Curve Cryptography and LSB Steganography for Securing Identity Data.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Autonomous Vehicle for Obstacle Detection and Avoidance Using Reinforcement Learning",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "13",
        "cover_date": "2020-01-01",
        "Abstract": "Obstacle detection and avoidance during navigation of an autonomous vehicle is one of the challenging problems. Different sensors like RGB camera, Radar, and Lidar are presently used to analyze the environment around the vehicle for obstacle detection. Analyzing the environment using supervised learning techniques has proven to be an expensive process due to the training of different obstacle for different scenarios. In order to overcome such difficulty, in this paper Reinforcement Learning (RL) techniques are used to understand the uncertain environment based on sensor information to make the decision. Policy free, model-free Q-learning based RL algorithm with the multilayer perceptron neural network (MLP-NN) is applied and trained to predict optimal vehicle future action based on the current state of the vehicle. Further, the proposed Q-Learning with MLP-NN based approach is compared with the state of the art, namely, Q-learning. A simulated urban area obstacles scenario is considered with the different number of ultrasonic radar sensors in detecting obstacles. The experimental result shows that Q-learning with MLP-NN along with the ultrasonic sensors is proven to be more accurate than conventional Q-learning technique with the ultrasonic sensors. Hence it is demonstrated that combining Q-learning with MLP-NN will improve in predicting obstacles for autonomous vehicle navigation.",
        "DOI": "10.1007/978-981-15-0035-0_5",
        "paper_author": "Arvind C.S.",
        "affiliation_name": "Dr. Ambedkar Institute of Technology",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60094585",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Unmanned Aerial Vehicles Path Planning Based on Deep Reinforcement Learning",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "Obstacle avoidance and path planning of unmanned aerial vehicles (UAVs) is an essential and challenging task, especially in the unknown environment with dynamic obstacles. To address this problem, a method of UAV path planning based on Deep Q-Learning is proposed. The experience replay mechanism is introduced in the deep reinforcement learning (DRL) process, and a value network is established to calculate the optimal value for the action of the UAV. The optimal flight policy of the UAV is determined through the ϵ -greed algorithm. The experimental results show that the UAV with well-trained model can avoid the obstacles in motion perfectly, and the cruise time is reduced by half compared with the untrained UAV.",
        "DOI": "10.1007/978-3-030-32456-8_9",
        "paper_author": "Wang G.",
        "affiliation_name": "Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60031863",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Development of an Efficient Driving Strategy for Connected and Automated Vehicles at Signalized Intersections: A Reinforcement Learning Approach",
        "publication": "IEEE Transactions on Intelligent Transportation Systems",
        "citied_by": "228",
        "cover_date": "2020-01-01",
        "Abstract": "The concept of Connected and Automated Vehicles (CAVs) enables instant traffic information to be shared among vehicle networks. With this newly proposed concept, a vehicle's driving behaviour will no longer be solely based on the driver's limited and incomplete observation. By taking advantages of the shared information, driving behaviours of CAVs can be improved greatly to a more responsible, accurate and efficient level. This study proposed a reinforcement-learning-based car following model for CAVs in order to obtain an appropriate driving behaviour to improve travel efficiency, fuel consumption and safety at signalized intersections in real-time. The result shows that by specifying an effective reward function, a controller can be learned and works well under different traffic demands as well as traffic light cycles with different durations. This study reveals a great potential of emerging reinforcement learning technologies in transport research and applications.",
        "DOI": "10.1109/TITS.2019.2942014",
        "paper_author": "Zhou M.",
        "affiliation_name": "Tencent",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60114181",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "3rd International Conference on Smart Trends for Information Technology and Computer Communications, SmartCom 2019",
        "publication": "Smart Innovation, Systems and Technologies",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 50 papers. The special focus in this conference is on Smart Trends for Information Technology and Computer Communications. The topics include: An Automated Framework to Uncover Malicious Traffic for University Campus Network; comparative Analysis of K-Means Algorithm and Particle Swarm Optimization for Search Result Clustering; design and Implementation of Rule-Based Hindi Stemmer for Hindi Information Retrieval; research on the Development Trend of Ship Integrated Power System Based on Patent Analysis; detection of Data Anomalies in Fog Computing Architectures; cloud Data for Marketing in Tourism Sector; road Travel Time Prediction Method Based on Random Forest Model; video Synchronization and Alignment Using Motion Detection and Contour Filtering; Mutichain Enabled EHR Management System and Predictive Analytics; PSO-ANN-Based Computer-Aided Diagnosis and Classification of Diabetes; quick Insight of Research Literature Using Topic Modeling; Secure Cloud-Based E-Healthcare System Using Ciphertext-Policy Identity-Based Encryption (CP-IBE); security Vulnerabilities of OpenStack Cloud and Security Assessment Using Different Software Tools; smart Physical Intruder Detection System for Highly Sensitive Area; two-level Classification of Radar Targets Using Machine Learning; a Cognitive Semantic-Based Approach for Human Event Detection in Videos; analysis of Adequate Bandwidths to Guarantee an Electoral Process in Ecuador; load and Renewable Energy Forecasting for System Modelling, an Effort in Reducing Renewable Energy Curtailment; RAM: Rotating Angle Method of Clustering for Heterogeneous-Aware Wireless Sensor Networks; GWO-GA Based Load Balanced and Energy Efficient Clustering Approach for WSN; Round Robin Scheduling Based on Remaining Time and Median (RR_RT&M) for Cloud Computing; proof of Authenticity-Based Electronic Medical Records Storage on Blockchain.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence, the internet of things, and virtual clinics: ophthalmology at the digital translation forefront",
        "publication": "The Lancet Digital Health",
        "citied_by": "63",
        "cover_date": "2020-01-01",
        "Abstract": "NA",
        "DOI": "10.1016/S2589-7500(19)30217-1",
        "paper_author": "Ting D.S.W.",
        "affiliation_name": "Duke-NUS Medical School",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60095034",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Sentiment analysis of tweets using supervised learning algorithms",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "19",
        "cover_date": "2020-01-01",
        "Abstract": "The proliferation of user-generated content (UGC) on social media platforms has made user opinion tracking a strenuous job. Twitter, being a huge mi-croblogging social network, could be used to accumulate views about politics, trends, and products, etc. Sentiment analysis is a mining technique employed to peruse opinions, emotions, and attitude of people toward any subject. This is conceptualized using digital data (text, video, audio, etc.) or psychological characteristics of humans. This procedure assists in opinion mining without having to read a plethora of tweets manually. The results could be wielded to provide an edge for businesses and governments in rolling out new entities (policies, products, topic, event). Cleaning data is an important step here, which we accomplished using regular expressions and NLTK library in Python. We implemented nine separate algorithms to classify tweets and compare their performance on cleaned data. It was observed that the convolutional neural network produces the most optimal results at 79% accuracy.",
        "DOI": "10.1007/978-981-15-0029-9_26",
        "paper_author": "Mehta R.P.",
        "affiliation_name": "Narsee Monjee Institute of Management Studies, Mumbai",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60079592",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Principal Component and Static Factor Analysis",
        "publication": "Advanced Studies in Theoretical and Applied Econometrics",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Factor models are widely used in macroeconomic forecasting. With large datasets, factor models are particularly useful due to their intrinsic dimension reduction. In this chapter, we consider the forecasting problem using factor models, with special consideration to large datasets. In factor model estimation, we focus on principal component methods, and show how the estimated factors can be used to assist forecasting. Machine learning methods are discussed to encompass the high-dimensional features of large factor models. We consider policy evaluation as a nowcasting problem and show how factor analysis can be used to perform counter-factual outcome prediction in complicated models with observational data. The usage of all these techniques is illustrated by empirical examples.",
        "DOI": "10.1007/978-3-030-31150-6_8",
        "paper_author": "Cao J.",
        "affiliation_name": "The University of Chicago Booth School of Business",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States",
        "affiliation_id": "60112748",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "learning with policy prediction in continuous state-action multi-agent decision processes",
        "publication": "Soft Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Inspired by recent attention to multi-agent reinforcement learning (MARL), the effort to provide efficient methods in this field is increasing. But, there are many issues which make this field challenging. Decision making of an agent depends on the other agents’ behavior while sharing information is not always possible. On the other hand, predicting other agents’ policies while they are also learning is a difficult task. Also, some agents in a multi-agent environment may not behave rationally. In such cases, achieving Nash equilibrium, as a target in a system with ideal behavior, is not possible and the best policy is the best response to the other agents’ policies. In addition, many real-world multi-agent problems have a continuous nature in their state and action spaces. This induces complexity in MARL scenarios. In order to overcome these challenges, we propose a new multi-agent learning method based on fuzzy least-square policy iteration. The proposed method consists of two parts: an Inner Model as one other agent policy approximation method and a multi-agent method to learn a near-optimal policy based on the others agents’ policies. Both of the proposed algorithms are applicable to problems with continuous state and action spaces. These methods can be used independently or in combination with each other. They are defined to perfectly suit each other so that the outputs of Inner Model are entirely consistent with the nature of inputs of the multi-agent method. In problems with no possibility of explicit communication, combinations of the proposed methods are recommended. In addition, theoretical analysis proves the near optimality of the policies learned by these methods. We evaluate the learning methods in problems with continuous state-action spaces: the well-known predator–prey problem and the unit commitment problem in the smart power grid. The results are satisfactory and show acceptable performance of our methods.",
        "DOI": "10.1007/s00500-019-04600-4",
        "paper_author": "Ghorbani F.",
        "affiliation_name": "University of Zanjan",
        "affiliation_city": "Zanjan",
        "affiliation_country": "Iran",
        "affiliation_id": "60012659",
        "affiliation_state": "Zanjan"
    },
    {
        "paper_title": "Empowering Citizens' Cognition and Decision Making in Smart Sustainable Cities",
        "publication": "IEEE Consumer Electronics Magazine",
        "citied_by": "29",
        "cover_date": "2020-01-01",
        "Abstract": "Advances in Internet technologies have made it possible to gather, store, and process large quantities of data, often in real time. When considering smart and sustainable cities, this big data generates useful information and insights to citizens, service providers, and policy makers. Transforming this data into knowledge allows for empowering citizens' cognition as well as supporting decision-making routines. However, several operational and computing issues need to be taken into account: 1) efficient data description and visualization, 2) forecasting citizens behavior, and 3) supporting decision making with intelligent algorithms. This paper identifies several challenges associated with the use of data analytics in smart sustainable cities and proposes the use of hybrid simulation-optimization and machine learning algorithms as an effective approach to empower citizens' cognition and decision making in such ecosystems.",
        "DOI": "10.1109/MCE.2019.2941457",
        "paper_author": "Beneicke J.",
        "affiliation_name": "Universitat Oberta de Catalunya",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain",
        "affiliation_id": "60002581",
        "affiliation_state": "Barcelona"
    },
    {
        "paper_title": "National Cyber Summit, NCS 2019",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 22 papers. The special focus in this conference is on National Cyber Summit. The topics include: Using modeled cyber-physical systems for independent review of intrusion detection systems; an efficient profiling-based side-channel attack on graphics processing units; enforcing secure coding rules for the c programming language using the eclipse development environment; a specification-based intrusion prevention system for malicious payloads; analyzing the vulnerabilities introduced by ddos mitigation techniques for software-defined networks; investigating crowdsourcing to generate distractors for multiple-choice assessments; a sequential investigation model for solving time critical digital forensic cases involving a single investigator; a cloud based entitlement granting engine; machine learning cyberattack strategies with petri nets with players, strategies, and costs; safety and consistency of subject attributes for attribute-based pre-authorization systems; capacity building for a cybersecurity workforce through hands-on labs for internet-of-things security; Cybersecurity framework requirements to quantify vulnerabilities based on GQM; impact of targeted cyber attacks on electrical power systems; A study on recent applications of blockchain technology in vehicular adhoc network (VANET); an analysis of cybersecurity legislation and policy creation on the state level; a survey of cyber security practices in small businesses; improving the efficiency of a cyber competition through data analysis: A guide to cyberforce competition™ red team recruitment and structure; interdisciplinary cybersecurity: Rethinking the approach and the process; developing and implementing a cybersecurity course for middle school; a comparison study of cybersecurity workforce frameworks and future directions.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "In Pursuit of Evidence in Air Pollution Epidemiology: The Role of Causally Driven Data Science",
        "publication": "Epidemiology",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "NA",
        "DOI": "10.1097/EDE.0000000000001090",
        "paper_author": "Carone M.",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States",
        "affiliation_id": "60015481",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Classifying Different Stages of Parkinson’s Disease Through Random Forests",
        "publication": "IFMBE Proceedings",
        "citied_by": "44",
        "cover_date": "2020-01-01",
        "Abstract": "Parkinson’s disease (PD) is a progressive, neurodegenerative and age-related disease whose clinical characteristics include both motor and non-motor symptoms. Gait analysis, a three dimensional, non-invasive and computerized analysis of gait, can analyse walking features and carry out spatial and temporal parameters that can be included in machine learning algorithms. Knime analytics platform is employed to implement Random Forests. The aim of the present research is to distinguish De Novo PD patients (patients in early phase, without treatment) and Stable PD patients (patients in intermediate phase, in stable treatment) using spatial and temporal parameters of gait analysis. The dataset consists of 59 people, 32.2% De Novo and 67.8% Stable patients. Results show high accuracy (84.6%) and capacity to detect De Novo patients (94.9% of sensitivity). Recall and precision got high values, too. Despite needing further investigation, this pilot research should encourage health policy and facilities to introduce machine learning techniques and gait analysis in clinical practice. Moreover, results suggest the existence of gait patterns characterizing each phase of Parkinson’s disease.",
        "DOI": "10.1007/978-3-030-31635-8_140",
        "paper_author": "Ricciardi C.",
        "affiliation_name": "Azienda Ospedaliera Universitaria Federico II",
        "affiliation_city": "Naples",
        "affiliation_country": "Italy",
        "affiliation_id": "60113487",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Guidelines for applied machine learning in construction industry—A case of profit margins estimation",
        "publication": "Advanced Engineering Informatics",
        "citied_by": "48",
        "cover_date": "2020-01-01",
        "Abstract": "The progress in the field of Machine Learning (ML) has enabled the automation of tasks that were considered impossible to program until recently. These advancements today have incited firms to seek intelligent solutions as part of their enterprise software stack. Even governments across the globe are motivating firms through policies to tape into ML arena as it promises opportunities for growth, productivity and efficiency. In reflex, many firms embark on ML without knowing what it entails. The outcomes so far are not as expected because the ML, as hyped by tech firms, is not the silver bullet. However, whatever ML offers, firms urge to capitalise it for their competitive advantage. Applying ML to real-life construction industry problems goes beyond just prototyping predictive models. It entails intensive activities which, in addition to training robust ML models, provides a comprehensive framework for answering questions asked by construction folks when intelligent solutions are getting deployed at their premises to substitute or facilitate their decision-making tasks. Existing ML guidelines used in the IT industry are vastly restricted to training ML models. This paper presents guidelines for Applied Machine Learning (AML) in the construction industry from training to operationalising models, which are drawn from our experience of working with construction folks to deliver Construction Simulation Tool (CST). The unique aspect of these guidelines lies not only in providing a novel framework for training models but also answering critical questions related to model confidence, trust, interpretability, bias, feature importance and model extrapolation capabilities. Generally, ML models are presumed black boxes; hence argued that nobody knows what a model learns and how it generates predictions. Even very few ML folks barely know approaches to answer questions asked by the end users. Without explaining the competence of ML, the broader adoption of intelligent solutions in the construction industry cannot be attained. This paper proposed a detailed process for AML to develop intelligent solutions in the construction industry. Most discussions in the study are elaborated in the context of profit margin estimation for new projects.",
        "DOI": "10.1016/j.aei.2019.101013",
        "paper_author": "Bilal M.",
        "affiliation_name": "Bristol Business School",
        "affiliation_city": "Bristol",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60114346",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Verifying the Gaming Strategy of Self-learning Game by Using PRISM-Games",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement Learning (RL) gained a huge amount of popularity in computer science; applied in fields such as gaming, intelligent robots, remote sensing, and so on. The objective of reinforcement learning is to generate the optimal policy. The main problem of that optimal policy is that it is not fully guaranteed to be satisfied all the system specifications. Model checking is a technique to verify the system to meet the system specifications. PRISM-games is one of the model-checking tools that is used to verify the probabilistic system with competitive or collaborative behavior. Safe Reinforcement Learning via Shielding is a method that uses shield to restrict the action of the RL agent if it violates the specification using temporal logic. This paper presents to compare the winning strategies between three agents; Monte-Carlo Tree Search agent (MCTS), RL agent and shielded RL agent (SRL) which uses PRISM-games to restrict the action based on Tic-Tac-Toe game. Over thousand times of simulations has been made, the experiments show that MCTS agent has the highest win rate compared to other agents, but the losing rate of the shielded agent is reduced by using PRISM-games.",
        "DOI": "10.1007/978-3-030-33585-4_15",
        "paper_author": "Zaw H.H.",
        "affiliation_name": "University of Information Technology",
        "affiliation_city": "Yangon",
        "affiliation_country": "Myanmar",
        "affiliation_id": "114777977",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Model-free Optimal Tracking Control for an Aircraft Skin Inspection Robot with Constrained-input and Input Time-delay via Integral Reinforcement Learning",
        "publication": "International Journal of Control, Automation and Systems",
        "citied_by": "8",
        "cover_date": "2020-01-01",
        "Abstract": "This paper presents a model-free optimal tracking control algorithm for an aircraft skin inspection robot with constrained-input and input time-delay. To tackle the input time-delay problem, the original system is transformed into a delay-free system with constrained-input and unknown input coupling term. In order to overcome the optimal control problem subject to constrained-input, a discounted value function is employed. In general, it is known that the HJB equation does not admit a classical smooth solution. Moreover, since the input coupling term of the delay-free system is unknown, a model-free integral reinforcement learning(IRL) algorithm which only requires the system sampling data generated by arbitrary different control inputs and external disturbances is proposed. The model-free IRL method is implemented on an actor-critic neural network (NN) structure. A system sampling data set is utilized to learn the value function and control policy. Finally, the simulation verifies the effectiveness of the proposed algorithm.",
        "DOI": "10.1007/s12555-019-0351-7",
        "paper_author": "Wu X.",
        "affiliation_name": "Nanjing University of Aeronautics and Astronautics",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60021666",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Apprenticeship Learning Based Load Balancing Technique for Cloud Environment",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Cloud Computing is accessing and handling data and documents from the internet rather than from any individual computer hard drive. The issues faced by cloud computing are security, privacy, vendor lock-in, server downtime, network connectivity, dependency, vulnerability to attacks, load balancing, etc. Load balancing in cloud computing is one of the important issues as huge amount of load need to be efficiently distributed among the servers. The existing approaches to address load balancing issue are throttled technology, active clustering, central policy for virtual machine, round robin technology, max-min min-min, fuzzy monitoring, honeybee foraging behavior, reinforcement learning, etc. The primary drawbacks of above-mentioned approaches towards load balancing are lowered throughput, high migration rate, overloading and under-loading of resources. This paper proposes a novel architecture which applies apprenticeship learning for load balancing in the cloud. Its performance is found to be good with respect to parameters like response time, accuracy, learning rate and speed.",
        "DOI": "10.1007/978-3-030-30465-2_74",
        "paper_author": "Vatsalya S.",
        "affiliation_name": "Siddaganga Institute of Technology",
        "affiliation_city": "Tumkur",
        "affiliation_country": "India",
        "affiliation_id": "60104736",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Deep-Reinforcement-Learning-Based Autonomous Voltage Control for Power Grid Operations",
        "publication": "IEEE Transactions on Power Systems",
        "citied_by": "325",
        "cover_date": "2020-01-01",
        "Abstract": "In this letter, a novel autonomous control framework 'Grid Mind' is proposed for the secure operation of power grids based on cutting-edge artificial intelligence (AI) technologies. The proposed platform provides a data-driven, model-free and closed-loop control agent trained using deep reinforcement learning (DRL) algorithms by interacting with massive simulations and/or real environment of a power grid. The proposed agent learns from scratch to master the power grid voltage control problem purely from data. It can make autonomous voltage control (AVC) strategies to support grid operators in making effective and timely control actions, according to the current system conditions detected by real-time measurements from supervisory control and data acquisition (SCADA) or phasor measurement units (PMUs). Two state-of-the-art DRL algorithms, namely deep Q-network (DQN) and deep deterministic policy gradient (DDPG), are proposed to formulate the AVC problem with performance compared. Case studies on a realistic 200-bus test system demonstrate the effectiveness and promising performance of the proposed framework.",
        "DOI": "10.1109/TPWRS.2019.2941134",
        "paper_author": "Duan J.",
        "affiliation_name": "GEIRI North America",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States",
        "affiliation_id": "118735874",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Predictability in sovereign bond returns using technical trading rules: Do developed and emerging markets differ?",
        "publication": "North American Journal of Economics and Finance",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "The study examines the predictability of 48 sovereign bond markets based on a strategy of 27,000 technical trading rules. These rules represent four popular trading rule classes, they are: moving average, filtering, support and resistance, and channel breakout rules, with numerous variants in each class. Empirical results show that (i) investing in sovereign bond markets is predictable, based on the buy-sell signals generated by trading rules, with the predictability of the emerging Asian markets being significantly higher than those of the advanced markets; (ii) the predictability is generally higher when the US tightens its monetary policies or undergoes recession or a financial crisis; (iii) two-thirds of sovereign bond markets have a higher predictability when we use a machine learning algorithm to determine the best trading rule strategy; and (iv) the predictability of a sovereign bond market is higher when the economy has a less effective government, lower regulatory quality, lower degree of financial openness, higher political risk, lower income and faster real money growth. Our results suggest that shocks originating from US monetary policy or economic conditions could have a considerable spillover effect on sovereign bond markets, particularly the emerging Asian markets.",
        "DOI": "10.1016/j.najef.2019.101105",
        "paper_author": "Fong T.P.W.",
        "affiliation_name": "Hong Kong Monetary Authority",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "China",
        "affiliation_id": "60023371",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Employing Night-Time Light Images for Wealth Assessment in India: A Machine Learning Perspective",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "With the urbanization upsurge and rapid development, India is the country with dense population of urban dwellers. However, disparity among various states in terms of infrastructures, per-capita wealth and socio-economic dynamics is still the serious issue that hinders the development process. In this light, wealth assessment for various states becomes crucial for effective policy implementation. Although, collecting data about economic status of Indian families is highly cost extensive, motivating remote sensing as a cheaper yet robust way of measuring economic livelihood data. In this work, we combine publicly available night time light imagery which are good proxy measure for economic activities, along with recent survey data to develop machine learning based models that predict per-capita consumption in India. We have presented state-wise economic status for different states and showed the effectiveness of the proposed scheme by comparing with the ground survey data.",
        "DOI": "10.1007/978-3-030-30577-2_54",
        "paper_author": "Saini S.",
        "affiliation_name": "Jaypee Institute of Information Technology",
        "affiliation_city": "Noida",
        "affiliation_country": "India",
        "affiliation_id": "60080305",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "DP-Siam: Dynamic Policy Siamese Network for Robust Object Tracking",
        "publication": "IEEE Transactions on Image Processing",
        "citied_by": "34",
        "cover_date": "2020-01-01",
        "Abstract": "Balancing the trade-off between real-time performance and accuracy in object tracking is a major challenge. In this paper, a novel dynamic policy gradient Agent-Environment architecture with Siamese network (DP-Siam) is proposed to train the tracker to increase the accuracy and the expected average overlap while performing in real-time. DP-Siam is trained offline with reinforcement learning to produce a continuous action that predicts the optimal object location. DP-Siam has a novel architecture that consists of three networks: an Agent network to predict the optimal state (bounding box) of the object being tracked, an Environment network to get the Q-value during the offline training phase to minimize the error of the loss function, and a Siamese network to produce a heat-map. During online tracking, the Environment network acts as a verifier to the Agent network action. Extensive experiments are performed on six widely used benchmarks: OTB2013, OTB50, OTB100, VOT2015, VOT2016 and VOT2018. The results show that DP-Siam significantly outperforms the current state-of-the-art trackers.",
        "DOI": "10.1109/TIP.2019.2942506",
        "paper_author": "Abdelpakey M.H.",
        "affiliation_name": "Memorial University of Newfoundland",
        "affiliation_city": "St John's",
        "affiliation_country": "Canada",
        "affiliation_id": "60019000",
        "affiliation_state": "NL"
    },
    {
        "paper_title": "Smart and Resilient EV Charging in SDN-Enhanced Vehicular Edge Computing Networks",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "157",
        "cover_date": "2020-01-01",
        "Abstract": "Smart grid delivers power with two-way flows of electricity and information with the support of information and communication technologies. Electric vehicles (EVs) with rechargeable batteries can be powered by external sources of electricity from the grid, and thus charging scheduling that guides low-battery EVs to charging services is significant for service quality improvement of EV drivers. The revolution of communications and data analytics driven by massive data in smart grid brings many challenges as well as chances for EV charging scheduling, and how to schedule EV charging in a smart and resilient way has inevitably become a crucial problem. Toward this end, we in this paper leverage the techniques of software defined networking and vehicular edge computing to investigate a joint problem of fast charging station selection and EV route planning. Our objective is to minimize the total overhead from users' perspective, including time and charging fares in the whole process, considering charging availability and electricity price fluctuation. A deep reinforcement learning (DRL) based solution is proposed to determine an optimal charging scheduling policy for low-battery EVs. Besides, in response to dynamic EV charging, we further develop a resilient EV charging strategy based on incremental update, with EV drivers' user experience being well considered. Extensive simulations demonstrate that our proposed DRL-based solution obtains near-optimal EV charging overhead with good adaptivity, and the solution with incremental update achieves much higher computation efficiency than conventional game-theoretical method in dynamic EV charging.",
        "DOI": "10.1109/JSAC.2019.2951966",
        "paper_author": "Liu J.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Matching code and law: achieving algorithmic fairness with optimal transport",
        "publication": "Data Mining and Knowledge Discovery",
        "citied_by": "30",
        "cover_date": "2020-01-01",
        "Abstract": "Increasingly, discrimination by algorithms is perceived as a societal and legal problem. As a response, a number of criteria for implementing algorithmic fairness in machine learning have been developed in the literature. This paper proposes the continuous fairness algorithm (CFA θ) which enables a continuous interpolation between different fairness definitions. More specifically, we make three main contributions to the existing literature. First, our approach allows the decision maker to continuously vary between specific concepts of individual and group fairness. As a consequence, the algorithm enables the decision maker to adopt intermediate “worldviews” on the degree of discrimination encoded in algorithmic processes, adding nuance to the extreme cases of “we’re all equal” and “what you see is what you get” proposed so far in the literature. Second, we use optimal transport theory, and specifically the concept of the barycenter, to maximize decision maker utility under the chosen fairness constraints. Third, the algorithm is able to handle cases of intersectionality, i.e., of multi-dimensional discrimination of certain groups on grounds of several criteria. We discuss three main examples (credit applications; college admissions; insurance contracts) and map out the legal and policy implications of our approach. The explicit formalization of the trade-off between individual and group fairness allows this post-processing approach to be tailored to different situational contexts in which one or the other fairness criterion may take precedence. Finally, we evaluate our model experimentally.",
        "DOI": "10.1007/s10618-019-00658-8",
        "paper_author": "Zehlike M.",
        "affiliation_name": "Max Planck Institute for Software Systems",
        "affiliation_city": "Saarbrucken",
        "affiliation_country": "Germany",
        "affiliation_id": "60002485",
        "affiliation_state": "Saarland"
    },
    {
        "paper_title": "Excitation emission matrix fluorescence spectroscopy for combustion generated particulate matter source identification",
        "publication": "Atmospheric Environment",
        "citied_by": "16",
        "cover_date": "2020-01-01",
        "Abstract": "The inhalation of particulate matter (PM) is a significant health risk associated with reduced life expectancy due to increased cardio-pulmonary disease and exacerbation of respiratory diseases such as asthma and pneumonia. PM originates from natural and anthropogenic sources including combustion engines, cigarettes, agricultural burning, and forest fires. Identifying the source of PM can inform effective mitigation strategies and policies, but this is difficult to do using current techniques. Here we present a method for identifying PM source using excitation emission matrix (EEM) fluorescence spectroscopy and a machine learning algorithm. We collected combustion generated PM2.5 from wood burning, diesel exhaust, and cigarettes using filters. Filters were weighted to determine mass concentration followed by extraction into cyclohexane and analysis by EEM fluorescence spectroscopy. Spectra obtained from each source served as training data for a convolutional neural network (CNN) used for source identification in mixed samples. This method can predict the presence or absence of the three laboratory sources with an overall accuracy of 89% when the threshold for classifying a source as present is 1.1 μg/m3 in air over a 24-h sampling time. The limit of detection for cigarette, diesel and wood are 0.7, 2.6, 0.9 μg/m3, respectively, in air assuming a 24-h sampling time at an air sampling rate of 1.8 L per minute. We applied the CNN algorithm developed using the laboratory training data to a small set of field samples and found the algorithm was effective in some cases but would require a training data set containing more samples to be more broadly applicable.",
        "DOI": "10.1016/j.atmosenv.2019.117065",
        "paper_author": "Rutherford J.W.",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States",
        "affiliation_id": "60015481",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Understanding cities with machine eyes: A review of deep computer vision in urban analytics",
        "publication": "Cities",
        "citied_by": "130",
        "cover_date": "2020-01-01",
        "Abstract": "Modelling urban systems has interested planners and modellers for decades. Different models have been achieved relying on mathematics, cellular automation, complexity, and scaling. While most of these models tend to be a simplification of reality, today within the paradigm shifts of artificial intelligence across the different fields of science, the applications of computer vision show promising potential in understanding the realistic dynamics of cities. While cities are complex by nature, computer vision shows progress in tackling a variety of complex physical and non-physical visual tasks. In this article, we review the tasks and algorithms of computer vision and their applications in understanding cities. We attempt to subdivide computer vision algorithms into tasks, and cities into layers to show evidence of where computer vision is intensively applied and where further research is needed. We focus on highlighting the potential role of computer vision in understanding urban systems related to the built environment, natural environment, human interaction, transportation, and infrastructure. After showing the diversity of computer vision algorithms and applications, the challenges that remain in understanding the integration between these different layers of cities and their interactions with one another relying on deep learning and computer vision. We also show recommendations for practice and policy-making towards reaching AI-generated urban policies.",
        "DOI": "10.1016/j.cities.2019.102481",
        "paper_author": "Ibrahim M.R.",
        "affiliation_name": "UCL Engineering",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60176024",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Benefits of influenza vaccination on the associations between ambient air pollution and allergic respiratory diseases in children and adolescents: New insights from the Seven Northeastern Cities study in China",
        "publication": "Environmental Pollution",
        "citied_by": "21",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Little information exists on interaction effects between air pollution and influenza vaccination on allergic respiratory diseases. We conducted a large population-based study to evaluate the interaction effects between influenza vaccination and long-term exposure to ambient air pollution on allergic respiratory diseases in children and adolescents. Methods: A cross-sectional study was investigated during 2012–2013 in 94 schools from Seven Northeastern Cities (SNEC) in China. Questionnaires surveys were obtained from 56 137 children and adolescents aged 2–17 years. Influenza vaccination was defined as receipt of the influenza vaccine. We estimated air pollutants exposure [nitrogen dioxide (NO2) and particulate matter with aerodynamic diameters ≤1 μm (PM1), ≤2.5 μm (PM2.5) and ≤10 μm (PM10)] using machine learning methods. We employed two-level generalized linear mix effects model to examine interactive effects between influenza vaccination and air pollution exposure on allergic respiratory diseases (asthma, asthma-related symptoms and allergic rhinitis), after controlling for important covariates. Results: We found statistically significant interactions between influenza vaccination and air pollutants on allergic respiratory diseases and related symptoms (doctor-diagnosed asthma, current wheeze, wheeze, persistent phlegm and allergic rhinitis). The adjusted ORs for doctor-diagnosed asthma, current wheeze and allergic rhinitis among the unvaccinated group per interquartile range (IQR) increase in PM1 and PM2.5 were significantly higher than the corresponding ORs among the vaccinated group [For PM1, doctor-diagnosed asthma: OR: 1.89 (95%CI: 1.57–2.27) vs 1.65 (95%CI: 1.36–2.00); current wheeze: OR: 1.50 (95%CI: 1.22–1.85) vs 1.10 (95%CI: 0.89–1.37); allergic rhinitis: OR: 1.38 (95%CI: 1.15–1.66) vs 1.21 (95%CI: 1.00–1.46). For PM2.5, doctor-diagnosed asthma: OR: 1.81 (95%CI: 1.52–2.14) vs 1.57 (95%CI: 1.32–1.88); current wheeze: OR: 1.46 (95%CI: 1.21–1.76) vs 1.11 (95%CI: 0.91–1.35); allergic rhinitis: OR: 1.35 (95%CI: 1.14–1.60) vs 1.19 (95%CI: 1.00–1.42)]. The similar patterns were observed for wheeze and persistent phlegm. The corresponding p values for interactions were less than 0.05, respectively. We assessed the risks of PM1-related and PM2.5-related current wheeze were decreased by 26.67% (95%CI: 1.04%–45.66%) and 23.97% (95%CI: 0.21%–42.08%) respectively, which was attributable to influenza vaccination (both p for efficiency <0.05). Conclusions: Influenza vaccination may play an important role in mitigating the detrimental effects of long-term exposure to ambient air pollution on childhood allergic respiratory diseases. Policy targeted at increasing influenza vaccination may yield co-benefits in terms of reduced allergic respiratory diseases.",
        "DOI": "10.1016/j.envpol.2019.113434",
        "paper_author": "Liu K.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021182",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Jointly dampening traffic oscillations and improving energy consumption with electric, connected and automated vehicles: A reinforcement learning based approach",
        "publication": "Applied Energy",
        "citied_by": "225",
        "cover_date": "2020-01-01",
        "Abstract": "It has been well recognized that human driver's limits, heterogeneity, and selfishness substantially compromise the performance of our urban transport systems. In recent years, in order to deal with these deficiencies, our urban transport systems have been transforming with the blossom of key vehicle technology innovations, most notably, connected and automated vehicles. In this paper, we develop a car following model for electric, connected and automated vehicles based on reinforcement learning with the aim to dampen traffic oscillations (stop-and-go traffic waves) caused by human drivers and improve electric energy consumption. Compared to classical modelling approaches, the proposed reinforcement learning based model significantly reduces the modelling constraints and has the capability of self-learning and self-correction. Experiment results demonstrate that the proposed model is able to improve travel efficiency by reducing the negative impact of traffic oscillations, and it can also reduce the average electric energy consumption.",
        "DOI": "10.1016/j.apenergy.2019.114030",
        "paper_author": "Qu X.",
        "affiliation_name": "Chalmers University of Technology",
        "affiliation_city": "Gothenburg",
        "affiliation_country": "Sweden",
        "affiliation_id": "60000990",
        "affiliation_state": "Vastra Gotaland"
    },
    {
        "paper_title": "Policy Analysis of Adaptive Traffic Signal Control Using Reinforcement Learning",
        "publication": "Journal of Computing in Civil Engineering",
        "citied_by": "23",
        "cover_date": "2020-01-01",
        "Abstract": "Previous research studies have successfully developed adaptive traffic signal controllers using reinforcement learning; however, few have focused on analyzing what specifically reinforcement learning does differently than other traffic signal control methods. This study proposes and develops two reinforcement learning adaptive traffic signal controllers, analyzes their learned policies, and compares them to a Webster's controller. The asynchronous Q-learning and advantage actor-critic adaptive algorithms are used to develop reinforcement learning traffic signal controllers using neural network function approximation with two action spaces. Using an aggregate statistic state representation (i.e., vehicle queue and density), the proposed reinforcement learning traffic signal controllers develop the optimal policy in a dynamic, stochastic traffic microsimulation. Results show that the reinforcement learning controllers increases red and yellow times but ultimately achieve superior performance compared to the Webster's controller, reducing mean queues, stopped time, and travel time. The reinforcement learning controllers exhibit goal-oriented behavior, developing a policy that excludes many phases found in a tradition phase cycle (i.e., protected turning movements) instead of choosing phases that maximize reward, as opposed to the Webster's controller, which is constrained by cyclical logic that diminishes performance.",
        "DOI": "10.1061/(ASCE)CP.1943-5487.0000859",
        "paper_author": "Genders W.",
        "affiliation_name": "McMaster University",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada",
        "affiliation_id": "60031828",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "IDRiD: Diabetic Retinopathy – Segmentation and Grading Challenge",
        "publication": "Medical Image Analysis",
        "citied_by": "246",
        "cover_date": "2020-01-01",
        "Abstract": "Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on “Diabetic Retinopathy – Segmentation and Grading” was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular.",
        "DOI": "10.1016/j.media.2019.101561",
        "paper_author": "Porwal P.",
        "affiliation_name": "Shri Guru Gobind Singhji Institute of Engineering and Technology",
        "affiliation_city": "Nanded",
        "affiliation_country": "India",
        "affiliation_id": "60104057",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Advanced text-mining for trend analysis of Russia's Extractive Industries",
        "publication": "Futures",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "The world economy relies on access to industrial metals, oil and gas for maintaining its critical industrial infrastructure. Although demand is likely to remain high, the most accessible deposits have been depleted. Future capacity growth will be facilitated through further technological developments. Russia as a leading producer is paying great attention to strengthening its competitive edge in global markets. This paper reports on a large-scale technology foresight study of the Russian extractive sector (including oil and gas), which combined expert-based foresight activities with statistical analyses and text-mining techniques based on artificial intelligence and machine learning technologies. The presented methodology helped to link the technologies to dominant discussions (e.g. climate change vs rural development) and to flag key trends. Furthermore, quantitative estimates can be identified quickly. The study's methodology should function as an example for similar studies to support policy planning and investment decisions based on text-mining techniques.",
        "DOI": "10.1016/j.futures.2019.102476",
        "paper_author": "Gokhberg L.",
        "affiliation_name": "HSE University",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60020513",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Identifying the drivers and predicting the outcome of conservation agriculture globally",
        "publication": "Agricultural Systems",
        "citied_by": "17",
        "cover_date": "2020-01-01",
        "Abstract": "Conservation agriculture (CA) is a potentially viable system for sustainable intensification across diverse agroecological and socio-economic landscapes. This analysis applied machine-learning techniques to a wealth of published data to create a predictive model of the agronomic outcome of CA relative to conventional practice (CP) based on 21 variables. The impact of different management scenarios were modeled by manipulating model input values for residue retention and N application rate, CA duration, and the ratio of CA to CP plant stand. Subsequently, the model was used to rank the importance of these variables in determining model outcome, and to create global maps of CA:CP outcomes for rainfed maize, wheat and soybean. Results showed that over-yielding of CA relative to CP was driven by a complex of climate, soil, geographic and management variables, and cannot be predicted accurately from precipitation amount or aridity index alone. Success of CA greatly increases with mean air temperature from 20 °C and with duration of CA for up to 13 years. Predictive maps showed that CA has the potential to increase system productivity in the humid tropics and sub-tropics given good plant stand establishment. Finally, this research demonstrates the ability of predictive modeling techniques to overcome the knowledge bottleneck created by the sole use of descriptive models within the CA literature to date. Predictive models can be used as an important tool by policy-makers and funding organizations to target financial resources to those regions where CA adoption will have the greatest impact on productivity.",
        "DOI": "10.1016/j.agsy.2019.102692",
        "paper_author": "Laborde J.P.",
        "affiliation_name": "Rwanda Institute for Conservation Agriculture",
        "affiliation_city": "Kigali",
        "affiliation_country": "Rwanda",
        "affiliation_id": "60280038",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting and explaining corruption across countries: A machine learning approach",
        "publication": "Government Information Quarterly",
        "citied_by": "69",
        "cover_date": "2020-01-01",
        "Abstract": "In the era of Big Data, Analytics, and Data Science, corruption is still ubiquitous and is perceived as one of the major challenges of modern societies. A large body of academic studies has attempted to identify and explain the potential causes and consequences of corruption, at varying levels of granularity, mostly through theoretical lenses by using correlations and regression-based statistical analyses. The present study approaches the phenomenon from the predictive analytics perspective by employing contemporary machine learning techniques to discover the most important corruption perception predictors based on enriched/enhanced nonlinear models with a high level of predictive accuracy. Specifically, within the multiclass classification modeling setting that is employed herein, the Random Forest (an ensemble-type machine learning algorithm) is found to be the most accurate prediction/classification model, followed by Support Vector Machines and Artificial Neural Networks. From the practical standpoint, the enhanced predictive power of machine learning algorithms coupled with a multi-source database revealed the most relevant corruption-related information, contributing to the related body of knowledge, generating actionable insights for administrator, scholars, citizens, and politicians. The variable importance results indicated that government integrity, property rights, judicial effectiveness, and education index are the most influential factors in defining the corruption level of significance.",
        "DOI": "10.1016/j.giq.2019.101407",
        "paper_author": "Lima M.S.M.",
        "affiliation_name": "Spears School of Business at Oklahoma State University",
        "affiliation_city": "Stillwater",
        "affiliation_country": "United States",
        "affiliation_id": "60159673",
        "affiliation_state": "OK"
    },
    {
        "paper_title": "Federated Echo State Learning for Minimizing Breaks in Presence in Wireless Virtual Reality Networks",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "86",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, the problem of enhancing the virtual reality (VR) experience for wireless users is investigated by minimizing the occurrence of breaks in presence (BIP) that can detach the users from their virtual world. To measure the BIP for wireless VR users, a novel model that jointly considers the VR application type, transmission delay, VR video quality, and users' awareness of the virtual environment is proposed. In the developed model, base stations (BSs) transmit VR videos to the wireless VR users using directional transmission links so as to provide high data rates for the VR users, thus, reducing the number of BIP for each user. Since the body movements of a VR user may result in a blockage of its wireless link, the location and orientation of VR users must also be considered when minimizing BIP. The BIP minimization problem is formulated as an optimization problem which jointly considers the predictions of users' locations, orientations, and their BS association. To predict the orientation and locations of VR users, a distributed learning algorithm based on the machine learning framework of deep echo state networks (ESNs) is proposed. The proposed algorithm uses federated learning to enable multiple BSs to locally train their deep ESNs using their collected data and cooperatively build a learning model to predict the entire users' locations and orientations. Using these predictions, the user association policy that minimizes BIP is derived. Simulation results demonstrate that the developed algorithm reduces the users' BIP by up to 16% and 26%, respectively, compared to centralized ESN and deep learning algorithms.",
        "DOI": "10.1109/TWC.2019.2942929",
        "paper_author": "Chen M.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Multi-agent Deep Reinforcement Learning for Pursuit-Evasion Game Scalability",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "In a pursuit-evasion game, the pursuers usually can capture the evaders successfully when the practical application environment is similar to the one that the pursuers was trained on. However, when there are some pursuers broken down or some new pursuers joining, which will result in that the number of agents in practice is different from the number of agents that was trained on. In other words, the environment has changed. In multi-agent deep reinforcement leaning algorithm, which means that the input and output dimension of network has changed, the trained pursuers may can not capture the evaders in the real-world application. To solve this problem, we proposed a multi-agent reinforcement learning framework so that when the number of pursuers has changed, the pursuers can also capture the evaders. Based on deep deterministic policy gradient (DDPG) framework and Bi directional recurrent neural network (Bi-RNN), we proposed the scalable deep reinforcement learning method for pursuit-evasion game, and apply it into multi-agent pursuit-evasion game in 2D-Dynamic environment. In this game, the speed of evaders is higher than the pursuers, but the number of evaders is less than the pursuers. Our experimental results show that this algorithm can increase the scalability and stability of multi-agent pursuit-evasion game.",
        "DOI": "10.1007/978-981-32-9682-4_69",
        "paper_author": "Xu L.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Spatial quantification to examine the effectiveness of payments for ecosystem services: A case study of Costa Rica's Pago de Servicios Ambientales",
        "publication": "Ecological Indicators",
        "citied_by": "24",
        "cover_date": "2020-01-01",
        "Abstract": "Payments for ecosystem services (PES) have been developed as a policy instrument to help safeguard the contributions of ecosystems to human well-being. A critical measure of a programme's effectiveness is whether it is generating an additional supply of ecosystem services (ES). So far, there has been limited analysis of PES programmes based on the actual supply of ES. In line with ecosystem accounting principles, we spatially quantified three ES recognised by Costa Rica's Pago de Servicios Ambientales (PSA) programme: carbon storage, soil erosion control and habitat suitability for biodiversity as a cultural ES. We used the machine learning algorithm random forest to model carbon storage, the Revised Universal Soil Loss Equation (RUSLE) to model soil erosion control and Maxent to model habitat suitability. The additional effect of the PSA programme on carbon storage was examined using linear regression. Forested land was found to store 235.3 Mt of carbon, control for 148 Mt yr−1 of soil erosion and contain 762,891 ha of suitable habitat for three iconic but threatened species. PSA areas enrolled in the programme in both 2011 and 2013 were found to store an additional 9 tonC ha−1 on average. As well as enabling a direct quantification of additionality, spatial distribution analysis can help administrators target high-value areas, confirm the conditional supply of ES and support the monetary valuation of ES. Ultimately, this can help improve the social efficiency of payments by enabling a comparison of societal costs and benefits.",
        "DOI": "10.1016/j.ecolind.2019.105766",
        "paper_author": "Havinga I.",
        "affiliation_name": "Wageningen University &amp; Research",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60004156",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Indirect and direct training of spiking neural networks for end-to-end control of a lane-keeping vehicle",
        "publication": "Neural Networks",
        "citied_by": "40",
        "cover_date": "2020-01-01",
        "Abstract": "Building spiking neural networks (SNNs) based on biological synaptic plasticities holds a promising potential for accomplishing fast and energy-efficient computing, which is beneficial to mobile robotic applications. However, the implementations of SNNs in robotic fields are limited due to the lack of practical training methods. In this paper, we therefore introduce both indirect and direct end-to-end training methods of SNNs for a lane-keeping vehicle. First, we adopt a policy learned using the Deep Q-Learning (DQN) algorithm and then subsequently transfer it to an SNN using supervised learning. Second, we adopt the reward-modulated spike-timing-dependent plasticity (R-STDP) for training SNNs directly, since it combines the advantages of both reinforcement learning and the well-known spike-timing-dependent plasticity (STDP). We examine the proposed approaches in three scenarios in which a robot is controlled to keep within lane markings by using an event-based neuromorphic vision sensor. We further demonstrate the advantages of the R-STDP approach in terms of the lateral localization accuracy and training time steps by comparing them with other three algorithms presented in this paper.",
        "DOI": "10.1016/j.neunet.2019.05.019",
        "paper_author": "Bing Z.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60021182",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Dependency-Aware Attention Control for Image Set-Based Face Recognition",
        "publication": "IEEE Transactions on Information Forensics and Security",
        "citied_by": "30",
        "cover_date": "2020-01-01",
        "Abstract": "This paper considers the problem of image set-based face verification and identification. Unlike traditional single sample (an image or a video) setting, this situation assumes the availability of a set of heterogeneous collection of orderless images and videos. The samples can be taken at different check points, different identity documents $etc$. The importance of each image is usually considered either equal or based on a quality assessment of that image independent of other images and/or videos in that image set. How to model the relationship of orderless images within a set remains a challenge. We address this problem by formulating it as a Markov Decision Process (MDP) in a latent space. Specifically, we first propose a dependency-aware attention control (DAC) network, which uses actor-critic reinforcement learning for attention decision of each image to exploit the correlations among the unordered images. An off-policy experience replay is introduced to speed up the learning process. Moreover, the DAC is combined with a temporal model for videos using divide and conquer strategies. We also introduce a pose-guided representation (PGR) scheme that can further boost the performance at extreme poses. We propose a parameter-free PGR without the need for training as well as a novel metric learning-based PGR for pose alignment without the need for pose detection in testing stage. Extensive evaluations on IJB-A/B/C, YTF, Celebrity-1000 datasets demonstrate that our method outperforms many state-of-art approaches on the set-based as well as video-based face recognition databases.",
        "DOI": "10.1109/TIFS.2019.2938418",
        "paper_author": "Liu X.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "The Mechanism of Servant Leadership on the Safety Performance of High-Speed Railway Drivers",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Servant leadership has a significant effect on the safety performance of high-speed railway drivers. Guided by the social learning theory, we propose a mediation relationship model to explain why and how servant leadership can affect the safety performance. First, we propose that servant leadership can promote the safety compliance and safety participation of high-speed railway drivers. Second, we use a structural equation model to analysis the mediation effect of public service motivation and test the mediation effect with a bootstrap method. The samples consist of 300 high-speed railway drivers from 11 railway bureaus in China. Finally, we propose some management policies and suggestions based on our research, which have important implications for management practice of high-speed railway drivers.",
        "DOI": "10.1007/978-981-13-8779-1_96",
        "paper_author": "Ye L.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022381",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A General Technique to Combine Off-Policy Reinforcement Learning Algorithms with Satellite Attitude Control",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "Reinforcement learning method has great potential in constructing next generation of intelligent attitude control for satellite. However, designing reward function when using reinforcement learning algorithm to achieve specific task is a hard problem, which limits reinforcement learning algorithm used in satellite attitude control. For avoiding complicated reward engineering, we present a technique which allows the off-policy reinforcement learning algorithm can be easily migrated to construct satellite attitude control method. A satellite simulation environment is constructed. In this environment, we train an attitude control agent with the technique and validate the technique’s effectiveness.",
        "DOI": "10.1007/978-981-32-9050-1_80",
        "paper_author": "Zhang J.",
        "affiliation_name": "Institute of Software Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025256",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Predicting serious injuries due to road traffic accidents in Malaysia by means of artificial neural network",
        "publication": "Lecture Notes in Mechanical Engineering",
        "citied_by": "7",
        "cover_date": "2020-01-01",
        "Abstract": "Malaysia has recorded a steady increase in the number of road traffic accidents from year to year at an alarming rate of 5%. Serious injuries due to the accidents, which could lead to permanent disability, might cause a long-term problem to the nation economy-wise. Predicting the number of serious injury cases in the future is important in understanding the trend of road traffic accidents to help policymakers in proposing a countermeasure. Time-series model has been employed to predict the occurrence of road traffic crashes including fatalities. Nonetheless, the prediction of serious injury cases, which should not be taken lightly due to its potential impact, has not been proposed especially with regards to Malaysian road traffic accident data. This study attempts to employ artificial neural networks (ANN), a machine learning algorithm, to predict the number of serious injury cases in Malaysia based on the road traffic accident data of the past 20 years. Machine learning has increasingly been adopted in recent years owing to its ability to predict as well as catering for the non-linear behaviour of the data examined. A single-hidden ANN model was developed based on seven features, namely the number of registered vehicles, population, length of federal road, length of FELDA road, length of federal institutional road, length of federal territory road, and length of the expressway in order to predict the number of serious injuries. It was established from the present investigation that the developed ANN model is capable to predict the number of serious injuries from 1997 until 2017 with a mean absolute percentage error of only 3%. This demonstrates the capability of the developed machine learning in road traffic accident prediction, and it could be useful in outlining an action plan to mitigate the number of serious injuries in Malaysia.",
        "DOI": "10.1007/978-981-13-9539-0_8",
        "paper_author": "Radzuan N.Q.",
        "affiliation_name": "Universiti Malaysia Pahang Al-Sultan Abdullah",
        "affiliation_city": "Pekan",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090654",
        "affiliation_state": "Pahang"
    },
    {
        "paper_title": "Multi-class twitter data categorization and geocoding with a novel computing framework",
        "publication": "Cities",
        "citied_by": "15",
        "cover_date": "2020-01-01",
        "Abstract": "This study details the progress in transportation data analysis with a novel computing framework in keeping with the continuous evolution of the computing technology. The computing framework combines the Labeled Latent Dirichlet Allocation (L-LDA)-incorporated Support Vector Machine (SVM) classifier with the supporting computing strategy on publicly available Twitter data in determining transportation-related events to provide reliable information to travelers. The analytical approach includes analyzing tweets using text classification and geocoding locations based on string similarity. A case study conducted for the New York City and its surrounding areas demonstrates the feasibility of the analytical approach. Approximately 700,010 tweets are analyzed to extract relevant transportation-related information for one week. The SVM classifier achieves >85% accuracy in identifying transportation-related tweets from structured data. To further categorize the transportation-related tweets into sub-classes: incident, congestion, construction, special events, and other events, three supervised classifiers are used: L-LDA, SVM, and L-LDA incorporated SVM. Findings from this study demonstrate that the analytical framework, which uses the L-LDA incorporated SVM, can classify roadway transportation-related data from Twitter with over 98.3% accuracy, which is significantly higher than the accuracies achieved by standalone L-LDA and SVM.",
        "DOI": "10.1016/j.cities.2019.102410",
        "paper_author": "Khan S.M.",
        "affiliation_name": "Clemson University College of Engineering, Computing and Applied Sciences",
        "affiliation_city": "Clemson",
        "affiliation_country": "United States",
        "affiliation_id": "60139609",
        "affiliation_state": "SC"
    },
    {
        "paper_title": "Reinforcement Learning for Active Damping of Harmonically Excited Pendulum with Highly Nonlinear Actuator",
        "publication": "Conference Proceedings of the Society for Experimental Mechanics Series",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "Active vibration dampers can reduce or eliminate unwanted vibrations, but determining a good control policy can be challenging for highly nonlinear systems. For these types of systems, reinforcement learning is one method to optimize a control policy with only limited prior knowledge of the system dynamics. An experimental system was constructed by attaching a permanent magnet to the end of a pendulum and positioning an electromagnetic actuator below the resting position of the pendulum. The pendulum was excited with a sinusoidal force applied horizontally at the pivot point, and the control input was the applied voltage across the electromagnet. Due to the geometric arrangement and the strong dependence of magnetic force on distance, the relationship between the position of the pendulum and the actuation torque for any control input was highly nonlinear. A generalized version of the PILCO reinforcement learning algorithm was used to optimize a control policy for the electromagnet with the objective of minimizing the distance between the end of the pendulum and the downward position. After 16 s of interaction with the experimental system, the resulting learned policy was able to substantially reduce the amplitude of oscillation. This experiment illustrates the applicability of reinforcement learning to highly nonlinear active vibration damping problems.",
        "DOI": "10.1007/978-3-030-12391-8_15",
        "paper_author": "Turner J.D.",
        "affiliation_name": "Pratt School of Engineering",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60140102",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Guiding Public Health Policy by Using Grocery Transaction Data to Predict Demand for Unhealthy Beverages",
        "publication": "Studies in Computational Intelligence",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "Sugar-Sweetened Beverages (SSB) are the primary source of artificially added sugar and cause many chronic diseases. Taxation of SSB has been proposed, but limited evidence exists to guide this public health policy. Grocery transaction data, with price, discounting and other product attributes, present an opportunity to evaluate the likely effects of taxation policy. Sales are non-linearly associated with price and are affected by the prices of multiple competing brands. We evaluated the predictive performance of Boosted Decision Tree Regression (B-DTR) and Deep Neural Networks (DNN) that account for the non-linearity and competition, and compared their performance to a benchmark regression, the Least Absolute Shrinkage and Selection Operator (LASSO). B-DTR and DNN showed a lower Mean Squared Error (MSE) of prediction in the sales of major SSB brands in comparison to LASSO, indicating a superior accuracy in predicting the effectiveness of SSB taxation. We have demonstrated how machine learning methods applied to large transactional data from grocery stores can provide evidence to guide public health policy.",
        "DOI": "10.1007/978-3-030-24409-5_16",
        "paper_author": "Lu X.H.",
        "affiliation_name": "Surveillance Lab",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "115000813",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Judgment analysis for real-time decision support using the cognitive shadow policy-capturing system",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "The present work introduces a prototype intelligent cognitive assistant that continuously learns the decision pattern of the user online, instantly recognizes deviations from that pattern as potential errors and then alerts the user accordingly. We investigated the potential of this prototype system using a human-in-the-loop experiment designed to assess impacts on decision making performance, workload and trust in the decision support capability. Study participants interacted with a naval air-defence testbed to classify radar contacts as friendly, uncertain or hostile based on track parameters displayed on screen. The between-group experimental design included a control condition and two decision support conditions (with system reliability provided either offline or online). Results showed that both decision support conditions significantly improved task accuracy compared to the control condition. The advisory system was successful at improving human performance without burdening the user with excessive additional workload, even when providing reliability information in real time.",
        "DOI": "10.1007/978-3-030-25629-6_13",
        "paper_author": "Lafond D.",
        "affiliation_name": "Thales Research and Technology Canada",
        "affiliation_city": "Quebec",
        "affiliation_country": "Canada",
        "affiliation_id": "120049398",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "1st International Congress on Blockchain and Applications, BLOCKCHAIN 2019",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 21 papers. The special focus in this conference is on Blockchain and Applications. The topics include: Anticipatory policy as a design challenge: Experiments with stakeholders engagement in blockchain and distributed ledger technologies (bdlts); the electronic bill of lading: Challenges of paperless trade; a methodology for a probabilistic security analysis of sharding-based blockchain protocols; the “Tokenization” of the eparticipation in public governance: An opportunity to hack democracy; blockchain approach to solve collective decision making problems for swarm robotics; prediction of transaction confirmation time in ethereum blockchain using machine learning; improving event monitoring in iot network using an integrated blockchain-distributed pattern recognition scheme; on value preservation with distributed ledger technologies, intelligent agents, and digital preservation; blockchain technology: A review of the current challenges of cryptocurrency; lightning network: A comparative review of transaction fees and data analysis; a blockchain- and ai-based platform for global employability; blockchain and biometrics: A first look into opportunities and challenges; do smart contract languages need to be turing complete?; towards integration of blockchain and iot: A bibliometric analysis of state-of-the-art; clinicappchain: A low-cost blockchain hyperledger solution for healthcare; smart contracts are more than objects: Pro-activeness on the blockchain; blockchain based informed consent with reputation support; privacy centric collaborative machine learning model training via blockchain; fuzzy rules based solution for system administration security management via a blockchain.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Future of smart parking: Automated valet parking using deep Q-learning",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "23",
        "cover_date": "2020-01-01",
        "Abstract": "Population growth and increasing the number of vehicles are causing many different economic and environmental problems. One of the crucial ones is finding a parking space. In order to deal with this issue, we can construct new parking lots or optimizing the old ones. In fact, building new parking costs a lot and will destroy nature. Most of the time there is not enough space to build a new one in cities. Thanks to the evolution of IoT, the implementation of smart parking based on IoT is possible. In this paper, We are focusing on an eco-friendly system called Automated Valet Parking which uses hybrid robotic valets in smart parking and helps optimizing parking space usage with Deep Q-Learning which is a reinforcement learning method, In order to achieve high performance. Because reinforcement learning is a goal absorbing algorithm and by well-defining the objective function (The goal), We can achieve optimum policy.",
        "DOI": "10.1007/978-3-030-23946-6_20",
        "paper_author": "Shoeibi N.",
        "affiliation_name": "Babol Noshirvani University of Technology",
        "affiliation_city": "Babol",
        "affiliation_country": "Iran",
        "affiliation_id": "60089290",
        "affiliation_state": "Mazandaran"
    },
    {
        "paper_title": "A data-driven supply-side approach for estimating cross-border Internet purchases within the European Union",
        "publication": "Journal of the Royal Statistical Society. Series A: Statistics in Society",
        "citied_by": "6",
        "cover_date": "2020-01-01",
        "Abstract": "The digital economy is a highly relevant item on the European Union's policy agenda. We focus on cross-border Internet purchases, as part of the digital economy, the total value of which cannot be accurately estimated by using existing consumer survey approaches. In fact, they lead to a serious underestimation. To obtain an accurate estimate, we propose a three-step data-driven approach based on supply-side data. For the first step, we develop a data-driven generic method for firm level probabilistic record linkage of tax data and business registers. In the second step, we use machine learning to identify webshops based on website data. Then, in the third step, we implement recently developed bias correction techniques that have hitherto been overlooked by the machine learning community. Subsequently, we claim that our three-step approach can be applied to any European Union member state, leading to more accurate estimates of cross-border Internet purchases than those obtained by currently existing approaches. To justify the claim, we apply our approach to the Netherlands for the year 2016 and find an estimate that is six times as high as current estimates, having a standard deviation of 8%. Hence, we may conclude that our new approach deserves more investigation and applications.",
        "DOI": "10.1111/rssa.12487",
        "paper_author": "Meertens Q.A.",
        "affiliation_name": "Centraal Bureau voor de Statistiek",
        "affiliation_city": "The Hague",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60103556",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A prospective prediction tool for understanding Crimean–Congo haemorrhagic fever dynamics in Turkey",
        "publication": "Clinical Microbiology and Infection",
        "citied_by": "23",
        "cover_date": "2020-01-01",
        "Abstract": "Objectives: We aimed to develop a prospective prediction tool on Crimean–Congo haemorrhagic fever (CCHF) to identify geographic regions at risk. The tool could support public health decision-makers in implementation of an effective control strategy in a timely manner. Methods: We used monthly surveillance data between 2004 and 2015 to predict case counts between 2016 and 2017 prospectively. The Turkish nationwide surveillance data set collected by the Ministry of Health contained 10 411 confirmed CCHF cases. We collected potential explanatory covariates about climate, land use, and animal and human populations at risk to capture spatiotemporal transmission dynamics. We developed a structured Gaussian process algorithm and prospectively tested this tool predicting the future year's cases given past years' cases. Results: We predicted the annual cases in 2016 and 2017 as 438 and 341, whereas the observed cases were 432 and 343, respectively. Pearson's correlation coefficient and normalized root mean squared error values for 2016 and 2017 predictions were (0.83; 0.58) and (0.87; 0.52), respectively. The most important covariates were found to be the number of settlements with fewer than 25 000 inhabitants, latitude, longitude and potential evapotranspiration (evaporation and transpiration). Conclusions: Main driving factors of CCHF dynamics were human population at risk in rural areas, geographical dependency and climate effect on ticks. Our model was able to prospectively predict the numbers of CCHF cases. Our proof-of-concept study also provided insight for understanding possible mechanisms of infectious diseases and found important directions for practice and policy to combat against emerging infectious diseases.",
        "DOI": "10.1016/j.cmi.2019.05.006",
        "paper_author": "Ak ",
        "affiliation_name": "Koç Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Türkiye",
        "affiliation_id": "60006369",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Multidisciplinary International Conference of Research Applied to Defense and Security, MICRADS 2019",
        "publication": "Smart Innovation, Systems and Technologies",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 41 papers. The special focus in this conference is on Research Applied to Defense and Security. The topics include: Visual Analytics for the Reduction of Air Pollution on Real-Time Data Derived from WSN; toward the Development of Surveillance and Reconnaissance Capacity in Ecuador: Geolocation System for Ground Targets Based on an Electro-Optical Sensor; fuzzy Logic for Speed Control in Object Tracking Inside a Restricted Area Using a Drone; Micro-controlled EOG Device for Track and Control Military Applications; Multilevel Military Leadership Model: Correlation Between the Levels and Styles of Military Leadership Using MLQ in the Ecuadorian Armed Forces; e-leadership Using WhatsApp, A Challenge for Navy Organizations: An Empirical Study; career Anchors for the Portuguese Army’s Volunteers and Contract Personnel: Using the Career Orientations Inventory; Implementation of Dubin Curves-Based RRT* Using an Aerial Image for the Determination of Obstacles and Path Planning to Avoid Them During Displacement of the Mobile Robot; machine Learning and Multipath Fingerprints for Emitter Localization in Urban Scenario; virtual Rehabilitation System Using Electromyographic Sensors for Strengthening Upper Extremities; single Sign-on Implementation: Leveraging Browser Storage for Handling Tabbed Browsing Sign-outs; the Portuguese Special Operations Forces as Instrument of Foreign Policy: The Case Study of Afghanistan; The Internal–External Security Nexus: EU Operation Sophia Through the Lens of Securitization; The Evolution of EU’s Maritime Security Thinking; the Obstacles Women Face in Gaining Access to Special Operations Forces; the Transformation of the Defense and Security Sector to the New Logistics 4.0: Public–Private Cooperation as a Necessary Catalyst Strategy.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Training a Four Legged Robot via Deep Reinforcement Learning and Multibody Simulation",
        "publication": "Computational Methods in Applied Sciences",
        "citied_by": "3",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper we use the Proximal Policy Optimization (PPO) deep reinforcement learning algorithm to train a Neural Network to control a four-legged robot in simulation. Reinforcement learning in general can learn complex behavior policies from simple state-reward tuples datasets and PPO in particular has proved its effectiveness in solving complex tasks with continuous states and actions. Moreover, since it is model-free, it is general and can adapt to changes in the environment or in the robot itself. The virtual environment used to train the agent was modeled using our physics engine Project Chrono. Chrono can handle non smooth dynamics simulation allowing us to introduce stiff leg-ground contacts and using its Python interface Pychrono it can be interfaced with the Machine Leaning framework TensorFlow with ease. We trained the Neural Network until it learned to control the motor torques, then various policy Neural Network input state choices have been compared.",
        "DOI": "10.1007/978-3-030-23132-3_47",
        "paper_author": "Benatti S.",
        "affiliation_name": "Università di Parma",
        "affiliation_city": "Parma",
        "affiliation_country": "Italy",
        "affiliation_id": "60004969",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "Land Use Land Cover Change Detection Through GIS and Unsupervised Learning Technique",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "The remote sensing technology provides the means of classification of land cover with diversity of additional endless environmental variables over large spatial and moderate temporal extents. To investigate the land cover classification, remote sensing is useful as it provides a synoptic view with high level of information. Natural phenomenon and human intervention are major causes in land cover change can be easily seen with the help of satellite. Using land use land cover analysis methods, urban planner and policy maker can easily identify the change happened in some specific time period. In this study, unsupervised K-means clustering algorithm has been applied to investigate the land use land cover change in the time span of 2011–2016.",
        "DOI": "10.1007/978-981-13-7166-0_23",
        "paper_author": "Kulkarni G.",
        "affiliation_name": "Swami Ramanand Teerth Marathwada University",
        "affiliation_city": "Nanded",
        "affiliation_country": "India",
        "affiliation_id": "60026737",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Successive Over-Relaxation Q -Learning",
        "publication": "IEEE Control Systems Letters",
        "citied_by": "11",
        "cover_date": "2020-01-01",
        "Abstract": "In a discounted reward Markov decision process (MDP), the objective is to find the optimal value function, i.e., the value function corresponding to an optimal policy. This problem reduces to solving a functional equation known as the Bellman equation and a fixed point iteration scheme known as the value iteration is utilized to obtain the solution. In literature, a successive over-relaxation (SOR)-based value iteration scheme is proposed to speed-up the computation of the optimal value function. The speed-up is achieved by constructing a modified Bellman equation that ensures faster convergence to the optimal value function. However, in many practical applications, the model information is not known and we resort to reinforcement learning (RL) algorithms to obtain optimal policy and value function. One such popular algorithm is Q -learning. In this letter, we propose SOR Q -learning. We first derive a modified fixed point iteration for SOR Q -values and utilize stochastic approximation to derive a learning algorithm to compute the optimal value function and an optimal policy. We then prove the almost sure convergence of the SOR Q -learning to SOR Q -values. Finally, through numerical experiments, we show that SOR Q -learning is faster compared to the standard Q -learning algorithm.",
        "DOI": "10.1109/LCSYS.2019.2921158",
        "paper_author": "Kamanchi C.",
        "affiliation_name": "Indian Institute of Science",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60014097",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Comparative study of regression models and deep learning models for insurance cost prediction",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "In the finance world, Insurance is a product that reduces or eliminate the cost of loss caused due to different risks. There are various factors associated that affect the insurance charges. These factors contribute in formulating the insurance policies. Using machine learning, we can predict insurance charges by developing a model that generalize the entire process. Machine Learning in the Insurance industry would enable seamless formulation of insurance policies with better performance and will time. This study presents how insurance charges can be predicted using various regression models. Also, comparison between the performances of models like Multiple Linear Regression, Support Vector Machine, Random Forest Regressor, XGBoost and Deep Neural Networks is done. This paper provides the most optimal solution using Deep Neural Networks with a root mean square error RMSE value of 0.0695 and model accuracy of 87.95.",
        "DOI": "10.1007/978-3-030-16657-1_103",
        "paper_author": "Shinde A.",
        "affiliation_name": "Dwarkadas Jivanlal Sanghvi College of Engineering",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60114754",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "Analysis of Teacher Training in Mathematics in Paraguay&amp;#x2019;s Elementary Education System Using Machine Learning Techniques",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "1",
        "cover_date": "2020-01-01",
        "Abstract": "In Paraguay, despite the fact that Elementary Education is one of the cornerstones of the educational system, it has not always received the recognition it deserves. Recently, the Paraguayan government has started to focus its effort on evaluating the quality of its education system through the analysis of some factors of the teachers. In this work, which falls into the context of such project, we study the ability to understand the different evaluation types structures in mathematics. The data, collected from elementary mathematics teachers from all over the country, is analyzed by applying an education data mining (EDM) approach. Results show that not all questions are equally important and it is necessary to continue through different lines of action to get insight about the action policy to improve the educational system quality.",
        "DOI": "10.1007/978-3-030-20005-3_29",
        "paper_author": "Chaves V.E.J.",
        "affiliation_name": "Universidad Americana",
        "affiliation_city": "Asuncion",
        "affiliation_country": "Paraguay",
        "affiliation_id": "60204479",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reliable on-line re-optimization control of a fed-batch fermentation process using bootstrap aggregated extreme learning machine",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "This paper presents a reliable on-line re-optimization control of a fed-batch fermentation process using bootstrap aggregated extreme learning machine. In order to overcome the difficulty in developing detailed mechanistic models, extreme learning machine (ELM) based data driven models are developed. In building an ELM model, the hidden layer weights are randomly assigned and the output layer weights are obtained in a one step regression type of learning. This feature makes the development of ELM very fast. A single ELM model can lack of robustness due the randomly assigned hidden layer weights. To overcome this problem, multiple ELM models are developed from bootstrap re-sampling replications of the original training data and are then combined. In addition to enhanced model accuracy, bootstrap aggregated ELM can also give model prediction confidence bounds. A reliable optimal control policy is achieved by means of the inclusion of model prediction confidence bounds within the optimization objective function to penalize wide model prediction confidence bounds which are associated with uncertain predictions as a consequence of plant model-mismatch. Finally, in order to deal with unknown process disturbances, an on-line re-optimization control strategy is developed in that on-line optimization is carried out while the batch process is progression. The proposed technique is successfully implemented on a simulated fed-batch fermentation process.",
        "DOI": "10.1007/978-3-030-11292-9_14",
        "paper_author": "Baron C.M.C.",
        "affiliation_name": "Newcastle University",
        "affiliation_city": "Newcastle",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60006222",
        "affiliation_state": "Tyne and Wear"
    },
    {
        "paper_title": "Poverty and Its Relation to Crime and the Environment: Applying Spatial Data Mining to Enhance Evidence-Based Policy",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "0",
        "cover_date": "2020-01-01",
        "Abstract": "The Data Revolution provides an unprecedented opportunity for enhancing evidence-based decision making in the area of public policy. Machine learning techniques will play an increasingly important role in knowledge extraction in data bases associated with important social phenomena such as poverty, crime and environmental degradation. As much of the corresponding data is spatio-temporal it is important to develop spatial data mining methodologies to attack these problems. In this paper, we will use spatial data mining techniques to analyze the relation between poverty and crime and poverty and environmental integrity in two bespoke data sets. We will show that the role and relation of poverty is measurable but is highly complex and heterogeneous.",
        "DOI": "10.1007/978-3-030-14118-9_25",
        "paper_author": "Stephens C.R.",
        "affiliation_name": "Universidad Nacional Autónoma de México",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico",
        "affiliation_id": "60032442",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "4th International Conference on Advanced Machine Learning Technologies and Applications, AMLTA 2019",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "2",
        "cover_date": "2020-01-01",
        "Abstract": "The proceedings contain 93 papers. The special focus in this conference is on Advanced Machine Learning Technologies and Applications. The topics include: Optimal Shortest Path in Mobile Ad-Hoc Network Based on Fruit Fly Optimization Algorithm; swarm Optimization for Solving Load Balancing in Cloud Computing; the Influence of New Energy Access on Load Peaks and Troughs Based on Optimization Techniques; multi-objective Solution of Traveling Salesman Problem with Time; game Theory Based Solver for Dynamic Vehicle Routing Problem; a Hybridization of Sine Cosine Algorithm with Steady State Genetic Algorithm for Engineering Design Problems; molecRank: A Specificity-Based Network Analysis Algorithm: Ranking Therapeutic Molecules in the Bibliome; Detecting Epileptic Seizures Using Abe Entropy, Line Length and SVM Classifier; Analyzing Electrooculography (EOG) for Eye Movement Detection; analysis of Classification Methods for Gene Expression Data; reduced 3-D Deep Learning Framework for Hyperspectral Image Classification; using Eye Movement to Assess Auditory Attention; Facilitating Classroom Orchestration Using EEG to Detect the Cognitive States of Learners; a New Nano-robots Control Strategy for Killing Cancer Cells Using Quorum Sensing Technique and Directed Particle Swarm Optimization Algorithm; mining Student Information System Records to Predict Students’ Academic Performance; bayesian Classification of Personal Histories - An application to the Obesity Epidemic; poverty and Its Relation to Crime and the Environment: Applying Spatial Data Mining to Enhance Evidence-Based Policy; identifying Different Types of Biclustering Patterns Using a Correlation-Based Dilated Biclusters Algorithm; Reduction of Variations Using Chemometric Model Transfer: A Case Study Using FT-NIR Miniaturized Sensors; Regression with Support Vector Machines and VGG Neural Networks.",
        "DOI": "NA",
        "paper_author": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Calculation of Energy Saving Based on Building Engineering",
        "publication": "Advances in Intelligent Systems and Computing",
        "citied_by": "4",
        "cover_date": "2020-01-01",
        "Abstract": "The development of energy-saving buildings has updated building construction. The energy consumption of buildings is the focus of our research. By expounding the calculation process of heat transfer coefficient of the exterior wall, roof, floor, door, and window, energy saving calculation is discussed. Due to the diversity of building energy-saving materials, the excessive use of materials leads to huge waste of resources in order to meet the energy-saving standards. Therefore, how to make full use of the existing materials to meet the requirements of energy conservation standards. Building energy conservation is the implementation and establishment of the scientific concept of development. Actively promote construction. Energy conservation is not only conducive to alleviating and alleviating energy shortages. Air pollution, greenhouse gas emission reduction, protected areas. The ball’s environment, it helps improve people’s lives and work. We will create conditions to promote sustainable development of the national economy. To achieve the goal of energy conservation, on the one hand, we need to improve energy efficiency. People’s awareness of energy conservation depends on the restrictions of relevant policies.",
        "DOI": "10.1007/978-3-030-14118-9_82",
        "paper_author": "Shao B.",
        "affiliation_name": "State Grid Liaoning Electric Power Supply Co., Ltd.",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60159689",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Correlation Filter Selection for Visual Tracking Using Reinforcement Learning",
        "publication": "IEEE Transactions on Circuits and Systems for Video Technology",
        "citied_by": "20",
        "cover_date": "2020-01-01",
        "Abstract": "Correlation filter has been proven to be an effective tool for a number of approaches in visual tracking, particularly for seeking a good balance between tracking accuracy and speed. However, correlation filter-based models are susceptible to wrong updates stemming from inaccurate tracking results. To date, very little effort has been devoted towards handling the correlation filter update problem. In this paper, we propose a novel approach to address the correlation filter update problem. In our approach, we update and maintain multiple correlation filter models in parallel, and we use deep reinforcement learning for the selection of an optimal correlation filter model among them. To facilitate the decision process in an efficient manner, we propose a decision-net to deal with target appearance modeling, which is trained through hundreds of challenging videos using proximal policy optimization and a lightweight learning network. An exhaustive evaluation of the proposed approach on the OTB100 and OTB2013 benchmarks shows that the approach is effective enough to achieve the average success rate of 62.3% and the average precision score of 81.2%, both exceeding the performance of traditional correlation filter-based trackers.",
        "DOI": "10.1109/TCSVT.2018.2889488",
        "paper_author": "Xie Y.",
        "affiliation_name": "Xi'an Jiaotong-Liverpool University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China",
        "affiliation_id": "60102426",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Application Behaviors Driven Self-Organizing Network (SON) for 4G LTE Networks",
        "publication": "IEEE Transactions on Network Science and Engineering",
        "citied_by": "10",
        "cover_date": "2020-01-01",
        "Abstract": "Self-Organizing Networks (SON) is an automation technology in the wireless industry implemented to simplify the planning, deployment, operation, optimization, and healing of networks. However, legacy SON functions are targeted at network automation and network optimization through certain optimization rules and policies which are globally applied in the entire networks. Therefore, scalable and targeted optimization is not supported in these existing SON solutions. Furthermore, such existing SON schemes are driven by performance optimization rather than ultimately improving user Quality of Experience (QoE). The impact of application characteristics on network performance and further on QoE are also not considered in SON defined by 3GPP. This paper presents an application characteristics-driven SON system (APP-SON) to optimize 4G/5G network performance and user Quality of Experience. APP-SON leverages a scalable big data platform for targeted optimization through profiling cell application characteristics with an incremental manner in temporal space. A Hungarian Algorithm Assisted Clustering (HAAC) algorithm and a deep learning-assisted regression algorithm are developed to profile the cell application characteristics and find the targeted KPIs to be optimized for each cell in a network. A similarity-based parameter-tuning algorithm is designed to tune the corresponding engineering parameters to optimize the targeted KPIs which further improve the QoE. Experimental results demonstrated that the APP-SON system can precisely profile cell traffic and application characteristics to find the targeted KPIs for optimization. APP-SON can also automatically tune the corresponding engineering parameters to improve corresponding KPIs, ultimately improving QoE. APP-SON has been successfully implemented in production and applied in a tier-1 operator's 4G network. As a universal SON solution, it will be smoothly transitioned and applied in 5G networks for this operator.",
        "DOI": "10.1109/TNSE.2018.2877353",
        "paper_author": "Ouyang Y.",
        "affiliation_name": "Verizon Wireless",
        "affiliation_city": "Basking Ridge",
        "affiliation_country": "United States",
        "affiliation_id": "60085989",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Development of secured data transmission using machine learning-based discrete-time partially observed Markov model and energy optimization in cognitive radio networks",
        "publication": "Neural Computing and Applications",
        "citied_by": "43",
        "cover_date": "2020-01-01",
        "Abstract": "The cognitive radio network (CR) is a primary and promising technology to distribute the spectrum assignment to an unlicensed user (secondary users) which is not utilized by the licensed user (primary user).The cognitive radio network frames a reactive security policy to enhance the energy monitoring while using the CR network primary channels. The CR network has a good amount of energy capacity using battery resource and accesses the data communication via the time-slotted channel. The data communication with moderate energy-level utilization during transmission is a great challenge in CR network security monitoring, since intruders may often attack the network in reducing the energy level of the PU or SU. The framework used to secure the communication is using the discrete-time partially observed Markov decision process. This system proposes a modern data communication-secured scheme using private key encryption with the sensing results, and eclat algorithm has been proposed for energy detection and Byzantine attack prediction. The data communication is secured using the AES algorithm at the CR network, and the simulation provides the best effort-efficient energy usage and security.",
        "DOI": "10.1007/s00521-018-3788-3",
        "paper_author": "Vimal S.",
        "affiliation_name": "National Engineering College, Kovilpatti",
        "affiliation_city": "Kovilpatti",
        "affiliation_country": "India",
        "affiliation_id": "60080495",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Mitigating Bottlenecks in Wide Area Data Analytics via Machine Learning",
        "publication": "IEEE Transactions on Network Science and Engineering",
        "citied_by": "5",
        "cover_date": "2020-01-01",
        "Abstract": "Over the past decade, we have witnessed exponential growth in the density (petabyte-level) and breadth (across geo-distributed datacenters) of data distribution. It becomes increasingly challenging but imperative to minimize the response times of data analytic queries over multiple geo-distributed datacenters. However, existing scheduling-based solutions have largely been motivated by pre-established mantras (e.g., bandwidth scarcity). Without data-driven insights into performance bottlenecks at runtime, schedulers might blindly assign tasks to workers that are suffering from unidentified bottlenecks. In this paper, we present Lube, a system framework that minimizes query response times by detecting and mitigating bottlenecks at runtime. Lube monitors geo-distributed data analytic queries in real-time, detects potential bottlenecks, and mitigates them with a bottleneck-aware scheduling policy. Our preliminary experiments on a real-world prototype across Amazon EC2 regions have shown that Lube can detect bottlenecks with over 90 percent accuracy, and reduce the median query response time by up to 33 percent compared to Spark's built-in locality-based scheduler.",
        "DOI": "10.1109/TNSE.2018.2816951",
        "paper_author": "Wang H.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    }
]