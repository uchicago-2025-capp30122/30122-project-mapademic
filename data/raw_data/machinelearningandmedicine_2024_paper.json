[
    {
        "paper_title": "Advancements in Microwave Absorption Motivated by Interdisciplinary Research",
        "publication": "Advanced Materials",
        "citied_by": "116",
        "cover_date": "2024-01-25",
        "Abstract": "Microwave absorption materials (MAMs) are originally developed for military purposes, but have since evolved into versatile materials with promising applications in modern technologies, including household use. Despite significant progress in bench-side research over the past decade, MAMs remain limited in their scope and have yet to be widely adopted. This review explores the history of MAMs from first-generation coatings to second-generation functional absorbers, identifies bottlenecks hindering their maturation. It also presents potential solutions such as exploring broader spatial scales, advanced characterization, introducing liquid media, utilizing novel toolbox (machine learning, ML), and proximity of lab to end-user. Additionally, it meticulously presents compelling applications of MAMs in medicine, mechanics, energy, optics, and sensing, which go beyond absorption efficiency, along with their current development status and prospects. This interdisciplinary research direction differs from previous research which primarily focused on meeting traditional requirements (i.e., thin, lightweight, wide, and strong), and can be defined as the next generation of smart absorbers. Ultimately, the effective utilization of ubiquitous electromagnetic (EM) waves, aided by third-generation MAMs, should be better aligned with future expectations.",
        "DOI": "10.1002/adma.202304182",
        "paper_author": "Zhao Z.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Artificial intelligence and illusions of understanding in scientific research",
        "publication": "Nature",
        "citied_by": "109",
        "cover_date": "2024-03-07",
        "Abstract": "Scientists are enthusiastically imagining ways in which artificial intelligence (AI) tools might improve research. Why are AI tools so attractive and what are the risks of implementing them across the research pipeline? Here we develop a taxonomy of scientists’ visions for AI, observing that their appeal comes from promises to improve productivity and objectivity by overcoming human shortcomings. But proposed AI solutions can also exploit our cognitive limitations, making us vulnerable to illusions of understanding in which we believe we understand more about the world than we actually do. Such illusions obscure the scientific community’s ability to see the formation of scientific monocultures, in which some types of methods, questions and viewpoints come to dominate alternative approaches, making science less innovative and more vulnerable to errors. The proliferation of AI tools in science risks introducing a phase of scientific enquiry in which we produce more but understand less. By analysing the appeal of these tools, we provide a framework for advancing discussions of responsible knowledge production in the age of AI.",
        "DOI": "10.1038/s41586-024-07146-0",
        "paper_author": "Messeri L.",
        "affiliation_name": "Yale University",
        "affiliation_city": "New Haven",
        "affiliation_country": "United States",
        "affiliation_id": "60005455",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine",
        "publication": "Scientific Reports",
        "citied_by": "97",
        "cover_date": "2024-12-01",
        "Abstract": "Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.",
        "DOI": "10.1038/s41598-023-50600-8",
        "paper_author": "DeGroat W.",
        "affiliation_name": "Institute for Health, Health Care Policy and Aging Research",
        "affiliation_city": "New Brunswick",
        "affiliation_country": "United States",
        "affiliation_id": "60119172",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Computer-Aided Drug Design and Drug Discovery: A Prospective Analysis",
        "publication": "Pharmaceuticals",
        "citied_by": "68",
        "cover_date": "2024-01-01",
        "Abstract": "In the dynamic landscape of drug discovery, Computer-Aided Drug Design (CADD) emerges as a transformative force, bridging the realms of biology and technology. This paper overviews CADDs historical evolution, categorization into structure-based and ligand-based approaches, and its crucial role in rationalizing and expediting drug discovery. As CADD advances, incorporating diverse biological data and ensuring data privacy become paramount. Challenges persist, demanding the optimization of algorithms and robust ethical frameworks. Integrating Machine Learning and Artificial Intelligence amplifies CADDs predictive capabilities, yet ethical considerations and scalability challenges linger. Collaborative efforts and global initiatives, exemplified by platforms like Open-Source Malaria, underscore the democratization of drug discovery. The convergence of CADD with personalized medicine offers tailored therapeutic solutions, though ethical dilemmas and accessibility concerns must be navigated. Emerging technologies like quantum computing, immersive technologies, and green chemistry promise to redefine the future of CADD. The trajectory of CADD, marked by rapid advancements, anticipates challenges in ensuring accuracy, addressing biases in AI, and incorporating sustainability metrics. This paper concludes by highlighting the need for proactive measures in navigating the ethical, technological, and educational frontiers of CADD to shape a healthier, brighter future in drug discovery.",
        "DOI": "10.3390/ph17010022",
        "paper_author": "Niazi S.K.",
        "affiliation_name": "University of Illinois at Chicago",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States",
        "affiliation_id": "60027561",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Applications of Artificial Neural Networks and Machine Learning in Civil Engineering",
        "publication": "Studies in Computational Intelligence",
        "citied_by": "67",
        "cover_date": "2024-01-01",
        "Abstract": "This book provides different applications of artificial neural networks (ANN) and machine learning (ML) in various problems of material science, structural optimization, and optimal analysis of structures in twenty two chapters. Nowadays, the world has witnessed unprecedented advances in technology and computer science. Artificial intelligence has emerged as a top field captivating global attention. Often referred to as AI, this technology stands apart from other disciplines as it aims to design machines and systems that exhibit intelligence, learn autonomously, and make decisions akin to humans. In order to comprehend the impact of this innovation, one must delve into the workings of artificial intelligence, trace its historical evolution from inception to the present day, and explore its diverse applications in domains like medicine, transportation, broadcasting, and marketing. Artificial intelligence introduces a transformative element to our reality, fostering significant breakthroughs and innovations. The book is used in any AI course, in particular, in Civil Engineering. It is also utilized in various fields of Industrial Civil Engineering.",
        "DOI": "10.1007/978-3-031-66051-1",
        "paper_author": "Kaveh A.",
        "affiliation_name": "Universität Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria",
        "affiliation_id": "60025988",
        "affiliation_state": "Vienna"
    },
    {
        "paper_title": "Large language models in radiology: fundamentals, applications, ethical considerations, risks, and future directions",
        "publication": "Diagnostic and Interventional Radiology",
        "citied_by": "65",
        "cover_date": "2024-03-01",
        "Abstract": "With the advent of large language models (LLMs), the artificial intelligence revolution in medicine and radiology is now more tangible than ever. Every day, an increasingly large number of articles are published that utilize LLMs in radiology. To adopt and safely implement this new technology in the field, radiologists should be familiar with its key concepts, understand at least the technical basics, and be aware of the potential risks and ethical considerations that come with it. In this review article, the authors provide an overview of the LLMs that might be relevant to the radiology community and include a brief discussion of their short history, technical basics, ChatGPT, prompt engineering, potential applications in medicine and radiology, advantages, disadvantages and risks, ethical and regulatory considerations, and future directions.",
        "DOI": "10.4274/dir.2023.232417",
        "paper_author": "Akinci D’Antonoli T.",
        "affiliation_name": "Kantonsspital Liestal",
        "affiliation_city": "Liestal",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60013276",
        "affiliation_state": "Basel-Country"
    },
    {
        "paper_title": "Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives",
        "publication": "Healthcare (Switzerland)",
        "citied_by": "65",
        "cover_date": "2024-01-01",
        "Abstract": "Artificial intelligence (AI) has emerged as a crucial tool in healthcare with the primary aim of improving patient outcomes and optimizing healthcare delivery. By harnessing machine learning algorithms, natural language processing, and computer vision, AI enables the analysis of complex medical data. The integration of AI into healthcare systems aims to support clinicians, personalize patient care, and enhance population health, all while addressing the challenges posed by rising costs and limited resources. As a subdivision of computer science, AI focuses on the development of advanced algorithms capable of performing complex tasks that were once reliant on human intelligence. The ultimate goal is to achieve human-level performance with improved efficiency and accuracy in problem-solving and task execution, thereby reducing the need for human intervention. Various industries, including engineering, media/entertainment, finance, and education, have already reaped significant benefits by incorporating AI systems into their operations. Notably, the healthcare sector has witnessed rapid growth in the utilization of AI technology. Nevertheless, there remains untapped potential for AI to truly revolutionize the industry. It is important to note that despite concerns about job displacement, AI in healthcare should not be viewed as a threat to human workers. Instead, AI systems are designed to augment and support healthcare professionals, freeing up their time to focus on more complex and critical tasks. By automating routine and repetitive tasks, AI can alleviate the burden on healthcare professionals, allowing them to dedicate more attention to patient care and meaningful interactions. However, legal and ethical challenges must be addressed when embracing AI technology in medicine, alongside comprehensive public education to ensure widespread acceptance.",
        "DOI": "10.3390/healthcare12020125",
        "paper_author": "Bekbolatova M.",
        "affiliation_name": "New York Institute of Technology College of Osteopathic Medicine",
        "affiliation_city": "Old Westbury",
        "affiliation_country": "United States",
        "affiliation_id": "60097848",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Integrating Artificial Intelligence for Drug Discovery in the Context of Revolutionizing Drug Delivery",
        "publication": "Life",
        "citied_by": "58",
        "cover_date": "2024-02-01",
        "Abstract": "Drug development is expensive, time-consuming, and has a high failure rate. In recent years, artificial intelligence (AI) has emerged as a transformative tool in drug discovery, offering innovative solutions to complex challenges in the pharmaceutical industry. This manuscript covers the multifaceted role of AI in drug discovery, encompassing AI-assisted drug delivery design, the discovery of new drugs, and the development of novel AI techniques. We explore various AI methodologies, including machine learning and deep learning, and their applications in target identification, virtual screening, and drug design. This paper also discusses the historical development of AI in medicine, emphasizing its profound impact on healthcare. Furthermore, it addresses AI’s role in the repositioning of existing drugs and the identification of drug combinations, underscoring its potential in revolutionizing drug delivery systems. The manuscript provides a comprehensive overview of the AI programs and platforms currently used in drug discovery, illustrating the technological advancements and future directions of this field. This study not only presents the current state of AI in drug discovery but also anticipates its future trajectory, highlighting the challenges and opportunities that lie ahead.",
        "DOI": "10.3390/life14020233",
        "paper_author": "Visan A.I.",
        "affiliation_name": "National Institute for Laser, Plasma and Radiation Physics",
        "affiliation_city": "Magurele",
        "affiliation_country": "Romania",
        "affiliation_id": "60012359",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "AI-enabled organoids: Construction, analysis, and application",
        "publication": "Bioactive Materials",
        "citied_by": "57",
        "cover_date": "2024-01-01",
        "Abstract": "Organoids, miniature and simplified in vitro model systems that mimic the structure and function of organs, have attracted considerable interest due to their promising applications in disease modeling, drug screening, personalized medicine, and tissue engineering. Despite the substantial success in cultivating physiologically relevant organoids, challenges remain concerning the complexities of their assembly and the difficulties associated with data analysis. The advent of AI-Enabled Organoids, which interfaces with artificial intelligence (AI), holds the potential to revolutionize the field by offering novel insights and methodologies that can expedite the development and clinical application of organoids. This review succinctly delineates the fundamental concepts and mechanisms underlying AI-Enabled Organoids, summarizing the prospective applications on rapid screening of construction strategies, cost-effective extraction of multiscale image features, streamlined analysis of multi-omics data, and precise preclinical evaluation and application. We also explore the challenges and limitations of interfacing organoids with AI, and discuss the future direction of the field. Taken together, the AI-Enabled Organoids hold significant promise for advancing our understanding of organ development and disease progression, ultimately laying the groundwork for clinical application.",
        "DOI": "10.1016/j.bioactmat.2023.09.005",
        "paper_author": "Bai L.",
        "affiliation_name": "Xinhua Hospital Affiliated to Shanghai Jiao Tong University School of Medicine",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073654",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning for functional protein design",
        "publication": "Nature Biotechnology",
        "citied_by": "54",
        "cover_date": "2024-02-01",
        "Abstract": "Recent breakthroughs in AI coupled with the rapid accumulation of protein sequence and structure data have radically transformed computational protein design. New methods promise to escape the constraints of natural and laboratory evolution, accelerating the generation of proteins for applications in biotechnology and medicine. To make sense of the exploding diversity of machine learning approaches, we introduce a unifying framework that classifies models on the basis of their use of three core data modalities: sequences, structures and functional labels. We discuss the new capabilities and outstanding challenges for the practical design of enzymes, antibodies, vaccines, nanomachines and more. We then highlight trends shaping the future of this field, from large-scale assays to more robust benchmarks, multimodal foundation models, enhanced sampling strategies and laboratory automation.",
        "DOI": "10.1038/s41587-024-02127-0",
        "paper_author": "Notin P.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Support Vector Machines Based Predictive Seizure Care using IoT-Wearable EEG Devices for Proactive Intervention in Epilepsy",
        "publication": "2024 2nd International Conference on Computer, Communication and Control, IC4 2024",
        "citied_by": "51",
        "cover_date": "2024-01-01",
        "Abstract": "Epilepsy, a neurological illness that causes repeated seizures, can interfere with everyday life and needs prompt treatment. Internet of Things (IoT) wearable Electroencephalogram (EEG) devices and Support Vector Machines (SVM) for predictive analytics are used in this study to suggest a unique strategy for proactive seizure treatment. Wearable EEG devices feed real-time brain activity data. It uses SVM, a strong machine learning method, to build a prediction model using historical EEG data to identify and predict seizures. The prediction software analyses EEG data in real-time to detect pre-seizure patterns and initiate preventive treatments. The seizure prediction method uses SVM's capacity to handle high-dimensional data and catch complicated patterns to improve accuracy and reliability. Healthcare practitioners and caregivers may get timely warnings and react efficiently thanks to the IoT infrastructure's seamless connectivity between wearable devices and a centralized monitoring system. It discusses the ethical and privacy issues of installing such a system, stressing user permission and data protection. Pilot investigations show promising prediction accuracy and reaction time. SVM with IoT-wearable EEG sensors for predictive seizure care offers a forward-looking technique for enhancing epilepsy patients' quality of life by enabling individualized and proactive treatments.",
        "DOI": "10.1109/IC457434.2024.10486581",
        "paper_author": "Srinivas P.",
        "affiliation_name": "Malla Reddy Institute of Engineering &amp; Technology",
        "affiliation_city": "Secunderabad",
        "affiliation_country": "India",
        "affiliation_id": "60283344",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Opportunities and challenges of artificial intelligence and distributed systems to improve the quality of healthcare service",
        "publication": "Artificial Intelligence in Medicine",
        "citied_by": "50",
        "cover_date": "2024-03-01",
        "Abstract": "The healthcare sector, characterized by vast datasets and many diseases, is pivotal in shaping community health and overall quality of life. Traditional healthcare methods, often characterized by limitations in disease prevention, predominantly react to illnesses after their onset rather than proactively averting them. The advent of Artificial Intelligence (AI) has ushered in a wave of transformative applications designed to enhance healthcare services, with Machine Learning (ML) as a noteworthy subset of AI. ML empowers computers to analyze extensive datasets, while Deep Learning (DL), a specific ML methodology, excels at extracting meaningful patterns from these data troves. Despite notable technological advancements in recent years, the full potential of these applications within medical contexts remains largely untapped, primarily due to the medical community's cautious stance toward novel technologies. The motivation of this paper lies in recognizing the pivotal role of the healthcare sector in community well-being and the necessity for a shift toward proactive healthcare approaches. To our knowledge, there is a notable absence of a comprehensive published review that delves into ML, DL and distributed systems, all aimed at elevating the Quality of Service (QoS) in healthcare. This study seeks to bridge this gap by presenting a systematic and organized review of prevailing ML, DL, and distributed system algorithms as applied in healthcare settings. Within our work, we outline key challenges that both current and future developers may encounter, with a particular focus on aspects such as approach, data utilization, strategy, and development processes. Our study findings reveal that the Internet of Things (IoT) stands out as the most frequently utilized platform (44.3 %), with disease diagnosis emerging as the predominant healthcare application (47.8 %). Notably, discussions center significantly on the prevention and identification of cardiovascular diseases (29.2 %). The studies under examination employ a diverse range of ML and DL methods, along with distributed systems, with Convolutional Neural Networks (CNNs) being the most commonly used (16.7 %), followed by Long Short-Term Memory (LSTM) networks (14.6 %) and shallow learning networks (12.5 %). In evaluating QoS, the predominant emphasis revolves around the accuracy parameter (80 %). This study highlights how ML, DL, and distributed systems reshape healthcare. It contributes to advancing healthcare quality, bridging the gap between technology and medical adoption, and benefiting practitioners and patients.",
        "DOI": "10.1016/j.artmed.2024.102779",
        "paper_author": "Aminizadeh S.",
        "affiliation_name": "Islamic Azad University, Tabriz Branch",
        "affiliation_city": "Tabriz",
        "affiliation_country": "Iran",
        "affiliation_id": "60022609",
        "affiliation_state": "East Azarbaijan Province"
    },
    {
        "paper_title": "The Integration of Artificial Intelligence into Clinical Practice",
        "publication": "Applied Biosciences",
        "citied_by": "49",
        "cover_date": "2024-03-01",
        "Abstract": "The purpose of this literature review is to provide a fundamental synopsis of current research pertaining to artificial intelligence (AI) within the domain of clinical practice. Artificial intelligence has revolutionized the field of medicine and healthcare by providing innovative solutions to complex problems. One of the most important benefits of AI in clinical practice is its ability to investigate extensive volumes of data with efficiency and precision. This has led to the development of various applications that have improved patient outcomes and reduced the workload of healthcare professionals. AI can support doctors in making more accurate diagnoses and developing personalized treatment plans. Successful examples of AI applications are outlined for a series of medical specialties like cardiology, surgery, gastroenterology, pneumology, nephrology, urology, dermatology, orthopedics, neurology, gynecology, ophthalmology, pediatrics, hematology, and critically ill patients, as well as diagnostic methods. Special reference is made to legal and ethical considerations like accuracy, informed consent, privacy issues, data security, regulatory framework, product liability, explainability, and transparency. Finally, this review closes by critically appraising AI use in clinical practice and its future perspectives. However, it is also important to approach its development and implementation cautiously to ensure ethical considerations are met.",
        "DOI": "10.3390/applbiosci3010002",
        "paper_author": "Karalis V.D.",
        "affiliation_name": "National &amp; Kapodistrian University of Athens, School of Health Sciences",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece",
        "affiliation_id": "60014758",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "AI in diagnostic imaging: Revolutionising accuracy and efficiency",
        "publication": "Computer Methods and Programs in Biomedicine Update",
        "citied_by": "48",
        "cover_date": "2024-01-01",
        "Abstract": "Introduction: This review evaluates the role of Artificial Intelligence (AI) in transforming diagnostic imaging in healthcare. AI has the potential to enhance accuracy and efficiency of interpreting medical images like X-rays, MRIs, and CT scans. Methods: A comprehensive literature search across databases like PubMed, Embase, and Google Scholar was conducted, focusing on articles published in peer-reviewed journals in English language since 2019. Inclusion criteria targeted studies on AI's application in diagnostic imaging, while exclusion criteria filtered out irrelevant or empirically unsupported studies. Results and discussion: Through 30 included studies, the review identifies four AI domains and eight functions in diagnostic imaging: 1) In the area of Image Analysis and Interpretation, AI capabilities enhanced image analysis, spotting minor discrepancies and anomalies, and by reducing human error, maintaining accuracy and mitigating the impact of fatigue or oversight, 2) The Operational Efficiency is enhanced by AI through efficiency and speed, which accelerates the diagnostic process, and cost-effectiveness, reducing healthcare costs by improving efficiency and accuracy, 3) Predictive and Personalised Healthcare benefit from AI through predictive analytics, leveraging historical data for early diagnosis, and personalised medicine, which employs patient-specific data for tailored diagnostic approaches, 4) Lastly, in Clinical Decision Support, AI assists in complex procedures by providing precise imaging support and integrates with other technologies like electronic health records for enriched health insights, showcasing ai's transformative potential in diagnostic imaging. The review also discusses challenges in AI integration, such as ethical concerns, data privacy, and the need for technology investments and training. Conclusion: AI is revolutionising diagnostic imaging by improving accuracy, efficiency, and personalised healthcare delivery. Recommendations include continued investment in AI, establishment of ethical guidelines, training for healthcare professionals, and ensuring patient-centred AI development. The review calls for collaborative efforts to integrate AI in clinical practice effectively and address healthcare disparities.",
        "DOI": "10.1016/j.cmpbup.2024.100146",
        "paper_author": "Khalifa M.",
        "affiliation_name": "Education Centre of Australia",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "100509241",
        "affiliation_state": "NS"
    },
    {
        "paper_title": "Mapping the literature on the application of artificial intelligence in libraries (AAIL): a scientometric analysis",
        "publication": "Library Hi Tech",
        "citied_by": "48",
        "cover_date": "2024-02-14",
        "Abstract": "Purpose: Artificial Intelligence (AI) is an emerging technology and turned into a field of knowledge that has been consistently displacing technologies for a change in human life. It is applied in all spheres of life as reflected in the review of the literature section here. As applicable in the field of libraries too, this study scientifically mapped the papers on AAIL and analyze its growth, collaboration network, trending topics, or research hot spots to highlight the challenges and opportunities in adopting AI-based advancements in library systems and processes. Design/methodology/approach: The study was developed with a bibliometric approach, considering a decade, 2012 to 2021 for data extraction from a premier database, Scopus. The steps followed are (1) identification, selection of keywords, and forming the search strategy with the approval of a panel of computer scientists and librarians and (2) design and development of a perfect algorithm to verify these selected keywords in title-abstract-keywords of Scopus (3) Performing data processing in some state-of-the-art bibliometric visualization tools, Biblioshiny R and VOSviewer (4) discussing the findings for practical implications of the study and limitations. Findings: As evident from several papers, not much research has been conducted on AI applications in libraries in comparison to topics like AI applications in cancer, health, medicine, education, and agriculture. As per the Price law, the growth pattern is exponential. The total number of papers relevant to the subject is 1462 (single and multi-authored) contributed by 5400 authors with 0.271 documents per author and around 4 authors per document. Papers occurred mostly in open-access journals. The productive journal is the Journal of Chemical Information and Modelling (NP = 63) while the highly consistent and impactful is the Journal of Machine Learning Research (z-index=63.58 and CPP = 56.17). In the case of authors, J Chen (z-index=28.86 and CPP = 43.75) is the most consistent and impactful author. At the country level, the USA has recorded the highest number of papers positioned at the center of the co-authorship network but at the institutional level, China takes the 1st position. The trending topics of research are machine learning, large dataset, deep learning, high-level languages, etc. The present information system has a high potential to improve if integrated with AI technologies. Practical implications: The number of scientific papers has increased over time. The evolution of themes like machine learning implicates AI as a broad field of knowledge that converges with other disciplines. The themes like large datasets imply that AI may be applied to analyze and interpret these data and support decision-making in public sector enterprises. Theme named high-level language emerged as a research hotspot which indicated that extensive research has been going on in this area to improve computer systems for facilitating the processing of data with high momentum. These implications are of high strategic worth for policymakers, library stakeholders, researchers and the government as a whole for decision-making. Originality/value: The analysis of collaboration, prolific authors/journals using consistency factor and CPP, testing the relationship between consistency (z-index) and impact (h-index), using state-of-the-art network visualization and cluster analysis techniques make this study novel and differentiates it from the traditional bibliometric analysis. To the best of the author's knowledge, this work is the first attempt to comprehend the research streams and provide a holistic view of research on the application of AI in libraries. The insights obtained from this analysis are instrumental for both academics and practitioners.",
        "DOI": "10.1108/LHT-07-2022-0331",
        "paper_author": "Borgohain D.J.",
        "affiliation_name": "Mizoram University",
        "affiliation_city": "Aizawl",
        "affiliation_country": "India",
        "affiliation_id": "60104887",
        "affiliation_state": "MZ"
    },
    {
        "paper_title": "Artificial intelligence for Sustainable Development Goals: Bibliometric patterns and concept evolution trajectories",
        "publication": "Sustainable Development",
        "citied_by": "45",
        "cover_date": "2024-02-01",
        "Abstract": "The development of artificial intelligence (AI) as a field has impacted almost all aspects of human life. More recently it has found a role in addressing developmental challenges, specifically the Sustainable Development Goals (SDGs). However, there are not enough systematic studies on analysis of the role of AI research towards the SDGs. Therefore, this article attempts to bridge this gap by identifying the major bibliometric trends and concept-evolution trajectories in the area of AI applications for sustainable-development goals. The research publication data for the last 20 years in the areas of artificial intelligence, machine learning, deep learning, and so forth, is obtained and computationally analysed using a framework comprising bibliometrics, path analysis and content analysis. The findings show an incremental trend in overall publications on the application of AI for SDGs across the different regions of the world. SDGs 3 (good health & well-being) and 7 (affordable and clean energy) are found as the areas with the most applications of AI. In SDG3, the literature reflects application of AI techniques such as deep learning for precision and personalised medicine while in SDG7, a number of studies have employed AI techniques for the integration of systems for efficient generation of solar power and improving the energy efficiency of a building. Furthermore, SDG 4 (quality education), SDG 13 (climate action), SDG 11 (sustainable cities and communities) and SDG 16 (peace, justice and strong institutions) are the other SDGs where AI approaches and techniques are applied. The analytical results present a detailed insight of application of AI for achieving the SDGs.",
        "DOI": "10.1002/sd.2706",
        "paper_author": "Singh A.",
        "affiliation_name": "Banaras Hindu University",
        "affiliation_city": "Varanasi",
        "affiliation_country": "India",
        "affiliation_id": "60008721",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "A survey of multimodal information fusion for smart healthcare: Mapping the journey from data to wisdom",
        "publication": "Information Fusion",
        "citied_by": "44",
        "cover_date": "2024-02-01",
        "Abstract": "Multimodal medical data fusion has emerged as a transformative approach in smart healthcare, enabling a comprehensive understanding of patient health and personalized treatment plans. In this paper, a journey from data to information to knowledge to wisdom (DIKW) is explored through multimodal fusion for smart healthcare. We present a comprehensive review of multimodal medical data fusion focused on the integration of various data modalities. The review explores different approaches such as feature selection, rule-based systems, machine; earning, deep learning, and natural language processing, for fusing and analyzing multimodal data. This paper also highlights the challenges associated with multimodal fusion in healthcare. By synthesizing the reviewed frameworks and theories, it proposes a generic framework for multimodal medical data fusion that aligns with the DIKW model. Moreover, it discusses future directions related to the four pillars of healthcare: Predictive, Preventive, Personalized, and Participatory approaches. The components of the comprehensive survey presented in this paper form the foundation for more successful implementation of multimodal fusion in smart healthcare. Our findings can guide researchers and practitioners in leveraging the power of multimodal fusion with the state-of-the-art approaches to revolutionize healthcare and improve patient outcomes.",
        "DOI": "10.1016/j.inffus.2023.102040",
        "paper_author": "Shaik T.",
        "affiliation_name": "University of Southern Queensland",
        "affiliation_city": "Toowoomba",
        "affiliation_country": "Australia",
        "affiliation_id": "60020321",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "From machine learning to deep learning: Advances of the recent data-driven paradigm shift in medicine and healthcare",
        "publication": "Current Research in Biotechnology",
        "citied_by": "43",
        "cover_date": "2024-01-01",
        "Abstract": "The medicine and healthcare sector has been evolving and advancing very fast. The advancement has been initiated and shaped by the applications of data-driven, robust, and efficient machine learning (ML) to deep learning (DL) technologies. ML in the medical sector is developing quickly, causing rapid progress, reshaping medicine, and improving clinician and patient experiences. ML technologies evolved into data-hungry DL approaches, which are more robust and efficient in dealing with medical data. This article reviews some critical data-driven aspects of machine intelligence in the medical field. In this direction, the article illustrated the recent progress of data-driven medical science using ML to DL in two categories: firstly, the recent development of data science in medicine with the use of ML to DL and, secondly, the chabot technologies in healthcare and medicine, particularly on ChatGPT. Here, we discuss the progress of ML, DL, and the transition requirements from ML to DL. To discuss the advancement in data science, we illustrate prospective studies of medical image data, newly evolved DL interpretation data from EMR or EHR, big data in personalized medicine, and dataset shifts in artificial intelligence (AI). Simultaneously, the article illustrated recently developed DL-enabled ChatGPT technology. Finally, we summarize the broad role of ML and DL in medicine and the significant challenges for implementing recent ML to DL technologies in healthcare. The overview of the data-driven paradigm shift in medicine using ML to DL technologies in the article will benefit researchers immensely.",
        "DOI": "10.1016/j.crbiot.2023.100164",
        "paper_author": "Chakraborty C.",
        "affiliation_name": "Adamas University",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India",
        "affiliation_id": "60272396",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Simulation-based approaches for drug delivery systems: Navigating advancements, opportunities, and challenges",
        "publication": "Journal of Molecular Liquids",
        "citied_by": "43",
        "cover_date": "2024-02-01",
        "Abstract": "Efficient drug delivery systems (DDSs) play a pivotal role in ensuring pharmaceuticals’ targeted and effective administration. However, the intricate interplay between drug formulations and delivery systems poses challenges in their design and optimization. Simulations have emerged as indispensable tools for comprehending these interactions and enhancing DDSs performance to address this complexity. This comprehensive review explores the latest advancements in simulation techniques for DDSs and provides a detailed analysis. The review encompasses various simulation methodologies, including molecular dynamics (MD), Monte Carlo (MC), finite element analysis (FEA), computational fluid dynamics (CFD), density functional theory (DFT), machine learning (ML), and dissipative particle dynamics (DPD). These techniques are critically examined in the context of drug delivery research. The article presents illustrative case studies involving liposomal, polymer-based, nano-particulate, and implantable DDSs, demonstrating the influential role of simulations in optimizing these systems. Furthermore, the review addresses the advantages and limitations of simulations in drug delivery research. It also identifies future directions for research and development, such as integrating multiple simulation techniques, refining and validating models for greater accuracy, overcoming computational limitations, and exploring applications of simulations in personalized medicine and innovative DDSs. Simulations employing various techniques like MD, MC, FEA, CFD, DFT, ML, and DPD offer crucial insights into drug behaviour, aiding in DDS design and optimization. Despite their advantages, including rapid and cost-effective screening, simulations require validation and addressing computational limitations. Future research should focus on integrating techniques, refining models, and exploring personalized medicine applications to enhance drug delivery outcomes. This paper underscores the indispensable contribution of simulations to drug research and development, emphasizing their role in providing valuable insights into drug behaviour, facilitating the development and optimization of DDSs, and ultimately enhancing patient outcomes. As we continue to explore and enhance simulation techniques, their impact on advancing drug discovery and improving DDSs is expected to be profound.",
        "DOI": "10.1016/j.molliq.2023.123888",
        "paper_author": "Salahshoori I.",
        "affiliation_name": "Iran Polymer and Petrochemical Institute",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60010312",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Advancing Precision Medicine: A Review of Innovative In Silico Approaches for Drug Development, Clinical Pharmacology and Personalized Healthcare",
        "publication": "Pharmaceutics",
        "citied_by": "41",
        "cover_date": "2024-03-01",
        "Abstract": "The landscape of medical treatments is undergoing a transformative shift. Precision medicine has ushered in a revolutionary era in healthcare by individualizing diagnostics and treatments according to each patient’s uniquely evolving health status. This groundbreaking method of tailoring disease prevention and treatment considers individual variations in genes, environments, and lifestyles. The goal of precision medicine is to target the “five rights”: the right patient, the right drug, the right time, the right dose, and the right route. In this pursuit, in silico techniques have emerged as an anchor, driving precision medicine forward and making this a realistic and promising avenue for personalized therapies. With the advancements in high-throughput DNA sequencing technologies, genomic data, including genetic variants and their interactions with each other and the environment, can be incorporated into clinical decision-making. Pharmacometrics, gathering pharmacokinetic (PK) and pharmacodynamic (PD) data, and mathematical models further contribute to drug optimization, drug behavior prediction, and drug–drug interaction identification. Digital health, wearables, and computational tools offer continuous monitoring and real-time data collection, enabling treatment adjustments. Furthermore, the incorporation of extensive datasets in computational tools, such as electronic health records (EHRs) and omics data, is also another pathway to acquire meaningful information in this field. Although they are fairly new, machine learning (ML) algorithms and artificial intelligence (AI) techniques are also resources researchers use to analyze big data and develop predictive models. This review explores the interplay of these multiple in silico approaches in advancing precision medicine and fostering individual healthcare. Despite intrinsic challenges, such as ethical considerations, data protection, and the need for more comprehensive research, this marks a new era of patient-centered healthcare. Innovative in silico techniques hold the potential to reshape the future of medicine for generations to come.",
        "DOI": "10.3390/pharmaceutics16030332",
        "paper_author": "Marques L.",
        "affiliation_name": "Centro de Investigação em Tecnologias e Serviços de Saúde, Porto",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60111040",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "Metabolomic machine learning predictor for diagnosis and prognosis of gastric cancer",
        "publication": "Nature Communications",
        "citied_by": "40",
        "cover_date": "2024-12-01",
        "Abstract": "Gastric cancer (GC) represents a significant burden of cancer-related mortality worldwide, underscoring an urgent need for the development of early detection strategies and precise postoperative interventions. However, the identification of non-invasive biomarkers for early diagnosis and patient risk stratification remains underexplored. Here, we conduct a targeted metabolomics analysis of 702 plasma samples from multi-center participants to elucidate the GC metabolic reprogramming. Our machine learning analysis reveals a 10-metabolite GC diagnostic model, which is validated in an external test set with a sensitivity of 0.905, outperforming conventional methods leveraging cancer protein markers (sensitivity < 0.40). Additionally, our machine learning-derived prognostic model demonstrates superior performance to traditional models utilizing clinical parameters and effectively stratifies patients into different risk groups to guide precision interventions. Collectively, our findings reveal the metabolic landscape of GC and identify two distinct biomarker panels that enable early detection and prognosis prediction respectively, thus facilitating precision medicine in GC.",
        "DOI": "10.1038/s41467-024-46043-y",
        "paper_author": "Chen Y.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Profiling the dysregulated immune response in sepsis: overcoming challenges to achieve the goal of precision medicine",
        "publication": "The Lancet Respiratory Medicine",
        "citied_by": "39",
        "cover_date": "2024-04-01",
        "Abstract": "Sepsis is characterised by a dysregulated host immune response to infection. Despite recognition of its significance, immune status monitoring is not implemented in clinical practice due in part to the current absence of direct therapeutic implications. Technological advances in immunological profiling could enhance our understanding of immune dysregulation and facilitate integration into clinical practice. In this Review, we provide an overview of the current state of immune profiling in sepsis, including its use, current challenges, and opportunities for progress. We highlight the important role of immunological biomarkers in facilitating predictive enrichment in current and future treatment scenarios. We propose that multiple immune and non-immune-related parameters, including clinical and microbiological data, be integrated into diagnostic and predictive combitypes, with the aid of machine learning and artificial intelligence techniques. These combitypes could form the basis of workable algorithms to guide clinical decisions that make precision medicine in sepsis a reality and improve patient outcomes.",
        "DOI": "10.1016/S2213-2600(23)00330-2",
        "paper_author": "Cajander S.",
        "affiliation_name": "Faculty of Medicine and Health",
        "affiliation_city": "Orebro",
        "affiliation_country": "Sweden",
        "affiliation_id": "60221525",
        "affiliation_state": "Orebro"
    },
    {
        "paper_title": "Refining the impact of genetic evidence on clinical success",
        "publication": "Nature",
        "citied_by": "38",
        "cover_date": "2024-05-16",
        "Abstract": "The cost of drug discovery and development is driven primarily by failure1, with only about 10% of clinical programmes eventually receiving approval2–4. We previously estimated that human genetic evidence doubles the success rate from clinical development to approval5. In this study we leverage the growth in genetic evidence over the past decade to better understand the characteristics that distinguish clinical success and failure. We estimate the probability of success for drug mechanisms with genetic support is 2.6 times greater than those without. This relative success varies among therapy areas and development phases, and improves with increasing confidence in the causal gene, but is largely unaffected by genetic effect size, minor allele frequency or year of discovery. These results indicate we are far from reaching peak genetic insights to aid the discovery of targets for more effective drugs.",
        "DOI": "10.1038/s41586-024-07316-0",
        "paper_author": "Minikel E.V.",
        "affiliation_name": "Broad Institute",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60001001",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Artificial intelligence in neuro-oncology: advances and challenges in brain tumor diagnosis, prognosis, and precision treatment",
        "publication": "npj Precision Oncology",
        "citied_by": "38",
        "cover_date": "2024-12-01",
        "Abstract": "This review delves into the most recent advancements in applying artificial intelligence (AI) within neuro-oncology, specifically emphasizing work on gliomas, a class of brain tumors that represent a significant global health issue. AI has brought transformative innovations to brain tumor management, utilizing imaging, histopathological, and genomic tools for efficient detection, categorization, outcome prediction, and treatment planning. Assessing its influence across all facets of malignant brain tumor management- diagnosis, prognosis, and therapy- AI models outperform human evaluations in terms of accuracy and specificity. Their ability to discern molecular aspects from imaging may reduce reliance on invasive diagnostics and may accelerate the time to molecular diagnoses. The review covers AI techniques, from classical machine learning to deep learning, highlighting current applications and challenges. Promising directions for future research include multimodal data integration, generative AI, large medical language models, precise tumor delineation and characterization, and addressing racial and gender disparities. Adaptive personalized treatment strategies are also emphasized for optimizing clinical outcomes. Ethical, legal, and social implications are discussed, advocating for transparency and fairness in AI integration for neuro-oncology and providing a holistic understanding of its transformative impact on patient care.",
        "DOI": "10.1038/s41698-024-00575-0",
        "paper_author": "Khalighi S.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Application of ChatGPT in Routine Diagnostic Pathology: Promises, Pitfalls, and Potential Future Directions",
        "publication": "Advances in Anatomic Pathology",
        "citied_by": "37",
        "cover_date": "2024-01-01",
        "Abstract": "Large Language Models are forms of artificial intelligence that use deep learning algorithms to decipher large amounts of text and exhibit strong capabilities like question answering and translation. Recently, an influx of Large Language Models has emerged in the medical and academic discussion, given their potential widespread application to improve patient care and provider workflow. One application that has gained notable recognition in the literature is ChatGPT, which is a natural language processing \"chatbot\" technology developed by the artificial intelligence development software company OpenAI. It learns from large amounts of text data to generate automated responses to inquiries in seconds. In health care and academia, chatbot systems like ChatGPT have gained much recognition recently, given their potential to become functional, reliable virtual assistants. However, much research is required to determine the accuracy, validity, and ethical concerns of the integration of ChatGPT and other chatbots into everyday practice. One such field where little information and research on the matter currently exists is pathology. Herein, we present a literature review of pertinent articles regarding the current status and understanding of ChatGPT and its potential application in routine diagnostic pathology. In this review, we address the promises, possible pitfalls, and future potential of this application. We provide examples of actual conversations conducted with the chatbot technology that mimic hypothetical but practical diagnostic pathology scenarios that may be encountered in routine clinical practice. On the basis of this experience, we observe that ChatGPT and other chatbots already have a remarkable ability to distill and summarize, within seconds, vast amounts of publicly available data and information to assist in laying a foundation of knowledge on a specific topic. We emphasize that, at this time, any use of such knowledge at the patient care level in clinical medicine must be carefully vetted through established sources of medical information and expertise. We suggest and anticipate that with the ever-expanding knowledge base required to reliably practice personalized, precision anatomic pathology, improved technologies like future versions of ChatGPT (and other chatbots) enabled by expanded access to reliable, diverse data, might serve as a key ally to the diagnostician. Such technology has real potential to further empower the time-honored paradigm of histopathologic diagnoses based on the integrative cognitive assessment of clinical, gross, and microscopic findings and ancillary immunohistochemical and molecular studies at a time of exploding biomedical knowledge.",
        "DOI": "10.1097/PAP.0000000000000406",
        "paper_author": "Schukow C.",
        "affiliation_name": "Corewell Health",
        "affiliation_city": "Royal Oak",
        "affiliation_country": "United States",
        "affiliation_id": "129565328",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Recent advances in artificial intelligence towards the sustainable future of agri-food industry",
        "publication": "Food Chemistry",
        "citied_by": "36",
        "cover_date": "2024-07-30",
        "Abstract": "Artificial intelligence has the potential to alter the agricultural and food processing industries, with significant ramifications for sustainability and global food security. The integration of artificial intelligence in agriculture has witnessed a significant uptick in recent years. Therefore, comprehensive understanding of these techniques is needed to broaden its application in agri-food supply chain. In this review, we explored cutting-edge artificial intelligence methodologies with a focus on machine learning, neural networks, and deep learning. The application of artificial intelligence in agri-food industry and their quality assurance throughout the production process is thoroughly discussed with an emphasis on the current scientific knowledge and future perspective. Artificial intelligence has played a significant role in transforming agri-food systems by enhancing efficiency, sustainability, and productivity. Many food industries are implementing the artificial intelligence in modelling, prediction, control tool, sensory evaluation, quality control, and tackling complicated challenges in food processing. Similarly, artificial intelligence applied in agriculture to improve the entire farming process, such as crop yield optimization, use of herbicides, weeds identification, and harvesting of fruits. In summary, the integration of artificial intelligence in agri-food systems offers the potential to address key challenges in agriculture, enhance sustainability, and contribute to global food security.",
        "DOI": "10.1016/j.foodchem.2024.138945",
        "paper_author": "Nath P.C.",
        "affiliation_name": "National Institute of Technology, Agartala",
        "affiliation_city": "Agartala",
        "affiliation_country": "India",
        "affiliation_id": "60104582",
        "affiliation_state": "TR"
    },
    {
        "paper_title": "Toward Explainable Artificial Intelligence for Precision Pathology",
        "publication": "Annual Review of Pathology: Mechanisms of Disease",
        "citied_by": "36",
        "cover_date": "2024-01-24",
        "Abstract": "The rapid development of precision medicine in recent years has started to challenge diagnostic pathology with respect to its ability to analyze histological images and increasingly large molecular profiling data in a quantitative, integrative, and standardized way. Artificial intelligence (AI) and, more precisely, deep learning technologies have recently demonstrated the potential to facilitate complex data analysis tasks, including clinical, histological, and molecular data for disease classification; tissue biomarker quantification; and clinical outcome prediction. This review provides a general introduction to AI and describes recent developments with a focus on applications in diagnostic pathology and beyond. We explain limitations including the black-box character of conventional AI and describe solutions to make machine learning decisions more transparent with so-called explainable AI. The purpose of the review is to foster a mutual understanding of both the biomedical and the AI side. To that end, in addition to providing an overview of the relevant foundations in pathology and machine learning, we present worked-through examples for a better practical understanding of what AI can achieve and how it should be done.",
        "DOI": "10.1146/annurev-pathmechdis-051222-113147",
        "paper_author": "Klauschen F.",
        "affiliation_name": "Ludwig-Maximilians-Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60028717",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Performance and risks of ChatGPT used in drug information: An exploratory real-world analysis",
        "publication": "European Journal of Hospital Pharmacy",
        "citied_by": "36",
        "cover_date": "2024-10-25",
        "Abstract": "Objectives To investigate the performance and risk associated with the usage of Chat Generative Pre-trained Transformer (ChatGPT) to answer drug-related questions. Methods A sample of 50 drug-related questions were consecutively collected and entered in the artificial intelligence software application ChatGPT. Answers were documented and rated in a standardised consensus process by six senior hospital pharmacists in the domains content (correct, incomplete, false), patient management (possible, insufficient, not possible) and risk (no risk, low risk, high risk). As reference, answers were researched in adherence to the German guideline of drug information and stratified in four categories according to the sources used. In addition, the reproducibility of ChatGPT's answers was analysed by entering three questions at different timepoints repeatedly (day 1, day 2, week 2, week 3). Results Overall, only 13 of 50 answers provided correct content and had enough information to initiate management with no risk of patient harm. The majority of answers were either false (38%, n=19) or had partly correct content (36%, n=18) and no references were provided. A high risk of patient harm was likely in 26% (n=13) of the cases and risk was judged low for 28% (n=14) of the cases. In all high-risk cases, actions could have been initiated based on the provided information. The answers of ChatGPT varied over time when entered repeatedly and only three out of 12 answers were identical, showing no reproducibility to low reproducibility. Conclusion In a real-world sample of 50 drug-related questions, ChatGPT answered the majority of questions wrong or partly wrong. The use of artificial intelligence applications in drug information is not possible as long as barriers like wrong content, missing references and reproducibility remain.",
        "DOI": "10.1136/ejhpharm-2023-003750",
        "paper_author": "Morath B.",
        "affiliation_name": "Universitätsklinikum Heidelberg",
        "affiliation_city": "Heidelberg",
        "affiliation_country": "Germany",
        "affiliation_id": "60003280",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Large Language Models in Healthcare and Medical Domain: A Review",
        "publication": "Informatics",
        "citied_by": "35",
        "cover_date": "2024-09-01",
        "Abstract": "The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension. These models exhibit the remarkable ability to provide proficient responses to free-text queries, demonstrating a nuanced understanding of professional medical knowledge. This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications and elucidates the trajectory of their development, starting with traditional Pretrained Language Models (PLMs) and then moving to the present state of LLMs in the healthcare sector. First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare applications, particularly focusing on clinical language understanding tasks. These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multimodal medical applications, document classification, and question-answering. Additionally, we conduct an extensive comparison of the most recent state-of-the-art LLMs in the healthcare domain, while also assessing the utilization of various open-source LLMs and highlighting their significance in healthcare applications. Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations. Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector by offering a holistic perspective on their potential benefits and shortcomings. This review provides a comprehensive exploration of the current landscape of LLMs in healthcare, addressing their role in transforming medical applications and the areas that warrant further research and development.",
        "DOI": "10.3390/informatics11030057",
        "paper_author": "Nazi Z.A.",
        "affiliation_name": "Marlan and Rosemary Bourns College of Engineering",
        "affiliation_city": "Riverside",
        "affiliation_country": "United States",
        "affiliation_id": "60137655",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Explainable and interpretable artificial intelligence in medicine: a systematic bibliometric review",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "34",
        "cover_date": "2024-12-01",
        "Abstract": "This review aims to explore the growing impact of machine learning and deep learning algorithms in the medical field, with a specific focus on the critical issues of explainability and interpretability associated with black-box algorithms. While machine learning algorithms are increasingly employed for medical analysis and diagnosis, their complexity underscores the importance of understanding how these algorithms explain and interpret data to take informed decisions. This review comprehensively analyzes challenges and solutions presented in the literature, offering an overview of the most recent techniques utilized in this field. It also provides precise definitions of interpretability and explainability, aiming to clarify the distinctions between these concepts and their implications for the decision-making process. Our analysis, based on 448 articles and addressing seven research questions, reveals an exponential growth in this field over the last decade. The psychological dimensions of public perception underscore the necessity for effective communication regarding the capabilities and limitations of artificial intelligence. Researchers are actively developing techniques to enhance interpretability, employing visualization methods and reducing model complexity. However, the persistent challenge lies in finding the delicate balance between achieving high performance and maintaining interpretability. Acknowledging the growing significance of artificial intelligence in aiding medical diagnosis and therapy, and the creation of interpretable artificial intelligence models is considered essential. In this dynamic context, an unwavering commitment to transparency, ethical considerations, and interdisciplinary collaboration is imperative to ensure the responsible use of artificial intelligence. This collective commitment is vital for establishing enduring trust between clinicians and patients, addressing emerging challenges, and facilitating the informed adoption of these advanced technologies in medicine.",
        "DOI": "10.1007/s44163-024-00114-7",
        "paper_author": "Frasca M.",
        "affiliation_name": "Università degli Studi di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60030318",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Individualized Treatment Effects of Oxygen Targets in Mechanically Ventilated Critically Ill Adults",
        "publication": "JAMA",
        "citied_by": "34",
        "cover_date": "2024-04-09",
        "Abstract": "Importance: Among critically ill adults, randomized trials have not found oxygenation targets to affect outcomes overall. Whether the effects of oxygenation targets differ based on an individual's characteristics is unknown. Objective: To determine whether an individual's characteristics modify the effect of lower vs higher peripheral oxygenation-saturation (Spo2) targets on mortality. Design, Setting, and Participants: A machine learning model to predict the effect of treatment with a lower vs higher Spo2 target on mortality for individual patients was derived in the Pragmatic Investigation of Optimal Oxygen Targets (PILOT) trial and externally validated in the Intensive Care Unit Randomized Trial Comparing Two Approaches to Oxygen Therapy (ICU-ROX) trial. Critically ill adults received invasive mechanical ventilation in an intensive care unit (ICU) in the United States between July 2018 and August 2021 for PILOT (n = 1682) and in 21 ICUs in Australia and New Zealand between September 2015 and May 2018 for ICU-ROX (n = 965). Exposures: Randomization to a lower vs higher Spo2 target group. Main Outcome and Measure: 28-Day mortality. Results: In the ICU-ROX validation cohort, the predicted effect of treatment with a lower vs higher Spo2 target for individual patients ranged from a 27.2% absolute reduction to a 34.4% absolute increase in 28-day mortality. For example, patients predicted to benefit from a lower Spo2 target had a higher prevalence of acute brain injury, whereas patients predicted to benefit from a higher Spo2 target had a higher prevalence of sepsis and abnormally elevated vital signs. Patients predicted to benefit from a lower Spo2 target experienced lower mortality when randomized to the lower Spo2 group, whereas patients predicted to benefit from a higher Spo2 target experienced lower mortality when randomized to the higher Spo2 group (likelihood ratio test for effect modification P =.02). The use of a Spo2 target predicted to be best for each patient, instead of the randomized Spo2 target, would have reduced the absolute overall mortality by 6.4% (95% CI, 1.9%-10.9%). Conclusion and relevance: Oxygenation targets that are individualized using machine learning analyses of randomized trials may reduce mortality for critically ill adults. A prospective trial evaluating the use of individualized oxygenation targets is needed.",
        "DOI": "10.1001/jama.2024.2933",
        "paper_author": "Buell K.G.",
        "affiliation_name": "The University of Chicago",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States",
        "affiliation_id": "60029278",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Machine learning applications in stroke medicine: Advancements, challenges, and future prospective",
        "publication": "Neural Regeneration Research",
        "citied_by": "34",
        "cover_date": "2024-04-01",
        "Abstract": "Stroke is a leading cause of disability and mortality worldwide, necessitating the development of advanced technologies to improve its diagnosis, treatment, and patient outcomes. In recent years, machine learning techniques have emerged as promising tools in stroke medicine, enabling efficient analysis of large-scale datasets and facilitating personalized and precision medicine approaches. This abstract provides a comprehensive overview of machine learning's applications, challenges, and future directions in stroke medicine. Recently introduced machine learning algorithms have been extensively employed in all the fields of stroke medicine. Machine learning models have demonstrated remarkable accuracy in imaging analysis, diagnosing stroke subtypes, risk stratifications, guiding medical treatment, and predicting patient prognosis. Despite the tremendous potential of machine learning in stroke medicine, several challenges must be addressed. These include the need for standardized and interoperable data collection, robust model validation and generalization, and the ethical considerations surrounding privacy and bias. In addition, integrating machine learning models into clinical workflows and establishing regulatory frameworks are critical for ensuring their widespread adoption and impact in routine stroke care. Machine learning promises to revolutionize stroke medicine by enabling precise diagnosis, tailored treatment selection, and improved prognostication. Continued research and collaboration among clinicians, researchers, and technologists are essential for overcoming challenges and realizing the full potential of machine learning in stroke care, ultimately leading to enhanced patient outcomes and quality of life. This review aims to summarize all the current implications of machine learning in stroke diagnosis, treatment, and prognostic evaluation. At the same time, another purpose of this paper is to explore all the future perspectives these techniques can provide in combating this disabling disease.",
        "DOI": "10.4103/1673-5374.382228",
        "paper_author": "Daidone M.",
        "affiliation_name": "Università degli Studi di Palermo",
        "affiliation_city": "Palermo",
        "affiliation_country": "Italy",
        "affiliation_id": "60017697",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Machine learning in sports science: challenges and opportunities",
        "publication": "Sports Biomechanics",
        "citied_by": "32",
        "cover_date": "2024-01-01",
        "Abstract": "NA",
        "DOI": "10.1080/14763141.2021.1910334",
        "paper_author": "Richter C.",
        "affiliation_name": "Kaia Health GmbH",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "120861895",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "CNN and Edge-Based Segmentation for the Identification of Medicinal Plants",
        "publication": "Proceedings - 2024 5th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks, ICICV 2024",
        "citied_by": "30",
        "cover_date": "2024-01-01",
        "Abstract": "In Ayurveda, traditional and herbal medicine industries, it is of the utmost importance to precisely identify the appropriate medicinal plants used in the production of medicines. A medicinal plant's identity is determined by the shape, color, and texture of its leaves. SVM and KNN are existing Machine Learning (ML) models employed for this task; however, when it comes to identifying medicinal plants, they are ineffective. For medicinal plant identification, complex properties like leaf form, color, and texture can be difficult to accurately represent using traditional methods like KNN and SVM. In image recognition tasks, large datasets are common, and some approaches may not scale well under those circumstances. They might become prohibitively expensive to compute, rendering them useless for everyday use. The development of strong characteristics for plant recognition is frequently a time-consuming process, despite the fact that traditional models heavily rely on feature engineering. Hence, a promising approach to quickly identify the beneficial plant species is presented in this study. A Convolutional Neural Network (CNN) is the solution proposed here to identify the medicinal plants. CNNs are appropriate for processing largescale data, for example, leaf structure, variety, and surface discovery, without requiring any prerequisite for broad element design due to their capacity to gain and concentrate requested qualities from the input images. CNNs are more adaptable to the real world because they can be trained effectively on large datasets and can be parallelized. When contrasted with different models, the one developed in this research study improves at characterizing the restorative plant.",
        "DOI": "10.1109/ICICV62344.2024.00021",
        "paper_author": "Kumar P.",
        "affiliation_name": "Rajalakshmi Engineering College",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60100989",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Use of Artificial Intelligence in Improving Outcomes in Heart Disease: A Scientific Statement From the American Heart Association",
        "publication": "Circulation",
        "citied_by": "29",
        "cover_date": "2024-04-02",
        "Abstract": "A major focus of academia, industry, and global governmental agencies is to develop and apply artificial intelligence and other advanced analytical tools to transform health care delivery. The American Heart Association supports the creation of tools and services that would further the science and practice of precision medicine by enabling more precise approaches to cardiovascular and stroke research, prevention, and care of individuals and populations. Nevertheless, several challenges exist, and few artificial intelligence tools have been shown to improve cardiovascular and stroke care sufficiently to be widely adopted. This scientific statement outlines the current state of the art on the use of artificial intelligence algorithms and data science in the diagnosis, classification, and treatment of cardiovascular disease. It also sets out to advance this mission, focusing on how digital tools and, in particular, artificial intelligence may provide clinical and mechanistic insights, address bias in clinical studies, and facilitate education and implementation science to improve cardiovascular and stroke outcomes. Last, a key objective of this scientific statement is to further the field by identifying best practices, gaps, and challenges for interested stakeholders.",
        "DOI": "10.1161/CIR.0000000000001201",
        "paper_author": "Armoundas A.A.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial Intelligence and Machine Learning for Improving Glycemic Control in Diabetes: Best Practices, Pitfalls, and Opportunities",
        "publication": "IEEE Reviews in Biomedical Engineering",
        "citied_by": "29",
        "cover_date": "2024-01-01",
        "Abstract": "Objective: Artificial intelligence and machine learning are transforming many fields including medicine. In diabetes, robust biosensing technologies and automated insulin delivery therapies have created a substantial opportunity to improve health. While the number of manuscripts addressing the topic of applying machine learning to diabetes has grown in recent years, there has been a lack of consistency in the methods, metrics, and data used to train and evaluate these algorithms. This manuscript provides consensus guidelines for machine learning practitioners in the field of diabetes, including best practice recommended approaches and warnings about pitfalls to avoid. Methods: Algorithmic approaches are reviewed and benefits of different algorithms are discussed including importance of clinical accuracy, explainability, interpretability, and personalization. We review the most common features used in machine learning applications in diabetes glucose control and provide an open-source library of functions for calculating features, as well as a framework for specifying data sets using data sheets. A review of current data sets available for training algorithms is provided as well as an online repository of data sources. Significance: These consensus guidelines are designed to improve performance and translatability of new machine learning algorithms developed in the field of diabetes for engineers and data scientists.",
        "DOI": "10.1109/RBME.2023.3331297",
        "paper_author": "Jacobs P.G.",
        "affiliation_name": "Department of Biomedical Engineering",
        "affiliation_city": "Portland",
        "affiliation_country": "United States",
        "affiliation_id": "60013512",
        "affiliation_state": "OR"
    },
    {
        "paper_title": "Multi-OMICS approaches in cancer biology: New era in cancer therapy",
        "publication": "Biochimica et Biophysica Acta - Molecular Basis of Disease",
        "citied_by": "28",
        "cover_date": "2024-06-01",
        "Abstract": "Innovative multi-omics frameworks integrate diverse datasets from the same patients to enhance our understanding of the molecular and clinical aspects of cancers. Advanced omics and multi-view clustering algorithms present unprecedented opportunities for classifying cancers into subtypes, refining survival predictions and treatment outcomes, and unravelling key pathophysiological processes across various molecular layers. However, with the increasing availability of cost-effective high-throughput technologies (HTT) that generate vast amounts of data, analyzing single layers often falls short of establishing causal relations. Integrating multi-omics data spanning genomes, epigenomes, transcriptomes, proteomes, metabolomes, and microbiomes offers unique prospects to comprehend the underlying biology of complex diseases like cancer. This discussion explores algorithmic frameworks designed to uncover cancer subtypes, disease mechanisms, and methods for identifying pivotal genomic alterations. It also underscores the significance of multi-omics in tumor classifications, diagnostics, and prognostications. Despite its unparalleled advantages, the integration of multi-omics data has been slow to find its way into everyday clinics. A major hurdle is the uneven maturity of different omics approaches and the widening gap between the generation of large datasets and the capacity to process this data. Initiatives promoting the standardization of sample processing and analytical pipelines, as well as multidisciplinary training for experts in data analysis and interpretation, are crucial for translating theoretical findings into practical applications.",
        "DOI": "10.1016/j.bbadis.2024.167120",
        "paper_author": "Chakraborty S.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India",
        "affiliation_id": "60010618",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "A quantum convolutional network and ResNet (50)-based classification architecture for the MNIST medical dataset",
        "publication": "Biomedical Signal Processing and Control",
        "citied_by": "28",
        "cover_date": "2024-01-01",
        "Abstract": "Biomedical image classification is crucial for both computer vision tasks and clinical care. The conventional method requires a significant amount of time and effort for extracting and selecting classification features. Deep Neural Networks (DNNs) and Quantum Convolutional Neural Networks (QCNN) are emerging techniques in machine learning that have demonstrated their efficacy for various classification tasks. Because of the complexity of their designs, the results of such models may also be challenging to interpret. In this paper, we propose an architecture called Medical Quantum Convolutional Neural Network (MQCNN), based on the QCNN model and a modified ResNet (50) pre-trained model, for enhancing the biomedical image classification in the MNIST medical dataset. During the training phase, the weights are updated using the Adam optimizer, while ResNet (50) is used to reduce the computational cost. MQCNN is compared to the QCNN model, the ResNet (50) pre-trained model, and some other related works on the Medical MNIST dataset. The results showed that MQCNN model achieves 99.6% accuracy, 99.7% precision, 99.6% recall, and 99.7% F1 score, and outperforms the ResNet (50) pre-trained model, the QCNN model, and the other compared related works.",
        "DOI": "10.1016/j.bspc.2023.105560",
        "paper_author": "Hassan E.",
        "affiliation_name": "Faculty of Artificial Intelligence",
        "affiliation_city": "Kafr el-Sheikh",
        "affiliation_country": "Egypt",
        "affiliation_id": "60227512",
        "affiliation_state": "Kafr el-Sheikh"
    },
    {
        "paper_title": "MetaFed: Federated Learning Among Federations With Cyclic Knowledge Distillation for Personalized Healthcare",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "28",
        "cover_date": "2024-01-01",
        "Abstract": "Federated learning (FL) has attracted increasing attention to building models without accessing raw user data, especially in healthcare. In real applications, different federations can seldom work together due to possible reasons such as data heterogeneity and distrust/inexistence of the central server. In this article, we propose a novel framework called MetaFed to facilitate trustworthy FL between different federations. MetaFed obtains a personalized model for each federation without a central server via the proposed cyclic knowledge distillation. Specifically, MetaFed treats each federation as a meta distribution and aggregates knowledge of each federation in a cyclic manner. The training is split into two parts: common knowledge accumulation and personalization. Comprehensive experiments on seven benchmarks demonstrate that MetaFed without a server achieves better accuracy compared with state-of-the-art methods [e.g., 10%+ accuracy improvement compared with the baseline for physical activity monitoring dataset (PAMAP2)] with fewer communication costs. More importantly, MetaFed shows remarkable performance in real-healthcare-related applications.",
        "DOI": "10.1109/TNNLS.2023.3297103",
        "paper_author": "Chen Y.",
        "affiliation_name": "Institute of Computing Technology Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60030904",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation",
        "publication": "Proceedings - 2024 IEEE Winter Conference on Applications of Computer Vision, WACV 2024",
        "citied_by": "27",
        "cover_date": "2024-01-03",
        "Abstract": "In this paper, we are the first to propose a new graph convolution-based decoder namely, Cascaded Graph Convolutional Attention Decoder (G-CASCADE), for 2D medical image segmentation. G-CASCADE progressively refines multi-stage feature maps generated by hierarchical transformer encoders with an efficient graph convolution block. The encoder utilizes the self-attention mechanism to capture long-range dependencies, while the decoder refines the feature maps preserving long-range information due to the global receptive fields of the graph convolution block. Rigorous evaluations of our decoder with multiple transformer encoders on five medical image segmentation tasks (i.e., Abdomen organs, Cardiac organs, Polyp lesions, Skin lesions, and Retinal vessels) show that our model outperforms other state-of-the-art (SOTA) methods. We also demonstrate that our decoder achieves better DICE scores than the SOTA CASCADE decoder with 80.8% fewer parameters and 82.3% fewer FLOPs. Our decoder can easily be used with other hierarchical encoders for general-purpose semantic and medical image segmentation tasks. The implementation can be found at: https://github.com/SLDGroup/G-CASCADE.",
        "DOI": "10.1109/WACV57701.2024.00755",
        "paper_author": "Rahman M.M.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Artificial intelligence in cancer diagnosis: Opportunities and challenges",
        "publication": "Pathology Research and Practice",
        "citied_by": "27",
        "cover_date": "2024-01-01",
        "Abstract": "Since cancer is one of the world's top causes of death, early diagnosis is critical to improving patient outcomes. Artificial intelligence (AI) has become a viable technique for cancer diagnosis by using machine learning algorithms to examine large volumes of data for accurate and efficient diagnosis. AI has the potential to alter the way cancer is detected fundamentally. Still, it has several disadvantages, such as requiring a large amount of data, technological limitations, and ethical concerns. This overview looks at the possibilities and restrictions of AI in cancer detection, as well as current applications and possible future developments. We can better understand how to use AI to improve patient outcomes and reduce cancer mortality rates by looking at its potential for cancer detection.",
        "DOI": "10.1016/j.prp.2023.154996",
        "paper_author": "S. Alshuhri M.",
        "affiliation_name": "Prince Sattam Bin Abdulaziz University",
        "affiliation_city": "Al Kharj",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60105222",
        "affiliation_state": "Ar Riyad"
    },
    {
        "paper_title": "The Evolving Landscape of Artificial Intelligence Applications in Animal Health",
        "publication": "Indian Journal of Animal Research",
        "citied_by": "26",
        "cover_date": "2024-10-01",
        "Abstract": "Background: This work explores the expansivetab realm of Artificial Intelligence (AI) applications in the dynamic landscape of animal health and veterinary sciences. Addressing challenges in conventional approaches, we delve into how AI is transforming diagnosis, treatment and healthcare practices for diverse animal species. Methods: Through a rigorous literature review and methodology, the study navigates the current state of AI in animal health, identifying gaps and emphasizing the need for further research. Looking ahead, the paper outlines future directions and opportunities, contributing to the discourse on technology’s intersection with animal care. By providing a comprehensive overview, this research paves the way for innovative solutions, promising a brighter and healthier future for our animal companions. Result: In the domain of animal health, AI emerges as a powerful tool for early disease detection and intervention, offering personalized treatment plans and proactive disease management through continuous monitoring and surveillance. In veterinary sciences, AI accelerates drug discovery, enhances genetic research and reshapes surgical procedures with robotic assistance. However, ethical considerations and challenges, including data privacy and AI-driven decision-making and critical examination should be addressed to.",
        "DOI": "10.18805/IJAR.BF-1742",
        "paper_author": "Min P.K.",
        "affiliation_name": "The University of Electro-Communications",
        "affiliation_city": "Chofu",
        "affiliation_country": "Japan",
        "affiliation_id": "60032315",
        "affiliation_state": "Tokyo"
    },
    {
        "paper_title": "Joint masking and self-supervised strategies for inferring small molecule-miRNA associations",
        "publication": "Molecular Therapy Nucleic Acids",
        "citied_by": "26",
        "cover_date": "2024-03-12",
        "Abstract": "Inferring small molecule-miRNA associations (MMAs) is crucial for revealing the intricacies of biological processes and disease mechanisms. Deep learning, renowned for its exceptional speed and accuracy, is extensively used for predicting MMAs. However, given their heavy reliance on data, inaccuracies during data collection can make these methods susceptible to noise interference. To address this challenge, we introduce the joint masking and self-supervised (JMSS)-MMA model. This model synergizes graph autoencoders with a probability distribution-based masking strategy, effectively countering the impact of noisy data and enabling precise predictions of unknown MMAs. Operating in a self-supervised manner, it deeply encodes the relationship data of small molecules and miRNA through the graph autoencoder, delving into its latent information. Our masking strategy has successfully reduced data noise, enhancing prediction accuracy. To our knowledge, this is the pioneering integration of a masking strategy with graph autoencoders for MMA prediction. Furthermore, the JMSS-MMA model incorporates a node-degree–based decoder, deepening the understanding of the network's structure. Experiments on two mainstream datasets confirm the model's efficiency and precision, and ablation studies further attest to its robustness. We firmly believe that this model will revolutionize drug development, personalized medicine, and biomedical research.",
        "DOI": "10.1016/j.omtn.2023.102103",
        "paper_author": "Zhou Z.",
        "affiliation_name": "Wenzhou University of Technology",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China",
        "affiliation_id": "60281291",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Transfer learning to leverage larger datasets for improved prediction of protein stability changes",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "25",
        "cover_date": "2024-01-01",
        "Abstract": "Amino acid mutations that lower a protein’s thermodynamic stability are implicated in numerous diseases, and engineered proteins with enhanced stability can be important in research and medicine. Computational methods for predicting how mutations perturb protein stability are, therefore, of great interest. Despite recent advancements in protein design using deep learning, in silico prediction of stability changes has remained challenging, in part due to a lack of large, high-quality training datasets for model development. Here, we describe ThermoMPNN, a deep neural network trained to predict stability changes for protein point mutations given an initial structure. In doing so, we demonstrate the utility of a recently released megascale stability dataset for training a robust stability model. We also employ transfer learning to leverage a second, larger dataset by using learned features extracted from ProteinMPNN, a deep neural network trained to predict a protein’s amino acid sequence given its three-dimensional structure. We show that our method achieves state-of-the-art performance on established benchmark datasets using a lightweight model architecture that allows for rapid, scalable predictions. Finally, we make ThermoMPNN readily available as a tool for stability prediction and design.",
        "DOI": "10.1073/pnas.2314853121",
        "paper_author": "Dieckhaus H.",
        "affiliation_name": "UNC School of Medicine",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States",
        "affiliation_id": "60020469",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Integrated Green Lean Six Sigma-Industry 4.0 approach to combat COVID-19: from literature review to framework development",
        "publication": "International Journal of Lean Six Sigma",
        "citied_by": "25",
        "cover_date": "2024-01-12",
        "Abstract": "Purpose: The coronavirus (COVID-19) pandemic has led to a surge in demand for health-care facilities, medicines, vaccines and other health-care items. The purpose of this study is to investigate different facets of integrated Green Lean Six Sigma and Industry 4.0 approach in the context of COVID-19 for better healthcare management. Integrating Green Lean Six Sigma (GLSS) and Industry 4.0 (I4.0) has the potential to meet the modern demand of health-care units and also leads to improving the quality of inpatient care with better safety, hygiene and real-time diagnoses. A systematic review has been conducted to determine the tools/techniques, challenges, application areas and potential benefits for the adoption of an integrated GLSS-I4.0 approach within health-care facilities from the perspective of COVID management. Further, a conceptual framework of integrated GLSS-I4.0 has been proposed for better COVID management. Design/methodology/approach: To conduct the literature review, the authors used the preferred reporting items for systematic reviews and meta-analysis and covers relevant papers from the arrival of COVID-19. Based on the systematic understanding of the different facets of the integrated GLSS-I4.0 approach and through insights of experts (academicians and health-care personnel), a conceptual framework is proposed to combat COVID-19 for better detection, prevention and cure. Findings: The systematic review presented here provides different avenues to comprehend the different facets of the integrated GLSS-I4.0 approach in different areas of COVID health-care management. In this study, the proposed framework reveals that the Internet of Things, big data and artificial intelligence are the major constituents of I4.0 technologies that lead to better COVID management. Moreover, integration of I4.0 with GLSS aids during different stages of the COVID management, right from diagnosis, manufacture of items and inpatient and outpatient care of the affected person. Practical implications: This study provides a significant knowledge database to the practitioners by understanding different tools and techniques of an integrated approach for better COVID management. Moreover, the proposed framework aids to grab day-to-day information from the affected people and ensures reduced hospital stay with better space utilization and the creation of a healthy environment around the patient. This inclusive implementation of the proposed framework will enhance knowledge base in medical areas and provides different novel prospects to combat other medical urgencies. Originality/value: To the best of the authors’ knowledge, this study is the first of its kind to review different facets of the integrated GLSS-I4.0 approach with a view of the COVID health-care perspective and provides a conceptual framework.",
        "DOI": "10.1108/IJLSS-11-2022-0227",
        "paper_author": "Kaswan M.S.",
        "affiliation_name": "Lovely Professional University",
        "affiliation_city": "Phagwara",
        "affiliation_country": "India",
        "affiliation_id": "60094571",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Transforming Cardiovascular Care With Artificial Intelligence: From Discovery to Practice: JACC State-of-the-Art Review",
        "publication": "Journal of the American College of Cardiology",
        "citied_by": "24",
        "cover_date": "2024-07-02",
        "Abstract": "Artificial intelligence (AI) has the potential to transform every facet of cardiovascular practice and research. The exponential rise in technology powered by AI is defining new frontiers in cardiovascular care, with innovations that span novel diagnostic modalities, new digital native biomarkers of disease, and high-performing tools evaluating care quality and prognosticating clinical outcomes. These digital innovations promise expanded access to cardiovascular screening and monitoring, especially among those without access to high-quality, specialized care historically. Moreover, AI is propelling biological and clinical discoveries that will make future cardiovascular care more personalized, precise, and effective. The review brings together these diverse AI innovations, highlighting developments in multimodal cardiovascular AI across clinical practice and biomedical discovery, and envisioning this new future backed by contemporary science and emerging discoveries. Finally, we define the critical path and the safeguards essential to realizing this AI-enabled future that helps achieve optimal cardiovascular health and outcomes for all.",
        "DOI": "10.1016/j.jacc.2024.05.003",
        "paper_author": "Khera R.",
        "affiliation_name": "Yale School of Medicine",
        "affiliation_city": "New Haven",
        "affiliation_country": "United States",
        "affiliation_id": "60017994",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Deep Machine Learning for Medical Diagnosis, Application to Lung Cancer Detection: A Review",
        "publication": "BioMedInformatics",
        "citied_by": "24",
        "cover_date": "2024-03-01",
        "Abstract": "Deep learning has emerged as a powerful tool for medical image analysis and diagnosis, demonstrating high performance on tasks such as cancer detection. This literature review synthesizes current research on deep learning techniques applied to lung cancer screening and diagnosis. This review summarizes the state-of-the-art in deep learning for lung cancer detection, highlighting key advances, limitations, and future directions. We prioritized studies utilizing major public datasets, such as LIDC, LUNA16, and JSRT, to provide a comprehensive overview of the field. We focus on deep learning architectures, including 2D and 3D convolutional neural networks (CNNs), dual-path networks, Natural Language Processing (NLP) and vision transformers (ViT). Across studies, deep learning models consistently outperformed traditional machine learning techniques in terms of accuracy, sensitivity, and specificity for lung cancer detection in CT scans. This is attributed to the ability of deep learning models to automatically learn discriminative features from medical images and model complex spatial relationships. However, several challenges remain to be addressed before deep learning models can be widely deployed in clinical practice. These include model dependence on training data, generalization across datasets, integration of clinical metadata, and model interpretability. Overall, deep learning demonstrates great potential for lung cancer detection and precision medicine. However, more research is required to rigorously validate models and address risks. This review provides key insights for both computer scientists and clinicians, summarizing progress and future directions for deep learning in medical image analysis.",
        "DOI": "10.3390/biomedinformatics4010015",
        "paper_author": "Gayap H.T.",
        "affiliation_name": "Université de Moncton",
        "affiliation_city": "Moncton",
        "affiliation_country": "Canada",
        "affiliation_id": "60009972",
        "affiliation_state": "NB"
    },
    {
        "paper_title": "Cognitive Motor Dissociation in Disorders of Consciousness",
        "publication": "New England Journal of Medicine",
        "citied_by": "23",
        "cover_date": "2024-08-15",
        "Abstract": "Background Patients with brain injury who are unresponsive to commands may perform cognitive tasks that are detected on functional magnetic resonance imaging (fMRI) and electroencephalography (EEG). This phenomenon, known as cognitive motor dissociation, has not been systematically studied in a large cohort of persons with disorders of consciousness. Methods In this prospective cohort study conducted at six international centers, we collected clinical, behavioral, and task-based fMRI and EEG data from a convenience sample of 353 adults with disorders of consciousness. We assessed the response to commands on task-based fMRI or EEG in participants without an observable response to verbal commands (i.e., those with a behavioral diagnosis of coma, vegetative state, or minimally conscious state-minus) and in participants with an observable response to verbal commands. The presence or absence of an observable response to commands was assessed with the use of the Coma Recovery Scale-Revised (CRS-R). Results Data from fMRI only or EEG only were available for 65% of the participants, and data from both fMRI and EEG were available for 35%. The median age of the participants was 37.9 years, the median time between brain injury and assessment with the CRS-R was 7.9 months (25% of the participants were assessed with the CRS-R within 28 days after injury), and brain trauma was an etiologic factor in 50%. We detected cognitive motor dissociation in 60 of the 241 participants (25%) without an observable response to commands, of whom 11 had been assessed with the use of fMRI only, 13 with the use of EEG only, and 36 with the use of both techniques. Cognitive motor dissociation was associated with younger age, longer time since injury, and brain trauma as an etiologic factor. In contrast, responses on task-based fMRI or EEG occurred in 43 of 112 participants (38%) with an observable response to verbal commands. Conclusions Approximately one in four participants without an observable response to commands performed a cognitive task on fMRI or EEG as compared with one in three participants with an observable response to commands.",
        "DOI": "10.1056/NEJMoa2400645",
        "paper_author": "Bodien Y.G.",
        "affiliation_name": "Spaulding Rehabilitation Hospital Network",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60000568",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "AI and Ethics: A Systematic Review of the Ethical Considerations of Large Language Model Use in Surgery Research",
        "publication": "Healthcare (Switzerland)",
        "citied_by": "23",
        "cover_date": "2024-04-01",
        "Abstract": "Introduction: As large language models receive greater attention in medical research, the investigation of ethical considerations is warranted. This review aims to explore surgery literature to identify ethical concerns surrounding these artificial intelligence models and evaluate how autonomy, beneficence, nonmaleficence, and justice are represented within these ethical discussions to provide insights in order to guide further research and practice. Methods: A systematic review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Five electronic databases were searched in October 2023. Eligible studies included surgery-related articles that focused on large language models and contained adequate ethical discussion. Study details, including specialty and ethical concerns, were collected. Results: The literature search yielded 1179 articles, with 53 meeting the inclusion criteria. Plastic surgery, orthopedic surgery, and neurosurgery were the most represented surgical specialties. Autonomy was the most explicitly cited ethical principle. The most frequently discussed ethical concern was accuracy (n = 45, 84.9%), followed by bias, patient confidentiality, and responsibility. Conclusion: The ethical implications of using large language models in surgery are complex and evolving. The integration of these models into surgery necessitates continuous ethical discourse to ensure responsible and ethical use, balancing technological advancement with human dignity and safety.",
        "DOI": "10.3390/healthcare12080825",
        "paper_author": "Pressman S.M.",
        "affiliation_name": "Mayo Clinic in Jacksonville, Florida",
        "affiliation_city": "Jacksonville",
        "affiliation_country": "United States",
        "affiliation_id": "60002333",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Enhanced image diagnosing approach in medicine using quantum adaptive machine learning techniques",
        "publication": "Optical and Quantum Electronics",
        "citied_by": "23",
        "cover_date": "2024-04-01",
        "Abstract": "This research introduces quantum adaptive machine learning (QAML) as an innovative solution to enhance the processing efficiency of machine learning in medical image classification, focusing on the diagnosis of brain tumors. QAML leverages quantum algorithms to address challenges associated with large and high-dimensional medical images, offering advantages such as accelerated processing rates, reduced model complexity with heightened accuracy, enhanced precision in handling intricate data relationships, and increased resistance to noise—critical in medical image analysis. The study details the implementation of QAML through a hybrid quantum–classical neural network, employing parameterized quantum circuits for image processing. Comparative experiments with traditional machine learning models demonstrate QAML's faster convergence and comparable accuracy. The research also explores the impact of adaptive optimization strategies on QAML performance, indicating promising results. Overall, QAML, with its quantum convolutional and pooling layers, emerges as a promising and efficient solution for medical image classification, marking significant progress in the integration of quantum-enhanced machine learning in healthcare applications.",
        "DOI": "10.1007/s11082-023-06203-8",
        "paper_author": "Suneel S.",
        "affiliation_name": "Institute of Aeronautical Engineering, Hyderabad",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India",
        "affiliation_id": "60106953",
        "affiliation_state": "TS"
    },
    {
        "paper_title": "Extracting structured information from unstructured histopathology reports using generative pre-trained transformer 4 (GPT-4)",
        "publication": "Journal of Pathology",
        "citied_by": "23",
        "cover_date": "2024-03-01",
        "Abstract": "Deep learning applied to whole-slide histopathology images (WSIs) has the potential to enhance precision oncology and alleviate the workload of experts. However, developing these models necessitates large amounts of data with ground truth labels, which can be both time-consuming and expensive to obtain. Pathology reports are typically unstructured or poorly structured texts, and efforts to implement structured reporting templates have been unsuccessful, as these efforts lead to perceived extra workload. In this study, we hypothesised that large language models (LLMs), such as the generative pre-trained transformer 4 (GPT-4), can extract structured data from unstructured plain language reports using a zero-shot approach without requiring any re-training. We tested this hypothesis by utilising GPT-4 to extract information from histopathological reports, focusing on two extensive sets of pathology reports for colorectal cancer and glioblastoma. We found a high concordance between LLM-generated structured data and human-generated structured data. Consequently, LLMs could potentially be employed routinely to extract ground truth data for machine learning from unstructured pathology reports in the future. © 2023 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of The Pathological Society of Great Britain and Ireland.",
        "DOI": "10.1002/path.6232",
        "paper_author": "Truhn D.",
        "affiliation_name": "Uniklinik RWTH Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany",
        "affiliation_id": "60001097",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "The Molecular Twin artificial-intelligence platform integrates multi-omic data to predict outcomes for pancreatic adenocarcinoma patients",
        "publication": "Nature Cancer",
        "citied_by": "22",
        "cover_date": "2024-02-01",
        "Abstract": "Contemporary analyses focused on a limited number of clinical and molecular biomarkers have been unable to accurately predict clinical outcomes in pancreatic ductal adenocarcinoma. Here we describe a precision medicine platform known as the Molecular Twin consisting of advanced machine-learning models and use it to analyze a dataset of 6,363 clinical and multi-omic molecular features from patients with resected pancreatic ductal adenocarcinoma to accurately predict disease survival (DS). We show that a full multi-omic model predicts DS with the highest accuracy and that plasma protein is the top single-omic predictor of DS. A parsimonious model learning only 589 multi-omic features demonstrated similar predictive performance as the full multi-omic model. Our platform enables discovery of parsimonious biomarker panels and performance assessment of outcome prediction models learning from resource-intensive panels. This approach has considerable potential to impact clinical care and democratize precision cancer medicine worldwide.",
        "DOI": "10.1038/s43018-023-00697-7",
        "paper_author": "Osipov A.",
        "affiliation_name": "Cedars-Sinai Medical Center",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60016173",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "An interpretable approach using hybrid graph networks and explainable AI for intelligent diagnosis recommendations in chronic disease care",
        "publication": "Biomedical Signal Processing and Control",
        "citied_by": "22",
        "cover_date": "2024-05-01",
        "Abstract": "With the rapid advancement of modern medical technology and the increasing demand for a higher quality of life there is an emergent requirement for personalized healthcare services. This is particularly pertinent in the sphere of pharmacological recommendations, where the necessity to provide patients with optimal and efficacious medication regimens is paramount. Traditional methodologies in this domain are increasingly seen as insufficient for the needs of contemporary medicine, prompting a shift towards more sophisticated technologies and algorithms. In this study, we addressed this pressing need by developing GCF++ i.e., two graph-based collaborative filtering methods, GCFYA (with attention) and GCFNA (without attention). These methods hold significant promise in revolutionizing how drug recommendations are made, ensuring that patients receive precise and trustworthy medication suggestions tailored to their unique needs and scenarios. To evaluate and compare these algorithms, we introduced three robust metrics: Precision, RMSE (Root Mean Square Error), and Recall. Precision value for GCF-YA is 88 % for hospital dataset, while 85 % for public dataset, similarly, GCF-NA is 77 % for hospital dataset while 78 % for public dataset which is much higher than other traditional methods. Furthermore, as algorithm models become increasingly intricate, transparency and interpretability have gained paramount importance. In response, we incorporated two model interpretation tools, SHAP and LIME, to demystify the decision-making processes behind these algorithms. These tools not only provide clear insights into the basis of recommendation results for both users and developers but also enhance patients' trust and satisfaction with the recommendation system. This study represents a significant step forward in the pursuit of personalized, transparent, and effective healthcare solutions.",
        "DOI": "10.1016/j.bspc.2023.105913",
        "paper_author": "Huang M.",
        "affiliation_name": "Hainan University",
        "affiliation_city": "Haikou",
        "affiliation_country": "China",
        "affiliation_id": "60017716",
        "affiliation_state": "Hainan"
    },
    {
        "paper_title": "Artificial intelligence-assisted digital pathology for non-alcoholic steatohepatitis: current status and future directions",
        "publication": "Journal of Hepatology",
        "citied_by": "22",
        "cover_date": "2024-02-01",
        "Abstract": "The worldwide prevalence of non-alcoholic steatohepatitis (NASH) is increasing, causing a significant medical burden, but no approved therapeutics are currently available. NASH drug development requires histological analysis of liver biopsies by expert pathologists for trial enrolment and efficacy assessment, which can be hindered by multiple issues including sample heterogeneity, inter-reader and intra-reader variability, and ordinal scoring systems. Consequently, there is a high unmet need for accurate, reproducible, quantitative, and automated methods to assist pathologists with histological analysis to improve the precision around treatment and efficacy assessment. Digital pathology (DP) workflows in combination with artificial intelligence (AI) have been established in other areas of medicine and are being actively investigated in NASH to assist pathologists in the evaluation and scoring of NASH histology. DP/AI models can be used to automatically detect, localise, quantify, and score histological parameters and have the potential to reduce the impact of scoring variability in NASH clinical trials. This narrative review provides an overview of DP/AI tools in development for NASH, highlights key regulatory considerations, and discusses how these advances may impact the future of NASH clinical management and drug development. This should be a high priority in the NASH field, particularly to improve the development of safe and effective therapeutics.",
        "DOI": "10.1016/j.jhep.2023.10.015",
        "paper_author": "Ratziu V.",
        "affiliation_name": "Hôpital Universitaire Pitié Salpêtrière",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60015622",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Artificial Intelligence in Andrology: From Semen Analysis to Image Diagnostics",
        "publication": "World Journal of Men's Health",
        "citied_by": "22",
        "cover_date": "2024-01-01",
        "Abstract": "Artificial intelligence (AI) in medicine has gained a lot of momentum in the last decades and has been applied to various fields of medicine. Advances in computer science, medical informatics, robotics, and the need for personalized medicine have facilitated the role of AI in modern healthcare. Similarly, as in other fields, AI applications, such as machine learning, artificial neural networks, and deep learning, have shown great potential in andrology and reproductive medicine. AI-based tools are poised to become valuable assets with abilities to support and aid in diagnosing and treating male infertility, and in improving the accuracy of patient care. These automated, AI-based predictions may offer consistency and efficiency in terms of time and cost in infertility research and clinical management. In andrology and reproductive medicine, AI has been used for objective sperm, oocyte, and embryo selection, prediction of surgical outcomes, cost-effective assessment, development of robotic surgery, and clinical decision-making systems. In the future, better integration and implementation of AI into medicine will undoubtedly lead to pioneering evidence-based breakthroughs and the reshaping of andrology and reproductive medicine.",
        "DOI": "10.5534/wjmh.230050",
        "paper_author": "Ghayda R.A.",
        "affiliation_name": "University Hospitals Case Medical Center",
        "affiliation_city": "Cleveland",
        "affiliation_country": "United States",
        "affiliation_id": "60021578",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Jetting-based bioprinting: process, dispense physics, and applications",
        "publication": "Bio-Design and Manufacturing",
        "citied_by": "21",
        "cover_date": "2024-09-01",
        "Abstract": "Jetting-based bioprinting facilitates contactless drop-on-demand deposition of subnanoliter droplets at well-defined positions to control the spatial arrangement of cells, growth factors, drugs, and biomaterials in a highly automated layer-by-layer fabrication approach. Due to its immense versatility, jetting-based bioprinting has been used for various applications, including tissue engineering and regenerative medicine, wound healing, and drug development. A lack of in-depth understanding exists in the processes that occur during jetting-based bioprinting. This review paper will comprehensively discuss the physical considerations for bioinks and printing conditions used in jetting-based bioprinting. We first present an overview of different jetting-based bioprinting techniques such as inkjet bioprinting, laser-induced forward transfer bioprinting, electrohydrodynamic jet bioprinting, acoustic bioprinting and microvalve bioprinting. Next, we provide an in-depth discussion of various considerations for bioink formulation relating to cell deposition, print chamber design, droplet formation and droplet impact. Finally, we highlight recent accomplishments in jetting-based bioprinting. We present the advantages and challenges of each method, discuss considerations relating to cell viability and protein stability, and conclude by providing insights into future directions of jetting-based bioprinting. Graphic abstract: (Figure presented.)",
        "DOI": "10.1007/s42242-024-00285-3",
        "paper_author": "Ng W.L.",
        "affiliation_name": "Singapore Centre for 3D Printing",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60119025",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "LORIS robustly predicts patient outcomes with immune checkpoint blockade therapy using common clinical, pathologic and genomic features",
        "publication": "Nature Cancer",
        "citied_by": "21",
        "cover_date": "2024-08-01",
        "Abstract": "Despite the revolutionary impact of immune checkpoint blockade (ICB) in cancer treatment, accurately predicting patient responses remains challenging. Here, we analyzed a large dataset of 2,881 ICB-treated and 841 non-ICB-treated patients across 18 solid tumor types, encompassing a wide range of clinical, pathologic and genomic features. We developed a clinical score called LORIS (logistic regression-based immunotherapy-response score) using a six-feature logistic regression model. LORIS outperforms previous signatures in predicting ICB response and identifying responsive patients even with low tumor mutational burden or programmed cell death 1 ligand 1 expression. LORIS consistently predicts patient objective response and short-term and long-term survival across most cancer types. Moreover, LORIS showcases a near-monotonic relationship with ICB response probability and patient survival, enabling precise patient stratification. As an accurate, interpretable method using a few readily measurable features, LORIS may help improve clinical decision-making in precision medicine to maximize patient benefit. LORIS is available as an online tool at https://loris.ccr.cancer.gov/.",
        "DOI": "10.1038/s43018-024-00772-7",
        "paper_author": "Chang T.G.",
        "affiliation_name": "National Cancer Institute (NCI)",
        "affiliation_city": "Rockville",
        "affiliation_country": "United States",
        "affiliation_id": "60013409",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Large language models streamline automated machine learning for clinical studies",
        "publication": "Nature Communications",
        "citied_by": "21",
        "cover_date": "2024-12-01",
        "Abstract": "A knowledge gap persists between machine learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the ChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to ChatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study’s training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Following the re-implementation and optimization of the published models, the head-to-head comparison of the ChatGPT ADA-crafted ML models and their respective manually crafted counterparts revealed no significant differences in traditional performance metrics (p ≥ 0.072). Strikingly, the ChatGPT ADA-crafted ML models often outperformed their counterparts. In conclusion, ChatGPT ADA offers a promising avenue to democratize ML in medicine by simplifying complex data analyses, yet should enhance, not replace, specialized training and resources, to promote broader applications in medical research and practice.",
        "DOI": "10.1038/s41467-024-45879-8",
        "paper_author": "Tayebi Arasteh S.",
        "affiliation_name": "Uniklinik RWTH Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany",
        "affiliation_id": "60001097",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "AI in Orthodontics: Revolutionizing Diagnostics and Treatment Planning—A Comprehensive Review",
        "publication": "Journal of Clinical Medicine",
        "citied_by": "21",
        "cover_date": "2024-01-01",
        "Abstract": "The advent of artificial intelligence (AI) in medicine has transformed various medical specialties, including orthodontics. AI has shown promising results in enhancing the accuracy of diagnoses, treatment planning, and predicting treatment outcomes. Its usage in orthodontic practices worldwide has increased with the availability of various AI applications and tools. This review explores the principles of AI, its applications in orthodontics, and its implementation in clinical practice. A comprehensive literature review was conducted, focusing on AI applications in dental diagnostics, cephalometric evaluation, skeletal age determination, temporomandibular joint (TMJ) evaluation, decision making, and patient telemonitoring. Due to study heterogeneity, no meta-analysis was possible. AI has demonstrated high efficacy in all these areas, but variations in performance and the need for manual supervision suggest caution in clinical settings. The complexity and unpredictability of AI algorithms call for cautious implementation and regular manual validation. Continuous AI learning, proper governance, and addressing privacy and ethical concerns are crucial for successful integration into orthodontic practice.",
        "DOI": "10.3390/jcm13020344",
        "paper_author": "Kazimierczak N.",
        "affiliation_name": "Kazimierczak Private Medical Practice",
        "affiliation_city": "Bydgoszcz",
        "affiliation_country": "Poland",
        "affiliation_id": "130327868",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "MASLD and the Development of HCC: Pathogenesis and Therapeutic Challenges",
        "publication": "Cancers",
        "citied_by": "21",
        "cover_date": "2024-01-01",
        "Abstract": "Metabolic-dysfunction-associated steatotic liver disease (MASLD, previously known as non-alcoholic fatty liver disease (NAFLD)) represents a rapidly increasing cause of chronic liver disease and hepatocellular carcinoma (HCC), mirroring increasing rates of obesity and metabolic syndrome in the Western world. MASLD-HCC can develop at an earlier stage of fibrosis compared to other causes of chronic liver disease, presenting challenges in how to risk-stratify patients to set up effective screening programmes. Therapeutic decision making for MASLD-HCC is also complicated by medical comorbidities and disease presentation at a later stage. The response to treatment, particularly immune checkpoint inhibitors, may vary by the aetiology of the disease, and, in the future, patient stratification will be key to optimizing the therapeutic pathways.",
        "DOI": "10.3390/cancers16020259",
        "paper_author": "Phoolchund A.G.S.",
        "affiliation_name": "University of Southampton, Faculty of Medicine",
        "affiliation_city": "Southampton",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60025287",
        "affiliation_state": "Hampshire"
    },
    {
        "paper_title": "Detection of epileptic seizure in EEG signals using machine learning and deep learning techniques",
        "publication": "Journal of Engineering and Applied Science",
        "citied_by": "21",
        "cover_date": "2024-12-01",
        "Abstract": "Around 50 million individuals worldwide suffer from epilepsy, a chronic, non-communicable brain disorder. Several screening methods, including electroencephalography, have been proposed to identify epileptic episodes. EEG data, which are frequently utilised to enhance epilepsy analysis, offer essential information on the electrical processes of the brain. Prior to the emergence of deep learning (DL), feature extraction was accomplished by standard machine learning techniques. As a result, they were only as good as the people who made the features by hand. But with DL, both feature extraction and classification are fully automated. These methods have significantly advanced several fields of medicine, including the diagnosis of epilepsy. In this paper, the works focused on automated epileptic seizure detection using ML and DL techniques are presented as well as their comparative analysis is done. The UCI-Epileptic Seizure Recognition dataset is used for training and validation. Some of the conventional ML and DL algorithms are used with a proposed model which uses long short-term memory (LSTM) to find the best approach. Post that comparative analysis is performed on these algorithms to find the best approach for epileptic seizure detection. As a result, the proposed model LSTM gives a validation accuracy of 97% giving the most appropriate and precise result as compared to other mentioned algorithms used in this study.",
        "DOI": "10.1186/s44147-023-00353-y",
        "paper_author": "Kunekar P.",
        "affiliation_name": "Swami Keshvanand Institute of Technology Management &amp; Gramothan",
        "affiliation_city": "Jaipur",
        "affiliation_country": "India",
        "affiliation_id": "60114554",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "A review and perspective on hybrid modeling methodologies",
        "publication": "Digital Chemical Engineering",
        "citied_by": "21",
        "cover_date": "2024-03-01",
        "Abstract": "The term hybrid modeling refers to the combination of parametric models (typically derived from knowledge about the system) and nonparametric models (typically deduced from data). Despite more than 20 years of research, over 150 scientific publications (Agharafeie et al., 2023), and some recent industrial applications on this topic, the capabilities of hybrid models often seem underrated, misunderstood, and disregarded by other disciplines as “simply combining some models” or maybe it has gone unnoticed at all. In fact, hybrid modeling could become an enabling technology in various areas of research and industry, such as systems and synthetic biology, personalized medicine, material design, or the process industries. Thus, a systematic investigation of the hybrid model properties is warranted to scoop the full potential of machine learning, reduce experimental effort, and increase the domain in which models can predict reliably.",
        "DOI": "10.1016/j.dche.2023.100136",
        "paper_author": "Schweidtmann A.M.",
        "affiliation_name": "Delft University of Technology",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60006288",
        "affiliation_state": "Zuid-Holland"
    },
    {
        "paper_title": "Strategies of Artificial intelligence tools in the domain of nanomedicine",
        "publication": "Journal of Drug Delivery Science and Technology",
        "citied_by": "21",
        "cover_date": "2024-01-01",
        "Abstract": "Nanomedicine is a field of medicine that uses nanotechnology to develop new diagnostic tools and therapies for a wide range of medical conditions. It encompasses a variety of different approaches, including the use of nanoparticles, nano-robots, and nanodevices. Some examples of how nanotechnology is being used in medicine include drug delivery, diagnostics imaging, tissue engineering, and biomedical devices. One of the main advantages of using nanomedicine-based drug delivery is the ability to deliver drugs at fixed and controlled doses. This is achieved by engineering nanoparticles to release drugs at a specific rate, which can be attuned to match the desires of the patient. Determining the optimal combination of nanotherapy, dosages, and administration schedule can be challenging, as it requires a thorough understanding of the pharmacokinetics and pharmacodynamics of the drugs, as well as the patient's individual physiognomies and the stage of the disease. To overcome this challenge, researchers and practitioners are increasingly using computational models, Artificial intelligence and machine learning algorithms, and personalized medicine approaches to predict the optimal drug combination, dosage, and administration schedule for each patient. In this review, we were given the outline of the different Artificial intelligence tools for the prediction of nanomedicine in the field of various medical applications.",
        "DOI": "10.1016/j.jddst.2023.105157",
        "paper_author": "Habeeb M.",
        "affiliation_name": "B.S.Abdur Rahman University",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60014273",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Unveiling the potential of proteomic and genetic signatures for precision therapeutics in lung cancer management",
        "publication": "Cellular Signalling",
        "citied_by": "21",
        "cover_date": "2024-01-01",
        "Abstract": "Lung cancer's enduring global significance necessitates ongoing advancements in diagnostics and therapeutics. Recent spotlight on proteomic and genetic biomarker research offers a promising avenue for understanding lung cancer biology and guiding treatments. This review elucidates genetic and proteomic lung cancer biomarker progress and their treatment implications. Technological strides in mass spectrometry-based proteomics and next-generation sequencing enable pinpointing of genetic abnormalities and abnormal protein expressions, furnishing vital data for precise diagnosis, patient classification, and customized treatments. Biomarker-driven personalized medicine yields substantial treatment improvements, elevating survival rates and minimizing adverse effects. Integrating omics data (genomics, proteomics, etc.) enhances understanding of lung cancer's intricate biological milieu, identifying novel treatment targets and biomarkers, fostering precision medicine. Liquid biopsies, non-invasive tools for real-time treatment monitoring and early resistance detection, gain popularity, promising enhanced management and personalized therapy. Despite advancements, biomarker repeatability and validation challenges persist, necessitating interdisciplinary efforts and large-scale clinical trials. Integrating artificial intelligence and machine learning aids analyzing vast omics datasets and predicting treatment responses. Single-cell omics reveal cellular connections and intratumoral heterogeneity, valuable for combination treatments. Biomarkers enable accurate diagnosis, tailored medicines, and treatment response tracking, significantly impacting personalized lung cancer care. This approach spurs patient-centered trials, empowering active patient engagement. Lung cancer proteomic and genetic biomarkers illuminate disease biology and treatment prospects. Progressing towards individualized efficient therapies is imminent, alleviating lung cancer's burden through ongoing research, omics integration, and technological strides.",
        "DOI": "10.1016/j.cellsig.2023.110932",
        "paper_author": "Srivastava S.",
        "affiliation_name": "Delhi Pharmaceutical Sciences and Research University (DPSRU)",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "121590755",
        "affiliation_state": "DL"
    },
    {
        "paper_title": "Emerging applications of machine learning in genomic medicine and healthcare",
        "publication": "Critical Reviews in Clinical Laboratory Sciences",
        "citied_by": "21",
        "cover_date": "2024-01-01",
        "Abstract": "The integration of artificial intelligence technologies has propelled the progress of clinical and genomic medicine in recent years. The significant increase in computing power has facilitated the ability of artificial intelligence models to analyze and extract features from extensive medical data and images, thereby contributing to the advancement of intelligent diagnostic tools. Artificial intelligence (AI) models have been utilized in the field of personalized medicine to integrate clinical data and genomic information of patients. This integration allows for the identification of customized treatment recommendations, ultimately leading to enhanced patient outcomes. Notwithstanding the notable advancements, the application of artificial intelligence (AI) in the field of medicine is impeded by various obstacles such as the limited availability of clinical and genomic data, the diversity of datasets, ethical implications, and the inconclusive interpretation of AI models’ results. In this review, a comprehensive evaluation of multiple machine learning algorithms utilized in the fields of clinical and genomic medicine is conducted. Furthermore, we present an overview of the implementation of artificial intelligence (AI) in the fields of clinical medicine, drug discovery, and genomic medicine. Finally, a number of constraints pertaining to the implementation of artificial intelligence within the healthcare industry are examined.",
        "DOI": "10.1080/10408363.2023.2259466",
        "paper_author": "Chafai N.",
        "affiliation_name": "Faculté des Sciences Rabat",
        "affiliation_city": "Rabat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60000784",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Applications of Hyperspectral Imaging Technology Combined with Machine Learning in Quality Control of Traditional Chinese Medicine from the Perspective of Artificial Intelligence: A Review",
        "publication": "Critical Reviews in Analytical Chemistry",
        "citied_by": "21",
        "cover_date": "2024-01-01",
        "Abstract": "Traditional Chinese medicine (TCM) is the treasure of China, and the quality control of TCM is of crucial importance. In recent years, with the quick rise of artificial intelligence (AI) and the rapid development of hyperspectral imaging (HSI) technology, the combination of the two has been widely used in the quality evaluation of TCM. Machine learning (ML) is the core wisdom of AI, and its progress in rapid analysis and higher accuracy improves the potential of applying HSI to the field of TCM. This article reviewed five aspects of ML applied to hyperspectral data analysis of TCM: partition of data set, data preprocessing, data dimension reduction, qualitative or quantitative models, and model performance measurement. The different algorithms proposed by researchers for quality assessment of TCM were also compared. Finally, the challenges in the analysis of hyperspectral images for TCM were summarized, and the future works were prospected.",
        "DOI": "10.1080/10408347.2023.2207652",
        "paper_author": "Pan Y.",
        "affiliation_name": "Zhejiang University of Technology",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60026282",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Artificial intelligence for diabetes care: current and future prospects",
        "publication": "The Lancet Diabetes and Endocrinology",
        "citied_by": "20",
        "cover_date": "2024-08-01",
        "Abstract": "Artificial intelligence (AI) use in diabetes care is increasingly being explored to personalise care for people with diabetes and adapt treatments for complex presentations. However, the rapid advancement of AI also introduces challenges such as potential biases, ethical considerations, and implementation challenges in ensuring that its deployment is equitable. Ensuring inclusive and ethical developments of AI technology can empower both health-care providers and people with diabetes in managing the condition. In this Review, we explore and summarise the current and future prospects of AI across the diabetes care continuum, from enhancing screening and diagnosis to optimising treatment and predicting and managing complications.",
        "DOI": "10.1016/S2213-8587(24)00154-2",
        "paper_author": "Sheng B.",
        "affiliation_name": "Shanghai Sixth People's Hospital",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60122016",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Advances in AI and machine learning for predictive medicine",
        "publication": "Journal of Human Genetics",
        "citied_by": "20",
        "cover_date": "2024-10-01",
        "Abstract": "The field of omics, driven by advances in high-throughput sequencing, faces a data explosion. This abundance of data offers unprecedented opportunities for predictive modeling in precision medicine, but also presents formidable challenges in data analysis and interpretation. Traditional machine learning (ML) techniques have been partly successful in generating predictive models for omics analysis but exhibit limitations in handling potential relationships within the data for more accurate prediction. This review explores a revolutionary shift in predictive modeling through the application of deep learning (DL), specifically convolutional neural networks (CNNs). Using transformation methods such as DeepInsight, omics data with independent variables in tabular (table-like, including vector) form can be turned into image-like representations, enabling CNNs to capture latent features effectively. This approach not only enhances predictive power but also leverages transfer learning, reducing computational time, and improving performance. However, integrating CNNs in predictive omics data analysis is not without challenges, including issues related to model interpretability, data heterogeneity, and data size. Addressing these challenges requires a multidisciplinary approach, involving collaborations between ML experts, bioinformatics researchers, biologists, and medical doctors. This review illuminates these complexities and charts a course for future research to unlock the full predictive potential of CNNs in omics data analysis and related fields.",
        "DOI": "10.1038/s10038-024-01231-y",
        "paper_author": "Sharma A.",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60025272",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Exosomes: a promising avenue for cancer diagnosis beyond treatment",
        "publication": "Frontiers in Cell and Developmental Biology",
        "citied_by": "20",
        "cover_date": "2024-01-01",
        "Abstract": "Exosomes, extracellular vesicles secreted by cells, have garnered significant attention in recent years for their remarkable therapeutic potential. These nanoscale carriers can be harnessed for the targeted delivery of therapeutic agents, such as pharmaceuticals, proteins, and nucleic acids, across biological barriers. This versatile attribute of exosomes is a promising modality for precision medicine applications, notably in the realm of cancer therapy. However, despite their substantial therapeutic potential, exosomes still confront challenges tied to standardization and scalability that impede their practice in clinical applications. Moreover, heterogeneity in isolation methodologies and limited cargo loading mechanisms pose obstacles to ensuring consistent outcomes, thereby constraining their therapeutic utility. In contrast, exosomes exhibit a distinct advantage in cancer diagnosis, as they harbor specific signatures reflective of the tumor’s genetic and proteomic profile. This characteristic endows them with the potential to serve as valuable liquid biopsies for non-invasive and real-time monitoring, making possible early cancer detection for the development of personalized treatment strategies. In this review, we provide an extensive evaluation of the advancements in exosome research, critically examining their advantages and limitations in the context of cancer therapy and early diagnosis. Furthermore, we present a curated overview of the most recent technological innovations utilizing exosomes, with a focus on enhancing the efficacy of early cancer detection.",
        "DOI": "10.3389/fcell.2024.1344705",
        "paper_author": "Wang Z.",
        "affiliation_name": "West China School of Medicine/West China Hospital of Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60073509",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "PubMed and beyond: biomedical literature search in the age of artificial intelligence",
        "publication": "eBioMedicine",
        "citied_by": "20",
        "cover_date": "2024-02-01",
        "Abstract": "Biomedical research yields vast information, much of which is only accessible through the literature. Consequently, literature search is crucial for healthcare and biomedicine. Recent improvements in artificial intelligence (AI) have expanded functionality beyond keywords, but they might be unfamiliar to clinicians and researchers. In response, we present an overview of over 30 literature search tools tailored to common biomedical use cases, aiming at helping readers efficiently fulfill their information needs. We first discuss recent improvements and continued challenges of the widely used PubMed. Then, we describe AI-based literature search tools catering to five specific information needs: 1. Evidence-based medicine. 2. Precision medicine and genomics. 3. Searching by meaning, including questions. 4. Finding related articles with literature recommendation. 5. Discovering hidden associations through literature mining. Finally, we discuss the impacts of recent developments of large language models such as ChatGPT on biomedical information seeking.",
        "DOI": "10.1016/j.ebiom.2024.104988",
        "paper_author": "Jin Q.",
        "affiliation_name": "National Center for Biotechnology Information (NCBI)",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States",
        "affiliation_id": "60087823",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Global and local interpretability techniques of supervised machine learning black box models for numerical medical data",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "20",
        "cover_date": "2024-05-01",
        "Abstract": "The most effective machine learning classification techniques, such as artificial neural networks, are not easily interpretable, which limits their usefulness in critical areas, such as medicine, where errors can have severe consequences. Researchers have been working to balance the trade-off between the model performance and interpretability. In this study, seven interpretability techniques (global surrogate, accumulated local effects, local interpretable model-agnostic explanations (LIME), Shapley additive explanations (SHAP), model agnostic post hoc local explanations (MAPLE), local rule-based explanation (LORE), and Contextual Importance and Utility (CIU)) were evaluated to interpret five medical classifiers (multilayer perceptron, support vector machines, random forests, extreme gradient boosting, and naïve bayes) using six model performance metrics and three interpretability technique metrics across six medical numerical datasets. The results confirmed the effectiveness of integrating global and local interpretability techniques, and highlighted the superior performance of global SHAP explainer and local CIU explanations. The quantitative evaluations of explanations emphasised the importance of assessing these interpretability techniques before employing them to interpret black box models.",
        "DOI": "10.1016/j.engappai.2023.107829",
        "paper_author": "Hakkoum H.",
        "affiliation_name": "Ecole Nationale Supérieure d'Informatique et d'Analyse des Systèmes",
        "affiliation_city": "Rabat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60106035",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Blockchain meets machine learning: a survey",
        "publication": "Journal of Big Data",
        "citied_by": "20",
        "cover_date": "2024-12-01",
        "Abstract": "Blockchain and machine learning are two rapidly growing technologies that are increasingly being used in various industries. Blockchain technology provides a secure and transparent method for recording transactions, while machine learning enables data-driven decision-making by analyzing large amounts of data. In recent years, researchers and practitioners have been exploring the potential benefits of combining these two technologies. In this study, we cover the fundamentals of blockchain and machine learning and then discuss their integrated use in finance, medicine, supply chain, and security, including a literature review and their contribution to the field such as increased security, privacy, and decentralization. Blockchain technology enables secure and transparent decentralized record-keeping, while machine learning algorithms can analyze vast amounts of data to derive valuable insights. Together, they have the potential to revolutionize industries by enhancing efficiency through automated and trustworthy processes, enabling data-driven decision-making, and strengthening security measures by reducing vulnerabilities and ensuring the integrity of information. However, there are still some important challenges to be handled prior to the common use of blockchain and machine learning such as security issues, strategic planning, information processing, and scalable workflows. Nevertheless, until the difficulties that have been identified are resolved, their full potential will not be achieved.",
        "DOI": "10.1186/s40537-023-00852-y",
        "paper_author": "Kayikci S.",
        "affiliation_name": "FAU College of Engineering and Computer Science",
        "affiliation_city": "Boca Raton",
        "affiliation_country": "United States",
        "affiliation_id": "60144960",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Recent Developments in Layer-by-Layer Assembly for Drug Delivery and Tissue Engineering Applications",
        "publication": "Advanced Healthcare Materials",
        "citied_by": "20",
        "cover_date": "2024-03-25",
        "Abstract": "Surfaces with biological functionalities are of great interest for biomaterials, tissue engineering, biophysics, and for controlling biological processes. The layer-by-layer (LbL) assembly is a highly versatile methodology introduced 30 years ago, which consists of assembling complementary polyelectrolytes or biomolecules in a stepwise manner to form thin self-assembled films. In view of its simplicity, compatibility with biological molecules, and adaptability to any kind of supporting material carrier, this technology has undergone major developments over the past decades. Specific applications have emerged in different biomedical fields owing to the possibility to load or immobilize biomolecules with preserved bioactivity, to use an extremely broad range of biomolecules and supporting carriers, and to modify the film's mechanical properties via crosslinking. In this review, the focus is on the recent developments regarding LbL films formed as 2D or 3D objects for applications in drug delivery and tissue engineering. Possible applications in the fields of vaccinology, 3D biomimetic tissue models, as well as bone and cardiovascular tissue engineering are highlighted. In addition, the most recent technological developments in the field of film construction, such as high-content liquid handling or machine learning, which are expected to open new perspectives in the future developments of LbL, are presented.",
        "DOI": "10.1002/adhm.202302713",
        "paper_author": "Borges J.",
        "affiliation_name": "CICECO – Instituto de Materiais de Aveiro",
        "affiliation_city": "Aveiro",
        "affiliation_country": "Portugal",
        "affiliation_id": "60013980",
        "affiliation_state": "Aveiro"
    },
    {
        "paper_title": "Use of artificial intelligence in critical care: opportunities and obstacles",
        "publication": "Critical Care",
        "citied_by": "19",
        "cover_date": "2024-12-01",
        "Abstract": "Background: Perhaps nowhere else in the healthcare system than in the intensive care unit environment are the challenges to create useful models with direct time-critical clinical applications more relevant and the obstacles to achieving those goals more massive. Machine learning-based artificial intelligence (AI) techniques to define states and predict future events are commonplace activities of modern life. However, their penetration into acute care medicine has been slow, stuttering and uneven. Major obstacles to widespread effective application of AI approaches to the real-time care of the critically ill patient exist and need to be addressed. Main body: Clinical decision support systems (CDSSs) in acute and critical care environments support clinicians, not replace them at the bedside. As will be discussed in this review, the reasons are many and include the immaturity of AI-based systems to have situational awareness, the fundamental bias in many large databases that do not reflect the target population of patient being treated making fairness an important issue to address and technical barriers to the timely access to valid data and its display in a fashion useful for clinical workflow. The inherent “black-box” nature of many predictive algorithms and CDSS makes trustworthiness and acceptance by the medical community difficult. Logistically, collating and curating in real-time multidimensional data streams of various sources needed to inform the algorithms and ultimately display relevant clinical decisions support format that adapt to individual patient responses and signatures represent the efferent limb of these systems and is often ignored during initial validation efforts. Similarly, legal and commercial barriers to the access to many existing clinical databases limit studies to address fairness and generalizability of predictive models and management tools. Conclusions: AI-based CDSS are evolving and are here to stay. It is our obligation to be good shepherds of their use and further development.",
        "DOI": "10.1186/s13054-024-04860-z",
        "paper_author": "Pinsky M.R.",
        "affiliation_name": "University of Pittsburgh School of Medicine",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States",
        "affiliation_id": "60001361",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Medical robotics and AI-assisted diagnostics for a high-tech healthcare industry",
        "publication": "Medical Robotics and AI-Assisted Diagnostics for a High-Tech Healthcare Industry",
        "citied_by": "19",
        "cover_date": "2024-03-04",
        "Abstract": "While ultra-high field strength diagnosis technologies and artificial intelligence have propelled medicine imaging towards microstructure analysis and precise medicine, persistent challenges remain. These range from long scanning times to motion sensitivity and issues with imaging quality for certain types of tissue. Medical Robotics and AI-Assisted Diagnostics for a High-Tech Healthcare Industry summarizes emerging techniques, outlines clinical applications, and confronts the challenges head-on, proposing avenues for further research. It explores emerging techniques such as human-like robotics, medical Internet of Things (IoT), low-cost CT scanners, portable MRI devices, and breakthroughs in diagnosis technologies like zero echo time (ZTM) and compressed sensing volume interpolation breath-holding test sequences (CS-VIBE). This book provides an overview of the current state of medical imaging and clinical diagnosis applications, then expands into a roadmap for the future, envisioning the seamless integration of medical robotics and AI-assisted applications in the high-tech healthcare industry. As the influence of artificial intelligence continues to grow, the book serves as a clarion call for collaborative efforts, increased research, and unified strategies to navigate the challenges and harness the opportunities presented by the high-tech medical industry. This book is ideal for medical analysts, healthcare scientists, biotechnology analysts, scholars, researchers, academics, professionals, engineers, and students worldwide. It consolidates contributions from a broad spectrum of experts to share ideas, methodologies, technologies, and approaches that can collectively address the challenges associated with the convergence of machine learning, deep learning, computer vision, AI-integrated applications, IoT-based technologies, human-like robotics, healthcare data analytics, and the application of biotechnology in the era of an AI-centric industry.",
        "DOI": "10.4018/979-8-3693-2105-8",
        "paper_author": "Khang A.",
        "affiliation_name": "Global Research Institute of Technology and Engineering",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States",
        "affiliation_id": "60281158",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "Implementing Whole Genome Sequencing (WGS) in Clinical Practice: Advantages, Challenges, and Future Perspectives",
        "publication": "Cells",
        "citied_by": "19",
        "cover_date": "2024-03-01",
        "Abstract": "The integration of whole genome sequencing (WGS) into all aspects of modern medicine represents the next step in the evolution of healthcare. Using this technology, scientists and physicians can observe the entire human genome comprehensively, generating a plethora of new sequencing data. Modern computational analysis entails advanced algorithms for variant detection, as well as complex models for classification. Data science and machine learning play a crucial role in the processing and interpretation of results, using enormous databases and statistics to discover new and support current genotype–phenotype correlations. In clinical practice, this technology has greatly enabled the development of personalized medicine, approaching each patient individually and in accordance with their genetic and biochemical profile. The most propulsive areas include rare disease genomics, oncogenomics, pharmacogenomics, neonatal screening, and infectious disease genomics. Another crucial application of WGS lies in the field of multi-omics, working towards the complete integration of human biomolecular data. Further technological development of sequencing technologies has led to the birth of third and fourth-generation sequencing, which include long-read sequencing, single-cell genomics, and nanopore sequencing. These technologies, alongside their continued implementation into medical research and practice, show great promise for the future of the field of medicine.",
        "DOI": "10.3390/cells13060504",
        "paper_author": "Brlek P.",
        "affiliation_name": "St. Catherine Specialty Hospital",
        "affiliation_city": "Zagreb",
        "affiliation_country": "Croatia",
        "affiliation_id": "115365849",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Current trends, limitations and future research in the fungi?",
        "publication": "Fungal Diversity",
        "citied_by": "19",
        "cover_date": "2024-03-01",
        "Abstract": "The field of mycology has grown from an underappreciated subset of botany, to a valuable, modern scientific discipline. As this field of study has grown, there have been significant contributions to science, technology, and industry, highlighting the value of fungi in the modern era. This paper looks at the current research, along with the existing limitations, and suggests future areas where scientists can focus their efforts, in the field mycology. We show how fungi have become important emerging diseases in medical mycology. We discuss current trends and the potential of fungi in drug and novel compound discovery. We explore the current trends in phylogenomics, its potential, and outcomes and address the question of how phylogenomics can be applied in fungal ecology. In addition, the trends in functional genomics studies of fungi are discussed with their importance in unravelling the intricate mechanisms underlying fungal behaviour, interactions, and adaptations, paving the way for a comprehensive understanding of fungal biology. We look at the current research in building materials, how they can be used as carbon sinks, and how fungi can be used in biocircular economies. The numbers of fungi have always been of great interest and have often been written about and estimates have varied greatly. Thus, we discuss current trends and future research needs in order to obtain more reliable estimates. We address the aspects of machine learning (AI) and how it can be used in mycological research. Plant pathogens are affecting food production systems on a global scale, and as such, we look at the current trends and future research needed in this area, particularly in disease detection. We look at the latest data from High Throughput Sequencing studies and question if we are still gaining new knowledge at the same rate as before. A review of current trends in nanotechnology is provided and its future potential is addressed. The importance of Arbuscular Mycorrhizal Fungi is addressed and future trends are acknowledged. Fungal databases are becoming more and more important, and we therefore provide a review of the current major databases. Edible and medicinal fungi have a huge potential as food and medicines, especially in Asia and their prospects are discussed. Lifestyle changes in fungi (e.g., from endophytes, to pathogens, and/or saprobes) are also extremely important and a current research trend and are therefore addressed in this special issue of Fungal Diversity.",
        "DOI": "10.1007/s13225-023-00532-5",
        "paper_author": "Hyde K.D.",
        "affiliation_name": "Kunming Institute of Botany",
        "affiliation_city": "Kunming",
        "affiliation_country": "China",
        "affiliation_id": "60018910",
        "affiliation_state": "Yunnan"
    },
    {
        "paper_title": "The paradigm change from reactive medical services to 3PM in ischemic stroke: a holistic approach utilising tear fluid multi-omics, mitochondria as a vital biosensor and AI-based multi-professional data interpretation",
        "publication": "EPMA Journal",
        "citied_by": "19",
        "cover_date": "2024-03-01",
        "Abstract": "Worldwide stroke is the second leading cause of death and the third leading cause of death and disability combined. The estimated global economic burden by stroke is over US$891 billion per year. Within three decades (1990–2019), the incidence increased by 70%, deaths by 43%, prevalence by 102%, and DALYs by 143%. Of over 100 million people affected by stroke, about 76% are ischemic stroke (IS) patients recorded worldwide. Contextually, ischemic stroke moves into particular focus of multi-professional groups including researchers, healthcare industry, economists, and policy-makers. Risk factors of ischemic stroke demonstrate sufficient space for cost-effective prevention interventions in primary (suboptimal health) and secondary (clinically manifested collateral disorders contributing to stroke risks) care. These risks are interrelated. For example, sedentary lifestyle and toxic environment both cause mitochondrial stress, systemic low-grade inflammation and accelerated ageing; inflammageing is a low-grade inflammation associated with accelerated ageing and poor stroke outcomes. Stress overload, decreased mitochondrial bioenergetics and hypomagnesaemia are associated with systemic vasospasm and ischemic lesions in heart and brain of all age groups including teenagers. Imbalanced dietary patterns poor in folate but rich in red and processed meat, refined grains, and sugary beverages are associated with hyperhomocysteinaemia, systemic inflammation, small vessel disease, and increased IS risks. Ongoing 3PM research towards vulnerable groups in the population promoted by the European Association for Predictive, Preventive and Personalised Medicine (EPMA) demonstrates promising results for the holistic patient-friendly non-invasive approach utilising tear fluid-based health risk assessment, mitochondria as a vital biosensor and AI-based multi-professional data interpretation as reported here by the EPMA expert group. Collected data demonstrate that IS-relevant risks and corresponding molecular pathways are interrelated. For examples, there is an evident overlap between molecular patterns involved in IS and diabetic retinopathy as an early indicator of IS risk in diabetic patients. Just to exemplify some of them such as the 5-aminolevulinic acid/pathway, which are also characteristic for an altered mitophagy patterns, insomnia, stress regulation and modulation of microbiota-gut-brain crosstalk. Further, ceramides are considered mediators of oxidative stress and inflammation in cardiometabolic disease, negatively affecting mitochondrial respiratory chain function and fission/fusion activity, altered sleep–wake behaviour, vascular stiffness and remodelling. Xanthine/pathway regulation is involved in mitochondrial homeostasis and stress-driven anxiety-like behaviour as well as molecular mechanisms of arterial stiffness. In order to assess individual health risks, an application of machine learning (AI tool) is essential for an accurate data interpretation performed by the multiparametric analysis. Aspects presented in the paper include the needs of young populations and elderly, personalised risk assessment in primary and secondary care, cost-efficacy, application of innovative technologies and screening programmes, advanced education measures for professionals and general population—all are essential pillars for the paradigm change from reactive medical services to 3PM in the overall IS management promoted by the EPMA.",
        "DOI": "10.1007/s13167-024-00356-6",
        "paper_author": "Golubnitschaja O.",
        "affiliation_name": "Universitätsklinikum Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany",
        "affiliation_id": "60030465",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Machine Learning in Modeling Disease Trajectory and Treatment Outcomes: An Emerging Enabler for Model-Informed Precision Medicine",
        "publication": "Clinical Pharmacology and Therapeutics",
        "citied_by": "19",
        "cover_date": "2024-04-01",
        "Abstract": "The increasing breadth and depth of resolution in biological and clinical data, including -omics and real-world data, requires advanced analytical techniques like artificial intelligence (AI) and machine learning (ML) to fully appreciate the impact of multi-dimensional population variability in intrinsic and extrinsic factors on disease progression and treatment outcomes. Integration of advanced data analytics in Quantitative Pharmacology is crucial for drug-disease knowledge management, enabling precise, efficient and inclusive drug development and utilization – an application we refer to as model-informed precision medicine. AI/ML enables characterization of the molecular and clinical sources of heterogeneity in disease trajectory, advancing end point qualification and biomarker discovery, and informing patient enrichment for proof-of-concept studies as well as trial designs for efficient evidence generation incorporating digital twins and virtual control arms. Explainable ML methods are valuable in elucidating predictors of efficacy and safety of pharmacological treatments, thereby informing response monitoring and risk mitigation strategies. In oncology, emerging opportunities exist for development of the next generation of disease models via ML-assisted joint longitudinal modeling of high-dimensional biomarker data such as circulating tumor DNA and radiomics profiles as predictors of survival outcomes. Finally, mining real-world data leveraging ML algorithms enables understanding of the impact of exclusion criteria on clinical outcomes, thereby informing rational design of appropriately inclusive clinical trials through data-driven broadening of eligibility criteria. Herein, we provide an overview of the aforementioned contexts of use of ML in drug-disease modeling based on examples across multiple therapeutic areas including neurology, rare diseases, autoimmune diseases, oncology and immuno-oncology.",
        "DOI": "10.1002/cpt.3153",
        "paper_author": "Terranova N.",
        "affiliation_name": "Merck KGaA",
        "affiliation_city": "Darmstadt",
        "affiliation_country": "Germany",
        "affiliation_id": "60018366",
        "affiliation_state": "Hessen"
    },
    {
        "paper_title": "A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing",
        "publication": "Current Problems in Cardiology",
        "citied_by": "19",
        "cover_date": "2024-03-01",
        "Abstract": "Background: Generative Artificial Intelligence (AI) tools have experienced rapid development over the last decade and are gaining increasing popularity as assistive models in academic writing. However, the ability of AI to generate reliable and accurate research articles is a topic of debate. Major scientific journals have issued policies regarding the contribution of AI tools in scientific writing. Methods: We conducted a review of the author and peer reviewer guidelines of the top 25 Cardiology and Cardiovascular Medicine journals as per the 2023 SCImago rankings. Data were obtained though reviewing journal websites and directly emailing the editorial office. Descriptive data regarding journal characteristics were coded on SPSS. Subgroup analyses of the journal guidelines were conducted based on the publishing company policies. Results: Our analysis revealed that all scientific journals in our study permitted the documented use of AI in scientific writing with certain limitations as per ICMJE recommendations. We found that AI tools cannot be included in the authorship or be used for image generation, and that all authors are required to assume full responsibility of their submitted and published work. The use of generative AI tools in the peer review process is strictly prohibited. Conclusion: Guidelines regarding the use of generative AI in scientific writing are standardized, detailed, and unanimously followed by all journals in our study according to the recommendations set forth by international forums. It is imperative to ensure that these policies are carefully followed and updated to maintain scientific integrity.",
        "DOI": "10.1016/j.cpcardiol.2024.102387",
        "paper_author": "Inam M.",
        "affiliation_name": "The Aga Khan University",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60052016",
        "affiliation_state": "Sindh"
    },
    {
        "paper_title": "Machine learning-driven multi-level composite SERS platform for trace detection of chlorogenic acid as pharmacodynamic substance in honeysuckle",
        "publication": "Optics and Laser Technology",
        "citied_by": "19",
        "cover_date": "2024-02-01",
        "Abstract": "We reported a multi-level composite SERS platform which could provide a new method for accurate and quantitative trace detection for pharmacodynamic substance in traditional Chinese medicine (TCM). Using natural dragonfly wings as the template, Ag NPs were deposited on V-Ti nano-columns through controllable magnetron sputtering technology. Ag30@V-Ti20@D.W possessed a uniform nanostructure and exhibited High-performance SERS signal sensing capability. The detection limit (LOD) of R6G was 1 × 10−10 M. Through machine learning, we accurately classified and recognized R6G at different concentrations. The multi-level composite structure provided a wide range of “hot spots” areas and ensured good reproducibility with a relative standard deviation (RSD) value of 7.13%. When quantitatively detected chlorogenic acid, an active ingredient in honeysuckle, LOD value of 1 × 10−6 g/l was obtained. In the future, the combination of SERS spectroscopy technology and machine learning will provide theoretical and experimental support for the development of new strategies for detecting Other pharmacodynamic substances in TCM.",
        "DOI": "10.1016/j.optlastec.2023.109911",
        "paper_author": "Yuan W.",
        "affiliation_name": "Chengde Medical University",
        "affiliation_city": "Chengde",
        "affiliation_country": "China",
        "affiliation_id": "60001700",
        "affiliation_state": "Hebei"
    },
    {
        "paper_title": "Secured Fog-Body-Torrent: A Hybrid Symmetric Cryptography with Multi-layer Feed Forward Networks Tuned Chaotic Maps for Physiological Data Transmission in Fog-BAN Environment",
        "publication": "International Journal of Computational and Experimental Science and Engineering",
        "citied_by": "18",
        "cover_date": "2024-10-02",
        "Abstract": "Recently, the Wireless Body Area Networks (WBAN) have become a promising and practical option in the tele-care medicine information system that aids for the better clinical monitoring and diagnosis. The trend of using Internet of Things (IoT) has propelled the WBAN technology to new dimension in terms of its network characteristics and efficient data transmission. However, these networks demand the strong authentication protocol to enhance the confidentiality, integrity, recoverability and dependability against the emerging cyber-physical attacks owing to the exposure of the IoT ecosystem and the confidentiality of biometric data. Hence this study proposes the Fog based WBAN infrastructure which incorporates the hybrid symmetric cryptography schemes with the chaotic maps and feed forward networks to achieve the physiological data info security without consuming the characteristics of power hungry WBAN devices. In the proposed model, scroll chaotic maps are iterated to produce the high dynamic keys streams for the real time applications and feed-forward layers are leveraged to align the complex input-output associations of cipher data for subsequent mathematical tasks. The feed forward layers are constructed which relies on the principle of Adaptive Extreme Learning Machines (AELM) thereby increasing randomness in the cipher keys thereby increasing its defensive nature against the different cyber-physical attacks and ensuring the high secured encrypted-decrypted data communication between the users and fog nodes. The real time analysis is conducted during live scenarios. BAN-IoT test beds interfaced with the heterogeneous healthcare sensors and various security metrics are analysed and compared with the various residing cryptographic algorithms. Results demonstrates that the recommended methodology has exhibited the high randomness characteristics and low computational overhead compared with the other traditional BAN oriented cryptography protocol schemes.",
        "DOI": "10.22399/ijcesen.490",
        "paper_author": "Parvathy S.",
        "affiliation_name": "Vels Institute of Science, Technology &amp; Advanced Studies",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60105237",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Navigating Challenges and Opportunities in Multi-Omics Integration for Personalized Healthcare",
        "publication": "Biomedicines",
        "citied_by": "18",
        "cover_date": "2024-07-01",
        "Abstract": "The field of multi-omics has witnessed unprecedented growth, converging multiple scientific disciplines and technological advances. This surge is evidenced by a more than doubling in multi-omics scientific publications within just two years (2022–2023) since its first referenced mention in 2002, as indexed by the National Library of Medicine. This emerging field has demonstrated its capability to provide comprehensive insights into complex biological systems, representing a transformative force in health diagnostics and therapeutic strategies. However, several challenges are evident when merging varied omics data sets and methodologies, interpreting vast data dimensions, streamlining longitudinal sampling and analysis, and addressing the ethical implications of managing sensitive health information. This review evaluates these challenges while spotlighting pivotal milestones: the development of targeted sampling methods, the use of artificial intelligence in formulating health indices, the integration of sophisticated n-of-1 statistical models such as digital twins, and the incorporation of blockchain technology for heightened data security. For multi-omics to truly revolutionize healthcare, it demands rigorous validation, tangible real-world applications, and smooth integration into existing healthcare infrastructures. It is imperative to address ethical dilemmas, paving the way for the realization of a future steered by omics-informed personalized medicine.",
        "DOI": "10.3390/biomedicines12071496",
        "paper_author": "Mohr A.E.",
        "affiliation_name": "Theriome Inc.",
        "affiliation_city": "Phoenix",
        "affiliation_country": "United States",
        "affiliation_id": "131318227",
        "affiliation_state": "AZ"
    },
    {
        "paper_title": "Machine learning in preclinical drug discovery",
        "publication": "Nature Chemical Biology",
        "citied_by": "18",
        "cover_date": "2024-08-01",
        "Abstract": "Drug-discovery and drug-development endeavors are laborious, costly and time consuming. These programs can take upward of 12 years and cost US $2.5 billion, with a failure rate of more than 90%. Machine learning (ML) presents an opportunity to improve the drug-discovery process. Indeed, with the growing abundance of public and private large-scale biological and chemical datasets, ML techniques are becoming well positioned as useful tools that can augment the traditional drug-development process. In this Perspective, we discuss the integration of algorithmic methods throughout the preclinical phases of drug discovery. Specifically, we highlight an array of ML-based efforts, across diverse disease areas, to accelerate initial hit discovery, mechanism-of-action (MOA) elucidation and chemical property optimization. With advances in the application of ML across diverse therapeutic areas, we posit that fully ML-integrated drug-discovery pipelines will define the future of drug-development programs. (Figure presented.)",
        "DOI": "10.1038/s41589-024-01679-1",
        "paper_author": "Catacutan D.B.",
        "affiliation_name": "McMaster University, Faculty of Health Sciences",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada",
        "affiliation_id": "60026748",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Revolutionizing drug discovery: The impact of artificial intelligence on advancements in pharmacology and the pharmaceutical industry",
        "publication": "Intelligent Pharmacy",
        "citied_by": "18",
        "cover_date": "2024-06-01",
        "Abstract": "To create novel treatments and treat complex diseases, the pharmaceutical sector is essential. Drug discovery, however, is a time-consuming, pricey, and dangerous endeavor. Artificial intelligence (AI) has become a potent instrument that has transformed several industries, including healthcare, in recent years. This summary gives a general overview of how AI is expediting the creation of novel medicines, revolutionizing the pharmaceutical sector, and enabling drug discovery. The pharmaceutical sector is experiencing a drug discovery revolution because of AI. The drug discovery process is changing at different phases because of AI approaches like machine learning and deep learning. This abstract demonstrates how AI facilitates drug development through target identification, lead compound optimization, drug design, drug repurposing, and clinical trial enhancement. AI integration has the potential to hasten the creation of novel treatments, save costs, and improve patient outcomes. To fully realize the potential of AI in pharmaceutical research and development, issues relating to data accessibility, algorithm interpretability, and laws must be resolved.",
        "DOI": "10.1016/j.ipha.2024.02.009",
        "paper_author": "Yadav S.",
        "affiliation_name": "Amity University",
        "affiliation_city": "Noida",
        "affiliation_country": "India",
        "affiliation_id": "60076774",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "MicroRNAs: circulating biomarkers for the early detection of imperceptible cancers via biosensor and machine-learning advances",
        "publication": "Oncogene",
        "citied_by": "18",
        "cover_date": "2024-07-05",
        "Abstract": "This review explores the topic of microRNAs (miRNAs) for improved early detection of imperceptible cancers, with potential to advance precision medicine and improve patient outcomes. Historical research exploring miRNA’s role in cancer detection collectively revealed initial hurdles in identifying specific miRNA signatures for early-stage and difficult-to-detect cancers. Early studies faced challenges in establishing robust biomarker panels and overcoming the heterogeneity of cancer types. Despite this, recent developments have supported the potential of miRNAs as sensitive and specific biomarkers for early cancer detection as well as having demonstrated remarkable potential as diagnostic tools for imperceptible cancers, such as those with elusive symptoms or challenging diagnostic criteria. This review discusses the advent of high-throughput technologies that have enabled comprehensive detection and profiling of unique miRNA signatures associated with early-stage cancers. Furthermore, advancements in bioinformatics and machine-learning techniques are considered, exploring the integration of multi-omics data which have potential to enhance both the accuracy and reliability of miRNA-based cancer detection assays. Finally, perspectives on the continuing development on technologies as well as discussion around challenges that remain, such as the need for standardised protocols and addressing the complex interplay of miRNAs in cancer biology are conferred.",
        "DOI": "10.1038/s41388-024-03076-3",
        "paper_author": "Metcalf G.A.D.",
        "affiliation_name": "Anglia Ruskin University",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60000913",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Should the Use of Adaptive Machine Learning Systems in Medicine be Classified as Research?",
        "publication": "American Journal of Bioethics",
        "citied_by": "18",
        "cover_date": "2024-01-01",
        "Abstract": "A novel advantage of the use of machine learning (ML) systems in medicine is their potential to continue learning from new data after implementation in clinical practice. To date, considerations of the ethical questions raised by the design and use of adaptive machine learning systems in medicine have, for the most part, been confined to discussion of the so-called “update problem,” which concerns how regulators should approach systems whose performance and parameters continue to change even after they have received regulatory approval. In this paper, we draw attention to a prior ethical question: whether the continuous learning that will occur in such systems after their initial deployment should be classified, and regulated, as medical research? We argue that there is a strong prima facie case that the use of continuous learning in medical ML systems should be categorized, and regulated, as research and that individuals whose treatment involves such systems should be treated as research subjects.",
        "DOI": "10.1080/15265161.2024.2337429",
        "paper_author": "Sparrow R.",
        "affiliation_name": "Monash University",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60019578",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "A Comprehensive Review of Vision-Based 3D Reconstruction Methods",
        "publication": "Sensors",
        "citied_by": "18",
        "cover_date": "2024-04-01",
        "Abstract": "With the rapid development of 3D reconstruction, especially the emergence of algorithms such as NeRF and 3DGS, 3D reconstruction has become a popular research topic in recent years. 3D reconstruction technology provides crucial support for training extensive computer vision models and advancing the development of general artificial intelligence. With the development of deep learning and GPU technology, the demand for high-precision and high-efficiency 3D reconstruction information is increasing, especially in the fields of unmanned systems, human-computer interaction, virtual reality, and medicine. The rapid development of 3D reconstruction is becoming inevitable. This survey categorizes the various methods and technologies used in 3D reconstruction. It explores and classifies them based on three aspects: traditional static, dynamic, and machine learning. Furthermore, it compares and discusses these methods. At the end of the survey, which includes a detailed analysis of the trends and challenges in 3D reconstruction development, we aim to provide a comprehensive introduction for individuals who are currently engaged in or planning to conduct research on 3D reconstruction. Our goal is to help them gain a comprehensive understanding of the relevant knowledge related to 3D reconstruction.",
        "DOI": "10.3390/s24072314",
        "paper_author": "Zhou L.",
        "affiliation_name": "Beijing Information Science &amp; Technology University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60088567",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Personalized Drug Therapy: Innovative Concept Guided With Proteoformics",
        "publication": "Molecular and Cellular Proteomics",
        "citied_by": "18",
        "cover_date": "2024-03-01",
        "Abstract": "Personalized medicine can reduce adverse effects, enhance drug efficacy, and optimize treatment outcomes, which represents the essence of personalized medicine in the pharmacy field. Protein drugs are crucial in the field of personalized drug therapy and are currently the mainstay, which possess higher target specificity and biological activity than small-molecule chemical drugs,making themefficient in regulating disease-related biological processes, and have significant potential in the development of personalized drugs. Currently, protein drugs are designed and developed for specific protein targets based on patient-specific protein data. However, due to the rapid development of twodimensional gel electrophoresis and mass spectrometry, it is now widely recognized that a canonical protein actually includes multiple proteoforms, and the differences between these proteoforms will result in varying responses to drugs. The variation in the effects of different proteoforms can be significant and the impact can even alter the intended benefit of adrug,potentiallymakingit harmful insteadof lifesaving.As a result,wepropose thatprotein drugs should shift from being targeted through the lens of protein (proteomics) to being targeted through the lens of proteoform (proteoformics). This will enable the development of personalized protein drugs that are better equipped tomeet patients' specific needs and disease characteristics.With further development in the field of proteoformics, individualized drug therapy, especially personalized protein drugs aimed at proteoforms as a drug target, will improve the understanding of disease mechanisms, discovery of new drug targets and signaling pathways, provide a theoretical basis for the development of new drugs, aid doctors in conducting health risk assessments and making more cost-effective targeted prevention strategies conducted by artificial intelligence/machine learning, promote technological innovation, and provide more convenient treatment tailored to individualized patient profile, which will benefit the affected individuals and society at large.",
        "DOI": "10.1016/j.mcpro.2024.100737",
        "paper_author": "Su J.",
        "affiliation_name": "Shandong Cancer Hospital",
        "affiliation_city": "Jinan",
        "affiliation_country": "China",
        "affiliation_id": "60073570",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Towards revolutionizing precision healthcare: A systematic literature review of artificial intelligence methods in precision medicine",
        "publication": "Informatics in Medicine Unlocked",
        "citied_by": "18",
        "cover_date": "2024-01-01",
        "Abstract": "In the realm of medicine, artificial intelligence (AI) has emerged as a transformative force, harnessing the power to convert raw data into meaningful insights. Rather than supplanting the discernment of physicians, AI serves as an unprecedented enabler, equipping them with unimaginable tools. Its far-reaching applications encompass drug discovery, disease diagnosis, prognosis, treatment optimization, and outcome prediction. This technological revolution owes much to the prowess of machine learning algorithms, which adeptly process multifaceted data. Consequently, AI is poised to become an integral pillar of digital health systems, shaping and bolstering the realm of personalized medicine. The current landscape is abuzz with AI's exponential growth, fueling a surge of research ventures aimed at enhancing medical practices. By delving into the realm of precision medicine, this paper endeavors to scrutinize and evaluate recent advancements in healthcare pertaining to the utilization of machine learning (ML) and deep learning (DL) algorithms. This systematic review comprehensively encompasses previously published works, dissecting key concepts, innovations, significant contributions, and pivotal enabling techniques. Aspiring to equip readers with a profound understanding and invaluable insights, this paper proves indispensable to those dedicated to exploring the state-of-the-art and contributing to future literature in this domain.",
        "DOI": "10.1016/j.imu.2024.101475",
        "paper_author": "Abbaoui W.",
        "affiliation_name": "Faculté des Sciences Rabat",
        "affiliation_city": "Rabat",
        "affiliation_country": "Morocco",
        "affiliation_id": "60000784",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The Promise and Potential of Brain Organoids",
        "publication": "Advanced Healthcare Materials",
        "citied_by": "18",
        "cover_date": "2024-08-21",
        "Abstract": "Brain organoids are 3D in vitro culture systems derived from human pluripotent stem cells that self-organize to model features of the (developing) human brain. This review examines the techniques behind organoid generation, their current and potential applications, and future directions for the field. Brain organoids possess complex architecture containing various neural cell types, synapses, and myelination. They have been utilized for toxicology testing, disease modeling, infection studies, personalized medicine, and gene-environment interaction studies. An emerging concept termed Organoid Intelligence (OI) combines organoids with artificial intelligence systems to generate learning and memory, with the goals of modeling cognition and enabling biological computing applications. Brain organoids allow neuroscience studies not previously achievable with traditional techniques, and have the potential to transform disease modeling, drug development, and the understanding of human brain development and disorders. The aspirational vision of OI parallels the origins of artificial intelligence, and efforts are underway to map a roadmap toward its realization. In summary, brain organoids constitute a disruptive technology that is rapidly advancing and gaining traction across multiple disciplines.",
        "DOI": "10.1002/adhm.202302745",
        "paper_author": "Smirnova L.",
        "affiliation_name": "Johns Hopkins Bloomberg School of Public Health",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60006183",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Automated detection of vertebral fractures from X-ray images: A novel machine learning model and survey of the field",
        "publication": "Neurocomputing",
        "citied_by": "18",
        "cover_date": "2024-01-21",
        "Abstract": "Vertebral fractures are a common problem and the most prevalent of thoracolumbar compression and burst fractures. However, vertebral fractures are difficult to diagnose: an experienced orthopedist or radiologist is required to detect and determine the type of vertebral fracture. Thus, artificial intelligence methods for diagnosing vertebral fractures are clinically useful. On the basis of a review of 12 studies in the literature, the earliest of which was published in 2020, we propose a machine learning model that detects and determines the type of vertebral fracture on the basis of X-ray data. In this method, YOLOv4 and ResUNet are used to segment vertebral bodies from X-ray images. In evaluation experiments, our method had a precision of 99%, 74%, and 94% in identifying healthy vertebrae, compression fractures, and burst fractures, respectively.",
        "DOI": "10.1016/j.neucom.2023.126946",
        "paper_author": "Cheng L.W.",
        "affiliation_name": "National Cheng Kung University",
        "affiliation_city": "Tainan",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60014982",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Bioinformatics-based analysis of programmed cell death pathway and key prognostic genes in gastric cancer: Implications for the development of therapeutics",
        "publication": "Journal of Gene Medicine",
        "citied_by": "18",
        "cover_date": "2024-01-01",
        "Abstract": "Background: Gastric cancer (GC) represents a major global health burden as a result of its high incidence and poor prognosis. The present study examined the role of the programmed cell death (PCD) pathway and identified key genes influencing the prognosis of patients with GC. Methods: Bioinformatics analysis, machine learning techniques and survival analysis were systematically integrated to identify core prognostic genes from the The Cancer Genome Atlas Stomach Adenocarcinoma (TCGA-STAD) dataset. A prognostic model was then developed to stratify patients into high-risk and low-risk groups, and further validated in the GSE84437 dataset. The model also demonstrated clinical relevance with tumor staging and histopathology. Immune infiltration analysis and the potential benefits of immunotherapy for each risk group were assessed. Finally, subgroup analysis was performed based on the expression of three key prognostic genes. Results: Three core prognostic genes (CAV1, MMP9 and MAGEA3) were identified. The prognostic model could effectively differentiate patients into high-risk and low-risk groups, leading to significantly distinct survival outcomes. Increased immune cell infiltration was observed in the high-risk group, and better potential for immunotherapy outcomes was observed in the low-risk group. Pathways related to cancer progression, such as epithelial–mesenchymal transition and tumor necrosis factor-α signaling via nuclear factor-kappa B, were enriched in the high-risk group. By contrast, the low-risk group showed a number of pathways associated with maintenance of cell functionality and immune responses. The two groups differed in gene mutation patterns and drug sensitivities. Subgroup analysis based on the expression of the three key genes revealed two distinct clusters with distinct survival outcomes, tumor immune microenvironment characteristics and pathway enrichment. Conclusions: The present study offers novel insights into the significance of PCD pathways and identifies key genes associated with the prognosis of patients with GC. This robust prognostic model, along with the delineation of distinct risk groups and molecular subtypes, provides valuable tools for risk stratification, treatment selection and personalized therapeutic interventions for GC.",
        "DOI": "10.1002/jgm.3590",
        "paper_author": "Huang L.",
        "affiliation_name": "Nanchang Hongdu Hospital of TCM",
        "affiliation_city": "Nanchang",
        "affiliation_country": "China",
        "affiliation_id": "118453200",
        "affiliation_state": "Jiangxi"
    },
    {
        "paper_title": "Advancements and Prospects of Machine Learning in Medical Diagnostics: Unveiling the Future of Diagnostic Precision",
        "publication": "Archives of Computational Methods in Engineering",
        "citied_by": "17",
        "cover_date": "2024-01-01",
        "Abstract": "Machine learning (ML) has emerged as a versatile and powerful tool in various fields of medicine, revolutionizing early disease diagnosis, particularly in cases where traditional diagnostic approaches face challenges due to unclear or overlapping symptoms. This survey provides a comprehensive overview of the wide-ranging applications of ML techniques in detecting and diagnosing various diseases at an early stage, highlighting their potential to transform healthcare practices. The survey commences with a comprehensive review of commonly used ML algorithms, emphasizing their relevance and adaptability in medical domains. With a focus on disease diagnosis, we delve into the specific implementation of ML algorithms for early detection in prominent diseases, including cancer, COVID-19, diabetes, kidney diseases, and heart diseases. By analyzing the current state of research and developments, this survey provides valuable insights into how ML algorithms are being employed to enhance disease diagnosis accuracy and efficacy. In the domain of cancer diagnosis, ML techniques have made significant strides in analyzing medical imaging data, genomic profiling, and predictive modeling. These advancements have led to improved cancer detection rates, enabling timely interventions and personalized treatment plans. Additionally, the survey explores the pivotal role of ML in addressing the challenges posed by the COVID-19 pandemic. ML-based automated screening tools have demonstrated efficiency in detecting potential cases, while predictive modeling has been instrumental in estimating disease progression and optimizing resource allocation. Furthermore, ML’s contributions extend to chronic diseases such as diabetes, kidney diseases, and heart diseases, where it has shown promising results in predicting disease progression, enabling early intervention, and enhancing management strategies. In conclusion, this comprehensive survey showcases the transformative potential of ML in early disease diagnosis across various medical conditions. By providing valuable references and insights into future trends, it serves as a guiding resource for researchers and clinicians interested in leveraging ML technologies to improve patient care and make significant advancements in the field of medical diagnostics. With the capacity to decipher complex patterns and facilitate intelligent predictions, ML has emerged as a pivotal ally in the journey towards early disease detection and improved healthcare outcomes.",
        "DOI": "10.1007/s11831-024-10148-w",
        "paper_author": "Asif S.",
        "affiliation_name": "Central South University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60017060",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Tribulations and future opportunities for artificial intelligence in precision medicine",
        "publication": "Journal of Translational Medicine",
        "citied_by": "17",
        "cover_date": "2024-12-01",
        "Abstract": "Upon a diagnosis, the clinical team faces two main questions: what treatment, and at what dose? Clinical trials' results provide the basis for guidance and support for official protocols that clinicians use to base their decisions. However, individuals do not consistently demonstrate the reported response from relevant clinical trials. The decision complexity increases with combination treatments where drugs administered together can interact with each other, which is often the case. Additionally, the individual's response to the treatment varies with the changes in their condition. In practice, the drug and the dose selection depend significantly on the medical protocol and the medical team's experience. As such, the results are inherently varied and often suboptimal. Big data and Artificial Intelligence (AI) approaches have emerged as excellent decision-making tools, but multiple challenges limit their application. AI is a rapidly evolving and dynamic field with the potential to revolutionize various aspects of human life. AI has become increasingly crucial in drug discovery and development. AI enhances decision-making across different disciplines, such as medicinal chemistry, molecular and cell biology, pharmacology, pathology, and clinical practice. In addition to these, AI contributes to patient population selection and stratification. The need for AI in healthcare is evident as it aids in enhancing data accuracy and ensuring the quality care necessary for effective patient treatment. AI is pivotal in improving success rates in clinical practice. The increasing significance of AI in drug discovery, development, and clinical trials is underscored by many scientific publications. Despite the numerous advantages of AI, such as enhancing and advancing Precision Medicine (PM) and remote patient monitoring, unlocking its full potential in healthcare requires addressing fundamental concerns. These concerns include data quality, the lack of well-annotated large datasets, data privacy and safety issues, biases in AI algorithms, legal and ethical challenges, and obstacles related to cost and implementation. Nevertheless, integrating AI in clinical medicine will improve diagnostic accuracy and treatment outcomes, contribute to more efficient healthcare delivery, reduce costs, and facilitate better patient experiences, making healthcare more sustainable. This article reviews AI applications in drug development and clinical practice, making healthcare more sustainable, and highlights concerns and limitations in applying AI.",
        "DOI": "10.1186/s12967-024-05067-0",
        "paper_author": "Carini C.",
        "affiliation_name": "Faculty of Life Sciences &amp; Medicine",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60177635",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Revolutionizing vascular health through the temporal convolutional transformer for drug screening and model evolution",
        "publication": "Biomedical Signal Processing and Control",
        "citied_by": "17",
        "cover_date": "2024-09-01",
        "Abstract": "Vascular illnesses include a spectrum of disorders affecting the blood vessels and continue to be major global health challenges. Vascular disorders are major worldwide health concerns that require ongoing development of drug screening models in order to find efficient treatment approaches. The ever-changing field of vascular health demands novel ways to medication screening due to the enduring difficulties presented by a variety of illnesses. This abstract explores a paradigm shift, highlighting the innovative role of the Temporal Convolutional Transformer (TCT) in redefining drug screening techniques and promoting model evolution. With its seamless integration of transformer mechanisms and temporal convolutional layers, the TCT is a revolutionary hybrid algorithm. Because of this special combination, the model can simultaneously identify spatial subtleties and capture temporal dynamics in complicated biological information. The temporal convolutional layers of the TCT are particularly good at revealing the sequential dependencies that are present in the development of vascular disorders. The model ensures a detailed knowledge of the developing nature of these diseases by analyzing temporal dynamics with skill. Simultaneously, the TCT's transformer mechanisms enable a thorough examination of long-range interdependence and global interconnections. The TCT's dual capability establishes it as a comprehensive solution by offering a nuanced perspective on spatial patterns that are essential for identifying the complexity of vascular health. The TCT is hybrid in the sense that it can learn features at several scales, supporting different temporal and spatial resolutions. This flexibility guarantees that the model may extract pertinent information at various scales, enhancing the characterization of the complex nature of vascular illnesses. The TCT is positioned as a holistic solution since its transformer mechanisms allow for a thorough investigation of long-range dependencies and global interconnections at the same time. This combined capacity offers a sophisticated viewpoint on spatial patterns that is essential for understanding the intricacies of vascular health. Moreover, the remarkable flexibility of the TCT to dynamic temporal scales is consistent with the dynamic character of biological processes, providing a strong and adaptable framework for drug screening. The TCT is used in many different fields of vascular disease research. The model performs well in image-based screening, collecting sequential dependencies over time and processing spatial information from medical imaging datasets. The TCT's capacity to identify long-range dependencies is essential for molecular interaction research since it helps to clarify the complex pathways associated with vascular disorders. Its adaptability also extends to personalized treatment approaches, which allow for the efficient modeling of patient-specific data, including genetic information. The TCT is a revolutionary tool that will continue to evolve as drug screening models do. By integrating temporal convolutional and transformer mechanisms, its all-encompassing methodology provides a sophisticated and comprehensive approach to deciphering the intricacies of vascular disorders. Across all evaluated metrics, the proposed method achieves near-perfect accuracy of 98.45%, sensitivity of 93.45%, specificity of 98.43%, precision of 84.25, AUC of 99 % and F1 score values 96.01%, respectively. This abstract sheds light on how the TCT has significantly changed drug development approaches, opening the door for more focused and effective therapies in the field of vascular health.",
        "DOI": "10.1016/j.bspc.2024.106390",
        "paper_author": "Kumar Ganiya R.",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India",
        "affiliation_id": "60079446",
        "affiliation_state": "AP"
    },
    {
        "paper_title": "Progression from ductal carcinoma in situ to invasive breast cancer: molecular features and clinical significance",
        "publication": "Signal Transduction and Targeted Therapy",
        "citied_by": "17",
        "cover_date": "2024-12-01",
        "Abstract": "Ductal carcinoma in situ (DCIS) represents pre-invasive breast carcinoma. In untreated cases, 25–60% DCIS progress to invasive ductal carcinoma (IDC). The challenge lies in distinguishing between non-progressive and progressive DCIS, often resulting in over- or under-treatment in many cases. With increasing screen-detected DCIS in these years, the nature of DCIS has aroused worldwide attention. A deeper understanding of the biological nature of DCIS and the molecular journey of the DCIS-IDC transition is crucial for more effective clinical management. Here, we reviewed the key signaling pathways in breast cancer that may contribute to DCIS initiation and progression. We also explored the molecular features of DCIS and IDC, shedding light on the progression of DCIS through both inherent changes within tumor cells and alterations in the tumor microenvironment. In addition, valuable research tools utilized in studying DCIS including preclinical models and newer advanced technologies such as single-cell sequencing, spatial transcriptomics and artificial intelligence, have been systematically summarized. Further, we thoroughly discussed the clinical advancements in DCIS and IDC, including prognostic biomarkers and clinical managements, with the aim of facilitating more personalized treatment strategies in the future. Research on DCIS has already yielded significant insights into breast carcinogenesis and will continue to pave the way for practical clinical applications.",
        "DOI": "10.1038/s41392-024-01779-3",
        "paper_author": "Wang J.",
        "affiliation_name": "Zhejiang University School of Medicine",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60029310",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Artificial Intelligence for Clinical Prediction: Exploring Key Domains and Essential Functions",
        "publication": "Computer Methods and Programs in Biomedicine Update",
        "citied_by": "17",
        "cover_date": "2024-01-01",
        "Abstract": "Background: Clinical prediction is integral to modern healthcare, leveraging current and historical medical data to forecast health outcomes. The integration of Artificial Intelligence (AI) in this field significantly enhances diagnostic accuracy, treatment planning, disease prevention, and personalised care leading to better patient outcomes and healthcare efficiency. Methods: This systematic review implemented a structured four-step methodology, including an extensive literature search in academic databases (PubMed, Embase, Google Scholar), applying specific inclusion and exclusion criteria, data extraction focusing on AI techniques and their applications in clinical prediction, and a thorough analysis of the collected information to understand AI's roles in enhancing clinical prediction. Results: Through the analysis of 74 experimental studies, eight key domains, where AI significantly enhances clinical prediction, were identified: (1) Diagnosis and early detection of disease; (2) Prognosis of disease course and outcomes; (3) Risk assessment of future disease; (4) Treatment response for personalised medicine; (5) Disease progression; (6) Readmission risks; (7) Complication risks; and (8) Mortality prediction. Oncology and radiology come on top of the specialties benefiting from AI in clinical prediction. Discussion: The review highlights AI's transformative impact across various clinical prediction domains, including its role in revolutionising diagnostics, improving prognosis accuracy, aiding in personalised medicine, and enhancing patient safety. AI-driven tools contribute significantly to the efficiency and effectiveness of healthcare delivery. Conclusion and recommendations: AI's integration in clinical prediction marks a substantial advancement in healthcare. Recommendations include enhancing data quality and accessibility, promoting interdisciplinary collaboration, focusing on ethical AI practices, investing in AI education, expanding clinical trials, developing regulatory oversight, involving patients in the AI integration process, and continuous monitoring and improvement of AI systems.",
        "DOI": "10.1016/j.cmpbup.2024.100148",
        "paper_author": "Khalifa M.",
        "affiliation_name": "Education Centre of Australia",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "100509241",
        "affiliation_state": "NS"
    },
    {
        "paper_title": "The genetic architecture of multimodal human brain age",
        "publication": "Nature Communications",
        "citied_by": "17",
        "cover_date": "2024-12-01",
        "Abstract": "The complex biological mechanisms underlying human brain aging remain incompletely understood. This study investigated the genetic architecture of three brain age gaps (BAG) derived from gray matter volume (GM-BAG), white matter microstructure (WM-BAG), and functional connectivity (FC-BAG). We identified sixteen genomic loci that reached genome-wide significance (P-value < 5×10−8). A gene-drug-disease network highlighted genes linked to GM-BAG for treating neurodegenerative and neuropsychiatric disorders and WM-BAG genes for cancer therapy. GM-BAG displayed the most pronounced heritability enrichment in genetic variants within conserved regions. Oligodendrocytes and astrocytes, but not neurons, exhibited notable heritability enrichment in WM and FC-BAG, respectively. Mendelian randomization identified potential causal effects of several chronic diseases on brain aging, such as type 2 diabetes on GM-BAG and AD on WM-BAG. Our results provide insights into the genetics of human brain aging, with clinical implications for potential lifestyle and therapeutic interventions. All results are publicly available at https://labs.loni.usc.edu/medicine.",
        "DOI": "10.1038/s41467-024-46796-6",
        "paper_author": "Wen J.",
        "affiliation_name": "Keck School of Medicine of USC",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60015183",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Cost-sensitive learning for imbalanced medical data: a review",
        "publication": "Artificial Intelligence Review",
        "citied_by": "17",
        "cover_date": "2024-04-01",
        "Abstract": "Integrating Machine Learning (ML) in medicine has unlocked many opportunities to harness complex medical data, enhancing patient outcomes and advancing the field. However, the inherent imbalanced distribution of medical data poses a significant challenge, resulting in biased ML models that perform poorly on minority classes. Mitigating the impact of class imbalance has prompted researchers to explore various strategies, wherein Cost-Sensitive Learning (CSL) arises as a promising approach to improve the accuracy and reliability of ML models. This paper presents the first review of CSL for imbalanced medical data. A comprehensive exploration of the existing literature encompassed papers published from January 2010 to December 2022 and sourced from five major digital libraries. A total of 173 papers were selected, analysed, and classified based on key criteria, including publication years, channels and sources, research types, empirical types, medical sub-fields, medical tasks, CSL approaches, strengths and weaknesses of CSL, frequently used datasets and data types, evaluation metrics, and development tools. The results indicate a noteworthy publication rise, particularly since 2020, and a strong preference for CSL direct approaches. Data type analysis unveiled diverse modalities, with medical images prevailing. The underutilisation of cost-related metrics and the prevalence of Python as the primary programming tool are highlighted. The strengths and weaknesses analysis covered three aspects: CSL strategy, CSL approaches, and relevant works. This study serves as a valuable resource for researchers seeking to explore the current state of research, identify strengths and gaps in the existing literature and advance CSL’s application for imbalanced medical data.",
        "DOI": "10.1007/s10462-023-10652-8",
        "paper_author": "Araf I.",
        "affiliation_name": "Mohammed VI Polytechnic University",
        "affiliation_city": "Ben Guerir",
        "affiliation_country": "Morocco",
        "affiliation_id": "60192082",
        "affiliation_state": "Marrakesh-Safi"
    }
]