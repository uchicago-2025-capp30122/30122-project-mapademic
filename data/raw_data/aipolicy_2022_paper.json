[
    {
        "paper_title": "LEGAL INSTRUMENTS FOR ENVIRONMENTAL PROTECTION AND COMBATTING CLIMATE CHANGE IN THE COMMON AGRICULTURAL POLICY 2023–2027",
        "publication": "Przeglad Prawa Rolnego",
        "citied_by": "1",
        "cover_date": "2022-12-20",
        "Abstract": "The subject of this article is the legal instruments for environmental protection and combatting climate change in the Common Agricultural Policy (CAP) for 2023–2027. The analysis was conducted in the context of the agricultural model adopted in the European Union. The starting point of the considerations was the construction of the new CAP and its budget, as well as the shape that the EU legislator gave to the legal instruments of this policy. The possible impact of the geopolitical situation on the implementation of CAP objectives was also examined. The legal instruments for environmental protection and combatting climate change have been significantly strengthened in the new CAP and the disbursement of the increasingly higher amounts of support depends now, among other things, on the implementation of these instruments by the Member States. The green architecture of the CAP has also been expanded. Its objectives are ambitious and concern many spheres of agricultural activity. However, it will only be possible to assess the effectiveness of these environmen-tal-climate instruments once experience of their implementation has been gained. Moreover, it may turn out that due to the need to ensure food security globally, it will be necessary to modify the CAP priorities, even if at the expense of the environment challenges.",
        "DOI": "10.14746/ppr.2022.31.2.1",
        "paper_author": "Włodarczyk B.",
        "affiliation_name": "Institute of Legal Studies of the Polish Academy of Sciences",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland",
        "affiliation_id": "60104538",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Teaching artificial intelligence as a fundamental toolset of medicine",
        "publication": "Cell Reports Medicine",
        "citied_by": "14",
        "cover_date": "2022-12-20",
        "Abstract": "Artificial intelligence (AI) is transforming the practice of medicine. Systems assessing chest radiographs, pathology slides, and early warning systems embedded in electronic health records (EHRs) are becoming ubiquitous in medical practice. Despite this, medical students have minimal exposure to the concepts necessary to utilize and evaluate AI systems, leaving them under prepared for future clinical practice. We must work quickly to bolster undergraduate medical education around AI to remedy this. In this commentary, we propose that medical educators treat AI as a critical component of medical practice that is introduced early and integrated with the other core components of medical school curricula. Equipping graduating medical students with this knowledge will ensure they have the skills to solve challenges arising at the confluence of AI and medicine.",
        "DOI": "10.1016/j.xcrm.2022.100824",
        "paper_author": "Ötleş E.",
        "affiliation_name": "University of Michigan Medical School",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60033182",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Artificial intelligence in STEM education: The paradigmatic shifts in research, education, and technology",
        "publication": "Artificial Intelligence in STEM Education: The Paradigmatic Shifts in Research, Education, and Technology",
        "citied_by": "6",
        "cover_date": "2022-12-20",
        "Abstract": "Artificial intelligence (AI) opens new opportunities for STEM education in K-12, higher education, and professional education contexts. This book summarizes AI in education (AIED) with a particular focus on the research, practice, and technological paradigmatic shifts of AIED in recent years. The 23 chapters in this edited collection track the paradigmatic shifts of AIED in STEM education, discussing how and why the paradigms have shifted, explaining how and in what ways AI techniques have ensured the shifts, and envisioning what directions next-generation AIED is heading in the new era. As a whole, the book illuminates the main paradigms of AI in STEM education, summarizes the AI-enhanced techniques and applications used to enable the paradigms, and discusses AI-enhanced teaching, learning, and design in STEM education. It provides an adapted educational policy so that practitioners can better facilitate the application of AI in STEM education. This book is a must-read for researchers, educators, students, designers, and engineers who are interested in the opportunities and challenges of AI in STEM education.",
        "DOI": "10.1201/9781003181187",
        "paper_author": "Ouyang F.",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60003970",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "An auxiliary decision-making method for autonomous driving via monte carlo tree search",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2022-12-16",
        "Abstract": "The decision-making problem in autonomous driving (AD) is one of the most challenging scenarios, for AD is a real time scenario with a huge space of actions and spaces. Besides there are multiple other agents, it is difficult to predict their actions. In this paper, we propose a fast decision-making auxiliary method based on Monte Carlo Tree Search (MCTS). First, our ego vehicle is controlled by some basic heuristic methods built by humans' driving experiences, then we use our auxiliary method to improve the ego vehicle's decision-making ability. Besides, we use a pruning technology to reduce time cost. Experiments are carried out on the simulation platform CARLA, the results show that our auxiliary method can improve the decision-making ability of the ego vehicle, and the pruning can make the driving policy stronger.",
        "DOI": "10.1145/3584376.3584444",
        "paper_author": "Ou T.",
        "affiliation_name": "Institute of Software Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025256",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Liability Rules for AI-Related Harm: Law and Economics Lessons for a European Approach",
        "publication": "European Journal of Risk Regulation",
        "citied_by": "11",
        "cover_date": "2022-12-16",
        "Abstract": "The potential of artificial intelligence (AI) has grown exponentially in recent years, which not only generates value but also creates risks. AI systems are characterised by their complexity, opacity and autonomy in operation. Now and in the foreseeable future, AI systems will be operating in a manner that is not fully autonomous. This signifies that providing appropriate incentives to the human parties involved is still of great importance in reducing AI-related harm. Therefore, liability rules should be adapted in such a way to provide the relevant parties with incentives to efficiently reduce the social costs of potential accidents. Relying on a law and economics approach, we address the theoretical question of what kind of liability rules should be applied to different parties along the value chain related to AI. In addition, we critically analyse the ongoing policy debates in the European Union, discussing the risk that European policymakers will fail to determine efficient liability rules with regard to different stakeholders.",
        "DOI": "10.1017/err.2022.26",
        "paper_author": "Li S.",
        "affiliation_name": "Helsingin Yliopisto",
        "affiliation_city": "Helsinki",
        "affiliation_country": "Finland",
        "affiliation_id": "60002952",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "Dynamics of a non-smooth model of prostate cancer with intermittent androgen deprivation therapy",
        "publication": "Physica D: Nonlinear Phenomena",
        "citied_by": "7",
        "cover_date": "2022-12-15",
        "Abstract": "Intermittent androgen deprivation therapy (IADT) is widely used in the clinic treatment for prostate cancer. We propose a Filippov system in this paper, which defines the following threshold policy: the androgen deprivation therapy (ADT) is implemented once the concentration of androgen-dependent (AD) cells exceeds the threshold level ET and it is suspended otherwise. To better understand the effect of the IADT on the evolution of prostate cancer, we perform a comprehensive qualitative analysis of global dynamics of the targeted model. As the threshold value varies, our model admits multistability of three equilibria, bistability of two equilibria, stability of the regular equilibrium or the pseudo-equilibrium, and the boundary equilibrium bifurcation. The steady-state regimes include high concentration, low concentration and no androgen-independent cells. This highlights the critical role of threshold values and the initial condition of prostate cancer cells of patients. The main results indicate that the concentration of AD cells and AI cells can be contained at a relatively satisfactory level, which can help to make treatment schedule and improve treatment outcomes for patients with prostate cancer.",
        "DOI": "10.1016/j.physd.2022.133522",
        "paper_author": "Yan R.",
        "affiliation_name": "Baoji University of Arts and Sciences",
        "affiliation_city": "Baoji",
        "affiliation_country": "China",
        "affiliation_id": "60073423",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Research on Renewable Energy Architectural Integration Technology and Building Form",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2022-12-13",
        "Abstract": "Architectural technology will have an impact on architectural form. With the transformation of industrialized society to post industrialized society in the 21st century and the comprehensive popularization of information technology, the cross interaction of AI technology, automation engineering technology, material science and other fields has promoted the qualitative changes in the design and manufacturing technology of architectural structure, structure and materials. With the energy crisis and the emergence of energy-saving buildings, energy-saving buildings have produced new architectural forms under the influence of energy-saving ideas and energy-saving technologies. Through a large number of contemporary physical buildings, we can see the influence of architectural technology on architectural forms and the relationship between technology and construction.",
        "DOI": "10.3233/ATDE220903",
        "paper_author": "Du Y.",
        "affiliation_name": "Shanghai Publishing and Printing College",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "109920533",
        "affiliation_state": "Shanghai"
    },
    {
        "paper_title": "Contested logistics simulation output analysis with approximate dynamic programming: a proposed methodology",
        "publication": "Journal of Defense Analytics and Logistics",
        "citied_by": "2",
        "cover_date": "2022-12-13",
        "Abstract": "Purpose: Rapid sensitivity analysis and near-optimal decision-making in contested environments are valuable requirements when providing military logistics support. Port of debarkation denial motivates maneuver from strategic operational locations, further complicating logistics support. Simulations enable rapid concept design, experiment and testing that meet these complicated logistic support demands. However, simulation model analyses are time consuming as output data complexity grows with simulation input. This paper proposes a methodology that leverages the benefits of simulation-based insight and the computational speed of approximate dynamic programming (ADP). Design/methodology/approach: This paper describes a simulated contested logistics environment and demonstrates how output data informs the parameters required for the ADP dialect of reinforcement learning (aka Q-learning). Q-learning output includes a near-optimal policy that prescribes decisions for each state modeled in the simulation. This paper's methods conform to DoD simulation modeling practices complemented with AI-enabled decision-making. Findings: This study demonstrates simulation output data as a means of state–space reduction to mitigate the curse of dimensionality. Furthermore, massive amounts of simulation output data become unwieldy. This work demonstrates how Q-learning parameters reflect simulation inputs so that simulation model behavior can compare to near-optimal policies. Originality/value: Fast computation is attractive for sensitivity analysis while divorcing evaluation from scenario-based limitations. The United States military is eager to embrace emerging AI analytic techniques to inform decision-making but is hesitant to abandon simulation modeling. This paper proposes Q-learning as an aid to overcome cognitive limitations in a way that satisfies the desire to wield AI-enabled decision-making combined with modeling and simulation.",
        "DOI": "10.1108/JDAL-07-2022-0004",
        "paper_author": "Powers M.",
        "affiliation_name": "MITRE Corporation",
        "affiliation_city": "McLean",
        "affiliation_country": "United States",
        "affiliation_id": "60012564",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications",
        "publication": "ACM Transactions on Interactive Intelligent Systems",
        "citied_by": "8",
        "cover_date": "2022-12-12",
        "Abstract": "While EXplainable Artificial Intelligence (XAI) approaches aim to improve human-AI collaborative decision-making by improving model transparency and mental model formations, experiential factors associated with human users can cause challenges in ways system designers do not anticipate. In this article, we first showcase a user study on how anchoring bias can potentially affect mental model formations when users initially interact with an intelligent system and the role of explanations in addressing this bias. Using a video activity recognition tool in cooking domain, we asked participants to verify whether a set of kitchen policies are being followed, with each policy focusing on a weakness or a strength. We controlled the order of the policies and the presence of explanations to test our hypotheses. Our main finding shows that those who observed system strengths early on were more prone to automation bias and made significantly more errors due to positive first impressions of the system, while they built a more accurate mental model of the system competencies. However, those who encountered weaknesses earlier made significantly fewer errors, since they tended to rely more on themselves, while they also underestimated model competencies due to having a more negative first impression of the model. Motivated by these findings and similar existing work, we formalize and present a conceptual model of user's past experiences that examine the relations between user's backgrounds, experiences, and human factors in XAI systems based on usage time. Our work presents strong findings and implications, aiming to raise the awareness of AI designers toward biases associated with user impressions and backgrounds.",
        "DOI": "10.1145/3531066",
        "paper_author": "Nourani M.",
        "affiliation_name": "University of Florida",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States",
        "affiliation_id": "60013959",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "DyCo: Dynamic, Contextualized AI Models",
        "publication": "ACM Transactions on Embedded Computing Systems",
        "citied_by": "1",
        "cover_date": "2022-12-12",
        "Abstract": "Devices with limited computing resources use smaller AI models to achieve low-latency inferencing. However, model accuracy is typically much lower than the accuracy of a bigger model that is trained and deployed in places where the computing resources are relatively abundant. We describe DyCo, a novel system that ensures privacy of stream data and dynamically improves the accuracy of small models used in devices. Unlike knowledge distillation or federated learning, DyCo treats AI models as black boxes. DyCo uses a semi-supervised approach to leverage existing training frameworks and network model architectures to periodically train contextualized, smaller models for resource-constrained devices. DyCo uses a bigger, highly accurate model in the edge-cloud to auto-label data received from each sensor stream. Training in the edge-cloud (as opposed to the public cloud) ensures data privacy, and bespoke models for thousands of live data streams can be designed in parallel by using multiple edge-clouds. DyCo uses the auto-labeled data to periodically re-train, stream-specific, bespoke small models. To reduce the periodic training costs, DyCo uses different policies that are based on stride, accuracy, and confidence information.We evaluate our system, and the contextualized models, by using two object detection models for vehicles and people, and two datasets (a public benchmark and another real-world proprietary dataset). Our results show that DyCo increases the mAP accuracy measure of small models by an average of 16.3% (and up to 20%) for the public benchmark and an average of 19.0% (and up to 64.9%) for the real-world dataset. DyCo also decreases the training costs for contextualized models by more than an order of magnitude.",
        "DOI": "10.1145/3520131",
        "paper_author": "Yang Y.",
        "affiliation_name": "NEC Laboratories America, Inc.",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States",
        "affiliation_id": "60018008",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Energy system digitization in the era of AI: A three-layered approach toward carbon neutrality",
        "publication": "Patterns",
        "citied_by": "7",
        "cover_date": "2022-12-09",
        "Abstract": "The transition toward carbon-neutral electricity is one of the biggest game changers in addressing climate change since it addresses the dual challenges of removing carbon emissions from the two largest sectors of emitters: electricity and transportation. The transition to a carbon-neutral electric grid poses significant challenges to conventional paradigms of modern grid planning and operation. Much of the challenge arises from the scale of the decision-making and the uncertainty associated with the energy supply and demand. Artificial intelligence (AI) could potentially have a transformative impact on accelerating the speed and scale of carbon-neutral transition, as many decision-making processes in the power grid can be cast as classic, though challenging, machine-learning tasks. We point out that to amplify AI's impact on carbon-neutral transition of the electric energy systems, the AI algorithms originally developed for other applications should be tailored in three layers of technology, markets, and policy.",
        "DOI": "10.1016/j.patter.2022.100640",
        "paper_author": "Xie L.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60148980",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "A robust control-theory-based exploration strategy in deep reinforcement learning for virtual network embedding",
        "publication": "Computer Networks",
        "citied_by": "6",
        "cover_date": "2022-12-09",
        "Abstract": "Network slice management and, more generally, resource orchestration should be fully automated in 6G networks, as envisioned by the ETSI ENI. In this context, artificial intelligence (AI) and context-aware policies are certainly major options to move in this direction and to adapt service delivery to changing user needs, environmental conditions and business objectives. In this paper, we step towards this objective by addressing the problem of optimal placement of dynamic virtual networks through a self-adaptive learning-based strategy. These constantly evolving networks present, however, several challenges, mainly due to their stochastic nature, and the high dimensionality of the state and the action spaces. This curse of dimensionality requires, indeed, a broader exploration, which is not always compatible with a real-time execution in an operational network. Thus, we propose DQMC, a new strategy for virtual network embedding in mobile networks combining a Deep Reinforcement Learning (DRL) strategy, namely a Deep Q-Network (DQN), and Monte Carlo (MC). As learning is costly in time and computing resources, and sensitive to changes in the network, we suggest a control-theory-based techniques to dynamically leverage exploration in DQMC. This leads to fast, efficient, and sober learning compared to a Monte Carlo-based strategy. This also ensures a reliable solution even in the case of a change in the requests’ sizes or a node's failure, showing promising perspectives for solutions combining control-theory and machine learning.",
        "DOI": "10.1016/j.comnet.2022.109366",
        "paper_author": "Dandachi G.",
        "affiliation_name": "Institut de Recherche en Informatique et Systèmes Aléatoires",
        "affiliation_city": "Rennes",
        "affiliation_country": "France",
        "affiliation_id": "60027031",
        "affiliation_state": "Brittany"
    },
    {
        "paper_title": "Challenges and solutions for transforming health ecosystems in low- and middle-income countries through artificial intelligence",
        "publication": "Frontiers in Medicine",
        "citied_by": "25",
        "cover_date": "2022-12-02",
        "Abstract": "Background: Recent studies demonstrate the potential of Artificial Intelligence to support diagnosis, mortality assessment, and clinical decisions in low-and-middle-income countries (LMICs). However, explicit evidence of strategies to overcome the particular challenges for transformed health systems in these countries does not exist. Objective: The present study undertakes a review of research on the current status of artificial intelligence (AI) to identify requirements, gaps, challenges, and possible strategies to strengthen the large, complex, and heterogeneous health systems in LMICs. Design: After introducing the general challenges developing countries face, the methodology of systematic reviews and the meta-analyses extension for scoping reviews (PRISMA-ScR) is introduced according to the preferred reporting items. Scopus and Web of Science databases were used to identify papers published between 2011–2022, from which we selected 151 eligible publications. Moreover, a narrative review was conducted to analyze the evidence in the literature about explicit evidence of strategies to overcome particular AI challenges in LMICs. Results: The analysis of results was divided into two groups: primary studies, which include experimental studies or case studies using or deploying a specific AI solution (n = 129), and secondary studies, including opinion papers, systematic reviews, and papers with strategies or guidelines (n = 22). For both study groups, a descriptive statistical analysis was performed describing their technological contribution, data used, health context, and type of health interventions. For the secondary studies group, an in-deep narrative review was performed, identifying a set of 40 challenges gathered in eight different categories: data quality, context awareness; regulation and legal frameworks; education and change resistance; financial resources; methodology; infrastructure and connectivity; and scalability. A total of 89 recommendations (at least one per challenge) were identified. Conclusion: Research on applying AI and ML to healthcare interventions in LMICs is growing; however, apart from very well-described ML methods and algorithms, there are several challenges to be addressed to scale and mainstream experimental and pilot studies. The main challenges include improving the quality of existing data sources, training and modeling AI solutions based on contextual data; and implementing privacy, security, informed consent, ethical, liability, confidentiality, trust, equity, and accountability policies. Also, robust eHealth environments with trained stakeholders, methodological standards for data creation, research reporting, product certification, sustained investment in data sharing, infrastructures, and connectivity are necessary. Systematic review registration: [https://rb.gy/frn2rz].",
        "DOI": "10.3389/fmed.2022.958097",
        "paper_author": "López D.M.",
        "affiliation_name": "Universidad del Cauca",
        "affiliation_city": "Popayan",
        "affiliation_country": "Colombia",
        "affiliation_id": "60051434",
        "affiliation_state": "Cauca"
    },
    {
        "paper_title": "Cocreative interaction: Somax2 and the reach project",
        "publication": "Computer Music Journal",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Somax2 is an artificial intelligence (AI)-based multiagent system for human–machine “coimprovisation” that generates stylistically coherent streams while continuously listening and adapting to musicians or other agents. The model on which it is based can be used with little configuration to interact with humans in full autonomy, but it also allows fine real-time control of its generative processes and interaction strategies, closer in this case to a “smart” digital instrument. An offspring of the Omax system, conceived at the Institut de Recherche et Coordination Acoustique/Musique (IRCAM), the Somax2 environment is part of the European Research Council Raising Cocreativity in Cyber–Human Musicianship (REACH) project, which studies distributed creativity as a general template for symbiotic interaction between humans and digital systems. It fosters mixed musical reality involving cocreative AI agents. The REACH project puts forward the idea that cocreativity in cyber–human systems results from the emergence of complex joint behavior, produced by interaction and featuring cross-learning mechanisms. Somax2 is a first step toward this ideal, and already shows life-size achievements. This article describes Somax2 extensively, from its theoretical model to its system architecture, through its listening and learning strategies, representation spaces, and interaction policies.",
        "DOI": "10.1162/comj_a_00662",
        "paper_author": "Assayag G.",
        "affiliation_name": "Sciences et Technologies de la Musique et du Son",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60158039",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Should we regulate Artificial Intelligence or some uses of software?",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Artificial Intelligence regulatory developments have been ever-increasing in both academia as well as within policy and governmental settings. Whilst extensive literature has been published on the topic of how such regulation should be developed, the question as to whether such regulation should be AI-specific or focused on software in general remains unexplored. In this commentary paper this question is explored and after arguments for whether regulation should be technology-specific or be focused on the use of technology are provided.",
        "DOI": "10.1007/s44163-022-00021-9",
        "paper_author": "Ellul J.",
        "affiliation_name": "Malta Digital Innovation Authority",
        "affiliation_city": "Mriehel",
        "affiliation_country": "Malta",
        "affiliation_id": "131180376",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Between vision and practice: lack of alignment between AI strategies and energy regulations in the Dutch electricity sector",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "Abstract: Different governmental institutions are publishing more and more visions, strategies, or proposed regulations related to artificial intelligence. This paper analyses how these visions or proposed regulations are put into practice. To this end, the proposed European Union Artificial Intelligence Act, the Dutch artificial intelligence strategy and the proposed new Dutch energy law are compared. Even though the new Dutch energy law was created parallel and published after the European Union Artificial Intelligence Act, it does not take into account the use of artificial intelligence in the electricity actor. Similarly, the focus points of the Dutch artificial intelligence strategy are ignored in the new Dutch energy law. Two issues emerge from this. First, it is questionable if and how visions, strategies and proposed regulations related to AI are translated into different sectors and related practices. Second, as the different acts and proposed regulations do not communicate or overlap, gaps develop between the different policies. It is unclear which institutions will fill in these gaps.",
        "DOI": "10.1007/s44163-022-00040-6",
        "paper_author": "Niet I.",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60032882",
        "affiliation_state": "Noord-Brabant"
    },
    {
        "paper_title": "The tech industry hijacking of the AI ethics research agenda and why we should reclaim it",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "This paper reflects on the tech industry’s colonization of the AI ethics research field and addresses conflicts of interest in public policymaking concerning AI. The AI ethics research community faces two intertwined challenges: In the first place, we have a tech industry heavily influencing the AI ethics research agenda. Secondly, cleaning up after the tech industry has implied that we have turned to value-driven design methods to bring ethics to AI design. But by framing research questions relevant to a technical practice, we have facilitated the technological solutionism behind the tech industry’s business model. Therefore, this paper takes the first steps to reshape the AI ethics research agenda by suggesting moving toward an emancipatory framework that brings politics to design while, at the same time, bearing in mind that AI is not to be treated as an inevitability. As a research community, we must focus on the repressive power dynamics exacerbated by AI and address challenges facing the vulnerable groups seldom heard, despite the fact that they are the ones most negatively affected by AI initiatives.",
        "DOI": "10.1007/s44163-022-00043-3",
        "paper_author": "Gerdes A.",
        "affiliation_name": "Syddansk Universitet",
        "affiliation_city": "Odense",
        "affiliation_country": "Denmark",
        "affiliation_id": "60019160",
        "affiliation_state": "Syddanmark"
    },
    {
        "paper_title": "The EU’s potential to lead in “ethical and secure” artificial intelligence: last, best hope?",
        "publication": "Journal of Transatlantic Studies",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "This article explores the capacity of the European Union (EU) to achieve its ambition to “become the world-leading region on developing and deploying cutting-edge, ethical and secure AI (European Commission. “Coordinated Plan on Artificial Intelligence 2021 Review”, 56.)” and secondarily considers the implications of this quest within the context of transatlantic relations. Mapping the EU’s current technological and commercial competitiveness in the AI field vis-à-vis China and the USA, we contest the conventional depiction of the EU as a laggard offering a more nuanced view challenging this characterization on empirical and normative grounds. Analysing the extent to which the EU’s market and regulatory power—the so-called Brussels effect—sufficiently equips the EU to defend “ethical and secure” AI globally, we argue that regardless of US support or transatlantic convergence in the AI policy space, the EU’s efforts represent the last, best hope for a fairer, more secure and open world order in the data-driven, digital era.",
        "DOI": "10.1057/s42738-023-00101-3",
        "paper_author": "Birchfield V.L.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Perspectives on AI adoption in Italy, the role of the Italian AI Strategy",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "The Industrial landscape in Italy is characterized by small medium enterprises. The information technology sector is teaming with a broad spectrum of players from smaller ones up to large system integrators that have access to the most advanced technologies. The present paper aims at analysing the recently published Italian AI Strategy framing it within the context of the Italian IT industry. It references to data gathered in a small scale survey on AI adoption of Italian IT companies, and provides an analysis of the Italian AI Strategies focusing on the risks that its implementation will have to face and eventually draws three different scenarios on AI adoption in the Italian productive system. The Italian industrial landscape witnessing a growing adoption of AI-enabled solutions, mostly driven by cost efficiency consideration. There are, however, the first indication of leveraging AI to increase the offer portfolio, generating more revenues. New technologies supporting AI in the small, embedded AI and distributed AI come handy in leveraging those data. A concurrent push of the Italian Government to foster AI and to promote standardization and sharing of data (GAIA-X initiative—Italian Regional Hub) will provide further steam to the increased adoption of AI. The paper is structured in the following sections: “Introduction”, “Trends in AI adoption in the industrial context”, “An AI Policy for Italy: commenting on the Italian AI Strategy”, “Future Scenarios” providing a pessimistic, realistic and optimistic views, “Conclusions”.",
        "DOI": "10.1007/s44163-022-00025-5",
        "paper_author": "Saracco R.",
        "affiliation_name": "IEEE",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60000251",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "The importance of humanizing AI: using a behavioral lens to bridge the gaps between humans and machines",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "13",
        "cover_date": "2022-12-01",
        "Abstract": "One of the biggest challenges in Artificial Intelligence (AI) development and application is the lack of consideration for human enhancement as a cornerstone for its operationalization. Nor is there a universally accepted approach that guides best practices in this field. However, the behavioral science field offers suggestions on how to develop a sustainable and enriching relationship between humans and intelligent machines. This paper provides a three-level (micro, meso and macro) framework on how to humanize AI with the intention of enhancing human properties and experiences. It argues that humanizing AI will help make intelligent machines not just more efficient but will also make their application more ethical and human-centric. Suggestions to policymakers, organizations, and developers are made on how to implement this framework to fix existing issues in AI and create a more symbiotic relationship between humans and machines moving into the future.",
        "DOI": "10.1007/s44163-022-00030-8",
        "paper_author": "Fenwick A.",
        "affiliation_name": "Hult International Business School, Dubai",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates",
        "affiliation_id": "60113233",
        "affiliation_state": "Dubai"
    },
    {
        "paper_title": "The Metaverse as a virtual form of data-driven smart cities: the ethics of the hyper-connectivity, datafication, algorithmization, and platformization of urban society",
        "publication": "Computational Urban Science",
        "citied_by": "98",
        "cover_date": "2022-12-01",
        "Abstract": "Recent advances in computing and immersive technologies have provided Meta (formerly Facebook) with the opportunity to leapfrog or expedite its way of thinking and devising a global computing platform called the “Metaverse”. This hypothetical 3D network of virtual spaces is increasingly shaping alternatives to the imaginaries of data-driven smart cities, as it represents ways of living in virtually inhabitable cities. At the heart of the Metaverse is a computational understanding of human users’ cognition, emotion, motivation, and behavior that reduces the experience of everyday life to logic and calculative rules and procedures. This implies that human users become more knowable and manageable and their behavior more predictable and controllable, thereby serving as passive data points feeding the AI and analytics system that they have no interchange with or influence on. This paper examines the forms, practices, and ethics of the Metaverse as a virtual form of data-driven smart cities, paying particular attention to: privacy, surveillance capitalism, dataveillance, geosurveillance, human health and wellness, and collective and cognitive echo-chambers. Achieving this aim will provide the answer to the main research question driving this study: What ethical implications will the Metaverse have on the experience of everyday life in post-pandemic urban society? In terms of methodology, this paper deploys a thorough review of the current status of the Metaverse, urban informatics, urban science, and data-driven smart cities literature, as well as trends, research, and developments. We argue that the Metaverse will do more harm than good to human users due to the massive misuse of the hyper-connectivity, datafication, algorithmization, and platformization underlying the associated global architecture of computer mediation. It follows that the Metaverse needs to be re-cast in ways that re-orientate in how users are conceived; recognize their human characteristics; and take into account the moral values and principles designed to realize the benefits of socially disruptive technologies while mitigating their pernicious effects. This paper contributes to the academic debates in the emerging field of data-driven smart urbanism by highlighting the ethical implications posed by the Metaverse as speculative fiction that illustrates the concerns raised by the pervasive and massive use of advanced technologies in data-driven smart cities. In doing so, it seeks to aid policy-makers in better understanding the pitfalls of the Metaverse and their repercussions upon the wellbeing of human users and the core values of urban society. It also stimulates prospective research and further critical perspectives on this timely topic.",
        "DOI": "10.1007/s43762-022-00050-1",
        "paper_author": "Bibri S.E.",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway",
        "affiliation_id": "60013141",
        "affiliation_state": "Trondelag"
    },
    {
        "paper_title": "The Impact of Artificial Intelligence (AI) on the Low-Carbon Economy: A Prospective Study on the Long-Term Rental Housing Market in Guangxi, China",
        "publication": "Chinese Journal of Urban and Environmental Studies",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "In recent years, the tourism economy of Guangxi Zhuang Autonomous Region (hereinafter referred to as \"Guangxi\"), China, has been caught in the contradiction between infrastructure construction and natural environmental protection. By combing Guangxi's tourism economy with its development path of smart long-term rental housing, this paper finds that the long-term rental market in Guangxi based on artificial intelligence (AI) technology can solve the development contradiction through accurate construction planning to improve efficiency. The long-term rental housing market in Guangxi has entered a low-carbon economy period since pilot programs were launched for the policy of managing public rental housing with AI and information technologies. From the perspective of AI, facts have proved that AI has the ability to re-adjust the competition order of an industry, which not only realizes the low-carbon development of the rental market, but also promotes the industrial upgrading of the tourist industry.",
        "DOI": "10.1142/S2345748122500245",
        "paper_author": "Li D.",
        "affiliation_name": "Universiti Sains Malaysia",
        "affiliation_city": "Minden",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60000906",
        "affiliation_state": "Penang"
    },
    {
        "paper_title": "A Study on Establishing the Strategies for Integrated Management and Utilization of Disaster &amp; Safety Research Data",
        "publication": "Korean Journal of Remote Sensing",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "With the increase of data and the development of AI technology, the strategies and policies related to integrated data are being actively established to increase the usability of data all over the world. Recently, in the research field, infrastructure projects and management systems are being prepared to utilize research data at the initiative of the government. Also, in Korea, platforms for searching and sharing research data are being actively developed. The National Disaster Management Research Institute (NDMI) has been conducting extensive research on disaster & safety as a national institute, but data-oriented management and utilization are insufficient. Because it still lacks consistent data management systems, metadata for outcomes of research, experts on data and policies for utilization of data to research. In order to move to the data-based research paradigm, we defined the master plans and verified a target model for the integrated management and utilization of disaster & safety research data. In this study, we found out the need to establish differentiated data governance, such as data standardization and unification of the data management system, and dedicated organization for managing data, based on the necessity and actual demands of NDMI. In order to verify the effectiveness of the target model reflecting the derived implications, we intend to establish a pilot mode. In the future, major improvement measures to establish a disaster & safety research data management system will be implement.",
        "DOI": "10.7780/kjrs.2022.38.6.3.4",
        "paper_author": "Ryu S.H.",
        "affiliation_name": "National Disaster Management Research Institute",
        "affiliation_city": "Ulsan",
        "affiliation_country": "South Korea",
        "affiliation_id": "129008067",
        "affiliation_state": "Ulsan"
    },
    {
        "paper_title": "AI and Redistricting: Useful Tool for the Courts or Another Source of Obfuscation?",
        "publication": "Forum (Germany)",
        "citied_by": "0",
        "cover_date": "2022-12-01",
        "Abstract": "Redistricting is a politically fraught exercise. Recently, new technology has emerged that has the potential to improve the redistricting process by providing information to aid in judicial oversight. These scientific advances create the potential to improve societal governance but are also potentially manipulable by partisan interests. To avoid these negative externalities, we must thoughtfully design the processes, implement safeguards, and have clear policies that regulate and steer the emerging AI toward democratically favorable goals. We propose institutional changes toward these aims.",
        "DOI": "10.1515/for-2022-2061",
        "paper_author": "Cho W.K.T.",
        "affiliation_name": "University of Illinois Urbana-Champaign",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States",
        "affiliation_id": "60000745",
        "affiliation_state": "IL"
    },
    {
        "paper_title": "Factors Affecting Artificial Intelligence and Management of Institutional Response to the Event of Coronavirus in Pakistan",
        "publication": "Pertanika Journal of Social Sciences and Humanities",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "With millions of people segregating around the globe, Coronavirus stands truly a global event. It ranges to the trajectories of states with miserable and wrecked health care systems. The transmission is aided by the wide-ranging response from the policy planning and state organizations. Experts are aware of the sternness and contamination of the infectious disease and its disastrous consequences that desire for inoculation of Artificial Intelligence (AI). The absence of an AI policy rejoinder may lead to increased fatalities for weathering the storm. Despite the wide range of responses, the up-to-date policy needs an organized way to track the inflexibility of state-run organizations’ frameworks to attain the objectives of AI organizational policy response. The study’s objectives include including key national institutions to understand perceptions and motivations to challenge the event of COVID-19 through common grounds of Artificial Intelligence. The data is obtained through an online survey from the foreign office, health care services, inter-coordination ministries, and science and technology ministry. The paper has unfolded the useless directions, impractical steps, uncertainty, ineffective communication, and social protection, which led to the rapid spread of infection. Refining each health indicator and reducing the progression of the pandemic through the AI archetype is conceivable only when officialdoms employ the AI-based approach.",
        "DOI": "10.47836/pjssh.30.4.01",
        "paper_author": "Sumra K.B.",
        "affiliation_name": "COMSATS University Islamabad",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60089631",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A New Framework for Winter Wheat Yield Prediction Integrating Deep Learning and Bayesian Optimization",
        "publication": "Agronomy",
        "citied_by": "25",
        "cover_date": "2022-12-01",
        "Abstract": "Early prediction of winter wheat yield at the regional scale is essential for food policy making and food security, especially in the context of population growth and climate change. Agricultural big data and artificial intelligence (AI) are key technologies for smart agriculture, bringing cost-effective solutions to the agricultural sector. Deep learning-based crop yield forecast has currently emerged as one of the key methods for guiding agricultural production. In this study, we proposed a Bayesian optimization-based long- and short-term memory model (BO-LSTM) to construct a multi-source data fusion-driven crop growth feature extraction algorithm for winter wheat yield prediction. The yield prediction performance of BO-LSTM, support vector machine (SVM), and least absolute shrinkage and selection operator (Lasso) was then compared with multi-source data as input variables. The results showed that effective deep learning hyperparameter optimization is made possible by Bayesian optimization. The BO-LSTM (RMSE = 177.84 kg/ha, R2 = 0.82) model had the highest accuracy of yield prediction with the input combination of “GPP + Climate + LAI + VIs”. BO-LSTM and SVM (RMSE = 185.7 kg/ha, R2 = 0.80) methods outperformed linear regression Lasso (RMSE = 214.5 kg/ha, R2 = 0.76) for winter wheat yield estimation. There were also differences between machine learning and deep learning, BO-LSTM outperformed SVM. indicating that the BO-LSTM model was more effective at capturing data correlations. In order to further verify the robustness of the BO-LSTM method, we explored the performance estimation performance of BO-LSTM in different regions. The results demonstrated that the BO-LSTM model could obtain higher estimation accuracy in regions with concentrated distribution of winter wheat cultivation and less influence of human factors. The approach used in this study can be expected to forecast crop yields, both in regions with a deficit of data and globally; it can also simply and effectively forecast winter wheat yields in a timely way utilizing publicly available multi-source data.",
        "DOI": "10.3390/agronomy12123194",
        "paper_author": "Di Y.",
        "affiliation_name": "Ministry of Agriculture of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60087826",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Mars Space Exploration and Astronautical Religion in Human Research History: Psychological Countermeasures of Long-Term Astronauts",
        "publication": "Aerospace",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "As the development of science and technology has reached the point where the desire to travel to Mars has become a tangible reality, the physical limits of human movement are also part of the systematic research based on the space environment. The critical issues of radiation, altered gravity, hostile environment, isolation or confinement, and distance from Earth (travel time) are the five major hazards for astronauts during spaceflight. The prepared technology of space medicine is significant for physical health. However, how would the lone space exploration (2.5 to three years) affect the mental conditions of the astronauts? How can the space community keep astronauts safe from psychological obstacles, such as depression, conflict, resentment, bipolar disorder, obsession, and addiction? This paper explores the environmental factors of a healthy lifestyle (well-being) of the spacecraft. It presumes that a successful mission often relies on positive interactions between crew members and between the crew and ground personnel. The paper considers the mental sustainability from stress, emotions, and perceptions to improve human tonicity or vitality and argues a new mental strategy in space exploration policy that the role of an astronautical religion beyond human intelligence and artificial intelligence (AI) could be a psychiatric anchor (in a moral, ethical, and self-sacrificial context) of each astronaut and leadership of the space team as a psychoanalytical countermeasure, along with physical exercise, hobbies, pets, and virtual and augmented reality (VR/AR) entertainment, especially in the case of unexpected crises where science and technology fail its general function.",
        "DOI": "10.3390/aerospace9120814",
        "paper_author": "Kim D.W.",
        "affiliation_name": "The Australian National University",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia",
        "affiliation_id": "60008950",
        "affiliation_state": "ACT"
    },
    {
        "paper_title": "Human Decision-making in an Artificial Intelligence–Driven Future in Health: Protocol for Comparative Analysis and Simulation",
        "publication": "JMIR Research Protocols",
        "citied_by": "0",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Health care can broadly be divided into two domains: clinical health services and complex health services (ie, nonclinical health services, eg, health policy and health regulation). Artificial intelligence (AI) is transforming both of these areas. Currently, humans are leaders, managers, and decision makers in complex health services. However, with the rise of AI, the time has come to ask whether humans will continue to have meaningful decision-making roles in this domain. Further, rationality has long dominated this space. What role will intuition play? Objective: The aim is to establish a protocol of protocols to be used in the proposed research, which aims to explore whether humans will continue in meaningful decision-making roles in complex health services in an AI-driven future. Methods: This paper describes a set of protocols for the proposed research, which is designed as a 4-step project across two phases. This paper describes the protocols for each step. The first step is a scoping review to identify and map human attributes that influence decision-making in complex health services. The research question focuses on the attributes that influence human decision-making in this context as reported in the literature. The second step is a scoping review to identify and map AI attributes that influence decision-making in complex health services. The research question focuses on attributes that influence AI decision-making in this context as reported in the literature. The third step is a comparative analysis: a narrative comparison followed by a mathematical comparison of the two sets of attributes—human and AI. This analysis will investigate whether humans have one or more unique attributes that could influence decision-making for the better. The fourth step is a simulation of a nonclinical environment in health regulation and policy into which virtual human and AI decision makers (agents) are introduced. The virtual human and AI will be based on the human and AI attributes identified in the scoping reviews. The simulation will explore, observe, and document how humans interact with AI, and whether humans are likely to compete, cooperate, or converge with AI. Results: The results will be presented in tabular form, visually intuitive formats, and—in the case of the simulation—multimedia formats. Conclusions: This paper provides a road map for the proposed research. It also provides an example of a protocol of protocols for methods used in complex health research. While there are established guidelines for a priori protocols for scoping reviews, there is a paucity of guidance on establishing a protocol of protocols. This paper takes the first step toward building a scaffolding for future guidelines in this regard. International Registered Report Identifier (IRRID): PRR1-10.2196/42353",
        "DOI": "10.2196/42353",
        "paper_author": "Doreswamy N.",
        "affiliation_name": "Independent Scholar",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia",
        "affiliation_id": "123434951",
        "affiliation_state": "ACT"
    },
    {
        "paper_title": "A Real-Time Energy Consumption Minimization Framework for Electric Vehicles Routing Optimization Based on SARSA Reinforcement Learning",
        "publication": "Vehicles",
        "citied_by": "15",
        "cover_date": "2022-12-01",
        "Abstract": "A real-time, metadata-driven electric vehicle routing optimization to reduce on-road energy requirements is proposed in this work. The proposed strategy employs the state–action–reward–state–action (SARSA) algorithm to learn the EV’s maximum travel policy as an agent. As a function of the received reward signal, the policy model evaluates the optimal behavior of the agent. Markov chain models (MCMs) are used to estimate the agent’s energy requirements on the road, in which a single Markov step represents the average energy consumption based on practical driving conditions, including driving patterns, road conditions, and restrictions that may apply. A real-time simulation in Python with TensorFlow, NumPy, and Pandas library requirements was run, considering real-life driving data for two EVs trips retrieved from Google’s API. The two trips started at 4.30 p.m. on 11 October 2021, in Los Angeles, California, and Miami, Florida, to reach EV charging stations six miles away from the starting locations. According to simulation results, the proposed AI-based energy minimization framework reduces the energy requirement by 11.04% and 5.72%, respectively. The results yield lower energy consumption compared with Google’s suggested routes and previous work reported in the literature using the DDQN algorithm.",
        "DOI": "10.3390/vehicles4040062",
        "paper_author": "Aljohani T.M.",
        "affiliation_name": "Taibah University",
        "affiliation_city": "Medina",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60008920",
        "affiliation_state": "Al Madinah al Munawwarah"
    },
    {
        "paper_title": "Reducing Children’s Obesity in the Age of Telehealth and AI/IoT Technologies in Gulf Countries",
        "publication": "Systems",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Childhood obesity has become one of the major health issues in the global population. The increasing prevalence of childhood obesity is associated with serious health issues and comorbidities related to obesity. Several studies mentioned that childhood obesity became even worse recently due to the effect of COVID-19 and the consequent policies and regulations. For that reason, Internet of Things (IoT) technologies should be utilized to overcome the challenges related to obesity management and provide care from a distance to improve the health care services for obesity. However, IoT by itself is a limited resource and it is important to consider other artificial intelligent (AI) components. Thus, this paper contributes into the literature of child obesity management by introducing a comprehensive survey for obesity management covering clinical work measuring the association between sleep disturbances and childhood obesity alongside physical activity and diet and comparatively analyzing the emerging technologies used to prevent childhood obesity. It further contributes to the literature by proposing an interactive smart framework that combines clinical and emerging AI/telehealth technologies to manage child obesity. The proposed framework can be used to reduce children obesity and improve their quality of life using Machine Learning (ML). It utilizes IoT devices to integrate information from different sources and complement it with a mobile application and web-based platform to connect parents and physicians with their child.",
        "DOI": "10.3390/systems10060241",
        "paper_author": "Faisal M.",
        "affiliation_name": "Kuwait College of Science &amp; Technology",
        "affiliation_city": "Doha",
        "affiliation_country": "Kuwait",
        "affiliation_id": "60121848",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Model-Free Deep Recurrent Q-Network Reinforcement Learning for Quantum Circuit Architectures Design",
        "publication": "Quantum Reports",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "Artificial intelligence (AI) technology leads to new insights into the manipulation of quantum systems in the Noisy Intermediate-Scale Quantum (NISQ) era. Classical agent-based artificial intelligence algorithms provide a framework for the design or control of quantum systems. Traditional reinforcement learning methods are designed for the Markov Decision Process (MDP) and, hence, have difficulty in dealing with partially observable or quantum observable decision processes. Due to the difficulty of building or inferring a model of a specified quantum system, a model-free-based control approach is more practical and feasible than its counterpart of a model-based approach. In this work, we apply a model-free deep recurrent Q-network (DRQN) reinforcement learning method for qubit-based quantum circuit architecture design problems. This paper is the first attempt to solve the quantum circuit design problem from the recurrent reinforcement learning algorithm, while using discrete policy. Simulation results suggest that our long short-term memory (LSTM)-based DRQN method is able to learn quantum circuits for entangled Bell–Greenberger–Horne–Zeilinger (Bell–GHZ) states. However, since we also observe unstable learning curves in experiments, suggesting that the DRQN could be a promising method for AI-based quantum circuit design application, more investigation on the stability issue would be required.",
        "DOI": "10.3390/quantum4040027",
        "paper_author": "Sogabe T.",
        "affiliation_name": "The University of Electro-Communications",
        "affiliation_city": "Chofu",
        "affiliation_country": "Japan",
        "affiliation_id": "60032315",
        "affiliation_state": "Tokyo"
    },
    {
        "paper_title": "Adaptive Distributed Parallel Training Method for a Deep Learning Model Based on Dynamic Critical Paths of DAG",
        "publication": "Mathematics",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "AI provides a new method for massive simulated data calculations in molecular dynamics, materials, and other scientific computing fields. However, the complex structures and large-scale parameters of neural network models make them difficult to develop and train. The automatic parallel technology based on graph algorithms is one of the most promising methods to solve this problem, despite the low efficiency in the design, implementation, and execution of distributed parallel policies for large-scale neural network models. In this paper, we propose an adaptive distributed parallel training method based on the dynamic generation of critical DAG (directed acyclic graph) paths, called FD-DPS, to solve this efficiency problem. Firstly, the proposed model splits operators with the dimension of the tensor, which can expand the space available for model parallelism. Secondly, a dynamic critical path generation method is employed to determine node priority changes in the DAG of the neural network models. Finally, the model implements the optimal scheduling of critical paths based on the priority of the nodes, thereby improving the performance of parallel strategies. Our experiments show that FD-DPS can achieve 12.76% and 11.78% faster training on PnasNet_mobile and ResNet_200 models, respectively, compared with the MP-DPS and Fast methods.",
        "DOI": "10.3390/math10244788",
        "paper_author": "Zeng Y.",
        "affiliation_name": "Hangzhou Dianzi University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60013614",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Variance Analysis in China’s Coal Mine Accident Studies Based on Data Mining",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "The risk of coal mine accidents rises significantly with mining depth, making it urgent for accident prevention to be supported by both scientific analysis and advanced technologies. Hence, a comprehensive grasp of the research progress and differences in hotspots of coal mine accidents in China serves as a guide to find the shortcomings of studies in the field, promote the effectiveness of coal mine disaster management, and enhance the prevention and control ability of coal mine accidents. This paper analyzes Chinese and foreign literature based on data mining algorithms (LSI + Apriori), and the findings indicate that: (1) 99% of the available achievements are published in Chinese or English-language journals, with the research history conforming to the stage of Chinese coal industry development, which is characterized by “statistical description, risk evaluation, mechanism research, and intelligent reasoning”. (2) Chinese authors are the primary contributors that lead and contribute to the continued development of coal mine accident research in China globally. Over 81% of the authors and over 60% of the new authors annually are from China. (3) The emphasis of the Chinese and English studies is different. Specifically, the Chinese studies focus on the analysis of accident patterns and causes at the macroscale, while the English studies concentrate on the occupational injuries of miners at the small-scale and the mechanism of typical coal mine disasters (gas and coal spontaneous combustion). (4) The research process in Chinese is generally later than that in English due to the joint influence of the target audience, industrial policy, and scientific research evaluation system. After 2018, the Chinese studies focus significantly on AI technology in deep mining regarding accident rules, regional variation analysis, risk monitoring and early warning, as well as knowledge intelligence services, while the hotspots of English studies remain unchanged. Furthermore, both Chinese and English studies around 2019 focus on “public opinion”, with Chinese ones focusing on serving the government to guide the correct direction of public opinion while English studies focus on critical research of news authenticity and China’s safety strategy.",
        "DOI": "10.3390/ijerph192416582",
        "paper_author": "Zhou T.",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60031150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Correction: “Autonomous weapons” as a geopolitical signifier in a national power play: analysing AI imaginaries in Chinese and US military policies (European Journal of Futures Research, (2022), 10, 1, (20), 10.1186/s40309-022-00202-w)",
        "publication": "European Journal of Futures Research",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Following publication of the original article [1], the authors reported some major and minor editing and formatting errors. 1. Jascha Bareis ’ email address has been corrected to \"jascha. bareis@ kit. edu\". 2. The level of sections and subsection headings has been corrected. 3. Table 1 caption has been corrected to \"Overview of published CCW standpoint papers and governmental documents concerning LAWS of the USA and China 2011– 2022\". 4. In the online version, space added after each reference number into \"...authors regarding “meaningful human control” [24, 68, 69, 70, 71, 72], it simultaneousl...\". 5. In-text referencing sections has been corrected such as \"Technological definition: United States of America\" and \"Military Doctrine: China\". The original article has been updated.",
        "DOI": "10.1186/s40309-022-00212-8",
        "paper_author": "Bächle T.C.",
        "affiliation_name": "Alexander von Humboldt Institute for Internet and Society",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "116367687",
        "affiliation_state": "Berlin"
    },
    {
        "paper_title": "Improving quality control in the routine practice for histopathological interpretation of gastrointestinal endoscopic biopsies using artificial intelligence",
        "publication": "PLoS ONE",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "Background Colorectal and gastric cancer are major causes of cancer-related deaths. In Korea, gastrointestinal (GI) endoscopic biopsy specimens account for a high percentage of histopathologic examinations. Lack of a sufficient pathologist workforce can cause an increase in human errors, threatening patient safety. Therefore, we developed a digital pathology total solution combining artificial intelligence (AI) classifier models and pathology laboratory information system for GI endoscopic biopsy specimens to establish a post-analytic daily fast quality control (QC) system, which was applied in clinical practice for a 3-month trial run by four pathologists. Methods and findings Our whole slide image (WSI) classification framework comprised patch-generator, patchlevel classifier, and WSI-level classifier. The classifiers were both based on DenseNet (Dense Convolutional Network). In laboratory tests, the WSI classifier achieved accuracy rates of 95.8% and 96.0% in classifying histopathological WSIs of colorectal and gastric endoscopic biopsy specimens, respectively, into three classes (Negative for dysplasia, Dysplasia, and Malignant). Classification by pathologic diagnosis and AI prediction were compared and daily reviews were conducted, focusing on discordant cases for early detection of potential human errors by the pathologists, allowing immediate correction, before the pathology report error is conveyed to the patients. During the 3-month AI-assisted daily QC trial run period, approximately 7-10 times the number of slides compared to that in the conventional monthly QC (33 months) were reviewed by pathologists; nearly 100% of GI endoscopy biopsy slides were double-checked by the AI models. Further, approximately 17-30 times the number of potential human errors were detected within an average of 1.2 days. Conclusions The AI-assisted daily QC system that we developed and established demonstrated notable improvements in QC, in quantitative, qualitative, and time utility aspects. Ultimately, we developed an independent AI-assisted post-analytic daily fast QC system that was clinically applicable and influential, which could enhance patient safety.",
        "DOI": "10.1371/journal.pone.0278542",
        "paper_author": "Ko Y.S.",
        "affiliation_name": "Seegene Medical Foundation",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "127066701",
        "affiliation_state": "Seoul"
    },
    {
        "paper_title": "Multi-scale governance and data for sustainable development",
        "publication": "Frontiers in Big Data",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Future societal systems will be characterized by heterogeneous human behaviors and data-driven collective action. Complexity will arise as a consequence of the 5th Industrial Revolution and 2nd Data Revolution possible, thanks to a new generation of digital systems and the Metaverse. These technologies will enable new computational methods to tackle inequality while preserving individual rights and self-development. In this context, we do not only need data innovation and computational science, but also new forms of digital policy and governance. The emerging fragility or robustness of the system will depend on how complexity and governance are developed. Through data, humanity has been able to study a number of multi-scale systems from biological to migratory. Multi-scale governance is the new paradigm that feeds the Data Revolution in a world that would be highly digitalized. In the social dimension, we will encounter meta-populations sharing economy and human values. In the temporal dimension, we still need to make all real-time response, evaluation, and mitigation systems a standard integrated system into policy and governance to build up a resilient digital society. Top-down governance is not sufficient to manage all the complexities and exploit all the data available. Coordinating top-down agencies with bottom-up digital platforms will be the design principle. Digital platforms have to be built on top of data innovation and implement Artificial Intelligence (AI)-driven systems to connect, compute, collaborate, and curate data to implement data-driven policy for sustainable development based on Collective Intelligence.",
        "DOI": "10.3389/fdata.2022.1025256",
        "paper_author": "Pastor-Escuredo D.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022148",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Simulating the profitability of male-sexed semen use in extensively farmed beef cow herds",
        "publication": "Livestock Science",
        "citied_by": "0",
        "cover_date": "2022-12-01",
        "Abstract": "Male-sexed semen can be used in beef cow herds to increase the number of heavier and faster-growing male offspring. The use of sexed semen requires artificial insemination (AI) which has limited use in extensive beef systems due to practical constraints and the additional breeding costs incurred. The objective of this study was to use bio-economic simulation modelling to predict the profitability of using sexed semen via fixed time AI for a New Zealand hill country farm system based around a beef cow herd. When modelling self-replacing Angus herds male-sexed Simmental semen was utilised across 43% of mixed-age cows then follow up Simmental bulls were used for subsequent natural mating. To generate replacement Angus heifers, first time calvers and remaining mixed-age cows were bred with unsexed Angus semen and then naturally bred with Angus bulls if they did not conceive. All mixed-age cows in an AngusxHolstein-Friesian herd with a bought-in replacements policy were bred with male-sexed Simmental semen followed by Simmental bulls. First time AngusxHolstein-Friesian calvers were bred with unsexed Angus semen followed by Angus bulls. Sire breed was assumed to have the same effects on offspring production regardless of use through AI or natural mating. Herds using sexed semen were assumed to undergo synchronised fixed-time AI which resulted in a more condensed calving spread and 3% heavier average weaning weights due to calves being predominantly male and on average seven days older. Total breeding costs were higher for herds using sexed semen via AI at NZD 135-166 /cow compared with NZD 67-102 /cow for herds using only natural mating. Increases in breeding costs were relatively larger than any additional income for all herds using sexed semen via AI, resulting in lower COS (cash operating surplus) compared with herds using all-natural mating. The COS of using sexed semen via AI were 14% (COS = NZD 280 /ha) and 9% (COS = NZD 405 /ha) lower than all-natural mating using Simmental sires for the purebred Angus (COS = NZD 325 /ha) and AngusxHolstein-Friesian crossbred (COS = NZD 444 /ha) cow herds, respectively. It appears producing more fast-growing male calves through use of sexed semen via AI is not currently an economically feasible option for beef producers under extensive production systems. Future analysis could include benefits of access to higher genetic merit sires as the combination of superior genes and more male offspring may be more profitable than all-natural mating.",
        "DOI": "10.1016/j.livsci.2022.105107",
        "paper_author": "Farrell L.J.",
        "affiliation_name": "DairyNZ Limited",
        "affiliation_city": "Hamilton",
        "affiliation_country": "New Zealand",
        "affiliation_id": "60093399",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Grid-Based Essential Urban Land Use Classification: A Data and Model Driven Mapping Framework in Xiamen City",
        "publication": "Remote Sensing",
        "citied_by": "5",
        "cover_date": "2022-12-01",
        "Abstract": "Accurate and timely mapping of essential urban land use categories (EULUC) is vital to understanding urban land use distribution, pattern, and composition. Recent advances in leveraging big open data and machine learning algorithms have demonstrated the possibility of large-scale mapping of EULUC in a new cost-effective way. However, they are still limited by the transferability of samples, models, and classification results across space, particularly across different cities. Given the heterogeneities of environmental and socioeconomic conditions among cities, in-depth studies of data and model adaptation towards city-specific EULUC mappings are highly required to support policy making, and urban renewal planning and management practices. In addition, the trending need for timely and detailed small land unit data processing with finer data granularity becomes increasingly important. We proposed a City Meta Unit (CMU) data model and classification framework driven by multisource data and artificial intelligence (AI) algorithms to address these challenges. The CMU Framework was innovatively applied to systematically set up a grid-based data model and classify urban land use with an improved AI algorithm by applying Moore neighborhood correlations. Specifically, we selected Xiamen, Fujian, in China, a coastal city, as the typical testbed to implement this proposed framework and apply an AI transfer learning technique for grid and parcel land-use study. Experimental results with our proposed CMU framework showed that the grid-based land use classification performance achieves overall accuracies of 81.17% and 76.55% for level I (major classes) and level II (minor classes), which is much higher than the parcel-based land use classification (overall accuracies of 72.37% for level I, and 68.99% for level II). We further investigated the relationship between training sample size and classification performance and quantified the contribution of different data sources to urban land use classifications. The CMU framework makes data collections and processing intelligent and efficient, with finer granularity, saving time and cost by using existing open social data. Incorporating the CMU framework with the proposed grid-based model is an effective and new approach for urban land use classification, which can be flexibly extended and applied to various cities.",
        "DOI": "10.3390/rs14236143",
        "paper_author": "Wang X.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial Intelligence Implementation in Healthcare: A Theory-Based Scoping Review of Barriers and Facilitators",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "43",
        "cover_date": "2022-12-01",
        "Abstract": "There is a large proliferation of complex data-driven artificial intelligence (AI) applications in many aspects of our daily lives, but their implementation in healthcare is still limited. This scoping review takes a theoretical approach to examine the barriers and facilitators based on empirical data from existing implementations. We searched the major databases of relevant scientific publications for articles related to AI in clinical settings, published between 2015 and 2021. Based on the theoretical constructs of the Consolidated Framework for Implementation Research (CFIR), we used a deductive, followed by an inductive, approach to extract facilitators and barriers. After screening 2784 studies, 19 studies were included in this review. Most of the cited facilitators were related to engagement with and management of the implementation process, while the most cited barriers dealt with the intervention’s generalizability and interoperability with existing systems, as well as the inner settings’ data quality and availability. We noted per-study imbalances related to the reporting of the theoretic domains. Our findings suggest a greater need for implementation science expertise in AI implementation projects, to improve both the implementation process and the quality of scientific reporting.",
        "DOI": "10.3390/ijerph192316359",
        "paper_author": "Chomutare T.",
        "affiliation_name": "Norwegian Centre for Telemedicine",
        "affiliation_city": "Tromso",
        "affiliation_country": "Norway",
        "affiliation_id": "113532838",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Influence of online opinions and interactions on the Covid-19 vaccination in Chile",
        "publication": "Scientific Reports",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "We analyze 6 months of Twitter conversations related to the Chilean Covid-19 vaccination process, in order to understand the online forces that argue for or against it and suggest effective digital communication strategies. Using AI, we classify accounts into four categories that emerge from the data as a result of the type of language used. This classification naturally distinguishes pro- and anti-vaccine activists from moderates that promote or inhibit vaccination in discussions, which also play a key role that should be addressed by public policies. We find that all categories display relatively constant opinions, but that the number of tweeting accounts grows in each category during controversial periods. We also find that accounts disfavoring vaccination tend to appear in the periphery of the interaction network, which is consistent with Chile’s high immunization levels. However, these are more active in addressing those favoring vaccination than vice-versa, revealing a potential communication problem even in a society where the antivaccine movement has no central role. Our results highlight the importance of social network analysis to understand public discussions and suggest online interventions that can help achieve successful immunization campaigns.",
        "DOI": "10.1038/s41598-022-23738-0",
        "paper_author": "Villegas C.",
        "affiliation_name": "Pontificia Universidad Católica de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile",
        "affiliation_id": "60029681",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Towards Sustainable Fuel Cells and Batteries with an AI Perspective",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "27",
        "cover_date": "2022-12-01",
        "Abstract": "With growing environmental and ecological concerns, innovative energy storage systems are urgently required to develop smart grids and electric vehicles (EVs). Since their invention in the 1970s, rechargeable lithium-ion batteries (LIBs) have risen as a revolutionary innovation due to their superior benefits of high operating potential and energy density. Similarly, fuel cells, especially Proton Exchange Membrane Fuel Cells (PEMFC) and Solid-Oxide Fuel Cells (SOFC), have been developed as an energy storage system for EVs due to their compactness and high-temperature stability, respectively. Various attempts have been made to explore novel materials to enhance existing energy storage technologies. Materials design and development are significantly based on trial-and-error techniques and require substantial human effort and time. Additionally, researchers work on individual materials for specific applications. As a viewpoint, we present the available sustainable routes for electrochemical energy storage, highlighting the use of (i) green materials and processes, (ii) renewables, (iii) the circular economy approach, (iv) regulatory policies, and (v) the data driven approach to find the best materials from several databases with minimal human involvement and time. Finally, we provide an example of a high throughput and machine learning assisted approach for optimizing the properties of several sustainable carbon materials and applying them to energy storage devices. This study can prompt researchers to think, advance, and develop opportunities for future sustainable materials selection, optimization, and application in various electrochemical energy devices utilizing ML.",
        "DOI": "10.3390/su142316001",
        "paper_author": "Ramasubramanian B.",
        "affiliation_name": "National University of Singapore",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60017161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Earth Observation and Artificial Intelligence: Understanding emerging ethical issues and opportunities",
        "publication": "IEEE Geoscience and Remote Sensing Magazine",
        "citied_by": "28",
        "cover_date": "2022-12-01",
        "Abstract": "Ethics is a central and growing concern in all applications utilizing artificial intelligence (AI). Earth observation (EO) and remote sensing (RS) research relies heavily on both big data and AI or machine learning (ML). While this reliance is not new, with increasing image resolutions and the growing number of EO/RS use cases that have a direct impact on governance, policy, and the lives of people, ethical issues are taking center stage. In this article, we provide scientists engaged with AI for EO (AI4EO) research, 1) a practically useful overview of the key ethical issues emerging in this field, with concrete examples from within EO/RS to explain these issues, and 2) a first road map (flowchart) that scientists can use to identify ethical issues in their ongoing research. With this, we aim to sensitize scientists to these issues and create a bridge to facilitate constructive and regular communication among scientists engaged in AI4EO research, on the one hand, and ethics research, on the other hand. The article also provides detailed illustrations from four AI4EO research fields to explain how scientists can redesign research questions to more effectively grab ethical opportunities to address real-world problems that are otherwise akin to ethical dilemmas with no win-win solution in sight. The article concludes by providing recommendations to institutions that want to support ethically mindful AI4EO research and provides suggestions for future research in this field.",
        "DOI": "10.1109/MGRS.2022.3208357",
        "paper_author": "Kochupillai M.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Priorities for successful use of artificial intelligence by public health organizations: a literature review",
        "publication": "BMC Public Health",
        "citied_by": "45",
        "cover_date": "2022-12-01",
        "Abstract": "Artificial intelligence (AI) has the potential to improve public health’s ability to promote the health of all people in all communities. To successfully realize this potential and use AI for public health functions it is important for public health organizations to thoughtfully develop strategies for AI implementation. Six key priorities for successful use of AI technologies by public health organizations are discussed: 1) Contemporary data governance; 2) Investment in modernized data and analytic infrastructure and procedures; 3) Addressing the skills gap in the workforce; 4) Development of strategic collaborative partnerships; 5) Use of good AI practices for transparency and reproducibility, and; 6) Explicit consideration of equity and bias.",
        "DOI": "10.1186/s12889-022-14422-z",
        "paper_author": "Fisher S.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Perspectives of radiographers on the emergence of artificial intelligence in diagnostic imaging in Saudi Arabia",
        "publication": "Insights into Imaging",
        "citied_by": "5",
        "cover_date": "2022-12-01",
        "Abstract": "Objectives: This study aimed to gain insight into radiographers’ views on the application of artificial intelligence (AI) in Saudi Arabia by conducting a qualitative investigation designed to provide recommendations to assist radiographic workforce improvement. Materials and methods: We conducted an online cross-sectional online survey of Saudi radiographers regarding perspectives on AI implementation, job security, workforce development, and ethics. Results: In total, 562 valid responses were received. Most respondents (90.6%) believed that AI was the direction of diagnostic imaging. Among the respondents, 88.5% stated that AI would improve the accuracy of diagnosis. Some challenges in implementing AI in Saudi Arabia include the high cost of equipment, inadequate knowledge, radiologists’ fear of losing employment, and concerns related to potential medical errors and cyber threats. Conclusion: Radiographers were generally positive about introducing AI to radiology departments. To integrate AI successfully into radiology departments, radiographers need training programs, transparent policies, and motivation.",
        "DOI": "10.1186/s13244-022-01319-z",
        "paper_author": "Aldhafeeri F.M.",
        "affiliation_name": "University of Hafr Al-Batin",
        "affiliation_city": "Hafar al Batin",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60110523",
        "affiliation_state": "Ash Sharqiyah"
    },
    {
        "paper_title": "An AI approach for managing financial systemic risk via bank bailouts by taxpayers",
        "publication": "Nature Communications",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "Bank bailouts are controversial governmental decisions, putting taxpayers’ money at risk to avoid a domino effect through the network of claims between financial institutions. Yet very few studies address quantitatively the convenience of government investments in failing banks from the taxpayers’ standpoint. We propose a dynamic financial network framework incorporating bailout decisions as a Markov Decision Process and an artificial intelligence technique that learns the optimal bailout actions to minimise the expected taxpayers’ losses. Considering the European global systemically important institutions, we find that bailout decisions become optimal only if the taxpayers’ stakes exceed some critical level, endogenously determined by all financial network’s characteristics. The convenience to intervene increases with the network’s distress, taxpayers’ stakes, bank bilateral credit exposures and crisis duration. Moreover, the government should optimally keep bailing-out banks that received previous investments, creating moral hazard for rescued banks that could increase their risk-taking, reckoning on government intervention.",
        "DOI": "10.1038/s41467-022-34102-1",
        "paper_author": "Petrone D.",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022109",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ischemic stroke of unclear aetiology: a case-by-case analysis and call for a multi-professional predictive, preventive and personalised approach",
        "publication": "EPMA Journal",
        "citied_by": "32",
        "cover_date": "2022-12-01",
        "Abstract": "Due to the reactive medical approach applied to disease management, stroke has reached an epidemic scale worldwide. In 2019, the global stroke prevalence was 101.5 million people, wherefrom 77.2 million (about 76%) suffered from ischemic stroke; 20.7 and 8.4 million suffered from intracerebral and subarachnoid haemorrhage, respectively. Globally in the year 2019 — 3.3, 2.9 and 0.4 million individuals died of ischemic stroke, intracerebral and subarachnoid haemorrhage, respectively. During the last three decades, the absolute number of cases increased substantially. The current prevalence of stroke is 110 million patients worldwide with more than 60% below the age of 70 years. Prognoses by the World Stroke Organisation are pessimistic: globally, it is predicted that 1 in 4 adults over the age of 25 will suffer stroke in their lifetime. Although age is the best known contributing factor, over 16% of all strokes occur in teenagers and young adults aged 15–49 years and the incidence trend in this population is increasing. The corresponding socio-economic burden of stroke, which is the leading cause of disability, is enormous. Global costs of stroke are estimated at 721 billion US dollars, which is 0.66% of the global GDP. Clinically manifested strokes are only the “tip of the iceberg”: it is estimated that the total number of stroke patients is about 14 times greater than the currently applied reactive medical approach is capable to identify and manage. Specifically, lacunar stroke (LS), which is characteristic for silent brain infarction, represents up to 30% of all ischemic strokes. Silent LS, which is diagnosed mainly by routine health check-up and autopsy in individuals without stroke history, has a reported prevalence of silent brain infarction up to 55% in the investigated populations. To this end, silent brain infarction is an independent predictor of ischemic stroke. Further, small vessel disease and silent lacunar brain infarction are considered strong contributors to cognitive impairments, dementia, depression and suicide, amongst others in the general population. In sub-populations such as diabetes mellitus type 2, proliferative diabetic retinopathy is an independent predictor of ischemic stroke. According to various statistical sources, cryptogenic strokes account for 15 to 40% of the entire stroke incidence. The question to consider here is, whether a cryptogenic stroke is fully referable to unidentifiable aetiology or rather to underestimated risks. Considering the latter, translational research might be of great clinical utility to realise innovative predictive and preventive approaches, potentially benefiting high risk individuals and society at large. In this position paper, the consortium has combined multi-professional expertise to provide clear statements towards the paradigm change from reactive to predictive, preventive and personalised medicine in stroke management, the crucial elements of which are:Consolidation of multi-disciplinary expertise including family medicine, predictive and in-depth diagnostics followed by the targeted primary and secondary (e.g. treated cancer) prevention of silent brain infarctionApplication of the health risk assessment focused on sub-optimal health conditions to effectively prevent health-to-disease transitionApplication of AI in medicine, machine learning and treatment algorithms tailored to robust biomarker patternsApplication of innovative screening programmes which adequately consider the needs of young populations.",
        "DOI": "10.1007/s13167-022-00307-z",
        "paper_author": "Golubnitschaja O.",
        "affiliation_name": "Universitätsklinikum Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany",
        "affiliation_id": "60030465",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Stereotypes, disproportions, and power asymmetries in the visual portrayal of migrants in ten countries: an interdisciplinary AI-based approach",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "13",
        "cover_date": "2022-12-01",
        "Abstract": "The visual portrayal of social groups in media reinforces stereotypes and narratives, potentially leading to discriminatory actions and policies. That is particularly true for underrepresented or stigmatized groups such as migrants and is a phenomenon that varies per country. Therefore, studying the representation of migrants requires analyzing considerable amounts of visual data from different locations. This work addresses that challenge with an interdisciplinary approach characterizing the visual portrayal of migrants using Deep Learning techniques and analyzing results through the lenses of migration and gender studies. Images associated with migrants found on the internet through a search engine and from ten countries are processed to quantify and analyze the demographic and emotional information of the people portrayed. An intersectional approach is employed regarding gender, age, physical features, and emotions. The general group “migrants” is compared with the specific groups “refugees” and “expats”. Results suggest that portrayals predominantly focus on asylum seekers and associate them with poverty and risks for host societies. Moreover, the demographics in the portrayals do not match the official statistics. For expats, an over-representation of “white” and an under-representation of “asian” faces were found, while for migrants and refugees, depictions align with the demographics of low-skilled migrants. Furthermore, results evidence the power struggle underlying the “expat vs. migrant” dichotomy and its inherent colonial nature. The emotions displayed are predominantly negative and align with emotional and gender stereotypes literature. Positive emotions are more associated with women than men, and with expats than refugees and migrants. Previous results regarding the under-representation of migrant women in media are confirmed. Also, women are portrayed as younger than men, and expat women are the youngest. Children appear more in pictures associated with refugees and migrants than with expats. Likewise, migrants are often depicted as crowds, but when that is not the case, migrant and refugee women appear in larger groups than men. A higher proportion of images associated with expats do not contain people. All these effects, however, differ per location. Finally, we suggest future directions and analyze possible limitations of automatic visual content analysis using existing Deep Learning models.",
        "DOI": "10.1057/s41599-022-01430-y",
        "paper_author": "Olier J.S.",
        "affiliation_name": "Tilburg University",
        "affiliation_city": "Tilburg",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60017145",
        "affiliation_state": "Noord-Brabant"
    },
    {
        "paper_title": "Disparities in traumatic brain injury-related deaths—United States, 2020",
        "publication": "Journal of Safety Research",
        "citied_by": "25",
        "cover_date": "2022-12-01",
        "Abstract": "Introduction: Traumatic brain injury (TBI) affects how the brain functions and remains a prominent cause of death in the United States. Although preventable, anyone can experience a TBI and epidemiological research suggests some groups have worse health outcomes following the injury. Methods: We analyzed 2020 multiple-cause-of-death data from the National Vital Statistics System to describe TBI mortality by geography, sociodemographic characteristics, mechanism of injury (MOI), and injury intent. Deaths were included if they listed an injury International Classification of Diseases, Tenth Revision (ICD-10) underlying cause of death code and a TBI-related ICD-10 code in one of the multiple-cause-of-death fields. Results: During 2020, 64,362 TBI-related deaths occurred and age-adjusted rates, per 100,000 population, were highest among persons residing in the South (20.2). Older adults (≥75) displayed the highest number and rate of TBI-related deaths compared with other age groups and unintentional falls and suicide were the leading external causes among this older age group. The age-adjusted rate of TBI-related deaths in males was more than three times the rate of females (28.3 versus 8.4, respectively); further, males displayed higher numbers and age-adjusted rates compared with females for all the principal MOIs that contributed to a TBI-related death. American Indian or Alaska Native, Non-Hispanic (AI/AN) persons had the highest age-adjusted rate (29.0) of TBI-related deaths when compared with other racial and ethnic groups. Suicide was the leading external cause of injury contributing to a TBI-related death among AI/AN persons. Practical application: Prevention efforts targeting older adult falls and suicide are warranted to reduce disparities in TBI mortality among older adults and AI/AN persons. Effective strategies are described in CDC's Stopping Elderly Accidents, Deaths, & Injuries (STEADI) initiative to reduce older adult falls and CDC's Preventing Suicide: A Technical Package of Policy, Programs, and Practices for the best available evidence in suicide prevention.",
        "DOI": "10.1016/j.jsr.2022.10.001",
        "paper_author": "Peterson A.B.",
        "affiliation_name": "National Center for Injury Prevention and Control",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60011584",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Global Catastrophic Risk and the Drivers of Scientist Attitudes Towards Policy",
        "publication": "Science and Engineering Ethics",
        "citied_by": "0",
        "cover_date": "2022-12-01",
        "Abstract": "An anthropogenic global catastrophic risk is a human-induced risk that threatens sustained and wide-scale loss of life and damage to civilisation across the globe. In order to understand how new research on governance mechanisms for emerging technologies might assuage such risks, it is important to ask how perceptions, beliefs, and attitudes towards the governance of global catastrophic risk within the research community shape the conduct of potentially risky research. The aim of this study is to deepen our understanding of emerging technology research culture as it relates to global catastrophic risks, and to shed new light on how new research governance mechanisms might be developed. We analyse in-depth interviews with leading AI and biotech researchers both from universities and the private sector. We develop new insights in terms of four salient themes. First, ‘engineering mindset’, which highlights the premium placed by many interviewees on pursuing interesting research about the physical world for its own sake. Second, ‘self-government’, which looks at how self-regulation of technological development currently occurs. Third, ‘pure incentives’, focussing on how career and other incentives shapes research. Fourth, ‘norms and persuasion’, which examines the role of moral considerations in guiding the research choices of scientists. We end by considering the implications of these findings for future research on governance of anthropogenic global catastrophic risk.",
        "DOI": "10.1007/s11948-022-00411-3",
        "paper_author": "Nathan C.",
        "affiliation_name": "University of Warwick",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022020",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "Does AI Debias Recruitment? Race, Gender, and AI’s “Eradication of Difference”",
        "publication": "Philosophy and Technology",
        "citied_by": "39",
        "cover_date": "2022-12-01",
        "Abstract": "In this paper, we analyze two key claims offered by recruitment AI companies in relation to the development and deployment of AI-powered HR tools: (1) recruitment AI can objectively assess candidates by removing gender and race from their systems, and (2) this removal of gender and race will make recruitment fairer, help customers attain their DEI goals, and lay the foundations for a truly meritocratic culture to thrive within an organization. We argue that these claims are misleading for four reasons: First, attempts to “strip” gender and race from AI systems often misunderstand what gender and race are, casting them as isolatable attributes rather than broader systems of power. Second, the attempted outsourcing of “diversity work” to AI-powered hiring tools may unintentionally entrench cultures of inequality and discrimination by failing to address the systemic problems within organizations. Third, AI hiring tools’ supposedly neutral assessment of candidates’ traits belie the power relationship between the observer and the observed. Specifically, the racialized history of character analysis and its associated processes of classification and categorization play into longer histories of taxonomical sorting and reflect the current demands and desires of the job market, even when not explicitly conducted along the lines of gender and race. Fourth, recruitment AI tools help produce the “ideal candidate” that they supposedly identify through by constructing associations between words and people’s bodies. From these four conclusions outlined above, we offer three key recommendations to AI HR firms, their customers, and policy makers going forward.",
        "DOI": "10.1007/s13347-022-00543-1",
        "paper_author": "Drage E.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031101",
        "affiliation_state": "Cambridgeshire"
    },
    {
        "paper_title": "Artificial intelligence, 21st century competences, and socio-emotional learning in education: More than high-risk?",
        "publication": "European Journal of Education",
        "citied_by": "25",
        "cover_date": "2022-12-01",
        "Abstract": "Over the last two decades, 21st century competences and socio-emotional skills have become a major focus in educational policy. In this article, skills for the 21st century, soft skills, as well as social and emotional skills, are contextualised in the context of technological change, machine learning, and the ethics of artificial intelligence. The use of data-driven AI technologies to model and measure these skills—in this article defined as non-epistemic competence components—can lead to major social challenges that have important implications for educational policies and practices. A moratorium on the use of data on these competence components in machine learning systems is proposed until the society-wide impact is better understood.",
        "DOI": "10.1111/ejed.12531",
        "paper_author": "Tuomi I.",
        "affiliation_name": "Meaning Processing Ltd.",
        "affiliation_city": "Helsinki",
        "affiliation_country": "Finland",
        "affiliation_id": "101379819",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Technology Adoption and Human Resource Management Practices: The Use of Artificial Intelligence for Recruitment in Bangladesh",
        "publication": "South Asian Journal of Human Resources Management",
        "citied_by": "17",
        "cover_date": "2022-12-01",
        "Abstract": "Artificial intelligence (AI) is now considered indispensable in undertaking operational activities, especially in the area of human resource analytics. However, in practice, the rate of the adoption of such modern algorithms in organisations is still in its early stages. Consequently, the primary objective of this study is to identify the main antecedents of the adoption of AI-based technologies in recruitment, using the lens of the unified theory of acceptance and use of technology (UTAUT) model, alongside perceived credibility and moderating variables, in the context of an emerging nation in South Asia, namely Bangladesh. Data were collected from 283 human resource professionals employed in different manufacturing and service firms in Bangladesh through the administration of a questionnaire, which was analysed by applying PLS-SEM. The outcomes of the study show that all the direct hypothesised relationships were found to be significant, apart from the extended variable of perceived credibility. However, no moderating effect of gender or firm size was found in any of the hypothesised propositions. Finally, policy implications and recommendations for future researchers are proposed.",
        "DOI": "10.1177/23220937221122329",
        "paper_author": "Islam M.",
        "affiliation_name": "University of Dhaka",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60014714",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Reflections on the human role in AI policy formulations: how do national AI strategies view people?",
        "publication": "Discover Artificial Intelligence",
        "citied_by": "8",
        "cover_date": "2022-12-01",
        "Abstract": "Purpose: There is no artificial intelligence (AI) without people. People design and develop AI; they modify and use it and they have to reorganize the ways they have carried out tasks in their work and everyday life. National strategies are documents made to describe how different nations foster AI and as human dimensions are such an important aspect of AI, this study sought to investigate major national strategy documents to determine how they view the human role in emerging AI societies. Approach: Our method for analyzing the strategies was conceptual analysis since the development of technology is embedded with conceptual ideas of humanity, explicit or implicit, and in addition to deepening analysis of explicit argumentation the method enables the deconstruction and reconstruction of meanings and conceptual relations within the strategies, exposing presumptions and tacit commitments of the writers. Findings: The analysis of the documents illustrates that the general tendency in national strategies is globally dominantly technology-driven as the state of affairs appears to be creating new technologies. However, various human research points such as usability, user experience, sociotechnical and life-based themes are less well represented. Because national strategies are used to develop innovation processes, we argue that future development of national strategies could be improved by taking human research issues more energetically in the agenda. Originality: Our study elaborates the current trends in AI-policy discourses and discusses reasons and possibilities for more holistic policymaking, making it a valuable resource for policymakers, researchers, and the larger public.",
        "DOI": "10.1007/s44163-022-00019-3",
        "paper_author": "Salo-Pöntinen H.",
        "affiliation_name": "University of Jyväskylä",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland",
        "affiliation_id": "60032398",
        "affiliation_state": "Central Finland"
    },
    {
        "paper_title": "Recent advances in applications of artificial intelligence in solid waste management: A review",
        "publication": "Chemosphere",
        "citied_by": "67",
        "cover_date": "2022-12-01",
        "Abstract": "Efficient management of solid waste is essential to lessen its potential health and environmental impacts. However, the current solid waste management practices encounter several challenges. The development of effective waste management systems using advanced technologies is vital to overcome the challenges faced by the current approaches. Artificial Intelligence (AI) has emerged as a powerful tool for applications in various fields. Several studies also reported the applications of AI techniques in the management of solid waste. This article critically reviews the recent advancements in the applications of AI techniques for the management of solid waste. Various AI and hybrid techniques have been successfully employed to predict the performance of various methods used for the generation, segregation, storage, and treatment of solid waste. The key challenges that limit the applications of AI in solid waste are highlighted. These include the availability and selection of applicable data, poor reproducibility, and less evidence of applications in real solid waste. Based on identified gaps and challenges, recommendations for future work are provided. This review is beneficial for all stakeholders in the field of solid waste management, including policy-makers, governments, waste management organizations, municipalities, and researchers.",
        "DOI": "10.1016/j.chemosphere.2022.136631",
        "paper_author": "Ihsanullah I.",
        "affiliation_name": "King Fahd University of Petroleum and Minerals",
        "affiliation_city": "Dhahran",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60009506",
        "affiliation_state": "Ash Sharqiyah"
    },
    {
        "paper_title": "Public Perceptions on Application Areas and Adoption Challenges of AI in Urban Services",
        "publication": "Emerging Science Journal",
        "citied_by": "39",
        "cover_date": "2022-12-01",
        "Abstract": "Artificial intelligence (AI) deployment is exceedingly relevant to local governments, for example, in planning and delivering urban services. AI adoption in urban services, however, is an understudied area, particularly because there is limited knowledge and hence a research gap on the public's perceptions-users/receivers of these services. This study aims to examine people’s behaviors and preferences regarding the most suited urban services for application of AI technology and the challenges for governments to adopt AI for urban service delivery. The methodological approach includes data collection through an online survey from Australia and Hong Kong and statistical analysis of the data through binary logistic regression modeling. The study finds that: (a) Attitudes toward AI applications and ease of use have significant effects on forming an opinion on AI; (b) initial thoughts regarding the meaning of AI have a significant impact on AI application areas and adoption challenges; (c) perception differences between the two countries in AI application areas are significant; and (d) perception differences between the two countries in government AI adoption challenges are minimal. The study consolidates our understanding of how the public perceives the application areas and adoption challenges of AI, particularly in urban services, which informs local authorities that deploy or plan to adopt AI in their urban services.",
        "DOI": "10.28991/ESJ-2022-06-06-01",
        "paper_author": "Yigitcanlar T.",
        "affiliation_name": "Queensland University of Technology",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60011019",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Blockchain technology and AI-facilitated polymers recycling: Utilization, realities, and sustainability",
        "publication": "Polymer Composites",
        "citied_by": "17",
        "cover_date": "2022-12-01",
        "Abstract": "From the environmental perspective, efficient plastic utilization and its recyclability become significant issues that need to be resolved for deploying urban and sustainable technologies. It is estimated that approximately 400 million tons of plastic are produced each year for different applications. This number will be doubled by 2050, which is a serious problem. The primary issue that arises in a recycling process is associated with optimum supply chain management. The comprehensive and transparent supply chain methodologies will help stockholders to make conclusive policies and precise strategies. Transparency in supply chain management assists in captivating planning, pricing, purchasing, and inventory management decisions. Environmental sustainability requires recycling, which should have innovative concepts like Artificial Intelligence (AI) and Block-chain Technology. Manual methods of sorting and segregating the waste have outdated and not much efficient. The inclusion of AI and Blockchain Technology brought a revolution by increasing the efficiency and accuracy of the recycling process. This critical review focused on recycling plastics and plastic waste using AI and Blockchain Technology. Various plastic regulation policies and AI utilization for plastic recycling are discussed. An overview of the blockchain and its classification for waste management or plastic recycling has been discussed. The utilization of Blockchain Technology for a plastic circular economy, its types, and critical benefits has also been systematically demonstrated.",
        "DOI": "10.1002/pc.27054",
        "paper_author": "Verma D.",
        "affiliation_name": "Chulalongkorn University",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand",
        "affiliation_id": "60028190",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "AI, Opacity, and Personal Autonomy",
        "publication": "Philosophy and Technology",
        "citied_by": "23",
        "cover_date": "2022-12-01",
        "Abstract": "Advancements in machine learning have fuelled the popularity of using AI decision algorithms in procedures such as bail hearings, medical diagnoses and recruitment. Academic articles, policy texts, and popularizing books alike warn that such algorithms tend to be opaque: they do not provide explanations for their outcomes. Building on a causal account of transparency and opacity as well as recent work on the value of causal explanation, I formulate a moral concern for opaque algorithms that is yet to receive a systematic treatment in the literature: when such algorithms are used in life-changing decisions, they can obstruct us from effectively shaping our lives according to our goals and preferences, thus undermining our autonomy. I argue that this concern deserves closer attention as it furnishes the call for transparency in algorithmic decision-making with both new tools and new challenges.",
        "DOI": "10.1007/s13347-022-00577-5",
        "paper_author": "Vaassen B.",
        "affiliation_name": "Umeå Universitet",
        "affiliation_city": "Umea",
        "affiliation_country": "Sweden",
        "affiliation_id": "60031040",
        "affiliation_state": "Västerbotten"
    },
    {
        "paper_title": "Integrated explainable deep learning prediction of harmful algal blooms",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "24",
        "cover_date": "2022-12-01",
        "Abstract": "Harmful algal blooms (HABs) can cause serious problems for aquatic ecosystems and human health, as well as massive social costs. Therefore, continuous monitoring and prevention are required. Water quality management is an important task to minimize such algae, and future occurrences can be accurately predicted through optimal water resource management. In this study, we developed a convolutional neural network model using eight water quality variables and four weather variables to predict the concentration of chlorophyll-a in four major Korean rivers. In addition, Deep SHAP was applied to aid in policy decision-making and identify the influence on variables affecting chlorophyll-a. This integrated prediction model showed a 38.01 % reduction in root mean square error and 36.16 % improvement in R-squared compared to the long short-term memory (LSTM) model. This demonstrated the effectiveness of the proposed integrated prediction approach. Furthermore, despite simultaneously predicting HABs at all monitoring stations and training 394 times faster than LSTM-based models, the proposed method exhibited a significant improvement in efficiency and elucidated variable influences that existing models failed to explain. The proposed integrated prediction model can predict HAB spread, identify variable influences to aid decision-makers, and effectively implement preemptive responses, thus reducing economic losses and preserving aquatic ecosystems.",
        "DOI": "10.1016/j.techfore.2022.122046",
        "paper_author": "Lee D.",
        "affiliation_name": "Tech University of Korea",
        "affiliation_city": "Siheung",
        "affiliation_country": "South Korea",
        "affiliation_id": "60068714",
        "affiliation_state": "Gyeonggi-do"
    },
    {
        "paper_title": "Detection and moderation of detrimental content on social media platforms: current status and future directions",
        "publication": "Social Network Analysis and Mining",
        "citied_by": "47",
        "cover_date": "2022-12-01",
        "Abstract": "Social Media has become a vital component of every individual's life in society opening a preferred spectrum of virtual communication which provides an individual with a freedom to express their views and thoughts. While virtual communication through social media platforms is highly desirable and has become an inevitable component, the dark side of social media is observed in form of detrimental/objectionable content. The reported detrimental contents are fake news, rumors, hate speech, aggressive, and cyberbullying which raise up as a major concern in the society. Such detrimental content is affecting person’s mental health and also resulted in loss which cannot be always recovered. So, detecting and moderating such content is a prime need of time. All social media platforms including Facebook, Twitter, and YouTube have made huge investments and also framed policies to detect and moderate such detrimental content. It is of paramount importance in the first place to detect such content. After successful detection, it should be moderated. With an overflowing increase in detrimental content on social media platforms, the current manual method to identify such content will never be enough. Manual and semi-automated moderation methods have reported limited success. A fully automated detection and moderation is a need of time to come up with the alarming detrimental content on social media. Artificial Intelligence (AI) has reached across all sectors and provided solutions to almost all problems, social media content detection and moderation is not an exception. So, AI-based methods like Natural Language Processing (NLP) with Machine Learning (ML) algorithms and Deep Neural Networks is rigorously deployed for detection and moderation of detrimental content on social media platforms. While detection of such content has been receiving good attention in the research community, moderation has received less attention. This research study spans into three parts wherein the first part emphasizes on the methods to detect the detrimental components using NLP. The second section describes about methods to moderate such content. The third part summarizes all observations to provide identified research gaps, unreported problems and provide research directions.",
        "DOI": "10.1007/s13278-022-00951-3",
        "paper_author": "Gongane V.U.",
        "affiliation_name": "Pune Institute of Computer Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India",
        "affiliation_id": "60272084",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "“Autonomous weapons” as a geopolitical signifier in a national power play: analysing AI imaginaries in Chinese and US military policies",
        "publication": "European Journal of Futures Research",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "“Autonomous weapon systems” (AWS) have been subject to intense discussions for years. Numerous political, academic and legal actors are debating their consequences, with many calling for strict regulation or even a global ban. Surprisingly, it often remains unclear which technologies the term AWS refers to and also in what sense these systems can be characterised as autonomous at all. Despite being feared by many, weapons that are completely self-governing and beyond human control are more of a conceptual possibility than an actual military reality. As will be argued, the conflicting interpretations of AWS are largely the result of the diverse meanings that are constructed in political discourses. These interpretations convert specific understandings of AI into strategic assets and consequently hinder the establishment of common ethical standards and legal regulations. In particular, this article looks at the publicly available military AI strategies and position papers by China and the USA. It analyses how AWS technologies, understood as evoking sociotechnical imaginaries, are politicised to serve particular national interests. The article presents the current theoretical debate, which has sought to find a functional definition of AWS that is sufficiently unambiguous for regulatory or military contexts. Approaching AWS as a phenomenon that is embedded in a particular sociotechnical imaginary, however, flags up the ways in which nation states portray themselves as part of a global AI race, competing over economic, military and geopolitical advantages. Nation states do not just enforce their geopolitical ambitions through a fierce realpolitik rhetoric but also play around with ambiguities in definitions. This especially holds true for China and the USA, since they are regarded and regard themselves as hegemonic antagonists, presenting competing self-conceptions that are apparent in their histories, political doctrines and identities. The way they showcase their AI-driven military prowess indicates an ambivalent rhetoric of legal sobriety, tech-regulation and aggressive national dominance. AWS take on the role of signifiers that are employed to foster political legitimacy or to spark deliberate confusion and deterrence.",
        "DOI": "10.1186/s40309-022-00202-w",
        "paper_author": "Bächle T.C.",
        "affiliation_name": "Alexander von Humboldt Institute for Internet and Society",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "116367687",
        "affiliation_state": "Berlin"
    },
    {
        "paper_title": "Changes in temporal pattern and spatial distribution of environmental pollutants in 8 Asian countries owing to COVID-19 pandemic",
        "publication": "Chemosphere",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "This study investigated the changes in air pollutant's concentration, spatio-temporal distribution and sensitivity of changes in air pollutant's concentration during pre and post COVID-19 outbreak. We employed Google Earth Engine Platform to access remote sensing datasets of air pollutants across Asian continent. Air pollution and cumulative confirmed-COVID cases data of Asian countries (Afghanistan, Bangladesh, China, India, Iran, Iraq, Pakistan, and Saudi Arabia) have been collected and analyzed for 2019 and 2020. The results indicate that aerosol index (AI) and nitrogen dioxide (NO2) is significantly reduced during COVID outbreak i.e. in year 2020. In addition, we found significantly positive (P < 0.05, 95% confidence interval, two-tailed) correlation between changes in AI and NO2 concentration for net active-COVID case increment in almost each country. For other atmospheric gases i.e. carbon monoxide (CO), formaldehyde (HCHO), ozone (O3), and Sulfur dioxide (SO2), insignificant and/or significant negative correlation is also observed. These results suggest that the atmospheric concentration of AI and NO2 are good indicators of human activities. Furthermore, the changes in O3 shows significantly negative correlation for net active-COVID case increment. In conclusion, we observed significant positive environmental impact of COVID-19 restrictions in Asia. This study would help and assist environmentalist and policy makers in restraining air pollution by implementing efficient restrictions on human activities with minimal economic loss.",
        "DOI": "10.1016/j.chemosphere.2022.136075",
        "paper_author": "Ali A.",
        "affiliation_name": "University of Karachi",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60061893",
        "affiliation_state": "Sindh"
    },
    {
        "paper_title": "Ethical Considerations in the Application of Artificial Intelligence to Monitor Social Media for COVID-19 Data",
        "publication": "Minds and Machines",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "The COVID-19 pandemic and its related policies (e.g., stay at home and social distancing orders) have increased people’s use of digital technology, such as social media. Researchers have, in turn, utilized artificial intelligence to analyze social media data for public health surveillance. For example, through machine learning and natural language processing, they have monitored social media data to examine public knowledge and behavior. This paper explores the ethical considerations of using artificial intelligence to monitor social media to understand the public’s perspectives and behaviors surrounding COVID-19, including potential risks and benefits of an AI-driven approach. Importantly, investigators and ethics committees have a role in ensuring that researchers adhere to ethical principles of respect for persons, beneficence, and justice in a way that moves science forward while ensuring public safety and confidence in the process.",
        "DOI": "10.1007/s11023-022-09610-0",
        "paper_author": "Flores L.",
        "affiliation_name": "University of California, Irvine",
        "affiliation_city": "Irvine",
        "affiliation_country": "United States",
        "affiliation_id": "60007278",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "The future of education utilizing artificial intelligence in Turkey",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "11",
        "cover_date": "2022-12-01",
        "Abstract": "This study examined the potential effects of artificial intelligence on Turkish education. A qualitative research approach was employed by posing an open-ended question to academics in order to attain this objective thanks to built-in capabilities for conducting complicated computer operations, cloud-based services, and conciliatory accession for agile network connections. This study emphasizes that Turkey is highly fragmented and consists of various business organizations at both the municipal and regional levels. The two main policy documents produced by the Turkish government suggest that colleges play a strong role in national and regional Artificial Intelligence (AI) strategies for workforce growth, with substantial consequences for AI adoption strategies. These documents include information on three well-known educational entities: The new oriental workgroups, recurrent neural networks, and classroom clustering. Significant aspects of Turkey’s educational AI growth include a strong private education industry and a growing international interest. The investigation results revealed a decline in the level of understanding regarding the methods of using artificial intelligence, indicating the necessity for additional awareness-raising in Turkey.",
        "DOI": "10.1057/s41599-022-01284-4",
        "paper_author": "İçen M.",
        "affiliation_name": "Yıldız Teknik Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey",
        "affiliation_id": "60019963",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Pandemic policy assessment by artificial intelligence",
        "publication": "Scientific Reports",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "Mobility-control policy is a controversial nonpharmacological approach to pandemic control due to its restriction on people’s liberty and economic impacts. Due to the computational complexity of mobility control, it is challenging to assess or compare alternative policies. Here, we develop a pandemic policy assessment system that employs artificial intelligence (AI) to evaluate and analyze mobility-control policies. The system includes three components: (1) a general simulation framework that models different policies to comparable network-flow control problems; (2) a reinforcement-learning (RL) oracle to explore the upper-bound execution results of policies; and (3) comprehensive protocols for converting the RL results to policy-assessment measures, including execution complexity, effectiveness, cost and benefit, and risk. We applied the system to real-world metropolitan data and evaluated three popular policies: city lockdown, community quarantine, and route management. For each policy, we generated mobility-pandemic trade-off frontiers. The results manifest that the smartest policies, such as route management, have high execution complexity but limited additional gain from mobility retention. In contrast, a moderate-level intelligent policy such as community quarantine has acceptable execution complexity but can effectively suppress infections and largely mitigate mobility interventions. The frontiers also show one or two turning points, reflecting the safe threshold of mobility retention when considering policy-execution errors. In addition, we simulated different policy environments and found inspirations for the current policy debates on the zero-COVID policy, vaccination policy, and relaxing restrictions.",
        "DOI": "10.1038/s41598-022-17892-8",
        "paper_author": "Song S.",
        "affiliation_name": "Université McGill",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60002494",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "Prediction of hydraulic blockage at culverts from a single image using deep learning",
        "publication": "Neural Computing and Applications",
        "citied_by": "14",
        "cover_date": "2022-12-01",
        "Abstract": "Cross-drainage hydraulic structures such as culverts and bridges in urban landscapes are prone to get blocked by the transported debris (e.g., urban, vegetated), which often reduces their hydraulic capacity and triggers flash floods. Unavailability of relevant data from blockage-originated flooding events and complex nature of debris accumulation are highlighted factors hindering the research within the blockage management domain. Wollongong City Council (WCC) blockage conduit policy is the leading formal guidelines to incorporate blockage into design guidelines; however, are criticized by the hydraulic engineers for its dependence on the post-flood visual inspections (i.e., visual blockage) instead of peak floods hydraulic investigations (i.e., hydraulic blockage). Apparently, no quantifiable relationship is reported between the visual blockage and hydraulic blockage; therefore, many consider WCC blockage guidelines invalid. This paper exploits the power of Artificial Intelligence (AI), motivated by its recent success, and attempts to relate visual blockage with hydraulic blockage by proposing a deep learning pipeline to predict hydraulic blockage from an image of the culvert. Two experiments are performed where the conventional pipeline and end-to-end learning approaches are implemented and compared in the context of predicting hydraulic blockage from a single image. In experiment one, the conventional deep learning pipeline approach (i.e., feature extraction using CNN and regression using ANN) is adopted. In contrast, in experiment two, end-to-end deep learning models (i.e., E2E_ MobileNet, E2E_ BlockageNet) are trained and compared with the conventional pipeline approach. Dataset (i.e., Hydraulics-Lab Blockage Dataset (HBD), Visual Hydraulics-Lab Dataset (VHD)) used in this research were collected from laboratory experiments performed using scaled physical models of culverts. E2E_ BlockageNet model was reported best in predicting hydraulic blockage with R2 score of 0.91 and indicated that hydraulic blockage could be interrelated with the visual features at the culvert.",
        "DOI": "10.1007/s00521-022-07593-8",
        "paper_author": "Iqbal U.",
        "affiliation_name": "University of Wollongong",
        "affiliation_city": "Wollongong",
        "affiliation_country": "Australia",
        "affiliation_id": "60011664",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "A Delphi consensus statement for digital surgery",
        "publication": "npj Digital Medicine",
        "citied_by": "49",
        "cover_date": "2022-12-01",
        "Abstract": "The use of digital technology is increasing rapidly across surgical specialities, yet there is no consensus for the term ‘digital surgery’. This is critical as digital health technologies present technical, governance, and legal challenges which are unique to the surgeon and surgical patient. We aim to define the term digital surgery and the ethical issues surrounding its clinical application, and to identify barriers and research goals for future practice. 38 international experts, across the fields of surgery, AI, industry, law, ethics and policy, participated in a four-round Delphi exercise. Issues were generated by an expert panel and public panel through a scoping questionnaire around key themes identified from the literature and voted upon in two subsequent questionnaire rounds. Consensus was defined if >70% of the panel deemed the statement important and <30% unimportant. A final online meeting was held to discuss consensus statements. The definition of digital surgery as the use of technology for the enhancement of preoperative planning, surgical performance, therapeutic support, or training, to improve outcomes and reduce harm achieved 100% consensus agreement. We highlight key ethical issues concerning data, privacy, confidentiality and public trust, consent, law, litigation and liability, and commercial partnerships within digital surgery and identify barriers and research goals for future practice. Developers and users of digital surgery must not only have an awareness of the ethical issues surrounding digital applications in healthcare, but also the ethical considerations unique to digital surgery. Future research into these issues must involve all digital surgery stakeholders including patients.",
        "DOI": "10.1038/s41746-022-00641-6",
        "paper_author": "Lam K.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60015150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "AoI Minimization in Energy Harvesting and Spectrum Sharing Enabled 6G Networks",
        "publication": "IEEE Transactions on Green Communications and Networking",
        "citied_by": "8",
        "cover_date": "2022-12-01",
        "Abstract": "Spectrum sharing is a method to solve the problem of frequency spectrum deficiency. This paper studies a novel spectrum sharing and energy harvesting system using artificial intelligence (AI) in which the freshness of information is guaranteed. The system is based on licensed shared access (LSA) which includes a primary user with access rights to the spectrum and a secondary user. The secondary user is an energy harvesting sensor that intends to use the primary user's spectrum opportunistically. The problem is formulated as partially observable Markov decision processes (POMDPs) and solved using two methods: 1) a deep Q-network (DQN) and 2) a dueling double deep Q-Network (D3QN) to achieve the optimal policy. The purpose is to choose the best action adaptively in every time slot based on the user's observations from the environment in overlay and underlay modes to minimize the average AoI of the secondary user. Finally, the simulation analyses are performed to evaluate the effectiveness of the proposed scheme compared to the overlay mode. According to the results, the average age of information (AoI) in the proposed system is less than that of the existing models, including only the overlay mode. The average user access is improved from 30% in the overlay mode to 45% and 48% in the proposed scheme which is implemented using DQN and D3QN, respectively.",
        "DOI": "10.1109/TGCN.2022.3186279",
        "paper_author": "Zarif A.H.",
        "affiliation_name": "Tarbiat Modares University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60032053",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Dynamic job shop scheduling based on deep reinforcement learning for multi-agent manufacturing systems",
        "publication": "Robotics and Computer-Integrated Manufacturing",
        "citied_by": "123",
        "cover_date": "2022-12-01",
        "Abstract": "Personalized orders bring challenges to the production paradigm, and there is an urgent need for the dynamic responsiveness and self-adjustment ability of the workshop. Traditional dispatching rules and heuristic algorithms solve the production planning and control problems by making schedules. However, the previous methods cannot work well in a changeable workshop environment when encountering a large number of stochastic disturbances of orders and resources. Recently, the potential of artificial intelligence (AI) algorithms in solving the dynamic scheduling problem has attracted researchers' attention. Therefore, this paper presents a multi-agent manufacturing system based on deep reinforcement learning (DRL), which integrates the self-organization mechanism and self-learning strategy. Firstly, the manufacturing equipment in the workshop is constructed as an equipment agent with the support of edge computing node, and an improved contract network protocol (CNP) is applied to guide the cooperation and competition among multiple agents, so as to complete personalized orders efficiently. Secondly, a multi-layer perceptron is employed to establish the decision-making module called AI scheduler inside the equipment agent. According to the perceived workshop state information, AI scheduler intelligently generates an optimal production strategy to perform task allocation. Then, based on the collected sample trajectories of scheduling process, AI scheduler is periodically trained and updated through the proximal policy optimization (PPO) algorithm to improve its decision-making performance. Finally, in the multi-agent manufacturing system testbed, dynamic events such as stochastic job insertions and unpredictable machine failures are considered in the verification experiments. The experimental results show that the proposed method is capable of obtaining the scheduling solutions that meet various performance metrics, as well as dealing with resource or task disturbances efficiently and autonomously.",
        "DOI": "10.1016/j.rcim.2022.102412",
        "paper_author": "Zhang Y.",
        "affiliation_name": "Nanjing University of Aeronautics and Astronautics",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60021666",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Challenges to implementing artificial intelligence in healthcare: a qualitative interview study with healthcare leaders in Sweden",
        "publication": "BMC Health Services Research",
        "citied_by": "149",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Artificial intelligence (AI) for healthcare presents potential solutions to some of the challenges faced by health systems around the world. However, it is well established in implementation and innovation research that novel technologies are often resisted by healthcare leaders, which contributes to their slow and variable uptake. Although research on various stakeholders’ perspectives on AI implementation has been undertaken, very few studies have investigated leaders’ perspectives on the issue of AI implementation in healthcare. It is essential to understand the perspectives of healthcare leaders, because they have a key role in the implementation process of new technologies in healthcare. The aim of this study was to explore challenges perceived by leaders in a regional Swedish healthcare setting concerning the implementation of AI in healthcare. Methods: The study takes an explorative qualitative approach. Individual, semi-structured interviews were conducted from October 2020 to May 2021 with 26 healthcare leaders. The analysis was performed using qualitative content analysis, with an inductive approach. Results: The analysis yielded three categories, representing three types of challenge perceived to be linked with the implementation of AI in healthcare: 1) Conditions external to the healthcare system; 2) Capacity for strategic change management; 3) Transformation of healthcare professions and healthcare practice. Conclusions: In conclusion, healthcare leaders highlighted several implementation challenges in relation to AI within and beyond the healthcare system in general and their organisations in particular. The challenges comprised conditions external to the healthcare system, internal capacity for strategic change management, along with transformation of healthcare professions and healthcare practice. The results point to the need to develop implementation strategies across healthcare organisations to address challenges to AI-specific capacity building. Laws and policies are needed to regulate the design and execution of effective AI implementation strategies. There is a need to invest time and resources in implementation processes, with collaboration across healthcare, county councils, and industry partnerships.",
        "DOI": "10.1186/s12913-022-08215-8",
        "paper_author": "Petersson L.",
        "affiliation_name": "Högskolan i Halmstad",
        "affiliation_city": "Halmstad",
        "affiliation_country": "Sweden",
        "affiliation_id": "60022085",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Legal concerns in health-related artificial intelligence: a scoping review protocol",
        "publication": "Systematic Reviews",
        "citied_by": "16",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Medical innovations offer tremendous hope. Yet, similar innovations in governance (law, policy, ethics) are likely necessary if society is to realize medical innovations’ fruits and avoid their pitfalls. As innovations in artificial intelligence (AI) advance at a rapid pace, scholars across multiple disciplines are articulating concerns in health-related AI that likely require legal responses to ensure the requisite balance. These scholarly perspectives may provide critical insights into the most pressing challenges that will help shape and advance future regulatory reforms. Yet, to the best of our knowledge, there is no comprehensive summary of the literature examining legal concerns in relation to health-related AI. We thus aim to summarize and map the literature examining legal concerns in health-related AI using a scoping review approach. Methods: The scoping review framework developed by (J Soc Res Methodol 8:19-32, 2005) and extended by (Implement Sci 5:69, 2010) and the Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for scoping reviews (PRISMA-ScR) guided our protocol development. In close consultation with trained librarians, we will develop a highly sensitive search for MEDLINE® (OVID) and adapt it for multiple databases designed to comprehensively capture texts in law, medicine, nursing, pharmacy, other healthcare professions (e.g., dentistry, nutrition), public health, computer science, and engineering. English- and French-language records will be included if they examine health-related AI, describe or prioritize a legal concern in health-related AI or propose a solution thereto, and were published in 2012 or later. Eligibility assessment will be conducted independently and in duplicate at all review stages. Coded data will be analyzed along themes and stratified across discipline-specific literatures. Discussion: This first-of-its-kind scoping review will summarize available literature examining, documenting, or prioritizing legal concerns in health-related AI to advance law and policy reform(s). The review may also reveal discipline-specific concerns, priorities, and proposed solutions to the concerns. It will thereby identify priority areas that should be the focus of future reforms and regulatory options available to stakeholders in reform processes. Trial registration: This protocol was submitted to the Open Science Foundation registration database. See https://osf.io/zav7w.",
        "DOI": "10.1186/s13643-022-01939-y",
        "paper_author": "Da Silva M.",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60028897",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Artificial intelligence against the first wave of COVID-19: evidence from China",
        "publication": "BMC Health Services Research",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Background: The COVID-19 pandemic unexpectedly broke out at the end of 2019. Due to the highly contagious, widespread, and risky nature of this disease, the pandemic prevention and control has been a tremendous challenge worldwide. One potentially powerful tool against the COVID-19 pandemic is artificial intelligence (AI). This study systematically assessed the effectiveness of AI in infection prevention and control during the first wave of COVID-19 in China. Methods: To better evaluate the role of AI in a pandemic emergency, we focused on the first-wave COVID-19 in the period from the early December 2019 to the end of April 2020 across 304 cities in China. We employed three sets of dependent variables to capture various dimensions of the effect of AI: (1) the time to the peak of cumulative confirmed cases, (2) the case fatality rate and whether there were severe cases, and (3) the number of local policies for work and production resumption and the time span to having the first such policy. The main explanatory variable was the local AI development measured by the number of AI patents. To fit the features of different dependent variables, we employed a variety of estimation methods, including the OLS, Tobit, Probit, and Poisson estimations. We included a large set of control variables and added interaction terms to test the mechanisms through which AI took an effect. Results: Our results showed that AI had highly significant effects on (1) screening and detecting the disease, and (2) monitoring and evaluating the epidemic evolution. Specifically, AI was useful to screen and detect the COVID-19 in cities with high cross-city mobility. Also, AI played an important role for production resumption in cities with high risk to reopen. However, there was limited evidence supporting the effectiveness of AI in the diagnosis and treatment of the disease. Conclusions: These results suggested that AI can play an important role against the pandemic.",
        "DOI": "10.1186/s12913-022-08146-4",
        "paper_author": "Wang T.",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60018308",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Machine-learning based routing of callers in an Israeli mental health hotline",
        "publication": "Israel Journal of Health Policy Research",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Mental health contact centers (also known as Hotlines) offer crisis intervention and counselling by phone calls and online chats. These mental health helplines have shown great success in improving the mental state of the callers, and are increasingly becoming popular in Israel and worldwide. Unfortunately, our knowledge about how to conduct successful routing of callers to counselling agents has been limited due to lack of large-scale data with labeled outcomes of the interactions. To date, many of these contact centers are overwhelmed by chat requests and operate in a simple first-come-first-serve (FCFS) scheduling policy which, combined, may lead to many callers receiving suboptimal counselling or abandoning the service before being treated. In this work our goal is to improve the efficiency of mental health contact centers by using a novel machine-learning based routing policy. Methods: We present a large-scale machine learning-based analysis of real-world data from the online contact center of ERAN, the Israeli Association for Emotional First Aid. The data includes over 35,000 conversations over a 2-years period. Based on this analysis, we present a novel call routing method, that integrates advanced AI-techniques including the Monte Carlo tree search algorithm. We conducted an experiment that included various realistic simulations of incoming calls to contact centers, based on data from ERAN. We divided the simulations into two common settings: standard call flow and heavy call flow. In order to establish a baseline, we compared our proposed solution to two baseline methods: (1) The FCFS method; and (2) a greedy solution based on machine learning predictions. Our comparison focuses on two metrics - the number of calls served and the average feedback of the callers (i.e., quality of the chats). Results: In the preliminary analysis, we identify indicative features that significantly contribute to the effectiveness of a conversation and demonstrate high accuracy in predicting the expected duration and the callers’ feedback. In the routing methods evaluation, we find that in heavy call flow settings, our proposed method significantly outperforms the other methods in both the quantity of served calls and average feedback. Most notably, we find that in the heavy call flow settings, our method improves the average feedback by 24% compared to FCFS and by 4% compared to the greedy solution. Regarding the standard-flow setting, we find that our proposed method significantly outperforms the FCFS method in the callers’ average feedback with a 12% improvement. However, in this setting, we did not find a significant difference between all methods in the quantity of served-calls and no significant difference was found between our proposed method and the greedy solution. Conclusion: The proposed routing policy has the potential to significantly improve the performance of mental health contact centers, especially in peak hours. Leveraging artificial intelligence techniques, such as machine learning algorithms, combined with real-world data can bring about a significant and necessary leap forward in the way mental health hotlines operate and consequently reduce the burden of mental illnesses on health systems. However, implementation and evaluation in an operational contact center is necessary in order to verify that the results replicate in practice.",
        "DOI": "10.1186/s13584-022-00534-9",
        "paper_author": "Kleinerman A.",
        "affiliation_name": "Bar-Ilan University",
        "affiliation_city": "Ramat Gan",
        "affiliation_country": "Israel",
        "affiliation_id": "60002765",
        "affiliation_state": "Tel Aviv District"
    },
    {
        "paper_title": "Food consumption patterns and nutrient intakes of infants and young children amidst the nutrition transition: the case of Lebanon",
        "publication": "Nutrition Journal",
        "citied_by": "9",
        "cover_date": "2022-12-01",
        "Abstract": "Background: This is the first study on dietary intakes of infants and young children in the Eastern Mediterranean Region, a region that is currently witnessing the nutrition transition. It aims at characterizing food consumption patterns amongst 0–4 year old children in Lebanon, evaluating their macro- and micronutrient intakes and assessing adherence to dietary recommendations. Methods: Based on a national cross-sectional survey in 2012 (n = 866), the study collected data on sociodemographic and anthropometric characteristics, and one 24-hour dietary recall was administered. Nutrient intakes were compared with reference values: Estimated Average Requirement (EAR), Adequate Intake (AI) and Acceptable Macronutrient Distribution Range (AMDR). Results: Milk was the highest contributor to energy intake (EI) in infants (95.8 and 56.5% in 0–5.9 months and 6–11.9 months old infants, respectively), while its intake was lower among toddlers and preschoolers (35.4 and 15.1%, respectively). In contrast, intakes of sweets and sweetened beverages were the highest in preschoolers compared to younger children, contributing 18.5% EI in preschoolers. Compared to dietary guidelines, the lowest dietary adherence was found for vegetables (17.8–20.7%) and fruits (14.4–34.3%). Protein intake was within the recommendations for the vast majority of children. Although total fat intake was lower in toddlers and preschoolers compared to infants, more than 40% of toddlers and preschoolers exceeded the AMDR for fat and 87.3% of preschoolers exceeded the upper limit for saturated fat. Only 3.6% of toddlers and 11.5% of preschoolers exceeded the AI level for dietary fiber. Micronutrient intake assessment showed that mean intakes in infants exceeded the AI for all micronutrients, except for vitamin D and magnesium. In toddlers, vitamin D and calcium were below the EAR among 84.7, and 44.6%, respectively. In preschoolers, most of the children (91.9%) had inadequate intakes of vitamin D, and a third had inadequate intakes of folate, calcium and vitamin A. Conclusions: This study identified priority issues for nutrition intervention in infants and young children in Lebanon. Concerted multi-stakeholder efforts are needed to instill heathier food consumption and nutrient intake patterns early in life.",
        "DOI": "10.1186/s12937-022-00779-9",
        "paper_author": "Jomaa L.",
        "affiliation_name": "North Carolina Central University",
        "affiliation_city": "Durham",
        "affiliation_country": "United States",
        "affiliation_id": "60032941",
        "affiliation_state": "NC"
    },
    {
        "paper_title": "BeCaked: An Explainable Artificial Intelligence Model for COVID-19 Forecasting",
        "publication": "Scientific Reports",
        "citied_by": "12",
        "cover_date": "2022-12-01",
        "Abstract": "From the end of 2019, one of the most serious and largest spread pandemics occurred in Wuhan (China) named Coronavirus (COVID-19). As reported by the World Health Organization, there are currently more than 100 million infectious cases with an average mortality rate of about five percent all over the world. To avoid serious consequences on people’s lives and the economy, policies and actions need to be suitably made in time. To do that, the authorities need to know the future trend in the development process of this pandemic. This is the reason why forecasting models play an important role in controlling the pandemic situation. However, the behavior of this pandemic is extremely complicated and difficult to be analyzed, so that an effective model is not only considered on accurate forecasting results but also the explainable capability for human experts to take action pro-actively. With the recent advancement of Artificial Intelligence (AI) techniques, the emerging Deep Learning (DL) models have been proving highly effective when forecasting this pandemic future from the huge historical data. However, the main weakness of DL models is lacking the explanation capabilities. To overcome this limitation, we introduce a novel combination of the Susceptible-Infectious-Recovered-Deceased (SIRD) compartmental model and Variational Autoencoder (VAE) neural network known as BeCaked. With pandemic data provided by the Johns Hopkins University Center for Systems Science and Engineering, our model achieves 0.98 R2 and 0.012 MAPE at world level with 31-step forecast and up to 0.99 R2 and 0.0026 MAPE at country level with 15-step forecast on predicting daily infectious cases. Not only enjoying high accuracy, but BeCaked also offers useful justifications for its results based on the parameters of the SIRD model. Therefore, BeCaked can be used as a reference for authorities or medical experts to make on time right decisions.",
        "DOI": "10.1038/s41598-022-11693-9",
        "paper_author": "Nguyen D.Q.",
        "affiliation_name": "Ho Chi Minh City University of Technology - HCMUT",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam",
        "affiliation_id": "60272237",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "What ethical approaches are used by scientists when sharing health data? An interview study",
        "publication": "BMC Medical Ethics",
        "citied_by": "12",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Health data-driven activities have become central in diverse fields (research, AI development, wearables, etc.), and new ethical challenges have arisen with regards to privacy, integrity, and appropriateness of use. To ensure the protection of individuals’ fundamental rights and freedoms in a changing environment, including their right to the protection of personal data, we aim to identify the ethical approaches adopted by scientists during intensive data exploitation when collecting, using, or sharing peoples’ health data. Methods: Twelve scientists who were collecting, using, or sharing health data in different contexts in Sweden, were interviewed. We used systematic expert interviews to access these scientists’ specialist knowledge, and analysed the interviews with thematic analysis. Phrases, sentences, or paragraphs through which ethical values and norms were expressed, were identified and coded. Codes that reflected similar concepts were grouped, subcategories were formulated, and categories were connected to traditional ethical approaches. Results: Through several examples, the respondents expressed four different ethical approaches, which formed the main conceptual categories: consideration of consequences, respect for rights, procedural compliance, and being professional. Conclusions: To a large extent, the scientists’ ethical approaches were consistent with ethical and legal principles. Data sharing was considered important and worth pursuing, even though it is difficult. An awareness of the complex issues involved in data sharing was reflected from different perspectives, and the respondents commonly perceived a general lack of practical procedures that would by default ensure ethical and legally compliant data collection and sharing. We suggest that it is an opportune time to move on from policy discussions to practical technological ethics-by-design solutions that integrate these principles into practice.",
        "DOI": "10.1186/s12910-022-00779-8",
        "paper_author": "Viberg Johansson J.",
        "affiliation_name": "Institutionen för folkhälso- och vårdvetenskap",
        "affiliation_city": "Uppsala",
        "affiliation_country": "Sweden",
        "affiliation_id": "60079985",
        "affiliation_state": "Uppsala"
    },
    {
        "paper_title": "Connecting brain and heart: artificial intelligence for sustainable development",
        "publication": "Scientometrics",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "A key objective of global policies on Artificial Intelligence (AI) is to foster AI research for sustainable development (SD). In this paper, we analyze the inclusion of SD in AI research indexed by the IEEE Xplore database from 2000 to 2019. We address three critical questions: (1) To what extent is AI research addressing the sustainable development goals (SDGs)? (2) Which subject areas of AI show an emerging interest in SD? And (3) What patterns of collaboration between regions of the world are being stimulated by AI? Our scientometric analysis consists of (1) Identifying the number of AI papers that address SDGs in their titles, abstracts, and keywords. (2) Developing a composite indicator based on the number of documents produced, scientific impact, and inventive impact to distinguish areas with an emerging interest in SD; (3) Exploring co-authorship networks at three levels: region, income group, and country. The overall results show that a small share of papers is explicitly focused on SD. Our composite indicator allowed us to identify an emerging interest in SD from Ultrasonics, Ferroelectrics, and Frequency Control, Education, Consumer Electronics, Electrical Engineering, Electromagnetic Compatibility and Interference. Specifically, on AI subjects, we found emerging interests in Prediction Methods, Computation Theory, Machine Learning, Learning (artificial intelligence), and Biological Neural Networks. Inter-regional and inter-income group collaboration are limited, and network power is concentrated in a few countries. The results could be useful to improve the connection between technical knowledge, strategic planning for S&T investment, and SD policies.",
        "DOI": "10.1007/s11192-022-04299-5",
        "paper_author": "Chavarro D.",
        "affiliation_name": "Colombian Society of Engineering Physics (SCIF)",
        "affiliation_city": "Pereira",
        "affiliation_country": "Colombia",
        "affiliation_id": "126633930",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The global environmental agenda urgently needs a semantic web of knowledge",
        "publication": "Environmental Evidence",
        "citied_by": "20",
        "cover_date": "2022-12-01",
        "Abstract": "Progress in key social-ecological challenges of the global environmental agenda (e.g., climate change, biodiversity conservation, Sustainable Development Goals) is hampered by a lack of integration and synthesis of existing scientific evidence. Facing a fast-increasing volume of data, information remains compartmentalized to pre-defined scales and fields, rarely building its way up to collective knowledge. Today's distributed corpus of human intelligence, including the scientific publication system, cannot be exploited with the efficiency needed to meet current evidence synthesis challenges; computer-based intelligence could assist this task. Artificial Intelligence (AI)-based approaches underlain by semantics and machine reasoning offer a constructive way forward, but depend on greater understanding of these technologies by the science and policy communities and coordination of their use. By labelling web-based scientific information to become readable by both humans and computers, machines can search, organize, reuse, combine and synthesize information quickly and in novel ways. Modern open science infrastructure—i.e., public data and model repositories—is a useful starting point, but without shared semantics and common standards for machine actionable data and models, our collective ability to build, grow, and share a collective knowledge base will remain limited. The application of semantic and machine reasoning technologies by a broad community of scientists and decision makers will favour open synthesis to contribute and reuse knowledge and apply it toward decision making.",
        "DOI": "10.1186/s13750-022-00258-y",
        "paper_author": "Balbi S.",
        "affiliation_name": "Universidad del Pais Vasco",
        "affiliation_city": "Leioa",
        "affiliation_country": "Spain",
        "affiliation_id": "60027856",
        "affiliation_state": "Biscay"
    },
    {
        "paper_title": "Barriers, frameworks, and mitigating strategies influencing the dissemination and implementation of health promotion interventions in indigenous communities: a scoping review",
        "publication": "Implementation Science",
        "citied_by": "16",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Many Indigenous communities across the USA and Canada experience a disproportionate burden of health disparities. Effective programs and interventions are essential to build protective skills for different age groups to improve health outcomes. Understanding the relevant barriers and facilitators to the successful dissemination, implementation, and retention of evidence-based interventions and/or evidence-informed programs in Indigenous communities can help guide their dissemination. Purpose: To identify common barriers to dissemination and implementation (D&I) and effective mitigating frameworks and strategies used to successfully disseminate and implement evidence-based interventions and/or evidence-informed programs in American Indian/Alaska Native (AI/AN), Native Hawaiian/Pacific Islander (NH/PI), and Canadian Indigenous communities. Methods: A scoping review, informed by the York methodology, comprised five steps: (1) identification of the research questions; (2) searching for relevant studies; (3) selection of studies relevant to the research questions; (4) data charting; and (5) collation, summarization, and reporting of results. The established D&I SISTER strategy taxonomy provided criteria for categorizing reported strategies. Results: Candidate studies that met inclusion/exclusion criteria were extracted from PubMed (n = 19), Embase (n = 18), and Scopus (n = 1). Seventeen studies were excluded following full review resulting in 21 included studies. The most frequently cited category of barriers was “Social Determinants of Health in Communities.” Forty-three percent of barriers were categorized in this community/society-policy level of the SEM and most studies (n = 12, 57%) cited this category. Sixteen studies (76%) used a D&I framework or model (mainly CBPR) to disseminate and implement health promotion evidence-based programs in Indigenous communities. Most highly ranked strategies (80%) corresponded with those previously identified as “important” and “feasible” for D&I The most commonly reported SISTER strategy was “Build partnerships (i.e., coalitions) to support implementation” (86%). Conclusion: D&I frameworks and strategies are increasingly cited as informing the adoption, implementation, and sustainability of evidence-based programs within Indigenous communities. This study contributes towards identifying barriers and effective D&I frameworks and strategies critical to improving reach and sustainability of evidence-based programs in Indigenous communities. Registration number: N/A (scoping review)",
        "DOI": "10.1186/s13012-022-01190-y",
        "paper_author": "Sacca L.",
        "affiliation_name": "UTHealth Houston School of Public Health",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "60012516",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Learning dynamic treatment strategies for coronary heart diseases by artificial intelligence: real-world data-driven study",
        "publication": "BMC Medical Informatics and Decision Making",
        "citied_by": "12",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Coronary heart disease (CHD) has become the leading cause of death and one of the most serious epidemic diseases worldwide. CHD is characterized by urgency, danger and severity, and dynamic treatment strategies for CHD patients are needed. We aimed to build and validate an AI model for dynamic treatment recommendations for CHD patients with the goal of improving patient outcomes and learning best practices from clinicians to help clinical decision support for treating CHD patients. Methods: We formed the treatment strategy as a sequential decision problem, and applied an AI supervised reinforcement learning-long short-term memory (SRL-LSTM) framework that combined supervised learning (SL) and reinforcement learning (RL) with an LSTM network to track patients’ states to learn a recommendation model that took a patient’s diagnosis and evolving health status as input and provided a treatment recommendation in the form of whether to take specific drugs. The experiments were conducted by leveraging a real-world intensive care unit (ICU) database with 13,762 admitted patients diagnosed with CHD. We compared the performance of the applied SRL-LSTM model and several state-of-the-art SL and RL models in reducing the estimated in-hospital mortality and the Jaccard similarity with clinicians’ decisions. We used a random forest algorithm to calculate the feature importance of both the clinician policy and the AI policy to illustrate the interpretability of the AI model. Results: Our experimental study demonstrated that the AI model could help reduce the estimated in-hospital mortality through its RL function and learn the best practice from clinicians through its SL function. The similarity between the clinician policy and the AI policy regarding the surviving patients was high, while for the expired patients, it was much lower. The dynamic treatment strategies made by the AI model were clinically interpretable and relied on sensible clinical features extracted according to monitoring indexes and risk factors for CHD patients. Conclusions: We proposed a pipeline for constructing an AI model to learn dynamic treatment strategies for CHD patients that could improve patient outcomes and mimic the best practices of clinicians. And a lot of further studies and efforts are needed to make it practical.",
        "DOI": "10.1186/s12911-022-01774-0",
        "paper_author": "Guo H.",
        "affiliation_name": "Renmin University of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60014402",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Technology Forecasting for Envisioning Bt Technology Scenario in Indian Agriculture",
        "publication": "Agricultural Research",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "For scoping the future prospects of Bacillus thuringiensis (Bt) technology in Indian agricultural scenario, case studies of three quantitative/quasi-quantitative techniques of Technology Forecasting tools viz., activity index (AI)-based scientometric analysis, Grey modeling and cross impact analysis (CIA) techniques have been done. Under AI-based scientometric analysis, information relating to abstract, keywords, authors, affiliation, etc., relevant to research publication on applications of Bt technology in India vis-à-vis three other competing country regions—China, USA cum Canada and European countries were collected from ScienceDirect database for the period 1997–2017. AI has been constructed for seven domains viz. Bt Cotton, Bt Maize, Bt Mustard, Bt Brinjal, Bt Soybean, Bt Sunflower, Bt Rice, and ‘Bt related but not crop specific’ under these four regions considered. From the values of AI, it has been found that India’s research effort is higher only in Bt Cotton and Bt Mustard than the other regions considered. Secondly, for Grey modeling, its conventional version as well as Grey model improved by Genetic Algorithm (GA) were fitted using yearly Bt cotton yield of India (2002–2003 to 2016–2017) obtained from Cotton Advisory Board of India. Only the first 11 years were utilized for model fitting and the rest were utilized for validation purposes. The results revealed that Grey model improved by GA performed better. Lastly, for employing CIA technique to study the direct as well as indirect cross impacts of Bt technology, 14 factors were considered. Three types of CIA techniques viz., Direct Classification, Cross-Impact Matrix Multiplication Applied to Classification, and CIA with Time Consideration have been attempted. The ranking of the factors obtained by three methods was combined using Technique for Order Preference by Similarity to an Ideal Solution approach. The analysis suggested that factors viz., Government policy, Bt seed sector, and technological interventions came out to be mainly responsible for future prospects of Bt technology in India.",
        "DOI": "10.1007/s40003-022-00612-z",
        "paper_author": "Ray M.",
        "affiliation_name": "ICAR - Indian Agricultural Statistics Research Institute, New Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60024234",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modeling and reasoning about uncertainty in goal models: a decision-theoretic approach",
        "publication": "Software and Systems Modeling",
        "citied_by": "10",
        "cover_date": "2022-12-01",
        "Abstract": "Goal models have been a popular subject of study by researchers in requirements engineering, due to their ability to capture and analyze alternative solutions through which a software system can achieve business objectives. A plethora of analysis methods for automated identification of optimal alternatives have been proposed. However, such methods often assume an idealized reality where all tasks are successfully performed when attempted and all goals are eventually satisfied with certainty when pursued according to a solution. In reality, some tasks run the risk of failure while others produce chance outcomes. In this paper, we extend the standard goal modeling language to allow representation and reasoning about both uncertainty and preferential utility in goals. Tasks are extended to allow for probabilistic effects and preferential statements of stakeholders are captured and translated into utilities over possible effects. Moreover, solutions are not mere specifications (functions, quality constraints, and assumptions), but rather policies, that is sequences of situational action decisions, through which stakeholder goals can be fulfilled. An AI reasoning tool is adapted and used for identifying optimal policies with respect to the value they offer to stakeholders measured against their probability of failure. Evaluation of the approach includes a simulation study and scalability experiments to assess the applicability of automated reasoning for larger problems.",
        "DOI": "10.1007/s10270-021-00968-w",
        "paper_author": "Liaskos S.",
        "affiliation_name": "York University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60033420",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Large-Scale Machine Learning Cluster Scheduling via Multi-Agent Graph Reinforcement Learning",
        "publication": "IEEE Transactions on Network and Service Management",
        "citied_by": "6",
        "cover_date": "2022-12-01",
        "Abstract": "Efficient scheduling of distributed deep learning (DL) jobs in large GPU clusters is crucial for resource efficiency and job performance. While server sharing among jobs improves resource utilization, interference among co-located DL jobs occurs due to resource contention. Interference-aware job placement has been studied, with white-box approaches based on explicit interference modeling and black-box schedulers with reinforcement learning. In today's clusters containing thousands of GPU servers, running a single scheduler to manage all arrival jobs in a timely and effective manner is challenging, due to the large workload scale. We adopt multiple schedulers in a large-scale cluster/data center, and propose a multi-agent reinforcement learning (MARL) scheduling framework to cooperatively learn fine-grained job placement policies, towards the objective of minimizing job completion time (JCT). To achieve topology-aware placements, our proposed framework uses hierarchical graph neural networks to encode the data center topology and server architecture. In view of a common lack of precise reward samples corresponding to different placements, a job interference model is further devised to predict interference levels in face of various co-locations, for training of the MARL schedulers. Testbed and trace-driven evaluations show that our scheduler framework outperforms representative scheduling schemes by more than 20% in terms of average JCT, and is adaptive to various machine learning cluster topologies.",
        "DOI": "10.1109/TNSM.2021.3139607",
        "paper_author": "Zhao X.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Speeding up to keep up: exploring the use of AI in the research process",
        "publication": "AI and Society",
        "citied_by": "70",
        "cover_date": "2022-12-01",
        "Abstract": "There is a long history of the science of intelligent machines and its potential to provide scientific insights have been debated since the dawn of AI. In particular, there is renewed interest in the role of AI in research and research policy as an enabler of new methods, processes, management and evaluation which is still relatively under-explored. This empirical paper explores interviews with leading scholars on the potential impact of AI on research practice and culture through deductive, thematic analysis to show the issues affecting academics and universities today. Our interviewees identify positive and negative consequences for research and researchers with respect to collective and individual use. AI is perceived as helpful with respect to information gathering and other narrow tasks, and in support of impact and interdisciplinarity. However, using AI as a way of ‘speeding up—to keep up’ with bureaucratic and metricised processes, may proliferate negative aspects of academic culture in that the expansion of AI in research should assist and not replace human creativity. Research into the future role of AI in the research process needs to go further to address these challenges, and ask fundamental questions about how AI might assist in providing new tools able to question the values and principles driving institutions and research processes. We argue that to do this an explicit movement of meta-research on the role of AI in research should consider the effects for research and researcher creativity. Anticipatory approaches and engagement of diverse and critical voices at policy level and across disciplines should also be considered.",
        "DOI": "10.1007/s00146-021-01259-0",
        "paper_author": "Chubb J.",
        "affiliation_name": "University of York",
        "affiliation_city": "York",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60016418",
        "affiliation_state": "North Yorkshire"
    },
    {
        "paper_title": "Performance Modelling and Analysis of IoT Based Edge Computing Policies",
        "publication": "Wireless Personal Communications",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "In today’s era, the acceptance of IoT-based edge devices is growing exponentially, which creates challenges of data acquisition, processing, and communication. In the edge computing paradigm, intelligence is shifted from the center to the edge by performing specific processing and prediction locally. Existing methods are not well computed with timely manner and it reduces the security level by overfitting problem. A strategy based on reducing communication resources between sensors and edge devices is the prime focus of this investigation. It uses a predictive model-based policy at edge devices for the reconstruction of not delivered context vector. A new hybrid Averaged Exponential Smoothening policy proposed is based on the current context vectors as well as a smoothing vector to reduce reconstruction error and improve the percentage of communication. It is observed that if we send data only when there is a marginal change in data then we can reduce communication overhead as well as keep reconstruction error low. This policy would be suitable for IoT-based edge computing applications for the smart city such as Smart Home, Healthcare, and Intelligent traffic to delivers the power of AI.",
        "DOI": "10.1007/s11277-021-09081-z",
        "paper_author": "Shirke A.",
        "affiliation_name": "Veermata Jijabai Technological Institute",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60022429",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "AI under great uncertainty: implications and decision strategies for public policy",
        "publication": "AI and Society",
        "citied_by": "34",
        "cover_date": "2022-12-01",
        "Abstract": "Decisions where there is not enough information for a well-informed decision due to unidentified consequences, options, or undetermined demarcation of the decision problem are called decisions under great uncertainty. This paper argues that public policy decisions on how and if to implement decision-making processes based on machine learning and AI for public use are such decisions. Decisions on public policy on AI are uncertain due to three features specific to the current landscape of AI, namely (i) the vagueness of the definition of AI, (ii) uncertain outcomes of AI implementations and (iii) pacing problems. Given that many potential applications of AI in the public sector concern functions central to the public sphere, decisions on the implementation of such applications are particularly sensitive. Therefore, it is suggested that public policy-makers and decision-makers in the public sector can adopt strategies from the argumentative approach in decision theory to mitigate the established great uncertainty. In particular, the notions of framing and temporal strategies are considered.",
        "DOI": "10.1007/s00146-021-01263-4",
        "paper_author": "Nordström M.",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60002014",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "AI, big data, and the future of consent",
        "publication": "AI and Society",
        "citied_by": "58",
        "cover_date": "2022-12-01",
        "Abstract": "In this paper, we discuss several problems with current Big data practices which, we claim, seriously erode the role of informed consent as it pertains to the use of personal information. To illustrate these problems, we consider how the notion of informed consent has been understood and operationalised in the ethical regulation of biomedical research (and medical practices, more broadly) and compare this with current Big data practices. We do so by first discussing three types of problems that can impede informed consent with respect to Big data use. First, we discuss the transparency (or explanation) problem. Second, we discuss the re-repurposed data problem. Third, we discuss the meaningful alternatives problem. In the final section of the paper, we suggest some solutions to these problems. In particular, we propose that the use of personal data for commercial and administrative objectives could be subject to a ‘soft governance’ ethical regulation, akin to the way that all projects involving human participants (e.g., social science projects, human medical data and tissue use) are regulated in Australia through the Human Research Ethics Committees (HRECs). We also consider alternatives to the standard consent forms, and privacy policies, that could make use of some of the latest research focussed on the usability of pictorial legal contracts.",
        "DOI": "10.1007/s00146-021-01262-5",
        "paper_author": "Andreotta A.J.",
        "affiliation_name": "Curtin University",
        "affiliation_city": "Perth",
        "affiliation_country": "Australia",
        "affiliation_id": "60031226",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "The political imaginary of National AI Strategies",
        "publication": "AI and Society",
        "citied_by": "22",
        "cover_date": "2022-12-01",
        "Abstract": "In the past few years, several democratic governments have published their National AI Strategies (NASs). These documents outline how AI technology should be implemented in the public sector and explain the policies that will ensure the ethical use of personal data. In this article, I examine these documents as political texts and reconstruct the political imaginary that underlies them. I argue that these documents intervene in contemporary democratic politics by suggesting that AI can help democracies overcome some of the challenges they are facing. To achieve this, NASs use different kinds of imaginaries—democratic, sociotechnical and data—that help citizens envision how a future AI democracy might look like. As part of this collective effort, a new kind of relationship between citizens and governments is formed. Citizens are seen as autonomous data subjects, but at the same time, they are expected to share their personal data for the common good. As a result, I argue, a new kind of political imaginary is developed in these documents. One that maintains a human-centric approach while championing a vision of collective sovereignty over data. This kind of political imaginary can become useful in understanding the roles of citizens and governments in this technological age.",
        "DOI": "10.1007/s00146-021-01258-1",
        "paper_author": "Paltieli G.",
        "affiliation_name": "The Van Leer Jerusalem Institute",
        "affiliation_city": "Jerusalem",
        "affiliation_country": "Israel",
        "affiliation_id": "60276543",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "New Pythias of public administration: ambiguity and choice in AI systems as challenges for governance",
        "publication": "AI and Society",
        "citied_by": "15",
        "cover_date": "2022-12-01",
        "Abstract": "As public administrations adopt artificial intelligence (AI), we see this transition has the potential to transform public service and public policies, by offering a rapid turnaround on decision making and service delivery. However, a recent series of criticisms have pointed to problematic aspects of mainstreaming AI systems in public administration, noting troubled outcomes in terms of justice and values. The argument supplied here is that any public administration adopting AI systems must consider and address ambiguities and uncertainties surrounding two key dimensions: the algorithms’ results, and how public managers make decisions for and about AI systems’ design. The article is based on bibliographic research in institutional theory perspective that relates the design of AI systems and relevant literature on the decision-making process in public policy. The main finding is to explain why autonomous decision systems continue to reproduce ambiguities and uncertainties when applied in public administration and propose a reflection on AI governance in public administration. This article points to the need for design institutions that immerse themselves in understanding the nuances, details, and potential outcomes of AI governance for public administration. Such institutions would reconcile consequentialist logic with a logic of appropriateness to help navigate and mediate ambiguities and uncertainties.",
        "DOI": "10.1007/s00146-021-01201-4",
        "paper_author": "Filgueiras F.",
        "affiliation_name": "Universidade Federal de Minas Gerais",
        "affiliation_city": "Belo Horizonte",
        "affiliation_country": "Brazil",
        "affiliation_id": "60030074",
        "affiliation_state": "MG"
    },
    {
        "paper_title": "REASONABLE AI AND OTHER CREATURES. WHAT ROLE FOR AI STANDARDS IN LIABILITY LITIGATION?",
        "publication": "Journal of Law, Market and Innovation",
        "citied_by": "1",
        "cover_date": "2022-11-30",
        "Abstract": "Standards play a vital role in supporting policies and legislation of the European Union. The regulation of artificial intelligence (AI) makes no exception as made clear by the AI Act proposal. Particularly, Articles 40 and 41 defer to harmonised standards and common specifications the concrete definition of safety and trustworthiness requirements, including risk management, data quality, transparency, human oversight, accuracy, robustness, and cybersecurity. Besides, other types of standards and professional norms are also relevant to the governance of AI. These include European non-harmonised standards, international and national standards, professional codes and guidelines, and uncodified best practices. This contribution casts light on the relationship between standards and private law in the context of liability litigation for damage caused by AI systems. Despite literature’s commitment to the issue of liability for AI, the role of standardisation in this regard has been largely overlooked hitherto. Furthermore, while much research has been undertaken on the regulation of AI, comparatively little has dealt with its standardisation. This paper aims to fill this gap. Building on previous scholarship, the contribution demonstrates that standards and professional norms are substantially normative in spite of their private and voluntary nature. In fact, they shape private relationships due to normative and economic reasons. Indeed, these private norms enter the courtrooms by explicit or implicit incorporation into contracts as well as by informing general clauses such as reasonableness and duty of care. Therefore, they represent the yardstick against which professionals’ performance and conduct are evaluated. Hence, a link between standards, safety, and liability can be established. Against this backdrop, the role of AI standards in private law is assessed. To set the scene, the article provides a bird’s-eye view of AI standardisation. The European AI standardisation initiative is analysed along with other institutional and non-institutional instruments. Finally, it is argued that AI standards contribute to defining the duty of care expected from developers and professional operators of AI systems. Hence, they might represent a valuable instrument for tackling the challenges posed by AI technology to extracontractual and contractual liability.",
        "DOI": "10.13135/2785-7867/7166",
        "paper_author": "Frattone C.",
        "affiliation_name": "Università degli Studi Roma Tre",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60012630",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Linked Open Government Data to Predict and Explain House Prices: The Case of Scottish Statistics Portal",
        "publication": "Big Data Research",
        "citied_by": "22",
        "cover_date": "2022-11-28",
        "Abstract": "Accurately estimating the prices of houses is important for various stakeholders including house owners, real estate agencies, government agencies, and policy-makers. Towards this end, traditional statistics and, only recently, advanced machine learning and artificial intelligence models are used. Open Government Data (OGD) have a huge potential especially when combined with AI technologies. OGD are often published as linked data to facilitate data integration and re-usability. EXplainable Artificial Intelligence (XAI) can be used by stakeholders to understand the decisions of a predictive model. This work creates a model that predicts house prices by applying machine learning on linked OGD. We present a case study that uses XGBoost, a powerful machine learning algorithm, and linked OGD from the official Scottish data portal to predict the probability the mean prices of houses in the various data zones of Scotland to be higher than the average price in Scotland. XAI is also used to globally and locally explain the decisions of the model. The created model has Receiver Operating Characteristic (ROC) AUC score 0.923 and Precision Recall Curve (PRC) AUC score 0.891. According to XAI, the variable that mostly affects the decisions of the model is Comparative Illness Factor, an indicator of health conditions. However, local explainability shows that the decisions made in some data zones may be mostly affected by other variables such as the percent of detached dwellings and employment deprived population.",
        "DOI": "10.1016/j.bdr.2022.100355",
        "paper_author": "Karamanou A.",
        "affiliation_name": "University of Macedonia",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece",
        "affiliation_id": "60001086",
        "affiliation_state": "Central Macedonia"
    },
    {
        "paper_title": "A literature review of the available artificial intelligence (AI) technology to assist in greening the Malaysian automotive industry",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2022-11-22",
        "Abstract": "Today's society is confronted with an ever-increasing number of technical issues, such as computer science, computer technology, digital technology, jargon, programming, and artificial intelligence. The future has been taken from the previous industrial revolution, which is paying for the present by causing harm to our world's well-being through economic growth. Today, the technological revolution must break this cycle and achieve sustainable economic growth. Artificial intelligence (AI) has the enormous potential to be a significant weapon in efforts to decouple economic growth from rising carbon emissions. There is a path to a more sustainable, equal, and prosperous future with advanced technology. The most significant gains visible on the map of nations are that many businesses already have a good understanding of AI. More pollution control is required. Outlines, policy development, the importance of edification and the guidance of new skills, and smooth changes in the job sector must all come together with a sense of shared responsibility as necessary to collectively solve these problems, perhaps especially because AI awareness will not be shaped solely by the technology field. As a result, this research is only the first step toward a greater understanding of how AI can create a more prosperous opportunity for Malaysia's automotive industry. However, we have more pressing concerns than advancing scholarly research. National action on climate change and nature should be prioritized in this situation. The discovery must be a portent of the end. We hope that efforts will be made to make the Fourth Industrial Revolution a forward-thinking epoch that will not only benefit society and the nation.",
        "DOI": "10.1063/5.0120583",
        "paper_author": "Husain R.",
        "affiliation_name": "National Defense University of Malaysia",
        "affiliation_city": "Kuala Lumpur",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60090676",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Preparing for the next pandemic: Simulation-based deep reinforcement learning to discover and test multimodal control of systemic inflammation using repurposed immunomodulatory agents",
        "publication": "Frontiers in Immunology",
        "citied_by": "4",
        "cover_date": "2022-11-21",
        "Abstract": "Background: Preparation to address the critical gap in a future pandemic between non-pharmacological measures and the deployment of new drugs/vaccines requires addressing two factors: 1) finding virus/pathogen-agnostic pathophysiological targets to mitigate disease severity and 2) finding a more rational approach to repurposing existing drugs. It is increasingly recognized that acute viral disease severity is heavily driven by the immune response to the infection (“cytokine storm” or “cytokine release syndrome”). There exist numerous clinically available biologics that suppress various pro-inflammatory cytokines/mediators, but it is extremely difficult to identify clinically effective treatment regimens with these agents. We propose that this is a complex control problem that resists standard methods of developing treatment regimens and accomplishing this goal requires the application of simulation-based, model-free deep reinforcement learning (DRL) in a fashion akin to training successful game-playing artificial intelligences (AIs). This proof-of-concept study determines if simulated sepsis (e.g. infection-driven cytokine storm) can be controlled in the absence of effective antimicrobial agents by targeting cytokines for which FDA-approved biologics currently exist. Methods: We use a previously validated agent-based model, the Innate Immune Response Agent-based Model (IIRABM), for control discovery using DRL. DRL training used a Deep Deterministic Policy Gradient (DDPG) approach with a clinically plausible control interval of 6 hours with manipulation of six cytokines for which there are existing drugs: Tumor Necrosis Factor (TNF), Interleukin-1 (IL-1), Interleukin-4 (IL-4), Interleukin-8 (IL-8), Interleukin-12 (IL-12) and Interferon-γ(IFNg). Results: DRL trained an AI policy that could improve outcomes from a baseline Recovered Rate of 61% to one with a Recovered Rate of 90% over ~21 days simulated time. This DRL policy was then tested on four different parameterizations not seen in training representing a range of host and microbe characteristics, demonstrating a range of improvement in Recovered Rate by +33% to +56% Discussion: The current proof-of-concept study demonstrates that significant disease severity mitigation can potentially be accomplished with existing anti-mediator drugs, but only through a multi-modal, adaptive treatment policy requiring implementation with an AI. While the actual clinical implementation of this approach is a projection for the future, the current goal of this work is to inspire the development of a research ecosystem that marries what is needed to improve the simulation models with the development of the sensing/assay technologies to collect the data needed to iteratively refine those models.",
        "DOI": "10.3389/fimmu.2022.995395",
        "paper_author": "Cockrell C.",
        "affiliation_name": "University of Vermont Larner College of Medicine",
        "affiliation_city": "Burlington",
        "affiliation_country": "United States",
        "affiliation_id": "60031576",
        "affiliation_state": "VT"
    },
    {
        "paper_title": "All the News That's Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation",
        "publication": "Journal of Experimental Political Science",
        "citied_by": "135",
        "cover_date": "2022-11-20",
        "Abstract": "Online misinformation has become a constant; only the way actors create and distribute that information is changing. Advances in artificial intelligence (AI) such as GPT-2 mean that actors can now synthetically generate text in ways that mimic the style and substance of human-created news stories. We carried out three original experiments to study whether these AI-generated texts are credible and can influence opinions on foreign policy. The first evaluated human perceptions of AI-generated text relative to an original story. The second investigated the interaction between partisanship and AI-generated news. The third examined the distributions of perceived credibility across different AI model sizes. We find that individuals are largely incapable of distinguishing between AI- and human-generated text; partisanship affects the perceived credibility of the story; and exposure to the text does little to change individuals' policy views. The findings have important implications in understanding AI in online misinformation campaigns.",
        "DOI": "10.1017/XPS.2020.37",
        "paper_author": "Kreps S.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States",
        "affiliation_id": "60007776",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Are plankton nets a thing of the past? An assessment of in situ imaging of zooplankton for large-scale ecosystem assessment and policy decision-making",
        "publication": "Frontiers in Marine Science",
        "citied_by": "14",
        "cover_date": "2022-11-16",
        "Abstract": "Zooplankton are fundamental to aquatic ecosystem services such as carbon and nutrient cycling. Therefore, a robust evidence base of how zooplankton respond to changes in anthropogenic pressures, such as climate change and nutrient loading, is key to implementing effective policy-making and management measures. Currently, the data on which to base this evidence, such as long time-series and large-scale datasets of zooplankton distribution and community composition, are too sparse owing to practical limitations in traditional collection and analysis methods. The advance of in situ imaging technologies that can be deployed at large scales on autonomous platforms, coupled with artificial intelligence and machine learning (AI/ML) for image analysis, promises a solution. However, whether imaging could reasonably replace physical samples, and whether AI/ML can achieve a taxonomic resolution that scientists trust, is currently unclear. We here develop a roadmap for imaging and AI/ML for future zooplankton monitoring and research based on community consensus. To do so, we determined current perceptions of the zooplankton community with a focus on their experience and trust in the new technologies. Our survey revealed a clear consensus that traditional net sampling and taxonomy must be retained, yet imaging will play an important part in the future of zooplankton monitoring and research. A period of overlapping use of imaging and physical sampling systems is needed before imaging can reasonably replace physical sampling for widespread time-series zooplankton monitoring. In addition, comprehensive improvements in AI/ML and close collaboration between zooplankton researchers and AI developers are needed for AI-based taxonomy to be trusted and fully adopted. Encouragingly, the adoption of cutting-edge technologies for zooplankton research may provide a solution to maintaining the critical taxonomic and ecological knowledge needed for future zooplankton monitoring and robust evidence-based policy decision-making.",
        "DOI": "10.3389/fmars.2022.986206",
        "paper_author": "Giering S.L.C.",
        "affiliation_name": "National Oceanography Centre Southampton",
        "affiliation_city": "Southampton",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60010934",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ultrafast true-green Ho:ZBLAN fiber laser inspired by the TD3 AI algorithm",
        "publication": "Optics Letters",
        "citied_by": "7",
        "cover_date": "2022-11-15",
        "Abstract": "Ultrafast lasers in the true-green spectrum, which are scarce due to the \"green gap\"in semiconductor materials, are in high demand for the surging field of biomedical photonics. One ideal candidate for efficient green lasing is Ho:ZBLAN fiber, as ZBLAN-hosted fibers have already reached picosecond dissipative soliton resonance (DSR) in the yellow. When attempting to push the DSR mode locking further into the green, traditional manual cavity tuning is faced with extreme difficulty, as the emission regime for these fiber lasers is so deeply concealed. Breakthroughs in artificial intelligence (AI), however, provide the opportunity to fulfill the task in a fully automated manner. This work, inspired by the emerging twin delayed deep deterministic policy gradient (TD3) algorithm, represents the first application, to the best of our knowledge, of the TD3 AI algorithm to generate picosecond emissions at the unprecedented true-green wavelength of ∼545 nm. The study thus extends the ongoing AI technique further into the ultrafast photonics region.",
        "DOI": "10.1364/OL.476942",
        "paper_author": "Luo S.",
        "affiliation_name": "Nanjing University of Science and Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60010080",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "The future of artificial intelligence in Southeast Asia: The case of Thailand",
        "publication": "Handbook of Research on Artificial Intelligence and Knowledge Management in Asia's Digital Economy",
        "citied_by": "3",
        "cover_date": "2022-11-11",
        "Abstract": "Thailand's robotics and artificial intelligence (AI) skills are increasing quickly as a result of its relevance to global supply chains and the improvements pushed by the coronavirus outbreak and global megatrends. The Thai government has incorporated AI into its National Development Plan, and the Thailand 4.0 national policy pays a lot of attention to AI, robotics, and digital industries. Since AI has a significant influence on digital transactions and Thailand's economic growth, the Thai government must foresee future advancements, particularly in the AI industry, in order to respond effectively to the volatile and uncertain future. Therefore, the technique of strategic foresight was employed to analyze the future of AI in Thailand. At the end of the chapter, a policy recommendation for how Thailand should deal with the future of AI is also made.",
        "DOI": "10.4018/978-1-6684-5849-5.ch002",
        "paper_author": "Mongkol K.",
        "affiliation_name": "Srinakharinwirot University",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand",
        "affiliation_id": "60000316",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The trading robot regulatory naratives: AI implications in Indonesia",
        "publication": "Handbook of Research on Artificial Intelligence and Knowledge Management in Asia's Digital Economy",
        "citied_by": "0",
        "cover_date": "2022-11-11",
        "Abstract": "Digital finance trading is a thriving market in Indonesia as an emerging country with enormous digital economy potency in the world. The increasing number of transactions in this market yields inevitable risks such as illegal trading, ponzi scheme, or binary option that may harm Indonesian investors as well as developers. Amid its huge potential in the future, this AI-based finance \"trading robot\" brings regulatory challenges since it may expose a gray area of the regulation. Study on this matter is limited. Therefore, this chapter introduces trading robot regulation in Indonesia based on narrative policy analysis approach through literature reviews, which highlights three domains of discussions: 1) the provider legality; 2) the technology specifications, and 3) the developer criteria.",
        "DOI": "10.4018/978-1-6684-5849-5.ch005",
        "paper_author": "Hamjen H.",
        "affiliation_name": "National Research and Innovation Agency Indonesia",
        "affiliation_city": null,
        "affiliation_country": "Indonesia",
        "affiliation_id": "128972181",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Research Handbook on Line Managers",
        "publication": "Research Handbook on Line Managers",
        "citied_by": "3",
        "cover_date": "2022-11-11",
        "Abstract": "This timely Research Handbook brings together 24 chapters with a wide range of different theoretical perspectives, empirical research, and innovative thought provoking ideas relating to an area of organisation and management that has been neglected for many decades - line managers. With a resurgence of interest in the topic in recent decades, this Research Handbook argues that line managers are a critical element of both employee experiences and organisational performance and worthy of close attention. Split into three sections, chapters present various ways in which line managers can implement HRM practices in the organisation, considering the implementation of a variety of HRM policies and practices (content), a variety of implementation processes (process), and a variety of line management actors. It also develops future directions for research on line managers, such as the future of work, digitalisation, robotisation and AI and the gig economy. Integrating theoretical and empirical research, the Research Handbook on Line Managers will be a key resource for scholars in the fields of business leadership, human resource management and organisation studies. It also provides managerial practices for organisations and line managers who are looking to improve the effectiveness and the efficiency of their work.",
        "DOI": "10.4337/9781839102745",
        "paper_author": "Townsend K.",
        "affiliation_name": "Griffith University",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60032987",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Challenges and best practices in corporate AI governance: Lessons from the biopharmaceutical industry",
        "publication": "Frontiers in Computer Science",
        "citied_by": "10",
        "cover_date": "2022-11-10",
        "Abstract": "While the use of artificial intelligence (AI) systems promises to bring significant economic and social benefits, it is also coupled with ethical, legal, and technical challenges. Business leaders thus face the question of how to best reap the benefits of automation whilst managing the associated risks. As a first step, many companies have committed themselves to various sets of ethics principles aimed at guiding the design and use of AI systems. So far so good. But how can well-intentioned ethical principles be translated into effective practice? And what challenges await companies that attempt to operationalize AI governance? In this article, we address these questions by drawing on our first-hand experience of shaping and driving the roll-out of AI governance within AstraZeneca, a biopharmaceutical company. The examples we discuss highlight challenges that any organization attempting to operationalize AI governance will have to face. These include questions concerning how to define the material scope of AI governance, how to harmonize standards across decentralized organizations, and how to measure the impact of specific AI governance initiatives. By showcasing how AstraZeneca managed these operational questions, we hope to provide project managers, CIOs, AI practitioners, and data privacy officers responsible for designing and implementing AI governance frameworks within other organizations with generalizable best practices. In essence, companies seeking to operationalize AI governance are encouraged to build on existing policies and governance structures, use pragmatic and action-oriented terminology, focus on risk management in development and procurement, and empower employees through continuous education and change management.",
        "DOI": "10.3389/fcomp.2022.1068361",
        "paper_author": "Mökander J.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175816",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Integration of artificial intelligence of things (AIoT) in the public sector: drivers, barriers and future research agenda",
        "publication": "Digital Policy, Regulation and Governance",
        "citied_by": "21",
        "cover_date": "2022-11-09",
        "Abstract": "Purpose: With the development of information technology (IT), governments around the globe are using state-of-the-art IT interfaces to implement the so-called 3E’s in public service delivery, that is, economy, efficiency and effectiveness. Two of these IT interfaces relate to Artificial Intelligence (AI) and Internet of Things (IoT). While AI focuses on providing a “human” garb for computing devices, thereby making them “intelligent” devices, IoT relies on interfaces between sensors and the environment to make “intelligent” decisions. Recently, the convergence of AI and IoT – also referred to as Artificial Intelligence of Things (AIoT) – is seen as a real opportunity to refurbish the public service delivery formats. However, there is limited understanding as to how AIoT could contribute to the improvisation of public service delivery. This study aims to create a modular framework for AIoT in addition to highlighting the drivers and barriers for its integration in the public sector. Design/methodology/approach: This descriptive-explanatory study takes a qualitative approach. It entails a thorough examination of the drivers and barriers of integrating AI and IoT in the public sector. A review of literature has led to the development of a conceptual framework outlining the various factors that contribute to creating public value. Findings: Value creation occurs when AI and IoT coalesce in the public service delivery mechanisms. Originality/value: AIoT is a cutting-edge technology revolutionizing health care, agriculture, infrastructure and all other industrial domains. This study adds to the growing body of knowledge on the public sector's use of AI and IoT. Understanding these disruptive technologies is critical to formulating policies and regulations that can maximize the potential benefits for the public-sector organizations.",
        "DOI": "10.1108/DPRG-06-2022-0067",
        "paper_author": "Ishengoma F.R.",
        "affiliation_name": "The University of Dodoma",
        "affiliation_city": "Dodoma",
        "affiliation_country": "Tanzania",
        "affiliation_id": "60138517",
        "affiliation_state": "NA"
    }
]