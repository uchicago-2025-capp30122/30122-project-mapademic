[
    {
        "paper_title": "MitoCarta3.0: An updated mitochondrial proteome now with sub-organelle localization and pathway annotations",
        "publication": "Nucleic Acids Research",
        "citied_by": "821",
        "cover_date": "2021-01-08",
        "Abstract": "The mammalian mitochondrial proteome is under dual genomic control, with 99% of proteins encoded by the nuclear genome and 13 originating from the mitochondrial DNA (mtDNA). We previously developed MitoCarta, a catalogue of over 1000 genes encoding the mammalian mitochondrial proteome. This catalogue was compiled using a Bayesian integration of multiple sequence features and experimental datasets, notably protein mass spectrometry of mitochondria isolated from fourteen murine tissues. Here, we introduce MitoCarta3.0. Beginning with the MitoCarta2.0 inventory, we performed manual review to remove 100 genes and introduce 78 additional genes, arriving at an updated inventory of 1136 human genes. We now include manually curated annotations of sub-mitochondrial localization (matrix, inner membrane, intermembrane space, outer membrane) as well as assignment to 149 hierarchical 'MitoPathways' spanning seven broad functional categories relevant to mitochondria. MitoCarta3.0, including sub-mitochondrial localization and MitoPathway annotations, is freely available at http://www.broadinstitute.org/mitocarta and should serve as a continued community resource for mitochondrial biology and medicine.",
        "DOI": "10.1093/nar/gkaa1011",
        "paper_author": "Rath S.",
        "affiliation_name": "Broad Institute",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60001001",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Antibiotic resistance in microbes: History, mechanisms, therapeutic strategies and future prospects",
        "publication": "Journal of Infection and Public Health",
        "citied_by": "613",
        "cover_date": "2021-12-01",
        "Abstract": "Antibiotics have been used to cure bacterial infections for more than 70 years, and these low-molecular-weight bioactive agents have also been used for a variety of other medicinal applications. In the battle against microbes, antibiotics have certainly been a blessing to human civilization by saving millions of lives. Globally, infections caused by multidrug-resistant (MDR) bacteria are on the rise. Antibiotics are being used to combat diversified bacterial infections. Synthetic biology techniques, in combination with molecular, functional genomic, and metagenomic studies of bacteria, plants, and even marine invertebrates are aimed at unlocking the world's natural products faster than previous methods of antibiotic discovery. There are currently only few viable remedies, potential preventive techniques, and a limited number of antibiotics, thereby necessitating the discovery of innovative medicinal approaches and antimicrobial therapies. MDR is also facilitated by biofilms, which makes infection control more complex. In this review, we have spotlighted comprehensively various aspects of antibiotics viz. overview of antibiotics era, mode of actions of antibiotics, development and mechanisms of antibiotic resistance in bacteria, and future strategies to fight the emerging antimicrobial resistant threat.",
        "DOI": "10.1016/j.jiph.2021.10.020",
        "paper_author": "Uddin T.M.",
        "affiliation_name": "University of Dhaka",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60014714",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "IOBR: Multi-Omics Immuno-Oncology Biological Research to Decode Tumor Microenvironment and Signatures",
        "publication": "Frontiers in Immunology",
        "citied_by": "607",
        "cover_date": "2021-07-02",
        "Abstract": "Recent advances in next-generation sequencing (NGS) technologies have triggered the rapid accumulation of publicly available multi-omics datasets. The application of integrated omics to explore robust signatures for clinical translation is increasingly emphasized, and this is attributed to the clinical success of immune checkpoint blockades in diverse malignancies. However, effective tools for comprehensively interpreting multi-omics data are still warranted to provide increased granularity into the intrinsic mechanism of oncogenesis and immunotherapeutic sensitivity. Therefore, we developed a computational tool for effective Immuno-Oncology Biological Research (IOBR), providing a comprehensive investigation of the estimation of reported or user-built signatures, TME deconvolution, and signature construction based on multi-omics data. Notably, IOBR offers batch analyses of these signatures and their correlations with clinical phenotypes, long non-coding RNA (lncRNA) profiling, genomic characteristics, and signatures generated from single-cell RNA sequencing (scRNA-seq) data in different cancer settings. Additionally, IOBR integrates multiple existing microenvironmental deconvolution methodologies and signature construction tools for convenient comparison and selection. Collectively, IOBR is a user-friendly tool for leveraging multi-omics data to facilitate immuno-oncology exploration and to unveil tumor-immune interactions and accelerating precision immunotherapy.",
        "DOI": "10.3389/fimmu.2021.687975",
        "paper_author": "Zeng D.",
        "affiliation_name": "Southern Medical University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60002593",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Recent advances in electrochemical biosensors: Applications, challenges, and future scope",
        "publication": "Biosensors",
        "citied_by": "580",
        "cover_date": "2021-09-01",
        "Abstract": "The electrochemical biosensors are a class of biosensors which convert biological information such as analyte concentration that is a biological recognition element (biochemical receptor) into current or voltage. Electrochemical biosensors depict propitious diagnostic technology which can detect biomarkers in body fluids such as sweat, blood, feces, or urine. Combinations of suitable immobilization techniques with effective transducers give rise to an efficient biosensor. They have been employed in the food industry, medical sciences, defense, studying plant biology, etc. While sensing complex structures and entities, a large data is obtained, and it becomes difficult to manually interpret all the data. Machine learning helps in interpreting large sensing data. In the case of biosensors, the presence of impurity affects the performance of the sensor and machine learning helps in removing signals obtained from the contaminants to obtain a high sensitivity. In this review, we discuss different types of biosensors along with their applications and the benefits of machine learning. This is followed by a discussion on the challenges, missing gaps in the knowledge, and solutions in the field of electrochemical biosensors. This review aims to serve as a valuable resource for scientists and engineers entering the interdisciplinary field of electrochemical biosensors. Further-more, this review provides insight into the type of electrochemical biosensors, their applications, the importance of machine learning (ML) in biosensing, and challenges and future outlook.",
        "DOI": "10.3390/bios11090336",
        "paper_author": "Singh A.",
        "affiliation_name": "University of Jammu",
        "affiliation_city": "Jammu",
        "affiliation_country": "India",
        "affiliation_id": "60031541",
        "affiliation_state": "JK"
    },
    {
        "paper_title": "Swarm Learning for decentralized and confidential clinical machine learning",
        "publication": "Nature",
        "citied_by": "579",
        "cover_date": "2021-06-10",
        "Abstract": "Fast and reliable detection of patients with severe and heterogeneous illnesses is a major goal of precision medicine1,2. Patients with leukaemia can be identified using machine learning on the basis of their blood transcriptomes3. However, there is an increasing divide between what is technically possible and what is allowed, because of privacy legislation4,5. Here, to facilitate the integration of any medical data from any data owner worldwide without violating privacy laws, we introduce Swarm Learning—a decentralized machine-learning approach that unites edge computing, blockchain-based peer-to-peer networking and coordination while maintaining confidentiality without the need for a central coordinator, thereby going beyond federated learning. To illustrate the feasibility of using Swarm Learning to develop disease classifiers using distributed data, we chose four use cases of heterogeneous diseases (COVID-19, tuberculosis, leukaemia and lung pathologies). With more than 16,400 blood transcriptomes derived from 127 clinical studies with non-uniform distributions of cases and controls and substantial study biases, as well as more than 95,000 chest X-ray images, we show that Swarm Learning classifiers outperform those developed at individual sites. In addition, Swarm Learning completely fulfils local confidentiality regulations by design. We believe that this approach will notably accelerate the introduction of precision medicine.",
        "DOI": "10.1038/s41586-021-03583-3",
        "paper_author": "Warnat-Herresthal S.",
        "affiliation_name": "Universität Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany",
        "affiliation_id": "60007493",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "MRI-based clinical-radiomics model predicts tumor response before treatment in locally advanced rectal cancer",
        "publication": "Scientific Reports",
        "citied_by": "519",
        "cover_date": "2021-12-01",
        "Abstract": "Neoadjuvant chemo-radiotherapy (CRT) followed by total mesorectal excision (TME) represents the standard treatment for patients with locally advanced (≥ T3 or N+) rectal cancer (LARC). Approximately 15% of patients with LARC shows a complete response after CRT. The use of pre-treatment MRI as predictive biomarker could help to increase the chance of organ preservation by tailoring the neoadjuvant treatment. We present a novel machine learning model combining pre-treatment MRI-based clinical and radiomic features for the early prediction of treatment response in LARC patients. MRI scans (3.0 T, T2-weighted) of 72 patients with LARC were included. Two readers independently segmented each tumor. Radiomic features were extracted from both the “tumor core” (TC) and the “tumor border” (TB). Partial least square (PLS) regression was used as the multivariate, machine learning, algorithm of choice and leave-one-out nested cross-validation was used to optimize hyperparameters of the PLS. The MRI-Based “clinical-radiomic” machine learning model properly predicted the treatment response (AUC = 0.793, p = 5.6 × 10–5). Importantly, the prediction improved when combining MRI-based clinical features and radiomic features, the latter extracted from both TC and TB. Prospective validation studies in randomized clinical trials are warranted to better define the role of radiomics in the development of rectal cancer precision medicine.",
        "DOI": "10.1038/s41598-021-84816-3",
        "paper_author": "Delli Pizzi A.",
        "affiliation_name": "University of G. d'Annunzio Chieti and Pescara",
        "affiliation_city": "Chieti",
        "affiliation_country": "Italy",
        "affiliation_id": "60004638",
        "affiliation_state": "CH"
    },
    {
        "paper_title": "Deep learning in histopathology: the path to the clinic",
        "publication": "Nature Medicine",
        "citied_by": "503",
        "cover_date": "2021-05-01",
        "Abstract": "Machine learning techniques have great potential to improve medical diagnostics, offering ways to improve accuracy, reproducibility and speed, and to ease workloads for clinicians. In the field of histopathology, deep learning algorithms have been developed that perform similarly to trained pathologists for tasks such as tumor detection and grading. However, despite these promising results, very few algorithms have reached clinical implementation, challenging the balance between hope and hype for these new techniques. This Review provides an overview of the current state of the field, as well as describing the challenges that still need to be addressed before artificial intelligence in histopathology can achieve clinical value.",
        "DOI": "10.1038/s41591-021-01343-4",
        "paper_author": "van der Laak J.",
        "affiliation_name": "Radboud University Medical Center",
        "affiliation_city": "Nijmegen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60002573",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Deep learning in cancer diagnosis, prognosis and treatment selection",
        "publication": "Genome Medicine",
        "citied_by": "458",
        "cover_date": "2021-12-01",
        "Abstract": "Deep learning is a subdiscipline of artificial intelligence that uses a machine learning technique called artificial neural networks to extract patterns and make predictions from large data sets. The increasing adoption of deep learning across healthcare domains together with the availability of highly characterised cancer datasets has accelerated research into the utility of deep learning in the analysis of the complex biology of cancer. While early results are promising, this is a rapidly evolving field with new knowledge emerging in both cancer biology and deep learning. In this review, we provide an overview of emerging deep learning techniques and how they are being applied to oncology. We focus on the deep learning applications for omics data types, including genomic, methylation and transcriptomic data, as well as histopathology-based genomic inference, and provide perspectives on how the different data types can be integrated to develop decision support tools. We provide specific examples of how deep learning may be applied in cancer diagnosis, prognosis and treatment management. We also assess the current limitations and challenges for the application of deep learning in precision oncology, including the lack of phenotypically rich data and the need for more explainable deep learning models. Finally, we conclude with a discussion of how current obstacles can be overcome to enable future clinical utilisation of deep learning.",
        "DOI": "10.1186/s13073-021-00968-x",
        "paper_author": "Tran K.A.",
        "affiliation_name": "QIMR Berghofer Medical Research Institute",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60025029",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",
        "publication": "BMJ Open",
        "citied_by": "435",
        "cover_date": "2021-07-09",
        "Abstract": "The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. CRD42019140361 and CRD42019161764.",
        "DOI": "10.1136/bmjopen-2020-048008",
        "paper_author": "Collins G.S.",
        "affiliation_name": "University of Oxford Medical Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60002634",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Using machine learning approaches for multi-omics data analysis: A review",
        "publication": "Biotechnology Advances",
        "citied_by": "427",
        "cover_date": "2021-07-01",
        "Abstract": "With the development of modern high-throughput omic measurement platforms, it has become essential for biomedical studies to undertake an integrative (combined) approach to fully utilise these data to gain insights into biological systems. Data from various omics sources such as genetics, proteomics, and metabolomics can be integrated to unravel the intricate working of systems biology using machine learning-based predictive algorithms. Machine learning methods offer novel techniques to integrate and analyse the various omics data enabling the discovery of new biomarkers. These biomarkers have the potential to help in accurate disease prediction, patient stratification and delivery of precision medicine. This review paper explores different integrative machine learning methods which have been used to provide an in-depth understanding of biological systems during normal physiological functioning and in the presence of a disease. It provides insight and recommendations for interdisciplinary professionals who envisage employing machine learning skills in multi-omics studies.",
        "DOI": "10.1016/j.biotechadv.2021.107739",
        "paper_author": "Reel P.S.",
        "affiliation_name": "University of Dundee School of Medicine",
        "affiliation_city": "Dundee",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60171138",
        "affiliation_state": "Scotland"
    },
    {
        "paper_title": "Synthetic data in machine learning for medicine and healthcare",
        "publication": "Nature Biomedical Engineering",
        "citied_by": "375",
        "cover_date": "2021-06-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41551-021-00751-8",
        "paper_author": "Chen R.J.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective",
        "publication": "Progress in Retinal and Eye Research",
        "citied_by": "374",
        "cover_date": "2021-05-01",
        "Abstract": "The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a “new normal”, the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.",
        "DOI": "10.1016/j.preteyeres.2020.100900",
        "paper_author": "Li J.P.O.",
        "affiliation_name": "Moorfields Eye Hospital NHS Foundation Trust",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60016691",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Current challenges and future opportunities for xai in machine learning-based clinical decision support systems: A systematic review",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "339",
        "cover_date": "2021-06-01",
        "Abstract": "Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs.",
        "DOI": "10.3390/app11115088",
        "paper_author": "Antoniadi A.M.",
        "affiliation_name": "University College Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland",
        "affiliation_id": "60005141",
        "affiliation_state": "Leinster"
    },
    {
        "paper_title": "Artifi Cial intelligence in cancer research and precision medicine",
        "publication": "Cancer Discovery",
        "citied_by": "330",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial intelligence (AI) is rapidly reshaping cancer research and personalized clinical care. Availability of high-dimensionality datasets coupled with advances in high-performance computing, as well as innovative deep learning architectures, has led to an explosion of AI use in various aspects of oncology research. These applications range from detection and classification of cancer, to molecular characterization of tumors and their microenvironment, to drug discovery and repurposing, to predicting treatment outcomes for patients. As these advances start penetrating the clinic, we foresee a shifting paradigm in cancer care becoming strongly driven by AI. Significance: AI has the potential to dramatically affect nearly all aspects of oncology—from enhancing diagnosis to personalizing treatment and discovering novel anticancer drugs. Here, we review the recent enormous progress in the application of AI to oncology, highlight limitations and pitfalls, and chart a path for adoption of AI in the cancer clinic.",
        "DOI": "10.1158/2159-8290.CD-21-0090",
        "paper_author": "Bhinder B.",
        "affiliation_name": "Weill Cornell Medicine",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60007997",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "A Survey on Causal Inference",
        "publication": "ACM Transactions on Knowledge Discovery from Data",
        "citied_by": "329",
        "cover_date": "2021-06-01",
        "Abstract": "Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine, and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods.",
        "DOI": "10.1145/3444944",
        "paper_author": "Yao L.",
        "affiliation_name": "Alibaba Group Holding Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60118460",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Machine learning and natural language processing in mental health: Systematic review",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "269",
        "cover_date": "2021-05-01",
        "Abstract": "Background: Machine learning systems are part of the field of artificial intelligence that automatically learn models from data to make better decisions. Natural language processing (NLP), by using corpora and learning approaches, provides good performance in statistical tasks, such as text classification or sentiment mining. Objective: The primary aim of this systematic review was to summarize and characterize, in methodological and technical terms, studies that used machine learning and NLP techniques for mental health. The secondary aim was to consider the potential use of these methods in mental health clinical practice Methods: This systematic review follows the PRISMA (Preferred Reporting Items for Systematic Review and Meta-analysis) guidelines and is registered with PROSPERO (Prospective Register of Systematic Reviews; number CRD42019107376). The search was conducted using 4 medical databases (PubMed, Scopus, ScienceDirect, and PsycINFO) with the following keywords: machine learning, data mining, psychiatry, mental health, and mental disorder. The exclusion criteria were as follows: languages other than English, anonymization process, case studies, conference papers, and reviews. No limitations on publication dates were imposed. Results: A total of 327 articles were identified, of which 269 (82.3%) were excluded and 58 (17.7%) were included in the review. The results were organized through a qualitative perspective. Although studies had heterogeneous topics and methods, some themes emerged. Population studies could be grouped into 3 categories: patients included in medical databases, patients who came to the emergency room, and social media users. The main objectives were to extract symptoms, classify severity of illness, compare therapy effectiveness, provide psychopathological clues, and challenge the current nosography. Medical records and social media were the 2 major data sources. With regard to the methods used, preprocessing used the standard methods of NLP and unique identifier extraction dedicated to medical texts. Efficient classifiers were preferred rather than transparent functioning classifiers. Python was the most frequently used platform. Conclusions: Machine learning and NLP models have been highly topical issues in medicine in recent years and may be considered a new paradigm in medical research. However, these processes tend to confirm clinical hypotheses rather than developing entirely new information, and only one major category of the population (ie, social media users) is an imprecise cohort. Moreover, some language-specific features can improve the performance of NLP methods, and their extension to other languages should be more closely investigated. However, machine learning and NLP techniques provide useful information from unexplored data (ie, patients' daily habits that are usually inaccessible to care providers). Before considering It as an additional tool of mental health care, ethical issues remain and should be discussed in a timely manner. Machine learning and NLP methods may offer multiple perspectives in mental health research but should also be considered as tools to support clinical practice.",
        "DOI": "10.2196/15708",
        "paper_author": "Le Glaz A.",
        "affiliation_name": "Centre Hospitalier Universitaire de Brest",
        "affiliation_city": "Brest",
        "affiliation_country": "France",
        "affiliation_id": "60004765",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Epileptic seizures detection using deep learning techniques: A review",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "268",
        "cover_date": "2021-06-01",
        "Abstract": "A variety of screening approaches have been proposed to diagnose epileptic seizures, using electroencephalography (EEG) and magnetic resonance imaging (MRI) modalities. Artificial intelligence encompasses a variety of areas, and one of its branches is deep learning (DL). Before the rise of DL, conventional machine learning algorithms involving feature extraction were performed. This limited their performance to the ability of those handcrafting the features. However, in DL, the extraction of features and classification are entirely automated. The advent of these techniques in many areas of medicine, such as in the diagnosis of epileptic seizures, has made significant advances. In this study, a comprehensive overview of works focused on automated epileptic seizure detection using DL techniques and neuroimaging modalities is presented. Various methods proposed to diagnose epileptic seizures automatically using EEG and MRI modalities are described. In addition, rehabilitation systems developed for epileptic seizures using DL have been analyzed, and a summary is provided. The rehabilitation tools include cloud computing techniques and hardware required for implementation of DL algorithms. The important challenges in accurate detection of automated epileptic seizures using DL with EEG and MRI modalities are discussed. The advantages and limitations in employing DL-based techniques for epileptic seizures diagnosis are presented. Finally, the most promising DL models proposed and possible future works on automated epileptic seizure detection are delineated.",
        "DOI": "10.3390/ijerph18115780",
        "paper_author": "Shoeibi A.",
        "affiliation_name": "K. N. Toosi University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60016248",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Machine learning for precision medicine",
        "publication": "Genome",
        "citied_by": "266",
        "cover_date": "2021-01-01",
        "Abstract": "Precision medicine is an emerging approach to clinical research and patient care that focuses on understanding and treating disease by integrating multi-modal or multi-omics data from an individual to make patient-tailored decisions. With the large and complex datasets generated using precision medicine diagnostic approaches, novel techniques to process and understand these complex data were needed. At the same time, computer science has progressed rapidly to develop techniques that enable the storage, processing, and analysis of these complex datasets, a feat that traditional statistics and early computing technologies could not accomplish. Machine learning, a branch of artificial intelligence, is a computer science methodology that aims to identify complex patterns in data that can be used to make predictions or classifications on new unseen data or for advanced exploratory data analysis. Machine learning analysis of precision medicine’s multi-modal data allows for broad analysis of large datasets and ultimately a greater understanding of human health and disease. This review focuses on machine learning utilization for precision medicine’s “big data”, in the context of genetics, genomics, and beyond.",
        "DOI": "10.1139/gen-2020-0131",
        "paper_author": "Maceachern S.J.",
        "affiliation_name": "Cumming School of Medicine",
        "affiliation_city": "Calgary",
        "affiliation_country": "Canada",
        "affiliation_id": "60000953",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "A machine learning approach to diagnosing lung and colon cancer using a deep learning‐based classification framework",
        "publication": "Sensors (Switzerland)",
        "citied_by": "265",
        "cover_date": "2021-02-01",
        "Abstract": "The field of Medicine and Healthcare has attained revolutionary advancements in the last forty years. Within this period, the actual reasons behind numerous diseases were unveiled, novel diagnostic methods were designed, and new medicines were developed. Even after all these achievements, diseases like cancer continue to haunt us since we are still vulnerable to them. Cancer is the second leading cause of death globally; about one in every six people die suffering from it. Among many types of cancers, the lung and colon variants are the most common and deadliest ones. Together, they account for more than 25% of all cancer cases. However, identifying the disease at an early stage significantly improves the chances of survival. Cancer diagnosis can be automated by using the potential of Artificial Intelligence (AI), which allows us to assess more cases in less time and cost. With the help of modern Deep Learning (DL) and Digital Image Processing (DIP) techniques, this paper inscribes a classification framework to differentiate among five types of lung and colon tissues (two benign and three malignant) by analyzing their histopathological images. The acquired results show that the proposed framework can identify cancer tissues with a maximum of 96.33% accuracy. Implementation of this model will help medical professionals to develop an automatic and reliable system capable of identifying various types of lung and colon cancers.",
        "DOI": "10.3390/s21030748",
        "paper_author": "Masud M.",
        "affiliation_name": "Taif University",
        "affiliation_city": "Taif",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60091164",
        "affiliation_state": "Makkah al Mukarramah"
    },
    {
        "paper_title": "Towards multi-modal causability with Graph Neural Networks enabling information fusion for explainable AI",
        "publication": "Information Fusion",
        "citied_by": "264",
        "cover_date": "2021-07-01",
        "Abstract": "AI is remarkably successful and outperforms human experts in certain tasks, even in complex domains such as medicine. Humans on the other hand are experts at multi-modal thinking and can embed new inputs almost instantly into a conceptual knowledge space shaped by experience. In many fields the aim is to build systems capable of explaining themselves, engaging in interactive what-if questions. Such questions, called counterfactuals, are becoming important in the rising field of explainable AI (xAI). Our central hypothesis is that using conceptual knowledge as a guiding model of reality will help to train more explainable, more robust and less biased machine learning models, ideally able to learn from fewer data. One important aspect in the medical domain is that various modalities contribute to one single result. Our main question is “How can we construct a multi-modal feature representation space (spanning images, text, genomics data) using knowledge bases as an initial connector for the development of novel explanation interface techniques?”. In this paper we argue for using Graph Neural Networks as a method-of-choice, enabling information fusion for multi-modal causability (causability – not to confuse with causality – is the measurable extent to which an explanation to a human expert achieves a specified level of causal understanding). The aim of this paper is to motivate the international xAI community to further work into the fields of multi-modal embeddings and interactive explainability, to lay the foundations for effective future human–AI interfaces. We emphasize that Graph Neural Networks play a major role for multi-modal causability, since causal links between features can be defined directly using graph structures.",
        "DOI": "10.1016/j.inffus.2021.01.008",
        "paper_author": "Holzinger A.",
        "affiliation_name": "Medizinische Universität Graz",
        "affiliation_city": "Graz",
        "affiliation_country": "Austria",
        "affiliation_id": "60006224",
        "affiliation_state": "Styria"
    },
    {
        "paper_title": "A review on machine learning approaches and trends in drug discovery",
        "publication": "Computational and Structural Biotechnology Journal",
        "citied_by": "261",
        "cover_date": "2021-01-01",
        "Abstract": "Drug discovery aims at finding new compounds with specific chemical properties for the treatment of diseases. In the last years, the approach used in this search presents an important component in computer science with the skyrocketing of machine learning techniques due to its democratization. With the objectives set by the Precision Medicine initiative and the new challenges generated, it is necessary to establish robust, standard and reproducible computational methodologies to achieve the objectives set. Currently, predictive models based on Machine Learning have gained great importance in the step prior to preclinical studies. This stage manages to drastically reduce costs and research times in the discovery of new drugs. This review article focuses on how these new methodologies are being used in recent years of research. Analyzing the state of the art in this field will give us an idea of where cheminformatics will be developed in the short term, the limitations it presents and the positive results it has achieved. This review will focus mainly on the methods used to model the molecular data, as well as the biological problems addressed and the Machine Learning algorithms used for drug discovery in recent years.",
        "DOI": "10.1016/j.csbj.2021.08.011",
        "paper_author": "Carracedo-Reboredo P.",
        "affiliation_name": "Universidade da Coruña",
        "affiliation_city": "La Coruna",
        "affiliation_country": "Spain",
        "affiliation_id": "60023610",
        "affiliation_state": "A Coruña"
    },
    {
        "paper_title": "The promise of machine learning in predicting treatment outcomes in psychiatry",
        "publication": "World Psychiatry",
        "citied_by": "257",
        "cover_date": "2021-06-01",
        "Abstract": "For many years, psychiatrists have tried to understand factors involved in response to medications or psychotherapies, in order to personalize their treatment choices. There is now a broad and growing interest in the idea that we can develop models to personalize treatment decisions using new statistical approaches from the field of machine learning and applying them to larger volumes of data. In this pursuit, there has been a paradigm shift away from experimental studies to confirm or refute specific hypotheses towards a focus on the overall explanatory power of a predictive model when tested on new, unseen datasets. In this paper, we review key studies using machine learning to predict treatment outcomes in psychiatry, ranging from medications and psychotherapies to digital interventions and neurobiological treatments. Next, we focus on some new sources of data that are being used for the development of predictive models based on machine learning, such as electronic health records, smartphone and social media data, and on the potential utility of data from genetics, electrophysiology, neuroimaging and cognitive testing. Finally, we discuss how far the field has come towards implementing prediction tools in real-world clinical practice. Relatively few retrospective studies to-date include appropriate external validation procedures, and there are even fewer prospective studies testing the clinical feasibility and effectiveness of predictive models. Applications of machine learning in psychiatry face some of the same ethical challenges posed by these techniques in other areas of medicine or computer science, which we discuss here. In short, machine learning is a nascent but important approach to improve the effectiveness of mental health care, and several prospective clinical studies suggest that it may be working already.",
        "DOI": "10.1002/wps.20882",
        "paper_author": "Chekroud A.M.",
        "affiliation_name": "Yale School of Medicine",
        "affiliation_city": "New Haven",
        "affiliation_country": "United States",
        "affiliation_id": "60017994",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review",
        "publication": "JMIR Cancer",
        "citied_by": "251",
        "cover_date": "2021-10-01",
        "Abstract": "Background: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine.",
        "DOI": "10.2196/27850",
        "paper_author": "Xu L.",
        "affiliation_name": "University of Toronto, Institute of Biomaterials and Biomedical Engineering",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60089742",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "A deep look into radiomics",
        "publication": "Radiologia Medica",
        "citied_by": "245",
        "cover_date": "2021-10-01",
        "Abstract": "Radiomics is a process that allows the extraction and analysis of quantitative data from medical images. It is an evolving field of research with many potential applications in medical imaging. The purpose of this review is to offer a deep look into radiomics, from the basis, deeply discussed from a technical point of view, through the main applications, to the challenges that have to be addressed to translate this process in clinical practice. A detailed description of the main techniques used in the various steps of radiomics workflow, which includes image acquisition, reconstruction, pre-processing, segmentation, features extraction and analysis, is here proposed, as well as an overview of the main promising results achieved in various applications, focusing on the limitations and possible solutions for clinical implementation. Only an in-depth and comprehensive description of current methods and applications can suggest the potential power of radiomics in fostering precision medicine and thus the care of patients, especially in cancer detection, diagnosis, prognosis and treatment evaluation.",
        "DOI": "10.1007/s11547-021-01389-x",
        "paper_author": "Scapicchio C.",
        "affiliation_name": "Università di Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60028868",
        "affiliation_state": "PI"
    },
    {
        "paper_title": "Artificial intelligence and machine learning for medical imaging: A technology review",
        "publication": "Physica Medica",
        "citied_by": "239",
        "cover_date": "2021-03-01",
        "Abstract": "Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.",
        "DOI": "10.1016/j.ejmp.2021.04.016",
        "paper_author": "Barragán-Montero A.",
        "affiliation_name": "Université Catholique de Louvain",
        "affiliation_city": "Louvain-la-Neuve",
        "affiliation_country": "Belgium",
        "affiliation_id": "60000874",
        "affiliation_state": "WBR"
    },
    {
        "paper_title": "Multiscale Modeling Meets Machine Learning: What Can We Learn?",
        "publication": "Archives of Computational Methods in Engineering",
        "citied_by": "220",
        "cover_date": "2021-05-01",
        "Abstract": "Machine learning is increasingly recognized as a promising technology in the biological, biomedical, and behavioral sciences. There can be no argument that this technique is incredibly successful in image recognition with immediate applications in diagnostics including electrophysiology, radiology, or pathology, where we have access to massive amounts of annotated data. However, machine learning often performs poorly in prognosis, especially when dealing with sparse data. This is a field where classical physics-based simulation seems to remain irreplaceable. In this review, we identify areas in the biomedical sciences where machine learning and multiscale modeling can mutually benefit from one another: Machine learning can integrate physics-based knowledge in the form of governing equations, boundary conditions, or constraints to manage ill-posted problems and robustly handle sparse and noisy data; multiscale modeling can integrate machine learning to create surrogate models, identify system dynamics and parameters, analyze sensitivities, and quantify uncertainty to bridge the scales and understand the emergence of function. With a view towards applications in the life sciences, we discuss the state of the art of combining machine learning and multiscale modeling, identify applications and opportunities, raise open questions, and address potential challenges and limitations. We anticipate that it will stimulate discussion within the community of computational mechanics and reach out to other disciplines including mathematics, statistics, computer science, artificial intelligence, biomedicine, systems biology, and precision medicine to join forces towards creating robust and efficient models for biological systems.",
        "DOI": "10.1007/s11831-020-09405-5",
        "paper_author": "Peng G.C.Y.",
        "affiliation_name": "National Institutes of Health (NIH)",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States",
        "affiliation_id": "60006577",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "The promise of artificial intelligence: A review of the opportunities and challenges of artificial intelligence in healthcare",
        "publication": "British Medical Bulletin",
        "citied_by": "212",
        "cover_date": "2021-09-01",
        "Abstract": "Introduction: Artificial intelligence (AI) and machine learning (ML) are rapidly evolving fields in various sectors, including healthcare. This article reviews AI's present applications in healthcare, including its benefits, limitations and future scope. Sources of data: A review of the English literature was conducted with search terms 'AI' or 'ML' or 'deep learning' and 'healthcare' or 'medicine' using PubMED and Google Scholar from 2000-2021. Areas of agreement: AI could transform physician workflow and patient care through its applications, from assisting physicians and replacing administrative tasks to augmenting medical knowledge. Areas of controversy: From challenges training ML systems to unclear accountability, AI's implementation is difficult and incremental at best. Physicians also lack understanding of what AI implementation could represent. Growing points: AI can ultimately prove beneficial in healthcare, but requires meticulous governance similar to the governance of physician conduct. Areas timely for developing research: Regulatory guidelines are needed on how to safely implement and assess AI technology, alongside further research into the specific capabilities and limitations of its medical use.",
        "DOI": "10.1093/bmb/ldab016",
        "paper_author": "Aung Y.Y.M.",
        "affiliation_name": "Imperial College London School of Medicine",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60175990",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The molecular biology of pancreatic adenocarcinoma: translational challenges and clinical perspectives",
        "publication": "Signal Transduction and Targeted Therapy",
        "citied_by": "201",
        "cover_date": "2021-12-01",
        "Abstract": "Pancreatic cancer is an increasingly common cause of cancer mortality with a tight correspondence between disease mortality and incidence. Furthermore, it is usually diagnosed at an advanced stage with a very dismal prognosis. Due to the high heterogeneity, metabolic reprogramming, and dense stromal environment associated with pancreatic cancer, patients benefit little from current conventional therapy. Recent insight into the biology and genetics of pancreatic cancer has supported its molecular classification, thus expanding clinical therapeutic options. In this review, we summarize how the biological features of pancreatic cancer and its metabolic reprogramming as well as the tumor microenvironment regulate its development and progression. We further discuss potential biomarkers for pancreatic cancer diagnosis, prediction, and surveillance based on novel liquid biopsies. We also outline recent advances in defining pancreatic cancer subtypes and subtype-specific therapeutic responses and current preclinical therapeutic models. Finally, we discuss prospects and challenges in the clinical development of pancreatic cancer therapeutics.",
        "DOI": "10.1038/s41392-021-00659-4",
        "paper_author": "Wang S.",
        "affiliation_name": "Fudan University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60009860",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Graph Neural Networks and Their Current Applications in Bioinformatics",
        "publication": "Frontiers in Genetics",
        "citied_by": "198",
        "cover_date": "2021-07-29",
        "Abstract": "Graph neural networks (GNNs), as a branch of deep learning in non-Euclidean space, perform particularly well in various tasks that process graph structure data. With the rapid accumulation of biological network data, GNNs have also become an important tool in bioinformatics. In this research, a systematic survey of GNNs and their advances in bioinformatics is presented from multiple perspectives. We first introduce some commonly used GNN models and their basic principles. Then, three representative tasks are proposed based on the three levels of structural information that can be learned by GNNs: node classification, link prediction, and graph generation. Meanwhile, according to the specific applications for various omics data, we categorize and discuss the related studies in three aspects: disease prediction, drug discovery, and biomedical imaging. Based on the analysis, we provide an outlook on the shortcomings of current studies and point out their developing prospect. Although GNNs have achieved excellent results in many biological tasks at present, they still face challenges in terms of low-quality data processing, methodology, and interpretability and have a long road ahead. We believe that GNNs are potentially an excellent method that solves various biological problems in bioinformatics research.",
        "DOI": "10.3389/fgene.2021.690049",
        "paper_author": "Zhang X.M.",
        "affiliation_name": "Yunnan Normal University",
        "affiliation_city": "Chenggong",
        "affiliation_country": "China",
        "affiliation_id": "60019218",
        "affiliation_state": "Yunnan"
    },
    {
        "paper_title": "Artificial Convolutional Neural Network in Object Detection and Semantic Segmentation for Medical Imaging Analysis",
        "publication": "Frontiers in Oncology",
        "citied_by": "198",
        "cover_date": "2021-03-09",
        "Abstract": "In the era of digital medicine, a vast number of medical images are produced every day. There is a great demand for intelligent equipment for adjuvant diagnosis to assist medical doctors with different disciplines. With the development of artificial intelligence, the algorithms of convolutional neural network (CNN) progressed rapidly. CNN and its extension algorithms play important roles on medical imaging classification, object detection, and semantic segmentation. While medical imaging classification has been widely reported, the object detection and semantic segmentation of imaging are rarely described. In this review article, we introduce the progression of object detection and semantic segmentation in medical imaging study. We also discuss how to accurately define the location and boundary of diseases.",
        "DOI": "10.3389/fonc.2021.638182",
        "paper_author": "Yang R.",
        "affiliation_name": "Shanghai Jiao Tong University School of Medicine",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60082819",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Applications of Machine Learning in Human Microbiome Studies: A Review on Feature Selection, Biomarker Identification, Disease Prediction and Treatment",
        "publication": "Frontiers in Microbiology",
        "citied_by": "198",
        "cover_date": "2021-02-19",
        "Abstract": "The number of microbiome-related studies has notably increased the availability of data on human microbiome composition and function. These studies provide the essential material to deeply explore host-microbiome associations and their relation to the development and progression of various complex diseases. Improved data-analytical tools are needed to exploit all information from these biological datasets, taking into account the peculiarities of microbiome data, i.e., compositional, heterogeneous and sparse nature of these datasets. The possibility of predicting host-phenotypes based on taxonomy-informed feature selection to establish an association between microbiome and predict disease states is beneficial for personalized medicine. In this regard, machine learning (ML) provides new insights into the development of models that can be used to predict outputs, such as classification and prediction in microbiology, infer host phenotypes to predict diseases and use microbial communities to stratify patients by their characterization of state-specific microbial signatures. Here we review the state-of-the-art ML methods and respective software applied in human microbiome studies, performed as part of the COST Action ML4Microbiome activities. This scoping review focuses on the application of ML in microbiome studies related to association and clinical use for diagnostics, prognostics, and therapeutics. Although the data presented here is more related to the bacterial community, many algorithms could be applied in general, regardless of the feature type. This literature and software review covering this broad topic is aligned with the scoping review methodology. The manual identification of data sources has been complemented with: (1) automated publication search through digital libraries of the three major publishers using natural language processing (NLP) Toolkit, and (2) an automated identification of relevant software repositories on GitHub and ranking of the related research papers relying on learning to rank approach.",
        "DOI": "10.3389/fmicb.2021.634511",
        "paper_author": "Marcos-Zambrano L.J.",
        "affiliation_name": "IMDEA Food Institute",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain",
        "affiliation_id": "60121744",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "LitCovid: An open database of COVID-19 literature",
        "publication": "Nucleic Acids Research",
        "citied_by": "196",
        "cover_date": "2021-01-08",
        "Abstract": "Since the outbreak of the current pandemic in 2020, there has been a rapid growth of published articles on COVID-19 and SARS-CoV-2, with about 10 000 new articles added each month. This is causing an increasingly serious information overload, making it difficult for scientists, healthcare professionals and the general public to remain up to date on the latest SARS-CoV-2 and COVID-19 research. Hence, we developed LitCovid (https://www.ncbi.nlm.nih.gov/research/coronavirus/), a curated literature hub, to track up-to-date scientific information in PubMed. LitCovid is updated daily with newly identified relevant articles organized into curated categories. To support manual curation, advanced machine-learning and deep-learning algorithms have been developed, evaluated and integrated into the curation workflow. To the best of our knowledge, LitCovid is the first-of-its-kind COVID-19-specific literature resource, with all of its collected articles and curated data freely available. Since its release, LitCovid has been widely used, with millions of accesses by users worldwide for various information needs, such as evidence synthesis, drug discovery and text and data mining, among others.",
        "DOI": "10.1093/nar/gkaa952",
        "paper_author": "Chen Q.",
        "affiliation_name": "National Center for Biotechnology Information (NCBI)",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States",
        "affiliation_id": "60087823",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Machine Learning in Healthcare",
        "publication": "Current Genomics",
        "citied_by": "193",
        "cover_date": "2021-05-01",
        "Abstract": "Recent advancements in Artificial Intelligence (AI) and Machine Learning (ML) technology have brought on substantial strides in predicting and identifying health emergencies, disease populations, and disease state and immune response, amongst a few. Although, skepticism remains regarding the practical application and interpretation of results from ML-based approaches in healthcare settings, the inclusion of these approaches is increasing at a rapid pace. Here we provide a brief overview of machine learning-based approaches and learning algorithms including super-vised, unsupervised, and reinforcement learning along with examples. Second, we discuss the application of ML in several healthcare fields, including radiology, genetics, electronic health records, and neuroimaging. We also briefly discuss the risks and challenges of ML application to healthcare such as system privacy and ethical concerns and provide suggestions for future applications.",
        "DOI": "10.2174/1389202922666210705124359",
        "paper_author": "Habehh H.",
        "affiliation_name": "Rutgers School of Health Professions",
        "affiliation_city": "Newark",
        "affiliation_country": "United States",
        "affiliation_id": "60119732",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Precision health data: Requirements, challenges and existing techniques for data security and privacy",
        "publication": "Computers in Biology and Medicine",
        "citied_by": "191",
        "cover_date": "2021-02-01",
        "Abstract": "Precision health leverages information from various sources, including omics, lifestyle, environment, social media, medical records, and medical insurance claims to enable personalized care, prevent and predict illness, and precise treatments. It extensively uses sensing technologies (e.g., electronic health monitoring devices), computations (e.g., machine learning), and communication (e.g., interaction between the health data centers). As health data contain sensitive private information, including the identity of patient and carer and medical conditions of the patient, proper care is required at all times. Leakage of these private information affects the personal life, including bullying, high insurance premium, and loss of job due to the medical history. Thus, the security, privacy of and trust on the information are of utmost importance. Moreover, government legislation and ethics committees demand the security and privacy of healthcare data. Besides, the public, who is the data source, always expects the security, privacy, and trust of their data. Otherwise, they can avoid contributing their data to the precision health system. Consequently, as the public is the targeted beneficiary of the system, the effectiveness of precision health diminishes. Herein, in the light of precision health data security, privacy, ethical and regulatory requirements, finding the best methods and techniques for the utilization of the health data, and thus precision health is essential. In this regard, firstly, this paper explores the regulations, ethical guidelines around the world, and domain-specific needs. Then it presents the requirements and investigates the associated challenges. Secondly, this paper investigates secure and privacy-preserving machine learning methods suitable for the computation of precision health data along with their usage in relevant health projects. Finally, it illustrates the best available techniques for precision health data security and privacy with a conceptual system model that enables compliance, ethics clearance, consent management, medical innovations, and developments in the health domain.",
        "DOI": "10.1016/j.compbiomed.2020.104130",
        "paper_author": "Thapa C.",
        "affiliation_name": "Commonwealth Scientific and Industrial Research Organisation",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia",
        "affiliation_id": "60029470",
        "affiliation_state": "ACT"
    },
    {
        "paper_title": "Connected healthcare: Improving patient care using digital health technologies",
        "publication": "Advanced Drug Delivery Reviews",
        "citied_by": "184",
        "cover_date": "2021-11-01",
        "Abstract": "Now more than ever, traditional healthcare models are being overhauled with digital technologies of Healthcare 4.0 increasingly adopted. Worldwide, digital devices are improving every stage of the patient care pathway. For one, sensors are being used to monitor patient metrics 24/7, permitting swift diagnosis and interventions. At the treatment stage, 3D printers are under investigation for the concept of personalised medicine by allowing patients access to on-demand, customisable therapeutics. Robots are also being explored for treatment, by empowering precision surgery, rehabilitation, or targeted drug delivery. Within medical logistics, drones are being leveraged to deliver critical treatments to remote areas, collect samples, and even provide emergency aid. To enable seamless integration within healthcare, the Internet of Things technology is being exploited to form closed-loop systems that remotely communicate with one another. This review outlines the most promising healthcare technologies and devices, their strengths, drawbacks, and opportunities for clinical adoption.",
        "DOI": "10.1016/j.addr.2021.113958",
        "paper_author": "Awad A.",
        "affiliation_name": "UCL School of Pharmacy",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60016379",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Neoantigen: A New Breakthrough in Tumor Immunotherapy",
        "publication": "Frontiers in Immunology",
        "citied_by": "184",
        "cover_date": "2021-04-16",
        "Abstract": "Cancer immunotherapy works by stimulating and strengthening the body’s anti-tumor immune response to eliminate cancer cells. Over the past few decades, immunotherapy has shown remarkable efficacy in the treatment of cancer, particularly the success of immune checkpoint blockade targeting CTLA-4, PD-1 and PDL1, which has led to a breakthrough in tumor immunotherapy. Tumor neoantigens, a new approach to tumor immunotherapy, include antigens produced by tumor viruses integrated into the genome and antigens produced by mutant proteins, which are abundantly expressed only in tumor cells and have strong immunogenicity and tumor heterogeneity. A growing number of studies have highlighted the relationship between neoantigens and T cells’ recognition of cancer cells. Vaccines developed against neoantigens are now being used in clinical trials in various solid tumors. In this review, we summarized the latest advances in the classification of immunotherapy and the process of classification, identification and synthesis of tumor-specific neoantigens, as well as their role in current cancer immunotherapy. Finally, the application prospects and existing problems of neoantigens were discussed.",
        "DOI": "10.3389/fimmu.2021.672356",
        "paper_author": "Zhang Z.",
        "affiliation_name": "Xinxiang Medical University",
        "affiliation_city": "Xinxiang",
        "affiliation_country": "China",
        "affiliation_id": "60021296",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "Automation of systematic literature reviews: A systematic literature review",
        "publication": "Information and Software Technology",
        "citied_by": "175",
        "cover_date": "2021-08-01",
        "Abstract": "Context: Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking. Objective: This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research. Method: A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed. Results: This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions. Conclusion: According to our study, the leading automated step is the Selection of Primary Studies. Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process.",
        "DOI": "10.1016/j.infsof.2021.106589",
        "paper_author": "van Dinter R.",
        "affiliation_name": "Wageningen University &amp; Research",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60004156",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Multi-disease prediction based on deep learning: A survey",
        "publication": "CMES - Computer Modeling in Engineering and Sciences",
        "citied_by": "172",
        "cover_date": "2021-01-01",
        "Abstract": "In recent years, the development of artificial intelligence (AI) and the gradual beginning of AI's research in the medical field have allowed people to see the excellent prospects of the integration of AI and healthcare. Among them, the hot deep learning field has shown greater potential in applications such as disease prediction and drug response prediction. From the initial logistic regression model to the machine learning model, and then to the deep learning model today, the accuracy of medical disease prediction has been continuously improved, and the performance in all aspects has also been significantly improved. This article introduces some basic deep learning frameworks and some common diseases, and summarizes the deep learning prediction methods corresponding to different diseases. Point out a series of problems in the current disease prediction, and make a prospect for the future development. It aims to clarify the effectiveness of deep learning in disease prediction, and demonstrates the high correlation between deep learning and the medical field in future development. The unique feature extraction methods of deep learning methods can still play an important role in future medical research.",
        "DOI": "10.32604/CMES.2021.016728",
        "paper_author": "Xie S.",
        "affiliation_name": "Qingdao University",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China",
        "affiliation_id": "60030434",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "AI in medicine must be explainable",
        "publication": "Nature Medicine",
        "citied_by": "169",
        "cover_date": "2021-08-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41591-021-01461-z",
        "paper_author": "Kundu S.",
        "affiliation_name": "The Johns Hopkins Hospital",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60001555",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Deep learning and the electrocardiogram: Review of the current state-of-the-art",
        "publication": "Europace",
        "citied_by": "169",
        "cover_date": "2021-08-01",
        "Abstract": "In the recent decade, deep learning, a subset of artificial intelligence and machine learning, has been used to identify patterns in big healthcare datasets for disease phenotyping, event predictions, and complex decision making. Public datasets for electrocardiograms (ECGs) have existed since the 1980s and have been used for very specific tasks in cardiology, such as arrhythmia, ischemia, and cardiomyopathy detection. Recently, private institutions have begun curating large ECG databases that are orders of magnitude larger than the public databases for ingestion by deep learning models. These efforts have demonstrated not only improved performance and generalizability in these aforementioned tasks but also application to novel clinical scenarios. This review focuses on orienting the clinician towards fundamental tenets of deep learning, state-of-the-art prior to its use for ECG analysis, and current applications of deep learning on ECGs, as well as their limitations and future areas of improvement.",
        "DOI": "10.1093/europace/euaa377",
        "paper_author": "Somani S.",
        "affiliation_name": "Icahn School of Medicine at Mount Sinai",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60012981",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Involvement of Machine Learning Tools in Healthcare Decision Making",
        "publication": "Journal of Healthcare Engineering",
        "citied_by": "166",
        "cover_date": "2021-01-01",
        "Abstract": "In the present day, there are many diseases which need to be identified at their early stages to start relevant treatments. If not, they could be uncurable and deadly. Due to this reason, there is a need of analysing complex medical data, medical reports, and medical images at a lesser time but with greater accuracy. There are even some instances where certain abnormalities cannot be directly recognized by humans. In healthcare for computational decision making, machine learning approaches are being used in these types of situations where a crucial data analysis needs to be performed on medical data to reveal hidden relationships or abnormalities which are not visible to humans. Implementing algorithms to perform such tasks itself is difficult, but what makes it even more challenging is to increase the accuracy of the algorithm while decreasing the required time for the algorithm to execute. In the early days, processing of large amount of medical data was an important task which resulted in machine learning being adapted in the biological domain. Since this happened, the biology and biomedical fields have been reaching higher levels by exploring more knowledge and identifying relationships which were never observed before. Reaching to its peak now the concern is being diverted towards treating patients not only based on the type of disease but also their genetics, which is known as precision medicine. Modifications in machine learning algorithms are being performed and tested daily to improve the performance of the algorithms in analysing and presenting more accurate information. In the healthcare field, starting from information extraction from medical documents until the prediction or diagnosis of a disease, machine learning has been involved. Medical imaging is a section that was greatly improved with the integration of machine learning algorithms to the field of computational biology. Nowadays, many disease diagnoses are being performed by medical image processing using machine learning algorithms. In addition, patient care, resource allocation, and research on treatments for various diseases are also being performed using machine learning-based computational decision making. Throughout this paper, various machine learning algorithms and approaches that are being used for decision making in the healthcare sector will be discussed along with the involvement of machine learning in healthcare applications in the current context. With the explored knowledge, it was evident that neural network-based deep learning methods have performed extremely well in the field of computational biology with the support of the high processing power of modern sophisticated computers and are being extensively applied because of their high predicting accuracy and reliability. When giving concern towards the big picture by combining the observations, it is noticeable that computational biology and biomedicine-based decision making in healthcare have now become dependent on machine learning algorithms, and thus they cannot be separated from the field of artificial intelligence.",
        "DOI": "10.1155/2021/6679512",
        "paper_author": "Jayatilake S.M.D.A.C.",
        "affiliation_name": "University of Moratuwa",
        "affiliation_city": "Moratuwa",
        "affiliation_country": "Sri Lanka",
        "affiliation_id": "60071105",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "THE COMPLEXITY OF ALZHEIMER’S DISEASE: AN EVOLVING PUZZLE",
        "publication": "Physiological Reviews",
        "citied_by": "165",
        "cover_date": "2021-07-01",
        "Abstract": "The history of Alzheimer’s disease (AD) started in 1907, but we needed to wait until the end of the century to identify the components of pathological hallmarks and genetic subtypes and to formulate the first pathogenic hypothesis. Thanks to biomarkers and new technologies, the concept of AD then rapidly changed from a static view of an amnestic dementia of the presenium to a biological entity that could be clinically manifested as normal cognition or dementia of different types. What is clearly emerging from studies is that AD is heterogeneous in each aspect, such as amyloid composition, tau distribution, relation between amyloid and tau, clinical symptoms, and genetic background, and thus it is probably impossible to explain AD with a single pathological process. The scientific approach to AD suffers from chronological mismatches between clinical, pathological, and technological data, causing difficulty in conceiving diagnostic gold standards and in creating models for drug discovery and screening. A recent mathematical computer-based approach offers the opportunity to study AD in real life and to provide a new point of view and the final missing pieces of the AD puzzle.",
        "DOI": "10.1152/physrev.00015.2020",
        "paper_author": "Ferrari C.",
        "affiliation_name": "Università degli Studi di Firenze",
        "affiliation_city": "Florence",
        "affiliation_country": "Italy",
        "affiliation_id": "60021859",
        "affiliation_state": "FI"
    },
    {
        "paper_title": "Federated Learning in a Medical Context: A Systematic Literature Review",
        "publication": "ACM Transactions on Internet Technology",
        "citied_by": "162",
        "cover_date": "2021-01-01",
        "Abstract": "Data privacy is a very important issue. Especially in fields like medicine, it is paramount to abide by the existing privacy regulations to preserve patients' anonymity. However, data is required for research and training machine learning models that could help gain insight into complex correlations or personalised treatments that may otherwise stay undiscovered. Those models generally scale with the amount of data available, but the current situation often prohibits building large databases across sites. So it would be beneficial to be able to combine similar or related data from different sites all over the world while still preserving data privacy. Federated learning has been proposed as a solution for this, because it relies on the sharing of machine learning models, instead of the raw data itself. That means private data never leaves the site or device it was collected on. Federated learning is an emerging research area, and many domains have been identified for the application of those methods. This systematic literature review provides an extensive look at the concept of and research into federated learning and its applicability for confidential healthcare datasets.",
        "DOI": "10.1145/3412357",
        "paper_author": "Pfitzner B.",
        "affiliation_name": "Hasso-Plattner-Institut für Softwaresystemtechnik GmbH",
        "affiliation_city": "Potsdam",
        "affiliation_country": "Germany",
        "affiliation_id": "60106550",
        "affiliation_state": "Brandenburg"
    },
    {
        "paper_title": "Mitigating bias in machine learning for medicine",
        "publication": "Communications Medicine",
        "citied_by": "161",
        "cover_date": "2021-12-01",
        "Abstract": "NA",
        "DOI": "10.1038/s43856-021-00028-w",
        "paper_author": "Vokinger K.N.",
        "affiliation_name": "Universität Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60012614",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Digital Twins for Multiple Sclerosis",
        "publication": "Frontiers in Immunology",
        "citied_by": "158",
        "cover_date": "2021-05-03",
        "Abstract": "An individualized innovative disease management is of great importance for people with multiple sclerosis (pwMS) to cope with the complexity of this chronic, multidimensional disease. However, an individual state of the art strategy, with precise adjustment to the patient’s characteristics, is still far from being part of the everyday care of pwMS. The development of digital twins could decisively advance the necessary implementation of an individualized innovative management of MS. Through artificial intelligence-based analysis of several disease parameters – including clinical and para-clinical outcomes, multi-omics, biomarkers, patient-related data, information about the patient’s life circumstances and plans, and medical procedures – a digital twin paired to the patient’s characteristic can be created, enabling healthcare professionals to handle large amounts of patient data. This can contribute to a more personalized and effective care by integrating data from multiple sources in a standardized manner, implementing individualized clinical pathways, supporting physician-patient communication and facilitating a shared decision-making. With a clear display of pre-analyzed patient data on a dashboard, patient participation and individualized clinical decisions as well as the prediction of disease progression and treatment simulation could become possible. In this review, we focus on the advantages, challenges and practical aspects of digital twins in the management of MS. We discuss the use of digital twins for MS as a revolutionary tool to improve diagnosis, monitoring and therapy refining patients’ well-being, saving economic costs, and enabling prevention of disease progression. Digital twins will help make precision medicine and patient-centered care a reality in everyday life.",
        "DOI": "10.3389/fimmu.2021.669811",
        "paper_author": "Voigt I.",
        "affiliation_name": "Universitätsklinikum Carl Gustav Carus Dresden",
        "affiliation_city": "Dresden",
        "affiliation_country": "Germany",
        "affiliation_id": "60204338",
        "affiliation_state": "Sachsen"
    },
    {
        "paper_title": "Application of decision tree-based ensemble learning in the classification of breast cancer",
        "publication": "Computers in Biology and Medicine",
        "citied_by": "157",
        "cover_date": "2021-01-01",
        "Abstract": "As a common screening and diagnostic tool, Fine Needle Aspiration Biopsy (FNAB) of the suspicious breast lumps can be used to distinguish between malignant and benign breast cytology. In this study, we first review published works on the classification of breast cancer where the machine learning and data mining algorithms have been applied by using the Wisconsin Breast Cancer Database (WBCD). This work then introduces useful new tools, based on Random Forest (RF) and Extremely Randomized Trees or Extra Trees (ET) algorithms to classify breast cancer. The RF and ET strategies use the decision trees as proper classifiers to attain the ultimate classification. The RF and ET approaches include four main stages: input identification, determination of the optimal number of trees, voting analysis, and final decision. The models implemented in this research consider important factors such as uniformity of cell size, bland chromatin, mitoses, and clump thickness as the input parameters. According to the statistical analysis, the proposed methods are able to classify the type of breast cancer accurately. The error analysis results reveal that the designed RF and ET models offer easy-to-use outcomes and the highest diagnostic performance, compared to previous tools/models in the literature for the WBCD classification. The highest and lowest magnitudes of relative importance are attributed to the uniformity of cell size and mitoses among the factors. It is expected that the RF and ET algorithms play an important role in medicine and health systems for screening and diagnosis in the near future.",
        "DOI": "10.1016/j.compbiomed.2020.104089",
        "paper_author": "Ghiasi M.M.",
        "affiliation_name": "Memorial University of Newfoundland",
        "affiliation_city": "St John's",
        "affiliation_country": "Canada",
        "affiliation_id": "60019000",
        "affiliation_state": "NL"
    },
    {
        "paper_title": "Ranking microbiome variance in inflammatory bowel disease: A large longitudinal intercontinental study",
        "publication": "Gut",
        "citied_by": "155",
        "cover_date": "2021-03-01",
        "Abstract": "Objective The microbiome contributes to the pathogenesis of inflammatory bowel disease (IBD) but the relative contribution of different lifestyle and environmental factors to the compositional variability of the gut microbiota is unclear. Design Here, we rank the size effect of disease activity, medications, diet and geographic location of the faecal microbiota composition (16S rRNA gene sequencing) in patients with Crohn's disease (CD; n=303), ulcerative colitis (UC; n = 228) and controls (n=161), followed longitudinally (at three time points with 16 weeks intervals). Results Reduced microbiota diversity but increased variability was confirmed in CD and UC compared with controls. Significant compositional differences between diseases, particularly CD, and controls were evident. Longitudinal analyses revealed reduced temporal microbiota stability in IBD, particularly in patients with changes in disease activity. Machine learning separated disease from controls, and active from inactive disease, when consecutive time points were modelled. Geographic location accounted for most of the microbiota variance, second to the presence or absence of CD, followed by history of surgical resection, alcohol consumption and UC diagnosis, medications and diet with most (90.3%) of the compositional variance stochastic or unexplained. Conclusion The popular concept of precision medicine and rational design of any therapeutic manipulation of the microbiota will have to contend not only with the heterogeneity of the host response, but also with widely differing lifestyles and with much variance still unaccounted for.",
        "DOI": "10.1136/gutjnl-2020-321106",
        "paper_author": "Clooney A.G.",
        "affiliation_name": "APC Microbiome Ireland",
        "affiliation_city": "Cork",
        "affiliation_country": "Ireland",
        "affiliation_id": "60005857",
        "affiliation_state": "Munster"
    },
    {
        "paper_title": "Low-dose CT image and projection dataset",
        "publication": "Medical Physics",
        "citied_by": "154",
        "cover_date": "2021-02-01",
        "Abstract": "Purpose: To describe a large, publicly available dataset comprising computed tomography (CT) projection data from patient exams, both at routine clinical doses and simulated lower doses. Acquisition and Validation Methods: The library was developed under local ethics committee approval. Projection and image data from 299 clinically performed patient CT exams were archived for three types of clinical exams: noncontrast head CT scans acquired for acute cognitive or motor deficit, low-dose noncontrast chest scans acquired to screen high-risk patients for pulmonary nodules, and contrast-enhanced CT scans of the abdomen acquired to look for metastatic liver lesions. Scans were performed on CT systems from two different CT manufacturers using routine clinical protocols. Projection data were validated by reconstructing the data using several different reconstruction algorithms and through use of the data in the 2016 Low Dose CT Grand Challenge. Reduced dose projection data were simulated for each scan using a validated noise-insertion method. Radiologists marked location and diagnosis for detected pathologies. Reference truth was obtained from the patient medical record, either from histology or subsequent imaging. Data Format and Usage Notes: Projection datasets were converted into the previously developed DICOM-CT-PD format, which is an extended DICOM format created to store CT projections and acquisition geometry in a nonproprietary format. Image data are stored in the standard DICOM image format and clinical data in a spreadsheet. Materials are provided to help investigators use the DICOM-CT-PD files, including a dictionary file, data reader, and user manual. The library is publicly available from The Cancer Imaging Archive (https://doi.org/10.7937/9npb-2637). Potential Applications: This CT data library will facilitate the development and validation of new CT reconstruction and/or denoising algorithms, including those associated with machine learning or artificial intelligence. The provided clinical information allows evaluation of task-based diagnostic performance.",
        "DOI": "10.1002/mp.14594",
        "paper_author": "Moen T.R.",
        "affiliation_name": "Mayo Clinic",
        "affiliation_city": "Rochester",
        "affiliation_country": "United States",
        "affiliation_id": "60005558",
        "affiliation_state": "MN"
    },
    {
        "paper_title": "Machine learning directed drug formulation development",
        "publication": "Advanced Drug Delivery Reviews",
        "citied_by": "152",
        "cover_date": "2021-08-01",
        "Abstract": "Machine learning (ML) has enabled ground-breaking advances in the healthcare and pharmaceutical sectors, from improvements in cancer diagnosis, to the identification of novel drugs and drug targets as well as protein structure prediction. Drug formulation is an essential stage in the discovery and development of new medicines. Through the design of drug formulations, pharmaceutical scientists can engineer important properties of new medicines, such as improved bioavailability and targeted delivery. The traditional approach to drug formulation development relies on iterative trial-and-error, requiring a large number of resource-intensive and time-consuming in vitro and in vivo experiments. This review introduces the basic concepts of ML-directed workflows and discusses how these tools can be used to aid in the development of various types of drug formulations. ML-directed drug formulation development offers unparalleled opportunities to fast-track development efforts, uncover new materials, innovative formulations, and generate new knowledge in drug formulation science. The review also highlights the latest artificial intelligence (AI) technologies, such as generative models, Bayesian deep learning, reinforcement learning, and self-driving laboratories, which have been gaining momentum in drug discovery and chemistry and have potential in drug formulation development.",
        "DOI": "10.1016/j.addr.2021.05.016",
        "paper_author": "Bannigan P.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Blockchain Medledger: Hyperledger fabric enabled drug traceability system for counterfeit drugs in pharmaceutical industry",
        "publication": "International Journal of Pharmaceutics",
        "citied_by": "150",
        "cover_date": "2021-03-15",
        "Abstract": "Counterfeit drugs are one of the most severe threats to the pharmaceutical industry. World Health Organization (WHO) highlights that nearly 1035% of the drugs, i.e., one out of ten medicines produced in the least developing countries, are counterfeit and have serious side effects on human lives. The upsurge in online and Internet-based pharmacies has made the safety and security of the drug supply chain process more intricate and complicated. This research proposes a new and novel track and trace blockchain-enabled Medledger system that leverages the Hyperledger Fabric blockchain platform using chaincodes (smart contracts). The proposed Medledger system helps to efficiently and securely execute drug supply chain transactions in a fabric enabled private permissioned distributed network of different pharmaceutical stakeholders. Our proposed traceability solution diminishes the need for a trusted centralized authority, intermediaries and provides transaction records, enhancing efficiency and safety with high integrity, reliability, and security that reduces the likelihood of meddling with stored data on the Medledger. Chaincodes are designed, coded, and implemented using sequence diagrams to govern and control the interaction amongst the participating stakeholders in the drug supply chain ecosystem. The proposed system perpetually stores and records all activities, events, and transactions on the blockchain's immutable Medledger linked with peer-to-peer decentralized file systems such as IPFS, Swarm, filecoin, etc. for storing and providing maximum transparency and traceability. We provide an insight into some of the ongoing implementation challenges for the hyperledger fabric platform. Finally, we discuss open challenges that serve as future research directions to improve the drug traceability solutions further.",
        "DOI": "10.1016/j.ijpharm.2021.120235",
        "paper_author": "Uddin M.",
        "affiliation_name": "Universiti Brunei Darussalam",
        "affiliation_city": "Bandar Seri Begawan",
        "affiliation_country": "Brunei Darussalam",
        "affiliation_id": "60072089",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Extrusion bioprinting: Recent progress, challenges, and future opportunities",
        "publication": "Bioprinting",
        "citied_by": "149",
        "cover_date": "2021-03-01",
        "Abstract": "Extrusion-based bioprinting involves extrusion of bioinks through nozzles to create three-dimensional structures. The bioink contains living organisms with biological relevance for emerging applications such as tissue scaffolds, organs-on-a-chip, regenerative medicine, and drug delivery systems. Bioinks, which are mixtures of biomaterials and living cells, influence the quality of printed constructs through their physical, mechanical, biological, and rheological behavior. Printability is a property of a bioink used to describe its ability to create well-defined structures. Amongst all contributing factors, rheological properties and printing parameters are primary factors that influence the quality of bioprinted constructs. With the increasing popularity of extrusion bioprinting, different approaches for controlling these properties and parameters have emerged. This review highlights the role of rheology and process parameters in extrusion bioprinting and discusses qualitative and quantitative methods proposed to measure and define the printability of bioinks. Finally, an overview of key challenges and future trends in extrusion bioprinting is provided.",
        "DOI": "10.1016/j.bprint.2020.e00116",
        "paper_author": "Ramesh S.",
        "affiliation_name": "Kate Gleason College of Engineering",
        "affiliation_city": "Rochester",
        "affiliation_country": "United States",
        "affiliation_id": "60148717",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Breast cancer type classification using machine learning",
        "publication": "Journal of Personalized Medicine",
        "citied_by": "148",
        "cover_date": "2021-02-01",
        "Abstract": "Background: Breast cancer is a heterogeneous disease defined by molecular types and subtypes. Advances in genomic research have enabled use of precision medicine in clinical management of breast cancer. A critical unmet medical need is distinguishing triple negative breast cancer, the most aggressive and lethal form of breast cancer, from non-triple negative breast cancer. Here we propose use of a machine learning (ML) approach for classification of triple negative breast cancer and non-triple negative breast cancer patients using gene expression data. Methods: We performed analysis of RNA-Sequence data from 110 triple negative and 992 non-triple negative breast cancer tumor samples from The Cancer Genome Atlas to select the features (genes) used in the development and validation of the classification models. We evaluated four different classification models including Support Vector Machines, K-nearest neighbor, Naïve Bayes and Decision tree using features selected at different threshold levels to train the models for classifying the two types of breast cancer. For performance evaluation and validation, the proposed methods were applied to independent gene expression datasets. Results: Among the four ML algorithms evaluated, the Support Vector Machine algorithm was able to classify breast cancer more accurately into triple negative and non-triple negative breast cancer and had less misclassification errors than the other three algorithms evaluated. Conclusions: The prediction results show that ML algorithms are efficient and can be used for classification of breast cancer into triple negative and non-triple negative breast cancer types.",
        "DOI": "10.3390/jpm11020061",
        "paper_author": "Wu J.",
        "affiliation_name": "LSU Health New Orleans School of Medicine",
        "affiliation_city": "New Orleans",
        "affiliation_country": "United States",
        "affiliation_id": "60005399",
        "affiliation_state": "LA"
    },
    {
        "paper_title": "Single-cell microfluidic impedance cytometry: From raw signals to cell phenotypes using data analytics",
        "publication": "Lab on a Chip",
        "citied_by": "147",
        "cover_date": "2021-01-07",
        "Abstract": "The biophysical analysis of single-cells by microfluidic impedance cytometry is emerging as a label-free and high-throughput means to stratify the heterogeneity of cellular systems based on their electrophysiology. Emerging applications range from fundamental life-science and drug assessment research to point-of-care diagnostics and precision medicine. Recently, novel chip designs and data analytic strategies are laying the foundation for multiparametric cell characterization and subpopulation distinction, which are essential to understand biological function, follow disease progression and monitor cell behaviour in microsystems. In this tutorial review, we present a comparative survey of the approaches to elucidate cellular and subcellular features from impedance cytometry data, covering the related subjects of device design, data analytics (i.e., signal processing, dielectric modelling, population clustering), and phenotyping applications. We give special emphasis to the exciting recent developments of the technique (timeframe 2017-2020) and provide our perspective on future challenges and directions. Its synergistic application with microfluidic separation, sensor science and machine learning can form an essential toolkit for label-free quantification and isolation of subpopulations to stratify heterogeneous biosystems.",
        "DOI": "10.1039/d0lc00840k",
        "paper_author": "Honrado C.",
        "affiliation_name": "University of Virginia School of Engineering and Applied Science",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States",
        "affiliation_id": "60152865",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Assessing the trustworthiness of saliency maps for localizing abnormalities in medical imaging",
        "publication": "Radiology: Artificial Intelligence",
        "citied_by": "145",
        "cover_date": "2021-11-01",
        "Abstract": "Purpose: To evaluate the trustworthiness of saliency maps for abnormality localization in medical imaging. Materials and Methods: Using two large publicly available radiology datasets (Society for Imaging Informatics in Medicine–American College of Radiology Pneumothorax Segmentation dataset and Radiological Society of North America Pneumonia Detection Challenge dataset), the performance of eight commonly used saliency map techniques were quantified in regard to (a) localization utility (segmentation and detection), (b) sensitivity to model weight randomization, (c) repeatability, and (d) reproducibility. Their performances versus baseline methods and localization network architectures were compared, using area under the precision-recall curve (AUPRC) and structural similarity index measure (SSIM) as metrics. Results: All eight saliency map techniques failed at least one of the criteria and were inferior in performance compared with localization networks. For pneumothorax segmentation, the AUPRC ranged from 0.024 to 0.224, while a U-Net achieved a significantly superior AUPRC of 0.404 (P,.005). For pneumonia detection, the AUPRC ranged from 0.160 to 0.519, while a RetinaNet achieved a significantly superior AUPRC of 0.596 (P,.005). Five and two saliency methods (of eight) failed the model randomization test on the segmentation and detection datasets, respectively, suggesting that these methods are not sensitive to changes in model parameters. The repeatability and reproducibility of the majority of the saliency methods were worse than localization networks for both the segmentation and detection datasets. Conclusion: The use of saliency maps in the high-risk domain of medical imaging warrants additional scrutiny and recommend that detection or segmentation models be used if localization is the desired output of the network.",
        "DOI": "10.1148/ryai.2021200267",
        "paper_author": "Arun N.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Emerging 3D printing technologies for drug delivery devices: Current status and future perspective",
        "publication": "Advanced Drug Delivery Reviews",
        "citied_by": "142",
        "cover_date": "2021-07-01",
        "Abstract": "The ‘one-size-fits-all’ approach followed by conventional drug delivery platforms often restricts its application in pharmaceutical industry, due to the incapability of adapting to individual pharmacokinetic traits. Driven by the development of additive manufacturing (AM) technology, three-dimensional (3D) printed drug delivery medical devices have gained increasing popularity, which offers key advantages over traditional drug delivery systems. The major benefits include the ability to fabricate 3D structures with customizable design and intricate architecture, and most importantly, ease of personalized medication. Furthermore, the emergence of multi-material printing and four-dimensional (4D) printing integrates the benefits of multiple functional materials, and thus provide widespread opportunities for the advancement of personalized drug delivery devices. Despite the remarkable progress made by AM techniques, concerns related to regulatory issues, scalability and cost-effectiveness remain major hurdles. Herein, we provide an overview on the latest accomplishments in 3D printed drug delivery devices as well as major challenges and future perspectives for AM enabled dosage forms and drug delivery systems.",
        "DOI": "10.1016/j.addr.2021.04.019",
        "paper_author": "Wang J.",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60013372",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Histologic subtype classification of non-small cell lung cancer using PET/CT images",
        "publication": "European Journal of Nuclear Medicine and Molecular Imaging",
        "citied_by": "142",
        "cover_date": "2021-02-01",
        "Abstract": "Purposes: To evaluate the capability of PET/CT images for differentiating the histologic subtypes of non-small cell lung cancer (NSCLC) and to identify the optimal model from radiomics-based machine learning/deep learning algorithms. Methods: In this study, 867 patients with adenocarcinoma (ADC) and 552 patients with squamous cell carcinoma (SCC) were retrospectively analysed. A stratified random sample of 283 patients (20%) was used as the testing set (173 ADC and 110 SCC); the remaining data were used as the training set. A total of 688 features were extracted from each outlined tumour region. Ten feature selection techniques, ten machine learning (ML) models and the VGG16 deep learning (DL) algorithm were evaluated to construct an optimal classification model for the differential diagnosis of ADC and SCC. Tenfold cross-validation and grid search technique were employed to evaluate and optimize the model hyperparameters on the training dataset. The area under the receiver operating characteristic curve (AUROC), accuracy, precision, sensitivity and specificity was used to evaluate the performance of the models on the test dataset. Results: Fifty top-ranked subset features were selected by each feature selection technique for classification. The linear discriminant analysis (LDA) (AUROC, 0.863; accuracy, 0.794) and support vector machine (SVM) (AUROC, 0.863; accuracy, 0.792) classifiers, both of which coupled with the ℓ2,1NR feature selection method, achieved optimal performance. The random forest (RF) classifier (AUROC, 0.824; accuracy, 0.775) and ℓ2,1NR feature selection method (AUROC, 0.815; accuracy, 0.764) showed excellent average performance among the classifiers and feature selection methods employed in our study, respectively. Furthermore, the VGG16 DL algorithm (AUROC, 0.903; accuracy, 0.841) outperformed all conventional machine learning methods in combination with radiomics. Conclusion: Employing radiomic machine learning/deep learning algorithms could help radiologists to differentiate the histologic subtypes of NSCLC via PET/CT images.",
        "DOI": "10.1007/s00259-020-04771-5",
        "paper_author": "Han Y.",
        "affiliation_name": "Capital Medical University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60026707",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Accessing Artificial Intelligence for Clinical Decision-Making",
        "publication": "Frontiers in Digital Health",
        "citied_by": "140",
        "cover_date": "2021-06-25",
        "Abstract": "Advancements in computing and data from the near universal acceptance and implementation of electronic health records has been formative for the growth of personalized, automated, and immediate patient care models that were not previously possible. Artificial intelligence (AI) and its subfields of machine learning, reinforcement learning, and deep learning are well-suited to deal with such data. The authors in this paper review current applications of AI in clinical medicine and discuss the most likely future contributions that AI will provide to the healthcare industry. For instance, in response to the need to risk stratify patients, appropriately cultivated and curated data can assist decision-makers in stratifying preoperative patients into risk categories, as well as categorizing the severity of ailments and health for non-operative patients admitted to hospitals. Previous overt, traditional vital signs and laboratory values that are used to signal alarms for an acutely decompensating patient may be replaced by continuously monitoring and updating AI tools that can pick up early imperceptible patterns predicting subtle health deterioration. Furthermore, AI may help overcome challenges with multiple outcome optimization limitations or sequential decision-making protocols that limit individualized patient care. Despite these tremendously helpful advancements, the data sets that AI models train on and develop have the potential for misapplication and thereby create concerns for application bias. Subsequently, the mechanisms governing this disruptive innovation must be understood by clinical decision-makers to prevent unnecessary harm. This need will force physicians to change their educational infrastructure to facilitate understanding AI platforms, modeling, and limitations to best acclimate practice in the age of AI. By performing a thorough narrative review, this paper examines these specific AI applications, limitations, and requisites while reviewing a few examples of major data sets that are being cultivated and curated in the US.",
        "DOI": "10.3389/fdgth.2021.645232",
        "paper_author": "Giordano C.",
        "affiliation_name": "University of Florida College of Medicine",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States",
        "affiliation_id": "60007567",
        "affiliation_state": "FL"
    },
    {
        "paper_title": "Human-interpretable image features derived from densely mapped cancer pathology slides predict diverse molecular phenotypes",
        "publication": "Nature Communications",
        "citied_by": "140",
        "cover_date": "2021-12-01",
        "Abstract": "Computational methods have made substantial progress in improving the accuracy and throughput of pathology workflows for diagnostic, prognostic, and genomic prediction. Still, lack of interpretability remains a significant barrier to clinical integration. We present an approach for predicting clinically-relevant molecular phenotypes from whole-slide histopathology images using human-interpretable image features (HIFs). Our method leverages >1.6 million annotations from board-certified pathologists across >5700 samples to train deep learning models for cell and tissue classification that can exhaustively map whole-slide images at two and four micron-resolution. Cell- and tissue-type model outputs are combined into 607 HIFs that quantify specific and biologically-relevant characteristics across five cancer types. We demonstrate that these HIFs correlate with well-known markers of the tumor microenvironment and can predict diverse molecular signatures (AUROC 0.601–0.864), including expression of four immune checkpoint proteins and homologous recombination deficiency, with performance comparable to ‘black-box’ methods. Our HIF-based approach provides a comprehensive, quantitative, and interpretable window into the composition and spatial architecture of the tumor microenvironment.",
        "DOI": "10.1038/s41467-021-21896-9",
        "paper_author": "Diao J.A.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Deep reinforcement learning in medical imaging: A literature review",
        "publication": "Medical Image Analysis",
        "citied_by": "136",
        "cover_date": "2021-10-01",
        "Abstract": "Deep reinforcement learning (DRL) augments the reinforcement learning framework, which learns a sequence of actions that maximizes the expected reward, with the representative power of deep neural networks. Recent works have demonstrated the great potential of DRL in medicine and healthcare. This paper presents a literature review of DRL in medical imaging. We start with a comprehensive tutorial of DRL, including the latest model-free and model-based algorithms. We then cover existing DRL applications for medical imaging, which are roughly divided into three main categories: (i) parametric medical image analysis tasks including landmark detection, object/lesion detection, registration, and view plane localization; (ii) solving optimization tasks including hyperparameter tuning, selecting augmentation strategies, and neural architecture search; and (iii) miscellaneous applications including surgical gesture segmentation, personalized mobile health intervention, and computational model personalization. The paper concludes with discussions of future perspectives.",
        "DOI": "10.1016/j.media.2021.102193",
        "paper_author": "Zhou S.K.",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China",
        "affiliation_id": "60019118",
        "affiliation_state": "Anhui"
    },
    {
        "paper_title": "Implementing Precision Psychiatry: A Systematic Review of Individualized Prediction Models for Clinical Practice",
        "publication": "Schizophrenia Bulletin",
        "citied_by": "136",
        "cover_date": "2021-03-01",
        "Abstract": "Background: The impact of precision psychiatry for clinical practice has not been systematically appraised. This study aims to provide a comprehensive review of validated prediction models to estimate the individual risk of being affected with a condition (diagnostic), developing outcomes (prognostic), or responding to treatments (predictive) in mental disorders. Methods: PRISMA/RIGHT/CHARMS-compliant systematic review of the Web of Science, Cochrane Central Register of Reviews, and Ovid/PsycINFO databases from inception until July 21, 2019 (PROSPERO CRD42019155713) to identify diagnostic/prognostic/predictive prediction studies that reported individualized estimates in psychiatry and that were internally or externally validated or implemented. Random effect meta-regression analyses addressed the impact of several factors on the accuracy of prediction models. Findings: Literature search identified 584 prediction modeling studies, of which 89 were included. 10.4% of the total studies included prediction models internally validated (n = 61), 4.6% models externally validated (n = 27), and 0.2% (n = 1) models considered for implementation. Across validated prediction modeling studies (n = 88), 18.2% were diagnostic, 68.2% prognostic, and 13.6% predictive. The most frequently investigated condition was psychosis (36.4%), and the most frequently employed predictors clinical (69.5%). Unimodal compared to multimodal models (β =. 29, P =. 03) and diagnostic compared to prognostic (β =. 84, p <. 0001) and predictive (β =. 87, P =. 002) models were associated with increased accuracy. Interpretation: To date, several validated prediction models are available to support the diagnosis and prognosis of psychiatric conditions, in particular, psychosis, or to predict treatment response. Advancements of knowledge are limited by the lack of implementation research in real-world clinical practice. A new generation of implementation research is required to address this translational gap.",
        "DOI": "10.1093/schbul/sbaa120",
        "paper_author": "Salazar De Pablo G.",
        "affiliation_name": "King's College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60011520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "New software tools, databases, and resources in metabolomics: updates from 2020",
        "publication": "Metabolomics",
        "citied_by": "132",
        "cover_date": "2021-05-01",
        "Abstract": "Background: Precision medicine, space exploration, drug discovery to characterization of dark chemical space of habitats and organisms, metabolomics takes a centre stage in providing answers to diverse biological, biomedical, and environmental questions. With technological advances in mass-spectrometry and spectroscopy platforms that aid in generation of information rich datasets that are complex big-data, data analytics tend to co-evolve to match the pace of analytical instrumentation. Software tools, resources, databases, and solutions help in harnessing the concealed information in the generated data for eventual translational success. Aim of the review: In this review, ~ 85 metabolomics software resources, packages, tools, databases, and other utilities that appeared in 2020 are introduced to the research community. Key scientific concepts of review: In Table 1 the computational dependencies and downloadable links of the tools are provided, and the resources are categorized based on their utility. The review aims to keep the community of metabolomics researchers updated with all the resources developed in 2020 at a collated avenue, in line with efforts form 2015 onwards to help them find these at one place for further referencing and use.",
        "DOI": "10.1007/s11306-021-01796-1",
        "paper_author": "Misra B.B.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep learning for drug response prediction in cancer",
        "publication": "Briefings in Bioinformatics",
        "citied_by": "132",
        "cover_date": "2021-01-01",
        "Abstract": "Predicting the sensitivity of tumors to specific anti-cancer treatments is a challenge of paramount importance for precision medicine. Machine learning(ML) algorithms can be trained on high-throughput screening data to develop models that are able to predict the response of cancer cell lines and patients to novel drugs or drug combinations. Deep learning (DL) refers to a distinct class of ML algorithms that have achieved top-level performance in a variety of fields, including drug discovery. These types of models have unique characteristics that may make them more suitable for the complex task of modeling drug response based on both biological and chemical data, but the application of DL to drug response prediction has been unexplored until very recently. The few studies that have been published have shown promising results, and the use of DL for drug response prediction is beginning to attract greater interest from researchers in the field. In this article, we critically review recently published studies that have employed DL methods to predict drug response in cancer cell lines. We also provide a brief description of DL and the main types of architectures that have been used in these studies. Additionally, we present a selection of publicly available drug screening data resources that can be used to develop drug response prediction models. Finally, we also address the limitations of these approaches and provide a discussion on possible paths for further improvement. Contact: Mrocha@di.uminho.pt",
        "DOI": "10.1093/bib/bbz171",
        "paper_author": "Baptista D.",
        "affiliation_name": "Universidade do Minho",
        "affiliation_city": "Braga",
        "affiliation_country": "Portugal",
        "affiliation_id": "60020475",
        "affiliation_state": "Braga"
    },
    {
        "paper_title": "The importance of being external. methodological insights for the external validation of machine learning models in medicine",
        "publication": "Computer Methods and Programs in Biomedicine",
        "citied_by": "131",
        "cover_date": "2021-09-01",
        "Abstract": "Background and Objective Medical machine learning (ML) models tend to perform better on data from the same cohort than on new data, often due to overfitting, or co-variate shifts. For these reasons, external validation (EV) is a necessary practice in the evaluation of medical ML. However, there is still a gap in the literature on how to interpret EV results and hence assess the robustness of ML models. Methods: We fill this gap by proposing a meta-validation method, to assess the soundness of EV procedures. In doing so, we complement the usual way to assess EV by considering both dataset cardinality, and the similarity of the EV dataset with respect to the training set. We then investigate how the notions of cardinality and similarity can be used to inform on the reliability of a validation procedure, by integrating them into two summative data visualizations. Results: We illustrate our methodology by applying it to the validation of a state-of-the-art COVID-19 diagnostic model on 8 EV sets, collected across 3 different continents. The model performance was moderately impacted by data similarity (Pearson ρ = 0.38, p< 0.001). In the EV, the validated model reported good AUC (average: 0.84), acceptable calibration (average: 0.17) and utility (average: 0.50). The validation datasets were adequate in terms of dataset cardinality and similarity, thus suggesting the soundness of the results. We also provide a qualitative guideline to evaluate the reliability of validation procedures, and we discuss the importance of proper external validation in light of the obtained results. Conclusions: In this paper, we propose a novel, lean methodology to: 1) study how the similarity between training and validation sets impacts the generalizability of a ML model; 2) assess the soundness of EV evaluations along three complementary performance dimensions: discrimination, utility and calibration; 3) draw conclusions on the robustness of the model under validation. We applied this methodology to a state-of-the-art model for the diagnosis of COVID-19 from routine blood tests, and showed how to interpret the results in light of the presented framework.",
        "DOI": "10.1016/j.cmpb.2021.106288",
        "paper_author": "Cabitza F.",
        "affiliation_name": "Università degli Studi di Milano-Bicocca",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60012306",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "A Survey of Topological Machine Learning Methods",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "129",
        "cover_date": "2021-05-26",
        "Abstract": "The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as “topological machine learning,” i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges.",
        "DOI": "10.3389/frai.2021.681108",
        "paper_author": "Hensel F.",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Artificial intelligence in colorectal cancer screening, diagnosis and treatment. A new era",
        "publication": "Current Oncology",
        "citied_by": "128",
        "cover_date": "2021-01-01",
        "Abstract": "The development of artificial intelligence (AI) algorithms has permeated the medical field with great success. The widespread use of AI technology in diagnosing and treating several types of cancer, especially colorectal cancer (CRC), is now attracting substantial attention. CRC, which represents the third most commonly diagnosed malignancy in both men and women, is considered a leading cause of cancer-related deaths globally. Our review herein aims to provide in-depth knowledge and analysis of the AI applications in CRC screening, diagnosis, and treatment based on current literature. We also explore the role of recent advances in AI systems regarding medical diagnosis and therapy, with several promising results. CRC is a highly preventable disease, and AI-assisted techniques in routine screening represent a pivotal step in declining incidence rates of this malignancy. So far, computer-aided detection and characterization systems have been developed to increase the detection rate of adenomas. Furthermore, CRC treatment enters a new era with robotic surgery and novel computer-assisted drug delivery techniques. At the same time, healthcare is rapidly moving toward precision or personalized medicine. Machine learning models have the potential to contribute to individual-based cancer care and transform the future of medicine.",
        "DOI": "10.3390/curroncol28030149",
        "paper_author": "Mitsala A.",
        "affiliation_name": "University General Hospital of Alexandroupolis",
        "affiliation_city": "Alexandroupoli",
        "affiliation_country": "Greece",
        "affiliation_id": "60069178",
        "affiliation_state": "Evros"
    },
    {
        "paper_title": "Precision medicine in human heart modeling: Perspectives, challenges, and opportunities",
        "publication": "Biomechanics and Modeling in Mechanobiology",
        "citied_by": "125",
        "cover_date": "2021-06-01",
        "Abstract": "Precision medicine is a new frontier in healthcare that uses scientific methods to customize medical treatment to the individual genes, anatomy, physiology, and lifestyle of each person. In cardiovascular health, precision medicine has emerged as a promising paradigm to enable cost-effective solutions that improve quality of life and reduce mortality rates. However, the exact role in precision medicine for human heart modeling has not yet been fully explored. Here, we discuss the challenges and opportunities for personalized human heart simulations, from diagnosis to device design, treatment planning, and prognosis. With a view toward personalization, we map out the history of anatomic, physical, and constitutive human heart models throughout the past three decades. We illustrate recent human heart modeling in electrophysiology, cardiac mechanics, and fluid dynamics and highlight clinically relevant applications of these models for drug development, pacing lead failure, heart failure, ventricular assist devices, edge-to-edge repair, and annuloplasty. With a view toward translational medicine, we provide a clinical perspective on virtual imaging trials and a regulatory perspective on medical device innovation. We show that precision medicine in human heart modeling does not necessarily require a fully personalized, high-resolution whole heart model with an entire personalized medical history. Instead, we advocate for creating personalized models out of population-based libraries with geometric, biological, physical, and clinical information by morphing between clinical data and medical histories from cohorts of patients using machine learning. We anticipate that this perspective will shape the path toward introducing human heart simulations into precision medicine with the ultimate goals to facilitate clinical decision making, guide treatment planning, and accelerate device design.",
        "DOI": "10.1007/s10237-021-01421-z",
        "paper_author": "Peirlinck M.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States",
        "affiliation_id": "60141508",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Computational pharmaceutics - A new paradigm of drug delivery",
        "publication": "Journal of Controlled Release",
        "citied_by": "123",
        "cover_date": "2021-10-10",
        "Abstract": "In recent decades pharmaceutics and drug delivery have become increasingly critical in the pharmaceutical industry due to longer time, higher cost, and less productivity of new molecular entities (NMEs). However, current formulation development still relies on traditional trial-and-error experiments, which are time-consuming, costly, and unpredictable. With the exponential growth of computing capability and algorithms, in recent ten years, a new discipline named “computational pharmaceutics” integrates with big data, artificial intelligence, and multi-scale modeling techniques into pharmaceutics, which offered great potential to shift the paradigm of drug delivery. Computational pharmaceutics can provide multi-scale lenses to pharmaceutical scientists, revealing physical, chemical, mathematical, and data-driven details ranging across pre-formulation studies, formulation screening, in vivo prediction in the human body, and precision medicine in the clinic. The present paper provides a comprehensive and detailed review in all areas of computational pharmaceutics and “Pharma 4.0”, including artificial intelligence and machine learning algorithms, molecular modeling, mathematical modeling, process simulation, and physiologically based pharmacokinetic (PBPK) modeling. We not only summarized the theories and progress of these technologies but also discussed the regulatory requirements, current challenges, and future perspectives in the area, such as talent training and a culture change in the future pharmaceutical industry.",
        "DOI": "10.1016/j.jconrel.2021.08.030",
        "paper_author": "Wang W.",
        "affiliation_name": "Institute of Chinese Medical Sciences",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao",
        "affiliation_id": "60202528",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data-independent acquisition mass spectrometry (DIA-MS) for proteomic applications in oncology",
        "publication": "Molecular Omics",
        "citied_by": "123",
        "cover_date": "2021-02-01",
        "Abstract": "Data-independent acquisition mass spectrometry (DIA-MS) is a next generation proteomic methodology that generates permanent digital proteome maps offering highly reproducible retrospective analysis of cellular and tissue specimens. The adoption of this technology has ushered a new wave of oncology studies across a wide range of applications including its use in molecular classification, oncogenic pathway analysis, drug and biomarker discovery and unravelling mechanisms of therapy response and resistance. In this review, we provide an overview of the experimental workflows commonly used in DIA-MS, including its current strengths and limitationsversusconventional data-dependent acquisition mass spectrometry (DDA-MS). We further summarise a number of key studies to illustrate the power of this technology when applied to different facets of oncology. Finally we offer a perspective of the latest innovations in DIA-MS technology and machine learning-based algorithms necessary for driving the development of high-throughput, in-depth and reproducible proteomic assays that are compatible with clinical diagnostic workflows, which will ultimately enable the delivery of precision cancer medicine to achieve optimal patient outcomes.",
        "DOI": "10.1039/d0mo00072h",
        "paper_author": "Krasny L.",
        "affiliation_name": "The Institute of Cancer Research",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60010337",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Sharing ICU Patient Data Responsibly Under the Society of Critical Care Medicine/European Society of Intensive Care Medicine Joint Data Science Collaboration: The Amsterdam University Medical Centers Database (AmsterdamUMCdb) Example∗",
        "publication": "Critical Care Medicine",
        "citied_by": "122",
        "cover_date": "2021-06-01",
        "Abstract": "OBJECTIVES: Critical care medicine is a natural environment for machine learning approaches to improve outcomes for critically ill patients as admissions to ICUs generate vast amounts of data. However, technical, legal, ethical, and privacy concerns have so far limited the critical care medicine community from making these data readily available. The Society of Critical Care Medicine and the European Society of Intensive Care Medicine have identified ICU patient data sharing as one of the priorities under their Joint Data Science Collaboration. To encourage ICUs worldwide to share their patient data responsibly, we now describe the development and release of Amsterdam University Medical Centers Database (AmsterdamUMCdb), the first freely available critical care database in full compliance with privacy laws from both the United States and Europe, as an example of the feasibility of sharing complex critical care data. SETTING: University hospital ICU. SUBJECTS: Data from ICU patients admitted between 2003 and 2016. INTERVENTIONS: We used a risk-based deidentification strategy to maintain data utility while preserving privacy. In addition, we implemented contractual and governance processes, and a communication strategy. Patient organizations, supporting hospitals, and experts on ethics and privacy audited these processes and the database. MEASUREMENTS AND MAIN RESULTS: AmsterdamUMCdb contains approximately 1 billion clinical data points from 23,106 admissions of 20,109 patients. The privacy audit concluded that reidentification is not reasonably likely, and AmsterdamUMCdb can therefore be considered as anonymous information, both in the context of the U.S. Health Insurance Portability and Accountability Act and the European General Data Protection Regulation. The ethics audit concluded that responsible data sharing imposes minimal burden, whereas the potential benefit is tremendous. CONCLUSIONS: Technical, legal, ethical, and privacy challenges related to responsible data sharing can be addressed using a multidisciplinary approach. A risk-based deidentification strategy, that complies with both U.S. and European privacy regulations, should be the preferred approach to releasing ICU patient data. This supports the shared Society of Critical Care Medicine and European Society of Intensive Care Medicine vision to improve critical care outcomes through scientific inquiry of vast and combined ICU datasets.",
        "DOI": "10.1097/CCM.0000000000004916",
        "paper_author": "Thoral P.J.",
        "affiliation_name": "Vrije Universiteit Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60008734",
        "affiliation_state": "Noord-Holland"
    },
    {
        "paper_title": "Homomorphic Encryption for Machine Learning in Medicine and Bioinformatics",
        "publication": "ACM Computing Surveys",
        "citied_by": "122",
        "cover_date": "2021-07-31",
        "Abstract": "Machine learning and statistical techniques are powerful tools for analyzing large amounts of medical and genomic data. On the other hand, ethical concerns and privacy regulations prevent free sharing of this data. Encryption techniques such as fully homomorphic encryption (FHE) enable evaluation over encrypted data. Using FHE, machine learning models such as deep learning, decision trees, and Naive Bayes have been implemented for privacy-preserving applications using medical data. These applications include classifying encrypted data and training models on encrypted data. FHE has also been shown to enable secure genomic algorithms, such as paternity and ancestry testing and privacy-preserving applications of genome-wide association studies. This survey provides an overview of fully homomorphic encryption and its applications in medicine and bioinformatics. The high-level concepts behind FHE and its history are introduced, and details on current open-source implementations are provided. The state of fully homomorphic encryption for privacy-preserving techniques in machine learning and bioinformatics is reviewed, along with descriptions of how these methods can be implemented in the encrypted domain.",
        "DOI": "10.1145/3394658",
        "paper_author": "Wood A.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60025778",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "121",
        "cover_date": "2021-04-15",
        "Abstract": "In Low- and Middle- Income Countries (LMICs), machine learning (ML) and artificial intelligence (AI) offer attractive solutions to address the shortage of health care resources and improve the capacity of the local health care infrastructure. However, AI and ML should also be used cautiously, due to potential issues of fairness and algorithmic bias that may arise if not applied properly. Furthermore, populations in LMICs can be particularly vulnerable to bias and fairness in AI algorithms, due to a lack of technical capacity, existing social bias against minority groups, and a lack of legal protections. In order to address the need for better guidance within the context of global health, we describe three basic criteria (Appropriateness, Fairness, and Bias) that can be used to help evaluate the use of machine learning and AI systems: 1) APPROPRIATENESS is the process of deciding how the algorithm should be used in the local context, and properly matching the machine learning model to the target population; 2) BIAS is a systematic tendency in a model to favor one demographic group vs another, which can be mitigated but can lead to unfairness; and 3) FAIRNESS involves examining the impact on various demographic groups and choosing one of several mathematical definitions of group fairness that will adequately satisfy the desired set of legal, cultural, and ethical requirements. Finally, we illustrate how these principles can be applied using a case study of machine learning applied to the diagnosis and screening of pulmonary disease in Pune, India. We hope that these methods and principles can help guide researchers and organizations working in global health who are considering the use of machine learning and artificial intelligence.",
        "DOI": "10.3389/frai.2020.561802",
        "paper_author": "Fletcher R.R.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60022195",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "From Real-World Patient Data to Individualized Treatment Effects Using Machine Learning: Current and Future Methods to Address Underlying Challenges",
        "publication": "Clinical Pharmacology and Therapeutics",
        "citied_by": "121",
        "cover_date": "2021-01-01",
        "Abstract": "Clinical decision making needs to be supported by evidence that treatments are beneficial to individual patients. Although randomized control trials (RCTs) are the gold standard for testing and introducing new drugs, due to the focus on specific questions with respect to establishing efficacy and safety vs. standard treatment, they do not provide a full characterization of the heterogeneity in the final intended treatment population. Conversely, real-world observational data, such as electronic health records (EHRs), contain large amounts of clinical information about heterogeneous patients and their response to treatments. In this paper, we introduce the main opportunities and challenges in using observational data for training machine learning methods to estimate individualized treatment effects and make treatment recommendations. We describe the modeling choices of the state-of-the-art machine learning methods for causal inference, developed for estimating treatment effects both in the cross-section and longitudinal settings. Additionally, we highlight future research directions that could lead to achieving the full potential of leveraging EHRs and machine learning for making individualized treatment recommendations. We also discuss how experimental data from RCTs and Pharmacometric and Quantitative Systems Pharmacology approaches can be used to not only improve machine learning methods, but also provide ways for validating them. These future research directions will require us to collaborate across the scientific disciplines to incorporate models based on RCTs and known disease processes, physiology, and pharmacology into these machine learning models based on EHRs to fully optimize the opportunity these data present.",
        "DOI": "10.1002/cpt.1907",
        "paper_author": "Bica I.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026851",
        "affiliation_state": "Oxfordshire"
    },
    {
        "paper_title": "Origins and evolving functionalities of tRNA-derived small RNAs",
        "publication": "Trends in Biochemical Sciences",
        "citied_by": "118",
        "cover_date": "2021-10-01",
        "Abstract": "Transfer RNA (tRNA)-derived small RNAs (tsRNAs) are among the most ancient small RNAs in all domains of life and are generated by the cleavage of tRNAs. Emerging studies have begun to reveal the versatile roles of tsRNAs in fundamental biological processes, including gene silencing, ribosome biogenesis, retrotransposition, and epigenetic inheritance, which are rooted in tsRNA sequence conservation, RNA modifications, and protein-binding abilities. We summarize the mechanisms of tsRNA biogenesis and the impact of RNA modifications, and propose how thinking of tsRNA functionality from an evolutionary perspective urges the expansion of tsRNA research into a wider spectrum, including cross-tissue/cross-species regulation and harnessing of the 'tsRNA code' for precision medicine.",
        "DOI": "10.1016/j.tibs.2021.05.001",
        "paper_author": "Chen Q.",
        "affiliation_name": "UCR School of Medicine",
        "affiliation_city": "Riverside",
        "affiliation_country": "United States",
        "affiliation_id": "60122729",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Natural language processing in medicine: A review",
        "publication": "Trends in Anaesthesia and Critical Care",
        "citied_by": "118",
        "cover_date": "2021-06-01",
        "Abstract": "Natural language processing (NLP) is a form of machine learning which enables the processing and analysis of free text. When used with medical notes, it can aid in the prediction of patient outcomes, augment hospital triage systems, and generate diagnostic models that detect early-stage chronic disease. These applications may be particularly useful in critical care where there is more patient data to analyse and prediction of patient mortality is routine. In addition to its natural language understanding (NLU) ability, NLP can also accomplish natural language generation (NLG), providing an interface for patients to ask questions and access relevant information in the form of chatbots. There are challenges to the use of NLP in medicine. Unbiased training data is an essential requirement if the conclusions reached by NLP algorithms are to be trusted. Clinicians will need training to understand how NLP can be safely used as part of routine practice. In the future, NLP applications are likely to be integrated into the clinical environment, working with clinicians to suggest problem lists, as patient facing applications to streamline triage systems, and as a tool to interrogate vast amounts of free text data, which could contribute to personalised, up to the minute evidence based medicine.",
        "DOI": "10.1016/j.tacc.2021.02.007",
        "paper_author": "Locke S.",
        "affiliation_name": "The University of Manchester",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60003771",
        "affiliation_state": "Greater Manchester"
    },
    {
        "paper_title": "Coupling machine learning with 3D bioprinting to fast track optimisation of extrusion printing",
        "publication": "Applied Materials Today",
        "citied_by": "118",
        "cover_date": "2021-03-01",
        "Abstract": "3D bioprinting, a paradigm shift in tissue engineering holds a promising perspective for regenerative medicine and disease modelling. 3D scaffolds are fabricated for subsequent cell seeding or incorporated directly to the bioink to create cell-laden 3D constructs. A plethora of factors relating to bioink properties, printing parameters and post print curing play a significant role in the optimisation of the printing process. Although qualitative evaluation of printability has been investigated largely, there is a paucity of studies on quantitative approaches to assess printability. Hence, this study explores machine learning as a novel tool to evaluate printability quantitatively and to fast track optimisation of extrusion printing in achieving a reproducible 3D scaffold. Bayesian Optimisation, a machine learning method has been employed for optimising 3D bioplotting with a scoring system established to assess the printability of gelatin methacryloyl (GelMA) and hyaluronic acid methacrylate (HAMA) bioinks. The performance of two fundamental criteria encountered in the printing process: the filament formation of the bioink and the layer stacking of the 3D scaffold have been incorporated in the scoring metric. The optimal print parameters for GelMA containing inks with ranging concentrations (10%, 7.5% & 5% (w/v)) were obtained in 19, 4 & 47 experiments whereas for GelMA:HAMA (10:2%, 7.5:2% & 5:2% (w/v)) 32, 25 & 32 experiments were required respectively. This number of experiments is drastically reduced compared to the 6000 to 10 000 possible combinations in the Bayesian algorithm. Hence, this study will be a stepping-stone into unravelling the benefits of machine learning in this rapidly developing area of 3D bioprinting.",
        "DOI": "10.1016/j.apmt.2020.100914",
        "paper_author": "Ruberu K.",
        "affiliation_name": "University of Wollongong",
        "affiliation_city": "Wollongong",
        "affiliation_country": "Australia",
        "affiliation_id": "60011664",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Artificial Intelligence/Machine Learning in Respiratory Medicine and Potential Role in Asthma and COPD Diagnosis",
        "publication": "Journal of Allergy and Clinical Immunology: In Practice",
        "citied_by": "117",
        "cover_date": "2021-06-01",
        "Abstract": "Artificial intelligence (AI) and machine learning, a subset of AI, are increasingly used in medicine. AI excels at performing well-defined tasks, such as image recognition; for example, classifying skin biopsy lesions, determining diabetic retinopathy severity, and detecting brain tumors. This article provides an overview of the use of AI in medicine and particularly in respiratory medicine, where it is used to evaluate lung cancer images, diagnose fibrotic lung disease, and more recently is being developed to aid the interpretation of pulmonary function tests and the diagnosis of a range of obstructive and restrictive lung diseases. The development and validation of AI algorithms requires large volumes of well-structured data, and the algorithms must work with variable levels of data quality. It is important that clinicians understand how AI can function in the context of heterogeneous conditions such as asthma and chronic obstructive pulmonary disease where diagnostic criteria overlap, how AI use fits into everyday clinical practice, and how issues of patient safety should be addressed. AI has a clear role in providing support for doctors in the clinical workplace, but its relatively recent introduction means that confidence in its use still has to be fully established. Overall, AI is expected to play a key role in aiding clinicians in the diagnosis and management of respiratory diseases in the future, and it will be exciting to see the benefits that arise for patients and doctors from its use in everyday clinical practice.",
        "DOI": "10.1016/j.jaip.2021.02.014",
        "paper_author": "Kaplan A.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "The quiet revolution in machine vision - a state-of-the-art survey paper, including historical review, perspectives, and future directions",
        "publication": "Computers in Industry",
        "citied_by": "116",
        "cover_date": "2021-09-01",
        "Abstract": "Over the past few years, what might not unreasonably be described as a true revolution has taken place in the field of machine vision, radically altering the way many things had previously been done and offering new and exciting opportunities for those able to quickly embrace and master the new techniques. Rapid developments in machine learning, largely enabled by faster GPU-equipped computing hardware, has facilitated an explosion of machine vision applications into hitherto extremely challenging or, in many cases, previously impossible to automate industrial tasks. Together with developments towards an internet of things and the availability of big data, these form key components of what many consider to be the fourth industrial revolution. This transformation has dramatically improved the efficacy of some existing machine vision activities, such as in manufacturing (e.g. inspection for quality control and quality assurance), security (e.g. facial biometrics) and in medicine (e.g. detecting cancers), while in other cases has opened up completely new areas of use, such as in agriculture and construction (as well as in the existing domains of manufacturing and medicine). Here we will explore the history and nature of this change, what underlies it, what enables it, and the impact it has had - the latter by reviewing several recent indicative applications described in the research literature. We will also consider the continuing role that traditional or classical machine vision might still play. Finally, the key future challenges and developing opportunities in machine vision will also be discussed.",
        "DOI": "10.1016/j.compind.2021.103472",
        "paper_author": "Smith M.L.",
        "affiliation_name": "University of the West of England",
        "affiliation_city": "Bristol",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60019611",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Generating functional protein variants with variational autoencoders",
        "publication": "PLoS Computational Biology",
        "citied_by": "116",
        "cover_date": "2021-02-26",
        "Abstract": "The vast expansion of protein sequence databases provides an opportunity for new protein design approaches which seek to learn the sequence-function relationship directly from natural sequence variation. Deep generative models trained on protein sequence data have been shown to learn biologically meaningful representations helpful for a variety of downstream tasks, but their potential for direct use in the design of novel proteins remains largely unexplored. Here we show that variational autoencoders trained on a dataset of almost 70000 luciferase-like oxidoreductases can be used to generate novel, functional variants of the luxA bacterial luciferase. We propose separate VAE models to work with aligned sequence input (MSA VAE) and raw sequence input (AR-VAE), and offer evidence that while both are able to reproduce patterns of amino acid usage characteristic of the family, the MSA VAE is better able to capture long-distance dependencies reflecting the influence of 3D structure. To confirm the practical utility of the models, we used them to generate variants of luxA whose luminescence activity was validated experimentally. We further showed that conditional variants of both models could be used to increase the solubility of luxA without disrupting function. Altogether 6/12 of the variants generated using the unconditional AR-VAE and 9/11 generated using the unconditional MSA VAE retained measurable luminescence, together with all 23 of the less distant variants generated by conditional versions of the models; the most distant functional variant contained 35 differences relative to the nearest training set sequence. These results demonstrate the feasibility of using deep generative models to explore the space of possible protein sequences and generate useful variants, providing a method complementary to rational design and directed evolution approaches.",
        "DOI": "10.1371/JOURNAL.PCBI.1008736",
        "paper_author": "Hawkins-Hooker A.",
        "affiliation_name": "Institut Pasteur, Paris",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60001772",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Personalized Prediction Model to Risk Stratify Patients With Myelodysplastic Syndromes",
        "publication": "Journal of Clinical Oncology",
        "citied_by": "114",
        "cover_date": "2021-11-20",
        "Abstract": "PURPOSE Patients with myelodysplastic syndromes (MDS) have a survival that can range from months to decades. Prognostic systems that incorporate advanced analytics of clinical, pathologic, and molecular data have the potential to more accurately and dynamically predict survival in patients receiving various therapies. METHODS A total of 1,471 MDS patients with comprehensively annotated clinical and molecular data were included in a training cohort and analyzed using machine learning techniques. A random survival algorithm was used to build a prognostic model, which was then validated in external cohorts. The accuracy of the proposed model, compared with other established models, was assessed using a concordance (c)index. RESULTS The median age for the training cohort was 71 years. Commonly mutated genes included SF3B1, TET2, and ASXL1. The algorithm identified chromosomal karyotype, platelet, hemoglobin levels, bone marrow blast percentage, age, other clinical variables, seven discrete gene mutations, and mutation number as having prognostic impact on overall and leukemia-free survivals. The model was validated in an independent external cohort of 465 patients, a cohort of patients with MDS treated in a prospective clinical trial, a cohort of patients with paired samples at different time points during the disease course, and a cohort of patients who underwent hematopoietic stem-cell transplantation. CONCLUSION A personalized prediction model on the basis of clinical and genomic data outperformed established prognostic models in MDS. The new model was dynamic, predicting survival and leukemia transformation probabilities at different time points that are unique for a given patient, and can upstage and downstage patients into more appropriate risk categories.",
        "DOI": "10.1200/JCO.20.02810",
        "paper_author": "Nazha A.",
        "affiliation_name": "Cleveland Clinic Foundation",
        "affiliation_city": "Cleveland",
        "affiliation_country": "United States",
        "affiliation_id": "60021160",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Artificial Intelligence in Undergraduate Medical Education: A Scoping Review",
        "publication": "Academic Medicine",
        "citied_by": "114",
        "cover_date": "2021-11-01",
        "Abstract": "Purpose Artificial intelligence (AI) is a rapidly growing phenomenon poised to instigate large-scale changes in medicine. However, medical education has not kept pace with the rapid advancements of AI. Despite several calls to action, the adoption of teaching on AI in undergraduate medical education (UME) has been limited. This scoping review aims to identify gaps and key themes in the peer-reviewed literature on AI training in UME. Method The scoping review was informed by Arksey and O'Malley's methodology. Seven electronic databases including MEDLINE and EMBASE were searched for articles discussing the inclusion of AI in UME between January 2000 and July 2020. A total of 4,299 articles were independently screened by 3 co-investigators and 22 full-text articles were included. Data were extracted using a standardized checklist. Themes were identified using iterative thematic analysis. Results The literature addressed: (1) a need for an AI curriculum in UME, (2) recommendations for AI curricular content including machine learning literacy and AI ethics, (3) suggestions for curriculum delivery, (4) an emphasis on cultivating \"uniquely human skills\" such as empathy in response to AI-driven changes, and (5) challenges with introducing an AI curriculum in UME. However, there was considerable heterogeneity and poor consensus across studies regarding AI curricular content and delivery. Conclusions Despite the large volume of literature, there is little consensus on what and how to teach AI in UME. Further research is needed to address these discrepancies and create a standardized framework of competencies that can facilitate greater adoption and implementation of a standardized AI curriculum in UME.",
        "DOI": "10.1097/ACM.0000000000004291",
        "paper_author": "Lee J.",
        "affiliation_name": "University of Toronto Faculty of Medicine",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60021600",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Machine learning predicts 3D printing performance of over 900 drug delivery systems",
        "publication": "Journal of Controlled Release",
        "citied_by": "114",
        "cover_date": "2021-09-10",
        "Abstract": "Three-dimensional printing (3DP) is a transformative technology that is advancing pharmaceutical research by producing personalized drug products. However, advances made via 3DP have been slow due to the lengthy trial-and-error approach in optimization. Artificial intelligence (AI) is a technology that could revolutionize pharmaceutical 3DP through analyzing large datasets. Herein, literature-mined data for developing AI machine learning (ML) models was used to predict key aspects of the 3DP formulation pipeline and in vitro dissolution properties. A total of 968 formulations were mined and assessed from 114 articles. The ML techniques explored were able to learn and provide accuracies as high as 93% for values in the filament hot melt extrusion process. In addition, ML algorithms were able to use data from the composition of the formulations with additional input features to predict the drug release of 3D printed medicines. The best prediction was obtained by an artificial neural network that was able to predict drug release times of a formulation with a mean error of ±24.29 min. In addition, the most important variables were revealed, which could be leveraged in formulation development. Thus, it was concluded that ML proved to be a suitable approach to modelling the 3D printing workflow.",
        "DOI": "10.1016/j.jconrel.2021.07.046",
        "paper_author": "Muñiz Castro B.",
        "affiliation_name": "Universidade da Coruña",
        "affiliation_city": "La Coruna",
        "affiliation_country": "Spain",
        "affiliation_id": "60023610",
        "affiliation_state": "A Coruña"
    },
    {
        "paper_title": "Multi-domain clinical natural language processing with MedCAT: The Medical Concept Annotation Toolkit",
        "publication": "Artificial Intelligence in Medicine",
        "citied_by": "113",
        "cover_date": "2021-07-01",
        "Abstract": "Electronic health records (EHR) contain large volumes of unstructured text, requiring the application of information extraction (IE) technologies to enable clinical analysis. We present the open source Medical Concept Annotation Toolkit (MedCAT) that provides: (a) a novel self-supervised machine learning algorithm for extracting concepts using any concept vocabulary including UMLS/SNOMED-CT; (b) a feature-rich annotation interface for customizing and training IE models; and (c) integrations to the broader CogStack ecosystem for vendor-agnostic health system deployment. We show improved performance in extracting UMLS concepts from open datasets (F1:0.448–0.738 vs 0.429–0.650). Further real-world validation demonstrates SNOMED-CT extraction at 3 large London hospitals with self-supervised training over ∼8.8B words from ∼17M clinical records and further fine-tuning with ∼6K clinician annotated examples. We show strong transferability (F1 > 0.94) between hospitals, datasets and concept types indicating cross-domain EHR-agnostic utility for accelerated clinical and research use cases.",
        "DOI": "10.1016/j.artmed.2021.102083",
        "paper_author": "Kraljevic Z.",
        "affiliation_name": "King's College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60011520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "3D printing of tissue engineering scaffolds: a focus on vascular regeneration",
        "publication": "Bio-Design and Manufacturing",
        "citied_by": "113",
        "cover_date": "2021-06-01",
        "Abstract": "Tissue engineering is an emerging means for resolving the problems of tissue repair and organ replacement in regenerative medicine. Insufficient supply of nutrients and oxygen to cells in large-scale tissues has led to the demand to prepare blood vessels. Scaffold-based tissue engineering approaches are effective methods to form new blood vessel tissues. The demand for blood vessels prompts systematic research on fabrication strategies of vascular scaffolds for tissue engineering. Recent advances in 3D printing have facilitated fabrication of vascular scaffolds, contributing to broad prospects for tissue vascularization. This review presents state of the art on modeling methods, print materials and preparation processes for fabrication of vascular scaffolds, and discusses the advantages and application fields of each method. Specially, significance and importance of scaffold-based tissue engineering for vascular regeneration are emphasized. Print materials and preparation processes are discussed in detail. And a focus is placed on preparation processes based on 3D printing technologies and traditional manufacturing technologies including casting, electrospinning, and Lego-like construction. And related studies are exemplified. Transformation of vascular scaffolds to clinical application is discussed. Also, four trends of 3D printing of tissue engineering vascular scaffolds are presented, including machine learning, near-infrared photopolymerization, 4D printing, and combination of self-assembly and 3D printing-based methods.",
        "DOI": "10.1007/s42242-020-00109-0",
        "paper_author": "Wang P.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Machine learning in polymer informatics",
        "publication": "InfoMat",
        "citied_by": "112",
        "cover_date": "2021-04-01",
        "Abstract": "Polymers have been widely used in energy storage, construction, medicine, aerospace, and so on. However, the complexity of chemical composition and morphology of polymers has brought challenges to their development. Thanks to the integration of machine learning algorithms and large data resources, the data-driven methods have opened up a new road for the development of polymer science and engineering. The emerging polymer informatics attempts to accelerate the performance prediction and process optimization of new polymers by using machine learning models based on reliable data. With the gradual supplement of currently available databases, the emergence of new databases and the continuous improvement of machine learning algorithms, the research paradigm of polymer informatics will be more efficient and widely used. Based on these points, this paper reviews the development trends of machine learning assisted polymer informatics and provides a simple introduction for researchers in materials, artificial intelligence, and other fields. (Figure presented.).",
        "DOI": "10.1002/inf2.12167",
        "paper_author": "Sha W.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60025761",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "A roadmap for the Human Developmental Cell Atlas",
        "publication": "Nature",
        "citied_by": "111",
        "cover_date": "2021-09-09",
        "Abstract": "The Human Developmental Cell Atlas (HDCA) initiative, which is part of the Human Cell Atlas, aims to create a comprehensive reference map of cells during development. This will be critical to understanding normal organogenesis, the effect of mutations, environmental factors and infectious agents on human development, congenital and childhood disorders, and the cellular basis of ageing, cancer and regenerative medicine. Here we outline the HDCA initiative and the challenges of mapping and modelling human development using state-of-the-art technologies to create a reference atlas across gestation. Similar to the Human Genome Project, the HDCA will integrate the output from a growing community of scientists who are mapping human development into a unified atlas. We describe the early milestones that have been achieved and the use of human stem-cell-derived cultures, organoids and animal models to inform the HDCA, especially for prenatal tissues that are hard to acquire. Finally, we provide a roadmap towards a complete atlas of human development.",
        "DOI": "10.1038/s41586-021-03620-1",
        "paper_author": "Haniffa M.",
        "affiliation_name": "Newcastle University",
        "affiliation_city": "Newcastle",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60006222",
        "affiliation_state": "Tyne and Wear"
    },
    {
        "paper_title": "Machine learning and applications in microbiology",
        "publication": "FEMS Microbiology Reviews",
        "citied_by": "111",
        "cover_date": "2021-09-01",
        "Abstract": "To understand the intricacies of microorganisms at the molecular level requires making sense of copious volumes of data such that it may now be humanly impossible to detect insightful data patterns without an artificial intelligence application called machine learning. Applying machine learning to address biological problems is expected to grow at an unprecedented rate, yet it is perceived by the uninitiated as a mysterious and daunting entity entrusted to the domain of mathematicians and computer scientists. The aim of this review is to identify key points required to start the journey of becoming an effective machine learning practitioner. These key points are further reinforced with an evaluation of how machine learning has been applied so far in a broad scope of real-life microbiology examples. This includes predicting drug targets or vaccine candidates, diagnosing microorganisms causing infectious diseases, classifying drug resistance against antimicrobial medicines, predicting disease outbreaks and exploring microbial interactions. Our hope is to inspire microbiologists and other related researchers to join the emerging machine learning revolution.",
        "DOI": "10.1093/femsre/fuab015",
        "paper_author": "Goodswen S.J.",
        "affiliation_name": "University of Technology Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60023932",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Does \"aI\" stand for augmenting inequality in the era of covid-19 healthcare?",
        "publication": "The BMJ",
        "citied_by": "111",
        "cover_date": "2021-03-15",
        "Abstract": "NA",
        "DOI": "10.1136/bmj.n304",
        "paper_author": "Leslie D.",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60111768",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Opening the black box of AI-Medicine",
        "publication": "Journal of Gastroenterology and Hepatology (Australia)",
        "citied_by": "111",
        "cover_date": "2021-03-01",
        "Abstract": "One of the biggest challenges of utilizing artificial intelligence (AI) in medicine is that physicians are reluctant to trust and adopt something that they do not fully understand and regarded as a “black box.” Machine Learning (ML) can assist in reading radiological, endoscopic and histological pictures, suggesting diagnosis and predict disease outcome, and even recommending therapy and surgical decisions. However, clinical adoption of these AI tools has been slow because of a lack of trust. Besides clinician's doubt, patients lacking confidence with AI-powered technologies also hamper development. While they may accept the reality that human errors can occur, little tolerance of machine error is anticipated. In order to implement AI medicine successfully, interpretability of ML algorithm needs to improve. Opening the black box in AI medicine needs to take a stepwise approach. Small steps of biological explanation and clinical experience in ML algorithm can help to build trust and acceptance. AI software developers will have to clearly demonstrate that when the ML technologies are integrated into the clinical decision-making process, they can actually help to improve clinical outcome. Enhancing interpretability of ML algorithm is a crucial step in adopting AI in medicine.",
        "DOI": "10.1111/jgh.15384",
        "paper_author": "Poon A.I.F.",
        "affiliation_name": "Abc",
        "affiliation_city": "Kingstown",
        "affiliation_country": "Saint Vincent and the Grenadines",
        "affiliation_id": "126419946",
        "affiliation_state": "Saint George"
    },
    {
        "paper_title": "Machine learning in clinical decision making",
        "publication": "Med",
        "citied_by": "108",
        "cover_date": "2021-06-11",
        "Abstract": "Machine learning is increasingly integrated into clinical practice, with applications ranging from pre-clinical data processing, bedside diagnosis assistance, patient stratification, treatment decision making, and early warning as part of primary and secondary prevention. However, a multitude of technological, medical, and ethical considerations are critical in machine-learning utilization, including the necessity for careful validation of machine-learning-based technologies in real-life contexts, unbiased evaluation of benefits and risks, and avoidance of technological over-dependence and associated loss of clinical, ethical, and social-related decision-making capacities. Other challenges include the need for careful benchmarking and external validations, dissemination of end-user knowledge from computational experts to field users, and responsible code and data sharing, enabling transparent assessment of pipelines. In this review, we highlight key promises and achievements in integration of machine-learning platforms into clinical medicine while highlighting limitations, pitfalls, and challenges toward enhanced integration of learning systems into the medical realm.",
        "DOI": "10.1016/j.medj.2021.04.006",
        "paper_author": "Adlung L.",
        "affiliation_name": "Weizmann Institute of Science Israel",
        "affiliation_city": "Rehovot",
        "affiliation_country": "Israel",
        "affiliation_id": "60017563",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A deep learning based ensemble learning method for epileptic seizure prediction",
        "publication": "Computers in Biology and Medicine",
        "citied_by": "108",
        "cover_date": "2021-09-01",
        "Abstract": "In epilepsy, patients suffer from seizures which cannot be controlled with medicines or surgical treatments in more than 30% of the cases. Prediction of epileptic seizures is extremely important so that they can be controlled with medication before they actually occur. Researchers have proposed multiple machine/deep learning based methods to predict epileptic seizures; however, accurate prediction of epileptic seizures with low false positive rate is still a challenge. In this research, we propose a deep learning based ensemble learning method to predict epileptic seizures. In the proposed method, EEG signals are preprocessed using empirical mode decomposition followed by bandpass filtering for noise removal. The class imbalance problem has been mitigated with synthetic preictal segments generated using generative adversarial networks. A three-layer customized convolutional neural network has been proposed to extract automated features from preprocessed EEG signals and combined them with handcrafted features to get a comprehensive feature set. The feature set is then used to train an ensemble classifier that combines the output of SVM, CNN and LSTM using Model agnostic meta learning. An average sensitivity of 96.28% and specificity of 95.65% with an average anticipation time of 33 min on all subjects of CHBMIT has been achieved by the proposed method, whereas, on American epilepsy society-Kaggle seizure prediction dataset, an average sensitivity of 94.2% and specificity of 95.8% has been achieved on all subjects.",
        "DOI": "10.1016/j.compbiomed.2021.104710",
        "paper_author": "Muhammad Usman S.",
        "affiliation_name": "Bahria University",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60070613",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A new molecular classification to drive precision treatment strategies in primary Sjögren’s syndrome",
        "publication": "Nature Communications",
        "citied_by": "105",
        "cover_date": "2021-12-01",
        "Abstract": "There is currently no approved treatment for primary Sjögren’s syndrome, a disease that primarily affects adult women. The difficulty in developing effective therapies is -in part- because of the heterogeneity in the clinical manifestation and pathophysiology of the disease. Finding common molecular signatures among patient subgroups could improve our understanding of disease etiology, and facilitate the development of targeted therapeutics. Here, we report, in a cross-sectional cohort, a molecular classification scheme for Sjögren’s syndrome patients based on the multi-omic profiling of whole blood samples from a European cohort of over 300 patients, and a similar number of age and gender-matched healthy volunteers. Using transcriptomic, genomic, epigenetic, cytokine expression and flow cytometry data, combined with clinical parameters, we identify four groups of patients with distinct patterns of immune dysregulation. The biomarkers we identify can be used by machine learning classifiers to sort future patients into subgroups, allowing the re-evaluation of response to treatments in clinical trials.",
        "DOI": "10.1038/s41467-021-23472-7",
        "paper_author": "Soret P.",
        "affiliation_name": "IRIS Institut de Recherches Internationales Servier",
        "affiliation_city": "Courbevoie",
        "affiliation_country": "France",
        "affiliation_id": "60004412",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep learning applications for IoT in health care: A systematic review",
        "publication": "Informatics in Medicine Unlocked",
        "citied_by": "105",
        "cover_date": "2021-01-01",
        "Abstract": "In machine learning, deep learning is the most popular topic having a wide range of applications such as computer vision, natural language processing, speech recognition, visual object detection, disease prediction, drug discovery, bioinformatics, biomedicine, etc. Of these applications, health care and medical science-related applications are dramatically on the rise. The tremendous big data growth, the Internet of Things (IoT), connected devices, and high-performance computers utilizing GPUs and TPUs are the main reasons why deep learning is so popular. Based on their specific tasks, medical IoT, digital images, electronic health record (EHR) data, genomic data, and central medical databases are the primary data sources for deep learning systems. Several potential issues such as privacy, QoS optimization, and deployment indicate the pivotal part of deep learning. In this paper, deep learning for IoT applications in health care systems is reviewed based on the Systematic Literature Review (SLR). This paper investigates the related researches, selected from among 44 published research papers, conducted within a period of ten years – 2010 to 2020. Firstly, theoretical concepts and ideas of deep learning and technical taxonomy are proposed. Afterwards, major deep learning applications for IoT in health care and medical sciences are presented through analyzing the related works. Later, the main idea, advantages, disadvantages, and limitations of each study are discussed, preceding suggestions for further research.",
        "DOI": "10.1016/j.imu.2021.100550",
        "paper_author": "Bolhasani H.",
        "affiliation_name": "Islamic Azad University, Science and Research Branch",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60105242",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Trends in predictive biodegradation for sustainable mitigation of environmental pollutants: Recent progress and future outlook",
        "publication": "Science of the Total Environment",
        "citied_by": "105",
        "cover_date": "2021-05-20",
        "Abstract": "The feasibility of in-silico techniques, together with the computational framework, has been applied to predictive bioremediation aiming to clean-up contaminants, toxicity evaluation, and possibilities for the degradation of complex recalcitrant compounds. Emerging contaminants from different industries have posed a significant hazard to the environment and public health. Given current bioremediation strategies, it is often a failure or inadequate for sustainable mitigation of hazardous pollutants. However, clear-cut vital information about biodegradation is quite incomplete from a conventional remediation techniques perspective. Lacking complete information on bio-transformed compounds leads to seeking alternative methods. Only scarce information about the transformed products and toxicity profile is available in the published literature. To fulfill this literature gap, various computational or in-silico technologies have emerged as alternating techniques, which are being recognized as in-silico approaches for bioremediation. Molecular docking, molecular dynamics simulation, and biodegradation pathways predictions are the vital part of predictive biodegradation, including the Quantitative Structure-Activity Relationship (QSAR), Quantitative structure-biodegradation relationship (QSBR) model system. Furthermore, machine learning (ML), artificial neural network (ANN), genetic algorithm (GA) based programs offer simultaneous biodegradation prediction along with toxicity and environmental fate prediction. Herein, we spotlight the feasibility of in-silico remediation approaches for various persistent, recalcitrant contaminants while traditional bioremediation fails to mitigate such pollutants. Such could be addressed by exploiting described model systems and algorithm-based programs. Furthermore, recent advances in QSAR modeling, algorithm, and dedicated biodegradation prediction system have been summarized with unique attributes.",
        "DOI": "10.1016/j.scitotenv.2020.144561",
        "paper_author": "Singh A.K.",
        "affiliation_name": "Indian Institute of Toxicology Research",
        "affiliation_city": "Lucknow",
        "affiliation_country": "India",
        "affiliation_id": "60101552",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Morphological and molecular breast cancer profiling through explainable machine learning",
        "publication": "Nature Machine Intelligence",
        "citied_by": "104",
        "cover_date": "2021-04-01",
        "Abstract": "Recent advances in cancer research and diagnostics largely rely on new developments in microscopic or molecular profiling techniques, offering high levels of detail with respect to either spatial or molecular features, but usually not both. Here, we present an explainable machine-learning approach for the integrated profiling of morphological, molecular and clinical features from breast cancer histology. First, our approach allows for the robust detection of cancer cells and tumour-infiltrating lymphocytes in histological images, providing precise heatmap visualizations explaining the classifier decisions. Second, molecular features, including DNA methylation, gene expression, copy number variations, somatic mutations and proteins are predicted from histology. Molecular predictions reach balanced accuracies up to 78%, whereas accuracies of over 95% can be achieved for subgroups of patients. Finally, our explainable AI approach allows assessment of the link between morphological and molecular cancer properties. The resulting computational multiplex-histology analysis can help promote basic cancer research and precision medicine through an integrated diagnostic scoring of histological, clinical and molecular features.",
        "DOI": "10.1038/s42256-021-00303-4",
        "paper_author": "Binder A.",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial Intelligence Techniques: Analysis, Application, and Outcome in Dentistry - A Systematic Review",
        "publication": "BioMed Research International",
        "citied_by": "103",
        "cover_date": "2021-01-01",
        "Abstract": "Objective. The objective of this systematic review was to investigate the quality and outcome of studies into artificial intelligence techniques, analysis, and effect in dentistry. Materials and Methods. Using the MeSH keywords: artificial intelligence (AI), dentistry, AI in dentistry, neural networks and dentistry, machine learning, AI dental imaging, and AI treatment recommendations and dentistry. Two investigators performed an electronic search in 5 databases: PubMed/MEDLINE (National Library of Medicine), Scopus (Elsevier), ScienceDirect databases (Elsevier), Web of Science (Clarivate Analytics), and the Cochrane Collaboration (Wiley). The English language articles reporting on AI in different dental specialties were screened for eligibility. Thirty-two full-text articles were selected and systematically analyzed according to a predefined inclusion criterion. These articles were analyzed as per a specific research question, and the relevant data based on article general characteristics, study and control groups, assessment methods, outcomes, and quality assessment were extracted. Results. The initial search identified 175 articles related to AI in dentistry based on the title and abstracts. The full text of 38 articles was assessed for eligibility to exclude studies not fulfilling the inclusion criteria. Six articles not related to AI in dentistry were excluded. Thirty-two articles were included in the systematic review. It was revealed that AI provides accurate patient management, dental diagnosis, prediction, and decision making. Artificial intelligence appeared as a reliable modality to enhance future implications in the various fields of dentistry, i.e., diagnostic dentistry, patient management, head and neck cancer, restorative dentistry, prosthetic dental sciences, orthodontics, radiology, and periodontics. Conclusion. The included studies describe that AI is a reliable tool to make dental care smooth, better, time-saving, and economical for practitioners. AI benefits them in fulfilling patient demand and expectations. The dentists can use AI to ensure quality treatment, better oral health care outcome, and achieve precision. AI can help to predict failures in clinical scenarios and depict reliable solutions. However, AI is increasing the scope of state-of-the-art models in dentistry but is still under development. Further studies are required to assess the clinical performance of AI techniques in dentistry.",
        "DOI": "10.1155/2021/9751564",
        "paper_author": "Ahmed N.",
        "affiliation_name": "Universiti Sains Malaysia, Health Campus",
        "affiliation_city": "Kubang Kerian",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60032354",
        "affiliation_state": "Kelantan"
    },
    {
        "paper_title": "Harnessing artificial intelligence for the next generation of 3D printed medicines",
        "publication": "Advanced Drug Delivery Reviews",
        "citied_by": "103",
        "cover_date": "2021-08-01",
        "Abstract": "Artificial intelligence (AI) is redefining how we exist in the world. In almost every sector of society, AI is performing tasks with super-human speed and intellect; from the prediction of stock market trends to driverless vehicles, diagnosis of disease, and robotic surgery. Despite this growing success, the pharmaceutical field is yet to truly harness AI. Development and manufacture of medicines remains largely in a ‘one size fits all’ paradigm, in which mass-produced, identical formulations are expected to meet individual patient needs. Recently, 3D printing (3DP) has illuminated a path for on-demand production of fully customisable medicines. Due to its flexibility, pharmaceutical 3DP presents innumerable options during formulation development that generally require expert navigation. Leveraging AI within pharmaceutical 3DP removes the need for human expertise, as optimal process parameters can be accurately predicted by machine learning. AI can also be incorporated into a pharmaceutical 3DP ‘Internet of Things’, moving the personalised production of medicines into an intelligent, streamlined, and autonomous pipeline. Supportive infrastructure, such as The Cloud and blockchain, will also play a vital role. Crucially, these technologies will expedite the use of pharmaceutical 3DP in clinical settings and drive the global movement towards personalised medicine and Industry 4.0.",
        "DOI": "10.1016/j.addr.2021.05.015",
        "paper_author": "Elbadawi M.",
        "affiliation_name": "UCL School of Pharmacy",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60016379",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Digital twins in livestock farming",
        "publication": "Animals",
        "citied_by": "103",
        "cover_date": "2021-04-01",
        "Abstract": "Artificial intelligence (AI), machine learning (ML) and big data are consistently called upon to analyze and comprehend many facets of modern daily life. AI and ML in particular are widely used in animal husbandry to monitor both the animals and environment around the clock, which leads to a better understanding of animal behavior and distress, disease control and prevention, and effective business decisions for the farmer. One particularly promising area that advances upon AI is digital twin technology, which is currently used to improve efficiencies and reduce costs across multiple industries and sectors. In contrast to a model, a digital twin is a digital replica of a real-world entity that is kept current with a constant influx of data. The application of digital twins within the livestock farming sector is the next frontier and has the potential to be used to improve large-scale precision livestock farming practices, machinery and equipment usage, and the health and well-being of a wide variety of farm animals. The mental and emotional states of animals can be monitored using recognition technology that examines facial features, such as ear postures and eye white regions. Used with modeling, simulation and augmented reality technologies, digital twins can help farmers to build more energy-efficient housing structures, predict heat cycles for breeding, discourage negative behaviors of livestock, and potentially much more. As with all disruptive technological advances, the implementation of digital twin technology will demand a thorough cost and benefit analysis of individual farms. Our goal in this review is to assess the progress toward the use of digital twin technology in livestock farming, with the goal of revolutionizing animal husbandry in the future.",
        "DOI": "10.3390/ani11041008",
        "paper_author": "Neethirajan S.",
        "affiliation_name": "Wageningen University &amp; Research",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands",
        "affiliation_id": "60004156",
        "affiliation_state": "Gelderland"
    },
    {
        "paper_title": "Automation and computer-assisted planning for chemical synthesis",
        "publication": "Nature Reviews Methods Primers",
        "citied_by": "101",
        "cover_date": "2021-12-01",
        "Abstract": "The molecules of today — the medicines that cure diseases, the agrochemicals that protect our crops, the materials that make life convenient — are becoming increasingly sophisticated thanks to advancements in chemical synthesis. As tools for synthesis improve, molecular architects can be bold and creative in the way they design and produce molecules. Several emerging tools at the interface of chemical synthesis and data science have come to the forefront in recent years, including algorithms for retrosynthesis and reaction prediction, and robotics for autonomous or high-throughput synthesis. This Primer covers recent additions to the toolbox of the data-savvy organic chemist. There is a new movement in retrosynthetic logic, predictive models of reactivity and chemistry automata, with considerable recent engagement from contributors in diverse fields. The promise of chemical synthesis in the information age is to improve the quality of the molecules of tomorrow through data-harnessing and automation. This Primer is written for organic chemists and data scientists looking to understand the software, hardware, data sets and tactics that are commonly used as well as the capabilities and limitations of the field. The Primer is split into three main components covering retrosynthetic logic, reaction prediction and automated synthesis. The former of these topics is about distilling the strategy of multistep synthesis to a logic that can be taught to a computer. The section on reaction prediction details modern tools and models for developing reaction conditions, catalysts and even new transformations based on information-rich data sets and statistical tools such as machine learning. Finally, we cover recent advances in the use of liquid handling robotics and autonomous systems that can physically perform experiments in the chemistry laboratory.",
        "DOI": "10.1038/s43586-021-00022-5",
        "paper_author": "Shen Y.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60025778",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Deep learning boosts sensitivity of mass spectrometry-based immunopeptidomics",
        "publication": "Nature Communications",
        "citied_by": "101",
        "cover_date": "2021-12-01",
        "Abstract": "Characterizing the human leukocyte antigen (HLA) bound ligandome by mass spectrometry (MS) holds great promise for developing vaccines and drugs for immune-oncology. Still, the identification of non-tryptic peptides presents substantial computational challenges. To address these, we synthesized and analyzed >300,000 peptides by multi-modal LC-MS/MS within the ProteomeTools project representing HLA class I & II ligands and products of the proteases AspN and LysN. The resulting data enabled training of a single model using the deep learning framework Prosit, allowing the accurate prediction of fragment ion spectra for tryptic and non-tryptic peptides. Applying Prosit demonstrates that the identification of HLA peptides can be improved up to 7-fold, that 87% of the proposed proteasomally spliced HLA peptides may be incorrect and that dozens of additional immunogenic neo-epitopes can be identified from patient tumors in published data. Together, the provided peptides, spectra and computational tools substantially expand the analytical depth of immunopeptidomics workflows.",
        "DOI": "10.1038/s41467-021-23713-9",
        "paper_author": "Wilhelm M.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany",
        "affiliation_id": "60019722",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Applied machine learning and artificial intelligence in rheumatology",
        "publication": "Rheumatology Advances in Practice",
        "citied_by": "101",
        "cover_date": "2021-01-01",
        "Abstract": "Machine learning as a field of artificial intelligence is increasingly applied in medicine to assist patients and physicians. Growing datasets provide a sound basis with which to apply machine learning methods that learn from previous experiences. This review explains the basics of machine learning and its subfields of supervised learning, unsupervised learning, reinforcement learning and deep learning. We provide an overview of current machine learning applications in rheumatology, mainly supervised learning methods for e-diagnosis, disease detection and medical image analysis. In the future, machine learning will be likely to assist rheumatologists in predicting the course of the disease and identifying important disease factors. Even more interestingly, machine learning will probably be able to make treatment propositions and estimate their expected benefit (e.g. by reinforcement learning). Thus, in future, shared decision-making will not only include the patient's opinion and the rheumatologist's empirical and evidence-based experience, but it will also be influenced by machine-learned evidence.",
        "DOI": "10.1093/rap/rkaa005",
        "paper_author": "Hügle M.",
        "affiliation_name": "Universität Freiburg",
        "affiliation_city": "Freiburg im Breisgau",
        "affiliation_country": "Germany",
        "affiliation_id": "60025641",
        "affiliation_state": "Baden-Wurttemberg"
    }
]