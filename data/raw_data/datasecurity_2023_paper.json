[
    {
        "paper_title": "Handbook of face recognition",
        "publication": "Handbook of Face Recognition",
        "citied_by": "795",
        "cover_date": "2023-12-29",
        "Abstract": "The history of computer-aided face recognition dates to the 1960s, yet the problem of automatic face recognition - a task that humans perform routinely and effortlessly in our daily lives - still poses great challenges, especially in unconstrained conditions. This highly anticipated new edition provides a comprehensive account of face recognition research and technology, spanning the full range of topics needed for designing operational recognition systems. After a thorough introduction, each subsequent chapter focuses on a specific topic, reviewing background information, up-to-date techniques, and recent results, as well as offering challenges and future directions. Topics and features: • Fully updated, revised, and expanded, covering the entire spectrum of concepts, methods, and algorithms for automated detection and recognition systems • Provides comprehensive coverage of face detection, alignment, feature extraction, and recognition technologies, and issues in evaluation, systems, security, and applications • Contains numerous step-by-step algorithms • Describes a broad range of applications from person verification, surveillance, and security, to entertainment • Presents contributions from an international selection of preeminent experts • Integrates numerous supporting graphs, tables, charts, and performance data This practical and authoritative reference is an essential resource for researchers, professionals and students involved in image processing, computer vision, biometrics, security, Internet, mobile devices, human-computer interface, E-services, computer graphics and animation, and the computer game industry.",
        "DOI": "10.1007/978-3-031-43567-6",
        "paper_author": "Li S.Z.",
        "affiliation_name": "Westlake University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117660",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "A Survey on Metaverse: Fundamentals, Security, and Privacy",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "622",
        "cover_date": "2023-01-01",
        "Abstract": "Metaverse, as an evolving paradigm of the next-generation Internet, aims to build a fully immersive, hyper spatiotemporal, and self-sustaining virtual shared space for humans to play, work, and socialize. Driven by recent advances in emerging technologies such as extended reality, artificial intelligence, and blockchain, metaverse is stepping from science fiction to an upcoming reality. However, severe privacy invasions and security breaches (inherited from underlying technologies or emerged in the new digital ecology) of metaverse can impede its wide deployment. At the same time, a series of fundamental challenges (e.g., scalability and interoperability) can arise in metaverse security provisioning owing to the intrinsic characteristics of metaverse, such as immersive realism, hyper spatiotemporality, sustainability, and heterogeneity. In this paper, we present a comprehensive survey of the fundamentals, security, and privacy of metaverse. Specifically, we first investigate a novel distributed metaverse architecture and its key characteristics with ternary-world interactions. Then, we discuss the security and privacy threats, present the critical challenges of metaverse systems, and review the state-of-the-art countermeasures. Finally, we draw open research directions for building future metaverse systems.",
        "DOI": "10.1109/COMST.2022.3202047",
        "paper_author": "Wang Y.",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60018308",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "A comprehensive AI policy education framework for university teaching and learning",
        "publication": "International Journal of Educational Technology in Higher Education",
        "citied_by": "389",
        "cover_date": "2023-12-01",
        "Abstract": "This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.",
        "DOI": "10.1186/s41239-023-00408-3",
        "paper_author": "Chan C.K.Y.",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60006541",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "RCSB Protein Data Bank (RCSB.org): delivery of experimentally-determined PDB structures alongside one million computed structure models of proteins from artificial intelligence/machine learning",
        "publication": "Nucleic Acids Research",
        "citied_by": "354",
        "cover_date": "2023-01-06",
        "Abstract": "The Research Collaboratory for Structural Bioinformatics Protein Data Bank (RCSB PDB), founding member of the Worldwide Protein Data Bank (wwPDB), is the US data center for the open-access PDB archive. As wwPDB-designated Archive Keeper, RCSB PDB is also responsible for PDB data security. Annually, RCSB PDB serves >10 000 depositors of three-dimensional (3D) biostructures working on all permanently inhabited continents. RCSB PDB delivers data from its research-focused RCSB.org web portal to many millions of PDB data consumers based in virtually every United Nations-recognized country, territory, etc. This Database Issue contribution describes upgrades to the research-focused RCSB.org web portal that created a one-stop-shop for open access to ∼200 000 experimentally-determined PDB structures of biological macromolecules alongside >1 000 000 incorporated Computed Structure Models (CSMs) predicted using artificial intelligence/machine learning methods. RCSB.org is a 'living data resource.' Every PDB structure and CSM is integrated weekly with related functional annotations from external biodata resources, providing up-to-date information for the entire corpus of 3D biostructure data freely available from RCSB.org with no usage limitations. Within RCSB.org, PDB structures and the CSMs are clearly identified as to their provenance and reliability. Both are fully searchable, and can be analyzed and visualized using the full complement of RCSB.org web portal capabilities.",
        "DOI": "10.1093/nar/gkac1077",
        "paper_author": "Burley S.K.",
        "affiliation_name": "Protein Data Bank",
        "affiliation_city": "Piscataway",
        "affiliation_country": "United States",
        "affiliation_id": "60120814",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "345",
        "cover_date": "2023-01-01",
        "Abstract": "The Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance specifications are poised to revolutionize the telecom ecosystem. O-RAN promotes virtualized RANs where disaggregated components are connected via open interfaces and optimized by intelligent controllers. The result is a new paradigm for the RAN design, deployment, and operations: O-RAN networks can be built with multi-vendor, interoperable components, and can be programmatically optimized through a centralized abstraction layer and data-driven closed-loop control. Therefore, understanding O-RAN, its architecture, its interfaces, and workflows is key for researchers and practitioners in the wireless community. In this article, we present the first detailed tutorial on O-RAN. We also discuss the main research challenges and review early research results. We provide a deep dive of the O-RAN specifications, describing its architecture, design principles, and the O-RAN interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to effectively control and manage 3GPP-defined RANs. Based on this, we discuss innovations and challenges of O-RAN networks, including the Artificial Intelligence (AI) and Machine Learning (ML) workflows that the architecture and interfaces enable, security, and standardization issues. Finally, we review experimental research platforms that can be used to design and test O-RAN networks, along with recent research results, and we outline future directions for O-RAN development.",
        "DOI": "10.1109/COMST.2023.3239220",
        "paper_author": "Polese M.",
        "affiliation_name": "Northeastern University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60028628",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
        "publication": "Journal of Big Data",
        "citied_by": "306",
        "cover_date": "2023-12-01",
        "Abstract": "Data scarcity is a major challenge when training deep learning (DL) models. DL demands a large amount of data to achieve exceptional performance. Unfortunately, many applications have small or inadequate data to train DL frameworks. Usually, manual labeling is needed to provide labeled data, which typically involves human annotators with a vast background of knowledge. This annotation process is costly, time-consuming, and error-prone. Usually, every DL framework is fed by a significant amount of labeled data to automatically learn representations. Ultimately, a larger amount of data would generate a better DL model and its performance is also application dependent. This issue is the main barrier for many applications dismissing the use of DL. Having sufficient data is the first step toward any successful and trustworthy DL application. This paper presents a holistic survey on state-of-the-art techniques to deal with training DL models to overcome three challenges including small, imbalanced datasets, and lack of generalization. This survey starts by listing the learning techniques. Next, the types of DL architectures are introduced. After that, state-of-the-art solutions to address the issue of lack of training data are listed, such as Transfer Learning (TL), Self-Supervised Learning (SSL), Generative Adversarial Networks (GANs), Model Architecture (MA), Physics-Informed Neural Network (PINN), and Deep Synthetic Minority Oversampling Technique (DeepSMOTE). Then, these solutions were followed by some related tips about data acquisition needed prior to training purposes, as well as recommendations for ensuring the trustworthiness of the training dataset. The survey ends with a list of applications that suffer from data scarcity, several alternatives are proposed in order to generate more data in each application including Electromagnetic Imaging (EMI), Civil Structural Health Monitoring, Medical imaging, Meteorology, Wireless Communications, Fluid Mechanics, Microelectromechanical system, and Cybersecurity. To the best of the authors’ knowledge, this is the first review that offers a comprehensive overview on strategies to tackle data scarcity in DL.",
        "DOI": "10.1186/s40537-023-00727-2",
        "paper_author": "Alzubaidi L.",
        "affiliation_name": "Queensland University of Technology",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60011019",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "An improved fire detection approach based on YOLO-v8 for smart cities",
        "publication": "Neural Computing and Applications",
        "citied_by": "294",
        "cover_date": "2023-10-01",
        "Abstract": "Fires in smart cities can have devastating consequences, causing damage to property, and endangering the lives of citizens. Traditional fire detection methods have limitations in terms of accuracy and speed, making it challenging to detect fires in real time. This paper proposes an improved fire detection approach for smart cities based on the YOLOv8 algorithm, called the smart fire detection system (SFDS), which leverages the strengths of deep learning to detect fire-specific features in real time. The SFDS approach has the potential to improve the accuracy of fire detection, reduce false alarms, and be cost-effective compared to traditional fire detection methods. It can also be extended to detect other objects of interest in smart cities, such as gas leaks or flooding. The proposed framework for a smart city consists of four primary layers: (i) Application layer, (ii) Fog layer, (iii) Cloud layer, and (iv) IoT layer. The proposed algorithm utilizes Fog and Cloud computing, along with the IoT layer, to collect and process data in real time, enabling faster response times and reducing the risk of damage to property and human life. The SFDS achieved state-of-the-art performance in terms of both precision and recall, with a high precision rate of 97.1% for all classes. The proposed approach has several potential applications, including fire safety management in public areas, forest fire monitoring, and intelligent security systems.",
        "DOI": "10.1007/s00521-023-08809-1",
        "paper_author": "Talaat F.M.",
        "affiliation_name": "Faculty of Artificial Intelligence",
        "affiliation_city": "Kafr el-Sheikh",
        "affiliation_country": "Egypt",
        "affiliation_id": "60227512",
        "affiliation_state": "Kafr el-Sheikh"
    },
    {
        "paper_title": "Deep learning modelling techniques: current progress, applications, advantages, and challenges",
        "publication": "Artificial Intelligence Review",
        "citied_by": "264",
        "cover_date": "2023-11-01",
        "Abstract": "Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.",
        "DOI": "10.1007/s10462-023-10466-8",
        "paper_author": "Ahmed S.F.",
        "affiliation_name": "Asian University for Women",
        "affiliation_city": "Chittagong",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60138980",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "ChatGPT for healthcare services: An emerging stage for an innovative perspective",
        "publication": "BenchCouncil Transactions on Benchmarks, Standards and Evaluations",
        "citied_by": "235",
        "cover_date": "2023-02-01",
        "Abstract": "Generative Pretrained Transformer, often known as GPT, is an innovative kind of Artificial Intelligence (AI) which can produce writing that seems to have been written by a person. OpenAI created this AI language model called ChatGPT. It is built using the GPT architecture and is trained on a large corpus of text data to respond to natural language inquiries that resemble a person's requirements. This technology has lots of applications in healthcare. The need for accurate and current data is one of the major obstacles to adopting ChatGPT in healthcare. GPT must have access to precise and up-to-date medical data to provide trustworthy suggestions and treatment options. It might be accomplished by ensuring that the data used by GPT is received from reliable sources and that the data is updated regularly. Since sensitive medical information would be involved, it will also be crucial to consider privacy and security issues while utilising GPT in the healthcare industry. This paper briefs about ChatGPT and its need for healthcare, its significant Work Flow Dimensions and typical features of ChatGPT for the Healthcare domain. Finally, it identified and discussed significant applications of ChatGPT for healthcare. ChatGPT can comprehend the conversational context and provide contextually appropriate replies. Its effectiveness as a conversational AI tool makes it useful for chatbots, virtual assistants, and other applications. However, we see many limitations in medical ethics, data interpretation, accountability and other issues related to the privacy. Regarding specialised tasks like text creation, language translation, text categorisation, text summarisation, and creating conversation systems, ChatGPT has been pre-trained on a large corpus of text data, and somewhat satisfactory results can be expected. Moreover, it can also be utilised for various Natural Language Processing (NLP) activities, including sentiment analysis, part-of-speech tagging, and named entity identification.",
        "DOI": "10.1016/j.tbench.2023.100105",
        "paper_author": "Javaid M.",
        "affiliation_name": "Jamia Millia Islamia",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India",
        "affiliation_id": "60020458",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A systematic literature review of artificial intelligence in the healthcare sector: Benefits, challenges, methodologies, and functionalities",
        "publication": "Journal of Innovation and Knowledge",
        "citied_by": "234",
        "cover_date": "2023-01-01",
        "Abstract": "Administrative and medical processes of the healthcare organizations are rapidly changing because of the use of artificial intelligence (AI) systems. This change demonstrates the critical impact of AI at multiple activities, particularly in medical processes related to early detection and diagnosis. Previous studies suggest that AI can raise the quality of services in the healthcare industry. AI-based technologies have reported to improve human life quality, making life easier, safer and more productive. This study presents a systematic review of academic articles on the application of AI in the healthcare sector. The review initially considered 1,988 academic articles from major scholarly databases. After a careful review, the list was filtered down to 180 articles for full analysis to present a classification framework based on four dimensions: AI-enabled healthcare benefits, challenges, methodologies, and functionalities. It was identified that AI continues to significantly outperform humans in terms of accuracy, efficiency and timely execution of medical and related administrative processes. Benefits for patients’ map directly to the relevant AI functionalities in the categories of diagnosis, treatment, consultation and health monitoring for self-management of chronic conditions. Implications for future research directions are identified in the areas of value-added healthcare services for medical decision-making, security and privacy for patient data, health monitoring features, and creative IT service delivery models using AI.",
        "DOI": "10.1016/j.jik.2023.100333",
        "paper_author": "Ali O.",
        "affiliation_name": "American University of the Middle East",
        "affiliation_city": "Al Ahmadi",
        "affiliation_country": "Kuwait",
        "affiliation_id": "60105846",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Comprehensive Survey on Graph Anomaly Detection With Deep Learning",
        "publication": "IEEE Transactions on Knowledge and Data Engineering",
        "citied_by": "230",
        "cover_date": "2023-12-01",
        "Abstract": "Anomalies are rare observations (e.g., data records or events) that deviate significantly from the others in the sample. Over the past few decades, research on anomaly mining has received increasing interests due to the implications of these occurrences in a wide range of disciplines - for instance, security, finance, and medicine. For this reason, anomaly detection, which aims to identify these rare observations, has become one of the most vital tasks in the world and has shown its power in preventing detrimental events, such as financial fraud, network intrusions, and social spam. The detection task is typically solved by identifying outlying data points in the feature space, which, inherently, overlooks the relational information in real-world data. At the same time, graphs have been prevalently used to represent the structural/relational information, which raises the graph anomaly detection problem - identifying anomalous graph objects (i.e., nodes, edges and sub-graphs) in a single graph, or anomalous graphs in a set/database of graphs. Conventional anomaly detection techniques cannot tackle this problem well because of the complexity of graph data (e.g., irregular structures, relational dependencies, node/edge types/attributes/directions/multiplicities/weights, large scale, etc.). However, thanks to the advent of deep learning in breaking these limitations, graph anomaly detection with deep learning has received a growing attention recently. In this survey, we aim to provide a systematic and comprehensive review of the contemporary deep learning techniques for graph anomaly detection. Specifically, we provide a taxonomy that follows a task-driven strategy and categorizes existing work according to the anomalous graph objects that they can detect. We especially focus on the challenges in this research area and discuss the key intuitions, technical details as well as relative strengths and weaknesses of various techniques in each category. From the survey results, we highlight 12 future research directions spanning unsolved and emerging problems introduced by graph data, anomaly detection, deep learning and real-world applications. Additionally, to provide a wealth of useful resources for future studies, we have compiled a set of open-source implementations, public datasets, and commonly-used evaluation metrics. With this survey, our goal is to create a 'one-stop-shop' that provides a unified understanding of the problem categories and existing approaches, publicly available hands-on resources, and high-impact open challenges for graph anomaly detection using deep learning.",
        "DOI": "10.1109/TKDE.2021.3118815",
        "paper_author": "Ma X.",
        "affiliation_name": "Macquarie University",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60019544",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT",
        "publication": "Entrepreneurial Business and Economics Review",
        "citied_by": "210",
        "cover_date": "2023-06-01",
        "Abstract": "Objective: The objective of the article is to provide a comprehensive identification and understanding of the challenges and opportunities associated with the use of generative artificial intelligence (GAI) in business. This study sought to develop a conceptual framework that gathers the negative aspects of GAI development in management and economics, with a focus on ChatGPT. Research Design & Methods: The study employed a narrative and critical literature review and developed a conceptual framework based on prior literature. We used a line of deductive reasoning in formulating our theoretical framework to make the study’s overall structure rational and productive. Therefore, this article should be viewed as a conceptual article that highlights the controversies and threats of GAI in management and economics, with ChatGPT as a case study. Findings: Based on the conducted deep and extensive query of academic literature on the subject as well as professional press and Internet portals, we identified various controversies, threats, defects, and disadvantages of GAI, in particular ChatGPT. Next, we grouped the identified threats into clusters to summarize the seven main threats we see. In our opinion they are as follows: (i) no regulation of the AI market and urgent need for regulation, (ii) poor quality, lack of quality control, disinformation, deepfake content, algorithmic bias, (iii) automationspurred job losses, (iv) personal data violation, social surveillance, and privacy violation, (v) social manipulation, weakening ethics and goodwill, (vi) widening socio-economic inequalities, and (vii) AI technostress. Implications & Recommendations: It is important to regulate the AI/GAI market. Advocating for the regulation of the AI market is crucial to ensure a level playing field, promote fair competition, protect intellectual property rights and privacy, and prevent potential geopolitical risks. The changing job market requires workers to continuously acquire new (digital) skills through education and retraining. As the training of AI systems becomes a prominent job category, it is important to adapt and take advantage of new opportunities. To mitigate the risks related to personal data violation, social surveillance, and privacy violation, GAI developers must prioritize ethical considerations and work to develop systems that prioritize user privacy and security. To avoid social manipulation and weaken ethics and goodwill, it is important to implement responsible AI practices and ethical guidelines: transparency in data usage, bias mitigation techniques, and monitoring of generated content for harmful or misleading information. Contribution & Value Added: This article may aid in bringing attention to the significance of resolving the ethical and legal considerations that arise from the use of GAI and ChatGPT by drawing attention to the controversies and hazards associated with these technologies.",
        "DOI": "10.15678/EBER.2023.110201",
        "paper_author": "Wach K.",
        "affiliation_name": "Krakow University of Economics",
        "affiliation_city": "Krakow",
        "affiliation_country": "Poland",
        "affiliation_id": "60015632",
        "affiliation_state": "MP"
    },
    {
        "paper_title": "A survey on federated learning: challenges and applications",
        "publication": "International Journal of Machine Learning and Cybernetics",
        "citied_by": "203",
        "cover_date": "2023-02-01",
        "Abstract": "Federated learning (FL) is a secure distributed machine learning paradigm that addresses the issue of data silos in building a joint model. Its unique distributed training mode and the advantages of security aggregation mechanism are very suitable for various practical applications with strict privacy requirements. However, with the deployment of FL mode into practical application, some bottlenecks appear in the FL training process, which affects the performance and efficiency of the FL model in practical applications. Therefore, more researchers have paid attention to the challenges of FL and sought for various effective research methods to solve these current bottlenecks. And various research achievements of FL have been made to promote the intelligent development of all application areas with privacy restriction. This paper systematically introduces the current researches in FL from five aspects: the basics knowledge of FL, privacy and security protection mechanisms in FL, communication overhead challenges and heterogeneity problems of FL. Furthermore, we make a comprehensive summary of the research in practical applications and prospect the future research directions of FL.",
        "DOI": "10.1007/s13042-022-01647-y",
        "paper_author": "Wen J.",
        "affiliation_name": "Taiyuan University of Science and Technology",
        "affiliation_city": "Taiyuan",
        "affiliation_country": "China",
        "affiliation_id": "60103975",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "AI-big data analytics for building automation and management systems: a survey, actual challenges and future perspectives",
        "publication": "Artificial Intelligence Review",
        "citied_by": "198",
        "cover_date": "2023-06-01",
        "Abstract": "In theory, building automation and management systems (BAMSs) can provide all the components and functionalities required for analyzing and operating buildings. However, in reality, these systems can only ensure the control of heating ventilation and air conditioning system systems. Therefore, many other tasks are left to the operator, e.g. evaluating buildings’ performance, detecting abnormal energy consumption, identifying the changes needed to improve efficiency, ensuring the security and privacy of end-users, etc. To that end, there has been a movement for developing artificial intelligence (AI) big data analytic tools as they offer various new and tailor-made solutions that are incredibly appropriate for practical buildings’ management. Typically, they can help the operator in (i) analyzing the tons of connected equipment data; and; (ii) making intelligent, efficient, and on-time decisions to improve the buildings’ performance. This paper presents a comprehensive systematic survey on using AI-big data analytics in BAMSs. It covers various AI-based tasks, e.g. load forecasting, water management, indoor environmental quality monitoring, occupancy detection, etc. The first part of this paper adopts a well-designed taxonomy to overview existing frameworks. A comprehensive review is conducted about different aspects, including the learning process, building environment, computing platforms, and application scenario. Moving on, a critical discussion is performed to identify current challenges. The second part aims at providing the reader with insights into the real-world application of AI-big data analytics. Thus, three case studies that demonstrate the use of AI-big data analytics in BAMSs are presented, focusing on energy anomaly detection in residential and office buildings and energy and performance optimization in sports facilities. Lastly, future directions and valuable recommendations are identified to improve the performance and reliability of BAMSs in intelligent buildings.",
        "DOI": "10.1007/s10462-022-10286-2",
        "paper_author": "Himeur Y.",
        "affiliation_name": "Department of Architecture and Urban Planning, College of Engineering, Qatar University",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar",
        "affiliation_id": "60197134",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Re-Thinking Data Strategy and Integration for Artificial Intelligence: Concepts, Opportunities, and Challenges",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "195",
        "cover_date": "2023-06-01",
        "Abstract": "The use of artificial intelligence (AI) is becoming more prevalent across industries such as healthcare, finance, and transportation. Artificial intelligence is based on the analysis of large datasets and requires a continuous supply of high-quality data. However, using data for AI is not without challenges. This paper comprehensively reviews and critically examines the challenges of using data for AI, including data quality, data volume, privacy and security, bias and fairness, interpretability and explainability, ethical concerns, and technical expertise and skills. This paper examines these challenges in detail and offers recommendations on how companies and organizations can address them. By understanding and addressing these challenges, organizations can harness the power of AI to make smarter decisions and gain competitive advantage in the digital age. It is expected, since this review article provides and discusses various strategies for data challenges for AI over the last decade, that it will be very helpful to the scientific research community to create new and novel ideas to rethink our approaches to data strategies for AI.",
        "DOI": "10.3390/app13127082",
        "paper_author": "Aldoseri A.",
        "affiliation_name": "College of Engineering, Qatar University",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar",
        "affiliation_id": "60197135",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Review on cyber-physical and cyber-security system in smart grid: Standards, protocols, constraints, and recommendations",
        "publication": "Journal of Network and Computer Applications",
        "citied_by": "192",
        "cover_date": "2023-01-01",
        "Abstract": "The smart grid (SG) system is an intelligent technology that facilitates the integration of green technology and environmental aspects, which is a two-way communication system for information transformation, power generation, and distribution. The development and application of communication technology in the traditional power system deployed the SG cyber-physical system. The SG systems have a complex architecture that contains critical devices and Internet of Things (IoT)-based infrastructures. These critical infrastructures and devices are faced with cyber-attacks. Therefore, the SG systems required lots of research to protect these attacks from economic damage, security deficits, national grid security, and life loss. This paper comprehensively reviews SG cyber-physical and cyber security systems, standard protocols, and challenges. We discussed the SG model, key elements, advanced distribution management system (ADMS), supervisory control and data acquisition (SCADA), and advanced metering infrastructure framework (AMI). Then, we discussed the SG cyber-physical system communication standards and protocols. We present a correlation between SG cyber-physical system communication technology, standards and protocols, and application. Then, we thoroughly study cyber security principles, standards, and protocols. Finally, we discuss some challenges for SG cyber-physical systems, cyber-attacks, and cyber security systems and recommend some solutions for future research. This study provided a deep understanding of the cyber security systems and standards and proposed direction for future research in smart grid system applications.",
        "DOI": "10.1016/j.jnca.2022.103540",
        "paper_author": "Hasan M.K.",
        "affiliation_name": "Universiti Kebangsaan Malaysia",
        "affiliation_city": "Bangi",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60001821",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Edge AI: A survey",
        "publication": "Internet of Things and Cyber-Physical Systems",
        "citied_by": "189",
        "cover_date": "2023-01-01",
        "Abstract": "Artificial Intelligence (AI) at the edge is the utilization of AI in real-world devices. Edge AI refers to the practice of doing AI computations near the users at the network's edge, instead of centralised location like a cloud service provider's data centre. With the latest innovations in AI efficiency, the proliferation of Internet of Things (IoT) devices, and the rise of edge computing, the potential of edge AI has now been unlocked. This study provides a thorough analysis of AI approaches and capabilities as they pertain to edge computing, or Edge AI. Further, a detailed survey of edge computing and its paradigms including transition to Edge AI is presented to explore the background of each variant proposed for implementing Edge Computing. Furthermore, we discussed the Edge AI approach to deploying AI algorithms and models on edge devices, which are typically resource-constrained devices located at the edge of the network. We also presented the technology used in various modern IoT applications, including autonomous vehicles, smart homes, industrial automation, healthcare, and surveillance. Moreover, the discussion of leveraging machine learning algorithms optimized for resource-constrained environments is presented. Finally, important open challenges and potential research directions in the field of edge computing and edge AI have been identified and investigated. We hope that this article will serve as a common goal for a future blueprint that will unite important stakeholders and facilitates to accelerate development in the field of Edge AI.",
        "DOI": "10.1016/j.iotcps.2023.02.004",
        "paper_author": "Singh R.",
        "affiliation_name": "University of Bath, Department of Computer Science",
        "affiliation_city": "Bath",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60171511",
        "affiliation_state": "Somerset"
    },
    {
        "paper_title": "A Comprehensive Review of Cyber Security Vulnerabilities, Threats, Attacks, and Solutions",
        "publication": "Electronics (Switzerland)",
        "citied_by": "183",
        "cover_date": "2023-03-01",
        "Abstract": "Internet usage has grown exponentially, with individuals and companies performing multiple daily transactions in cyberspace rather than in the real world. The coronavirus (COVID-19) pandemic has accelerated this process. As a result of the widespread usage of the digital environment, traditional crimes have also shifted to the digital space. Emerging technologies such as cloud computing, the Internet of Things (IoT), social media, wireless communication, and cryptocurrencies are raising security concerns in cyberspace. Recently, cyber criminals have started to use cyber attacks as a service to automate attacks and leverage their impact. Attackers exploit vulnerabilities that exist in hardware, software, and communication layers. Various types of cyber attacks include distributed denial of service (DDoS), phishing, man-in-the-middle, password, remote, privilege escalation, and malware. Due to new-generation attacks and evasion techniques, traditional protection systems such as firewalls, intrusion detection systems, antivirus software, access control lists, etc., are no longer effective in detecting these sophisticated attacks. Therefore, there is an urgent need to find innovative and more feasible solutions to prevent cyber attacks. The paper first extensively explains the main reasons for cyber attacks. Then, it reviews the most recent attacks, attack patterns, and detection techniques. Thirdly, the article discusses contemporary technical and nontechnical solutions for recognizing attacks in advance. Using trending technologies such as machine learning, deep learning, cloud platforms, big data, and blockchain can be a promising solution for current and future cyber attacks. These technological solutions may assist in detecting malware, intrusion detection, spam identification, DNS attack classification, fraud detection, recognizing hidden channels, and distinguishing advanced persistent threats. However, some promising solutions, especially machine learning and deep learning, are not resistant to evasion techniques, which must be considered when proposing solutions against intelligent cyber attacks.",
        "DOI": "10.3390/electronics12061333",
        "paper_author": "Aslan Ö.",
        "affiliation_name": "Bandırma Onyedi Eylül University",
        "affiliation_city": "Bandirma",
        "affiliation_country": "Turkey",
        "affiliation_id": "60197897",
        "affiliation_state": "Balikesir"
    },
    {
        "paper_title": "AI for life: Trends in artificial intelligence for biotechnology",
        "publication": "New Biotechnology",
        "citied_by": "177",
        "cover_date": "2023-05-25",
        "Abstract": "Due to popular successes (e.g., ChatGPT) Artificial Intelligence (AI) is on everyone's lips today. When advances in biotechnology are combined with advances in AI unprecedented new potential solutions become available. This can help with many global problems and contribute to important Sustainability Development Goals. Current examples include Food Security, Health and Well-being, Clean Water, Clean Energy, Responsible Consumption and Production, Climate Action, Life below Water, or protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss. AI is ubiquitous in the life sciences today. Topics include a wide range from machine learning and Big Data analytics, knowledge discovery and data mining, biomedical ontologies, knowledge-based reasoning, natural language processing, decision support and reasoning under uncertainty, temporal and spatial representation and inference, and methodological aspects of explainable AI (XAI) with applications of biotechnology. In this pre-Editorial paper, we provide an overview of open research issues and challenges for each of the topics addressed in this special issue. Potential authors can directly use this as a guideline for developing their paper.",
        "DOI": "10.1016/j.nbt.2023.02.001",
        "paper_author": "Holzinger A.",
        "affiliation_name": "BOKU University",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria",
        "affiliation_id": "60024895",
        "affiliation_state": "Vienna"
    },
    {
        "paper_title": "Internet of Things (IoT) Security Intelligence: A Comprehensive Overview, Machine Learning Solutions and Research Directions",
        "publication": "Mobile Networks and Applications",
        "citied_by": "177",
        "cover_date": "2023-02-01",
        "Abstract": "The Internet of Things (IoT) is one of the most widely used technologies today, and it has a significant effect on our lives in a variety of ways, including social, commercial, and economic aspects. In terms of automation, productivity, and comfort for consumers across a wide range of application areas, from education to smart cities, the present and future IoT technologies hold great promise for improving the overall quality of human life. However, cyber-attacks and threats greatly affect smart applications in the environment of IoT. The traditional IoT security techniques are insufficient with the recent security challenges considering the advanced booming of different kinds of attacks and threats. Utilizing artificial intelligence (AI) expertise, especially machine and deep learning solutions, is the key to delivering a dynamically enhanced and up-to-date security system for the next-generation IoT system. Throughout this article, we present a comprehensive picture on IoT security intelligence, which is built on machine and deep learning technologies that extract insights from raw data to intelligently protect IoT devices against a variety of cyber-attacks. Finally, based on our study, we highlight the associated research issues and future directions within the scope of our study. Overall, this article aspires to serve as a reference point and guide, particularly from a technical standpoint, for cybersecurity experts and researchers working in the context of IoT.",
        "DOI": "10.1007/s11036-022-01937-3",
        "paper_author": "Sarker I.H.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "A Review on Digital Twin Technology in Smart Grid, Transportation System and Smart City: Challenges and Future",
        "publication": "IEEE Access",
        "citied_by": "172",
        "cover_date": "2023-01-01",
        "Abstract": "With recent advances in information and communication technology (ICT), the bleeding edge concept of digital twin (DT) has enticed the attention of many researchers to revolutionize the entire modern industries. DT concept refers to a digital representation of a physical entity that is able to reflect its physical behavior by applying platforms and bidirectional interaction of data in real-time. The remarkable deployment of the internet of things in the power grid has led to reliable access to information that improves its performance and equips it with a powerful tool for real-time data management and analysis. This paper aims to trace the continuous investigation and propose practical ideas in originating and developing DT technology, according to various application domains of power systems, and also describes the proposed solutions to deal with the challenges associated with DT. Indeed, with the development of modern cities, different energy layers such as transportation systems, smart grids, and microgrids have emerged facing various issues that challenge the multi-dimensional energy management system. For example, in transportation systems, traffic is a major problem that requires real-time management, planning, and analysis. In power grids, remote data transfer within the grid and also various analyzes needing real data are just some of the current challenges in the field. These problems can be cracked by providing and analyzing a real twin framework in each section. All in all, this paper aims to survey different applications of DT in the development of the various aspects of energy management within a city including transportation systems, power grids, and microgrids. Besides, the security of DT technology based on ML is discussed. It also provides a complete view for the readers to be able to develop and deploy a DT technology for various power system applications.",
        "DOI": "10.1109/ACCESS.2023.3241588",
        "paper_author": "Jafari M.",
        "affiliation_name": "Shiraz University of Technology",
        "affiliation_city": "Shiraz",
        "affiliation_country": "Iran",
        "affiliation_id": "60072431",
        "affiliation_state": "Fars"
    },
    {
        "paper_title": "The fourth industrial revolution in the food industry—Part I: Industry 4.0 technologies",
        "publication": "Critical Reviews in Food Science and Nutrition",
        "citied_by": "171",
        "cover_date": "2023-01-01",
        "Abstract": "Climate change, the growth in world population, high levels of food waste and food loss, and the risk of new disease or pandemic outbreaks are examples of the many challenges that threaten future food sustainability and the security of the planet and urgently need to be addressed. The fourth industrial revolution, or Industry 4.0, has been gaining momentum since 2015, being a significant driver for sustainable development and a successful catalyst to tackle critical global challenges. This review paper summarizes the most relevant food Industry 4.0 technologies including, among others, digital technologies (e.g., artificial intelligence, big data analytics, Internet of Things, and blockchain) and other technological advances (e.g., smart sensors, robotics, digital twins, and cyber-physical systems). Moreover, insights into the new food trends (such as 3D printed foods) that have emerged as a result of the Industry 4.0 technological revolution will also be discussed in Part II of this work. The Industry 4.0 technologies have significantly modified the food industry and led to substantial consequences for the environment, economics, and human health. Despite the importance of each of the technologies mentioned above, ground-breaking sustainable solutions could only emerge by combining many technologies simultaneously. The Food Industry 4.0 era has been characterized by new challenges, opportunities, and trends that have reshaped current strategies and prospects for food production and consumption patterns, paving the way for the move toward Industry 5.0.",
        "DOI": "10.1080/10408398.2022.2034735",
        "paper_author": "Hassoun A.",
        "affiliation_name": "Sustainable AgriFoodtech Innovation &amp; Research (SAFIR)",
        "affiliation_city": "Arras",
        "affiliation_country": "France",
        "affiliation_id": "127686811",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Crude oil security in a turbulent world: China's geopolitical dilemmas and opportunities",
        "publication": "Extractive Industries and Society",
        "citied_by": "163",
        "cover_date": "2023-12-01",
        "Abstract": "China's economic and social development relies heavily on crude oil, which it imports and consumes more than any other country. Thus, the country's oil security is crucial. Geopolitical risk (GPR) is used to describe the instability and uncertainty resulting from political conflicts, terrorism, wars, sanctions, and other events that affect the production, transportation, and consumption of crude oil. Therefore, we use MF-VAR to examine how geopolitical risk GPR causes changes in Chinese crude oil security (COS). Unlike previous studies, we treat GPR as an outcome variable and use oil demand and cost channels to analyse its effects on COS. Quarterly government hazards endanger Chinese oil safety, and combined frequency data fixation reveals a dynamic link in various quarters of the year. Hence, to ensure a consistent supply of crude oil, the Chinese government's oil corporations must implement several initiatives, including purchasing shares and developing oil fields. To protect oil production and transportation, China should also forge strong links with nations that export oil and participate in UN initiatives such as the Somali escort and peacekeeping in Africa. To better manage oil price volatility brought on by geopolitical dilemmas, RMB-based crude oil futures are a smart approach for increasing affordability.",
        "DOI": "10.1016/j.exis.2023.101334",
        "paper_author": "Yuan H.",
        "affiliation_name": "Northwest University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60001298",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Blockchain-Based Federated Learning for Securing Internet of Things: A Comprehensive Survey",
        "publication": "ACM Computing Surveys",
        "citied_by": "163",
        "cover_date": "2023-09-30",
        "Abstract": "The Internet of Things (IoT) ecosystem connects physical devices to the internet, offering significant advantages in agility, responsiveness, and potential environmental benefits. The number and variety of IoT devices are sharply increasing, and as they do, they generate significant data sources. Deep learning (DL) algorithms are increasingly integrated into IoT applications to learn and infer patterns and make intelligent decisions. However, current IoT paradigms rely on centralized storage and computing to operate the DL algorithms. This key central component can potentially cause issues in scalability, security threats, and privacy breaches. Federated learning (FL) has emerged as a new paradigm for DL algorithms to preserve data privacy. Although FL helps reduce privacy leakage by avoiding transferring client data, it still has many challenges related to models' vulnerabilities and attacks. With the emergence of blockchain and smart contracts, the utilization of these technologies has the potential to safeguard FL across IoT ecosystems. This study aims to review blockchain-based FL methods for securing IoT systems holistically. It presents the current state of research in blockchain, how it can be applied to FL approaches, current IoT security issues, and responses to outline the need to use emerging approaches toward the security and privacy of IoT ecosystems. It also focuses on IoT data analytics from a security perspective and the open research questions. It also provides a thorough literature review of blockchain-based FL approaches for IoT applications. Finally, the challenges and risks associated with integrating blockchain and FL in IoT are discussed to be considered in future works.",
        "DOI": "10.1145/3560816",
        "paper_author": "Issa W.",
        "affiliation_name": "School of Engineering and Information Technology",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "100817880",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Privacy-preserving artificial intelligence in healthcare: Techniques and applications",
        "publication": "Computers in Biology and Medicine",
        "citied_by": "162",
        "cover_date": "2023-05-01",
        "Abstract": "There has been an increasing interest in translating artificial intelligence (AI) research into clinically-validated applications to improve the performance, capacity, and efficacy of healthcare services. Despite substantial research worldwide, very few AI-based applications have successfully made it to clinics. Key barriers to the widespread adoption of clinically validated AI applications include non-standardized medical records, limited availability of curated datasets, and stringent legal/ethical requirements to preserve patients’ privacy. Therefore, there is a pressing need to improvise new data-sharing methods in the age of AI that preserve patient privacy while developing AI-based healthcare applications. In the literature, significant attention has been devoted to developing privacy-preserving techniques and overcoming the issues hampering AI adoption in an actual clinical environment. To this end, this study summarizes the state-of-the-art approaches for preserving privacy in AI-based healthcare applications. Prominent privacy-preserving techniques such as Federated Learning and Hybrid Techniques are elaborated along with potential privacy attacks, security challenges, and future directions.",
        "DOI": "10.1016/j.compbiomed.2023.106848",
        "paper_author": "Khalid N.",
        "affiliation_name": "Information Technology University",
        "affiliation_city": "Lahore",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60105219",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A hybrid CNN + LSTMbased intrusion detection system for industrial IoT networks",
        "publication": "Engineering Science and Technology, an International Journal",
        "citied_by": "162",
        "cover_date": "2023-02-01",
        "Abstract": "The Internet of Things (IoT) ecosystem has proliferated based on the use of the internet and cloud-based technologies in the industrial area. IoT technology used in the industry has become a large-scale network based on the increasing amount of data and number of devices. Industrial IoT (IIoT) networks are intrinsically unprotected against cyber threats and intrusions. It is, therefore, significant to develop Intrusion Detection Systems (IDS) in order to ensure the security of the IIoT networks. Three different models were proposed to detect intrusions in the IIoT network by using deep learning architectures of Convolutional Neural Network (CNN), Long Short Term Memory (LSTM), and CNN + LSTM generated from a hybrid combination of these. In the study conducted by using the UNSW-NB15 and X-IIoTID datasets, normal and abnormal data were determined and compared with other studies in the literature following a binary and multi-class classification. The hybrid CNN + LSTM model attained the highest accuracy value for intrusion detection in both datasets among the proposed models. The proposed CNN + LSTM architecture attained an accuracy of 93.21% for binary classification and 92.9% for multi-class classification in the UNSW-NB15 dataset while the same model attained a detection accuracy of 99.84% for binary classification and 99.80% for multi-class classification in the X-IIoTID dataset. In addition, the accurate detection success of the implemented models regarding the types of attacks within the datasets was evaluated.",
        "DOI": "10.1016/j.jestch.2022.101322",
        "paper_author": "Altunay H.C.",
        "affiliation_name": "Ondokuz Mayis Üniversitesi",
        "affiliation_city": "Samsun",
        "affiliation_country": "Türkiye",
        "affiliation_id": "60009477",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence for cybersecurity: Literature review and future research directions",
        "publication": "Information Fusion",
        "citied_by": "157",
        "cover_date": "2023-09-01",
        "Abstract": "Artificial intelligence (AI) is a powerful technology that helps cybersecurity teams automate repetitive tasks, accelerate threat detection and response, and improve the accuracy of their actions to strengthen the security posture against various security issues and cyberattacks. This article presents a systematic literature review and a detailed analysis of AI use cases for cybersecurity provisioning. The review resulted in 2395 studies, of which 236 were identified as primary. This article classifies the identified AI use cases based on a NIST cybersecurity framework using a thematic analysis approach. This classification framework will provide readers with a comprehensive overview of the potential of AI to improve cybersecurity in different contexts. The review also identifies future research opportunities in emerging cybersecurity application areas, advanced AI methods, data representation, and the development of new infrastructures for the successful adoption of AI-based cybersecurity in today's era of digital transformation and polycrisis.",
        "DOI": "10.1016/j.inffus.2023.101804",
        "paper_author": "Kaur R.",
        "affiliation_name": "Institut \"Jožef Stefan\"",
        "affiliation_city": "Ljubljana",
        "affiliation_country": "Slovenia",
        "affiliation_id": "60023955",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Decentralized Federated Learning: Fundamentals, State of the Art, Frameworks, Trends, and Challenges",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "156",
        "cover_date": "2023-01-01",
        "Abstract": "In recent years, Federated Learning (FL) has gained relevance in training collaborative models without sharing sensitive data. Since its birth, Centralized FL (CFL) has been the most common approach in the literature, where a central entity creates a global model. However, a centralized approach leads to increased latency due to bottlenecks, heightened vulnerability to system failures, and trustworthiness concerns affecting the entity responsible for the global model creation. Decentralized Federated Learning (DFL) emerged to address these concerns by promoting decentralized model aggregation and minimizing reliance on centralized architectures. However, despite the work done in DFL, the literature has not (i) studied the main aspects differentiating DFL and CFL; (ii) analyzed DFL frameworks to create and evaluate new solutions; and (iii) reviewed application scenarios using DFL. Thus, this article identifies and analyzes the main fundamentals of DFL in terms of federation architectures, topologies, communication mechanisms, security approaches, and key performance indicators. Additionally, the paper at hand explores existing mechanisms to optimize critical DFL fundamentals. Then, the most relevant features of the current DFL frameworks are reviewed and compared. After that, it analyzes the most used DFL application scenarios, identifying solutions based on the fundamentals and frameworks previously defined. Finally, the evolution of existing DFL solutions is studied to provide a list of trends, lessons learned, and open challenges.",
        "DOI": "10.1109/COMST.2023.3315746",
        "paper_author": "Martinez Beltran E.T.",
        "affiliation_name": "Universidad de Murcia",
        "affiliation_city": "Murcia",
        "affiliation_country": "Spain",
        "affiliation_id": "60000130",
        "affiliation_state": "Murcia"
    },
    {
        "paper_title": "Integration of Healthcare 4.0 and blockchain into secure cloud-based electronic health records systems",
        "publication": "Applied Nanoscience (Switzerland)",
        "citied_by": "156",
        "cover_date": "2023-03-01",
        "Abstract": "Since the last decade, cloud-based electronic health records (EHRs) have gained significant attention to enable remote patient monitoring. The recent development of Healthcare 4.0 using the Internet of Things (IoT) components and cloud computing to access medical operations remotely has gained the researcher's attention from a smart city perspective. Healthcare 4.0 mainly consisted of periodic medical data sensing, aggregation, data transmission, data sharing, and data storage. The sensitive and personal data of patients lead to several challenges while protecting it from hackers. Therefore storing, accessing, and sharing the patient medical information on the cloud needs security attention that data should not be compromised by the authorized user's components of E-healthcare systems. To achieve secure medical data storage, sharing, and accessing in cloud service provider, several cryptography algorithms are designed so far. However, such conventional solutions failed to achieve the trade-off between the requirements of EHR security solutions such as computational efficiency, service side verification, user side verifications, without the trusted third party, and strong security. Blockchain-based security solutions gained significant attention in the recent past due to the ability to provide strong security for data storage and sharing with the minimum computation efforts. The blockchain made focused on bitcoin technology among the researchers. Utilizing the blockchain which secure healthcare records management has been of recent interest. This paper presents the systematic study of modern blockchain-based solutions for securing medical data with or without cloud computing. We implement and evaluate the different methods using blockchain in this paper. According to the research studies, the research gaps, challenges, and future roadmap are the outcomes of this paper that boost emerging Healthcare 4.0 technology.",
        "DOI": "10.1007/s13204-021-02164-0",
        "paper_author": "Mahajan H.B.",
        "affiliation_name": "Godwit Technologies",
        "affiliation_city": "Pune",
        "affiliation_country": "India",
        "affiliation_id": "127612829",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Ethics and governance of trustworthy medical artificial intelligence",
        "publication": "BMC Medical Informatics and Decision Making",
        "citied_by": "153",
        "cover_date": "2023-12-01",
        "Abstract": "Background: The growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring. Methods: We adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects. Results: Medical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can affect AI clinical predictions and exacerbate health disparities. The opacity of algorithms affects patients’ and doctors’ trust in medical AI, and algorithmic errors or security vulnerabilities can pose significant risks and harm to patients. The involvement of medical AI in clinical practices may threaten doctors ‘and patients’ autonomy and dignity. When accidents occur with medical AI, the responsibility attribution is not clear. All these factors affect people’s trust in medical AI. Conclusions: In order to make medical AI trustworthy, at the ethical level, the ethical value orientation of promoting human health should first and foremost be considered as the top-level design. At the legal level, current medical AI does not have moral status and humans remain the duty bearers. At the regulatory level, strengthening data quality management, improving algorithm transparency and traceability to reduce algorithm bias, and regulating and reviewing the whole process of the AI industry to control risks are proposed. It is also necessary to encourage multiple parties to discuss and assess AI risks and social impacts, and to strengthen international cooperation and communication.",
        "DOI": "10.1186/s12911-023-02103-9",
        "paper_author": "Zhang J.",
        "affiliation_name": "Nanjing University of Chinese Medicine",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60005189",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Security and Privacy in Metaverse: A Comprehensive Survey",
        "publication": "Big Data Mining and Analytics",
        "citied_by": "152",
        "cover_date": "2023-06-01",
        "Abstract": "Metaverse describes a new shape of cyberspace and has become a hot-trending word since 2021. There are many explanations about what Meterverse is and attempts to provide a formal standard or definition of Metaverse. However, these definitions could hardly reach universal acceptance. Rather than providing a formal definition of the Metaverse, we list four must-have characteristics of the Metaverse: socialization, immersive interaction, real world-building, and expandability. These characteristics not only carve the Metaverse into a novel and fantastic digital world, but also make it suffer from all security/privacy risks, such as personal information leakage, eavesdropping, unauthorized access, phishing, data injection, broken authentication, insecure design, and more. This paper first introduces the four characteristics, then the current progress and typical applications of the Metaverse are surveyed and categorized into four economic sectors. Based on the four characteristics and the findings of the current progress, the security and privacy issues in the Metaverse are investigated. We then identify and discuss more potential critical security and privacy issues that can be caused by combining the four characteristics. Lastly, the paper also raises some other concerns regarding society and humanity.",
        "DOI": "10.26599/BDMA.2022.9020047",
        "paper_author": "Huang Y.",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States",
        "affiliation_id": "60019740",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Adversarial Machine Learning for Network Intrusion Detection Systems: A Comprehensive Survey",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "152",
        "cover_date": "2023-01-01",
        "Abstract": "Network-based Intrusion Detection System (NIDS) forms the frontline defence against network attacks that compromise the security of the data, systems, and networks. In recent years, Deep Neural Networks (DNNs) have been increasingly used in NIDS to detect malicious traffic due to their high detection accuracy. However, DNNs are vulnerable to adversarial attacks that modify an input example with imperceivable perturbation, which causes a misclassification by the DNN. In security-sensitive domains, such as NIDS, adversarial attacks pose a severe threat to network security. However, existing studies in adversarial learning against NIDS directly implement adversarial attacks designed for Computer Vision (CV) tasks, ignoring the fundamental differences in the detection pipeline and feature spaces between CV and NIDS. It remains a major research challenge to launch and detect adversarial attacks against NIDS. This article surveys the recent literature on NIDS, adversarial attacks, and network defences since 2015 to examine the differences in adversarial learning against deep neural networks in CV and NIDS. It provides the reader with a thorough understanding of DL-based NIDS, adversarial attacks and defences, and research trends in this field. We first present a taxonomy of DL-based NIDS and discuss the impact of taxonomy on adversarial learning. Next, we review existing white-box and black-box adversarial attacks on DNNs and their applicability in the NIDS domain. Finally, we review existing defence mechanisms against adversarial examples and their characteristics.",
        "DOI": "10.1109/COMST.2022.3233793",
        "paper_author": "He K.",
        "affiliation_name": "The University of Auckland",
        "affiliation_city": "Auckland",
        "affiliation_country": "New Zealand",
        "affiliation_id": "60005686",
        "affiliation_state": "AUK"
    },
    {
        "paper_title": "Photo-triggered full-color circularly polarized luminescence based on photonic capsules for multilevel information encryption",
        "publication": "Nature Communications",
        "citied_by": "148",
        "cover_date": "2023-12-01",
        "Abstract": "Materials with phototunable full-color circularly polarized luminescence (CPL) have a large storage density, high-security level, and enormous prospects in the field of information encryption and decryption. In this work, device-friendly solid films with color tunability are prepared by constructing Förster resonance energy transfer (FRET) platforms with chiral donors and achiral molecular switches in liquid crystal photonic capsules (LCPCs). These LCPCs exhibit photoswitchable CPL from initial blue emission to RGB trichromatic signals under UV irradiation due to the synergistic effect of energy and chirality transfer and show strong time dependence because of the different FRET efficiencies at each time node. Based on these phototunable CPL and time response characteristics, the concept of multilevel data encryption by using LCPC films is demonstrated.",
        "DOI": "10.1038/s41467-023-38801-1",
        "paper_author": "Lin S.",
        "affiliation_name": "Beijing University of Chemical Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60021843",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Fusion of statistical importance for feature selection in Deep Neural Network-based Intrusion Detection System",
        "publication": "Information Fusion",
        "citied_by": "148",
        "cover_date": "2023-02-01",
        "Abstract": "Intrusion Detection System (IDS) is an essential part of network as it contributes towards securing the network against various vulnerabilities and threats. Over the past decades, there has been comprehensive study in the field of IDS and various approaches have been developed to design intrusion detection and classification system. With the proliferation in the usage of Deep Learning (DL) techniques and their ability to learn data extensively, we aim to design Deep Neural Network (DNN)-based IDS. In this study, we aim to focus on enhancing the performance of DNN-based IDS by proposing a novel feature selection technique that selects features via fusion of statistical importance using Standard Deviation and Difference of Mean and Median. Here, in the proposed approach, features are pruned based on their rank derived using fusion of statistical importance. Moreover, fusion of statistical importance aims to derive relevant features that possess high discernibility and deviation, that assists in better learning of data. The performance of the proposed approach is evaluated using three intrusion detection datasets, namely, NSL-KDD, UNSW_NB-15, and CIC-IDS-2017. Performance analysis is presented in terms of different evaluation metrics such as accuracy, precision, recall, f-score, and False Positive Rate (FPR) and the results are compared with existing feature selection techniques. Apart from evaluation metrics, performance comparison is also presented in terms of execution time. Moreover, results achieved are also statistically tested using Wilcoxon Signed Rank test.",
        "DOI": "10.1016/j.inffus.2022.09.026",
        "paper_author": "Thakkar A.",
        "affiliation_name": "Nirma University, Institute of Technology",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India",
        "affiliation_id": "60115002",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Drawbacks of Artificial Intelligence and Their Potential Solutions in the Healthcare Sector",
        "publication": "Biomedical Materials and Devices",
        "citied_by": "147",
        "cover_date": "2023-09-01",
        "Abstract": "Artificial intelligence (AI) has the potential to make substantial progress toward the goal of making healthcare more personalized, predictive, preventative, and interactive. We believe AI will continue its present path and ultimately become a mature and effective tool for the healthcare sector. Besides this AI-based systems raise concerns regarding data security and privacy. Because health records are important and vulnerable, hackers often target them during data breaches. The absence of standard guidelines for the moral use of AI and ML in healthcare has only served to worsen the situation. There is debate about how far artificial intelligence (AI) may be utilized ethically in healthcare settings since there are no universal guidelines for its use. Therefore, maintaining the confidentiality of medical records is crucial. This study enlightens the possible drawbacks of AI in the implementation of healthcare sector and their solutions to overcome these situations. Graphical Abstract: (Figure presented.)",
        "DOI": "10.1007/s44174-023-00063-2",
        "paper_author": "khan B.",
        "affiliation_name": "Hong Kong Centre for Cerebro-Caradiovasular Health Engineering (COCHE)",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "128018953",
        "affiliation_state": "Hong Kong"
    },
    {
        "paper_title": "Privacy Protection of Medical Data Based on Multi-Scroll Memristive Hopfield Neural Network",
        "publication": "IEEE Transactions on Network Science and Engineering",
        "citied_by": "147",
        "cover_date": "2023-03-01",
        "Abstract": "Memristive Hopfield neural network (MHNN) has complex dynamic behavior, which is suitable for encryption applications. In order to ensure the information security of the medical data transmitted in Internet of Things (IoT), we propose three new MHNN models by using a non-ideal flux-controlled memristor model with multi-piecewise nonlinearity. In these models, there are complex dynamical behaviors such as coexisting attractors, multi-scroll attractors and grid multi-scroll attractors. In terms of hardware, the proposed model is implemented using field programmable gate array (FPGA). In addition, we provide a complete set of medical data sharing solution, which are helpful for the referral patients to receive timely medical treatment. The whole solution is successfully verified on Raspberry Pi, the encrypted Computed Tomography (CT) image is transmitted safely under Message Queuing Telemetry Transport (MQTT) protocol, and the CT image is subjected to basic security analysis. The results show that the ciphertext histogram is evenly distributed, the correlation between adjacent pixels is almost 0, the information entropy reaches 7.9977, and the values of number of pixels change rate (NPCR) and unified average change intensity (UACI) are 99.6078% and 33.4875%. The solution not only performs the exchange of medical data, but also protects the privacy of patients.",
        "DOI": "10.1109/TNSE.2022.3223930",
        "paper_author": "Yu F.",
        "affiliation_name": "Changsha University of Science and Technology",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60001338",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "A Review on Unmanned Aerial Vehicle Remote Sensing: Platforms, Sensors, Data Processing Methods, and Applications",
        "publication": "Drones",
        "citied_by": "146",
        "cover_date": "2023-06-01",
        "Abstract": "In recent years, UAV remote sensing has gradually attracted the attention of scientific researchers and industry, due to its broad application prospects. It has been widely used in agriculture, forestry, mining, and other industries. UAVs can be flexibly equipped with various sensors, such as optical, infrared, and LIDAR, and become an essential remote sensing observation platform. Based on UAV remote sensing, researchers can obtain many high-resolution images, with each pixel being a centimeter or millimeter. The purpose of this paper is to investigate the current applications of UAV remote sensing, as well as the aircraft platforms, data types, and elements used in each application category; the data processing methods, etc.; and to study the advantages of the current application of UAV remote sensing technology, the limitations, and promising directions that still lack applications. By reviewing the papers published in this field in recent years, we found that the current application research of UAV remote sensing research can be classified into four categories according to the application field: (1) Precision agriculture, including crop disease observation, crop yield estimation, and crop environmental observation; (2) Forestry remote sensing, including forest disease identification, forest disaster observation, etc.; (3) Remote sensing of power systems; (4) Artificial facilities and the natural environment. We found that in the papers published in recent years, image data (RGB, multi-spectral, hyper-spectral) processing mainly used neural network methods; in crop disease monitoring, multi-spectral data are the most studied type of data; for LIDAR data, current applications still lack an end-to-end neural network processing method; this review examines UAV platforms, sensors, and data processing methods, and according to the development process of certain application fields and current implementation limitations, some predictions are made about possible future development directions.",
        "DOI": "10.3390/drones7060398",
        "paper_author": "Zhang Z.",
        "affiliation_name": "Zhongkai University of Agriculture and Engineering",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60082183",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "A dependable hybrid machine learning model for network intrusion detection",
        "publication": "Journal of Information Security and Applications",
        "citied_by": "144",
        "cover_date": "2023-02-01",
        "Abstract": "Network intrusion detection systems (NIDSs) play an important role in computer network security. There are several detection mechanisms where anomaly-based automated detection outperforms others significantly. Amid the sophistication and growing number of attacks, dealing with large amounts of data is a recognized issue in the development of anomaly-based NIDS. However, do current models meet the needs of today's networks in terms of required accuracy and dependability? In this research, we propose a new hybrid model that combines machine learning and deep learning to increase detection rates while securing dependability. Our proposed method ensures efficient pre-processing by combining SMOTE for data balancing and XGBoost for feature selection. We compared our developed method to various machine learning and deep learning algorithms in order to find a more efficient algorithm to implement in the pipeline. Furthermore, we chose the most effective model for network intrusion based on a set of benchmarked performance analysis criteria. Our method produces excellent results when tested on two datasets, KDDCUP’99 and CIC-MalMem-2022, with an accuracy of 99.99% and 100% for KDDCUP’99 and CIC-MalMem-2022, respectively, and no overfitting or Type-1 and Type-2 issues.",
        "DOI": "10.1016/j.jisa.2022.103405",
        "paper_author": "Talukder M.A.",
        "affiliation_name": "Jagannath University, Bangladesh",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60111554",
        "affiliation_state": "Dhaka"
    },
    {
        "paper_title": "The impact of ChatGPT on higher education",
        "publication": "Frontiers in Education",
        "citied_by": "141",
        "cover_date": "2023-01-01",
        "Abstract": "Introduction: This study explores the effects of Artificial Intelligence (AI) chatbots, with a particular focus on OpenAI’s ChatGPT, on Higher Education Institutions (HEIs). With the rapid advancement of AI, understanding its implications in the educational sector becomes paramount. Methods: Utilizing databases like PubMed, IEEE Xplore, and Google Scholar, we systematically searched for literature on AI chatbots’ impact on HEIs. Our criteria prioritized peer-reviewed articles, prominent media outlets, and English publications, excluding tangential AI chatbot mentions. After selection, data extraction focused on authors, study design, and primary findings. The analysis combined descriptive and thematic approaches, emphasizing patterns and applications of AI chatbots in HEIs. Results: The literature review revealed diverse perspectives on ChatGPT’s potential in education. Notable benefits include research support, automated grading, and enhanced human-computer interaction. However, concerns such as online testing security, plagiarism, and broader societal and economic impacts like job displacement, the digital literacy gap, and AI-induced anxiety were identified. The study also underscored the transformative architecture of ChatGPT and its versatile applications in the educational sector. Furthermore, potential advantages like streamlined enrollment, improved student services, teaching enhancements, research aid, and increased student retention were highlighted. Conversely, risks such as privacy breaches, misuse, bias, misinformation, decreased human interaction, and accessibility issues were identified. Discussion: While AI’s global expansion is undeniable, there is a pressing need for balanced regulation in its application within HEIs. Faculty members are encouraged to utilize AI tools like ChatGPT proactively and ethically to mitigate risks, especially academic fraud. Despite the study’s limitations, including an incomplete representation of AI’s overall effect on education and the absence of concrete integration guidelines, it is evident that AI technologies like ChatGPT present both significant benefits and risks. The study advocates for a thoughtful and responsible integration of such technologies within HEIs.",
        "DOI": "10.3389/feduc.2023.1206936",
        "paper_author": "Dempere J.",
        "affiliation_name": "HCT-Ras Al Khaimah Campus",
        "affiliation_city": "Ras al Khaimah",
        "affiliation_country": "United Arab Emirates",
        "affiliation_id": "60281802",
        "affiliation_state": "Ras Al Khaimah"
    },
    {
        "paper_title": "Machine Learning Methods for Small Data Challenges in Molecular Science",
        "publication": "Chemical Reviews",
        "citied_by": "141",
        "cover_date": "2023-07-12",
        "Abstract": "Small data are often used in scientific and engineering research due to the presence of various constraints, such as time, cost, ethics, privacy, security, and technical limitations in data acquisition. However, big data have been the focus for the past decade, small data and their challenges have received little attention, even though they are technically more severe in machine learning (ML) and deep learning (DL) studies. Overall, the small data challenge is often compounded by issues, such as data diversity, imputation, noise, imbalance, and high-dimensionality. Fortunately, the current big data era is characterized by technological breakthroughs in ML, DL, and artificial intelligence (AI), which enable data-driven scientific discovery, and many advanced ML and DL technologies developed for big data have inadvertently provided solutions for small data problems. As a result, significant progress has been made in ML and DL for small data challenges in the past decade. In this review, we summarize and analyze several emerging potential solutions to small data challenges in molecular science, including chemical and biological sciences. We review both basic machine learning algorithms, such as linear regression, logistic regression (LR), k-nearest neighbor (KNN), support vector machine (SVM), kernel learning (KL), random forest (RF), and gradient boosting trees (GBT), and more advanced techniques, including artificial neural network (ANN), convolutional neural network (CNN), U-Net, graph neural network (GNN), Generative Adversarial Network (GAN), long short-term memory (LSTM), autoencoder, transformer, transfer learning, active learning, graph-based semi-supervised learning, combining deep learning with traditional machine learning, and physical model-based data augmentation. We also briefly discuss the latest advances in these methods. Finally, we conclude the survey with a discussion of promising trends in small data challenges in molecular science.",
        "DOI": "10.1021/acs.chemrev.3c00189",
        "paper_author": "Dou B.",
        "affiliation_name": "Wuhan Textile University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60104662",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Smart Transportation: An Overview of Technologies and Applications",
        "publication": "Sensors",
        "citied_by": "141",
        "cover_date": "2023-04-01",
        "Abstract": "As technology continues to evolve, our society is becoming enriched with more intelligent devices that help us perform our daily activities more efficiently and effectively. One of the most significant technological advancements of our time is the Internet of Things (IoT), which interconnects various smart devices (such as smart mobiles, intelligent refrigerators, smartwatches, smart fire alarms, smart door locks, and many more) allowing them to communicate with each other and exchange data seamlessly. We now use IoT technology to carry out our daily activities, for example, transportation. In particular, the field of smart transportation has intrigued researchers due to its potential to revolutionize the way we move people and goods. IoT provides drivers in a smart city with many benefits, including traffic management, improved logistics, efficient parking systems, and enhanced safety measures. Smart transportation is the integration of all these benefits into applications for transportation systems. However, as a way of further improving the benefits provided by smart transportation, other technologies have been explored, such as machine learning, big data, and distributed ledgers. Some examples of their application are the optimization of routes, parking, street lighting, accident prevention, detection of abnormal traffic conditions, and maintenance of roads. In this paper, we aim to provide a detailed understanding of the developments in the applications mentioned earlier and examine current researches that base their applications on these sectors. We aim to conduct a self-contained review of the different technologies used in smart transportation today and their respective challenges. Our methodology encompassed identifying and screening articles on smart transportation technologies and its applications. To identify articles addressing our topic of review, we searched for articles in the four significant databases: IEEE Xplore, ACM Digital Library, Science Direct, and Springer. Consequently, we examined the communication mechanisms, architectures, and frameworks that enable these smart transportation applications and systems. We also explored the communication protocols enabling smart transportation, including Wi-Fi, Bluetooth, and cellular networks, and how they contribute to seamless data exchange. We delved into the different architectures and frameworks used in smart transportation, including cloud computing, edge computing, and fog computing. Lastly, we outlined current challenges in the smart transportation field and suggested potential future research directions. We will examine data privacy and security issues, network scalability, and interoperability between different IoT devices.",
        "DOI": "10.3390/s23083880",
        "paper_author": "Oladimeji D.",
        "affiliation_name": "Sam Houston State University",
        "affiliation_city": "Huntsville",
        "affiliation_country": "United States",
        "affiliation_id": "60025157",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Distributed Artificial Intelligence Empowered by End-Edge-Cloud Computing: A Survey",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "140",
        "cover_date": "2023-01-01",
        "Abstract": "As the computing paradigm shifts from cloud computing to end-edge-cloud computing, it also supports artificial intelligence evolving from a centralized manner to a distributed one. In this paper, we provide a comprehensive survey on the distributed artificial intelligence (DAI) empowered by end-edge-cloud computing (EECC), where the heterogeneous capabilities of on-device computing, edge computing, and cloud computing are orchestrated to satisfy the diverse requirements raised by resource-intensive and distributed AI computation. Particularly, we first introduce several mainstream computing paradigms and the benefits of the EECC paradigm in supporting distributed AI, as well as the fundamental technologies for distributed AI. We then derive a holistic taxonomy for the state-of-the-art optimization technologies that are empowered by EECC to boost distributed training and inference, respectively. After that, we point out security and privacy threats in DAI-EECC architecture and review the benefits and shortcomings of each enabling defense technology in accordance with the threats. Finally, we present some promising applications enabled by DAI-EECC and highlight several research challenges and open issues toward immersive performance acquisition.",
        "DOI": "10.1109/COMST.2022.3218527",
        "paper_author": "Duan S.",
        "affiliation_name": "Central South University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60017060",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection",
        "publication": "IEEE Transactions on Knowledge and Data Engineering",
        "citied_by": "138",
        "cover_date": "2023-02-01",
        "Abstract": "Smart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. More importantly, expert-defined rules tend to be error-prone and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks. In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a contract graph. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches 89.15, 89.02, and 83.21 percent for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively.",
        "DOI": "10.1109/TKDE.2021.3095196",
        "paper_author": "Liu Z.",
        "affiliation_name": "Zhejiang Gongshang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60012581",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "A global federated real-world data and analytics platform for research",
        "publication": "JAMIA Open",
        "citied_by": "137",
        "cover_date": "2023-07-01",
        "Abstract": "Objective: This article describes a scalable, performant, sustainable global network of electronic health record data for biomedical and clinical research. Materials and Methods: TriNetX has created a technology platform characterized by a conservative security and governance model that facilitates collaboration and cooperation between industry participants, such as pharmaceutical companies and contract research organizations, and academic and community-based healthcare organizations (HCOs). HCOs participate on the network in return for access to a suite of analytics capabilities, large networks of de-identified data, and more sponsored trial opportunities. Industry participants provide the financial resources to support, expand, and improve the technology platform in return for access to network data, which provides increased efficiencies in clinical trial design and deployment. Results: TriNetX is a growing global network, expanding from 55 HCOs and 7 countries in 2017 to over 220 HCOs and 30 countries in 2022. Over 19 000 sponsored clinical trial opportunities have been initiated through the TriNetX network. There have been over 350 peer-reviewed scientific publications based on the network’s data. Conclusions: The continued growth of the TriNetX network and its yield of clinical trial collaborations and published studies indicates that this academic-industry structure is a safe, proven, sustainable path for building and maintaining research-centric data networks.",
        "DOI": "10.1093/jamiaopen/ooad035",
        "paper_author": "Palchuk M.B.",
        "affiliation_name": "LLC",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "127777640",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Federated learning-based AI approaches in smart healthcare: concepts, taxonomies, challenges and open issues",
        "publication": "Cluster Computing",
        "citied_by": "137",
        "cover_date": "2023-08-01",
        "Abstract": "Federated Learning (FL), Artificial Intelligence (AI), and Explainable Artificial Intelligence (XAI) are the most trending and exciting technology in the intelligent healthcare field. Traditionally, the healthcare system works based on centralized agents sharing their raw data. Therefore, huge vulnerabilities and challenges are still existing in this system. However, integrating with AI, the system would be multiple agent collaborators who are capable of communicating with their desired host efficiently. Again, FL is another interesting feature, which works decentralized manner; it maintains the communication based on a model in the preferred system without transferring the raw data. The combination of FL, AI, and XAI techniques can be capable of minimizing several limitations and challenges in the healthcare system. This paper presents a complete analysis of FL using AI for smart healthcare applications. Initially, we discuss contemporary concepts of emerging technologies such as FL, AI, XAI, and the healthcare system. We integrate and classify the FL-AI with healthcare technologies in different domains. Further, we address the existing problems, including security, privacy, stability, and reliability in the healthcare field. In addition, we guide the readers to solving strategies of healthcare using FL and AI. Finally, we address extensive research areas as well as future potential prospects regarding FL-based AI research in the healthcare management system.",
        "DOI": "10.1007/s10586-022-03658-4",
        "paper_author": "Rahman A.",
        "affiliation_name": "National Institute of Textile Engineering and Research (NITER), University of Dhaka",
        "affiliation_city": "Savar",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60279451",
        "affiliation_state": "Dhaka"
    },
    {
        "paper_title": "Ageing threatens sustainability of smallholder farming in China",
        "publication": "Nature",
        "citied_by": "136",
        "cover_date": "2023-04-06",
        "Abstract": "Rapid demographic ageing substantially affects socioeconomic development1–4 and presents considerable challenges for food security and agricultural sustainability5–8, which have so far not been well understood. Here, by using data from more than 15,000 rural households with crops but no livestock across China, we show that rural population ageing reduced farm size by 4% through transferring cropland ownership and land abandonment (approximately 4 million hectares) in 2019, taking the population age structure in 1990 as a benchmark. These changes led to a reduction of agricultural inputs, including chemical fertilizers, manure and machinery, which decreased agricultural output and labour productivity by 5% and 4%, respectively, further lowering farmers’ income by 15%. Meanwhile, fertilizer loss increased by 3%, resulting in higher pollutant emissions to the environment. In new farming models, such as cooperative farming, farms tend to be larger and operated by younger farmers, who have a higher average education level, hence improving agricultural management. By encouraging the transition to new farming models, the negative consequences of ageing can be reversed. Agricultural input, farm size and farmer’s income would grow by approximately 14%, 20% and 26%, respectively, and fertilizer loss would reduce by 4% in 2100 compared with that in 2020. This suggests that management of rural ageing will contribute to a comprehensive transformation of smallholder farming to sustainable agriculture in China.",
        "DOI": "10.1038/s41586-023-05738-w",
        "paper_author": "Ren C.",
        "affiliation_name": "College of Environmental and Resource Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117779",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Blockchain Technology: Security Issues, Healthcare Applications, Challenges and Future Trends",
        "publication": "Electronics (Switzerland)",
        "citied_by": "136",
        "cover_date": "2023-02-01",
        "Abstract": "Blockchain technology provides a data structure with inherent security properties that include cryptography, decentralization, and consensus, which ensure trust in transactions. It covers widely applicable usages, such as in intelligent manufacturing, finance, the Internet of things (IoT), medicine and health, and many different areas, especially in medical health data security and privacy protection areas. Its natural attributes, such as contracts and consensus mechanisms, have leading-edge advantages in protecting data confidentiality, integrity, and availability. The security issues are gradually revealed with in-depth research and vigorous development. Unlike traditional paper storage methods, modern medical records are stored electronically. Blockchain technology provided a decentralized solution to the trust-less issues between distrusting parties without third-party guarantees, but the “trust-less” security through technology was easily misunderstood and hindered the security differences between public and private blockchains appropriately. The mentioned advantages and disadvantages motivated us to provide an advancement and comprehensive study regarding the applicability of blockchain technology. This paper focuses on the healthcare security issues in blockchain and sorts out the security risks in six layers of blockchain technology by comparing and analyzing existing security measures. It also explores and defines the different security attacks and challenges when applying blockchain technology, which promotes theoretical research and robust security protocol development in the current and future distributed work environment.",
        "DOI": "10.3390/electronics12030546",
        "paper_author": "Wenhua Z.",
        "affiliation_name": "Universiti Kebangsaan Malaysia",
        "affiliation_city": "Bangi",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60001821",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Homomorphic Encryption-Based Privacy-Preserving Federated Learning in IoT-Enabled Healthcare System",
        "publication": "IEEE Transactions on Network Science and Engineering",
        "citied_by": "136",
        "cover_date": "2023-09-01",
        "Abstract": "In this work, the federated learning mechanism is introduced into the deep learning of medical models in Internet of Things (IoT)-based healthcare system. Cryptographic primitives, including masks and homomorphic encryption, are applied for further protecting local models, so as to prevent the adversary from inferring private medical data by various attacks such as model reconstruction attack or model inversion attack, etc. The qualities of the datasets owned by different participants are considered as the main factor for measuring the contribution rate of the local model to the global model in each training epoch, instead of the size of datasets commonly used in deep learning. A dropout-tolerable scheme is proposed in which the process of federated learning would not be terminated if the number of online clients is not less than a preset threshold. Through the analysis of the security, it shows that the proposed scheme satisfies data privacy. Computation cost and communication cost are also analyzed theoretically. Finally, skin lesion classification using training images provided by the HAM10000 medical dataset is set as an example of healthcare applications. Experimental results show that compared with existing schemes, the proposed scheme obtained promising results while ensuring privacy preserving.",
        "DOI": "10.1109/TNSE.2022.3185327",
        "paper_author": "Zhang L.",
        "affiliation_name": "Hunan University of Science and Technology",
        "affiliation_city": "Xiangtan",
        "affiliation_country": "China",
        "affiliation_id": "60024617",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",
        "publication": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citied_by": "134",
        "cover_date": "2023-02-01",
        "Abstract": "As machine learning systems grow in scale, so do their training data requirements, forcing practitioners to automate and outsource the curation of training data in order to achieve state-of-the-art performance. The absence of trustworthy human supervision over the data collection process exposes organizations to security vulnerabilities; training data can be manipulated to control and degrade the downstream behaviors of learned models. The goal of this work is to systematically categorize and discuss a wide range of dataset vulnerabilities and exploits, approaches for defending against these threats, and an array of open problems in this space.",
        "DOI": "10.1109/TPAMI.2022.3162397",
        "paper_author": "Goldblum M.",
        "affiliation_name": "University of Maryland, College Park",
        "affiliation_city": "College Park",
        "affiliation_country": "United States",
        "affiliation_id": "60020304",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "A blockchain-orchestrated deep learning approach for secure data transmission in IoT-enabled healthcare system",
        "publication": "Journal of Parallel and Distributed Computing",
        "citied_by": "133",
        "cover_date": "2023-02-01",
        "Abstract": "The integration of the Internet of Things (IoT) with traditional healthcare systems has improved quality of healthcare services. However, the wearable devices and sensors used in Healthcare System (HS) continuously monitor and transmit data to the nearby devices or servers using an unsecured open channel. This connectivity between IoT devices and servers improves operational efficiency, but it also gives a lot of room for attackers to launch various cyber-attacks that can put patients under critical surveillance in jeopardy. In this article, a Blockchain-orchestrated Deep learning approach for Secure Data Transmission in IoT-enabled healthcare system hereafter referred to as “BDSDT” is designed. Specifically, first a novel scalable blockchain architecture is proposed to ensure data integrity and secure data transmission by leveraging Zero Knowledge Proof (ZKP) mechanism. Then, BDSDT integrates with the off-chain storage InterPlanetary File System (IPFS) to address difficulties with data storage costs and with an Ethereum smart contract to address data security issues. The authenticated data is further used to design a deep learning architecture to detect intrusion in HS network. The latter combines Deep Sparse AutoEncoder (DSAE) with Bidirectional Long Short-Term Memory (BiLSTM) to design an effective intrusion detection system. Experiments on two public data sources (CICIDS-2017 and ToN-IoT) reveal that the proposed BDSDT outperformed state-of-the-arts in both non-blockchain and blockchain settings and have obtained accuracy close to 99% using both datasets.",
        "DOI": "10.1016/j.jpdc.2022.10.002",
        "paper_author": "Kumar P.",
        "affiliation_name": "LUT University",
        "affiliation_city": "Lappeenranta",
        "affiliation_country": "Finland",
        "affiliation_id": "60014304",
        "affiliation_state": "South Karelia"
    },
    {
        "paper_title": "Experimental quantum secure network with digital signatures and encryption",
        "publication": "National Science Review",
        "citied_by": "130",
        "cover_date": "2023-04-01",
        "Abstract": "Cryptography promises four information security objectives, namely, confidentiality, integrity, authenticity and non-repudiation, to support trillions of transactions annually in the digital economy. Efficient digital signatures, ensuring integrity, authenticity and non-repudiation of data with information-Theoretical security are highly urgent and intractable open problems in cryptography. Here, we propose a high-efficiency quantum digital signature (QDS) protocol using asymmetric quantum keys acquired via secret sharing, one-Time universal2 hashing and a one-Time pad.We just need to use a 384-bit key to sign documents of lengths up to 264 with a security bound of 10-19. If a one-megabit document is signed, the signature efficiency is improved by more than 108 times compared with previous QDS protocols. Furthermore, we build the first all-in-one quantum secure network integrating information-Theoretically secure communication, digital signatures, secret sharing and conference key agreement and experimentally demonstrate this signature efficiency advantage. Our work completes the cryptography toolbox of the four information security objectives.",
        "DOI": "10.1093/nsr/nwac228",
        "paper_author": "Yin H.L.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60033100",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "The use of ChatGPT in the digital era: Perspectives on chatbot implementation",
        "publication": "Journal of Applied Learning and Teaching",
        "citied_by": "130",
        "cover_date": "2023-01-02",
        "Abstract": "The rapid advancement of technology has led to the integration of ChatGPT, an artificial intelligence (AI)-powered chatbot, in various sectors, including education. This research aims to explore the perceptions of educators and students on the use of ChatGPT in education during the digital era. This study adopted a qualitative research approach, using in-depth interviews to gather data. A purposive sampling technique was used to select ten educators and 15 students from different academic institutions in Krabi, Thailand. The data collected was analysed using content analysis and NVivo. The findings revealed that educators and students generally have a positive perception of using ChatGPT in education. The chatbot was perceived to be a helpful tool for providing immediate feedback, answering questions, and providing support to students. Educators noted that ChatGPT could reduce their workload by answering routine questions and enabling them to focus on higher-order tasks. However, the findings also showed some concerns regarding the use of ChatGPT in education. Participants were worried about the accuracy of information provided by the chatbot and the potential loss of personal interaction with teachers. The need for privacy and data security was also raised as a significant concern. The results of this study could help educators and policymakers make informed decisions about using ChatGPT in education.",
        "DOI": "10.37074/jalt.2023.6.1.32",
        "paper_author": "Limna P.",
        "affiliation_name": "Rangsit University",
        "affiliation_city": "Pathum Thani",
        "affiliation_country": "Thailand",
        "affiliation_id": "60023366",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "EHDHE: Enhancing security of healthcare documents in IoT-enabled digital healthcare ecosystems using blockchain",
        "publication": "Information Sciences",
        "citied_by": "130",
        "cover_date": "2023-06-01",
        "Abstract": "Nowadays, blockchain technology is one of the advanced technologies to ensure the security of users’ sensitive or confidential data. Blockchain technology plays a vital role in various applications like artificial intelligence, supply chain, cloud computing, the healthcare sector, and many more. It helps the healthcare domain to get benefitted from its many advanced features, such as confidentiality, decentralization, security, and privacy. Also, the Internet of Things (IoT) devices connect with the healthcare systems, and the healthcare sector application software further communicates with the IT industry. The blockchain-based IoT systems have significantly impacted the healthcare sector by enhancing security, privacy, transparency, and efficiency, providing better business opportunities. Moreover, traditional healthcare systems face severe security and privacy problems, such as phishing, masquerades, identity theft, and many others. Thus, a secure blockchain-based Proposed Application (PA) is designed to generate, maintain, and validate healthcare certificates. The PA acts as a communication medium between the backend blockchain network and application entities like hospitals, patients, doctors, and IoT devices to create and verify medical certificates. It also ensures various security features, namely confidentiality, authentication, and access control, using the concept of smart contracts. The comparative and performance analysis of the proposed work shows that it provides a more effective solution than the existing schemes.",
        "DOI": "10.1016/j.ins.2023.01.148",
        "paper_author": "Sharma P.",
        "affiliation_name": "Bennett University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India",
        "affiliation_id": "60121496",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Metaverse in Healthcare Integrated with Explainable AI and Blockchain: Enabling Immersiveness, Ensuring Trust, and Providing Patient Data Security",
        "publication": "Sensors",
        "citied_by": "130",
        "cover_date": "2023-01-01",
        "Abstract": "Digitization and automation have always had an immense impact on healthcare. It embraces every new and advanced technology. Recently the world has witnessed the prominence of the metaverse which is an emerging technology in digital space. The metaverse has huge potential to provide a plethora of health services seamlessly to patients and medical professionals with an immersive experience. This paper proposes the amalgamation of artificial intelligence and blockchain in the metaverse to provide better, faster, and more secure healthcare facilities in digital space with a realistic experience. Our proposed architecture can be summarized as follows. It consists of three environments, namely the doctor’s environment, the patient’s environment, and the metaverse environment. The doctors and patients interact in a metaverse environment assisted by blockchain technology which ensures the safety, security, and privacy of data. The metaverse environment is the main part of our proposed architecture. The doctors, patients, and nurses enter this environment by registering on the blockchain and they are represented by avatars in the metaverse environment. All the consultation activities between the doctor and the patient will be recorded and the data, i.e., images, speech, text, videos, clinical data, etc., will be gathered, transferred, and stored on the blockchain. These data are used for disease prediction and diagnosis by explainable artificial intelligence (XAI) models. The GradCAM and LIME approaches of XAI provide logical reasoning for the prediction of diseases and ensure trust, explainability, interpretability, and transparency regarding the diagnosis and prediction of diseases. Blockchain technology provides data security for patients while enabling transparency, traceability, and immutability regarding their data. These features of blockchain ensure trust among the patients regarding their data. Consequently, this proposed architecture ensures transparency and trust regarding both the diagnosis of diseases and the data security of the patient. We also explored the building block technologies of the metaverse. Furthermore, we also investigated the advantages and challenges of a metaverse in healthcare.",
        "DOI": "10.3390/s23020565",
        "paper_author": "Ali S.",
        "affiliation_name": "Inje University",
        "affiliation_city": "Gimhae",
        "affiliation_country": "South Korea",
        "affiliation_id": "60015143",
        "affiliation_state": "Gyeongnam"
    },
    {
        "paper_title": "Medical Image Encryption by Content-Aware DNA Computing for Secure Healthcare",
        "publication": "IEEE Transactions on Industrial Informatics",
        "citied_by": "130",
        "cover_date": "2023-02-01",
        "Abstract": "There exists a rising concern on security of healthcare data and service. Even small lost, stolen, displaced, hacked, or communicated in personal health data could bring huge damage to patients. Therefore, we propose a novel content-aware deoxyribonucleic acid (DNA) computing system to encrypt medical images, thus guaranteeing privacy and promoting secure healthcare environment. The proposed system consists of sender and receiver to perform tasks of encryption and decryption, respectively, where both contain the same structure design, but perform opposite operations. In either sender or receiver, we design a randomly DNA encoding and a content-aware permutation and diffusion module. Considering introducing random mechanism to increase difficulty of cracking, the former module builds a random encryption rule selector in DNA encoding process by randomly mapping quantity of medical image pixels to outputs. Meanwhile, the latter module constructs a permutation sequence, which not only encodes information of pixel values, but also involves redundant correlation between adjacent pixels located in a patch. Such design brings awareness property of medical image content to greatly increase complexity in cracking by embedding semantical information for encryption. We demonstrate that the proposed system successfully improve cybersecurity of medical images against various attacks in robustness and effectiveness when transmitting data in wireless broadcasting scenarios.",
        "DOI": "10.1109/TII.2022.3194590",
        "paper_author": "Wu Y.",
        "affiliation_name": "Hohai University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60010851",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "TSMAE: A Novel Anomaly Detection Approach for Internet of Things Time Series Data Using Memory-Augmented Autoencoder",
        "publication": "IEEE Transactions on Network Science and Engineering",
        "citied_by": "130",
        "cover_date": "2023-09-01",
        "Abstract": "With the development of communication, the Internet of Things (IoT) has been widely deployed and used in industrial manufacturing, intelligent transportation, and healthcare systems. The time-series feature of the IoT increases the data density and the data dimension, where anomaly detection is important to ensure hardware and software security. However, for the general anomaly detection methods, the anomaly may be well-reconstructed with tiny differences that are hard to discover. Measuring model complexity and the dataset feature space is a long and inefficient process. In this paper, we propose a memory-augmented autoencoder approach for detecting anomalies in IoT data, which is unsupervised, end-to-end, and not easily overgeneralized. First, a memory mechanism is introduced to suppress the generalization ability of the model, and a memory-augmented time-series autoencoder (TSMAE) is designed. Each memory item is encoded and recombined according to the similarity with the latent representation. Then, the new representation is decoded to generate the reconstructed sample, based on which the anomaly score can be obtained. Second, the addressing vector tends to be sparse by adding penalties and rectification functions to the loss. Memory modules are encouraged to extract typical normal patterns, thus inhibiting model generalization ability. Long short-term memory (LSTM) is introduced for decoding and encoding time-series data to obtain the contextual characteristics of time-series data. Finally, through experiments on the ECG and Wafer datasets, the validity of the TSMAE is verified. The rationality of the hyperparameter setting is discussed by visualizing the memory module addressing vector.",
        "DOI": "10.1109/TNSE.2022.3163144",
        "paper_author": "Gao H.",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60023813",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Angular momentum holography via a minimalist metasurface for optical nested encryption",
        "publication": "Light: Science and Applications",
        "citied_by": "129",
        "cover_date": "2023-12-01",
        "Abstract": "Metasurfaces can perform high-performance multi-functional integration by manipulating the abundant physical dimensions of light, demonstrating great potential in high-capacity information technologies. The orbital angular momentum (OAM) and spin angular momentum (SAM) dimensions have been respectively explored as the independent carrier for information multiplexing. However, fully managing these two intrinsic properties in information multiplexing remains elusive. Here, we propose the concept of angular momentum (AM) holography which can fully synergize these two fundamental dimensions to act as the information carrier, via a single-layer, non-interleaved metasurface. The underlying mechanism relies on independently controlling the two spin eigenstates and arbitrary overlaying them in each operation channel, thereby spatially modulating the resulting waveform at will. As a proof of concept, we demonstrate an AM meta-hologram allowing the reconstruction of two sets of holographic images, i.e., the spin-orbital locked and the spin-superimposed ones. Remarkably, leveraging the designed dual-functional AM meta-hologram, we demonstrate a novel optical nested encryption scheme, which is able to achieve parallel information transmission with ultra-high capacity and security. Our work opens a new avenue for optionally manipulating the AM, holding promising applications in the fields of optical communication, information security and quantum science.",
        "DOI": "10.1038/s41377-023-01125-2",
        "paper_author": "Yang H.",
        "affiliation_name": "Hunan University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60032356",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Long Persistent Luminescence from Metal–Organic Compounds: State of the Art",
        "publication": "Advanced Functional Materials",
        "citied_by": "129",
        "cover_date": "2023-05-08",
        "Abstract": "The excited-state tuning of luminescent metal–organic compounds has made great progress in the fields of optical imaging, photocatalysis, photodynamic therapy, light-emitting devices, sensors, and so on. Although metal–organic compounds with high luminescence efficiency can be realized via enhanced molecular rigidity and heavy-atom effect, their corresponding luminescence lifetimes are still limited on the order of a nanosecond to a millisecond, owing to the inherent competition between luminous efficiency and lifetime. Therefore, the advanced applications (i.e., persistent afterglow imaging, information security, anti-counterfeiting, and smart materials, among others) related with long persistent luminescence (LPL, typically with the excited-state lifetime larger than millisecond) are seriously hindered. This review gives a timely and systematic summary of metal–organic compounds for realizing room-temperature phosphorescence (RTP)-type and thermally activated delayed fluorescence (TADF)-type LPL during last few years. Particularly, based on the perspectives of time, space, and energy dimensions, fundamental materials design and coordination assembly are systematically described for the first time. Moreover, the internal and external factors of influencing the LPL properties in terms of luminescence efficiency, lifetime, and color are illustrated. Last but not least, perspectives and challenges are also discussed for developing LPL from metal–organic compounds.",
        "DOI": "10.1002/adfm.202300735",
        "paper_author": "Zhou B.",
        "affiliation_name": "Beijing Normal University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60023237",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Critical Cybersecurity Analysis and Future Research Directions for the Internet of Things: A Comprehensive Review",
        "publication": "Sensors",
        "citied_by": "127",
        "cover_date": "2023-04-01",
        "Abstract": "The emergence of the Internet of Things (IoT) technology has brought about tremendous possibilities, but at the same time, it has opened up new vulnerabilities and attack vectors that could compromise the confidentiality, integrity, and availability of connected systems. Developing a secure IoT ecosystem is a daunting challenge that requires a systematic and holistic approach to identify and mitigate potential security threats. Cybersecurity research considerations play a critical role in this regard, as they provide the foundation for designing and implementing security measures that can address emerging risks. To achieve a secure IoT ecosystem, scientists and engineers must first define rigorous security specifications that serve as the foundation for developing secure devices, chipsets, and networks. Developing such specifications requires an interdisciplinary approach that involves multiple stakeholders, including cybersecurity experts, network architects, system designers, and domain experts. The primary challenge in IoT security is ensuring the system can defend against both known and unknown attacks. To date, the IoT research community has identified several key security concerns related to the architecture of IoT systems. These concerns include issues related to connectivity, communication, and management protocols. This research paper provides an all-inclusive and lucid review of the current state of anomalies and security concepts related to the IoT. We classify and analyze prevalent security distresses regarding IoT’s layered architecture, including connectivity, communication, and management protocols. We establish the foundation of IoT security by examining the current attacks, threats, and cutting-edge solutions. Furthermore, we set security goals that will serve as the benchmark for assessing whether a solution satisfies the specific IoT use cases.",
        "DOI": "10.3390/s23084117",
        "paper_author": "Tariq U.",
        "affiliation_name": "Prince Sattam Bin Abdulaziz University",
        "affiliation_city": "Al Kharj",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60105222",
        "affiliation_state": "Ar Riyad"
    },
    {
        "paper_title": "Anomaly Detection in Blockchain Networks: A Comprehensive Survey",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "125",
        "cover_date": "2023-01-01",
        "Abstract": "Over the past decade, blockchain technology has attracted a huge attention from both industry and academia because it can be integrated with a large number of everyday applications of modern information and communication technologies (ICT). Peer-to-peer (P2P) architecture of blockchain enhances these applications by providing strong security and trust-oriented guarantees, such as immutability, verifiability, and decentralization. Despite these incredible features that blockchain technology brings to these ICT applications, recent research has indicated that the strong guarantees are not sufficient enough and blockchain networks may still be prone to various security, privacy, and reliability issues. In order to overcome these issues, it is important to identify the anomalous behaviour within the actionable time frame. In this article, we provide an in-depth survey regarding integration of anomaly detection models in blockchain technology. For this, we first discuss how anomaly detection can aid in ensuring security of blockchain based applications. Then, we demonstrate certain fundamental evaluation metrics and key requirements that can play a critical role while developing anomaly detection models for blockchain. Afterwards, we present a thorough survey of various anomaly detection models from the perspective of each layer of blockchain. Finally, we conclude the article by highlighting certain important challenges alongside discussing how they can serve as future research directions for new researchers in the field.",
        "DOI": "10.1109/COMST.2022.3205643",
        "paper_author": "Ul Hassan M.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "A 3D model encryption scheme based on a cascaded chaotic system",
        "publication": "Signal Processing",
        "citied_by": "125",
        "cover_date": "2023-01-01",
        "Abstract": "With the birth of the metaverse, 3D models have received extensive attention, and the security of information transmission continues to be an important issue. In this paper, we propose a 3D model encryption method based on a 2D chaotic system constructed via the coupling of the logistic map and infinite collapse (2D-LAIC) and on semi-tensor product (STP) theory. In terms of Lyapunov exponents, NIST test results, bifurcation diagrams, etc., 2D-LAIC exhibits better dynamical behavior than classical chaotic systems. 2D-LAIC can generate an unpredictable keystream, which is highly suitable for cryptography. Therefore, we propose a new 3D model encryption algorithm based on 2D-LAIC, named 3DME-SC. For a 3D model of the floating-point data type, XOR and STP processing are applied to the integer part and fractional part, respectively, of the model to obtain a 3D ciphertext model. The keystream required for XOR and STP processing is generated by 2D-LAIC. The results of a detailed security analysis and a comparative experimental analysis show that 3DME-SC exhibits good performance and effectiveness. (Code: https://github.com/Gao5211996/3D-model-encryption)",
        "DOI": "10.1016/j.sigpro.2022.108745",
        "paper_author": "Gao S.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Role of emerging technologies in future IoT-driven Healthcare 4.0 technologies: a survey, current challenges and future directions",
        "publication": "Journal of Ambient Intelligence and Humanized Computing",
        "citied_by": "125",
        "cover_date": "2023-01-01",
        "Abstract": "Since its inception, Healthcare 4.0 has empowered the integration of advanced technologies to create and improve the quality of healthcare services. The delivery of healthcare services has come a long way from physical appointments with doctors to remote health monitoring and disease prediction, surgery assistive systems. This advancement has only been possible because of the integration of cutting-edge technologies like Tele-healthcare, software-defined networking and many more, with healthcare systems. In this survey, we have targeted some of the pioneering research works that could contribute significantly to the future development of Healthcare 4.0 systems. We have identified the significant research gaps and presented the modern state-of-the-art of healthcare systems, introducing the Healthcare IoT Application and Service Stacks. We have also discussed the latest paradigm of Wireless Body Area Networks, emphasizing its significance and how it can contribute to the development of next-generation healthcare applications using emerging technologies like Machine Learning, Blockchain, Cloud Computing, Internet of things, Edge/ Fog Computing, Tele-healthcare, Big Data Analytics, Software-Defined Networking and many more. We have performed a comparative study of different architectural implementations considering their advantages, shortcomings, and quality-of-service requirements. We emphasize the importance of the different emerging technologies in detail, discussing the opportunities available and their potential to create better healthcare solutions that can provide superior service quality. Finally, we highlight the fundamental need for establishing security and privacy in future healthcare systems. Overall, this survey provides a strong outlook into the development of the future of healthcare 4.0.",
        "DOI": "10.1007/s12652-021-03302-w",
        "paper_author": "Krishnamoorthy S.",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India",
        "affiliation_id": "60000414",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Security and Privacy on 6G Network Edge: A Survey",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "124",
        "cover_date": "2023-01-01",
        "Abstract": "To meet the stringent service requirements of 6G applications such as immersive cloud eXtended Reality (XR), holographic communication, and digital twin, there is no doubt that an increasing number of servers will be deployed on the network edge. Then, the techniques, edge computing, edge caching, and edge intelligence will be more widely utilized for intelligent local data storage and processing generated by 6G applications, while innovative access network architecture based on the cloud-edge servers, such as the Open-Radio Access Network (O-RAN) will be adopted to improve the flexibility and openness for new service deployment and frequent network changes. On the other hand, new attack surfaces and vectors targeting local infrastructure and users will emerge along with the deployment of novel network architecture and techniques. Massive researchers have studied the potential security and privacy threats on the 6G network edge as well as the countermeasures. The three techniques, edge computing, edge caching, and edge intelligence have become a double-edged sword that can not only be synchronously utilized to develop defense countermeasures, but also become the targets of many new security and privacy threats. In this article, we provide a comprehensive survey of articles on the three techniques-related security threats and countermeasures on the 6G network edge. We explain how security and privacy can be destroyed by attacking one of the three technologies and how the three services support each other to realize efficient and achievable security protection. Moreover, the researches on the benefits and limitations of Federated Learning (FL) and blockchain for decentralized edge network systems in terms of security and privacy are also investigated. Additionally, we also analyze the existing challenges and future directions towards 6G.",
        "DOI": "10.1109/COMST.2023.3244674",
        "paper_author": "Mao B.",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60003977",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Anomaly based network intrusion detection for IoT attacks using deep learning technique",
        "publication": "Computers and Electrical Engineering",
        "citied_by": "122",
        "cover_date": "2023-04-01",
        "Abstract": "Internet of Things (IoT) applications are growing in popularity for being widely used in many real-world services. In an IoT ecosystem, many devices are connected with each other via internet, making IoT networks more vulnerable to various types of cyber attacks, thus a major concern in its deployment is network security and user privacy. To protect IoT networks against various attacks, an efficient and practical Intrusion Detection System (IDS) could be an effective solution. In this paper, a novel anomaly-based IDS system for IoT networks is proposed using Deep Learning technique. Particularly, a filter-based feature selection Deep Neural Network (DNN) model where highly correlated features are dropped has been presented. Further, the model is tuned with various parameters and hyper parameters. The UNSW-NB15 dataset comprising of four attack classes is utilized for this purpose. The proposed model achieved an accuracy of 84%. Generative Adversarial Networks (GANs) were used to generate synthetic data of minority attacks to resolve class imbalance issues in the dataset and achieved 91% accuracy with balanced class dataset.",
        "DOI": "10.1016/j.compeleceng.2023.108626",
        "paper_author": "Sharma B.",
        "affiliation_name": "Manipal University Jaipur",
        "affiliation_city": "Jaipur",
        "affiliation_country": "India",
        "affiliation_id": "60108737",
        "affiliation_state": "RJ"
    },
    {
        "paper_title": "Revolutionizing Maize Disease Management with Federated Learning CNNs: A Decentralized and Privacy-Sensitive Approach",
        "publication": "2023 4th International Conference for Emerging Technology, INCET 2023",
        "citied_by": "121",
        "cover_date": "2023-01-01",
        "Abstract": "For sustainable maize production, reliable and prompt disease identification is crucial. Maize diseases represent a danger to world food security. In this work, utilizing decentralized and privacy-sensitive data, to constructed and evaluated a Federated Learning CNN model to identify and diagnose maize illnesses. The 9878 maize photos in to dataset, divided into training, validation, and test sets, depict a variety of diseases and conditions. To prepare the dataset for training the model, to did data pre-processing, such as picture scaling, normalization, augmentation, and label encoding. The Federated Learning CNN model outperformed conventional CNNs and other frequently used machine learning algorithms in agriculture, achieving an overall accuracy of 89.4% on the test set. The Federated Learning CNN model can precisely identify and categorize maize illnesses, as shown by the model's superior precision, recall, and F1-score values compared to other algorithms for each disease class. The CNN model from Federated Learning also showed resilience and consistency across the various disease classes, demonstrating the model's ability to adjust to local circumstances and variances in maize illnesses across multiple locations and farms. Additionally, to visualized the feature maps and activation patterns to understand the model, revealing how it generates predictions and which aspects of the maize photos are most crucial for disease diagnosis. To work underscores the significance of creating decentralized, privacy-preserving machine learning models in agriculture and shows the promise of federated learning CNNs for crop disease diagnosis and management.",
        "DOI": "10.1109/INCET57972.2023.10170499",
        "paper_author": "Mehta S.",
        "affiliation_name": "Chitkara University, Punjab",
        "affiliation_city": "Rajpura",
        "affiliation_country": "India",
        "affiliation_id": "60113205",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Integrated biochar solutions can achieve carbon-neutral staple crop production",
        "publication": "Nature Food",
        "citied_by": "121",
        "cover_date": "2023-01-01",
        "Abstract": "Agricultural food production is a main driver of global greenhouse gas emissions, with unclear pathways towards carbon neutrality. Here, through a comprehensive life-cycle assessment using data from China, we show that an integrated biomass pyrolysis and electricity generation system coupled with commonly applied methane and nitrogen mitigation measures can help reduce staple crops’ life-cycle greenhouse gas emissions from the current 666.5 to −37.9 Tg CO2-equivalent yr−1. Emission reductions would be achieved primarily through carbon sequestration from biochar application to the soil, and fossil fuel displacement by bio-energy produced from pyrolysis. We estimate that this integrated system can increase crop yield by 8.3%, decrease reactive nitrogen losses by 25.5%, lower air pollutant emissions by 125–2,483 Gg yr−1 and enhance net environmental and economic benefits by 36.2%. These results indicate that integrated biochar solutions could contribute to China’s 2060 carbon neutrality objective while enhancing food security and environmental sustainability.",
        "DOI": "10.1038/s43016-023-00694-0",
        "paper_author": "Xia L.",
        "affiliation_name": "Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60019499",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "A data-driven approach for intrusion and anomaly detection using automated machine learning for the Internet of Things",
        "publication": "Soft Computing",
        "citied_by": "120",
        "cover_date": "2023-10-01",
        "Abstract": "Cyber-attacks and network intrusion have surfaced as major concerns for modern days applications of the Internet of Things (IoT). The existing intrusion detection and prevention techniques have a wide range of limitations and thus are unable to precisely detect any type of attack or anomaly within the network traffic. Many machine learning-based algorithms have also been presented by the researchers, which lack performance in terms of classification accuracy, or in terms of multi-class classification. This research presents a data-driven approach for intrusion and anomaly detection, where the data is processed and filtered using different algorithms. The quality of the training dataset is improved by using Synthetic Minority Oversampling Technique (SMOTE) algorithm and mutual information. Automated machine learning is also used to detect the algorithm with auto-tuned hyper-parameters that best suit to classify the data. This technique not only saves the computational cost to test the data at run-time but also provides an optimal algorithm without the need to run calculations to tune hyper-parameters, manually. The resultant algorithm solves a multi-class classification problem with an accuracy of 99.7%, outperforming the existing algorithms by a decent margin.",
        "DOI": "10.1007/s00500-023-09037-4",
        "paper_author": "Xu H.",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China",
        "affiliation_id": "60010432",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "Federated-Learning Based Privacy Preservation and Fraud-Enabled Blockchain IoMT System for Healthcare",
        "publication": "IEEE Journal of Biomedical and Health Informatics",
        "citied_by": "120",
        "cover_date": "2023-02-01",
        "Abstract": "These days, the usage of machine-learning-enabled dynamic Internet of Medical Things (IoMT) systems with multiple technologies for digital healthcare applications has been growing progressively in practice. Machine learning plays a vital role in the IoMT system to balance the load between delay and energy. However, the traditional learning models fraud on the data in the distributed IoMT system for healthcare applications are still a critical research problem in practice. The study devises a federated learning-based blockchain-enabled task scheduling (FL-BETS) framework with different dynamic heuristics. The study considers the different healthcare applications that have both hard constraint (e.g., deadline) and resource energy consumption (e.g., soft constraint) during execution on the distributed fog and cloud nodes. The goal of FL-BETS is to identify and ensure the privacy preservation and fraud of data at various levels, such as local fog nodes and remote clouds, with minimum energy consumption and delay, and to satisfy the deadlines of healthcare workloads. The study introduces the mathematical model. In the performance evaluation, FL-BETS outperforms all existing machine learning and blockchain mechanisms in fraud analysis, data validation, energy and delay constraints for healthcare applications.",
        "DOI": "10.1109/JBHI.2022.3165945",
        "paper_author": "Lakhan A.",
        "affiliation_name": "Wenzhou University",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China",
        "affiliation_id": "60020224",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Mapping of cropland, cropping patterns and crop types by combining optical remote sensing images with decision tree classifier and random forest",
        "publication": "Geo-Spatial Information Science",
        "citied_by": "119",
        "cover_date": "2023-01-01",
        "Abstract": "Mapping and monitoring the distribution of croplands and crop types support policymakers and international organizations by reducing the risks to food security, notably from climate change and, for that purpose, remote sensing is routinely used. However, identifying specific crop types, cropland, and cropping patterns using space-based observations is challenging because different crop types and cropping patterns have similarity spectral signatures. This study applied a methodology to identify cropland and specific crop types, including tobacco, wheat, barley, and gram, as well as the following cropping patterns: wheat-tobacco, wheat-gram, wheat-barley, and wheat-maize, which are common in Gujranwala District, Pakistan, the study region. The methodology consists of combining optical remote sensing images from Sentinel-2 and Landsat-8 with Machine Learning (ML) methods, namely a Decision Tree Classifier (DTC) and a Random Forest (RF) algorithm. The best time-periods for differentiating cropland from other land cover types were identified, and then Sentinel-2 and Landsat 8 NDVI-based time-series were linked to phenological parameters to determine the different crop types and cropping patterns over the study region using their temporal indices and ML algorithms. The methodology was subsequently evaluated using Landsat images, crop statistical data for 2020 and 2021, and field data on cropping patterns. The results highlight the high level of accuracy of the methodological approach presented using Sentinel-2 and Landsat-8 images, together with ML techniques, for mapping not only the distribution of cropland, but also crop types and cropping patterns when validated at the county level. These results reveal that this methodology has benefits for monitoring and evaluating food security in Pakistan, adding to the evidence base of other studies on the use of remote sensing to identify crop types and cropping patterns in other countries.",
        "DOI": "10.1080/10095020.2022.2100287",
        "paper_author": "Tariq A.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60029306",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Federated Learning for Privacy Preservation in Smart Healthcare Systems: A Comprehensive Survey",
        "publication": "IEEE Journal of Biomedical and Health Informatics",
        "citied_by": "119",
        "cover_date": "2023-02-01",
        "Abstract": "Recent advances in electronic devices and communication infrastructure have revolutionized the traditional healthcare system into a smart healthcare system by using internet of medical things (IoMT) devices. However, due to the centralized training approach of artificial intelligence (AI), mobile and wearable IoMT devices raise privacy issues concerning the information communicated between hospitals and end-users. The information conveyed by the IoMT devices is highly confidential and can be exposed to adversaries. In this regard, federated learning (FL), a distributive AI paradigm, has opened up new opportunities for privacy preservation in IoMT without accessing the confidential data of the participants. Further, FL provides privacy to end-users as only gradients are shared during training. For these specific properties of FL, in this paper, we present privacy-related issues in IoMT. Afterwards, we present the role of FL in IoMT networks for privacy preservation and introduce some advanced FL architectures by incorporating deep reinforcement learning (DRL), digital twin, and generative adversarial networks (GANs) for detecting privacy threats. Moreover, we present some practical opportunities for FL in IoMT. In the end, we conclude this survey by discussing open research issues and challenges while using FL in future smart healthcare systems.",
        "DOI": "10.1109/JBHI.2022.3181823",
        "paper_author": "Ali M.",
        "affiliation_name": "École de Technologie Supérieure",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada",
        "affiliation_id": "60026786",
        "affiliation_state": "QC"
    },
    {
        "paper_title": "The applications of machine learning techniques in medical data processing based on distributed computing and the Internet of Things",
        "publication": "Computer Methods and Programs in Biomedicine",
        "citied_by": "117",
        "cover_date": "2023-11-01",
        "Abstract": "Medical data processing has grown into a prominent topic in the latest decades with the primary goal of maintaining patient data via new information technologies, including the Internet of Things (IoT) and sensor technologies, which generate patient indexes in hospital data networks. Innovations like distributed computing, Machine Learning (ML), blockchain, chatbots, wearables, and pattern recognition can adequately enable the collection and processing of medical data for decision-making in the healthcare era. Particularly, to assist experts in the disease diagnostic process, distributed computing is beneficial by digesting huge volumes of data swiftly and producing personalized smart suggestions. On the other side, the current globe is confronting an outbreak of COVID-19, so an early diagnosis technique is crucial to lowering the fatality rate. ML systems are beneficial in aiding radiologists in examining the incredible amount of medical images. Nevertheless, they demand a huge quantity of training data that must be unified for processing. Hence, developing Deep Learning (DL) confronts multiple issues, such as conventional data collection, quality assurance, knowledge exchange, privacy preservation, administrative laws, and ethical considerations. In this research, we intend to convey an inclusive analysis of the most recent studies in distributed computing platform applications based on five categorized platforms, including cloud computing, edge, fog, IoT, and hybrid platforms. So, we evaluated 27 articles regarding the usage of the proposed framework, deployed methods, and applications, noting the advantages, drawbacks, and the applied dataset and screening the security mechanism and the presence of the Transfer Learning (TL) method. As a result, it was proved that most recent research (about 43%) used the IoT platform as the environment for the proposed architecture, and most of the studies (about 46%) were done in 2021. In addition, the most popular utilized DL algorithm was the Convolutional Neural Network (CNN), with a percentage of 19.4%. Hence, despite how technology changes, delivering appropriate therapy for patients is the primary aim of healthcare-associated departments. Therefore, further studies are recommended to develop more functional architectures based on DL and distributed environments and better evaluate the present healthcare data analysis models.",
        "DOI": "10.1016/j.cmpb.2023.107745",
        "paper_author": "Aminizadeh S.",
        "affiliation_name": "Islamic Azad University, Tabriz Branch",
        "affiliation_city": "Tabriz",
        "affiliation_country": "Iran",
        "affiliation_id": "60022609",
        "affiliation_state": "East Azarbaijan Province"
    },
    {
        "paper_title": "Implications of large language models such as ChatGPT for dental medicine",
        "publication": "Journal of Esthetic and Restorative Dentistry",
        "citied_by": "117",
        "cover_date": "2023-10-01",
        "Abstract": "Objective: This article provides an overview of the implications of ChatGPT and other large language models (LLMs) for dental medicine. Overview: ChatGPT, a LLM trained on massive amounts of textual data, is adept at fulfilling various language-related tasks. Despite its impressive capabilities, ChatGPT has serious limitations, such as occasionally giving incorrect answers, producing nonsensical content, and presenting misinformation as fact. Dental practitioners, assistants, and hygienists are not likely to be significantly impacted by LLMs. However, LLMs could affect the work of administrative personnel and the provision of dental telemedicine. LLMs offer potential for clinical decision support, text summarization, efficient writing, and multilingual communication. As more people seek health information from LLMs, it is crucial to safeguard against inaccurate, outdated, and biased responses to health-related queries. LLMs pose challenges for patient data confidentiality and cybersecurity that must be tackled. In dental education, LLMs present fewer challenges than in other academic fields. LLMs can enhance academic writing fluency, but acceptable usage boundaries in science need to be established. Conclusions: While LLMs such as ChatGPT may have various useful applications in dental medicine, they come with risks of malicious use and serious limitations, including the potential for misinformation. Clinical Significance: Along with the potential benefits of using LLMs as an additional tool in dental medicine, it is crucial to carefully consider the limitations and potential risks inherent in such artificial intelligence technologies.",
        "DOI": "10.1111/jerd.13046",
        "paper_author": "Eggmann F.",
        "affiliation_name": "University of Pennsylvania School of Dental Medicine",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60096942",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Highly efficient vectorial field manipulation using a transmitted tri-layer metasurface in the terahertz band",
        "publication": "Opto-Electronic Advances",
        "citied_by": "117",
        "cover_date": "2023-01-01",
        "Abstract": "Polarization is a basic characteristic of electromagnetic waves that conveys much optical information owing to its many states. The polarization state is manipulated and controlled for optical information security, optical encryption, and optical communication. Metasurface devices provide a new way to manipulate wave-fronts of light. A single ultrathin metasur-face device can generate and modulate several differently polarized light fields, and thus carries optical information in several different channels. Terahertz (THz) waves have become widely used as carrier waves for wireless communica-tion. Compact and functional metasurface devices are in high demand for THz elements and systems. This paper pro-poses a tri-layer metallic THz metasurface for multi-channel polarization generation and phase modulation with a high efficiency of approximately 80%. An azimuthally polarized THz vectorial beam generator is realized and characterized for use as a THz polarization analyzer. The incident polarization angle can be observed graphically with high accuracy. Moreover, a vectorial hologram with eight channels for different linear polarization states is demonstrated experimentally. The information in different holograms can be hidden by choosing the polarization channel for detection. This work con-tributes to achieving multi-functional metasurface in the THz band and can benefit THz communication and optical information security.",
        "DOI": "10.29026/oea.2023.220012",
        "paper_author": "Zhao H.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Does regional integration improve economic resilience? Evidence from urban agglomerations in China",
        "publication": "Sustainable Cities and Society",
        "citied_by": "117",
        "cover_date": "2023-01-01",
        "Abstract": "Under the dual pressure of “slow-burn” challenges and acute shocks, increasing economic resilience is gaining attention around the world to ensure the security and stability of economic activities. With the goal of achieving sustainable development, the China is exploring an innovative, coordinated, green, open, shared and secure development path for the regional economy. Using panel data for 241 cities at the prefecture level and above in China from 2010 to 2019, this research considers urban agglomeration planning as a quasi-natural experiment of regional integration and use a difference-in-differences method to explore the effect of regional integration on economic resilience. The results show the following. 1) Regional integration does improve economic resilience after various robustness tests. 2) The policy effect of regional integration on economic resilience varies by time, region, and urban structure. 3) Urban size structure and industrial structure are important ways in which regional integration affects economic resilience. Our findings enrich the theoretical study of the relationship between regional integration and economic resilience and provide a new path to improve regional economic resilience and achieve sustainable development.",
        "DOI": "10.1016/j.scs.2022.104273",
        "paper_author": "Feng Y.",
        "affiliation_name": "Nanchang University",
        "affiliation_city": "Nanchang",
        "affiliation_country": "China",
        "affiliation_id": "60008332",
        "affiliation_state": "Jiangxi"
    },
    {
        "paper_title": "Dual-IDS: A bagging-based gradient boosting decision tree model for network anomaly intrusion detection system",
        "publication": "Expert Systems with Applications",
        "citied_by": "116",
        "cover_date": "2023-03-01",
        "Abstract": "The mission of an intrusion detection system (IDS) is to monitor network activities and assess whether or not they are malevolent. Specifically, anomaly-based IDS can discover irregular activities by discriminating between normal and anomalous deviations. Nonetheless, existing strategies for detecting anomalies generally rely on single classification models that are still incapable of reducing the false alarm rate and increasing the detection rate. This study introduces a dual ensemble model by combining two existing ensemble techniques, such as bagging and gradient boosting decision tree (GBDT). Multiple dual ensemble schemes involving various fine-tuned GBDT algorithms such as gradient boosting machine (GBM), LightGBM, CatBoost, and XGBoost, are extensively appraised using multiple publicly available data sets, such as NSL-KDD, UNSW-NB15, and HIKARI-2021. The results indicate that the proposed technique is a reasonable solution for the anomaly-based IDS task. Furthermore, we demonstrate that the combination of Bagging and GBM is superior to all alternative combination schemes. In addition, the proposed dual ensemble (e.g., Bagging-GBM) is considerably more competitive than similar techniques reported in the current literature.",
        "DOI": "10.1016/j.eswa.2022.119030",
        "paper_author": "Louk M.H.L.",
        "affiliation_name": "Universitas Surabaya",
        "affiliation_city": "Surabaya",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60104303",
        "affiliation_state": "East Java"
    },
    {
        "paper_title": "Secure Intelligent Fuzzy Blockchain Framework: Effective Threat Detection in IoT Networks",
        "publication": "Computers in Industry",
        "citied_by": "115",
        "cover_date": "2023-01-01",
        "Abstract": "Integrating blockchain into the Internet of Things (IoT) for security is a new development in computational communication systems. While security threats are changing their strategies and constructing new threats on blockchain-based IoT systems. Also, in combining blockchain with IoT networks, malicious transactions and active attacks deliver more vulnerabilities, privacy issues, and security threats. The concept of blockchain-based IoT attacks is a hot topic in both IoT and blockchain disciplines. Network attacks are a type of security and privacy threat and cover the exact scope of threats related to the combination of IoT and blockchain. Even though blockchain has potential security benefits, new cyberattacks have emerged that make blockchain alone insufficient to deal with threats and attacks in IoT networks since vagueness and ambiguity issues are unavoidable in IoT data. The heterogeneous nature of IoT sources has made uncertainty a critical issue in IoT networks. Deep Learning (DL) models have difficulty dealing with uncertainty issues and cannot manage them efficiently as an essential tool in security techniques. Thus, we need better security, privacy, and practical approaches, such as efficient threat detection against network attacks in blockchain-based IoT environments. Also helpful to consider fuzzy logic to tackle deterministic issues when DL models face uncertainty. This paper designs and implements a secure, intelligent fuzzy blockchain framework. This framework utilizes a novel fuzzy DL model, optimized adaptive neuro-fuzzy inference system (ANFIS)-based attack detection, fuzzy matching (FM), and fuzzy control system (FCS) for detection of network attacks. The proposed fuzzy DL applies the fuzzy Choquet integral to have a powerful nonlinear aggregation function in the detection. We use metaheuristic algorithms to optimize the attack detection error function in ANFIS. We also validate transactions via FM to tackle fraud detection and efficiency in the blockchain layer. This framework is the first secure, intelligent fuzzy blockchain framework that identifies and detects security threats while considering uncertainty issues in IoT networks and having more flexibility in decision-making and accepting transactions in the blockchain layer. Evaluation results verify the efficiency of the blockchain layer in throughput and latency metrics and the intelligent fuzzy layer in performance metrics (Accuracy, Precision, Recall, and F1-Score) in threat detection on both blockchain and IoT network sides. Additionally, FCS demonstrates that we obtain an effective system (stable model) for threat detection in blockchain-based IoT networks.",
        "DOI": "10.1016/j.compind.2022.103801",
        "paper_author": "Yazdinejad A.",
        "affiliation_name": "University of Guelph",
        "affiliation_city": "Guelph",
        "affiliation_country": "Canada",
        "affiliation_id": "60015881",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Internet of Things intrusion detection systems: a comprehensive review and future directions",
        "publication": "Cluster Computing",
        "citied_by": "115",
        "cover_date": "2023-12-01",
        "Abstract": "The Internet of Things (IoT) is a paradigm that connects objects to the Internet as a whole and enables them to work together to achieve common objectives, such as innovative home automation. Potential attackers see the scattered and open IoT service structure as an appealing target for cyber-attacks. So, security cannot be dealt with independently. Security must be designed and built-in to every layer of the IoT system. IoT security concerns not only network and data security but also human health and life attacks. Therefore, the development of the loT system to provide security through resistance to attacks is a de facto requirement to make the loT safe and operational. Protecting these things is very important for system security. Plus, it is important to integrate the Intrusion Detection System (IDS) with IoT systems. IDS intends to track and analyze network traffic from different resources and detect malicious activities. It is a significant part of cybersecurity technology. In short, IDS is a process used to detect malicious activities against victims by several methods. Besides, the method of Systematic Literature Review (SLR) is used to classify, review, and incorporate results from all similar research that answers one or more IDS research topics and perform a detailed empirical research analysis on IDS techniques. Furthermore, depending on the detection technique, we classify IDS approaches in IoT as signature-based, anomaly-based, specification-based, and hybrid. Also, for the IDS approaches, the authors give a parametric comparison. The benefits and drawbacks of the chosen mechanisms are then addressed. Eventually, there is an analysis of open problems as well as potential trend directions.",
        "DOI": "10.1007/s10586-022-03776-z",
        "paper_author": "Heidari A.",
        "affiliation_name": "Islamic Azad University, Tabriz Branch",
        "affiliation_city": "Tabriz",
        "affiliation_country": "Iran",
        "affiliation_id": "60022609",
        "affiliation_state": "East Azarbaijan Province"
    },
    {
        "paper_title": "A novel deep learning-based approach for malware detection",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "114",
        "cover_date": "2023-06-01",
        "Abstract": "Malware detection approaches can be classified into two classes, including static analysis and dynamic analysis. Conventional approaches of the two classes have their respective advantages and disadvantages. For example, static analysis is faster but cannot detect the malware variants generated through code obfuscation, whereas dynamic analysis can effectively detect variants generated through code obfuscation but is slower and requires intensive resources. This paper proposes a novel deep learning-based approach for malware detection. It delivers better performance than conventional approaches by combining static and dynamic analysis advantages. First, it visualises a portable executable (PE) file as a coloured image. Second, it extracts deep features from the colour image using fine-tuned deep learning model. Third, it detects malware based on the deep features using support vector machines (SVM). The proposed method combines deep learning with machine learning and eliminates the need for intensive feature engineering tasks and domain knowledge. The proposed approach is scalable, cost-effective, and efficient. The detection effectiveness of the proposed method is validated through 12 machine learning models and 15 deep learning models. The generalisability of the proposed framework is validated on various benchmark datasets. The proposed approach outperformed with an accuracy of 99.06% on the Malimg dataset. The Wilcoxon signed-rank test is used to show the statistical significance of the proposed framework. The detailed experimental results demonstrate the superiority of the proposed method over the other state-of-the-art approaches, with an average increase in accuracy of 16.56%. Finally, to tackle the problems of imbalanced data and the shortage of publicly available datasets for malware detection, various data augmentation techniques are proposed, which lead to improved performance. It is evident from the results that the proposed framework can be useful to the defence industry, which will be helpful in devising more efficient malware detection solutions.",
        "DOI": "10.1016/j.engappai.2023.106030",
        "paper_author": "Shaukat K.",
        "affiliation_name": "The University of Newcastle, Australia",
        "affiliation_city": "Callaghan",
        "affiliation_country": "Australia",
        "affiliation_id": "60010571",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "A Survey of Blockchain and Intelligent Networking for the Metaverse",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "114",
        "cover_date": "2023-02-15",
        "Abstract": "The virtual world created by the development of the Internet, computers, artificial intelligence (AI), and hardware technologies have brought various degrees of digital transformation to people's lives. With multiple demands for virtual reality increasing, the metaverse, a new type of social ecology that can connect the physical and virtual worlds, is booming. However, with the rapid growth of data volume and value, the continuous evolution of the metaverse faces the demands and challenges of privacy, security, high synchronization, and low latency. Fortunately, the ever-evolving blockchain and intelligent networking technologies can be used to satisfy the trusted construction, continuous data interaction, and computing demands of the metaverse. Therefore, it is necessary to conduct an in-depth review of the role and gains of blockchain, intelligent networking, and the combination of both in providing the immersive experiences of the metaverse. In this survey, we first discuss the development trend, characteristics, and architecture of the metaverse. Then, the existing work on blockchain, networking, and the combination of the two technologies are reviewed, including overviews, applications, and challenges. Next, applications of the metaverse are summarized, emphasizing the importance of the metaverse and the fields of development. Finally, we discuss some open issues, challenges, and future research directions.",
        "DOI": "10.1109/JIOT.2022.3222521",
        "paper_author": "Fu Y.",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60025578",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Climate change and its effect on groundwater quality",
        "publication": "Environmental Geochemistry and Health",
        "citied_by": "114",
        "cover_date": "2023-04-01",
        "Abstract": "Knowing water quality at larger scales and related ground and surface water interactions impacted by land use and climate is essential to our future protection and restoration investments. Population growth has driven humankind into the Anthropocene where continuous water quality degradation is a global phenomenon as shown by extensive recalcitrant chemical contamination, increased eutrophication, hazardous algal blooms, and faecal contamination connected with microbial hazards antibiotic resistance. In this framework, climate change and related extreme events indeed exacerbate the negative trend in water quality. Notwithstanding the increasing concern in climate change and water security, research linking climate change and groundwater quality remain early. Additional research is required to improve our knowledge of climate and groundwater interactions and integrated groundwater management. Long-term monitoring of groundwater, surface water, vegetation, and land-use patterns must be supported and fortified to quantify baseline properties. Concerning the ways climate change affects water quality, limited literature data are available. This study investigates the link between climate change and groundwater quality aquifers by examining case studies of regional carbonate aquifers located in Central Italy. This study also highlights the need for strategic groundwater management policy and planning to decrease groundwater quality due to aquifer resource shortages and climate change factors. In this scenario, the role of the Society of Environmental Geochemistry is to work together within and across geochemical environments linked with the health of plants, animals, and humans to respond to multiple challenges and opportunities made by global warming.",
        "DOI": "10.1007/s10653-021-01140-5",
        "paper_author": "Barbieri M.",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60032350",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Internet of Things and smart sensors in agriculture: Scopes and challenges",
        "publication": "Journal of Agriculture and Food Research",
        "citied_by": "113",
        "cover_date": "2023-12-01",
        "Abstract": "Agriculture is an essential sector needed for survival of the human community. Several measures have been taken to enhance the crop production. However harsh environmental conditions and frequent pest infestation lead to the agricultural loss. In such scenario, integration of advanced technologies such as advanced sensors coupled with Internet of Things (IoT) could escalate the agricultural production and minimize the economic loss. Studies have been conducted across the world that satisfactorily demonstrated the implication of integrated IoT-smart sensors in monitoring environmental factors such as moisture, humidity, temperature, and soil composition that are critical for crop growth. Green house gases such as Carbon dioxide, Methane, etc., are also measured through automated sensors. Smart farming also enables measurement of nitrogen contents in soil that helps farmers to determine the amount of fertilizers to be used in farm lands. Some IoT-enabled equipments and unmanned aerial vehicles are useful in accurate surveillance of pest attack and associated diseases in farm vegetation. Though the smart farming has great scopes in future, it faces certain limitations related to high implementation cost, data security, and lack of sufficient digital knowledge in farmers. Special economic policies, data encryption, and digital literacy could ease IoT-enabled smart farming in future.",
        "DOI": "10.1016/j.jafr.2023.100776",
        "paper_author": "Rajak P.",
        "affiliation_name": "Kazi Nazrul University",
        "affiliation_city": "Bardhaman",
        "affiliation_country": "India",
        "affiliation_id": "60111753",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "In-Sensor Computing: Materials, Devices, and Integration Technologies",
        "publication": "Advanced Materials",
        "citied_by": "113",
        "cover_date": "2023-09-14",
        "Abstract": "The number of sensor nodes in the Internet of Things is growing rapidly, leading to a large volume of data generated at sensory terminals. Frequent data transfer between the sensors and computing units causes severe limitations on the system performance in terms of energy efficiency, speed, and security. To efficiently process a substantial amount of sensory data, a novel computation paradigm that can integrate computing functions into sensor networks should be developed. The in-sensor computing paradigm reduces data transfer and also decreases the high computing complexity by processing data locally. Here, the hardware implementation of the in-sensor computing paradigm at the device and array levels is discussed. The physical mechanisms that lead to unique sensory response characteristics and their corresponding computing functions are illustrated. In particular, bioinspired device characteristics enable the implementation of the functionalities of neuromorphic computation. The integration technology is also discussed and the perspective on the future development of in-sensor computing is provided.",
        "DOI": "10.1002/adma.202203830",
        "paper_author": "Wan T.",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008928",
        "affiliation_state": "Hong Kong"
    },
    {
        "paper_title": "Dynamic Photoresponsive Ultralong Phosphorescence from One-Dimensional Halide Microrods Toward Multilevel Information Storage",
        "publication": "CCS Chemistry",
        "citied_by": "112",
        "cover_date": "2023-12-01",
        "Abstract": "Ultralong room temperature phosphorescence (RTP) has drawn much attention in fields such as optical imaging, sensors, information security, and so on. To meet the need for intelligent systems, the development of photoresponsive ultralong RTP materials is highly desirable; however, it remains a challenge due to the lack of rational design strategies that can leverage RTP and photochromism effectively. Herein, we report a new type of one-dimensional (1D) metal–organic halides (MOHs) that simultaneously exhibited dynamic ultralong RTP and photochromic optical waveguide with a large switching ratio, obvious visualization contrast, and robust reversibility. These properties facilitate future applications for multicolor photonic barcodes and optical logic gates. Moreover, benefiting from the color-time-space multidimensional tunable ultralong RTP, this 1D microrod displayed a multimode luminescent signal output, with significantly higher information storage capacity than typical fluorescent systems. Therefore, this work demonstrates a new 1D color-tunable optical waveguide and photoresponsive ultralong RTP based on molecular self-assembly of MOHs and extends frontier photonic applications as multilevel data encryption and information storage at the micro/nanoscale.",
        "DOI": "10.31635/ccschem.023.202202605",
        "paper_author": "Xing C.",
        "affiliation_name": "Beijing Normal University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60023237",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?",
        "publication": "Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",
        "citied_by": "112",
        "cover_date": "2023-06-29",
        "Abstract": "In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.",
        "DOI": "10.1145/3587102.3588827",
        "paper_author": "Malinka K.",
        "affiliation_name": "Brno University of Technology",
        "affiliation_city": "Brno",
        "affiliation_country": "Czech Republic",
        "affiliation_id": "60013826",
        "affiliation_state": "South Moravian Region"
    },
    {
        "paper_title": "CardioVerse: The cardiovascular medicine in the era of Metaverse",
        "publication": "Trends in Cardiovascular Medicine",
        "citied_by": "112",
        "cover_date": "2023-11-01",
        "Abstract": "The recent pandemic launched an acceleration in adopting telemedicine by cardiovascular health and triggered the flourishing of technological advancements, such as the metaverse, which is a novel interactive mix of digital worlds that leverages augmented reality with virtual reality. The CardioVerse represents a theoretical term for the embracement of the metaverse by cardiovascular medicine, encompassing the endless possibilities as well as the challenges that it holds and introduces new dimensions to disease education, prevention and diagnosis. Its applications are numerous, notably in enhancing medical visits, assisting cardiovascular interventions and reshaping the way medical education is provided. Although obstacles are expected in diverse domains such as security, technical, legislative and regulatory, the utilization of non-fungible tokens as a security asset for patient data appears as potential solution.",
        "DOI": "10.1016/j.tcm.2022.05.004",
        "paper_author": "Skalidis I.",
        "affiliation_name": "Centre Hospitalier Universitaire Vaudois",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60023561",
        "affiliation_state": "VD"
    },
    {
        "paper_title": "Edge Intelligence Empowered Vehicle Detection and Image Segmentation for Autonomous Vehicles",
        "publication": "IEEE Transactions on Intelligent Transportation Systems",
        "citied_by": "111",
        "cover_date": "2023-11-01",
        "Abstract": "Edge intelligence (EI) migrates data and artificial intelligence (AI) to the 'edge' of a network, enhancing the high-bandwidth and low-latency of wireless data transmission with the multiplier effect of 5G and AI, greatly improving the edges' processing speed. Through integrating EI and computer vision technology, video surveillance systems in ITS can improve the processing capability of traffic information, which improves traffic efficiency and ensures traffic safety. Accordingly, first, we propose an edge intelligence-based improved-YOLOv4 vehicle detection algorithm, introducing an efficient channel attention (ECA) mechanism and a high-resolution network (HRNet) to enhance vehicle detection ability. Second, an edge intelligence-based improved DeepLabv3+ image segmentation algorithm is proposed, replacing the original backbone network with MobileNetv2 and using the softpool method, thus reducing the network size while improving the segmentation accuracy. Experimental results show that our proposed model has a higher average precision (AP) and can improve vehicle detection accuracy from 82.03% to 86.22%. The mean intersection over union (mIOU) of the image segmentation model improves from 73.32% to 75.63%.",
        "DOI": "10.1109/TITS.2022.3232153",
        "paper_author": "Chen C.",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60025578",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "External field-assisted techniques for polymer matrix composites with electromagnetic interference shielding",
        "publication": "Science Bulletin",
        "citied_by": "110",
        "cover_date": "2023-09-15",
        "Abstract": "The rapid development of mobile devices has greatly improved the lives of people, but they have also caused problems with electromagnetic interference (EMI) and information security. Therefore, there is an urgent need to develop high performance EMI shielding materials to suppress electromagnetic radiation and prevent information leakage. Some reports point out that the self-orientation behavior of fillers under external forces contributes to the improvement of EMI shielding performance. So how to construct an effective filler orientation structure in the polymer matrix is becoming a hot topic in the research of EMI shielding materials. In view of the fact that there are few reports on the preparation of polymer matrix EMI shielding composites by external field induction, from this perspective, we first highly focus on strategies for the construction of conductive networks within composites based on external field induction. Subsequently, the research progress on the preparation of polymer matrix EMI shielding composites by inducing the orientation of inorganic fillers through external fields, including temperature, electrostatic, gravity, mechanical force and magnetic fields, is organized and sorted out in detail. Notably, the particular response relationship between the unique composite structures prepared by external field induction and the incident electromagnetic waves is further dissected. Finally, the key scientific problems that need to be solved in the preparation of polymer matrix EMI shielding composites assisted by external fields are proposed. The approach discussed and the strategies proposed are expected to provide some guidance for the innovative design of high-performance polymer matrix EMI shielding composites.",
        "DOI": "10.1016/j.scib.2023.07.046",
        "paper_author": "Liang C.",
        "affiliation_name": "North University of China",
        "affiliation_city": "Taiyuan",
        "affiliation_country": "China",
        "affiliation_id": "60001305",
        "affiliation_state": "Shanxi"
    },
    {
        "paper_title": "Blockchain-based decentralized federated transfer learning methodology for collaborative machinery fault diagnosis",
        "publication": "Reliability Engineering and System Safety",
        "citied_by": "110",
        "cover_date": "2023-01-01",
        "Abstract": "Due to the limitations of data quality and quantity of a single industrial user, the development of intelligent machinery fault diagnosis methods has been reaching a bottleneck in the perspectives of both academic research and engineering applications in the recent years. Collaborative fault diagnosis model development has been receiving increasing attention, where the distributed data at different users are explored simultaneously. However, data security and privacy are the major industrial concerns, which have not been well addressed in the literature. In this paper, a blockchain-based decentralized federated transfer learning method is proposed for collaborative machinery fault diagnosis. A tailored committee consensus scheme is designed for optimization of the model aggregation process, and a source data-free transfer learning method is further proposed. After global model initialization, the fault diagnosis model can be built through iterations of committee member selection, performance evaluation, transfer learning, model aggregation and blockchain updates. The experiments on two decentralized fault diagnosis datasets are implemented for validations, and higher than 90% testing accuracies can be generally achieved. The experimental results indicate the proposed method is effective in data privacy-preserving collaborative fault diagnosis of multiple users. It offers a promising tool for applications in the real industrial scenarios.",
        "DOI": "10.1016/j.ress.2022.108885",
        "paper_author": "Zhang W.",
        "affiliation_name": "Shenyang Aerospace University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60018326",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "An Enhanced AI-Based Network Intrusion Detection System Using Generative Adversarial Networks",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "109",
        "cover_date": "2023-02-01",
        "Abstract": "As communication technology advances, various and heterogeneous data are communicated in distributed environments through network systems. Meanwhile, along with the development of communication technology, the attack surface has expanded, and concerns regarding network security have increased. Accordingly, to deal with potential threats, research on network intrusion detection systems (NIDSs) has been actively conducted. Among the various NIDS technologies, recent interest is focused on artificial intelligence (AI)-based anomaly detection systems, and various models have been proposed to improve the performance of NIDS. However, there still exists the problem of data imbalance, in which AI models cannot sufficiently learn malicious behavior and thus fail to detect network threats accurately. In this study, we propose a novel AI-based NIDS that can efficiently resolve the data imbalance problem and improve the performance of the previous systems. To address the aforementioned problem, we leveraged a state-of-the-art generative model that could generate plausible synthetic data for minor attack traffic. In particular, we focused on the reconstruction error and Wasserstein distance-based generative adversarial networks, and autoencoder-driven deep learning models. To demonstrate the effectiveness of our system, we performed comprehensive evaluations over various data sets and demonstrated that the proposed systems significantly outperformed the previous AI-based NIDS.",
        "DOI": "10.1109/JIOT.2022.3211346",
        "paper_author": "Park C.",
        "affiliation_name": "Electronics and Telecommunications Research Institute",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60001558",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Federated learning for secure IoMT-applications in smart healthcare systems: A comprehensive review",
        "publication": "Knowledge-Based Systems",
        "citied_by": "108",
        "cover_date": "2023-08-15",
        "Abstract": "Recent developments in the Internet of Things (IoT) and various communication technologies have reshaped numerous application areas. Nowadays, IoT is assimilated into various medical devices and equipment, leading to the progression of the Internet of Medical Things (IoMT). Therefore, various IoMT-based healthcare applications are deployed and used in the day-to-day scenario. Traditionally, machine learning (ML) models use centralized data compilation and learning that is impractical in pragmatic healthcare frameworks due to rising privacy and data security issues. Federated Learning (FL) has been observed as a developing distributed collective paradigm, the most appropriate for modern healthcare framework, that manages various stakeholders (e.g., patients, hospitals, laboratories, etc.) to carry out training of the models without the actual exchange of sensitive medical data. Consequently, in this work, the authors present an exhaustive survey on the security of FL-based IoMT applications in smart healthcare frameworks. First, the authors introduced IoMT devices, their types, applications, datasets, and the IoMT security framework in detail. Subsequently, the concept of FL, its application domains, and various tools used to develop FL applications are discussed. The significant contribution of FL in deploying secure IoMT systems is presented by focusing on FL-based IoMT applications, patents, real-world FL-based healthcare projects, and datasets. A comparison of FL-based security techniques with other schemes in the smart healthcare ecosystem is also presented. Finally, the authors discussed the challenges faced and potential future research recommendations to deploy secure FL-based IoMT applications in smart healthcare frameworks.",
        "DOI": "10.1016/j.knosys.2023.110658",
        "paper_author": "Rani S.",
        "affiliation_name": "Guru Nanak Dev Engineering College, Ludhiana",
        "affiliation_city": "Ludhiana",
        "affiliation_country": "India",
        "affiliation_id": "60111242",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models",
        "publication": "IEEE Access",
        "citied_by": "107",
        "cover_date": "2023-01-01",
        "Abstract": "The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across several case studies and contrasts the performances with prior studies.",
        "DOI": "10.1109/ACCESS.2023.3274199",
        "paper_author": "Maddigan P.",
        "affiliation_name": "Massey University Auckland",
        "affiliation_city": "Auckland",
        "affiliation_country": "New Zealand",
        "affiliation_id": "60110548",
        "affiliation_state": "AUK"
    },
    {
        "paper_title": "Ethical Dilemmas and Privacy Issues in Emerging Technologies: A Review",
        "publication": "Sensors",
        "citied_by": "107",
        "cover_date": "2023-02-01",
        "Abstract": "Industry 5.0 is projected to be an exemplary improvement in digital transformation allowing for mass customization and production efficiencies using emerging technologies such as universal machines, autonomous and self-driving robots, self-healing networks, cloud data analytics, etc., to supersede the limitations of Industry 4.0. To successfully pave the way for acceptance of these technologies, we must be bound and adhere to ethical and regulatory standards. Presently, with ethical standards still under development, and each region following a different set of standards and policies, the complexity of being compliant increases. Having vague and inconsistent ethical guidelines leaves potential gray areas leading to privacy, ethical, and data breaches that must be resolved. This paper examines the ethical dimensions and dilemmas associated with emerging technologies and provides potential methods to mitigate their legal/regulatory issues.",
        "DOI": "10.3390/s23031151",
        "paper_author": "Dhirani L.L.",
        "affiliation_name": "University of Limerick",
        "affiliation_city": "Limerick",
        "affiliation_country": "Ireland",
        "affiliation_id": "60009602",
        "affiliation_state": "Munster"
    },
    {
        "paper_title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings",
        "publication": "Proceedings - International Symposium on Computer Architecture",
        "citied_by": "106",
        "cover_date": "2023-06-17",
        "Abstract": "In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x–7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus nearly 10x faster overall, which along with OCS flexibility and availability allows a large language model to train at an average of ~60% of peak FLOPS/second. For similar sized systems, it is ~4.3x–4.5x faster than the Graphcore IPU Bow and is 1.2x–1.7x faster and uses 1.3x–1.9x less power than the Nvidia A100. TPU v4s inside the energy-optimized warehouse scale computers of Google Cloud use ~2-6x less energy and produce ~20x less CO2e than contemporary DSAs in typical on-premise data centers.",
        "DOI": "10.1145/3579371.3589350",
        "paper_author": "Jouppi N.P.",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States",
        "affiliation_id": "60006191",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A Survey on Digital Twins: Architecture, Enabling Technologies, Security and Privacy, and Future Prospects",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "106",
        "cover_date": "2023-09-01",
        "Abstract": "By interacting, synchronizing, and cooperating with its physical counterpart in real time, digital twin (DT) is promised to promote an intelligent, predictive, and optimized modern city. Via interconnecting massive physical entities and their virtual twins with inter-twin and intra-twin communications, the Internet of DTs (IoDT) enables free data exchange, dynamic mission cooperation, and efficient information aggregation for composite insights across vast physical/virtual entities. However, as IoDT incorporates various cutting-edge technologies to spawn the new ecology, severe known/unknown security flaws, and privacy invasions of IoDT hinder its wide deployment. Besides, the intrinsic characteristics of IoDT, such as decentralized structure, information-centric routing, and semantic communications, entail critical challenges for security service provisioning in IoDT. To this end, this article presents an in-depth review of the IoDT with respect to system architecture, enabling technologies, and security/privacy issues. Specifically, we first explore a novel distributed IoDT architecture with cyber-physical interactions and discuss its key characteristics and communication modes. Afterward, we investigate the taxonomy of security and privacy threats in IoDT, discuss the key research challenges, and review the state-of-the-art defense approaches. Finally, we point out the new trends and open research directions related to IoDT.",
        "DOI": "10.1109/JIOT.2023.3263909",
        "paper_author": "Wang Y.",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60018308",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "A review of data-driven fault detection and diagnostics for building HVAC systems",
        "publication": "Applied Energy",
        "citied_by": "106",
        "cover_date": "2023-06-01",
        "Abstract": "With the wide adoption of building automation system, and the advancement of data, sensing, and machine learning techniques, data-driven fault detection and diagnostics (FDD) for building heating, ventilation, and air conditioning systems has gained increasing attention. In this paper, data-driven FDD is defined as those that are built or trained from data via machine learning or multivariate statistical analysis methods. Following this definition, this paper reviews and summarizes the literature on data-driven FDD from three aspects: process, systems studied (including the systems being investigated, the faults being identified, and the associated data sources), and evaluation metrics. A data-driven FDD process is further divided into the following steps: data collection, data cleansing, data preprocessing, baseline establishment, fault detection, fault diagnostics, and potential fault prognostics. Literature reported data-driven methods used in each step of an FDD process are firstly discussed. Applications of data-driven FDD in various HVAC systems/components and commonly used data source for FDD development are reviewed secondly, followed by a summary of typical metrics for evaluating FDD methods. Finally, this literature review concludes that despite the promising performance reported in the literature, data-driven FDD methods still face many challenges, such as real-building deployment, performance evaluation and benchmarking, scalability and transferability, interpretability, cyber security and data privacy, user experience, etc. Addressing these challenges is critical for a broad real-building adoption of data-driven FDD.",
        "DOI": "10.1016/j.apenergy.2023.121030",
        "paper_author": "Chen Z.",
        "affiliation_name": "Drexel University",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60014662",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Unintended consequences of combating desertification in China",
        "publication": "Nature Communications",
        "citied_by": "104",
        "cover_date": "2023-12-01",
        "Abstract": "Since the early 2000s, China has carried out extensive “grain-for-green” and grazing exclusion practices to combat desertification in the desertification-prone region (DPR). However, the environmental and socioeconomic impacts of these practices remain unclear. We quantify and compare the changes in fractional vegetation cover (FVC) with economic and population data in the DPR before and after the implementation of these environmental programmes. Here we show that climatic change and CO2 fertilization are relatively strong drivers of vegetation rehabilitation from 2001-2020 in the DPR, and the declines in the direct incomes of farmers and herders caused by ecological practices exceed the subsidies provided by governments. To minimize economic hardship, enhance food security, and improve the returns on policy investments in the DPR, China needs to adapt its environmental programmes to address the potential impacts of future climate change and create positive synergies to combat desertification and improve the economy in this region.",
        "DOI": "10.1038/s41467-023-36835-z",
        "paper_author": "Wang X.",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60031150",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Blockchain Application in Healthcare Systems: A Review",
        "publication": "Systems",
        "citied_by": "104",
        "cover_date": "2023-01-01",
        "Abstract": "In the recent years, blockchain technology has gained significant attention in the healthcare sector. It has the potential to alleviate a wide variety of major difficulties in electronic health record systems. This study presents an elaborate overview of the existing research works on blockchain applications in the healthcare industry. This paper evaluates 144 articles that discuss the importance and limits of using blockchain technologies to improve healthcare operations. The objective is to demonstrate the technology’s potential uses and highlight the difficulties and possible sectors for future blockchain research in the healthcare domain. The paper starts with an extensive background study of blockchain and its features. Then, the paper focuses on providing an extensive literature review of the selected articles to highlight the current research themes in blockchain-based healthcare systems. After that, major application areas along with the solutions provided by blockchain in healthcare systems are pointed out. Finally, a discussion section provides insight into the limitations, challenges and future research directions.",
        "DOI": "10.3390/systems11010038",
        "paper_author": "Ghosh P.K.",
        "affiliation_name": "North South University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60028220",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "RIS-Assisted Visible Light Communication Systems: A Tutorial",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "104",
        "cover_date": "2023-01-01",
        "Abstract": "Recent intensive and extensive development of the fifth-generation (5G) of cellular networks has led to their deployment throughout much of the world. As part of this implementation, one of the challenges that must be addressed is the skip-zone problem, which occurs when objects such as trees, people, animals, and vehicles obstruct the transmission of signals. In free-space optical (FSO) and radio frequency (RF) systems, dead zones are most often caused by buildings and trees, while in visible light communications (VLC), obstructions are caused by individuals moving around a room or objects placed in the room. A signal obstruction can significantly reduce the signal-to-noise ratio in RF and indoor VLC systems, whereas in FSO systems, where the transmitted signals are directional, the obstruction can completely disrupt data transmission. Therefore, the skip-zone dilemma must be resolved to ensure the smooth and efficient operation of 5G and beyond networks. By placing a relay between a transmitter and a receiver, the effects of obstacles can be mitigated. As a result, the signal from the transmitter will reach the receiver. In recent years, reconfigurable intelligent surfaces (RISs) that are more efficient than relays have become widely accepted as a method of mitigating skip-zones and providing reconfigurable radio environments. However, there have been limited studies of RISs for optical wireless communication (OWC) systems. Through the RIS technology, OWC and RF communication channels can be reconfigured. This paper aims to provide a comprehensive tutorial on indoor VLC systems utilizing RIS technology. The article discusses the basics of VLC and RISs and reintroduces RISs for OWC systems, focusing on RIS-assisted indoor VLC systems. We also provide a comprehensive overview of optical RISs and examine the differences between optical RISs, RF-RISs, and optical relays. Furthermore, we discuss in detail how RISs can be used to overcome line-of-sight blockages and the device orientation issue in VLC systems while revealing key challenges such as RIS element orientation design, RIS elements to access point/user assignment design, and RIS array positioning design problems that need to be studied. Moreover, we discuss and propose several research problems on integrating optical RISs with other emerging technologies, including non-orthogonal multiple access, multiple-input multiple-output systems, physical layer security, and simultaneous lightwave and power transfer in VLC systems. Finally, we highlight other important research directions that can further improve the performance of RIS-assisted VLC systems.",
        "DOI": "10.1109/COMST.2022.3225859",
        "paper_author": "Aboagye S.",
        "affiliation_name": "Memorial University of Newfoundland",
        "affiliation_city": "St John's",
        "affiliation_country": "Canada",
        "affiliation_id": "60019000",
        "affiliation_state": "NL"
    },
    {
        "paper_title": "Generative artificial intelligence empowers educational reform: current status, issues, and prospects",
        "publication": "Frontiers in Education",
        "citied_by": "103",
        "cover_date": "2023-01-01",
        "Abstract": "The emergence of Chat GPT has once again sparked a wave of information revolution in generative artificial intelligence. This article provides a detailed overview of the development and technical support of generative artificial intelligence. It conducts an in-depth analysis of the current application of generative artificial intelligence in the field of education, and identifies problems in four aspects: opacity and unexplainability, data privacy and security, personalization and fairness, and effectiveness and reliability. Corresponding solutions are proposed, such as developing explainable and fair algorithms, upgrading encryption technology, and formulating relevant laws and regulations to protect data, as well as improving the quality and quantity of datasets. The article also looks ahead to the future development trends of generative artificial intelligence in education from four perspectives: personalized education, intelligent teaching, collaborative education, and virtual teaching. The aim of the study is to provide important reference value for research and practice in this field.",
        "DOI": "10.3389/feduc.2023.1183162",
        "paper_author": "Yu H.",
        "affiliation_name": "Shaanxi Normal University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60000174",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "A Secure Intrusion Detection Platform Using Blockchain and Radial Basis Function Neural Networks for Internet of Drones",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "103",
        "cover_date": "2023-05-15",
        "Abstract": "The Internet of Drones (IoD) is built on the Internet of Things (IoT) by replacing 'Things' with 'Drones' while retaining incomparable features. Because of its vital applications, IoD technologies have attracted much attention in recent years. Nevertheless, gaining the necessary degree of public acceptability of IoD without demonstrating safety and security for human life is exceedingly difficult. In addition, intrusion detection systems (IDSs) in IoD confront several obstacles because of the dynamic network architecture, particularly in balancing detection accuracy and efficiency. To increase the performance of the IoD network, we proposed a blockchain-based radial basis function neural networks (RBFNNs) model in this article. The proposed method can improve data integrity and storage for smart decision-making across different IoDs. We discussed the usage of blockchain to create decentralized predictive analytics and a model for effectively applying and sharing deep learning (DL) methods in a decentralized fashion. We also assessed the model using a variety of data sets to demonstrate the viability and efficacy of implementing the blockchain-based DL technique in IoD contexts. The findings showed that the suggested model is an excellent option for developing classifiers while adhering to the constraints placed by network intrusion detection. Furthermore, the proposed model can outperform the cutting-edge methods in terms of specificity, F1, recall, precision, and accuracy.",
        "DOI": "10.1109/JIOT.2023.3237661",
        "paper_author": "Heidari A.",
        "affiliation_name": "Islamic Azad University, Tabriz Branch",
        "affiliation_city": "Tabriz",
        "affiliation_country": "Iran",
        "affiliation_id": "60022609",
        "affiliation_state": "East Azarbaijan Province"
    }
]