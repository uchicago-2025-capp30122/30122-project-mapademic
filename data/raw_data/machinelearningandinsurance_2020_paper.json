[
    {
        "paper_title": "A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",
        "publication": "Ageing Research Reviews",
        "citied_by": "383",
        "cover_date": "2020-12-01",
        "Abstract": "One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",
        "DOI": "10.1016/j.arr.2020.101174",
        "paper_author": "Fang E.F.",
        "affiliation_name": "Akershus University Hospital",
        "affiliation_city": "Lorenskog",
        "affiliation_country": "Norway",
        "affiliation_id": "60068728",
        "affiliation_state": "Viken"
    },
    {
        "paper_title": "Explainable decision forest: Transforming a decision forest into an interpretable tree",
        "publication": "Information Fusion",
        "citied_by": "134",
        "cover_date": "2020-09-01",
        "Abstract": "Decision forests are considered the best practice in many machine learning challenges, mainly due to their superior predictive performance. However, simple models like decision trees may be preferred over decision forests in cases in which the generated predictions must be efficient or interpretable (e.g. in insurance or health-related use cases). This paper presents a novel method for transforming a decision forest into an interpretable decision tree, which aims at preserving the predictive performance of decision forests while enabling efficient classifications that can be understood by humans. This is done by creating a set of rule conjunctions that represent the original decision forest; the conjunctions are then hierarchically organized to form a new decision tree. We evaluate the proposed method on 33 UCI datasets and show that the resulting model usually approximates the ROC AUC gained by random forest while providing an interpretable decision path for each classification.",
        "DOI": "10.1016/j.inffus.2020.03.013",
        "paper_author": "Sagi O.",
        "affiliation_name": "Ben-Gurion University of the Negev",
        "affiliation_city": "Beer-Sheva",
        "affiliation_country": "Israel",
        "affiliation_id": "60027161",
        "affiliation_state": "Southern District"
    },
    {
        "paper_title": "Hurtful words",
        "publication": "ACM CHIL 2020 - Proceedings of the 2020 ACM Conference on Health, Inference, and Learning",
        "citied_by": "105",
        "cover_date": "2020-02-04",
        "Abstract": "In this work, we examine the extent to which embeddings may encode marginalized populations differently, and how this may lead to a perpetuation of biases and worsened performance on clinical tasks. We pretrain deep embedding models (BERT) on medical notes from the MIMIC-III hospital dataset, and quantify potential disparities using two approaches. First, we identify dangerous latent relationships that are captured by the contextual word embeddings using a fill-in-the-blank method with text from real clinical notes and a log probability bias score quantification. Second, we evaluate performance gaps across different definitions of fairness on over 50 downstream clinical prediction tasks that include detection of acute and chronic conditions. We find that classifiers trained from BERT representations exhibit statistically significant differences in performance, often favoring the majority group with regards to gender, language, ethnicity, and insurance status. Finally, we explore shortcomings of using adversarial debiasing to obfuscate subgroup information in contextual word embeddings, and recommend best practices for such deep embedding models in clinical settings.",
        "DOI": "10.1145/3368555.3384448",
        "paper_author": "Zhang H.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60016849",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "A Secure AI-Driven Architecture for Automated Insurance Systems: Fraud Detection and Risk Measurement",
        "publication": "IEEE Access",
        "citied_by": "104",
        "cover_date": "2020-01-01",
        "Abstract": "The private insurance sector is recognized as one of the fastest-growing industries. This rapid growth has fueled incredible transformations over the past decade. Nowadays, there exist insurance products for most high-value assets such as vehicles, jewellery, health/life, and homes. Insurance companies are at the forefront in adopting cutting-edge operations, processes, and mathematical models to maximize profit whilst servicing their customers claims. Traditional methods that are exclusively based on human-in-the-loop models are very time-consuming and inaccurate. In this paper, we develop a secure and automated insurance system framework that reduces human interaction, secures the insurance activities, alerts and informs about risky customers, detects fraudulent claims, and reduces monetary loss for the insurance sector. After presenting the blockchain-based framework to enable secure transactions and data sharing among different interacting agents within the insurance network, we propose to employ the extreme gradient boosting (XGBoost) machine learning algorithm for the aforementioned insurance services and compare its performances with those of other state-of-the-art algorithms. The obtained results reveal that, when applied to an auto insurance dataset, the XGboost achieves high performance gains compared to other existing learning algorithms. For instance, it reaches 7% higher accuracy compared to decision tree models when detecting fraudulent claims. The obtained results reveal that, when applied to an auto insurance dataset, the XGboost achieves high performance gains compared to other existing learning algorithms. For instance, it reaches 7% higher accuracy compared to decision tree models when detecting fraudulent claims. Furthermore, we propose an online learning solution to automatically deal with real-time updates of the insurance network and we show that it outperforms another online state-of-the-art algorithm. Finally, we combine the developed machine learning modules with the hyperledger fabric composer to implement and emulate the artificial intelligence and blockchain-based framework.",
        "DOI": "10.1109/ACCESS.2020.2983300",
        "paper_author": "Dhieb N.",
        "affiliation_name": "Charles V. Schaefer, Jr. School of Engineering and Science",
        "affiliation_city": "Hoboken",
        "affiliation_country": "United States",
        "affiliation_id": "60148800",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Prediction of Sex-Specific Suicide Risk Using Machine Learning and Single-Payer Health Care Registry Data from Denmark",
        "publication": "JAMA Psychiatry",
        "citied_by": "97",
        "cover_date": "2020-01-01",
        "Abstract": "Importance: Suicide is a public health problem, with multiple causes that are poorly understood. The increased focus on combining health care data with machine-learning approaches in psychiatry may help advance the understanding of suicide risk. Objective: To examine sex-specific risk profiles for death from suicide using machine-learning methods and data from the population of Denmark. Design, Setting, and Participants: A case-cohort study nested within 8 national Danish health and social registries was conducted from January 1, 1995, through December 31, 2015. The source population was all persons born or residing in Denmark as of January 1, 1995. Data were analyzed from November 5, 2018, through May 13, 2019. Exposures: Exposures included 1339 variables spanning domains of suicide risk factors. Main Outcomes and Measures: Death from suicide from the Danish cause of death registry. Results: A total of 14103 individuals died by suicide between 1995 and 2015 (10 152 men [72.0%]; mean [SD] age, 43.5 [18.8] years and 3951 women [28.0%]; age, 47.6 [18.8] years). The comparison subcohort was a 5% random sample (n = 265183) of living individuals in Denmark on January 1, 1995 (130 591 men [49.2%]; age, 37.4 [21.8] years and 134 592 women [50.8%]; age, 39.9 [23.4] years). With use of classification trees and random forests, sex-specific differences were noted in risk for suicide, with physical health more important to men's suicide risk than women's suicide risk. Psychiatric disorders and possibly associated medications were important to suicide risk, with specific results that may increase clarity in the literature. Generally, diagnoses and medications measured 48 months before suicide were more important indicators of suicide risk than when measured 6 months earlier. Individuals in the top 5% of predicted suicide risk appeared to account for 32.0% of all suicide cases in men and 53.4% of all cases in women. Conclusions and Relevance: Despite decades of research on suicide risk factors, understanding of suicide remains poor. In this study, the first to date to develop risk profiles for suicide based on data from a full population, apparent consistency with what is known about suicide risk was noted, as well as potentially important, understudied risk factors with evidence of unique suicide risk profiles among specific subpopulations.",
        "DOI": "10.1001/jamapsychiatry.2019.2905",
        "paper_author": "Gradus J.L.",
        "affiliation_name": "School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60018701",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Using text mining to extract depressive symptoms and to validate the diagnosis of major depressive disorder from electronic health records",
        "publication": "Journal of Affective Disorders",
        "citied_by": "97",
        "cover_date": "2020-01-01",
        "Abstract": "Background: Many studies have used Taiwan's National Health Insurance Research database (NHIRD) to conduct psychiatric research. However, the accuracy of the diagnostic codes for psychiatric disorders in NHIRD is not validated, and the symptom profiles are not available either. This study aimed to evaluate the accuracy of diagnostic codes and use text mining to extract symptom profile and functional impairment from electronic health records (EHRs) to overcome the above research limitations. Methods: A total of 500 discharge notes were randomly selected from a medical center's database. Three annotators reviewed the notes to establish gold standards. The accuracy of diagnostic codes for major psychiatric illness was evaluated. Text mining approaches were applied to extract depressive symptoms and function profiles and to identify patients with major depressive disorder. Results: The accuracy of the diagnostic code for major depressive disorder, schizophrenia, and dementia was acceptable but that of bipolar disorder and minor depression was less satisfactory. The performance of text mining approach to recognize depressive symptoms is satisfactory; however, the recall for functional impairment is lower resulting in lower F-scores of 0.774–0.753. Using the text mining approach to identify major depressive disorder, the recall was 0.85 but precision was only 0.69. Conclusions: The accuracy of the diagnostic code for major depressive disorder in discharge notes was generally acceptable. This finding supports the utilization of psychiatric diagnoses in claims databases. The application of text mining to EHRs might help in overcoming current limitations in research using claims databases.",
        "DOI": "10.1016/j.jad.2019.09.044",
        "paper_author": "Wu C.S.",
        "affiliation_name": "National Taiwan University Hospital",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60073385",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning improves accounting estimates: evidence from insurance payments",
        "publication": "Review of Accounting Studies",
        "citied_by": "95",
        "cover_date": "2020-09-01",
        "Abstract": "Managerial estimates are ubiquitous in accounting: most balance sheet and income statement items are based on estimates; some, such as the pension and employee stock options expenses, derive from multiple estimates. These estimates are affected by objective estimation errors as well as by managerial manipulation, thereby harming the reliability and relevance of financial reports. We show that machine learning can substantially improve managerial estimates. Specifically, using insurance companies’ data on loss reserves (future customer claims) estimates and realizations, we document that the loss estimates generated by machine learning were superior to actual managerial estimates reported in financial statements in four out of five insurance lines examined. Our evidence suggests that machine learning techniques can be highly useful to managers and auditors in improving accounting estimates, thereby enhancing the usefulness of financial information to investors.",
        "DOI": "10.1007/s11142-020-09546-9",
        "paper_author": "Ding K.",
        "affiliation_name": "Southwestern University of Finance and Economics",
        "affiliation_city": "Newark",
        "affiliation_country": "United States",
        "affiliation_id": "124749756",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Combat COVID-19 with artificial intelligence and big data",
        "publication": "Journal of Travel Medicine",
        "citied_by": "88",
        "cover_date": "2020-01-01",
        "Abstract": "NA",
        "DOI": "10.1093/JTM/TAAA080",
        "paper_author": "Lin L.",
        "affiliation_name": "London School of Hygiene &amp; Tropical Medicine",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60031331",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning prediction of incidence of Alzheimer’s disease using large-scale administrative health data",
        "publication": "npj Digital Medicine",
        "citied_by": "84",
        "cover_date": "2020-12-01",
        "Abstract": "Nationwide population-based cohort provides a new opportunity to build an automated risk prediction model based on individuals’ history of health and healthcare beyond existing risk prediction models. We tested the possibility of machine learning models to predict future incidence of Alzheimer’s disease (AD) using large-scale administrative health data. From the Korean National Health Insurance Service database between 2002 and 2010, we obtained de-identified health data in elders above 65 years (N = 40,736) containing 4,894 unique clinical features including ICD-10 codes, medication codes, laboratory values, history of personal and family illness and socio-demographics. To define incident AD we considered two operational definitions: “definite AD” with diagnostic codes and dementia medication (n = 614) and “probable AD” with only diagnosis (n = 2026). We trained and validated random forest, support vector machine and logistic regression to predict incident AD in 1, 2, 3, and 4 subsequent years. For predicting future incidence of AD in balanced samples (bootstrapping), the machine learning models showed reasonable performance in 1-year prediction with AUC of 0.775 and 0.759, based on “definite AD” and “probable AD” outcomes, respectively; in 2-year, 0.730 and 0.693; in 3-year, 0.677 and 0.644; in 4-year, 0.725 and 0.683. The results were similar when the entire (unbalanced) samples were used. Important clinical features selected in logistic regression included hemoglobin level, age and urine protein level. This study may shed a light on the utility of the data-driven machine learning model based on large-scale administrative health data in AD risk prediction, which may enable better selection of individuals at risk for AD in clinical trials or early detection in clinical settings.",
        "DOI": "10.1038/s41746-020-0256-0",
        "paper_author": "Park J.H.",
        "affiliation_name": "Brookhaven National Laboratory",
        "affiliation_city": "Upton",
        "affiliation_country": "United States",
        "affiliation_id": "60006221",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Recent trends and future direction of dental research in the digital era",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "84",
        "cover_date": "2020-03-02",
        "Abstract": "The digital transformation in dental medicine, based on electronic health data information, is recognized as one of the major game-changers of the 21st century to tackle present and upcoming challenges in dental and oral healthcare. This opinion letter focuses on the estimated top five trends and innovations of this new digital era, with potential to decisively influence the direction of dental research: (1) rapid prototyping (RP), (2) augmented and virtual reality (AR/VR), (3) artificial intelligence (AI) and machine learning (ML), (4) personalized (dental) medicine, and (5) tele-healthcare. Digital dentistry requires managing expectations pragmatically and ensuring transparency for all stakeholders: patients, healthcare providers, university and research institutions, the medtech industry, insurance, public media, and state policy. It should not be claimed or implied that digital smart data technologies will replace humans providing dental expertise and the capacity for patient empathy. The dental team that controls digital applications remains the key and will continue to play the central role in treating patients. In this context, the latest trend word is created: augmented intelligence, e.g., the meaningful combination of digital applications paired with human qualities and abilities in order to achieve improved dental and oral healthcare, ensuring quality of life.",
        "DOI": "10.3390/IJERPH17061987",
        "paper_author": "Joda T.",
        "affiliation_name": "Universität Basel",
        "affiliation_city": "Basel",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60023588",
        "affiliation_state": "BS"
    },
    {
        "paper_title": "Clinical concept embeddings learned from massive sources of multimodal medical data",
        "publication": "Pacific Symposium on Biocomputing",
        "citied_by": "80",
        "cover_date": "2020-01-01",
        "Abstract": "Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-The-Art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-Trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings.",
        "DOI": "NA",
        "paper_author": "Beam A.L.",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60032499",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Epidemiology and Socioeconomic Trends in Adult Spinal Deformity Care",
        "publication": "Neurosurgery",
        "citied_by": "77",
        "cover_date": "2020-07-01",
        "Abstract": "Adult spinal deformity (ASD) has gained significant attention over the past decade with improvements in diagnostic tools, classification schemes, and surgical technique. The demographics of the aging population in the United States are undergoing a fundamental shift as medical care advances and life expectancy increases. The \"baby boomers\" represent the fastest growing demographic in the United States and by 2050, the number of individuals 65 yr and older is projected to reach 89 million, more than double its current size. Based on current prevalence estimates there are approximately 27.5 million elderly individuals with some form of spinal deformity, which will place a significant burden on our health care systems. Rates of surgery for ASD and case complexity are both increasing, with concomitant increase in the cost of deformity care. At the same time, patients are more medically complex with increasing number of comorbidities that result in increased surgical risk and complication profiles. This review aims to highlight recent trends in the epidemiology and socioeconomic patterns in surgery for ASD.",
        "DOI": "10.1093/neuros/nyz454",
        "paper_author": "Safaee M.M.",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States",
        "affiliation_id": "60031970",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Secondary use of electronic health record: Opportunities and challenges",
        "publication": "IEEE Access",
        "citied_by": "70",
        "cover_date": "2020-01-01",
        "Abstract": "In the present technological era, healthcare providers generate huge amounts of clinical data on a daily basis. Generated clinical data is stored digitally in the form of Electronic Health Record (EHR) as a central data repository of hospitals. Data contained in EHR is not only used for the patients' primary care but also for various secondary purposes such as clinical research, automated disease surveillance and clinical audits for quality enhancement. Using EHR data for secondary purposes without consent or in some cases even with consent creates privacy issues. Secondly, EHR data is also made accessible to various stakeholders including different government agencies at various geographical sites through wired or wireless networks. Sharing of EHR across multiple agencies makes it vulnerable to cyber attacks and also makes it difficult to implement strict privacy laws as in some cases data is shared with organization that is governed by specific regional law. Privacy of individuals could be severely affected when their sensitive private information contained in EHR is leaked or exposed to the public. Data leaks can cause financial losses or an individual may encounter social boycott if his / her medical condition is exposed in public. To protect patients personal data from such threats, there exists different privacy regulations such as General Data Protection Regulation (GDPR), Health Insurance Portability and Accountability Act (HIPAA) and My Health Record (MHR). However, continually evolving state-of-the-art techniques in Machine Learning (ML), Data Analytics (DA) and hacking are making it even more difficult to completely protect an individual's/patient's privacy. In this article, we have systematically examined various secondary uses of EHR with the aim to highlight how these secondary uses affect patients' privacy. Secondly, we have critically analyzed GDPR HIPAA regulations and highlighted their possible areas of improvement, considering escalating use of technology and different secondary uses of EHR.",
        "DOI": "10.1109/ACCESS.2020.3011099",
        "paper_author": "Shah S.M.",
        "affiliation_name": "Salim Habib University",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60279721",
        "affiliation_state": "Sindhi"
    },
    {
        "paper_title": "A Survey on Churn Analysis in Various Business Domains",
        "publication": "IEEE Access",
        "citied_by": "67",
        "cover_date": "2020-01-01",
        "Abstract": "In this paper, we present churn prediction techniques that have been released so far. Churn prediction is used in the fields of Internet services, games, insurance, and management. However, since it has been used intensively to increase the predictability of various industry/academic fields, there is a big difference in its definition and utilization. In this paper, we collected the definitions of churn used in the fields of business administration, marketing, IT, telecommunications, newspapers, insurance and psychology, and described their differences. Based on this, we classified and explained churn loss, feature engineering, and prediction models. Our study can be used to select the definition of churn and its associated models suitable for the service field that researchers are most interested in by integrating fragmented churn studies in industry/academic fields.",
        "DOI": "10.1109/ACCESS.2020.3042657",
        "paper_author": "Ahn J.",
        "affiliation_name": "Intelligence Laboratories",
        "affiliation_city": "Seongnam",
        "affiliation_country": "South Korea",
        "affiliation_id": "125554725",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Accountable algorithms? The ethical implications of data-driven business models",
        "publication": "Journal of Service Management",
        "citied_by": "64",
        "cover_date": "2020-09-24",
        "Abstract": "Purpose: The purpose of this study is to identify, analyze and explain the ethical implications that can result from the datafication of service. Design/methodology/approach: This study uses a midrange theorizing approach to integrate currently disconnected perspectives on technology-enabled service, data-driven business models, data ethics and business ethics to introduce a novel analytical framework centered on data-driven business models as the general metatheoretical unit of analysis. The authors then contextualize the framework using data-intensive insurance services. Findings: The resulting midrange theory offers new insights into how using machine learning, AI and big data sets can lead to unethical implications. Centered around 13 ethical challenges, this work outlines how data-driven business models redefine the value network, alter the roles of individual actors as cocreators of value, lead to the emergence of new data-driven value propositions, as well as novel revenue and cost models. Practical implications: Future research based on the framework can help guide practitioners to implement and use advanced analytics more effectively and ethically. Originality/value: At a time when future technological developments related to AI, machine learning or other forms of advanced data analytics are unpredictable, this study instigates a critical and timely discourse within the service research community about the ethical implications that can arise from the datafication of service by introducing much-needed theory and terminology.",
        "DOI": "10.1108/JOSM-03-2019-0073",
        "paper_author": "Breidbach C.F.",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60031004",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Metamorphic testing and certified mitigation of fairness violations in NLP models",
        "publication": "IJCAI International Joint Conference on Artificial Intelligence",
        "citied_by": "61",
        "cover_date": "2020-01-01",
        "Abstract": "Natural language processing (NLP) models have been increasingly used in sensitive application domains including credit scoring, insurance, and loan assessment. Hence, it is critical to know that the decisions made by NLP models are free of unfair bias toward certain subpopulation groups. In this paper, we propose a novel framework employing metamorphic testing, a well-established software testing scheme, to test NLP models and find discriminatory inputs that provoke fairness violations. Furthermore, inspired by recent breakthroughs in the certified robustness of machine learning, we formulate NLP model fairness in a practical setting as (o, k)-fairness and accordingly smooth the model predictions to mitigate fairness violations. We demonstrate our technique using popular (commercial) NLP models, and successfully flag thousands of discriminatory inputs that can cause fairness violations. We further enhance the evaluated models by adding certified fairness guarantee at a modest cost.",
        "DOI": "NA",
        "paper_author": "Ma P.",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008592",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Machine learning algorithm for early detection of end-stage renal disease",
        "publication": "BMC Nephrology",
        "citied_by": "61",
        "cover_date": "2020-12-01",
        "Abstract": "Background: End stage renal disease (ESRD) describes the most severe stage of chronic kidney disease (CKD), when patients need dialysis or renal transplant. There is often a delay in recognizing, diagnosing, and treating the various etiologies of CKD. The objective of the present study was to employ machine learning algorithms to develop a prediction model for progression to ESRD based on a large-scale multidimensional database. Methods: This study analyzed 10,000,000 medical insurance claims from 550,000 patient records using a commercial health insurance database. Inclusion criteria were patients over the age of 18 diagnosed with CKD Stages 1–4. We compiled 240 predictor candidates, divided into six feature groups: demographics, chronic conditions, diagnosis and procedure features, medication features, medical costs, and episode counts. We used a feature embedding method based on implementation of the Word2Vec algorithm to further capture temporal information for the three main components of the data: diagnosis, procedures, and medications. For the analysis, we used the gradient boosting tree algorithm (XGBoost implementation). Results: The C-statistic for the model was 0.93 [(0.916–0.943) 95% confidence interval], with a sensitivity of 0.715 and specificity of 0.958. Positive Predictive Value (PPV) was 0.517, and Negative Predictive Value (NPV) was 0.981. For the top 1 percentile of patients identified by our model, the PPV was 1.0. In addition, for the top 5 percentile of patients identified by our model, the PPV was 0.71. All the results above were tested on the test data only, and the threshold used to obtain these results was 0.1. Notable features contributing to the model were chronic heart and ischemic heart disease as a comorbidity, patient age, and number of hypertensive crisis events. Conclusions: When a patient is approaching the threshold of ESRD risk, a warning message can be sent electronically to the physician, who will initiate a referral for a nephrology consultation to ensure an investigation to hasten the establishment of a diagnosis and initiate management and therapy when appropriate.",
        "DOI": "10.1186/s12882-020-02093-0",
        "paper_author": "Segal Z.",
        "affiliation_name": "Diagnostic Robotics Inc.",
        "affiliation_city": "Ariel",
        "affiliation_country": "Israel",
        "affiliation_id": "125429453",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep Learning Models for Health and Safety Risk Prediction in Power Infrastructure Projects",
        "publication": "Risk Analysis",
        "citied_by": "61",
        "cover_date": "2020-10-01",
        "Abstract": "Inappropriate management of health and safety (H&S) risk in power infrastructure projects can result in occupational accidents and equipment damage. Accidents at work have detrimental effects on workers, company, and the general public. Despite the availability of H&S incident data, utilizing them to mitigate accident occurrence effectively is challenging due to inherent limitations of existing data logging methods. In this study, we used a text-mining approach for retrieving meaningful terms from data and develop six deep learning (DL) models for H&S risks management in power infrastructure. The DL models include DNNclassify (risk or no risk), DNNreg1 (loss time), DNNreg2 (body injury), DNNreg3 (plant and fleet), DNNreg4 (equipment), and DNNreg5 (environment). An H&S risk database obtained from a leading UK power infrastructure construction company was used in developing the models using the H2O framework of the R language. Performances of DL models were assessed and benchmarked with existing models using test data and appropriate performance metrics. The overall accuracy of the classification model was 0.93. The average R2 value for the five regression models was 0.92, with mean absolute error between 0.91 and 0.94. The presented results, in addition to the developed user-interface module, will help practitioners obtain a better understanding of H&S challenges, minimize project costs (such as third-party insurance and equipment repairs), and offer effective strategies to mitigate H&S risk.",
        "DOI": "10.1111/risa.13425",
        "paper_author": "Ajayi A.",
        "affiliation_name": "University of the West of England",
        "affiliation_city": "Bristol",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60019611",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The Role of Wearables in Heart Failure",
        "publication": "Current Heart Failure Reports",
        "citied_by": "58",
        "cover_date": "2020-08-01",
        "Abstract": "Purpose of Review: This review discusses how wearable devices—sensors externally applied to the body to measure a physiological signal—can be used in heart failure (HF) care. Recent Findings: Most wearables are marketed to consumers and can measure movement, heart rate, and blood pressure; detect and monitor arrhythmia; and support exercise training and rehabilitation. Wearable devices targeted at healthcare professionals include ECG patch recorders and vests, patches, and textiles with in-built sensors for improved prognostication and the early detection of acute decompensation. Integrating data from wearables into clinical decision-making has been slow due to clinical inertia and concerns regarding data security and validity, lack of evidence of meaningful impact, interoperability, regulatory and reimbursement issues, and legal liability. Summary: Although few studies have assessed how best to integrate wearable technologies into clinical practice, their use is rapidly expanding and may support improved decision-making by patients and healthcare professionals along the whole patient pathway.",
        "DOI": "10.1007/s11897-020-00467-x",
        "paper_author": "Singhal A.",
        "affiliation_name": "Royal Brompton Hospital",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60009009",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting prolonged opioid prescriptions in opioid-naïve lumbar spine surgery patients",
        "publication": "Spine Journal",
        "citied_by": "58",
        "cover_date": "2020-06-01",
        "Abstract": "IMPORTANCE: Preoperative determination of the potential for postoperative opioid dependence in previously naïve patients undergoing elective spine surgery may facilitate targeted interventions. OBJECTIVE: The purpose of this study was to develop supervised machine learning algorithms for preoperative prediction of prolonged opioid prescription use in opioid-naïve patients following lumbar spine surgery. DESIGN: Retrospective review of clinical registry data. Variables considered for prediction included demographics, insurance status, preoperative medications, surgical factors, laboratory values, comorbidities, and neighborhood characteristics. Five supervised machine learning algorithms were developed and assessed by discrimination, calibration, Brier score, and decision curve analysis. SETTING: One healthcare entity (two academic medical centers, three community hospitals), 2000 to 2018. PARTICIPANTS: Opioid-naïve patients undergoing decompression and/or fusion for lumbar disk herniation, stenosis, and spondylolisthesis. MAIN OUTCOME: Sustained prescription opioid use exceeding 90 days after surgery. RESULTS: Overall, of 8,435 patients included, 359 (4.3%) were found to have prolonged postoperative opioid prescriptions. The elastic-net penalized logistic regression achieved the best performance in the independent testing set not used for algorithm development with c-statistic=0.70, calibration intercept=0.06, calibration slope=1.02, and Brier score=0.039. The five most important factors for prolonged opioid prescriptions were use of instrumented spinal fusion, preoperative benzodiazepine use, preoperative antidepressant use, preoperative gabapentin use, and uninsured status. Individual patient-level explanations were provided for the algorithm predictions and the algorithms were incorporated into an open access digital application available here: https://sorg-apps.shinyapps.io/lumbaropioidnaive/. CONCLUSION AND RELEVANCE: The clinician decision aid developed in this study may be helpful to preoperatively risk-stratify opioid-naïve patients undergoing lumbar spine surgery. The tool demonstrates moderate discriminative capacity for identifying those at greatest risk of prolonged prescription opioid use. External validation is required to further support the potential utility of this tool in practice.",
        "DOI": "10.1016/j.spinee.2019.12.019",
        "paper_author": "Karhade A.V.",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States",
        "affiliation_id": "60002746",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Artificial intelligence-assisted prediction of preeclampsia: Development and external validation of a nationwide health insurance dataset of the BPJS Kesehatan in Indonesia",
        "publication": "EBioMedicine",
        "citied_by": "57",
        "cover_date": "2020-04-01",
        "Abstract": "Background: We developed and validated an artificial intelligence (AI)-assisted prediction of preeclampsia applied to a nationwide health insurance dataset in Indonesia. Methods: The BPJS Kesehatan dataset have been preprocessed using a nested case-control design into preeclampsia/eclampsia (n = 3318) and normotensive pregnant women (n = 19,883) from all women with one pregnancy. The dataset provided 95 features consisting of demographic variables and medical histories started from 24 months to event and ended by delivery as the event. Six algorithms were compared by area under the receiver operating characteristics curve (AUROC) with a subgroup analysis by time to the event. We compared our model to similar prediction models from systematically reviewed studies. In addition, we conducted a text mining analysis based on natural language processing techniques to interpret our modeling results. Findings: The best model consisted of 17 predictors extracted by a random forest algorithm. Nine∼12 months to the event was the period that had the best AUROC in external validation by either geographical (0.88, 95% confidence interval (CI) 0.88–0.89) or temporal split (0.86, 95% CI 0.85–0.86). We compared this model to prediction models in seven studies from 869 records in PUBMED, EMBASE, and SCOPUS. This model outperformed the previous models in terms of the precision, sensitivity, and specificity in all validation sets. Interpretation: Our low-cost model improved preliminary prediction to decide pregnant women that will be predicted by the models with high specificity and advanced predictors. Funding: This work was supported by grant no. MOST108-2221-E-038-018 from the Ministry of Science and Technology of Taiwan.",
        "DOI": "10.1016/j.ebiom.2020.102710",
        "paper_author": "Sufriyana H.",
        "affiliation_name": "Taipei Medical University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60022095",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "XGBoost in handling missing values for life insurance risk prediction",
        "publication": "SN Applied Sciences",
        "citied_by": "56",
        "cover_date": "2020-08-01",
        "Abstract": "Insurance risk prediction is carried out to classify the levels of risk in insurance industries. From the machine learning point of view, the problem of risk level prediction is a multi-class classification. To classify the risk, a machine learning model will predict the level of applicant’s risk based on historical data. In the insurance applicant’s historical data, there will be the possibility of missing values so that it is necessary to deal with these problems to provide better performance. XGBoost is a machine learning method that is widely used for classification problems and can handle missing values without an imputation preprocessing. This paper analyzed the performance of the XGBoost model in handling the missing values for risk prediction in life insurance. The simulations show that the XGBoost model without any imputation preprocessing gives a comparable accuracy to one of the XGBoost models with an imputation preprocessing.",
        "DOI": "10.1007/s42452-020-3128-y",
        "paper_author": "Rusdah D.A.",
        "affiliation_name": "Universitas Indonesia",
        "affiliation_city": "Depok",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069377",
        "affiliation_state": "West Java"
    },
    {
        "paper_title": "Predicting suicide attempt or suicide death following a visit to psychiatric specialty care: A machine learning study using Swedish national registry data",
        "publication": "PLoS Medicine",
        "citied_by": "52",
        "cover_date": "2020-11-01",
        "Abstract": "Background: Suicide is a major public health concern globally. Accurately predicting suicidal behavior remains challenging. This study aimed to use machine learning approaches to examine the potential of the Swedish national registry data for prediction of suicidal behavior. Methods and findings: The study sample consisted of 541,300 inpatient and outpatient visits by 126,205 Swedenborn patients (54% female and 46% male) aged 18 to 39 (mean age at the visit: 27.3) years to psychiatric specialty care in Sweden between January 1, 2011 and December 31, 2012. The most common psychiatric diagnoses at the visit were anxiety disorders (20.0%), major depressive disorder (16.9%), and substance use disorders (13.6%). A total of 425 candidate predictors covering demographic characteristics, socioeconomic status (SES), electronic medical records, criminality, as well as family history of disease and crime were extracted from the Swedish registry data. The sample was randomly split into an 80% training set containing 433,024 visits and a 20% test set containing 108,276 visits. Models were trained separately for suicide attempt/death within 90 and 30 days following a visit using multiple machine learning algorithms. Model discrimination and calibration were both evaluated. Among all eligible visits, 3.5% (18,682) were followed by a suicide attempt/death within 90 days and 1.7% (9,099) within 30 days. The final models were based on ensemble learning that combined predictions from elastic net penalized logistic regression, random forest, gradient boosting, and a neural network. The area under the receiver operating characteristic (ROC) curves (AUCs) on the test set were 0.88 (95% confidence interval [CI] = 0.87-0.89) and 0.89 (95% CI = 0.88-0.90) for the outcome within 90 days and 30 days, respectively, both being significantly better than chance (i.e., AUC = 0.50) (p < 0.01). Sensitivity, specificity, and predictive values were reported at different risk thresholds. A limitation of our study is that our models have not yet been externally validated, and thus, the generalizability of the models to other populations remains unknown. Conclusions: By combining the ensemble method of multiple machine learning algorithms and high-quality data solely from the Swedish registers, we developed prognostic models to predict shortterm suicide attempt/death with good discrimination and calibration. Whether novel predictors can improve predictive performance requires further investigation.",
        "DOI": "10.1371/JOURNAL.PMED.1003416",
        "paper_author": "Chen Q.",
        "affiliation_name": "Karolinska Institutet",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60012311",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "Cyber resilience in firms, organizations and societies",
        "publication": "Internet of Things (Netherlands)",
        "citied_by": "52",
        "cover_date": "2020-09-01",
        "Abstract": "Cyber resilience involves most societal actors, i.e. organizations, individuals, threat actors, governments, insurers, etc., at most levels of organization. Actors are embedded within each other and choose strategies based on beliefs and preferences which impact and is impacted by cyber resilience. The article reviews the literature, attempting to capture the core ingredients of cyber resilience. Non-threat actors seeking to obtain cyber resilience are distinguished from threat actors. Actors have resources, competence, technology, and tools. They make choices that impact the cyber resilience for all actors, including themselves. Cyber resilience relates to cyber insurance through entry requirements or preconditions for cyber contracts, need for various services such as incident response, data gathering, and cover limitations. Cyber resilience is linked to the internet of things which in the future can be expected to simplify life through artificial intelligence and machine learning, while being vulnerable through a large attack surface, insufficient technology, challenging handling of data, possible high trust in computers and software, and ethics.",
        "DOI": "10.1016/j.iot.2020.100204",
        "paper_author": "Hausken K.",
        "affiliation_name": "Universitetet i Stavanger",
        "affiliation_city": "Stavanger",
        "affiliation_country": "Norway",
        "affiliation_id": "60014497",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Performance of CatBoost and XGBoost in Medicare Fraud Detection",
        "publication": "Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",
        "citied_by": "51",
        "cover_date": "2020-12-01",
        "Abstract": "Due to the size of the data involved, performance is an important consideration in the task of detecting fraudulent Medicare insurance claims. We evaluate CatBoost and XGBoost on the task of Medicare fraud detection, and report performance in terms of running time and Area Under the Receiver Operating Characteristic Curve (AUC). We show that adding a categorical feature for XGBoost and CatBoost improves performance in terms of AUC, and that CatBoost's performance is higher in a statistically significant sense. Moreover, we conduct experiments to find the optimal number of decision trees to use for XGBoost and CatBoost in the task of Medicare fraud detection. This is an important contribution because the number of trees in the ensemble governs overall resource consumption of a Gradient Boosted Decision Tree implementation. We find that with a purely numerical dataset, CatBoost and XGBoost yield nearly equivalent performance in terms of AUC, and XGBoost has a shorter training time. With respect to Medicare fraud detection, to the best of our knowledge, this is the first study to evaluate the performance of CatBoost and XGBoost in terms of running time and AUC on highly imbalanced, Big Data. Our contribution of evaluating running time performance on a large imbalanced dataset benefits researchers looking for more efficient utilization of valuable resources.",
        "DOI": "10.1109/ICMLA51294.2020.00095",
        "paper_author": "Hancock J.",
        "affiliation_name": "FAU College of Engineering and Computer Science",
        "affiliation_city": "Boca Raton",
        "affiliation_country": "United States",
        "affiliation_id": "60144960",
        "affiliation_state": "FL"
    }
]